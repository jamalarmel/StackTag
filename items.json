[
{"link": "https://stackoverflow.com//questions/231767/what-does-the-yield-keyword-do-in-python", "qbody": "What is the use of the  keyword in Python? What does it do?For example, I'm trying to understand this code:And this is the caller:What happens when the method  is called?\nIs a list returned? A single element? Is it called again? When will subsequent calls stop?To understand what  does, you must understand what  are. And before generators come .When you create a list, you can read its items one by one. Reading its items one by one is called iteration: is an . When you use a list comprehension, you create a list, and so an iterable:Everything you can use \"\" on is an iterable; , , files...These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.Generators are iterators, but . It's because they do not store all the values in memory, :It is just the same except you used  instead of . BUT, you  perform  a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one. is a keyword that is used like , except the function will return a generator.Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.To master , you must understand that  The function only returns the generator object, this is a bit tricky :-)Then, your code will be run each time the  uses the generator.Now the hard part:The first time the  calls the generator object created from your function, it will run the code in your function from the beginning until it hits , then it'll return the first value of the loop. Then, each other call will run the loop you have written in the function one more time, and return the next value, until there is no value to return.The generator is considered empty once the function runs but does not hit  anymore. It can be because the loop had come to an end, or because you do not satisfy an  anymore.Generator:Caller:This code contains several smart parts:Usually we pass a list to it:But in your code it gets a generator, which is good because:And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples and generators! This is called duck typing and is one of the reason why Python is so cool. But this is another story, for another question...You can stop here, or read a little bit to see an advanced use of a generator:It can be useful for various things like controlling access to a resource.The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?\nChain two generators? Group values in a nested list with a one liner?  without creating another list?Then just .An example? Let's see the possible orders of arrival for a 4 horse race:Iteration is a process implying iterables (implementing the  method) and iterators (implementing the  method).\nIterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.More about it in this article about .When you see a function with  statements, apply this easy trick to understand what will happen:This trick may give you an idea of the logic behind the function, but what actually happens with  is significantly different that what happens in the list based approach. In many cases the yield approach will be a lot more memory efficient and faster too. In other cases this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more...First, the  - when you writePython performs the following two steps:The truth is Python performs the above two steps anytime it wants to  the contents of an object - so it could be a for loop, but it could also be code like  (where  is a Python list).Here  is an  because it implements the iterator protocol. In a user defined class, you can implement the  method to make instances of your class iterable. This method should return an . An iterator is an object with a  method. It is possible to implement both  and  on the same class, and have  return . This will work for simple cases, but not when you want two iterators looping over the same object at the same time.So that's the iterator protocol, many objects implement this protocol:Note that a  loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls . Built-in lists return their items one by one, dictionaries return the  one by one, files return the  one by one, etc. And generators return... well that's where  comes in:Instead of  statements, if you had three  statements in  only the first would get executed, and the function would exit. But  is no ordinary function. When  is called, it  return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the  loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the  it previously returned from, executes the next line of code, in this case a  statement, and returns that as the next item. This happens until the function exits, at which point the generator raises , and the loop exits. So the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing  and  methods to keep the  loop happy. At the other end however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode.Usually you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class  that keeps state in instance members and performs the next logical step in it's  (or  in Python 3) method. Depending on the logic, the code inside the  method may end up looking very complex and be prone to bugs. Here generators provide a clean and easy solution.Think of it this way:An iterator is just a fancy sounding term for an object that has a next() method.  So a yield-ed function ends up being something like this:Original version:This is basically what the python interpreter does with the above code:For more insight as to what's happening behind the scenes, the for loop can be rewritten to this:Does that make more sense or just confuse you more?  :) I should note that this IS an oversimplification for illustrative purposes.  :) Forgot to throw the StopIteration exceptionThe  keyword is reduced to two simple facts:In a nutshell: , and  the generator should incrementally spit out.Let's define a function  that's just like Python's . Calling  RETURNS A GENERATOR:To force the generator to immediately return its pending values, you can pass it into  (just like you could any iterable):The above example can be thought of as merely creating a list which you append to and return:There is one major difference, though; see the last section.An iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so:To get a better feel for generators, you can play around with the  module (be sure to use  rather than  when warranted). For example, you might even use generators to implement infinitely-long lazy lists like . You could implement your own , or alternatively do so with the  keyword in a while-loop.Please note: generators can actually be used for many more things, such as  or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find.This is how the \"Python iteration protocol\" works. That is, what is going on when you do . This is what I describe earlier as a \"lazy, incremental list\".The built-in function  just calls the objects  function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the  function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that...Normally, most people would not care about the following distinctions and probably want to stop reading here.In Python-speak, an  is any object which \"understands the concept of a for-loop\" like a list , and an  is a specific instance of the requested for-loop like . A  is exactly the same as any iterator, except for the way it was written (with function syntax).When you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself.Thus, in the unlikely event that you are failing to do something like this...... then remember that a generator is an ; that is, it is one-time-use. If you want to reuse it, you should call  again. If you need to use the result twice, convert the result to a list and store it in a variable . Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use  if absolutely necessary, since the copyable iterator Python  standards proposal has been deferred. is just like  - it returns whatever you tell it to.  The only difference is that the next time you call the function, execution starts from the last call to the  statement.In the case of your code, the function  is acting like an iterator so that when you extend your list, it adds one element at a time to the new list. calls an iterator until it's exhausted.  In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list.There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this:Then I can use it in other code like this:It really helps simplify some problems, and makes some things easier to work with.  is only legal inside of a function definition, and The idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is  at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield. provides an \neasy way of , defined by the following two methods: \n and  (Python 2) or  (Python 3).  Both of those methods\nmake an object an iterator that you could type-check with the  Abstract Base \nClass from the  module.The generator type is a sub-type of iterator:And if necessary, we can type-check like this:A feature of an  , you can't reuse or reset it:You'll have to make another if you want to use its functionality again (see footnote 2):One can yield data programmatically, for example:The above simple generator is also equivalent to the below - as of Python 3.3 (and not available in Python 2), you can use :However,  also allows for delegation to subgenerators, \nwhich will be explained in the following section on cooperative delegation with sub-coroutines. forms an expression that allows data to be sent into the generator (see footnote 3)Here is an example, take note of the  variable, which will point to the data that is sent to the generator:First, we must queue up the generator with the builtin function, . It will \ncall the appropriate  or  method, depending on the version of\nPython you are using:And now we can send data into the generator. (.) :Now, recall that  is available in Python 3. This allows us to delegate\ncoroutines to a subcoroutine:And now we can delegate functionality to a sub-generator and it can be used\nby a generator just as above:You can read more about the precise semantics of  in The  method raises  at the point the function \nexecution was frozen. This will also be called by  so you \ncan put any cleanup code where you handle the :You can also throw an exception which can be handled in the generator\nor propagated back to the user:I believe I have covered all aspects of the following question:It turns out that  does a lot. I'm sure I could add even more \nthorough examples to this. If you want more or have some constructive criticism, let me know by commenting\nbelow.In :An  is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with , but you can't return a value.In : For those who prefer a minimal working example, meditate on this interactive  session:Yield gives you a generator. As you can see, in the first case foo holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called. In the second case, bar just gives you a generator. A generator is an iterable--which means you can use it in a for loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through. Again, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :)This is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things.There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators.  Here is the PL theory answer:The  statement in python returns a generator.  A generator in python is a function that returns  (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on).Continuations in programming languages theory are a much more fundamental kind of computation, but they are not often used because they are extremely hard to reason about and also very difficult to implement.  But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state are saved the current values of variables and the operations that have yet to be performed, and so on. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out.Continuations, in this more general form, can be implemented in two ways. In the  way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored.In continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows:In this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger)The rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read.Now let's talk about generators in python. Generators are a specific subtype of continuation. Whereas  (i.e., the program's call stack), . Although, this definition is slightly misleading for certain use cases of generators. For instance:This is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e., ). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration.To reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand ).But you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style: Whenever  is called, it tells the function to return a continuation.  When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode  (i.e., not pseudocode but not code) the generator's  method is basically as follows: where  keyword is actually syntactic sugar for the real generator function, basically something like:Remember that this is just pseudocode and the actual implementation of generators in python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the  keyword.It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as  if you're familiar with those.There's an  which explains it reasonably well (for Python) as far as I can see.The key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values - . Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself.An example in plain language. I will provide a correspondence between high-level human concepts to low-level python concepts.I want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following:This is what a generator does (a function that contains a ); it starts executing, pauses whenever it does a , and when asked for a  value it continues from the point it was last. It fits perfectly by design with the iterator protocol of python, which describes how to sequentially request for values.The most famous user of the iterator protocol is the  command in python. So, whenever you do a:it doesn't matter if  is a list, a string, a dictionary or a generator  like described above; the result is the same: you read items off a sequence one by one.Note that ining a function which contains a  keyword is not the only way to create a generator; it's just the easiest way to create one.For more accurate information, read about , the  and  in the Python documentation.While a lot of answers show why you'd use a  to create a generator, there are more uses for .  It's quite easy to make a coroutine, which enables the passing of information between two blocks of code.  I won't repeat any of the fine examples that have already been given about using  to create a generator.To help understand what a  does in the following code, you can use your finger to trace the cycle through any code that has a .  Every time your finger hits the , you have to wait for a  or a  to be entered.  When a  is called, you trace through the code until you hit the \u2026 the code on the right of the  is evaluated and returned to the caller\u2026 then you wait.  When  is called again, you perform another loop through the code.  However, you'll note that in a coroutine,  can also be used with a \u2026 which will send a value from the caller  the yielding function. If a  is given, then  receives the value sent, and spits it out the left hand side\u2026 then the trace through the code progresses until you hit the  again (returning the value at the end, as if  was called).For example:There is another  use and meaning (since python 3.3):moreover  will introduce (since python 3.5):to avoid coroutines confused with regular generator (today  is used in both).I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already.Also, note that  can be used in coroutines as the dual of their use in generator functions.  Although it isn't the same use as your code snippet,  can be used as an expression in a function.  When a caller sends a value to the method using the  method, then the coroutine will execute until the next  statement is encountered.Generators and coroutines are a cool way to set up data-flow type applications.  I thought it would be worthwhile knowing about the other use of the  statement in functions.This was my first aha-moment with yield. is a sugary way to say Same behavior:Different behavior:Yield is : you can only iterate through once. Conceptually the yield-function returns an ordered container of things. But it's revealing that we call any function with a yield in it a . And the term for what it returns is an .Yield is , it puts off computation until you need it. A function with a yield in it  when you call it. The iterator object it returns uses  to maintain the function's internal context. Each time you call  on the iterator (as happens in a for-loop), execution inches forward to the next yield. (Or , which raises  and ends the series.)Yield is . It can do infinite loops:If you need  and the series isn't humongous, just pass the iterator to Brilliant choice of the word  because  apply:...provide the next data in the series....relinquish CPU execution until the iterator advances.Here are some  as if Python did not provide syntactic sugar for them (or in a language without native syntax, like ). Snippets from that link is below. (because )Here is a simple example:output :I am not a Python developer, but it looks to me  holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work.Seems to me an interesting and nice ability :D From a programming viewpoint, the iterators are implemented as  To implement iterators/generators/thread pools for concurrent execution/etc as thunks (also called anonymous functions), one uses messages sent to a closure object, which has a dispatcher, and the dispatcher answers to \"messages\".\"\" is a message sent to a closure, created by \"\" call.There are lots of ways to implement this computation.  I used mutation but it is easy to do it without mutation, by returning the current value and the next yielder.Here is a demonstration which uses the structure of R6RS but the semantics is absolutely identical as in python, it's the same model of computation, only a change in syntax is required to rewrite it in python.Here is a mental image of what  does.I like to think of a thread as having a stack (even when it's not implemented that way).When a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again.With a  function, when its code begins to run (i.e. after the function is called, returning a generator object, whose  method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the  statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular  statement).So it's a kind of a frozen function that the generator is hanging onto.When  is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage.Compare the following examples:When we call the second function, it behaves very differently to the first. The  statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with.Calling  doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the  prefix for readability.)The  and  fields are where the frozen state is stored. Exploring them with , we can confirm that our mental model above is credible.Like every answer suggests,  is used for creating a sequence generator. It's used for generating some sequence dynamically. Eg. While reading a file line by line on a network, you can use the  function as follows:You can use it in your code as follows :The execution control will be transferred from getNextLines() to the for loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time.Thus in short, a function with the following codewill print I hope this helps you. is like a return element for a function. The difference is, that the  element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling .A  in a function will return a single value.If you want  use .More importantly,  is a  i.eIt will run the code in your function from the beginning until it hits . Then, it\u2019ll return the first value of the loop. \nThen, every other call will run the loop you have written in the function one more time, returning the next value until there is no value to return.(My below answer only speaks from the perspective of using Python generator, not the , which involves some tricks of stack and heap manipulation.)When  is used instead of a  in a python function, that function is turned into something special called . That function will return an object of  type.  Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function  as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a  exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about  but this  from the  is the most digestable.(Now I want to talk about the rationale behind , and the  based on my own understanding. I hope this can help you grasp the  of iterator and generator. Such concept shows up in other languages as well such as C#.)As I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this  approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand. . There are 2 approaches to wrap such metadata.Either way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you.The  keyword simply collects returning results. Think of  like Most questions regarding the  statement and the semantics/functionality that it introduces are present in . The collective knowledge from all previous answers is amazing but I'll add an answer that references the official presentation.So first of, the form of the  statement:consist of the   along with an optional . Syntactically yield can only appear inside a function definition and its presence alone is responsible for tranforming a function into a generator object:So after you define your generator you're left with a generator function that is waiting to be called: So parameters are bound in the same way as they do for all callable but the body of the generator object is not executed, what happens is:We get back an object that comforms to the  this means that the  object implements  and  and as such can be used in  loops like any object that supports iteration. The key difference that  makes is here, specifically:So everything  the  is executed and then execution stops, at that point what happens is: So in the case of a  loop:  the value of  is going to be equal to  as previously stated.But \"frozen\" you may ask, what does that mean? This is further explained as: So state is retained when  is encountered thereby allowing consequent calls to  to continue smoothly. When a  call is made the generator is going to execute everything until it finds another  statement. That cicle is repeated until no  (i.e control flows off the end of the generator) or a  is found in which case a  exception is raised signalling that the generator has been exhausted.Many people use  rather than  but in some cases  can be more efficient and easier to work with.Here is an example which  is definitely best for:Both functions do the same thing but  uses 3 lines instead of 5 and has one less variable to worry about.As you can see both functions do the same thing, the only difference is  gives a list and  gives a generatorA real life example would be something like reading a file line by line or if you just want to make a generatorAt a glance, the yield statement is used to define generators, replacing the return of a function to provide a result to its caller without destroying local variables. Unlike a function, where on each call it starts with new set of variables, a generator will resume the execution where it was left off.About Python Generators\nSince the yield keyword is only used with generators, it makes sense to recall the concept of generators first.The idea of generators is to calculate a series of results one-by-one on demand (on the fly). In the simplest case, a generator can be used as a list, where each element is calculated lazily. Let's compare a list and a generator that do the same thing - return powers of two:Iterating over the list and the generator looks completely the same. However, although the generator is iterable, it is not a collection and thus has no length. Collections (lists, tuples, sets, etc) keep all values in memory and we can access them whenever needed. A generator calculates the values on the fly and forgets them, so it does not have any overview about the own result set.Generators are especially useful for memory-intensive tasks, where there is no need to keep all of the elements of a memory-heavy list accessible at the same time. Calculating a series of values one-by-one can also be useful in situations where the complete result is never needed, yielding intermediate results to the caller until some requirement is satisfied and further processing stops.Using the Python \"yield\" keyword\nA good example is a search task, where typically there is no need to wait for all results to be found. Performing a file-system search, a user would be happier to receive results on-the-fly, rather the wait for a search engine to go through every single file and only afterwards return results. Are there any people who really navigate through all Google search results until the last page?Since a search functionality cannot be created using list-comprehensions, we are going to define a generator using a function with the yield statement/keyword. The yield instruction should be put into a place where the generator returns an intermediate result to the caller and sleeps until the next invocation occurs. So far the most practical aspects of Python generators have been described. For more detailed info and an interesting discussion take a look at the Python Enhancement Proposal 255, which discusses the feature of the language in detail.Happy Pythoning!\nIn summary, the  statement transforms your function into a factory that produces a special object called a  which wraps around the body of your original function. When the  is iterated, it executes your function  until it reaches the next  then suspends execution and evaluates to the value passed to . It repeats this process on each iteration until the path of execution exits the function. For instance;simply outputs ;The power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculationsSay you wanted to create a your own  function that produces an iterable range of numbers, you could do it like so,and use it like this;but this is ineffecient becauseLuckily Guido and his team were generous enough to develop generators so we could just do this;Now upon each iteration a function on the generator called  executes the function until it either reaches a 'yield' statement in which it stops and  'yields' the value or reaches the end of the function. In this case on the first call,  executes up to the yield statement and yield 'n', on the next call it will execute the  increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function. Yet another TL;DR:  returns the next element of the list:  will compute the next element on the fly (execute code)You can see the yield/generator as a way to manually run the  from outside (like continue loop 1 step), by calling next, however complex the flow.NOTE: the generator is  a normal function, it remembers previous state like local variables (stack), see other answers or articles for detailed explanation, the generator can only be .\nYou could do without  but it would not be as nice, so it can be considered 'very nice' language sugar."},
{"link": "https://stackoverflow.com//questions/1712227/how-to-get-the-size-of-a-list", "qbody": "How do I get the number of elements in the list?The  function can be used with a lot of types in  - both built-in types and library types.While this may not be useful due to the fact that it'd make a lot more sense as being \"out of the box\" functionality, a fairly simple hack would be to build a class with a  property:You can use it like so:Essentially, it's exactly identical to a list object, with the added benefit of having an OOP-friendly  property.As always, your mileage may vary.To find the size of a list, use the builtin function, :And now:returns 3. is implemented with , from the data model :And we can also see that  is a method of lists:returns 3.And in fact we see we can get this information for all of the described types:Answering your question as the examples also given previously:Besides  you can also use  (requires python 3.4+). For normal  both are equivalent but  makes it possible to get the length of a list-iterator, which could be useful in certain circumstances:But  is by definition only a \"hint\", so most of the time  is better.I've seen several answers suggesting accessing . This is alright when dealing with built-in classes like  but it could lead to problems with custom classes because  (and ) implement some safety checks. For example both do not allow negative lengths or lengths that exceed a certain value (the  value). So it's always safer to use the  function instead of the  method!If you need to know MEMORY USAGE of a given type, you can use the function sys.getsizeofThis function works fine for native python types\nBut if you need to analyse complex structures, have a look at .The Python  function is enough for determining a list's size. There is also the  function you can use."},
{"link": "https://stackoverflow.com//questions/663171/is-there-a-way-to-substring-a-string-in-python", "qbody": "Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?Maybe like ?If leaving the second part means 'till the end', if you leave the first part, does it start from the start?Python calls this concept \"slicing\" and it works on more than just strings. Take a look  for a comprehensive introduction.Just for completeness as nobody else has mentioned it.  The third parameter to an array slice is a step.  So reversing a string is as simple as:Or selecting alternate characters would be:The ability to step forwards and backwards through the string maintains consistency with being able to array slice from the start or end.Substr() normally (i.e. PHP, Perl) works this way: So the parameters are beginning and LENGTHBut Python's behaviour is different, it expects beginning and one after END (!).  So the correct replacement for Substr(s, beginning, LENGTH) isA common way to achieve this is by String slicing.  gives you a substring from index a to (b - 1)One example seems to be missing here: full (shallow) copy.This is a common idiom for creating a copy of sequence types (not of interned strings).  Shallow copies a list, See .Yes there is. Your example is very close: .. leave off the second index to go to the endYou've got it right there except for \"end\".  Its called slice notation.  Your example should read.If you leave out the second param it is implicitly the end of the string.Maybe I missed it, but I couldn't find a complete answer on this page to the original question(s) because variables are not further discussed here. So I had to go on searching.Since I'm not yet allowed to comment, let me add my conclusion here. I'm sure I was not the only one interested in it when accessing this page:  If you leave the first part, you get   And if you left the : in the middle as well you got the simplest substring, which would be the 5th character (count starting with 0, so it's the blank in this case):I would like to add two points to the discussion: No one mention about using hardcode indexes itself can be a mess. In order to avoid that, python offers a built-in object . If we want to know how many money I got left. Normal solution:Using slices:You can notice using slice you gain readabilityhere is some method to do sub string.using slicing and dicing."},
{"link": "https://stackoverflow.com//questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "qbody": "I spent most of the day yesterday searching for a clear answer for installing  (package manager for Python). I can't find a good solution.How do I install it?All you need to do isYou can install it through Homebrew on OS X.  Why would you install Python with Homebrew?Homebrew is something of a package manager for OS X.  Find more details on the .  Once Homebrew is installed, run the following to install the latest Python, Pip & Setuptools:: All you have to do is:MacOS comes with  installed. But to make sure that you have  installed open the terminal and run the following command.If this command returns a version number that means  exists. That also means you already have access to  considering you are using .\u2139\ufe0f Now, all you have to do is run the following command.After that,  will be installed and you'll be able to use it for installing other packages.Let me know if you have any problems installing  this way.Complimentary GIF.Cheers! On Mac: is available on OS X via .\nOpen a terminal and type:When prompted for a password enter your normal login password.\nAfter the installation has completed you should be able to use  as expected.   The simplest solution is to follow the .Basically, this consists in:The main advantage of that solution is that it install pip for the python version that has been used to run , which means that if you use the default OS X installation of python to run  you will install pip for the python install from the system.Most solutions that use a package manager (homebrew or macport) on OS X create a redundant installation of python in the environment of the package manager which can create inconsistencies in your system since, depending on what you are doing, you may call one installation of python instead of another.I'm surprised no-one has mentioned this - it's a built-in way to install pip, without external tools or scripts:Works in pretty much the same way as , but worth knowing anyway.Installing a separate copy of Python is a popular option, even though Python already comes with MacOS. You take on the responsibility to make sure you're using the copy of Python you intend. But, the benefits are having the latest Python release and some protection from hosing your system if things go badly wrong.To install Python using :Now confirm that we're working with our newly installed Python:...should show a symbolic link to a path with \"Cellar\" in it like:Pip should be installed along with Python. You might want to upgrade it by typing:Now you're ready to install any of the 50,000+ packages on .Formerly, I've used . But, the docs warn that get-pip.py does not coordinate with package managers and may leave your system in an inconsistent state. Anyway, there's no need, given that pip is now .Note that pip isn't the only package manager for Python. There's also easy_install. It's no good to mix the two, so don't do it.Finally, if you have both Python 2 and 3 installed,  will point to whichever Python you installed last. Get in the habit of explicitly using either  or , so you're sure which Python is getting the new library.Happy hacking!You should install Brew first:Then brew install PythonThen  will workNEW 2016 December: This worked for me on  (El Capitan):Mac comes with , but not with pip.Requirements:With this I got these errors (but I've solved them in step 3):The directory  or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want .The directory  or its parent directory is not owned by the current user and caching wheels has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want .Finally you can install an app like:: If you install , pip will be installed automatically.You need only to upgrade pip, but before that you need create a virtual environment to work with Python 3. You can use a project folder or any folder:Check the versions:To deactivate the environment:Download this file: Then simply typeMake sure you are on the same directory as get-pip.py or you supply the correct path for that file.For details, you can visit: or,  Then update your PATH to include py27-pip bin directory (you can add this in ~/.bash_profile\nPATH=/opt/local/Library/Frameworks/Python.framework/Versions/2.7/bin:$PATHpip will be available in new terminal window.To install or upgrade , download  from Then run the following:\nFor example:Download python setup tools from the below website:Use the tar file.Once you download, go to the downloaded folder and run Once you do that,you will have easy_install.Use the below then to install pip:Install python3 first, then use pip3 to install packages.python3 will be installed, and pip is shipped with it. To use pip to install some package, run the followingNotice it's pip3 because you want to use python3.I recommend Anaconda to you. It`s the leading open data science platform powered by Python. There are many basic packages installed. "},
{"link": "https://stackoverflow.com//questions/68645/static-class-variables-in-python", "qbody": "Is it possible to have static class variables or methods in python? What syntax is required to do this?Variables declared inside the class definition, but not inside a method are class or static variables:As @ points out, this creates a class-level \"i\" variable, but this is distinct from any instance-level \"i\" variable, so you could haveThis is different from C++ and Java, but not so different from C#, where a static member can't be accessed using a reference to an instance.See .@Steve Johnson has already answered regarding , also documented under .@beidy recommends s over staticmethod, as the method then receives the class type as the first argument, but I'm still a little fuzzy on the advantages of this approach over staticmethod. If you are too, then it probably doesn't matter.@Blair Conrad said static variables declared inside the class definition, but not inside a method are class or \"static\" variables:There are a few gotcha's here. Carrying on from the example above:Notice how the instance variable  got out of sync with the \"static\" class variable when the attribute  was set directly on . This is because  was re-bound within the  namespace, which is distinct from the  namespace. If you want to change the value of a \"static\" variable, you must change it within the scope (or object) where it was originally defined. I put \"static\" in quotes because Python does not really have static variables in the sense that C++ and Java do.Although it doesn't say anything specific about static variables or methods, the  has some relevant information on . @Steve Johnson also answered regarding static methods, also documented under \"Built-in Functions\" in the Python Library Reference.@beid also mentioned classmethod, which is similar to staticmethod. A classmethod's first argument is the class object. Example:As the other answers have noted, static and class methods are easily accomplished using the built-in decorators:As usual, the first argument to  is bound to the class instance object. In contrast, the first argument to  is  (e.g., in this case, ). For , none of the arguments are bound, and having arguments at all is optional. However, implementing \"static variables\" (well,  static variables, anyway, if that's not a contradiction in terms...) is not as straight forward. As millerdev , the problem is that Python's class attributes are not truly \"static variables\". Consider: This is because the line  has added a new instance attribute  to  instead of changing the value of the  class  attribute.  expected static variable behavior, i.e., syncing of the attribute between multiple instances (but  with the class itself; see \"gotcha\" below), can be achieved by turning the class attribute into a property:Now you can do:The static variable will now remain in sync . (NOTE: That is, unless a class instance decides to define its own version of ! But if someone decides to do THAT, they deserve what they get, don't they???)Note that technically speaking,  is still not a 'static variable' at all; it is a , which is a special type of descriptor. However, the  behavior is now equivalent to a (mutable) static variable synced across all class instances. For immutable static variable behavior, simply omit the  setter:Now attempting to set the instance  attribute will return an : Note that the above methods only work with  of your class - they will  work . So for example: The line  produces an error, because the  attribute of  and  are two different objects. Many people will find this surprising. However, it should not be. If we go back and inspect our  class definition (the second version), we take note of this line: Clearly, the member  of  must be a  object, which is the type of object returned from the  function. If you find the above confusing, you are most likely still thinking about it from the perspective of other languages (e.g. Java or c++). You should go study the  object, about the order in which Python attributes are returned, the descriptor protocol, and the method resolution order (MRO). I present a solution to the above 'gotcha' below; however I would suggest - strenuously - that you do not try to do something like the following until - at minimum - you thoroughly understand why  causes an error. I present the (Python 3) solution below for informational purposes only. I am not endorsing it as a \"good solution\". I have my doubts as to whether emulating the static variable behavior of other languages in Python is ever actually necessary. However, regardless as to whether it is actually useful, the below should help further understanding of how Python works. A metaclass is the class of a class. The default metaclass for all classes in Python (i.e., the \"new style\" classes post Python 2.3 I believe) is . For example: However, you can define your own metaclass like this: And apply it to your own class like this (Python 3 only):Below is a metaclass I have created which attempts to emulate \"static variable\" behavior of other languages. It basically works by replacing the default getter, setter, and deleter with versions which check to see if the attribute being requested is a \"static variable\". A catalog of the \"static variables\" is stored in the  attribute. All attribute requests are initially attempted to be resolved using a substitute resolution order. I have dubbed this the \"static resolution order\", or \"SRO\". This is done by looking for the requested attribute in the set of \"static variables\" for a given class (or its parent classes). If the attribute does not appear in the \"SRO\", the class will fall back on the default attribute get/set/delete behavior (i.e., \"MRO\"). You can also add class variables to classes on the flyAnd class instances can change class variablesPersonally I would use a classmethod whenever I needed a static method. Mainly because I get the class as an argument.or use a decoratorFor static properties.. Its time you look up some python definition.. variable can always change. There are two types of them mutable and immutable.. Also, there are class attributes and instance attributes.. Nothing really like static attributes in the sense of java & c++Why use static method in pythonic sense, if it has no relation whatever to the class! If I were you, I'd either use classmethod or define the method independent from the class.One special thing to note about static properties & instance properties, shown in the example below:This means before assigning the value to instance property, if we try to access the property thru' instance, the static value is used. .Static methods in python are called s. Take a look at the following codeNotice that when we call the method , we get an error. This is because it requires that method be called on an instance of this class. The method  is set as a classmethod using the  .Just for kicks and giggles, we could call  on the class by passing in an instance of the class, like so:You could also enforce a class to be static using metaclass.Then whenever by accident you try to initialize  you'll get an StaticClassError.When define some member variable outside any member method, the variable can be either static or non-static depending on how the variable is expressed. For example:The results areIt is possible to have  class variables, but probably not worth the effort.Here's a proof-of-concept written in Python 3 -- if any of the exact details are wrong the code can be tweaked to match just about whatever you mean by a :and in use:and some tests:To avoid any potential confusion, I would like to contrast static variables and immutable objects.Some primitive object types like integers, floats, strings, and touples are immutable in Python. This means that the object that is referred to by a given name cannot change if it is of one of the aforementioned object types. The name can be reassigned to a different object, but the object itself may not be changed.Making a variable static takes this a step further by disallowing the variable name to point to any object but that to which it currently points. (Note: this is a general software concept and not specific to Python; please see others' posts for information about implementing statics in Python).Absolutely Yes,\n  Python by itself don't have any static data member explicitly, but We can have by doing so outputexplanationIn regards to this , for a  static variable, you can use a descriptor. Here's an example:resulting in ...You can always raise an exception if quietly ignoring setting value ( above) is not your thing. If you're looking for a C++, Java style static class variable:Have a look at  and the official docs  for more information about descriptors. The best way I found is to use another class. You can create an object and then use it on other objects.With the example above, I made a class named .This class should present the static var  (Private Static Var). class represented the regular class we need to use.Now I made an object for one flag (). This flag will be sent as reference to all the regular objects.All these objects are being added to the list .This Script Results:For anyone using a class factory with  and up use the  keyword to add it to the scope / context of the class being created like so:"},
{"link": "https://stackoverflow.com//questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "qbody": "I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.I was looking for something useful in  but I couldn't find anything obviously useful. Might've missed it, though.Related question: Here's a generator that yields the chunks you want:If you're using Python 2, you should use  instead of :Also you can simply use list comprehension instead of write a function. Python 3:Python 2 version:If you want something super simple:Directly from the (old) Python documentation (recipes for itertools):The current version, as suggested by J.F.Sebastian:I guess Guido's time machine works\u2014worked\u2014will work\u2014will have worked\u2014was working again.These solutions work because  (or the equivalent in the earlier version) creates  iterator, repeated  times in the list.  then effectively performs a round-robin of \"each\" iterator; because this is the same iterator, it is advanced by each such call, resulting in each such zip-roundrobin generating one tuple of  items.Here is a generator that work on arbitrary iterables:Example:I know this is kind of old but I don't why nobody mentioned :I'm surprised nobody has thought of using 's :Demo:This works with any iterable and produces output lazily. It returns tuples rather than iterators, but I think it has a certain elegance nonetheless. It also doesn't pad; if you want padding, a simple variation on the above will suffice:Demo:Like the -based solutions, the above  pads. As far as I know, there's no one- or two-line itertools recipe for a function that  pads. By combining the above two approaches, this one comes pretty close:Demo:I believe this is the shortest chunker proposed that offers optional padding. Simple yet elegantor if you prefer:I saw the most awesome Python-ish answer in a  of this question:You can create n-tuple for any n.It also has a lot more things, including all the recipes in the itertools documentation.None of these answers are evenly sized chunks, they all leave a runt chunk at the end, so they're not completely balanced. If you were using these functions to distribute work, you've built-in the prospect of one likely finishing well before the others, so it would sit around doing nothing while the others continued working hard.For example, the current top answer ends with:I just hate that runt at the end!Others, like , and  both return: . The 's are just padding, and rather inelegant in my opinion. They are NOT evenly chunking the iterables.Why can't we divide these better?Here's a balanced solution, adapted from a function I've used in production (Note in Python 3 to replace  with ):And I created a generator that does the same if you put it into a list:And finally, since I see that all of the above functions return elements in a contiguous order (as they were given):To test them out:Which prints out:Notice that the contiguous generator provide chunks in the same length patterns as the other two, but the items are all in order, and they are as evenly divided as one may divide a list of discrete elements.If you had a chunk size of 3 for example, you could do:source:\nI would use this when my chunk size is fixed number I can type, e.g. '3', and would never change.A generator expression:eg.I like the Python doc's version proposed by tzot and J.F.Sebastian a lot,\n but it has two shortcomings:I'm using this one a lot in my code:UPDATE: A lazy chunks version:If you know list size:If you don't (an iterator):In the latter case, it can be rephrased in a more beautiful way if you can be sure that the sequence always contains a whole number of chunks of given size (i.e. there is no incomplete last chunk).The  library has the  function for this:At this point, I think we need a , just in case...In python 2:In python 3:Also, in case of massive Alien invasion, a  might become handy:usage:Where AA is array, SS is chunk size. For example:You may also use  function of  library as:You can install  via pip:.Consider using  piecesfor example:Another more explicit version.code:result:heh, one line versionI realise this question is old (stumbled over it on Google), but surely something like the following is far simpler and clearer than any of the huge complex suggestions and only uses slicing:See Python3If you are into brackets - I picked up a book on Erlang :)"},
{"link": "https://stackoverflow.com//questions/1720421/how-to-append-list-to-second-list-concatenate-lists", "qbody": "How do I concatenate two lists in Python?Example:Expected outcome:Python makes this ridiculously easy.It's also possible to create a generator that simply iterates over the items in both lists.  This allows you to chain lists (or any iterable) together for processing without copying the items to a new list:You can use sets to obtain merged list of unique valuesYou could also use  in order to add a  add the end of another one:This is quite simple, I think it was even shown in the :You could simply use the  or  operator as follows:Or:Also, if you want the values in the merged list to be unique you can do:Even though this is an old answer, another alternative has been introduced via the acceptance of  which deserves mentioning. The PEP, titled , generally reduced some syntactic restrictions when using the starred  expression in Python; with it, joining two lists (applies to any iterable) can now also be done with:This functionality ; from testing it in  I don't belive it has been backported to previous versions in the  family. In unsupported versions a  is going to be raised.The  to this approach is that you really don't need lists in order to perform it, anything that is iterable will do. As stated in the PEP:So while addition with  would raise a  due to type mismatch:The following won't:because it will first unpack the contents of the iterables and then simply create a  from the contents.It's worth noting that the  function accepts variable number of arguments:If an iterable (tuple, list, generator, etc.) is the input, the  class method may be used:This question directly asks about joining two lists. However it's pretty high in search even when you are looking for a way of joining many lists (including the case when you joining zero lists). Consider this more generic approach:Will output:Note, this also works correctly when  is  or .Consider better alternative suggested by Patrick Collins in the comments:With Python 3.3+ you can use :Or, if you want to support an arbitrary number of iterators:If you want to merge the two lists in sorted form, you can use merge function from the heapq library.If you don't want to or can't use the plus operator (), you can uses the   function:If you need to merge two ordered lists with complicated sorting rules, you might have to roll it yourself like in the following code (using a simple sorting rule for readability :-) ).As a more general way for more lists you can put them within a list and use  function which based on  answer is the best way for flatting a nested list :Joining two lists in Python:If you don't want any duplication:You could use the  method defined on  objects: The above code, does not preserve order, removes duplicate from each list (but not from the concatenated list)Yes, it's that simple.. This gives a new list that is the concatenation of  and .As already pointed out by many,  is the way to go if one needs to apply  to both lists. In my case, I had a label and a flag which were different from one list to the other, so I needed something slightly more complex. As it turns out, behind the scenes  simply does the following:(see ), so I took inspiration from here and wrote something along these lines:The main points to understand here are that lists are just a special case of iterable, which are objects like any other; and that  loops in python can work with tuple variables, so it is simple to loop on multiple variables at the same time. lst1 = [1,2]lst2 = [3,4]def list_combinationer(Bushisms, are_funny):list_combinationer(lst1, lst2)[1,2,3,4]you just take the values of the first and second and  add them to one variable. if I:I will have:"},
{"link": "https://stackoverflow.com//questions/36932/how-can-i-represent-an-enum-in-python", "qbody": "I'm mainly a C# developer, but I'm currently working on a project in Python.How can I represent the equivalent of an Enum in Python?  Enums have been added to Python 3.4 as described in .  It has also been  on pypi.  For more advanced Enum techniques try the  (2.7, 3.3+, same author as . Code is not perfectly compatible between py2 and py3, e.g. you'll need ).Installing  (no numbers) will install a completely different and incompatible version.or equivalently:In earlier versions, one way of accomplishing enums is:which is used like so:You can also easily support automatic enumeration with something like this:and used like so:Support for converting the values back to names can be added this way:This overwrites anything with that name, but it is useful for rendering your enums in output.  It will throw KeyError if the reverse mapping doesn't exist.  With the first example:Before PEP 435, Python didn't have an equivalent but you could implement your own.Myself, I like keeping it simple (I've seen some horribly complex examples on the net), something like this ...In Python 3.4 (), you can make Enum the base class.  This gets you a little bit of extra functionality, described in the PEP.  For example, enum values are distinct from integers.If you don't want to type the values, use the following shortcut:Here is one implementation:Here is its usage:If you need the numeric values, here's the quickest way:In Python 3.x you can also add a starred placeholder at the end, which will soak up all the remaining values of the range in case you don't mind wasting memory and cannot count:The best solution for you would depend on what you require from your  .If you need the  as only a list of  identifying different , the solution by  (above) is great:Using a  also allows you to set any :In addition to the above, if you also require that the items belong to a  of some sort, then embed them in a class:To use the enum item, you would now need to use the container name and the item name:For long lists of enum or more complicated uses of enum, these solutions will not suffice. You could look to the recipe by Will Ware for  published in the . An online version of that is available . has the interesting details of a proposal for enum in Python and why it was rejected.The typesafe enum pattern which was used in Java pre-JDK 5 has a\nnumber of advantages. Much like in Alexandru's answer, you create a\nclass and class level fields are the enum values; however, the enum\nvalues are instances of the class rather than small integers. This has\nthe advantage that your enum values don't inadvertently compare equal\nto small integers, you can control how they're printed, add arbitrary\nmethods if that's useful and make assertions using isinstance:A recent  pointed out there are a couple of enum libraries in the wild, including:An Enum class can be a one-liner.How to use it (forward and reverse lookup, keys, values, items, etc.)Python doesn't have a built-in equivalent to , and other answers have ideas for implementing your own (you may also be interested in the  in the Python cookbook).However, in situations where an  would be called for in C, I usually end up : because of the way objects/attributes are implemented, (C)Python is optimized to work very fast with short strings anyway, so there wouldn't really be any performance benefit to using integers. To guard against typos / invalid values you can insert checks in selected places.(One disadvantage compared to using a class is that you lose the benefit of autocomplete)So, I agree. Let's not enforce type safety in Python, but I would like to protect myself from silly mistakes. So what do we think about this?It keeps me from value-collision in defining my enums.There's another handy advantage: really fast reverse lookups:Use it like this:  if you just want unique symbols and don't care about the values, replace this line:  with this:I prefer to define enums in Python like so:It's more bug-proof than using integers since you don't have to worry about ensuring that the integers are unique (e.g. if you said Dog = 1 and Cat = 1 you'd be screwed).It's more bug-proof than using strings since you don't have to worry about typos (e.g.\nx == \"catt\" fails silently, but x == Animal.Catt is a runtime exception).On 2013-05-10, Guido agreed to accept  into the Python 3.4 standard library. This means that Python finally has builtin support for enumerations!There is a backport available for Python 3.3, 3.2, 3.1, 2.7, 2.6, 2.5, and 2.4.  It's on Pypi as .Declaration:Representation:Iteration:Programmatic access:For more information, refer to . Official documentation will probably follow soon.Hmmm... I suppose the closest thing to an enum would be a dictionary, defined either like this:orThen, you can use the symbolic name for the constants like this:There are other options, like a list of tuples, or a tuple of tuples, but the dictionary is the only one that provides you with a \"symbolic\" (constant string) way to access the \nvalue.Edit: I like Alexandru's answer too!Another, very simple, implementation of an enum in Python, using :or, alternatively,Like the method above that subclasses , this allows:But has more flexibility as it can have different keys and values. This allowsto act as is expected if you use the version that fills in sequential number values.What I use:How to use:So this gives you integer constants like state.PUBLISHED and the two-tuples to use as choices in Django models.davidg recommends using dicts.  I'd go one step further and use sets:Now you can test whether a value matches one of the values in the set like this:like dF, though, I usually just use string constants in place of enums.This is the best one I have seen: \"First Class Enums in Python\"It gives you a class, and the class contains all the enums. The enums can be compared to each other, but don't have any particular value; you can't use them as an integer value. (I resisted this at first because I am used to C enums, which are integer values. But if you can't use it as an integer, you can't use it as an integer by mistake so overall I think it is a win.) Each enum is a unique value. You can print enums, you can iterate over them, you can test that an enum value is \"in\" the enum. It's pretty complete and slick.Edit (cfi): The above link is not Python 3 compatible. Here's my port of enum.py to Python 3:From Python 3.4 there will be official support for enums. You can find documentation and examples .I have had occasion to need of an Enum class, for the purpose of decoding a binary file format. The features I happened to want is concise enum definition, the ability to freely create instances of the enum by either integer value or string, and a useful esentation.  Here's what I ended up with:A whimsical example of using it:Key features:Keep it simple:Then:I really like Alec Thomas' solution (http://stackoverflow.com/a/1695250):It's elegant and clean looking, but it's just a function that creates a class with the specified attributes.With a little modification to the function, we can get it to act a little more 'enumy':This creates an enum based off a specified type. In addition to giving attribute access like the previous function, it behaves as you would expect an Enum to with respect to types.  It also inherits the base class.For example, integer enums:Another interesting thing that can be done with this method is customize specific behavior by overriding built-in methods:The new standard in Python is , so an Enum class will be available in future versions of Python:However to begin using it now you can install the  that motivated the PEP:Then you :If you name it, is your problem, but if not creating objects instead of values allows you to do this:When using other implementations sited here (also when using named instances in my example) you must be sure you never try to compare objects from different enums. For here's a possible pitfall:Yikes!Alexandru's suggestion of using class constants for enums works quite well. I also like to add a dictionary for each set of constants to lookup a human-readable string representation. This serves two purposes: a) it provides a simple way to pretty-print your enum and b) the dictionary logically groups the constants so that you can test for membership.The enum package from  provides a robust implementation of enums. An earlier answer mentioned PEP 354; this was rejected but the proposal was implemented \n.Usage is easy and elegant:This solution is a simple way of getting a class for the enumeration defined as a list (no more annoying integer assignments):enumeration.py:example.py:While the original enum proposal, , was rejected years ago, it keeps coming back up. Some kind of enum was intended to be added to 3.2, but it got pushed back to 3.3 and then forgotten. And now there's a  intended for inclusion in Python 3.4. The reference implementation of PEP 435 is .As of April 2013, there seems to be a general consensus that  should be added to the standard library in 3.4\u2014as long as people can agree on what that \"something\" should be. That's the hard part. See the threads starting  and , and a half dozen other threads in the early months of 2013.Meanwhile, every time this comes up, a slew of new designs and implementations appear on PyPI, ActiveState, etc., so if you don't like the FLUFL design, try a .Here's an approach with some different characteristics I find valuable:and most importantly !Based closely on .Many doctests included here to illustrate what's different about this approach.I had need of some symbolic constants in pyparsing to represent left and right associativity of binary operators.  I used class constants like this:Now when client code wants to use these constants, they can import the entire enum using:The enumerations are unique, they can be tested with 'is' instead of '==', they don't take up a big footprint in my code for a minor concept, and they are easily imported into the client code.  They don't support any fancy str() behavior, but so far that is in the  category.Here is a variant on :"},
{"link": "https://stackoverflow.com//questions/2612802/how-to-clone-or-copy-a-list", "qbody": "What are the options to clone or copy a list in Python?Using  then modifies  every time  changes.\nWhy is this?With , you don't actually have two lists. The assignment just copies the reference to the list, not the actual list, so both  and  refer to the same list after the assignment.To actually copy the list, you have various possibilities:Result:Felix already provided an excellent answer, but I thought I'd do a speed comparison of the various methods:So the fastest is list slicing. But be aware that ,  and , unlike  and the python version don't copy any lists, dictionaries and class instances in the list, so if the originals change, they will change in the copied list too and vice versa.(Here's the script if anyone's interested or wants to raise any issues:): Added new-style, old-style classes and dicts to the benchmarks, and made the python version much faster and added some more methods including list expressions and .I've  that Python 3.3+  method, which should be as fast as slicing:There are two semantic ways to copy a list. A shallow copy creates a new list of the same objects, a deep copy creates a new list containing equivalent objects.A shallow copy only copies the list itself, which is a container of references to the objects in the list. If the objects contained themselves are mutable and one is changed, the change will be reflected in both lists. There are different ways to do this in Python 2 and 3. The Python 2 ways will also work in Python 3.In Python 2, the idiomatic way of making a shallow copy of a list is with a complete slice of the original:You can also accomplish the same thing by passing the list through the list constructor, but using the constructor is less efficient:In Python 3, lists get the  method:In Python 3.5: is a pointer to the actual list in memory. When you say  you're not making a copy, you're just adding another name that points at that original list in memory. We can have similar issues when we make copies of lists. The list is just an array of pointers to the contents, so a shallow copy just copies the pointers, and so you have two different lists, but they have the same contents. To make copies of the contents, you need a deep copy.To make a :To demonstrate how this allows us to make new sub-lists:And so we see that the deep copied list is an entirely different list from the original. You could roll your own function - but don't. You're likely to create bugs you otherwise wouldn't have by using the standard library's deepcopy function.You may see this used as a way to deepcopy, but don't do it:In 64 bit Python 2.7:on 64 bit Python 3.5:This answer is only for Python 2. I haven't upgraded to Python 3 yet. There are many answers already that tell you how to make a proper copy, but none of them say why your original 'copy' failed. Python doesn't store values in variables; it binds names to objects. Your original assignment took the object referred to by  and bound it to  as well. No matter which name you use there is still only one list, so changes made when referring to it as  will persist when referring to it as . Each of the other answers to this question give you different ways of creating a new object to bind to . Each element of a list acts like a name, in that each element binds non-exclusively to an object. A shallow copy creates a new list whose elements bind to the same objects as before.To take your list copy one step further, copy each object that your list refers to, and bind those element copies to a new list. This is not yet a deep copy, because each element of a list may refer to other objects, just like the list is bound to its elements. To recursively copy every element in the list, and then each other object referred to by each element, and so on: perform a deep copy. See  for more information about corner cases in copying.Use Python's idiom for doing this is All of the other contributors gave  answers, which work when you have a single dimension (leveled) list, however of the methods mentioned so far, only  works to clone/copy a list and not have it point to the nested  objects when you are working with multidimensional, nested lists (list of lists). While  refers to it in his answer, there is a little bit more to the issue and possibly a workaround using built-ins that might prove a faster alternative to .While ,  and for Py3k  work for single-leveled lists, they revert to pointing at the  objects nested within the  and the , and changes to one of the  objects are perpetuated in the other. As others have stated, there   performance issues using the  module and  . Basically what this does is make a representation of  as a string and then evaluates the string as if it were the object that the string represents. By doing this, no link to the original  object is made. A new  object is created and each variable points to its own independent object. Here is an example using a 2 dimensional nested list.If you then check the contents of each list, for example a 4 by 3 list, Python will return While this probably isn't the canonical or syntactically correct way to do it, it seems to work well. I haven't tested performance, but I am going to guess that  and  will have less overhead to run than  will. Unlike other languages have , python has .means give the list(object) a name \"a\", the just gives the same object a new name \"b\", so whenever you do something with a, the object changes and therefore b changes. The only way to make a  copy of a is to  like other answers have said.You can see more about this Here are the timing results using Python 3.6.0. Keep in mind these times are relative to one another, not absolute.I stuck to only doing shallow copies, and also added some new methods that weren't possible in Python2, such as  (the Python3 ) and  ():We can see the old winner still comes out on top, but not really by a huge amount, considering the increased readability of the Python3  approach. They all work for sliceable objects, a few work for any iterable, but only  works for any Python object.Here is the testing code for interested parties ():Another method (that I feel is fairly readable) is to turn it into a string and then switch it back to a list."},
{"link": "https://stackoverflow.com//questions/3277503/how-do-i-read-a-file-line-by-line-into-a-list", "qbody": "How do I read every line of a file in Python and store each line as an element in a list? I want to read the file line by line and append each line to the end of the list.I'm guessing that you meant  and not array.See :or with stripping the newline character:This is more explicit than necessary, but does what you want.This will yield an \"array\" of lines from the file.If you want the  included:If you do not want  included:You could simply do the following, as has been suggested:Note that this approach has 2 downsides:1) You store all the lines in memory. In the general case, this is a very bad idea. The file could be very large, and you could run out of memory. Even if it's not large, it is simply a waste of memory.2) This does not allow processing of each line as you read them. So if you process your lines after this, it is not efficient (requires two passes rather than one).A better approach for the general case would be the following:Where you define your process function any way you want. For example:(The implementation of the  class is left as an exercise for you).This will work nicely for any file size and you go through your file in just 1 pass. This is typically how generic parsers will work.if you don't care about closing the file, this one-liner works:The  way:Using  (recommended):This should encapsulate the open command. First and foremost, you should focus on opening your file and reading its contents in an efficient and pythonic way. Here is an example of the way I personally DO NOT prefer:Instead, I prefer the below method of opening files for both reading and writing as it\nis very clean, and does not require an extra step of closing the file\nonce you are done using it. In the statement below, we're opening the file\nfor reading, and assigning it to the variable 'infile.'  Once the code within\nthis statement has finished running, the file will be automatically closed.Now we need to focus on bringing this data into a  because they are iterable, efficient, and flexible.  In your case, the desired goal is to bring each line of the text file into a separate element. To accomplish this, we will use the  method as follows:I'd do it like this.Here's one more option by using list comprehensions on files;This should be more efficient way as the most of the work is done inside the Python interpreter.Another option is , for example:This will make  a NumPy array with as many rows as are in your file.If you'd like to read a file from the command line or from stdin, you can also use the  module:Pass files to it like so:Read more here: A simple way is to:In one line, that would give:Now variable out is a list (array) of what you want. You could either do:oryou'll get the same results.Just use the splitlines() functions. Here is an example.In the output you will have the list of lines.A real easy way:If you want to make it a fully-fledged program, type this in:For some reason, it doesn't read .py files properly.To my knowledge Python doesn't have a native array data structure. But it does support the list data structure which is much simpler to use than an array.Could also use the loadtxt command in numpy. This checks for fewer conditions than genfromtxt so it may be faster. Use this: is a dataframe type, and uses values to get ndarray. You can also get a list by using .If you want to are faced with a  and want to  (imagine you are in a Topcoder/Hackerrank coding competition), you might read a considerably bigger chunk of lines into a memory buffer at one time, rather than just iterate line by line at file level.:put this code (save it as read_txt.py) in the same dir and execute it: python read_txt.pyyou will get thisif you are in the console and you'll get thisYou can just open your file for reading using\nfile1=open(\"filename\",\"r\")\nand for reading use\nlines=file1.readlines()\nThe list lines will contain all your lines as individual elements and you can call a specific element using lines[\"linenumber-1\"] as python starts its counting from 0.This should answer your question. The replace function will act as delimiter to strip the file.\"textFileLines\" is the array you wantedHow about:Declare a Unix-like method:And just invoke it to get the file content."},
{"link": "https://stackoverflow.com//questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "qbody": "I wonder whether there is a shortcut to make a simple list out of list of lists in Python.I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with , but I get an error.is faster than the shortcuts posted so far. ( is the list to flatten.)Here is a the corresponding function:For evidence, as always, you can use the  module in the standard library:Explanation: the shortcuts based on  (including the implied use in ) are, of necessity,  when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So (for simplicity and without actual loss of generality) say you have L sublists of I items each: the first I items are copied back and forth L-1 times, the second I items L-2 times, and so on; total number of copies is I times the sum of x for x from 1 to L excluded, i.e., .The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.You can use :or, on Python >=2.6, use  which doesn't require unpacking the list:This approach is arguably more readable than  and appears to be faster too:Note that only works on lists of lists. For lists of lists of lists, you'll need another solution.@Nadia: You have to use much longer lists. Then you see the difference quite strikingly!\nMy results for where:The  method in your example modifies  instead of returning a useful value (which  expects).A faster way to do the  version would be The sum version is still running for more than a minute and it hasn't done processing yet!For medium lists:Using small lists and timeit: number=1000000Why do you use extend?This should work fine.There seems to be a confusion with ! When you add two lists together, the correct term for that is , not add.  is what you need to use.If you're thinking functional, it is as easy as this::You see reduce respects the sequence type, so when you supply a tuple, you get back a tuple. let's try with a list::Aha, you get back a list.How about performance::from_iterable is pretty fast! But it's no comparison to reduce with concat.Here is a general approach that applies to lists of lists, numbers strings, and other mixed containers types.This solution employs Python 3's powerful  keyword, which extracts items from sub-generators.    UPDATE: Now supports strings.  REF: solution modified from The reason your function didn't work: the extend extends array in-place and doesn't return it. You can still return x from lambda, using some trick:Note: extend is more efficient than + on lists.An bad feature of Anil's function above is that it requires the user to always manually specify the second argument to be an empty list . This should instead be a default. Due to the way Python objects work, these should be set inside the function, not in the arguments.Here's a working function:Testing:One can also use NumPy's :Edit 11/02/2016: Only works when sublists have identical dimensions.Fastest solution I have found (for large list anyway):Done! You can of course turn it back into a list by executing list(l)If you want to flatten a data-structure where you don't know how deep it's nested you could use It's a generator so you need to cast the result to a  or explicitly iterate over it.To flatten only one level and if each of the items is itself iterable you can also use  which itself is just a thin wrapper around :Consider installing the  package.It ships with an implementation for  (, from the ):As of version 2.4, you can flatten more complicated, nested iterables with  (, contributed by  abarnet).If you are willing to give up a tiny amount of speed for a cleaner look, then you could use  or :You can find out more here in the docs  and Simple code for  package fanIt solves all flatten problems (none list item or complex nesting)You can install  with pipCleaned up @Deleet exampleExample: "},
{"link": "https://stackoverflow.com//questions/287871/print-in-terminal-with-colors-using-python", "qbody": "How can I output colored text to the terminal, in Python?\nWhat is the best Unicode symbol to represent a solid block?This somewhat depends on what platform you are on. The most common way to do this is by printing ANSI escape sequences. For a simple example, here's some python code from the :To use code like this, you can do something like This will work on unixes including OS X, linux and windows (provided you use , or in Windows 10 provided you enable ). There are ansi codes for setting the color, moving the cursor, and more.If you are going to get complicated with this (and it sounds like you are if you are writing a game), you should look into the \"curses\" module, which handles a lot of the complicated parts of this for you. The  is a good introduction.If you are not using extended ASCII (i.e. not on a PC), you are stuck with the ascii characters below 127, and '#' or '@' is probably your best bet for a block. If you can ensure your terminal is using a IBM , you have many more options. Characters 176, 177, 178 and 219 are the \"block characters\".Some modern text-based programs, such as \"Dwarf Fortress\", emulate text mode in a graphical mode, and use images of the classic PC font. You can find some of these bitmaps that you can use on the  see ().The  has more resources for doing graphics in text mode.Hmm.. I think got a little carried away on this answer. I am in the midst of planning an epic text-based adventure game, though. Good luck with your colored text!I'm surprised no one has mentioned the . Usage is pretty simple:It may not be sophisticated enough, however, for game programming and the \"colored blocks\" that you want to do...The answer is  for all cross-platform coloring in Python.Print a string that starts a color/style, then the string, then end the color/style change with :Get a table of format options for shell text with following code:You want to learn about ANSI escape sequences. Here's a brief example:For more info see For a block character, try a unicode character like \\u2588:Putting it all together:My favorite way is with the  library (full disclosure: I wrote it). For example:To print colored bricks, the most reliable way is to print spaces with background colors. I use this technique to draw the progress bar in :You can print in specific locations as well:If you have to muck with other terminal capabilities in the course of your game, you can do that as well. You can use Python's standard string formatting to keep it readable:The nice thing about Blessings is that it does its best to work on all sorts of terminals, not just the (overwhelmingly common) ANSI-color ones. It also keeps unreadable escape sequences out of your code while remaining concise to use. Have fun!Try this simple code On Windows you can use module 'win32console' (available in some Python distributions) or module 'ctypes' (Python 2.5 and up) to access the Win32 API.To see complete code that supports both ways, see the  from .ctypes example:generated a class with all the colors using a for loop to iterate every combination of color up to 100, then wrote a class with python colors. Copy and paste as you will, GPLv2 by me:I have wrapped @joeld answer into a module with global functions that I can use anywhere in my code.file: log.py     use as follows:I use the colorama module for coloured terminal printing in Python. A link is here Some example code of printing red and green text:I used colorama to write a basic Matrix programInstallation on Ubuntu (your distribution install command may be different)Stupidly simple based on @joeld's answerThen justDefine a string that starts a color and a string that ends the color, then print your text with the start string at the front and the end string at the end.This produces the following in , in  with a Zenburn-style color scheme:Through experemintation, we can get more colors:Note:  and  are blinking.This way we can create a full color collection:Here is the code to generate the test:For Windows you cannot print to console with colors unless you're using the win32api.For Linux it's as simple as using print, with the escape sequences outlined here:For the character to print like a box, it really depends on what font you are using for the console window. The pound symbol works well, but it depends on the font:uses ANSI  Make your function :-Call function :- Note :- not required any module note how well the  keyword mixes with modifiers like these that need to be reset (using Python 3 and Colorama):You can use the Python implementation of the curses library:\nAlso, run this and you'll find your box:You could use :.If you are programming a game perhaps you would like to change the background color and use only spaces? For example:Here's a curses example:while i find  answer useful, i modified it a bit. this  is the resultin addition you can wrap common usages:I ended up doing this, I felt it was cleanest: If you are using Windows, then here you go!If you are using  snapshot:(I generally use colored output for debugging on runserver terminal so I added it.)Give it a Try!! provides a portable support for building text UI and animations:Asciicast:Yet another pypi module that wraps the python 3 print function:It's usable in python 2.x if you also .I wrote a simple module, available at:\nIt works with Windows, Mac OS X and Linux.\nIt uses ANSI for Linux and Mac, but native calls to console functions on Windows.\nYou have colors, cursor positioning and keyboard input. It is not a replacement for curses, but can be very useful if you need to use in simple scripts or ASCII games.Your terminal most probably uses Unicode (typically UTF-8 encoded) characters, so it's only a matter of the appropriate font selection to see your favorite character. Unicode char U+2588, \"Full block\" is the one I would suggest you use.Try the following:Examine the file later with your favourite viewer. is the module you want to use. Check this .I wrote a module that handles colors in Linux/OSX/Windows. It supports all 16 colors on all platforms, you can set foreground and background colors at different times, and the string objects give sane results for things like len() and .capitalize()."},
{"link": "https://stackoverflow.com//questions/510348/how-can-i-make-a-time-delay-in-python", "qbody": "I would like to know how to put a time delay in a Python script.Here is another example where something is run once a minute:You can use the sleep() function in the time module. It can take a float argument for sub second resolution.Please read , which can help you further:A bit of fun with sleepy generator.The question is about time delay. It can be fixed time, but in some cases we might need a delay measured since last time. Here is one possible solutions:The situation can be, we want to do something as regularly as possible and we do not want to bother with all the ,  stuff all around our code.Following code () defines  gerenaratorand running it we see:We can also use it directly in a loop:and running it we might see:As we see, this buzzer is not too rigid and allow us to catch up regular sleepy intervals even if we oversleep and get out of regular schedule.N.B. (Just in case you haven't heard of it, tkinter is an interactive tool which you can import. Basically, you can create buttons and boxes and popups and stuff that appear as windows which you manipulate with code.)If you use tkinter, DO NOT USE TIME.SLEEP() because it will muck up your program. This happened to me. Instead, use root.after() and replace the values for however many seconds, with a milliseconds. E.g, time.sleep(1) is equivalent to root.after(1000) on tkinter.Otherwise, time.sleep(), which many answers have pointed out, is the way to go."},
{"link": "https://stackoverflow.com//questions/2225038/determine-the-type-of-an-object", "qbody": "Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.To get the type of an object, you can use the built-in  function. Passing an object as the only parameter will return the type object of that object:This of course also works for custom types:Note that  will only return the immediate type of the object, but won\u2019t be able to tell you about type inheritance.To cover that, you should use the  function. This of course also works for built-in types: is usually the preferred way to ensure the type of an object because it will also accept derived types. So unless you actually need the type object (for whatever reason), using  is preferred over .The second parameter of  also accepts a tuple of types, so it\u2019s possible to check for multiple types at once.  will then return true, if the object is of any of those types:You can do that using :It might be more Pythonic to use a ... block. That way, if you have a class which quacks like a list, or quacks like a dict, it will behave properly regardless of what its type  is.To clarify, the preferred method of \"telling the difference\" between variable types is with something called : as long as the methods (and return types) that a variable responds to are what your subroutine expects, treat it like what you expect it to be. For example, if you have a class that overloads the bracket operators with  and , but uses some funny internal scheme, it would be appropriate for it to behave as a dictionary if that's what it's trying to emulate.The other problem with the  checking is that if  is a subclass of , it evaluates to  when, programmatically, you would hope it would be . If an object is a subclass of a list, it should work like a list: checking the type as presented in the other answer will prevent this. ( will work, however).On instances of object you also have the:attribute. Here is a sample taken from Python 3.3 consoleBeware that in python 3.x and in New-Style classes (aviable optionally from Python 2.6) class and type have been merged and this can sometime lead to unexpected results. Mainly for this reason my favorite way of testing types/classes is to the  built in function.You can use  or .Be warned that you can clobber  or any other type by assigning a variable in the current scope of the same name.Above we see that  gets reassigned to a string, therefore the test:...fails.To get around this and use  more cautiously:While the questions is pretty old, I stumbled across this while finding out a proper way myself, and I think it still needs clarifying,  (did not check on Python 3, but since the issue arises with classic classes which are gone on such version, it probably doesn't matter).Here I'm trying to answer the title's question: ? Other suggestions about using or not using isinstance are fine in many comments and answers, but I'm not addressing those concerns.The main issue with the  approach is that :Executing this snippet would yield:Which, I argue, is not what most people would expect.The  approach is the most close to correctness, but it won't work in one crucial case: when the passed-in object is an old-style  (not an instance!), since those objects lack such attribute.This is the smallest snippet of code I could think of that satisfies such legitimate question in a consistent fashion:Determine the type of an object with Although it works, avoid double underscore attributes like  - they're not semantically public, and, while perhaps not in this case, the builtin functions usually have better behavior.Well that's a different question, don't use type - use :This covers the case where your user might be doing something clever or sensible by subclassing  - according to the principle of Liskov Substitution, you want to be able to use subclass instances without breaking your code - and  supports this. Even better, you might look for a specific Abstract Base Class from  or :Or, perhaps best of all, use duck-typing, and don't explicitly type-check your code. Duck-typing supports Liskov Substitution with more elegance and less verbosity. As an aside to the previous answers, it's worth mentioning the existence of  which contains several abstract base classes (ABCs) that complement duck-typing.For example, instead of explicitly checking if something is a list with: you could, if you're only interested in seeing if the object you have allows getting items, use :if you're strictly interested in objects that allow getting, setting  deleting items (i.e  sequences), you'd opt for .Many other ABCs are defined there,  for objects that can be used as maps, , , et cetera. A full list of all these can be seen in "},
{"link": "https://stackoverflow.com//questions/379906/parse-string-to-float-or-int", "qbody": "In Python, how can I parse a numeric string like  to its corresponding float value, ? Or parse the string  to an integer, ?I just want to know how to parse a float string to a float, and (separately) an int string to an int.A longer and more accurate name for this function could be: You think you know what numbers are? You are not so good as you think! Not big surprise.This is another method which deserves to be mentioned here, :That is, a safe 'eval'You should consider the possibility of commas in the string representation of a number, for cases like   which throws an exception. Instead, use methods in  to convert the strings to numbers and interpret commas correctly. The  method converts to a float in one step once the locale has been set for the desired number convention. In the United States and the UK, commas can be used as a thousands separator.  In this example with American locale, the comma is handled properly as a separator:In the ,  commas are used for decimal marks instead of periods.  In this example with French locale, the comma is correctly handled as a decimal mark:The method  is also available, but the argument should be an integer.Users  and  are correct, but keep in mind if you know the string is an integer (for example, 545) you can call int(\"545\") without first casting to float.If your strings are in a list, you could use the map function as well. It is only good if they're all the same type.The question seems a little bit old. But let me suggest a function, parseStr, which makes something similar, that is, returns integer or float and if a given ASCII string cannot be converted to none of them it returns it untouched. The code of course might be adjusted to do only what you want:It's good that you ask to do these separately. If you're mixing them, you may be setting yourself up for problems later. The simple answer is:Conversions from various bases, and you should know the base in advance (10 is the default). Note you can prefix them with what Python expects for its literals (see below) or remove the prefix:If you don't know the base in advance, but you do know they will have the correct prefix, Python can infer this for you if you pass  as the base:If your motivation is to have your own code clearly represent hard-coded specific values, however, you may not need to convert from the bases - you can let Python do it for you automatically with the correct syntax.You can use the apropos prefixes to get automatic conversion to integers with . These are valid for Python 2 and 3:Binary, prefix Octal, prefix Hexadecimal, prefix This can be useful when describing binary flags, file permissions in code, or hex values for colors - for example, note no quotes:If you see an integer that starts with a 0, in Python 2, this is (deprecated) octal syntax.It is bad because it looks like the value should be . So in Python 3, it now raises a :Convert your Python 2 octals to octals that work in both 2 and 3 with the  prefix:If you aren't averse to third-party modules, you could check out the  module. It provides a function called  that does exactly what this question is asking for and does it faster than a pure-Python implementation: and The  parser can help you figure out what datatype your string is. Use , and then you can use  to test for type:You need to take into account rounding to do this properly.I.e. int(5.1) => 5\n     int(5.6) => 5  -- wrong, should be 6 so we do int(5.6 + 0.5) => 6 of \nThis will try to parse a string and return either  or  depending on what the string represents.\nIt might rise parsing exceptions or .Use:This is the most Pythonic way I could come up with. Use:Here's another interpretation of your question (hint: it's vague). It's possible you're looking for something like this:It works like this...Theoretically, there's an injection vulnerability. The string could, for example be . Without any background on where the string comes from, however, the possibility is theoretical speculation.  Since the question is vague, it's not at all clear if this vulnerability actually exists or not."},
{"link": "https://stackoverflow.com//questions/36901/what-does-double-star-and-star-do-for-parameters", "qbody": "In the following method definitions, what does the  and  do for ?The  and  is a common idiom to allow arbitrary number of arguments to functions as described in the section  in the Python documentation.The  will give you all function parameters :The  will give you all \n except for those corresponding to a formal parameter as a dictionary.Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:Another usage of the  idiom is to  when calling a function.In Python 3 it is possible to use  on the left side of an assignment (), though it gives a list instead of a tuple in this context:Also Python 3 adds new semantic (refer ):Such function accepts only 3 positional arguments, and everything after  can only be passed as keyword arguments.It's also worth noting that you can use * and ** when calling functions as well. This is a shortcut that allows you to pass multiple arguments to a function directly using either a list/tuple or a dictionary. For example, if you have the following function:You can do things like:The single * means that there can be any number of extra positional arguments.  can be invoked like . In the body of foo() param2 is a sequence containing 2-5.The double ** means there can be any number of extra named parameters.  can be invoked like . In the body of bar() param2 is a dictionary containing {'a':2, 'b':3 }With the following code:the output isThey allow for  and for  any number of arguments, positional () and keyword (). allows for any number of optional positional arguments (parameters), which will be assigned to a tuple named .  allows for any number of optional keyword arguments (parameters), which will be in a dict named .You can (and should) choose any appropriate name, but if the intention is for the arguments to be of non-specific semantics,  and  are standard names.You can also use  and  to pass in parameters from lists (or any iterable) and dicts (or any mapping), respectively.The function recieving the parameters does not have to know that they are being expanded. For example, Python 2's xrange does not explicitly expect , but since it takes 3 integers as arguments:As another example, we can use dict expansion in :You can have  after the  - for example, here,  must be given as a keyword argument - not positionally:Usage:Also,  can be used by itself  to indicate that keyword only arguments follow, without allowing for unlimited positional arguments.Here,  again must be an explicitly named, keyword argument:And we can no longer accept unlimited positional arguments because we don't have :Again, more simply, here we require  to be given by name, not positionally:In this example, we see that if we try to pass  positionally, we get an error:We must explicitly pass the  parameter as a keyword argument. (typically said \"star-args\") and  (stars can be implied by saying \"kwargs\", but be explicit with \"double-star kwargs\") are common idioms of Python for using the  and  notation. These specific variable names aren't required (e.g. you could use  and ), but a departure from convention is likely to enrage your fellow Python coders. We typically use these when we don't know what our function is going to receive or how many arguments we may be passing, and sometimes even when naming every variable separately would get very messy and redundant (but this is a case where usually explicit is better than implicit).The following function describes how they can be used, and demonstrates behavior. Note the named  argument will be consumed by the second positional argument before :We can check the online help for the function's signature, with , which tells us Let's call this function with  which prints:We can also call it using another function, into which we just provide : prints:OK, so maybe we're not seeing the utility yet. So imagine you have several functions with redundant code before and/or after the differentiating code. The following named functions are just pseudo-code for illustrative purposes.We might be able to handle this differently, but we can certainly extract the redundancy with a decorator, and so our below example demonstrates how  and  can be very useful:And now every wrapped function can be written much more succinctly, as we've factored out the redundancy:And by factoring out our code, which  and  allows us to do, we reduce lines of code, improve readability and maintainability, and have sole canonical locations for the logic in our program. If we need to change any part of this structure, we have one place in which to make each change.Let us first understand what are positional arguments and keyword arguments.\nBelow is an example of function definition with So this is a function definition with positional arguments.\nYou can call it with keyword/named arguments as well:Now let us study an example of function definition with :You can call this function with positional arguments as well:So we now know function definitions with positional as well as keyword arguments.Now let us study the '*' operator and '**' operator.Please note these operators can be used in 2 areas:a) b) The use of '*' operator and '**' operator in  Let us get straight to an example and then discuss it.So remember when the '*' or '**' operator is used in a  -'*' operator unpacks data structure such as a list or tuple  into arguments needed by function definition.'**' operator unpacks a dictionary into arguments needed by function definition.Now let us study the '*' operator use in .\nExample:In function  the '*' operator packs the received arguments into a tuple.Now let us see an example of '**' used in function definition:In function  The '**' operator packs the received arguments into a dictionary.So remember:In a  the '*'  data structure of tuple or list into positional or keyword arguments to be received by function definition.In a  the '**'  data structure of dictionary into positional or keyword arguments to be received by function definition.In a  the '*'  positional arguments into a tuple.In a  the '**'  keyword arguments into a dictionary. and  have special usage in the function argument list. \nimplies that the argument is a list and  implies that the argument\nis a dictionary. This allows functions to take arbitrary number of\nargumentsFrom the Python documentation:In Python 3.5, you can also use this syntax in , , , and  displays (also sometimes called literals). See .It also allows multiple iterables to be unpacked in a single function call.(Thanks to mgilson for the PEP link.)In addition to function calls, *args and **kwargs are useful in class hierarchies and also avoid having to write  method in Python. Similar usage is seen in frameworks like Django code.For example,A subclass can then beThe subclass then be called as Also, a subclass with a new attribute which makes sense only to that subclass instance can call the Base class  to offload the attributes setting.\nThis is done through *args and **kwargs. kwargs mainly used so that code is readable using named arguments. For example,which can be instatiated asThe complete code is I want to give an example which others haven't  mentioned* can also unpack a An example from Python3 Documentunzip_x will be [1, 2, 3], unzip_y will be [4, 5, 6]The zip() receives multiple iretable args, and return a generator. A good example of using both in a function is:This example would help you remember ,  and even  and inheritance in Python at once."},
{"link": "https://stackoverflow.com//questions/3294889/iterating-over-dictionaries-using-for-loops", "qbody": "I am a bit puzzled by the following code:What I don't understand is the  portion. How does Python recognize that it needs only to read the key from the dictionary? Is  a special word in Python? Or is it simply a variable? is just a variable name.  will simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:For Python 2.x:For Python 3.x:To test for yourself, change the word  to .For Python 3.x,  has been replaced with simply , which returns a set-like view backed by the dict, like  but even better. \nThis is also available in 2.7 as . The operation  will work for both 2 and 3, but in 2 it will return a list of the dictionary's  pairs, which will not reflect changes to the dict that happen after the  call. If you want the 2.x behavior in 3.x, you can call .It's not that key is a special word, but that dictionaries implement the iterator protocol.  You could do this in your class, e.g. see  for how to build class iterators.In the case of dictionaries, it's implemented at the C level.  The details are available in .  In particular, the section titled \"Dictionary Iterators\":Iterating over a  iterates through its keys in no particular order, as you can see here:For your example, it is a better idea to use :This gives you a list of tuples. When you loop over them like this, each tuple is unpacked into  and  automatically:Using  and  as variable names when looping over a  is quite common if the body of the loop is only a few lines. For more complicated loops it may be a  good idea to use more descriptive names:It's a good idea to get into the habit of using format strings:When you iterate through dictionaries using the -syntax, it always iterates over the keys (the values are accessible using ).To iterate over key-value pairs, use .  is simply a variable.You can do this:... or better,This is a very common looping idiom.  is an operator. For when to use  and when it must be  see .You can use this:To iterate over keys, it is slower but better to use . If you tried to do something like this:it would create a runtime error because you are changing the keys while the program is running. If you are absolutely set on reducing time, use the  way, but you have been warned ;). I have a use case where I have to iterate through the dict to get the key, value pair, also the index indicating where I am. This is how I do it:Note that the parentheses around the key, value is important, without the parentheses, you get an ValueError \"not enough values to unpack\"."},
{"link": "https://stackoverflow.com//questions/415511/how-to-get-current-time-in-python", "qbody": "What is the module/method used to get current time?And just the time:The same but slightly more compact:See the  for more info.To save typing, you can import the  object from the  module:Then remove the leading  from all the above.You can use :    Similar to , but use the  function for a quick-n-dirty, slightly more human readable format:For this example, the output will be like this: The format for  is at:\nDoThere is some difference for Unix and Windows platforms.The  module provides functions that tells us the time in \"seconds since the epoch\" as well as other utilities.This is the format you should get timestamps in for saving in databases. It is a simple floating point number that can be converted to an integer. It is also good for arithmetic in seconds, as it represents the number of seconds since Jan 1, 1970 00:00:00, and it is memory light relative to the other representations of time we'll be looking at next:This timestamp does not account for leap-seconds, so it's not linear - leap seconds are ignored. So while it is not equivalent to the international UTC standard, it is close, and therefore quite good for most cases of record-keeping. This is not ideal for human scheduling, however. If you have a future event you wish to take place at a certain point in time, you'll want to store that time with a string that can be parsed into a datetime object or a serialized datetime object (these will be described later).You can also represent the current time in the way preferred by your operating system (which means it can change when you change your system preferences, so don't rely on this to be standard across all systems, as I've seen others expect). This is typically user friendly, but doesn't typically result in strings one can sort chronologically:You can hydrate timestamps into human readable form with  as well:This conversion is also not good for record-keeping (except in text that will only be parsed by humans - and with improved Optical Character Recognition and Artificial Intelligence, I think the number of these cases will diminish).The  module is also quite useful here:The  is a class method that returns the current time. It uses the  without the timezone info (if not given, otherwise see timezone aware below). It has a representation (which would allow you to recreate an equivalent object) echoed on the shell, but when printed (or coerced to a ), it is in human readable (and nearly ISO) format, and the lexicographic sort is equivalent to the chronological sort:You can get a datetime object in UTC time, a global standard, by doing this:UTC is a time standard that is nearly equivalent to the GMT timezone. (While GMT and UTC do not change for Daylight Savings Time, their users may switch to other timezones, like British Summer Time, during the Summer.) However, none of the datetime objects we've created so far can be easily converted to various timezones. We can solve that problem with the  module:Equivalently, in Python 3 we have the  class with a utc  instance attached, which also makes the object timezone aware (but to convert to another timezone without the handy  module is left as an exercise to the reader):And we see we can easily convert to timezones from the original utc object.You can also make a naive datetime object aware with the  timezone  method, or by replacing the tzinfo attribute (with , this is done blindly), but these are more last resorts than best practices:The  module allows us to make our  objects timezone aware and convert the times to the hundreds of timezones available in the  module.One could ostensibly serialize this object for UTC time and store  in a database, but it would require far more memory and be more prone to error than simply storing the Unix Epoch time, which I demonstrated first. The other ways of viewing times are much more error prone, especially when dealing with data that may come from different time zones. You want there to be no confusion as to which timezone a string or serialized datetime object was intended for.If you're displaying the time with Python for the user,  works nicely, not in a table (it doesn't typically sort well), but perhaps in a clock. However, I personally recommend, when dealing with time in Python, either using Unix time, or a timezone aware UTC  object. That outputs the current GMT in the specified format. There is also a localtime() method. This  has more details.All good suggestions, but I find it easiest to use  myself:This gives a nicely formatted string representation of current local time.why not just keep things simple. If you need current time as a  object:I'll contribute to this because  is in the documentation but not yet here\n(this is mighty similar to @Ray Vega's answer):Quickest way isThis is what I ended up going with: Also, this table is a necessary reference for choosing the appropriate format codes to get the date formatted just the way you want it (from Python \"datetime\" documentation ).Why not ask the , the official timekeeper of the United States Navy?If you live in the D.C. area (like me) the latency might not be too bad... returns the current time as a naive datetime object that represents time in the local timezone. That value may be ambiguous e.g., during DST transitions (\"fall back\"). To avoid ambiguity either UTC timezone should be used:Or a timezone-aware object that has the corresponding timezone info attached (Python 3.2+):Try the arrow module from or the utc versionto change it's output add .format()for a specific timezone?an hour agoor if you want the gist.You can use the time module.The use of the captial  gives the full year, using  would give You could also use to give a more lengthy time.do  or any variables including the package, you can get all the attributes and methods associated to the variable.This is what i use to get the time without having to format , some people dont like the split method but it is useful here :Will print in HH:MM:SS formatI am a simple man and i want time with milliseconds. Simple way to get them:But i want , right? Shortest way to get them:Add or remove zeroes from the last multiplication to adjust number of decimal points, or just:date will print date and time will print time."},
{"link": "https://stackoverflow.com//questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "qbody": "This has always confused me. It seems like this would be nicer:Than this:Is there a specific reason it is like this?It's because any iterable can be joined, not just lists, but the result and the \"joiner\" are always strings.E.G:Because the  method is in the string class, instead of the list class?I agree it looks funny.See :This was discussed in the  thread in the Python-Dev achive, and was accepted by Guido. This thread began in Jun 1999, and  was included in Python 1.6 (which supported Unicode) was released in Sep 2000. Python 2.0 (supported  methods including ) was released in Oct 2000.Here are some additional thoughts (my own, and my friend's):Guido's decision is recorded in a , deciding on :I agree that it's counterintuitive at first, but there's a good reason. Join can't be a method of a list because:There are actually two join methods (Python 3.0):If join was a method of a list, then it would have to inspect its arguments to decide which one of them to call. And you can't join byte and str together, so the way they have it now makes sense. This is because  is a \"string\" method! It creates a string from any iterable. If we stuck the method on lists, what about when we have iterables that aren't lists? What if you have a tuple of strings? If this were a  method, you would have to cast every such iterator of strings as a  before you could join the elements into a single string! For example:Let's roll our own list join method:And to use it, note that we have to first create a list from each iterable to join the strings in that iterable, wasting both memory and processing power:So we see we have to add an extra step to use our list method, instead of just using the builtin string method:The algorithm Python uses to create the final string with  actually has to pass over the iterable twice, so if you provide it a generator expression, it has to materialize it into a list first before it can create the final string. Thus, while passing around generators is usually better than list comprehensions,  is an exception:Nevertheless, the  operation is still semantically a \"string\" operation, so it still makes sense to have it on the  object than on miscellaneous iterables.Think of it as the natural orthogonal operation to split.I understand why it is applicable to anything iterable and so can't easily be implemented  on list.For readability, I'd like to see it in the language but I don't think that is actually feasible - if iterability were an interface then it could be added to the interface but it is just a convention and so there's no central way to add it to the set of things which are iterable.Primarily because the result of a  is a string.The sequence (list or tuple or whatever) doesn't appear in the result, just a string.  Because the result is a string, it makes sense as a method of a string."},
{"link": "https://stackoverflow.com//questions/2720014/upgrading-all-packages-with-pip", "qbody": "Is it possible to upgrade all Python packages at one time with ?Note that there is  for this on the official issue tracker.There isn't a built-in flag yet, but you can useNote: there are infinite potential variations for this. I'm trying to keep this answer short and simple, but please do suggest variations in the comments!Relevant edits:You can use the following Python code. Unlike , this will not print warnings and FIXME errors.To upgrade all local packages; you could use : is a fork of . See  mentioned by .  package works but  package no longer works. works on Windows .Works on Windows. Should be good for others too.\n($ is whatever directory you're in, in command prompt. eg. C:/Users/Username>)dothen doIf you have a problem with a certain package stalling the upgrade (numpy sometimes), just go to the directory ($), comment out the name (add a # before it) and run the upgrade again. You can later uncomment that section back.Windows version after consulting excellent  for  by Rob van der WoudeYou can just print the packages that are outdatedThe following one-liner might prove of help: keeps going if an error occurs. If you need more \"fine grained\" control over what is omitted and what raises an error you should not add the  flag and explicitly define the errors to ignore, by \"piping\" the following line for each separate error:Here is an example:This option seems to me more straightforward and readable:( selects the first word of the line (separated by a space))And this version allows for the suppression of warning message from :( removes line containing a given pattern. In my case the warning messages include \"Could not\" and \"ignored\" respectively)From  :however you need to get yolk first:This seems more concise.Explanation: gets lines like theseIn ,  sets \"space\" as the delimiter,  means to get the first column. So the above lines becomes:then pass them to  to run the command, , with each line as appending arguments limits the number of arguments passed to each command  to be 1One-liner version of @Ramana's answer.`when using a virtualenv and if you just want to upgrade packages  to your virtualenv, you may want to do:You can try this :@Ramana's worked the best for me, of those here, but I had to add a few catches:The  check excludes my development packages, because they are not located in the system site-packages directory. The try-except simply skips packages that have been removed from PyPI.@endolith: I was hoping for an easy , too, but it doesn't look like pip was meant to be used by anything but the command line (the docs don't mention the internal API, and the pip developers didn't use docstrings).Sent through ; in the meantime use this pip library solution I wrote:This seemed to work for me...I used  with a space afterwards to properly separate the package names.The rather amazing yolk makes this easy.For more info on yolk: It can do lots of things you'll probably find useful.Windows Powershell solutionMy script:I had the same problem with upgrading. Thing is, i never upgrade all packages. I upgrade only what i need, because project may break.Because there was no easy way for upgrading package by package, and updating the requirements.txt file, i wrote this  which  for the packages chosen (or all packages).Activate your virtualenv (important, because it will also install the new versions of upgraded packages in current virtualenv). into your project directory, then run:If the requirements are placed in a non-standard location, send them as arguments:If you already know what package you want to upgrade, simply send them as arguments:If you need to upgrade to  pre-release / post-release version, add  argument to your command.Full disclosure: I wrote this package.Here is my variation on rbp's answer, which bypasses \"editable\" and development distributions. It shares two flaws of the original: it re-downloads and reinstalls unnecessarily; and an error on one package will prevent the upgrade of every package after that.Related bug reports, a bit disjointed after the migration from bitbucket:I have tried the code of Ramana and I found out on Ubuntu you have to write  for each command. Here is my script which works fine on ubuntu 13.10:Isn't this more effective?here is another way of doing with a script in pythonHere is a scripts that only updates the outdated packages.    I've been using  lately. It's simple and to the point. It updates your  file to reflect the upgrades and you can then upgrade with your  file as usual.For pip3 use this:For pip, just remove the 3s as such:This solution is well designed and tested, whereas there are problems with even the most popular solutions.The above command uses the simplest and most portable pip syntax in combination with sed and sh to overcome these issues completely.  Details of sed operation can be scrutinized with the commented version.[1] Tested and regularly used in a Linux 4.8.16-200.fc24.x86_64 cluster and tested on five other Linux/Unix flavors.  It also runs on Cygwin64 installed on Windows 10.  Testing on iOS is needed.[2] To see the anatomy of the command more clearly, this is the exact equivalent of the above pip3 command with comments: [3] Upgrading a Python or PIP component that is also used in the upgrading of a Python or PIP component can be a potential cause of a deadlock or package database corruption.or even:Works fast as it is not constantly launching a shell.  I would love to find the time to get this actually using the list outdated to speed things up still more.Here is my variation:I took @Ramana's answer and made it pip3 friendly."},
{"link": "https://stackoverflow.com//questions/1024847/add-new-keys-to-a-dictionary", "qbody": "Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an  method.I feel like consolidating info about Python dictionaries:Feel free to add more!Yeah, it's pretty easy. Just do the following:Yes it is possible, and it does have a method that implements this, but you don't want to use it directly.To demonstrate how and how not to use it, let's create an empty dict with the dict literal, :To update this dict with a single new key and value, you can use  that provides for item assignment:  is now:We can also update the dict with multiple values efficiently as well using .  We may be unnecessarily creating an extra  here, so we hope our  has already been created and came from or was used for another purpose: is now:Another efficient way of doing this with the update method is with keyword arguments, but since they have to be legitimate python words, you can't have spaces or special symbols or start the name with a number, but many consider this a more readable way to create keys for a dict, and here we certainly avoid creating an extra unnecessary :and  is now:So now we have covered three Pythonic ways of updating a . There's another way of updating a  that you shouldn't use, which uses the  method. Here's an example of how one might use the  method to add a key-value pair to a , and a demonstration of the poor performance of using it:So we see that using the subscript notation is actually much faster than using . Doing the Pythonic thing, that is, using the language in the way it was intended to be used, usually is both more readable and computationally efficient.If you want to add a dictionary within a dictionary you can do it this way. Example: Add a new entry to your dictionary & sub dictionary Python requires that you first add a sub  before adding entries.The orthodox syntax is , but if your keyboard is missing the square bracket keys you could do:In fact, defining  and  methods is how you can make your own class support the  square bracket syntax. See you can create onegives addresses  methods of merging dictionaries  and .Here are some of the more straightforward methods (tested in Python 3)..., the  dictionary would contain only that one element...This is equivalent to...results in This is exactly how I would do it:\n    # fixed data with sapceThis works for me. Enjoy!we can add new keys to dictionary by this way:Here is the Example:Output:It has a update method which you can use like this:"},
{"link": "https://stackoverflow.com//questions/735975/static-methods-in-python", "qbody": "Is it possible to have static methods in Python so I can call them without initializing a class, like:Yep, using the  decoratorNote that some code might use the old method of defining a static method, using  as a function rather than a decorator. This should only be used if you have to support ancient versions of Python (2.2 and 2.3)This is entirely identical to the first example (using ), just not using the nice decorator syntaxFinally, use  sparingly! There are very few situations where static-methods are necessary in Python, and I've seen them used many times where a separate \"top-level\" function would have been clearer.:I think that Steven is actually right. To answer the original question, then, in order to set up a class method, simply assume that the first argument is not going to be a calling instance, and then make sure that you only call the method from the class.(Note that this answer refers to Python 3.x. In Python 2.x you'll get a  for calling the method on the class itself.)For example:In this code, the \"rollCall\" method assumes that the first argument is not an instance (as it would be if it were called by an instance instead of a class). As long as \"rollCall\" is called from the class rather than an instance, the code will work fine. If we try to call \"rollCall\" from an instance, e.g.:however, it would cause an exception to be raised because it would send two arguments: itself and -1, and \"rollCall\" is only defined to accept one argument.Incidentally, rex.rollCall() would send the correct number of arguments, but would also cause an exception to be raised because now n would be representing a Dog instance (i.e., rex) when the function expects n to be numerical.This is where the decoration comes in:\nIf we precede the \"rollCall\" method withthen, by explicitly stating that the method is static, we can even call it from an instance. Now, would work. The insertion of @staticmethod before a method definition, then, stops an instance from sending itself as an argument.You can verify this by trying the following code with and without the @staticmethod line commented out.Yes, check out the  decorator:You don't really need to use the  decorator. Just declaring a method (that doesn't expect the self parameter) and call it from the class. The decorator is only there in case you want to be able to call it from an instance as well (which was not what you wanted to do)Mostly, you just use functions though...Yes, static methods can be created like this (although it's a bit more  to use underscores instead of CamelCase for methods):The above uses the decorator syntax. This syntax is equivalent to This can be used just as you described:A builtin example of a static method is  in Python 3, which was a function in the  module in Python 2.Another option that can be used as you describe is the , the difference is that the classmethod gets the class as an implicit first argument, and if subclassed, then it gets the subclass as the implicit first argument.Note that  is not a required name for the first argument, but most experienced Python coders will consider it badly done if you use anything else.These are typically used as alternative constructors. A builtin example is :Aside from the particularities of how  behave, there is a certain kind of beauty you can strike with them when it comes to organizing your module-level code..........It now becomes a bit more intuitive and self-documenting in which context certain components are meant to be used and it pans out ideally for naming distinct test cases as well as having a straightforward approach to how test modules map to actual modules under tests for purists.I frequently find it viable to apply this approach to organizing a project's utility code. Quite often, people immediately rush and create a  package and end up with 9 modules of which one has 120 LOC and the rest are two dozen LOC at best. I prefer to start with this and convert it to a package and create modules only for the beasts that truly deserve them:Perhaps the simplest option is just to put those functions outside of the class:Using this method, functions which modify or use internal object state (have side effects) can be kept in the class, and the reusable utility functions can be moved outside.Let's say this file is called . To use these, you'd call  instead of .If you really need a static method to be part of the class, you can use the  decorator."},
{"link": "https://stackoverflow.com//questions/275018/how-can-i-remove-chomp-a-newline-in-python", "qbody": "What is the Python equivalent of Perl's  function, which removes the last character of a value?Try the method  (see doc  and )Python's  method strips  kinds of trailing whitespace by default, not just one newline as Perl does with .To strip only newlines:There are also the methods  and :And I would say the \"pythonic\" way to get lines without trailing newline characters is splitlines().The canonical way to strip end-of-line (EOL) characters is to use the string rstrip() method removing any trailing \\r or \\n.  Here are examples for Mac, Windows, and Unix EOL characters.Using '\\r\\n' as the parameter to rstrip means that it will strip out any trailing combination of '\\r' or '\\n'.  That's why it works in all three cases above.This nuance matters in rare cases.  For example, I once had to process a text file which contained an HL7 message.  The HL7 standard requires a trailing '\\r' as its EOL character.  The Windows machine on which I was using this message had appended its own '\\r\\n' EOL character.  Therefore, the end of each line looked like '\\r\\r\\n'.  Using rstrip('\\r\\n') would have taken off the entire '\\r\\r\\n' which is not what I wanted.  In that case, I simply sliced off the last two characters instead.Note that unlike Perl's  function, this will strip all specified characters at the end of the string, not just one:Note that rstrip doesn't act exactly like Perl's chomp() because it doesn't modify the string. That is, in Perl:results in  being .but in Python:will mean that the value of  is  . Even  doesn't always give the same result, as it strips all whitespace from the end of the string, not just one newline at most.I might use something like this:I think the problem with  is that you'll probably want to make sure the line separator is portable. (some antiquated systems are rumored to use ). The other gotcha is that  will strip out repeated whitespace. Hopefully  will contain the right characters. the above works for me.You may use . This will strip all newlines from the end of the string, not just one.will remove all newlines at the end of the string . The assignment is needed because  returns a new string instead of modifying the original string. Careful with : That will only chomp the newline characters for the platform where your Python is being executed. Imagine you're chimping the lines of a Windows file under Linux, for instance:Use  instead, as Mike says above.or you could always get geekier with regexps :)have fun!you can use strip:demo:An  simply uses .Perl's  function removes one linebreak sequence from the end of a string only if it's actually there.Here is how I plan to do that in Python, if  is conceptually the function that I need in order to do something useful to each line from this file:rstrip doesn't do the same thing as chomp, on so many levels. Read  and see that chomp is very complex indeed.However, my main point is that chomp removes at most 1 line ending, whereas rstrip will remove as many as it can.Here you can see rstrip removing all the newlines:A much closer approximation of typical Perl chomp usage can be accomplished with re.sub, like this:I don't program in Python, but I came across an  at python.org advocating S.rstrip(\"\\r\\n\") for python 2.2 or later.workaround solution for special case:if the newline character is the last character (as is the case with most file inputs), then for any element in the collection you can index as follows: to slice out your newline character. If your question is to clean up all the line breaks in a multiple line str object (oldstr), you can split it into a list according to the delimiter '\\n' and then join this list into a new str(newstr).    This would replicate exactly perl's chomp (minus behavior on arrays) for \"\\n\" line terminator:(Note: it does not modify string 'in place'; it does not strip extra trailing whitespace; takes \\r\\n in account)Here we go Official Complete Documentation  Just use : orYou don't need any of this complicated stuffA catch all:There are three types of line endings that we normally encounter: ,  and . A rather simple regular expression in , namely , is able to catch them all.(And we , am I right?)With the last argument, we limit the number of occurences replaced to one, mimicking chomp to some extent. Example:... where  is .I find it convenient to have be able to get the chomped lines via in iterator, parallel to the way you can get the un-chomped lines from a file object. You can do so with the following code:Sample usage:If you are concerned about speed (say you have a looong list of strings) and you know the nature of the newline char, string slicing is actually faster than rstrip. A little test to illustrate this:Output:It looks like there is not a perfect analog for perl's .  In particular,  cannot handle multi-character newline delimiters like . However,  does .\nFollowing  on a different question, you can combine  and  to remove/replace all newlines from a string :The following removes  newline (as chomp would, I believe). Passing  as the  argument to splitlines retain the delimiters.  Then, splitlines is called again to remove the delimiters on just the last \"line\": "},
{"link": "https://stackoverflow.com//questions/101268/hidden-features-of-python", "qbody": "What are the lesser-known but useful features of the Python programming language?In case you're thinking it's doing , which comes out as , and then comparing , which is also , then no, that's really not what happens (see the last example.) It's really translating into , and , but with less typing and each term is only evaluated once.Regular expressions are a great feature of python, but debugging them can be a pain, and it's all too easy to get a regex wrong.Fortunately, python can print the regex parse tree, by passing the undocumented, experimental, hidden flag  (actually, 128) to .Once you understand the syntax, you can spot your errors.  There we can see that I forgot to escape the  in .Of course you can combine it with whatever flags you want, like commented regexes:Wrap an iterable with enumerate and it will yield the item along with its index.For example:References:If you write you can get out the generator and assign it to x. Now it means you can doThe advantage of this is that you don't need intermediate storage, which you would need if you didIn some cases this can lead to significant speed up.You can append many if statements to the end of the generator, basically replicating nested for loops:For instance:The  function repeatedly calls  and yields its result until  is returned. Instead, you should use a sentinel value denoting \"not given\" and replace with the mutable you'd like as default:. For example having this function:You can:If you don't like using whitespace to denote scopes, you can use the C-style {} by issuing:The step argument in slice operators. For example:The special case  is a useful idiom for 'x reversed'. allow to wrap a function or method in another function that can add functionality, modify arguments or results, etc. You write decorators one line above the function definition, beginning with an \"at\" sign (@).Example shows a  decorator that prints the decorated function's arguments before calling it:The for...else syntax (see  )The \"else\" block will be normally executed at the end of the for loop, unless the break is called.The above code could be emulated as follows:From 2.5 onwards dicts have a special method  that is invoked for missing items:There is also a dict subclass in  called  that does pretty much the same but calls a function without arguments for not existing items:I recommend converting such dicts to regular dicts before passing them to functions that don't expect such subclasses.  A lot of code uses  and catches KeyErrors to check if an item exists which would add a new item to the dict.The right-hand side of the assignment is an expression that creates a new tuple. The left-hand side of the assignment immediately unpacks that (unreferenced) tuple to the names  and .After the assignment, the new tuple is unreferenced and marked for garbage collection, and the values bound to  and  have been swapped.As noted in the ,In Python you can split a regular expression over multiple lines, name your matches and insert comments.Example verbose syntax (from ):Example naming matches (from )You can also verbosely write a regex without using  thanks to string literal concatenation.You can unpack a list or a dictionary as function arguments using  and .For example:Very useful shortcut since lists, tuples and dicts are widely used as containers.ROT13 is a valid encoding for source code, when you use the right coding declaration at the top of the code file:which is exactly the same asProbably not the most useful thing, but nice to know.: Fixed name of new type, should be  to be the exact same thing as with  statement.: Adjusted the title to more accurately describe the feature.Introduced in , a  is an object that acts as a run-time context for a suite of statements.Since the feature makes use of new keywords, it is introduced gradually: it is available in Python 2.5 via the  directive. Python 2.6 and above (including Python 3) has it available by default.I have used the  a lot because I think it's a very useful construct, here is a quick demo:What's happening here behind the scenes, is that the  calls the special  and  methods on the file object. Exception details are also passed to  if any exception was raised from the with statement body, allowing for exception handling to happen there.What this does for you in this particular case is that it guarantees that the file is closed when execution falls out of scope of the  suite, regardless if that occurs normally or whether an exception was thrown. It is basically a way of abstracting away common exception-handling code.Other common use cases for this include locking with threads and database transactions. Dictionaries have a 'get()' method. If you do d['key'] and key isn't there, you get an exception. If you do d.get('key'), you get back None if 'key' isn't there. You can add a second argument to get that item back instead of None, eg: d.get('key', 0).It's great for things like adding up numbers:They're the magic behind a whole bunch of core Python features. When you use dotted access to look up a member (eg, x.y), Python first looks for the member in the instance dictionary. If it's not found, it looks for it in the class dictionary. If it finds it in the class dictionary, and the object implements the descriptor protocol, instead of just returning it, Python executes it. A descriptor is any class that implements the , , or  methods.Here's how you'd implement your own (read-only) version of property using descriptors:and you'd use it just like the built-in property():Descriptors are used in Python to implement properties, bound methods, static methods, class methods and slots, amongst other things. Understanding them makes it easy to see why a lot of things that previously looked like Python 'quirks' are the way they are.Raymond Hettinger has  that does a much better job of describing them than I do.It does exactly what it sounds like: \"assign 3 to x if y is 1, otherwise assign 2 to x\". Note that the parens are not necessary, but I like them for readability. You can also chain it if you have something more complicated:Though at a certain point, it goes a little too far.Note that you can use if ... else in any expression. For example:Here func1 will be called if y is 1 and func2, otherwise. In both cases the corresponding function will be called with arguments arg1 and arg2.Analogously, the following is also valid:where class1 and class2 are two classes.Example extracted from the Python documentation:% -formatting takes a dictionary (also applies %i/%s etc. validation).And since locals() is also a dictionary, you can simply pass that as a dict and have % -substitions from your local variables. I think this is frowned upon, but simplifies things..To add more python modules (espcially 3rd party ones), most people seem to use PYTHONPATH environment variables or they add symlinks or directories in their site-packages directories. Another way, is to use *.pth files. Here's the official python doc's explanation:Exception  clause:The use of the else clause is better than adding additional code to the try clause because it avoids accidentally catching an exception that wasn\u2019t raised by the code being protected by the try ... except statement.See :The 'raise' statement with no arguments inside an error handler tells Python to re-raise the exception , allowing you to say \"oh, sorry, sorry, I didn't mean to catch that, sorry, sorry.\"If you wish to print, store or fiddle with the original traceback, you can get it with sys.exc_info(), and printing it like Python would is done with the 'traceback' module.:You will also have to set a PYTHONSTARTUP environment variable.Nested list comprehensions and generator expressions:These can replace huge chunks of nested-loop code.More detail from the standard library reference: "},
{"link": "https://stackoverflow.com//questions/6470428/catch-multiple-exceptions-in-one-line-except-block", "qbody": "I know that I can do:I can also do this:But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:Is there any way that I can do something like this (since the action to take in both exceptions is to ):Now this really won't work, as it matches the syntax for:So, my effort to catch the two distinct exceptions doesn't exactly come through.Is there a way to do this?From :Separating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using .To do this in a manner currently and forward compatible with Python, you need to separate the Exceptions with commas and wrap them with parentheses to differentiate from earlier syntax that assigned the exception instance to a variable name by following the Exception type to be caught with a comma. Here's an example of simple usage: I'm currently wrapping the  in my interactive command-line  program with a catch for KeyboardInterrupt and EOFError so that the user can leave an interactive keyboard input session semi-gracefully with + or +:I'm specifying these exceptions to avoid hiding bugs, which if I encounter I expect the full stack trace from.This is documented here: You can assign the exception to a variable, ( is common, but you might prefer a more verbose variable if you have long exception handling or your IDE only highlights selections larger than that, as mine does.) The instance has an args attribute. Here is an example:Note that in Python 3, the  object falls out of scope when the  block is concluded.You may see code that assigns the error with a comma. This usage, the only form available in Python 2.5 and earlier, is deprecated, and if you wish your code to be forward compatible in Python 3, you should update the syntax to use the new form:For python 2.5 and earlier versions, the correct syntax is:Where  is the Exception instance.From :"},
{"link": "https://stackoverflow.com//questions/101754/is-there-a-way-to-run-python-on-android", "qbody": "We are working on an  version and this platform has a nice Python API. However, there is nothing official about Python on Android, but since  exists, is there a way to let the snake and the robot work together?One way is to use :  There is also the new  (ASE) project. It looks awesome, and it has some integration with native Android components. An example  -- \"here\u2019s a barcode scanner written in six lines of Python code:There's also  written by a Google employee.The examples include a complete game packaged in an APK, which is pretty interesting. I've posted instructions and a patch for cross compiling Python 2.7.2 for Android, you can get it at my blog here: EDIT: I've open sourced , my 2D Game Engine, it's Python/SDL based and it cross compiles for Android. Even if you don't use it for games, you might get useful ideas from the code and the builder utility (named Schafer, after Tim...you know who).As a  lover and Android programmer, I am sad to say this is not really a good way to go. There are two problems.One problem is that there is a lot more than just a programming language to the Android development tools. A lot of the Android graphics involve XML files to configure the display, similar to HTML. The built-in java objects are really integrated with this XML layout, and it's a lot easier than writing your own code to go from logic to bitmap.The other problem is that the G1 (and probably other Android devices for the near future) are really not that fast. 200 MHz processors, and RAM is very limited. Even in Java you have to do a decent amount of rewriting-to-avoid-more-object-creation if you want to make your app perfectly smooth. Python is going to be too slow for a while still on mobile devices. does what you want. You can easily install it directly onto your device from their site, and do not need root.It supports a range of languages; Python is the most mature. By default, it uses Python 2.6, but there is a  you can use instead. I have used that port for all kinds of things on a Galaxy S2 and it worked fine.SL4A provides a port of their  library for each supported language. The library provides an interface to the underlying Android API through a single  object.Each language has pretty much the same API. You can even use the JavaScript API inside webviews.For user interfaces, you have three options:You can mix options, so you can have a webview for the main interface, and still use native dialogues.There is a third party project named . It builds on SL4A, and throws in some other useful stuff.QPython gives you a nicer UI to manage your installation, and includes a little, touchscreen code editor, a Python shell, and a PIP shell for package management. They also have a Python 3 port. Both versions are available from the Play Store, free of charge. QPython also bundles libraries from a bunch of Python on Android projects, including Kivy, so it is not just SL4A.Note that QPython still develop their fork of SL4A (though, not much to be honest). The main SL4A project itself is pretty much dead.Not at the moment and you would be lucky to get Jython to work soon. If you're planning to start your development now you would be better off with just sticking to Java for now on.Using SL4A (which has already been mentioned by itself in other answers) you can  a full-blown  instance (other  are likely candidates as well).  SL4A doesn't allow you to do native UI components (buttons, scroll bars, and the like), but it does support .  A WebView is basically nothing more than a striped down web browser pointed at a fixed address. I believe the native Gmail app uses a WebView instead of going the regular widget route.  This route would have some interesting features:I use the QPython application. It has an editor, a console, and you can run your Python programs with it. The application is free, and the link is .I want to post this as an extension to what  has already answered ()It has been years since then, and  has also  to , the biggest selling point of  in my opinion is its cross-platform compatibility, you can code and test under your local environment , you can also build, debug and package your app to run in your  devices.With 's own  language, one can easily code and build the GUI interface easily (it's just like Java XML, but rather than TextView etc.,  has its own  for the similar translation), which is in my opinion quite easy to adopt.Currently  and  are most recommended tools to build/package your apps. Having tried them both and I can firmly say that they make building Android apps with Python a breeze. Users who feel comfortable in their console/terminal/command prompt should have no problems using them, and their guides are well documented, too.Futhermore,  is another big selling point of Kivy, provided that you can use the same code base with little changes required to test-run on your  device, via  Homebrew tools, although  are required for the build before running on their devices (AFAIK iOS Simulator in Xcode currently doesn't work for the x86-architecture build). There are also some dependency issues which required manually compiled and fiddled around in Xcode to have a successful build, but wouldn't be too difficult to resolve and people in  are really helpful too.With all being said, users with good Python knowledge should have no problem picking up the basics in weeks (if not days) to build some simple apps.Also worth mentioning is that you can  your Python modules with the build so users can really make use of many existing libraries Python bring us, like  &  etc. through .The last but no the least, if you are going to use  for more serious/commercial projects, you may find existing modules not satisfactory to what are expected. There are some workable solutions too, with the \"work in progress\" of  for Andoird, and , users can now access to Java/Objective-C classes through those modules to control some of the native APIs.My experience in Kivy is that it will find its best fit with seasonal Python programmers and some serious programmer who wants rapid development or simple code base maintenance. It runs well in multiple platforms, albeit not really at the level of  feeling. From the  site:Yet another attempt: This one embed directly the Python interpretter in your app apk.You can run your Python code using . sl4a supports Python, , , , BeanShell, JavaScript, , and shell script.You can learn sl4a .There's also python-on-a-chip possibly running mosync: Didn't see this posted here, but you can do it with Pyside and Qt now that Qt works on Android thanks to Necessitas.It seems like quite a kludge at the moment but could be a viable route eventually...Another option if you are looking for 3.4.2 or 3.5.1 is this archive on GitHub.   or It currently supports Python 3.4.2 or 3.5.1 and the 10d version of the NDK.  It can also support 3.3 and 9c, 11c and 12It's nice in that you simply download it, run make and you get the .so or the .aI currently use this to run raw Python on android devices. With a couple modifications to the build files you can also make x86 and armeabi 64 bitYou can use  application:Note that apt install python install python 3.\nfor python 2 you shoud call apt install python2.Some demos here: And also the github page: One more option seems to be  which citing the docs is:According to  it is actively developed, although it is difficult to find examples of working Android apps or tutorial on how to cross-compile all the required libraries to Android. It is an interesting project to keep in mind though!You can use :It has a Python Console, Editor, as well as Package Management / InstallersIt's an open source project with both Python 2 and Python 3 implementations. You can download the source and the Android .apk files directly from github.QPython 2: QPython 3: There is an app called QPython3 in playstore which can be used for both editing and running python script.Another app called Termux in which you can install python using command"},
{"link": "https://stackoverflow.com//questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "qbody": "For a list  and an item in the list , what's the cleanest way to get its index (1) in Python?Reference: One thing that is really helpful in learning Python is to use the interactive help function:which will often lead you to the method you are looking for.I'm honestly surprised no one has mentioned  yet:This can be more useful than index if there are duplicates in the list, because index() only returns the first occurrence, while enumerate returns all occurrences.As a list comprehension:Here's also another small solution with  (which is pretty much the same approach as enumerate):This is more efficient for larger lists than using : returns the  index of value!To get all indexes:A problem will arise if the element is not in the list. This function handles the issue:You have to set a condition to check if the element you're searching is in the listAll of the proposed functions here reproduce inherent language behavior but obscure what's going on.Why write a function with exception handling if the language provides the methods to do what you want itself?If you want all indexes, then you can use numpy:It is clear, readable solution.Simply you can go withall indexes with zip functionAnother optionA variant on the answer from FMc and user7177 will give a dict that can return all indices for any entry:You could also use this as a one liner to get all indices for a single entry. There are no guarantees for efficiency, though I did use set(a) to reduce the number of times the lambda is called.This solution is not as powerful as others, but if you're a beginner and only know about loops it's still possible to find the first index of an item while avoiding the ValueError:And now, for something completely different, checking for the existence of the item before getting the index.  The nice thing about this approach is the function always returns a list of indices -- even if it is an empty list.  It works with strings as well.When pasted into an interactive python window:This accounts for if the string is not in the list too, if it isn't in the list then location = -1"},
{"link": "https://stackoverflow.com//questions/576169/understanding-python-super-with-init-methods", "qbody": "I'm trying to understand . From the looks of it, both child classes can be created just fine. I'm curious as to what difference there actually is between the following child classes: lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of  can happen. See the  if you haven't already.Note that the syntax changed in Python 3.0: you can just say  instead of  which IMO is quite a bit nicer.It's been noted that in Python 3.0+ you can use to make your call, which is concise and does not require you to reference the parent OR class names explicitly, which can be handy. I just want to add that for Python 2.7 or under, you can achieve the same name-insensitive approach by writing  instead of the class name, i.e.This unfortunately does not necessarily work if you want to inherit the constructor from the superclass. For example:Here I have a class , which is a sub-class of . Say I don't want to write a separate constructor for  because the constructor for  is good enough, but for whatever reason I want to implement a Square so I can reimplement some other method.When I create a  using , Python calls the constructor for  because I haven't given  its own constructor. However, in the constructor for , the call  is going to return the superclass of , so it calls the constructor for  again. This is how the infinite loop happens, as was mentioned by @S_C. In this case, when I run  I am calling the constructor for  but since I give it no arguments, I will get an error.The reason we use  is so that child classes that may be using cooperative multiple inheritance will call the correct next parent class function in the Method Resolution Order (MRO).The primary difference in this code is that you get a layer of indirection in the  with , which uses the current class to determine the next class's  to look up in the MRO.I illustrate this difference in an answer at the , which demonstrates  and .Here's code that's actually closely equivalent to  (how it's implemented in C, minus some checking and fallback behavior, and translated to Python):Written a little more like native Python:If we didn't have the  object, we'd have to write this manual code everywhere (or recreate it!) to ensure that we call the proper next method in the Method Resolution Order!The current second to top answer on this question suggests calling super like this:This is  wrong.  lets us look up the next parent in the MRO (see the first section of this answer) for child classes. If you tell  we're in the child instance's method, it will then lookup the next method in line (probably this one) resulting in recursion, probably causing a logical failure (in the answerer's example, it does) or a  when the recursion depth is exceeded.I am at a loss as to why an answer that doesn't work has been so upvoted.It's rather hand-wavey and doesn't tell us much, but the point of  is not to avoid writing the parent class. The point is to ensure that the next method in line in the method resolution order (MRO) is called. This becomes important in multiple inheritance.I'll explain here.And let's create a dependency that we want to be called after the Child:Now remember,  uses super,  does not:And  does not call the UserDependency method:But , because  uses , does!:Super has no side effectsworks as expectedgets into infinite recursion.Just a heads up... with Python 2.7, and I believe ever since  was introduced in version 2.2, you can only call  if one of the parents inherit from a class that eventually inherits  ().Personally, as for python 2.7 code, I'm going to continue using  until I actually get the advantage of using .There isn't, really.  looks at the next class in the MRO (method resolution order, accessed with ) to call the methods. Just calling the base  calls the base . As it happens, the MRO has exactly one item-- the base. So you're really doing the exact same thing, but in a nicer way with  (particularly if you get into multiple inheritance later).The main difference is that  will unconditionally call  whereas  will call  is \n(which may differ from what you expect). If you add a  that uses multiple inheritance: then  for  instances. Now  will point to  if  is a  instance.You have inserted  in between  and . And you can take advantage of it with So if you are designed your classes so that they can be used in a Cooperative Multiple Inheritance scenario, you use  because you don't really know who is going to be the ancestor at runtime. The  and  explain this pretty well.  "},
{"link": "https://stackoverflow.com//questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "qbody": "I wanted to test if a key exists in a dictionary before updating the value for the key.\nI wrote the following code:I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary? is the intended way to test for the existence of a key in a .If you wanted a default, you can always use :... and if you wanted to always ensure a default value for any key you can use  from the  module, like so:... but in general, the  keyword is the best way to do it.You don't have to call keys:That will be much  as it uses the dictionary's hashing as opposed to doing a linear search, which calling keys would do.You can test for the presence of a key in a dictionary, using the  keyword:A common use for checking the existence of a key in a dictionary before mutating it is to default-initialize the value (e.g. if your values are lists, for example, and you want to ensure that there is an empty list to which you can append when inserting the first value for a key). In cases such as those, you may find the  type to be of interest.In older code, you may also find some uses of , a deprecated method for checking the existence of keys in dictionaries (just use , instead).You can shorten this:However, this is at best a cosmetic improvement. Why do you believe this is not the best way?I would recommend using the  method instead.  It sounds like it will do everything you want.For additional info on speed execution of the accepted answer's proposed methods (10m loops):Therefore using  or  are recommended against .Just an FYI adding to Chris. B (best answer):Works as well; the reason is that calling  returns  which is what  does behind the scenes (when constructing a dictionary), hence the name \"Factory Function\" in the documentation.For checking you can use  method If you want a value then you can use  methodIf you want a tuple or list or dictionary or any string  as a default value as return value, then use  methodWhat about using EAFP (easier to ask forgiveness than permission):See other SO posts: orWon't print boo for the values in the dict, but accomplishes the goal by printing the value of key1 to confirm it's existence instead.Read More: Use of try/block instead of 'in' or 'if':Dictionary in python has a get('key', default) method. So you can just set a default value in case there is no key. \nEasiest one is if you know which key(key name) is to look for:or you can also do simply as:Python dictionary has the method called . This method will return True if the dictionary has the key else returns False."},
{"link": "https://stackoverflow.com//questions/1436703/difference-between-str-and-repr-in-python", "qbody": "What is the difference between  and  in ?Alex summarized well but, surprisingly, was too succinct.First, let me reiterate the main points in Alex\u2019s post:This is mostly a surprise because Python\u2019s defaults tend to be fairly useful. However, in this case, having a default for  which would act like:would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if  is defined, and  is not, the object will behave as though .This means, in simple terms: almost every object you implement should have a functional  that\u2019s usable for understanding the object. Implementing  is optional: do that if you need a \u201cpretty print\u201d functionality (for example, used by a report generator).Let me come right out and say it \u2014 I do not believe in debuggers. I don\u2019t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature \u2014 most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is aBut you have to do the last step \u2014 make sure every object you implement has a useful repr, so code like that can just work. This is why the \u201ceval\u201d thing comes up: if you have enough information so , that means you know everything there is to know about . If that\u2019s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about  anyway. I usually use an eval-like format: . It does not mean that you can actually construct MyClass, or that those are the right constructor arguments \u2014 but it is a useful form to express \u201cthis is everything you need to know about this instance\u201d.Note: I used  above, not . You always want to use  [or  formatting character, equivalently] inside  implementation, or you\u2019re defeating the goal of repr. You want to be able to differentiate  and .Specifically, it is not intended to be unambiguous \u2014 notice that . Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be \"2010/4/12 15:35:22\", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class \u2014 as long is it supports readability, it is an improvement.This seems surprising, doesn\u2019t it? It is a little, but how readable wouldbe? Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you\u2019re printing a list, just(you can probably also figure out what to do about dictionaries.Implement  for any class you implement. This should be second nature. Implement  if you think it would be useful to have a string version which errs on the side of more readability in favor of more ambiguity.Unless you specifically act to ensure otherwise, most classes don't have helpful results for either:As you see -- no difference, and no info beyond the class and object's .  If you only override one of the two...:as you see, if you override , that's ALSO used for , but not vice versa.Other crucial tidbits to know:  on a built-on container uses the , NOT the , for the items it contains. And, despite the words on the subject found in typical docs, hardly anybody bothers making the  of objects be a string that  may use to build an equal object (it's just too hard, AND not knowing how the relevant module was actually imported makes it actually flat out impossible).So, my advice: focus on making  reasonably human-readable, and  as unambiguous as you possibly can, even if that interferes with the fuzzy unattainable goal of making 's returned value acceptable as input to !My rule of thumb:   is for developers,  is for customers.: representation of python object usually eval will convert it back to that object: is whatever you think is that object in text forme.g.Here is a good example:Read this documentation for repr:Here is the documentation for str: (read as \"dunder (double-underscore) string\") and  (read as \"dunder-repper\" (for \"representation\")) are both special methods that return strings based on the state of the object.  provides backup behavior if  is missing. So one should first write a  that allows you to reinstantiate an equivalent object from the string it returns e.g. using  or by typing it in character-for-character in a Python shell. At any time later, one can write a  for a user-readable string representation of the instance, when one believes it to be necessary.If you print an object, or pass it to , , or , then if a  method is defined, that method will be called, otherwise,  will be used. The  method is called by the builtin function  and is what is echoed on your python shell when it evaluates an expression that returns an object. Since it provides a backup for , if you can only write one, start with Here's the builtin help on :That is, for most objects, if you type in what is printed by , you should be able to create an equivalent object. The default object  is () something like:That means by default you'll print the module the object is from, the class name, and the hexadecimal representation of its location in memory - for example:This information isn't very useful, but there's no way to derive how one might accurately create a canonical representation of any given instance, and it's better than nothing, at least telling us how we might uniquely identify it in memory.Let's look at how useful it can be, using the Python shell and  objects. First we need to import the  module:If we call  in the shell, we'll see everything we need to recreate an equivalent datetime object. This is created by the datetime :If we print a datetime object, we see a nice human readable (in fact, ISO) format. This is implemented by datetime's :It is a simple matter to recreate the object we lost because we didn't assign it to a variable by copying and pasting from the  output, and then printing it, and we get it in the same human readable output as the other object:As you're developing, you'll want to be able to reproduce objects in the same state, if possible. This, for example, is how the datetime object defines  (). It is fairly complex, because of all of the attributes needed to reproduce such an object:If you want your object to have a more human readable representation, you can implement  next. Here's how the datetime object () implements , which it easily does because it already has a function to display it in ISO format:This is a critique of another answer here that suggests setting .Setting  is silly -  is a fallback for  and a , written for developers usage in debugging, should be written before you write a .You need a  only when you need a textual representation of the object.Define  for objects you write so you and other developers have a reproducible example when using it as you develop. Define  when you need a human readable string representation of it. In all honesty,  is never used. If you find yourself using it, you should stop, because  is dangerous, and strings are a very inefficient way to serialize your objects (use  instead). Therefore, I would recommend setting . The reason is that  calls  on the elements (I consider this to be one of the biggest design flaws of Python that was not addressed by Python 3). An actual  will probably not be very helpful as the output of . To qualify this, in my experience, the most useful use case of the  function is to put a string inside another string (using string formatting). This way, you don't have to worry about escaping quotes or anything. But note that there is no  happening here. From  by effbot: \"computes the \"informal\" string representation of an object. This differs from  in that it does not have to be a valid Python expression: a more convenient or concise representation may be used instead.\"To put it simply: is used in to show a string representation of your object  by others. is used to show a string representation of  object.Let's say I want to create a  class where the string representation of a fraction is '(1/2)' and the object (Fraction class) is to be represented as 'Fraction (1,2)'So we can create a simple Fraction class:Apart from all the answers given, I would like to add few points :-1)  is invoked when you use object with print statement. In case, if  is missing, then print invokes  of object.2)  is invoked when you simply write object's name on interactive python console and press enter.3)  of containers, when invoked will execute  method of its contained elements. - Creates a new string object from the given object. - Returns the canonical string representation of the object.The differences:When print() is called on the result of decimal.Decimal(23) / deci- mal.Decimal(\"1.05\") the raw number is printed; this output is in  which can be achieved with __str __(). If we simply enter the expression we get a decimal.Decimal output\u2014this output is in  which can be achieved with __repr __(). All Python objects have two output forms. String form is designed to be human-readable. Representational form is designed to produce output that if fed to a Python interpreter would (when possible) re- produce the represented object, the  call of a  calls the contained objects' , the  representation of an object. Although the formal representation is harder to read than an informal one, it is unambiguous and more robust against bugs.Excellent answers are already cover the difference between  and , which for me boils down to the former being readable even by an end user, and the latter being as useful as possible to developers. Given that, I find that the default implementation of  often fails to achieve this goal because it  information useful to developers.For this reason, if I have a simple enough , I generally just try to get the best of both worlds with something like:On page 358 of the book  by Hans Petter Langtangen, it clearly states that So, I prefer to understand them asfrom the user point of view\nalthough this is a misunderstanding i made when learning python.A small but good example is also given on the same page as follows:From the book: Fluent PythonOne aspect that is missing in other answers. It's true that in general the pattern is:Unfortunately, this differentiation is flawed, because the Python REPL and also IPython use  for printing objects in a REPL console (see related questions for  and ). Thus, projects which are targeted for interactive console work (e.g., Numpy or Pandas) have started to ignore above rules and provide a human-readable  implementation instead."},
{"link": "https://stackoverflow.com//questions/509211/explain-slice-notation", "qbody": "I need a good explanation (references are a plus) on Python's slice notation. To me, this notation needs a bit of picking up. It looks extremely powerful, but I haven't quite got my head around it.It's pretty simple really:There is also the  value, which can be used with any of the above:The key point to remember is that the  value represents the first value that is  in the selected slice. So, the difference beween  and  is the number of elements selected (if  is 1, the default).The other feature is that  or  may be a  number, which means it counts from the end of the array instead of the beginning. So:Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for  and  only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.The tutorial talks about it:(Scroll down a bit until you get to the part about slicing.)  The ASCII art diagram is helpful too for remembering how slices work:Enumerating the possibilities allowed by the grammar:Of course, if , then the end point will be a little lower than .Extended slicing (with commas and ellipses) are mostly used only by special data structures (like Numpy); the basic sequences don't support them.The answers above don't discuss slice assignment:This may also clarify the difference between slicing and indexing.In short, the colons () in subscript notation () make slice notation - which has the optional arguments, , , :Python slicing is a computationally fast way to methodically access parts of your data. In my opinion, to be even an intermediate Python programmer, it's one aspect of the language that it is necessary to be familiar with.To begin with, let's define a few terms:You can make any of these positive or negative numbers. The meaning of the positive numbers is straightforward, but for negative numbers, just like indexes in Python, you count backwards from the end for the  and , and for the , you simply decrement your index. This example is , but I've modified it slightly to indicate which item in a sequence each index references:To use slice notation with a sequence that supports it, you must include at least one colon in the square brackets that follow the sequence (which actually .)Slice notation works like this:And recall that there are defaults for , , and , so to access the defaults, simply leave out the argument.Slice notation to get the last nine elements from a list (or any other sequence that supports it, like a string) would look like this:When I see this, I read the part in the brackets as \"9th from the end, to the end.\" (Actually, I abbreviate it mentally as \"-9, on\")The full notation is and to substitute the defaults (actually when  is negative, 's default is , so  for stop really just means it goes to whichever end step takes it to):The , ,  is what tells Python you're giving it a slice and not a regular index. That's why the idiomatic way of making a shallow copy of lists in Python 2 isAnd clearing them is with:(Python 3 gets a  and  method.)You may find it useful to separate forming the slice from passing it to the  method (). Even if you're not new to it, it keeps your code more readable so that others that may have to read your code can more readily understand what you're doing.However, you can't just assign some integers separated by colons to a variable. You need to use the slice object:The second argument, , is required, so that the first argument is interpreted as the  argument . You can then pass the slice object to your sequence:Since slices of Python lists create new objects in memory, another important function to be aware of is . Typically you'll want to iterate over a slice, not just have it created statically in memory.  is perfect for this. A caveat, it doesn't support negative arguments to , , or , so if that's an issue you may need to calculate indices or reverse the iterable in advance.The fact that list slices make a copy is a feature of lists themselves. If you're slicing advanced objects like a Pandas DataFrame, it may return a view on the original, and not a copy. And a couple of things that weren't immediately obvious to me when I first saw the slicing syntax:Easy way to reverse sequences!And if you wanted, for some reason, every second item in the reversed sequence:Found this great table at In Python 2.7Slicing in PythonUnderstanding index assignment is very important.When you say [a:b:c], you are saying depending on the sign of c (forward or backward), start at a and end at b (excluding element at bth index). Use the indexing rule above and remember you will only find elements in this range:But this range continues in both directions infinitely:For example:If your choice of a, b, and c allows overlap with the range above as you traverse using rules for a,b,c above you will either get a list with elements (touched during traversal) or you will get an empty list.One last thing: if a and b are equal, then also you get an empty list:After using it a bit I realise that the simplest description is that it is exactly the same as the arguments in a for loop...any of them are optionalthen the negative indexing just needs you to add the length of the string to the negative indices to understand it.This works for me anyway...I find it easier to remember how it's works, then I can figure out any specific start/stop/step combination.It's instructive to understand  first:Begin from , increment by , do not reach .  Very simple.The thing to remember about negative step is that  is always the excluded end, whether it's higher or lower. If you want same slice in opposite order, it's much cleaner to do the reversal separately: e.g.  slices off one char from left, two from right, then reverses. (See also .)Sequence slicing is same, except it first normalizes negative indexes, and can never go outside the sequence:: The code below had a bug with \"never go outside the sequence\" when abs(step)>1; I  I patched it to be correct, but it's hard to understand.Don't worry about the  details - just remember that omitting  and/or  always does the right thing to give you the whole sequence.Normalizing negative indexes first allows start and/or stop to be counted from the end independently:  despite .\nThe normalization is sometimes thought of as \"modulo the length\" but note it adds the length just once: e.g.  is just the whole string.I hope this will help you to model the list in Python.Reference: I use the \"an index points between elements\" method of thinking about it myself, but one way of describing it which sometimes helps others get it is this:X is the index of the first element you want.\nY is the index of the first element you  want.Python slicing notation:The notation extends to (numpy) matrices and multidimensional arrays.  For example, to slice entire columns you can use:Slices hold references, not copies, of the array elements.  If you want to make a separate copy an array, you can use .This is just for some extra info...\nConsider the list below Few other tricks for reversing the list:See abc's answer aboveYou can also use slice assignment to remove one or more elements from a list:As a general rule, writing code with a lot of hardcoded index values leads to a readability\nand maintenance mess. For example, if you come back to the code a year later, you\u2019ll\nlook at it and wonder what you were thinking when you wrote it. The solution shown\nis simply a way of more clearly stating what your code is actually doing.\nIn general, the built-in slice() creates a slice object that can be used anywhere a slice\nis allowed. For example:If you have a slice instance s, you can get more information about it by looking at its\ns.start, s.stop, and s.step attributes, respectively. For example:This is how I teach slices to newbies:Wiki Python has this amazing picture which clearly distinguishes indexing and slicing.It is a list with 6 elements in it. To understand slicing better, consider that list as a set of six boxes placed together. Each box has an alphabet in it.Indexing is like dealing with the contents of box. You can check contents of any box. But You can't check contents of multiple boxes at once. You can even replace contents of the box. But You can't place 2 balls in 1 box or replace 2 balls at a time.Slicing is like dealing with boxes itself. You can pickup first box and place it on another table. To pickup the box all You need to know is the position of beginning  & ending of the box.You can even pickup first 3 boxes or last 2 boxes or all boxes between 1 & 4. So, You can pick any set of boxes if You know beginning & ending. This positions are called start & stop positions.The interesting thing is that You can replace multiple boxes at once. Also You can place multiple boxes where ever You like.Till now You have picked boxes continuously. But some times You need to pickup discretely. For example You can pickup every second box. You can even pickup every third box from the end. This value is called step size. This represents the gap between Your successive pickups. The step size should be positive if You are picking boxes from the beginning to end and vice versa.When slicing if You leave out any parameter, Python tries to figure it out automatically.If You check source code of CPython, You will find a function called PySlice_GetIndicesEx which figures out indices to a slice for any given parameters. Here is the logical equivalent code in Python.This function takes a Python object & optional parameters for slicing and returns start, stop, step & slice length for the requested slice.This is the intelligence that is present behind slices. Since Python has inbuilt function called slice, You can pass some parameters & check how smartly it calculates missing parameters. This post is originally written in my blog To make it simple, remember and here is how it works:Another import thing:  And if they are omitted, their default value will be used: ,, accordingly.So possible variations are:NOTE: If (considering only when ), python will return a empty slice .The above part explains the core features on how slice works, it will work on most occasions. However there can be pitfalls you should watch out, and this part explains them.The very first thing confuses python learners is that  \nDon't panic: For example:Make things more confusing is that  : when step is negative, the default value for  to (while  does not equal to , because  contains ). For example:Be surprised: If the index is out of range, python will try its best set the index to  or  according to the situation. For example:Let's finish this answer with examples explains everything we have discussed:To get a certain piece of an iterable (like a list), here is an example:In this example, a positive number for number 1 is how many components you take off the front. A negative number is the exact opposite, how many you keep from the end. A positive number for number 2 indicates how many components you intend to keep from the beginning, and a negative is how many you intend to take off from the end. This is somewhat counter intuitive, but you are correct in supposing that list slicing is extremely useful.My brain seems happy to accept that  contains the -th item. I might even say that it is a 'natural assumption'.But occasionally a doubt creeps in and my brain asks for reassurance that it does not contain the -th element.In these moments I rely on this simple theorem:This pretty property tells me that  does not contain the -th item because it is in .Note that this theorem is true for any  at all. For example, you can check thatreturns .You can run this script and experiment with it, below is some samples that I got from the script.When using a negative step, notice that the answer is shifted to the right by 1.The answers above don't discuss multi-dimentional array slicing:The \":2\" before comma operates on the first dimension and the \"0:3:2\" after the comma operates on the second dimension."},
{"link": "https://stackoverflow.com//questions/986006/how-do-i-pass-a-variable-by-reference", "qbody": "The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'Is there something I can do to pass the variable by actual reference?Arguments are . The rationale behind this is twofold:So:To make it even more clear, let's have some examples. Output:Since the parameter passed in is a reference to , not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.Output:Since the  parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The  was a copy of the  reference, and we had  point to a new list, but there was no way to change where  pointed.Output:Again, since the  parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The  was a copy of the  reference, and we had  point to a new string, but there was no way to change where  pointed.I hope this clears things up a little. It's been noted that this doesn't answer the question that @David originally asked, \"Is there something I can do to pass the variable by actual reference?\". Let's work on that.As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:Although this seems a little cumbersome.The problem comes from a misunderstanding of what variables are in Python. If you're used to most traditional languages, you have a mental model of what happens in the following sequence:You believe that  is a memory location that stores the value , then is updated to store the value . That's not how things work in Python. Rather,  starts as a reference to an object with the value , then gets reassigned as a reference to an object with the value . Those two objects may continue to coexist even though  doesn't refer to the first one anymore; in fact they may be shared by any number of other references within the program.When you call a function with a parameter, a new reference is created that refers to the object passed in. This is separate from the reference that was used in the function call, so there's no way to update that reference and make it refer to a new object. In your example: is a reference to the string object . When you call  you create a second reference  to the object. Inside the function you reassign the reference  to a different string object , but the reference  is separate and does not change.The only way around this is to pass a mutable object. Because both references refer to the same object, any changes to the object are reflected in both places.It is neither pass-by-value or pass-by-reference - it is call-by-object. See this, by Fredrik Lundh: Here is a significant quote:In your example, when the  method is called--a  is created for it; and  becomes a name, within that namespace, for the string object . That object then has a name in two namespaces. Next,  binds  to a new string object, and thus the method's namespace forgets about . Finally, that namespace is forgotten, and the string  along with it.I found the other answers rather long and complicated, so I created this simple diagram to explain the way Python treats variables and parameters.\nThink of stuff being passed  instead of by reference/by value. That way, it is allways clear, what is happening as long as you understand what happens during normal assignment.So, when passing a list to a function/method, the list is assigned to the parameter name. Appending to the list will result in the list being modified. Reassigning the list  the function will not change the original list, since:Since immutable types cannot be modified, they  like being passed by value - passing an int into a function means assigning the int to the functions parameter. You can only ever reassign that, but it won't change the originial variables value.Technically, . I am going to repeat  to support my statement.Python always uses pass-by-reference values. There isn't any exception. Any variable assignment means copying the reference value. No exception. Any variable is the name bound to the reference value. Always.You can think about a reference value as the address of the target object. The address is automatically dereferenced when used. This way, working with the reference value, it seems you work directly with the target object. But there always is a reference in between, one step more to jump to the target.Here is the example that proves that Python uses passing by reference:If the argument was passed by value, the outer  could not be modified. The green are the target objects (the black is the value stored inside, the red is the object type), the yellow is the memory with the reference value inside -- drawn as the arrow. The blue solid arrow is the reference value that was passed to the function (via the dashed blue arrow path). The ugly dark yellow is the internal dictionary. (It actually could be drawn also as a green ellipse. The colour and the shape only says it is internal.)You can use the  built-in function to learn what the reference value is (that is, the address of the target object).In compiled languages, a variable is a memory space that is able to capture the value of the type. In Python, a variable is a name (captured internally as a string) bound to the reference variable that holds the reference value to the target object. The name of the variable is the key in the internal dictionary, the value part of that dictionary item stores the reference value to the target.Reference values are hidden in Python. There isn't any explicit user type for storing the reference value. However, you can use a list element (or element in any other suitable container type) as the reference variable, because all containers do store the elements also as references to the target objects. In other words, elements are actually not contained inside the container -- only the references to elements are.Effbot (aka Fredrik Lundh) has described Python's variable passing style as call-by-object:  Objects are allocated on the heap and pointers to them can be passed around anywhere.  Hope that clarifies the issue for you. (edit - Blair has updated his enormously popular answer so that it is now accurate)I think it is important to note that the current post with the most votes (by Blair Conrad), while being correct with respect to its result, is misleading and is borderline incorrect based on its definitions.  While there are many languages (like C) that allow the user to either pass by reference or pass by value, Python is not one of them.David Cournapeau's answer points to the real answer and explains why the behavior in Blair Conrad's post seems to be correct while the definitions are not.To the extent that Python is pass by value, all languages are pass by value since some piece of data (be it a \"value\" or a \"reference\") must be sent. However, that does not mean that Python is pass by value in the sense that a C programmer would think of it.If you want the behavior, Blair Conrad's answer is fine.  But if you want to know the nuts and bolts of why Python is neither pass by value or pass by reference, read David Cournapeau's answer.A simple trick I normally use is to just wrap it in a list:(Yeah I know this can be inconvenient, but sometimes it is simple enough to do this.)The key to understanding parameter passing is to stop thinking about \"variables\". There are names and objects in Python and together they\nappear like variables, but it is useful to always distinguish the three.That is all there is to it. Mutability is irrelevant for this question.Example: This binds the name  to an object of type integer that holds the value 1.This binds the name  to the same object that the name  is currently bound to.\nAfterwards, the name  has nothing to do with the name  any more.See sections  and  in the Python 3 language reference.So in the code shown in the question, the statement  binds the name  (in the scope of function ) to the object that holds the value  and the assignment  (in the body of function ) assigns that same name again: to some other object (that happens to hold a string as well but could have been something else entirely).You got some really good answers here.In this case the variable titled  in the method  is assigned a reference to , and you immediately assign a string to . It's no longer pointing to . The following code snippet shows what would happen if you modify the data structure pointed to by  and , in this case a list:I'm sure someone else could clarify this further.Python\u2019s pass-by-assignment scheme isn\u2019t quite the same as C++\u2019s reference parameters option, but it turns out to be very similar to the argument-passing model of the C language (and others) in practice:As you can state you need to have a mutable object, but let me suggest you to check over the global variables as they can help you or even solve this kind of issue!example:A lot of insights in answers here, but i think an additional point is not clearly mentioned here explicitly.   Quoting from python documentation   \"In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the function\u2019s body, it\u2019s assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as \u2018global\u2019.\nThough a bit surprising at first, a moment\u2019s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you\u2019d be using global all the time. You\u2019d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects.\"Even when passing a mutable object to a function this still applies. And to me clearly explains the reason for the difference in behavior between assigning to the object and operating on the object in the function.gives:The assignment to an global variable that is not declared global therefore creates a new local object and breaks the link to the original object.Here is the simple (I hope) explanation of the concept  used in Python.\nWhenever you pass an object to the function, the object itself is passed (object in Python is actually what you'd call a value in other programming languages) not the reference to this object. In other words, when you call:The actual object - [0, 1] (which would be called a value in other programming languages) is being passed. So in fact the function  will try to do something like:which obviously will not change the object passed to the function. If the function looked like this:Then the call would result in:which obviously will change the object.  explains it well.There is a little trick to pass an object by reference, even though the language doesn't make it possible. It works in Java too, it's the list with one item. ;-)It's an ugly hack, but it works. ;-PAside from all the great explanations on how this stuff works in Python, I don't see a simple suggestion for the problem. As you seem to do create objects and instances, the pythonic way of handling instance variables and changing them is the following:In instance methods, you normally refer to  to access instance attributes. It is normal to set instance attributes in  and read or change them in instance methods. That is also why you pass  als the first argument to .Another solution would be to create a static method like this:I used the following method to quickly convert a couple of Fortran codes to Python.  True, it's not pass by reference as the original question was posed, but is a simple work around in some cases.While pass by reference is nothing that fits well into python and should be rarely used there are some workarounds that actually can work to get the object currently assigned to a local variable or even reassign a local variable from inside of a called function.The basic idea is to have a function that can do that access and can be passed as object into other functions or stored in a class.One way is to use  (for global variables) or  (for local variables in a function) in a wrapper function.The same idea works for reading and eting a variable.For just reading there is even a shorter way of just using  which returns a callable that when called returns the current value of x. This is somewhat like \"call by name\" used in languages in the distant past.Passing 3 wrappers to access a variable is a bit unwieldy so those can be wrapped into a class that has a proxy attribute:Pythons \"reflection\" support makes it possible to get a object that is capable of reassigning a name/variable in a given scope without defining functions explicitly in that scope:Here the  class wraps a dictionary access. So attribute access to  is translated to a item access in the passed dictionary. By passing the result of the builtin  and the name of a local variable this ends up accessing a local variable. The python documentation as of 3.5 advises that changing the dictionary might not work but it seems to work for me.given the way python handles values and references to them, the only way you can reference an arbitrary instance attribute is by name:in real code you would, of course, add error checking on the dict lookup."},
{"link": "https://stackoverflow.com//questions/522563/accessing-the-index-in-python-for-loops", "qbody": "How do I access the index itself for a list like the following?When I loop through it using a  loop, how do I access the loop index, from 1 to 5 in this case?Using an additional state variable, such as an index variable (which you would normally use in languages such as C or PHP), is considered non-pythonic.The better option is to use the built-in function , available in both Python 2 and 3:Check out  for more.Use :And note that indexes start at zero, so you would get 0 to 4 with this. If you want the count, I explain that below.What you are asking for is the Pythonic equivalent of the following, which is the algorithm most programmers of lower-level languages would use:Or in languages that do not have a for-each loop:or sometimes more commonly (but unidiomatically) found in Python:Python's  reduces the visual clutter by hiding the accounting for the indexes, and encapsulating the iterable into another iterable (an  object) that yields a two-item tuple of the index and the item that the original iterable would provide. That looks like this:This code sample is fairly well the  example of the difference between code that is idiomatic of Python and code that is not. Idiomatic code is sophisticated (but not complicated) Python, written in the way that it was intended to be used. Idiomatic code is expected by the designers of the language, which means that usually this code is not just more readable, but also more efficient.Even if you don't need indexes as you go, but you need a count of the iterations (sometimes desirable) you can start with  and the final number will be your count.The count seems to be more what you intend to ask for (as opposed to index) when you said you wanted from 1 to 5.To break these examples down, say we have a list of items that we want to iterate over with an index:Now we pass this iterable to enumerate, creating an enumerate object:We can pull the first item out of this iterable that we would get in a loop with the  function:And we see we get a tuple of , the first index, and , the first item:we can use what is referred to as \"\" to extract the elements from this two-tuple:and when we inspect , we find it refers to the first index, 0, and  refers to the first item, .So do this:It's pretty simple to start it from  other than :Important hint, though a little misleading, since  will be a   here.\nGood to go.Old fashioned way:List comprehension:This way you can extend a list. Extend means you can add multiple values at a time.To append this list you have to write the code given below:This way you can add a single value at a time. If you write  so this will create a sub list for this element.According to this discussion: Loop counter iterationThe current idiom for looping over the indices makes use of the built-in 'range' function:Looping over both elements and indices can be achieved either by the old idiom or by using the new 'zip' built-in function[2]:orvia I don't know if the following is pythonic or not, but it uses the Python function  and prints the enumerator and the value.First of all, the indexes will be from 0 to 4. Programming languages start counting from 0; don't forget that or you will come across an index out of bounds exception. All you need in the for loop is a variable counting from 0 to 4 like so:Keep in mind that I wrote 0 to 5 because the loop stops one number before the max. :)To get the value of an index useThe fastest way to access indexes of list within loop in  is to use the  for small lists and  for medium and huge size lists.Please see  which can be used to iterate over list and access index value and  (which I suppose would be useful for you) in code samples below:See performance metrics for each method below:As the result, using  method is the fastest one up to list with 1000 items. For list with size > 10 000 items  is the winner.Adding some useful links below:You can do it with this code:Use this code if you need to reset the index value at the end of the loop:"},
{"link": "https://stackoverflow.com//questions/1132941/least-astonishment-and-the-mutable-default-argument", "qbody": "Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:Python novices would expect this function to always return a list with only one element: . The result is instead very different, and very astonishing (for a novice):A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?): Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?Doing the binding inside the function would mean that  is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the  line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.Actually, this is not a design flaw, and it is not because of internals, or performance.\nIt comes simply from the fact that functions in Python are first-class objects, and not only a piece of code.As soon as you get to think into this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of \"member data\" and therefore their state may change from one call to the other - exactly as in any other object.In any case, Effbot has a very nice explanation of the reasons for this behavior in .\nI found it very clear, and I really suggest reading it for a better knowledge of how function objects work.Suppose you have the following codeWhen I see the declaration of eat, the least astonishing thing is to think that if the first parameter is not given, that it will be equal to the tuple However, supposed later on in the code, I do something likethen if default parameters were bound at function execution rather than function declaration then I would be astonished (in a very bad way) to discover that fruits had been changed.  This would be more astonishing IMO than discovering that your  function above was mutating the list.The real problem lies with mutable variables, and all languages have this problem to some extent. Here's a question: suppose in Java I have the following code:Now, does my map use the value of the  key when it was placed into the map, or does it store the key by reference?  Either way, someone is astonished; either the person who tried to get the object out of the  using a value identical to the one they put it in with, or the person who can't seem to retrieve their object even though the key they're using is literally the same object that was used to put it into the map (this is actually why Python doesn't allow its mutable built-in data types to be used as dictionary keys).Your example is a good one of a case where Python newcomers will be surprised and bitten.  But I'd argue that if we \"fixed\" this, then that would only create a different situation where they'd be bitten instead, and that one would be even less intuitive. Moreover, this is always the case when dealing with mutable variables; you always run into cases where someone could intuitively expect one or the opposite behavior depending on what code they're writing.I personally like Python's current approach: default function arguments are evaluated when the function is defined and that object is always the default. I suppose they could special-case using an empty list, but that kind of special casing would cause even more astonishment, not to mention be backwards incompatible.AFAICS no one has yet posted the relevant part of the :I know nothing about the Python interpreter inner workings (and I'm not an expert in compilers and interpreters either) so don't blame me if I propose anything unsensible or impossible.Provided that python objects  I think that this should be taken into account when designing the default arguments stuff.\nWhen you instantiate a list:you expect to get a  list referenced by .Why should the a=[] ininstantiate a new list on function definition and not on invocation?\nIt's just like you're asking \"if the user doesn't provide the argument then  a new list and use it as if it was produced by the caller\".\nI think this is ambiguous instead:user, do you want  to default to the datetime corresponding to when you're defining or executing ?\nIn this case, as in the previous one, I'll keep the same behaviour as if the default argument \"assignment\" was the first instruction of the function (datetime.now() called on function invocation).\nOn the other hand, if the user wanted the definition-time mapping he could write:I know, I know: that's a closure. Alternatively Python might provide a keyword to force definition-time binding:Well, the reason is quite simply that bindings are done when code is executed, and the function definition is executed, well... when the functions is defined.Compare this:This code suffers from the exact same unexpected happenstance. bananas is a class attribute, and hence, when you add things to it, it's added to all instances of that class. The reason is exactly the same.It's just \"How It Works\", and making it work differently in the function case would probably be complicated, and in the class case likely impossible, or at least slow down object instantiation a lot, as you would have to keep the class code around and execute it when objects are created.Yes, it is unexpected. But once the penny drops, it fits in perfectly with how Python works in general. In fact, it's a good teaching aid, and once you understand why this happens, you'll grok python much better.That said it should feature prominently in any good Python tutorial. Because as you mention, everyone runs into this problem sooner or later.I used to think that creating the objects at runtime would be the better approach.  I'm less certain now, since you do lose some useful features, though it may be worth it regardless simply to prevent newbie confusion.  The disadvantages of doing so are:If call-time evaluation is used, then the expensive function is called every time your function is used without an argument.  You'd either pay an expensive price on each call, or need to manually cache the value externally, polluting your namespace and adding verbosity.A useful trick is to bind parameters of a lambda to the  binding of a variable when the lambda is created.  For example:This returns a list of functions that return 0,1,2,3... respectively.  If the behaviour is changed, they will instead bind  to the  value of i, so you would get a list of functions that all returned .The only way to implement this otherwise would be to create a further closure with the i bound, ie:Consider the code:We can get information about the arguments and defaults using the  module, which This information is very useful for things like document generation, metaprogramming, decorators etc.Now, suppose the behaviour of defaults could be changed so that this is the equivalent of:However, we've lost the ability to introspect, and see what the default arguments .  Because the objects haven't been constructed, we can't ever get hold of them without actually calling the function.  The best we could do is to store off the source code and return that as a string.This behavior is easy explained by:So:What you're asking is why this:isn't internally equivalent to this:except for the case of explicitly calling func(None, None), which we'll ignore.In other words, instead of evaluating default parameters, why not store each of them, and evaluate them when the function is called?One answer is probably right there--it would effectively turn every function with default parameters into a closure.  Even if it's all hidden away in the interpreter and not a full-blown closure, the data's got to be stored somewhere.  It'd be slower and use more memory.1)  The so-called problem of \"Mutable Default Argument\" is in general a special example demonstrating that:\n\"All functions with this problem ,\"\nThat is against the rules of functional programming, usually undesiderable and should be fixed both together.Example::  a \nAn absolutely safe solution is to  or  the input object first and then to do whatever with the copy.Many builtin mutable types have a copy method like  or  or can be copied easy like  or . Every object can be also copied by  or more thorough by  (the latter useful if the mutable object is composed from mutable objects). Some objects are fundamentally based on side effects like \"file\" object and can not be meaningfully reproduced by copy. Example problem for It shouldn't be neither saved in any  attribute of an instance returned by this function. (Assuming that  attributes of instance should not be modified from outside of this class or subclasses by convention. i.e.  is a private attribute )Conclusion:\nInput parameters objects shouldn't be modified in place (mutated) nor they should not be binded into an object returned by the function. (If we prefere programming without side effects which is strongly recommended. see  (The first two paragraphs are relevent in this context.)\n.)2)\nOnly if the side effect on the actual parameter is required but unwanted on the default parameter then the useful solution is    3) In some cases is .I'm  surprised no one has performed the insightful introspection offered by Python ( and  apply) on callables. Given a simple little function  defined as:When Python encounters it, the first thing it will do is compile it in order to create a  object for this function. While this compilation step is done, . As the top answer mentioned: the list  can now be considered a  of the function .So, let's do some introspection, a before and after to examine how the list gets expanded  the function object. I'm using  for this, for Python 2 the same applies (use  or  in Python 2; yes, two names for the same thing).After Python executes this definition it will take any default parameters specified ( here) and  (relevant section: Callables):     O.k, so an empty list as the single entry in , just as expected. Let's now execute this function:Now, let's see those  again:  The value inside the object changes! Consecutive calls to the function will now simply append to that embedded  object:So, there you have it, the reason why this  happens, is because default arguments are part of the function object. There's nothing weird going on here, it's all just a bit surprising.To further verify that the list in  is the same as that used in the function  you can just change your function to return the  of the list  used inside the function body. Then, compare it to the list in  (position  in ) and you'll see how these are indeed refering to the same list instance:All with the power of introspection!  To verify that Python evaluates the default arguments during compilation of the function, try executing the following:as you'll notice,  is called before the process of building the function and binding it to the name  is made.This actually has nothing to do with default values, other than that it often comes up as an unexpected behaviour when you write functions with mutable default values.No default values in sight in this code, but you get exactly the same problem.The problem is that  is  a mutable variable passed in from the caller, when the caller doesn't expect this. Code like this would be fine if the function was called something like ; then the caller would be calling the function in order to modify the value they pass in, and the behaviour would be expected. But such a function would be very unlikely to take a default argument, and probably wouldn't return the list (since the caller already has a reference to that list; the one it just passed in).Your original , with a default argument, shouldn't be modifying  whether it was explicitly passed in or got the default value. Your code should leave mutable arguments alone unless it is clear from the context/name/documentation that the arguments are supposed to be modified. Using mutable values passed in as arguments as local temporaries is an extremely bad idea, whether we're in Python or not and whether there are default arguments involved or not.If you need to destructively manipulate a local temporary in the course of computing something, and you need to start your manipulation from an argument value, you need to make a copy.It's a performance optimization.  As a result of this functionality, which of these two function calls do you think is faster?I'll give you a hint.  Here's the disassembly (see ):As you can see, there  a performance benefit when using immutable default arguments.  This can make a difference if it's a frequently called function or the default argument takes a long time to construct.  Also, bear in mind that Python isn't C.  In C you have constants that are pretty much free.  In Python you don't have this benefit.This behavior is not surprising if you take the following into consideration:The role of  has been covered extensively in this thread.  is likely the astonishment causing factor, as this behavior is not \"intuitive\" when coming from other languages. is described in the Python . In an attempt to assign a value to a read-only class attribute:Look back to the original example and consider the above points:Here  is an object and  is an attribute of  (available at ). Since  is a list,  is mutable and is thus a read-write attribute of . It is initialized to the empty list as specified by the signature when the function is instantiated, and is available for reading and writing as long as the function object exists. Calling  without overriding a default uses that default's value from . In this case,  is used for  within function object's code scope. Changes to  change , which is part of the  object and persists between execution of the code in .Now, compare this to the example from the documentation on , such that the function signature defaults are used every time the function is executed:Taking  and  into account, one can see why this accomplishes the the desired behavior: Already busy topic, but from what I read here, the following helped me realizing how it's working internally:A simple workaround using NoneThe solutions here are:The second option is nice because users of the function can pass in a callable, which may be already existing (such as a )the shortest answer would probably be \"definition is execution\", therefore the whole argument makes no strict sense. as a more contrived example, you may cite this:hopefully it's enough to show that not executing the default argument expressions at the execution time of the def statement isn't easy or doesn't make sense, or both.i agree it's a gotcha when you try to use default constructors, though.I sometimes exploit this behavior as an alternative to the following pattern:If  is only used by , I like the following pattern as a replacement:I've used this for instantiating client classes that access external resources, and also for creating dicts or lists for memoization.Since I don't think this pattern is well known, I do put a short comment in to guard against future misunderstandings.You can get round this by replacing the object (and therefore the tie with the scope):Ugly, but it works.When we do this:... we assign the argument  to an  list, if the caller does not pass the value of a.To make things simpler for this discussion, let's temporarily give the unnamed list a name. How about  ?At any time, if the caller doesn't tell us what  is, we reuse .If  is mutable (modifiable), and  ends up modifying it, an effect we notice the next time  is called without specifying .So this is what you see (Remember,  is initialized to []):Now,  is [5].Calling  again modifies  again:Specifying  when calling  ensures  is not touched.So,  is still .It may be true that:it is entirely consistent to hold to both of the features above and still make another point:The other answers, or at least some of them either make points 1 and 2 but not 3, or make point 3 and downplay points 1 and 2. It may be true that switching horses in midstream here would be asking for significant breakage, and that there could be more problems created by changing Python to intuitively handle Stefano's opening snippet. And it may be true that someone who knew Python internals well could explain a minefield of consequences. The existing behavior is not Pythonic, and Python is successful because very little about the language violates the principle of least astonishment anywhere  this badly. It is a real problem, whether or not it would be wise to uproot it. It is a design flaw. If you understand the language much better by trying to trace out the behavior, I can say that C++ does all of this and more; you learn a lot by navigating, for instance, subtle pointer errors. But this is not Pythonic: people who care about Python enough to persevere in the face of this behavior are people who are drawn to the language because Python has far fewer surprises than other language. Dabblers and the curious become Pythonistas when they are astonished at how little time it takes to get something working--not because of a design fl--I mean, hidden logic puzzle--that cuts against the intuitions of programmers who are drawn to Python because it .I am going to demonstrate an alternative structure to pass a default list value to a function (it works equally well with dictionaries).  As others have extensively commented, the list parameter is bound to the function when it is defined as opposed to when it is executed.  Because lists and dictionaries are mutable, any alteration to this parameter will affect other calls to this function.  As a result, subsequent calls to the function will receive this shared list which may have been altered by any other calls to the function.  Worse yet, two parameters are using this function's shared parameter at the same time oblivious to the changes made by the other.:You can verify that they are one and the same object by using :Per Brett Slatkin's \"Effective Python: 59 Specific Ways to Write Better Python\",  (p. 48)This implementation ensures that each call to the function either receives the default list or else the list passed to the function.:There may be legitimate use cases for the 'Wrong Method' whereby the programmer intended the default list parameter to be shared, but this is more likely the exception than the rule.This \"bug\" gave me a lot of overtime work hours! But I'm beginning to see a potential use of it (but I would have liked it to be at the execution time, still)I'm gonna give you what I see as a useful example.prints the followingDefault arguments get evaluated at the time the function is compiled into a function object. When used by the function, multiple times by that function, they are and remain the same object. When they are mutable, when mutated (for example, by adding an element to it) they remain mutated on consecutive calls.They stay mutated because they are the same object each time.Here's a demonstration - you can verify that they are the same object each time they are referenced by and running it with :This order of execution is frequently confusing to new users of Python. If you understand the Python execution model, then it becomes quite expected. But this is why the usual instruction to new users is to create their default arguments like this instead:This uses the None singleton as a sentinel object to tell the function whether or not we've gotten an argument other than the default. If we get no argument, then we actually want to use a new empty list, , as the default.As the  says:I think the answer to this question lies in how python pass data to parameter (pass by value or by reference), not mutability or how python handle the \"def\" statement.A brief introduction. First, there are two type of data types in python, one is simple elementary data type, like numbers, and another data type is objects. Second, when passing data to parameters, python pass elementary data type by value, i.e., make a local copy of the value to a local variable, but pass object by reference, i.e., pointers to the object.Admitting the above two points, let's explain what happened to the python code. It's only because of passing by reference for objects, but has nothing to do with mutable/immutable, or arguably the fact that \"def\" statement is executed only once when it is defined.[] is an object, so python pass the reference of [] to , i.e.,  is only a pointer to [] which lies in memory as an object. There is only one copy of [] with, however, many references to it. For the first foo(), the list [] is changed to  by append method. But Note that there is only one copy of the list object and this object now becomes . When running the second foo(), what effbot webpage says (items is not evaluated any more) is wrong.  is evaluated to be the list object, although now the content of the object is . This is the effect of passing by reference! The result of foo(3) can be easily derived in the same way.To further validate my answer, let's take a look at two additional codes.====== No. 2 ======== is an object, so is  (the former is mutable while the latter is immutable. But the mutability has nothing to do with the question). None is somewhere in the space but we know it's there and there is only one copy of None there. So every time foo is invoked, items is evaluated (as opposed to some answer that it is only evaluated once) to be None, to be clear, the reference (or the address) of None. Then in the foo, item is changed to [], i.e., points to another object which has a different address. ====== No. 3 =======The invocation of foo(1) make items point to a list object [] with an address, say, 11111111. the content of the list is changed to  in the foo function in the sequel, but the address is not changed, still 11111111. Then foo(2,[]) is coming. Although the [] in foo(2,[]) has the same content as the default parameter [] when calling foo(1), their address are different! Since we provide the parameter explicitly,  has to take the address of this new , say 2222222, and return it after making some change. Now foo(3) is executed. since only  is provided, items has to take its default value again. What's the default value? It is set when defining the foo function: the list object located in 11111111. So the items is evaluated to be the address 11111111 having an element 1. The list located at 2222222 also contains one element 2, but it is not pointed by items any more. Consequently, An append of 3 will make  [1,3]. From the above explanations, we can see that the  webpage recommended in the accepted answer failed to give a relevant answer to this question. What is more, I think a point in the effbot webpage is wrong. I think the code regarding the UI.Button is correct:Each button can hold a distinct callback function which will display different value of . I can provide an example to show this:If we execute  we'll get 7 as expected, and  will gives 9, another value of .A very subtle issue being pointed out here. Thanks for all the insights.I ran into a similar problem and found a fix for this.  Now, independent of the number of times you call, this will work as \"expected\"Just change the function to be:"},
{"link": "https://stackoverflow.com//questions/4750806/how-do-i-install-pip-on-windows", "qbody": " is a replacement for . But should I install  using  on Windows?  Is there a better way?Good news!  (released March 2014) and  (released December 2014) ship with Pip. This is the best feature of any Python release. It makes the community's wealth of libraries accessible to everyone. Newbies are no longer excluded from using community libraries by the prohibitive difficulty of setup. In shipping with a package manager, Python joins , , , , --almost every other contemporary language with a majority open-source community. Thank you Python.Of course, that doesn't mean Python packaging is problem solved. The experience remains frustrating. I discuss this .And, alas for everyone using Python 2.7.8 or earlier (a sizable portion of the community). There's no plan to ship Pip to you. Manual instructions follow.Flying in the face of its  motto, Python ships without a package manager. To make matters worse, Pip was--until recently--ironically difficult to install.Per :Download , being careful to save it as a  file rather than . Then, run it from the command prompt:You possibly need an administrator command prompt to do this. Follow  (Microsoft TechNet).The official documentation tells users to install Pip and each of its dependencies from source. That's tedious for the experienced, and prohibitively difficult for newbies.For our sake, Christoph Gohlke prepares Windows installers () for popular Python packages. He builds installers for all Python versions, both 32 and 64 bit. You need toFor me, this installed Pip at . Find  on your computer, then add its folder (for example, ) to your path (Start / Edit environment variables). Now you should be able to run  from the command line. Try installing a package:There you go (hopefully)! Solutions for common problems are given below:If you work in an office, you might be behind a HTTP proxy. If so, set the environment variables . Most Python applications (and other free software) respect these. Example syntax:If you're really unlucky, your proxy might be a Microsoft  proxy. Free software can't cope. The only solution is to install a free software friendly proxy that forwards to the nasty proxy. Python modules can be part written in C or C++. Pip tries to compile from source. If you don't have a C/C++ compiler installed and configured, you'll see this cryptic error message.You can fix that by  such as  or . Microsoft actually ship one specifically for use with Python. Or try .Often though it's easier to check  for your package.\n--  -- use setuptools as distribute is deprecated.As you mentioned pip doesn't include an independent installer, but you can install it with its predecessor easy_install.So:You are done. Now you can use  to easily install packages as in Linux :)1) If you have installed Python 3.4 or later, pip is included with Python and should already be working on your system.2) If you are running a version below Python 3.4 or if pip was not installed with Python 3.4 for some reason, then you'd probably use pip's official installation script . The pip installer now grabs setuptools for you, and works regardless of architecture (32-bit or 64-bit).The installation  and involve:I'll leave the two sets of old instructions below for posterity.For Windows editions of the  variety - 64-bit Windows + Python used to require a separate installation method due to ez_setup, but I've tested the new distribute method on 64-bit Windows running 32-bit Python and 64-bit Python, and you can now use the same method for all versions of Windows/Python 2.7X: using :The last step will not work unless you're either in the directory  is located in (C:\\Python27\\Scripts would be the default for Python 2.7), or you have that directory added to your path. using ez_setup: --After this, you may continue with: These answers are outdated or otherwise wordy and difficult.If you've got Python 3.4+ or 2.7.9+, it will be  on Windows.  Otherwise, in short:The new binaries  (and the deprecated ) will be found in the  folder (or similar), which is likely not in your  variable.  I recommend adding it.Python 3.4, which  was released in March 2014, comes with  included:\n\nSo since the release of Python 3.4, the up-to-date way to install pip on Windows is to just install Python.\nWhen sticking to all defaults during installation, pip will be installed to\n.When I have to use Windows, I use ActivePython, which automatically adds everything to your PATH and includes a package manager called  which provides  package management making it faster and simpler to install packages. and  aren't exactly the same thing, so there are some things you can get through  but not  .My recommendation is that you get  and don't worry about the huge hassle of getting everything set up for Python on Windows. Then, you can just use .In case you want to use  you have to check the  option in the ActiveState installer. After installation you only need to logoff and log on again, and  will be available on the commandline, because it is contained in the ActiveState installer  option and the paths have been set by the installer for you already.  will also be available, but you do not have to use it.The up-to-date way is to use Windows' package manager .Once this is installed, all you have to do is open a command prompt and run the following the three commands below, which will install Python 2.7, easy_install and pip. It will automatically detect whether you're on x64 or x86 Windows.All of the other Python packages on the Chocolatey Gallery can be found .Python 2.7.9 and later (on the Python 2 series), and Python 3.4 and later include pip by default, so you may have pip already.If you don't, run this one line command on your prompt (which may require administrator access):It will install . If  is not already installed,  will install it for you too.As mentioned in comments, the above command will download code from the Pip source code repository at , and dynamically run it at your environment. So be noticed that this is a shortcut of the steps download, inspect and run, . If you trust Pip, proceed without doubt.Be sure that your Windows environment variable PATH includes Python's folders (for Python 2.7.x default install:  and , for Python 3.3x:  and , and so on).I've built Windows installers for both  and  here (the goal being to use  without having to either bootstrap with  or save and run Python scripts):On Windows, simply download and install first , then  from the above links. The  link above does contain stub  installers, and these are currently 32-bit only. I haven't tested the effect on 64-bit Windows.The process to redo this for new versions is not difficult, and I've included it here for reference.In order to get the stub  files, you need to have a Visual C++ compiler (it is apparently compilable with MinGW as well)The following works for Python 2.7. Save this script and launch it:  \n  \nPip is installed, then add the path to your environment : FinallyAlso you need Microsoft  to get the good compiler and avoid these kind of messages when installing packages:If you have a 64-bit version of Windows 7, you may read  to successfully install the Python executable package (issue with registry entries).To install pip  on Python 2.x, easy_install appears to be the best solution as Adri\u00e1n states.However the  for pip recommend using  since every virtualenv has pip installed in it automatically.  This does not require root access or modify your system Python installation.Installing virtualenv still requires easy_install though.To use pip, it is not mandatory that you need to install pip in the system directly. You can use it through . What you can do is follow these steps:We normally need to install Python packages for one particular project. So, now create a project folder, let\u2019s say myproject.Now create a virtual environment, let\u2019s say  as follows, inside the  folder:It will show you:Now your virtual environment, , is created inside your project folder. You might notice, pip is now installed inside you virtual environment. All you need to do is activate the virtual environment with the following command.You will see the following at the command prompt:Now you can start using pip, but make sure you have activated the virtualenv looking at the left of your prompt.This is one of the easiest way to install pip i.e. inside virtual environment, but you need to have virtualenv.py file with you.For more ways to install pip/virtualenv/virtualenvwrapper, you can refer to .I just wanted to add one more solution for those having issues installing setuptools from Windows 64-bit. The issue is discussed in this bug on python.org and is still unresolved as of the date of this comment. A simple workaround is mentioned and it works flawlessly. One registry change did the trick for me.Link: Solution that worked for me...:Add this registry setting for 2.6+ versions of Python:This is most likely the registry setting you will already have for Python 2.6+:Clearly, you will need to replace the 2.6 version with whatever version of Python you are running.The best way I found so far, is just two lines of code:It was tested on Windows 8 with , Cmd, and  Bash ().And you probably want to add the path to your environment. It's somewhere like .  should already be included in , but if for whatever reason it is not there, you can use the following one-liner.PS:Can't believe there are so many lengthy (perhaps outdated?) answers out there. Feeling thankful to them but, please up-vote this short answer to help more new comers! comes with  included, among .Here how to install pip with easy way.I use the cross-platform  package manager from continuum.io on Windows and it is reliable.  It has virtual environment management and a fully featured shell with common utilities (e.g. conda, pip). also comes with binaries for libraries with non-Python dependencies, e.g. , , etc.  This proves useful particularly on Windows as it can be  hard to correctly compile C dependencies.I wrote  that wraps both the ez_setup.py and get-pip.py install scripts that were mentioned in Gringo Suave's answer (and runs a pip install --upgrade setuptools for the latest setuptools version once pip is installed).Clone the repository with:Or download a .zip archive:And then run the pipinstall.py script in the top level of the repository directory:This will give you the latest releases for both applications.  It's safe to remove the script repository after the install.I had some issues installing in different ways when I followed instructions here. I think it's very tricky to install in every Windows environment in the same way. In my case I need Python 2.6, 2.7 and 3.3 in the same machine for different purposes so that's why I think there're more problems.\nBut the following instructions worked perfectly for me, so might be depending on your environment you should try this one:Also, due to the different environments I found incredible useful to use Virtual Environments, I had websites that use different libraries and it's much better to encapsulate them into a single folder, check out the instructions, briefly if PIP is installed you just install VirtualEnv:Into the folder you have all your files runAnd seconds later you have a virtual environment with everything in venv folder, to activate it run venv/Scripts/activate.bat (deactivate the environment is easy, use deactivate.bat). Every library you install will end up in venv\\Lib\\site-packages and it's easy to move your whole environment somewhere.The only downside I found is some code editors can't recognize this kind of environments, and you will see warnings in your code because imported libraries are not found. Of course there're tricky ways to do it but it would be nice editors keep in mind Virtual Environments are very normal nowadays.Hope it helps.Guide link: Note: Make sure scripts path like this (C:\\Python27\\Scripts) is added int %PATH% environment variable as well.It's very simple:(Make sure your Python and Python script directory (for example,  and ) are in the PATH.)Working as of Feb 04 2014 :):If you have tried installing pip through the Windows installer file from  as suggested by @Colonel Panic, you might have installed the pip package manager successfully, but you might be unable to install any packages with pip. You might also have got the same SSL error as I got when I tried to install  if you look in the pip.log file:The problem is an issue with an old version of  being incompatible with pip 1.3.1 and above versions. The easy workaround for now, is to install pip 1.2.1, which does not require :Installing Pip on Windows:Now try to install any package using pip.For example, to install the  package using pip, run this from cmd:Whola!  will be successfully installed and you will get a success message.Just download setuptools-15.2.zip (md5), from here  , and run ez_setup.py.Alternatively, you can get  which is an all-in-one installer for pip and  on Windows and its GUI. is already installed if you're using Python 2 >=2.7.9 or Python 3 >=3.4 binaries downloaded from , but you'll need to upgrade pip.On Windows upgrade can be done easily Go to Python command line and run below Python commandpython -m pip install -U pipInstalling with get-pip.pyDownload  in the same folder or any other folder of your choice. I am assuming you will download it in the same folder from you have python.exe file and run this command Pip's  is pretty clean and simple.Using this you should be able to get started with Pip in under two minutes.you have to get the get_pip.py file search it on google copy   from there and  save it locally in c drive in pip directory I think the question makes it seem like the answer is simpler than it really is. Running of pip will sometimes require native compilation of a module (64-bit Numpy is a common example of that). In order for pip's compilation to succeed, you need Python which was compiled with the same version of MSVC as the one pip is using. Standard Python distributions are compiled with MSVC 2008. You can install an Express version of VC2008, but it is not maintained. Your best bet is to get an express version of a later MSVC and compile Python. Then PIP and Python will be using the same MSVC version.How to install pip:There is also an issue with  on . After installation, the output of  command is always empty, no matters what commands/options do you use (even  doesn't produce any output).If it's your case, just install the development version of Cygwin's package  called . Without that package using of  causes a segfault. And  uses that package, so the segfault is the cause of an empty output of  on Cygwin x64. On 32 bit Cygwin it's working fine even without that package.You can read some details there: "},
{"link": "https://stackoverflow.com//questions/3437059/does-python-have-a-string-contains-substring-method", "qbody": "I'm looking for a  or  method in Python.I want to do:You can use the :If it's just a substring search you can use .You do have to be a little careful with , , and  though, as they are substring searches. In other words, this:It would print  Similarly,  would evaluate to . This may or may not be what you want. is the normal use, as @Michael says -- it relies on the  operator, more readable and faster than a method call.If you truly need a method instead of an operator (e.g. to do some weird  for a very peculiar sort...?), that would be .  But since your example is for use in an , I guess you don't really mean what you say;-).  It's not good form (nor readable, nor efficient) to use special methods directly -- they're meant to be used, instead, through the operators and builtins that delegate to them.No, there isn't any  method, but there is the  operator:Here is a more complex working example:Basically, you want to find a substring in a string in python. There are two ways to search for a substring in a string in Python.You can use the Python's  operator to check for a substring. It's quite simple and intuitive. It will return  if the substring was found in the string else .The second method is to use the  method. Here, we call the  method on the string in which substring is to found. We pass the substring to the find() method and check its return value. If its value is other than -1, the substring was found in the string, otherwise not. The value returned is the index where substring was found.I would recommend you to use the first method as it is more Pythonic and intuitive.Yes, but Python has a comparison operator that you should use instead, because the language intends its usage, and other programmers will expect you to use it. That keyword is , which is used as a comparison operator:The opposite (complement), which the original question asks for, is :This is semantically the same as  but it's much more readable and explicitly provided for in the language as a readability improvement.As promised, here's the  method:returns . You could also call this function from the instance of the superstring:But don't. Methods that start with underscores are considered semantically private. The only reason to use this is when extending the  and  functionality (e.g. if subclassing ): and now:Also, avoid the following string methods:Other languages may have no methods to directly test for substrings, and so you would have to use these types of methods, but with Python, it is more efficient to use the  comparison operator:And now we see that using  -is much faster than the below:So apparently there is nothing similar for vector-wise comparison. An obvious Python way to do so would be:Another way to find whether a string contains a few characters or not with the Boolean return value (i.e.  or `False):In Python there are two simple ways you can achieve this: takes two \"arguments\", one on the left() and one on the right, and returns  if the left argument is contained within the rightside argument and if not,it returns .Output:The  method returns the position of the string within the string or -1 if it's not found. But simply check if the position is not -1.Output:Here is your answer:For checking if it is false:OR:Here are a few useful examples that speak for themselves concerning the  method:Caveat. Lists are iterables, and the  method acts on iterables, not just strings."},
{"link": "https://stackoverflow.com//questions/3207219/how-do-i-list-all-files-of-a-directory", "qbody": "How can I list all files of a directory in Python and add them to a list? will get you everything that's in a directory - files and directories.If you want  files, you could either filter this down using :or you could use  which will yield two lists for each directory it visits - splitting into files and dirs for you. If you only want the top directory you can just break the first time it yieldsAnd lastly, as that example shows, adding one list to another you can either use  or Personally, I prefer I prefer using the  module, as it does pattern matching and expansion.Will return a list with the queried files:will return a list of all files and directories in \"somedirectory\".A one-line solution to get  (no subdirectories):or absolute pathnames:If you'd like, you can open and read the contents, or focus only on files with the extension \".dat\" like in the code below:It's the same as in Python 3 (except the print)I really liked , suggesting that you use , from the module of the same name. This allows you to have pattern matching with s.But as other people pointed out in the comments,  can get tripped up over inconsistent slash directions. To help with that, I suggest you use the  and  functions in the  module, and perhaps the  function in the  module, as well.As examples:The above is terrible - the path has been hardcoded and will only ever work on Windows between the drive name and the s being hardcoded into the path.The above works better, but it relies on the folder name  which is often found on Windows and not so often found on other OSs. It also relies on the user having a specific name, .This works perfectly across all platforms.Another great example that works perfectly across platforms and does something a bit different:Hope these examples help you see the power of a few of the functions you can find in the standard Python library modules.Since version 3.4 there are builtin  for this which are a lot more efficient than :: According to , the aim of the  library is to provide a simple hierarchy of classes to handle filesystem paths and the common operations users do over them. : Note that  use  instead of  from version 3.5 and it's speed got increased by 2-20 times according to .Let me also recommend reading ShadowRanger's comment below.You should use  module for listing directory content. returns all the contents of the directory. We iterate over the result and append to the list.os.listdir returns a list containing the names of the entries in the directory given by path. If you are looking for a Python implementation of , this is a recipe I use rather frequently:So I made a PyPI  out of it and there is also a . I hope that someone finds it potentially useful for this code.Python 3.5 introduced new, faster method for walking through the directory - .Example:List all files in a directory:Here, you get list of all files in a directory.If you care about performance, try , for Python 2.x, you may need to install it manually. Examples:This save a lot of time when you need to scan a huge directory, you do not need to buffer a huge list, just fetch one by one. And also you can do it recursively:Use this function if you want to different file type or get full directory.By using  library.Using generatorsHere is a simple example:Here is the example returning list of files with absolute paths:Documentation:  and  for Python 2,  and  for Python 3."},
{"link": "https://stackoverflow.com//questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "qbody": "What is the difference between a function decorated with  and one decorated with ?Maybe a bit of example code will help: Notice the difference in the call signatures of ,  and :Below is the usual way an object instance calls a method. The object instance, , is implicitly passed as the first argument., the class of the object instance is implicitly passed as the first argument instead of .You can also call  using the class. In fact, if you define something to be\na classmethod, it is probably because you intend to call it from the class rather than from a class instance.  would have raised a TypeError, but  works just fine:One use people have found for class methods is to create ., neither  (the object instance) nor   (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:Staticmethods are used to group functions which have some logical connection with a class to the class. is just a function, but when you call  you don't just get the function,\nyou get a \"partially applied\" version of the function with the object instance  bound as the first argument to the function.  expects 2 arguments, while  only expects 1 argument. is bound to . That is what is meant by the term \"bound\" below:With ,  is not bound to , rather the class  is bound to .Here, with a staticmethod, even though it is a method,  just returns\na good 'ole function with no arguments bound.  expects 1 argument, and\n expects 1 argument too.And of course the same thing happens when you call  with the class  instead.A staticmethod is a method that knows nothing about the class or instance it was called on. It just gets the arguments that were passed, no implicit first argument. It is basically useless in Python -- you can just use a module function instead of a staticmethod.A classmethod, on the other hand, is a method that gets passed the class it was called on, or the class of the instance it was called on, as first argument. This is useful when you want the method to be a factory for the class: since it gets the actual class it was called on as first argument, you can always instantiate the right class, even when subclasses are involved. Observe for instance how , a classmethod, returns an instance of the subclass when called on a subclass:Basically  makes a method whose first argument is the class it's called from (rather than the class instance),  does not have any implicit arguments. is a short article on this question@decorators were added in python 2.4 If you're using python < 2.4 you can use the classmethod() and staticmethod() function.For example, if you want to create a factory method (A function returning an instance of a different implementation of a class depending on what argument it gets) you can do something like:Also observe that this is a good example for using a classmethod and a static method,\nThe static method clearly belongs to the class, since it uses the class Cluster internally.\nThe classmethod only needs information about the class, and no instance of the object.Another benefit of making the  method a classmethod is so a subclass can decide to change it's implementation, maybe because it is pretty generic and can handle more than one type of cluster, so just checking the name of the class would not be enough.You may have seen Python code like this pseudocode, which demonstrates the signatures of the various method types and provides a docstring to explain each:First I'll explain the . This may be better called an \"\". When an instance method is used, it is used as a partial function (as opposed to a total function, defined for all values when viewed in source code) that is, when used, the first of the arguments is predefined as the instance of the object, with all of its given attributes. It has the instance of the object bound to it, and it must be called from an instance of the object. Typically, it will access various attributes of the instance.For example, this is an instance of a string:if we use the instance method,  on this string, to join another iterable,\nit quite obviously is a function of the instance, in addition to being a function of the iterable list, :The static method does  take the instance as an argument. Yes it is very similar to a module level function. However, a module level function must live in the module and be specially imported to other places where it is used. If it is attached to the object, however, it will follow the object conveniently through importing and inheritance as well.An example is the  static method, moved from the  module in Python 3.  It makes a translation table suitable for consumption by . It does seem rather silly when used from an instance of a string, as demonstrated below, but importing the function from the  module is rather clumsy, and it's nice to be able to call it from the class, as in In python 2, you have to import this function from the increasingly deprecated string module:A class method is a similar to a static method in that it takes an implicit first argument, but instead of taking the instance, it takes the class. Frequently these are used as alternative constructors for better semantic usage and it will support inheritance.The most canonical example of a builtin classmethod is . It is used as an alternative constructor of dict, (well suited for when you know what your keys are and want a default value for them.)When we subclass dict, we can use the same constructor, which creates an instance of the subclass.See the  for other similar examples of alternative constructors, and see also the official Python documentation on  and .I think a better question is \"When would you use @classmethod vs @staticmethod?\"@classmethod allows you easy access to private members that are associated to the class definition. this is a great way to do singletons, or factory classes that control the number of instances of the created objects exist.@staticmethod provides marginal performance gains, but I have yet to see a productive use of a static method within a class that couldn't be achieved as a standalone function outside the class.To decide whether to use  or  you have to look inside your method. . On the other hand if your method does not touch any other parts of the class then use @staticmethod. just disables the default function as method descriptor.  classmethod wraps your function in a container callable that passes a reference to the owning class as first argument:As a matter of fact,  has a runtime overhead but makes it possible to access the owning class.  Alternatively I recommend using a metaclass and putting the class methods on that metaclass: is one good link for this topic, and summary it as following. function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It\u2019s definition is immutable via inheritance. function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance, can be overridden by subclass. That\u2019s because the first argument for  function must always be  (class).: when this method is called, we pass the class as the first argument instead of the instance of that class (as we normally do with methods). This means you can use the class and its properties inside that method rather than a particular instance. when this method is called, we don't pass an instance of the class to it (as we normally do with methods). This means you can put a function inside a class but you can't access the instance of that class (this is useful when your method does not use the instance).Another consideration with respect to staticmethod vs classmethod comes up with inheritance.  Say you have the following class:And you then want to override  in a child class:This works, but note that now the  implementation in the child class () can no longer take advantage of anything specific to that class.  For example, say  had a method called  that you want to use in the  implementation of :The workaround here would be to call  in , but then you're repeating yourself (if the name of  changes, you'll have to remember to update that  method).To me, this is a slight violation of the , since a decision made in  is impacting your ability to refactor common code in a derived class (ie it's less open to extension).  If  were a  we'd be fine:Gives: In , a classmethod receives a class as the implicit first argument. The class of the object instance is implicitly passed as the first argument. This can be useful\nwhen one wants the method to be a factory of the class as it gets the actual class (which called the method) as the first argument, one can instantiate the right class, even if subclasses are also concerned.A staticmethod is just a function defined inside a class. It does not  know anything about the class or instance it was called on and only gets  the arguments that were passed without any implicit first argument.\nExample:staticmethods are used to group functions which have some logical connection with a class to the class.I will try to explain the basic difference using an example.1 - we can directly call static and classmethods without initializing2- Static method cannot call self method but can call other static and classmethod3- Static method belong to class and will not use object at all.4- Class method are not bound to an object but to a class.A quick hack-up ofotherwise identical methods in iPython reveals that  yields marginal performance gains (in the nanoseconds), but otherwise it seems to serve no function. Also, any performance gains will probably be wiped out by the additional work of processing the method through  during compilation (which happens prior to any code execution when you run a script).For the sake of code readability I'd avoid  unless your method will be used for loads of work, where the nanoseconds count."},
{"link": "https://stackoverflow.com//questions/252703/append-vs-extend", "qbody": "What's the difference between the list methods  and ?: Appends object at end.gives you: : Extends list by appending elements from the iterable.gives you:  adds an element to a list,  concatenates the first list with another list (or another iterable not necessarily a list.)From .And in this context it can also be good to remember that strings are also iterable.The  method appends an object to the end of the list.Whatever the object is, whether a number, a string, another list, or something else, it gets added onto the end of  as a single entry on the list. So keep in mind that a list is an object. If you append another list onto a list, the first list will be a single object at the end of the list (which may not be what you want):The  method extends a list by appending elements from an iterable:So with extend, each element of the iterable gets appended onto the list. For example:Keep in mind that a string is an iterable, so if you extend a list with a string, you'll append each character as you iterate over the string (which may not be what you want):Both  and  operators are defined for . They are semantically similar to extend. creates a third list in memory, so you can return the result of it, but it requires that the second iterable be a list.  modifies the list in-place (it  the in-place operator, and lists are mutable objects, as we've seen) so it does not create a new list. It also works like extend, in that the second iterable can be any kind of iterable.Append has , O(1). Extend has time complexity, O(k). Iterating through the multiple calls to  adds to the complexity, making it equivalent to that of extend, and since extend's iteration is implemented in C, it will always be faster if you intend to append successive items from an iterable onto a listYou may wonder what is more performant, since append can be used to achieve the same outcome as extend. The following functions do the same thing:So let's time them:We see that  can run much faster than , and it is semantically clearer, so it is preferred  If you only have a single element to add to the list, use . appends a single element.  appends a list of elements.Note that if you pass a list to append, it still adds one element:The following two snippets are semantically equivalent:andThe latter may be faster as the loop is implemented in C.You can use \"+\" for returning extend, instead of extending in place.Similarly  for in place behavior, but with slight differences from  & . One of the biggest differences of  from  and  is when it is used in function scopes, see .The append() method adds a single item to the end of the list. The extend() method takes one argument, a list, and appends each of the items of the argument to the original list. (Lists are implemented as classes. \u201cCreating\u201d a list is really instantiating a class. As such, a list has methods that operate on it.)From append(object) - Updates the list by adding an object to the list.extend(list) - Essentially concatenates 2 lists. can be used with an iterator argument. Here is an example. You wish to make a list out of a list of lists this way:fromyou wantYou may use  to do so. This method's output is an iterator. It's implementation is equivalent toBack to our example, we can do and get the wanted list.Here is how equivalently  can be used with an iterator argument:This is the equivalent of  and  using the  operator:An interesting point that has been hinted, but not explained, is that extend is faster than append. For any loop that has append inside should be considered to be replaced by list.extend(processed_elements).Bear in mind that apprending new elements might result in the realloaction of the whole list to a better location in memory. If this is done several times because we are appending 1 element at a time, overall performance suffers. In this sense, list.extend is analogous to \"\".join(stringlist).: It is basically used in Python to add one element.: Where extend(), is used to merge two lists or insert multiple elements in one list.Append adds the entire data at once. The whole data will be added to the newly created index. On the other hand, , as it name suggests, extends the current array. For exampleWith  we get:While on  we get:append:output : [1,2,3,4,5,[\"a\",\"b\",\"c\",\"d\",\"e\"]]extend :output : [1,2,3,4,5,\"a\",\"b\",\"c\",\"d\",\"e\"]The method \"append\" adds its parameter as a  to the list, while \"extend\" gets a list and adds its content.for example,  I hope I can make a useful supplement to this question. If your list stores a specific type object, for example , here is a situation that  method is not suitable: In a  loop and and generating an  object every time and using  to store it into your list, it will fail. The exception is like below:But if you use the  method, the result is OK. Because every time using the  method, it will always treat it as a list or any other collection type, iterate it, and place it after the previous list. A specific object can not be iterated, obviously.extend(L) extends the list by appending all the items in the given list L."},
{"link": "https://stackoverflow.com//questions/423379/using-global-variables-in-a-function-other-than-the-one-that-created-them", "qbody": "If I create a global variable in one function, how can I use that variable in another function?\nDo I need to store the global variable in a local variable of the function which needs its access?You can use a global variable in other functions by declaring it as  in each function that assigns to it:I imagine the reason for it is that, since global variables are so dangerous, Python wants to make sure that you really know that's what you're playing with by explicitly requiring the  keyword.See other answers if you want to share a global variable across modules.If I'm understanding your situation correctly, what you're seeing is the result of how Python handles local (function) and global (module) namespaces.Say you've got a module like this:You might expecting this to print 42, but instead it prints 5.  As has already been mentioned, if you add a '' declaration to , then  will print 42.What's going on here is that Python assumes that any name that is , anywhere within a function, is local to that function unless explicitly told otherwise.  If it is only  from a name, and the name doesn't exist locally, it will try to look up the name in any containing scopes (e.g. the module's global scope).When you assign 42 to the name , therefore, Python creates a local variable that shadows the global variable of the same name.  That local goes out of scope and is  when  returns; meanwhile,  can never see anything other than the (unmodified) global name.  Note that this namespace decision happens at compile time, not at runtime -- if you were to read the value of  inside  before you assign to it, you'd get an , because Python has already decided that it must be a local variable but it has not had any value associated with it yet.  But by using the '' statement, you tell Python that it should look elsewhere for the name instead of assigning to it locally.(I believe that this behavior originated largely through an optimization of local namespaces -- without this behavior,  Python's VM would need to perform at least three name lookups each time a new name is assigned to inside a function (to ensure that the name didn't already exist at module/builtin level), which would significantly slow down a very common operation.)You may want to explore the notion of . In Python, the  is the natural place for  data:A specific use of global-in-a-module is described here - :Python uses a simple heuristic to decide which scope it should load a variable from, between local and global.  If a variable name appears on the left hand side of an assignment, but is not declared global, it is assumed to be local.  If it does not appear on the left hand side of an assignment, it is assumed to be global.  See how baz, which appears on the left side of an assignment in , is the only  variable.If you want to refer to a global variable in a function, you can use the  keyword to declare which variables are global. You don't have to use it in all cases (as someone here incorrectly claims) - if the name referenced in an expression cannot be found in local scope or scopes in the functions in which this function is defined, it is looked up among global variables.However, if you assign to a new variable not declared as global in the function, it is implicitly declared as local, and it can overshadow any existing global variable with the same name.Also, global variables are useful, contrary to some OOP zealots who claim otherwise - especially for smaller scripts, where OOP is overkill.In addition to already existing answers and to make this more confusing:Source: .With parallel execution, global variables can cause unexpected results if you don't understand what is happening. Here is an example of using a global variable within multiprocessing. We can clearly see that each process works with its own copy of the variable:We can create a global with the following function:Writing a function does not actually run its code. So we call the  function:You can just use it, so long as you don't expect to change which object it points to: For example, and now we can use the global variable:To point the global variable at a different object, you are required to use the global keyword again:Note that after writing this function, the code actually changing it has still not run:So after calling the function:we can see that the global variable has been changed. The  name now points to :Note that \"global\" in Python is not truly global - it's only global to the module level. So it is only available to functions written in the modules in which it is global. Functions remember the module in which they are written, so when they are exported into other modules, they still look in the module in which they were created to find global variables.If you create a local variable with the same name, it will overshadow a global variable:But using that misnamed local variable does not change the global variable:Note that you should avoid using the local variables with the same names as globals unless you know precisely what you are doing and have a very good reason to do so. I have not yet encountered such a reason.You're not actually storing the global in a local variable, just creating a local reference to the same object that your original global reference refers to. Remember that pretty much everything in Python is a name referring to an object, and nothing gets copied in usual operation.If you didn't have to explicitly specify when an identifier was to refer to a predefined global, then you'd presumably have to explicitly specify when an identifier is a new local variable instead (for example, with something like the 'var' command seen in JavaScript). Since local variables are more common than global variables in any serious and non-trivial system, Python's system makes more sense in most cases.You  have a language which attempted to guess, using a global variable if it existed or creating a local variable if it didn't. However, that would be very error-prone. For example, importing another module could inadvertently introduce a global variable by that name, changing the behaviour of your program.As it turns out the answer is always simple.Here is a small sample module. It is is a way to show it in a main definition:Here is a way to show it in a main definition:This simple code works just like that, and it will execute. I hope it helps.You need to reference the global variable in every function you want to use.As follows:What you are saying is to use the method like this:But the better way is to use the global variable like this:Both give the same output.Try this:Following on and as an add on, use a file to contain all global variables all declared locally and then 'import as':.....Writing to explicit elements of a global array does not apparently need the global declaration, though writing to it \"wholesale\" does have that requirement:In case you have a local variable with the same name, you might want to use the ."},
{"link": "https://stackoverflow.com//questions/739654/how-to-make-a-chain-of-function-decorators", "qbody": "How can I make two decorators in Python that would do the following?...which should return:I'm not trying to make  this way in a real application - just trying to understand how decorators and decorator chaining works.Check out  to see how decorators work. Here is what you asked for:If you are not into long explanations, see .To understand decorators, you must first understand that functions are objects in Python. This has important consequences. Let\u2019s see why with a simple example :Keep this in mind. We\u2019ll circle back to it shortly. Another interesting property of Python functions is they can be defined inside another function!Okay, still here? Now the fun part...You\u2019ve seen that functions are objects. Therefore, functions:That means that .There\u2019s more! If you can  a function, you can pass one as a parameter:Well, you just have everything needed to understand decorators. You see, decorators are \u201cwrappers\u201d, which means that  without modifying the function itself.How you\u2019d do it manually:Now, you probably want that every time you call ,  is called instead. That\u2019s easy, just overwrite  with the function returned by :The previous example, using the decorator syntax:Yes, that\u2019s all, it\u2019s that simple.  is just a shortcut to:Decorators are just a pythonic variant of the . There are several classic design patterns embedded in Python to ease development (like iterators).Of course, you can accumulate decorators:Using the Python decorator syntax:The order you set the decorators MATTERS:As a conclusion, you can easily see how to answer the question:You can now just leave happy, or burn your brain a little bit more and see advanced uses of decorators.One nifty thing about Python is that methods and functions are really the same.  The only difference is that methods expect that their first argument is a reference to the current object (). That means you can build a decorator for methods the same way! Just remember to take  into consideration:If you\u2019re making general-purpose decorator--one you\u2019ll apply to any function or method, no matter its arguments--then just use :Great, now what would you say about passing arguments to the decorator itself? This can get somewhat twisted, since a decorator must accept a function as an argument. Therefore, you cannot pass the decorated function\u2019s arguments directly to the decorator.Before rushing to the solution, let\u2019s write a little reminder: It\u2019s exactly the same. \"\" is called. So when you , you are telling Python to call the function 'labelled by the variable \"\"'. This is important! The label you give can point directly to the decorator\u2014. Let\u2019s get evil. \u263aNo surprise here. Let\u2019s do EXACTLY the same thing, but skip all the pesky intermediate variables:Let\u2019s make it :Hey, did you see that? We used a function call with the \"\" syntax! :-)So, back to decorators with arguments. If we can use functions to generate the decorator on the fly, we can pass arguments to that function, right?Here it is: a decorator with arguments. Arguments can be set as variable:As you can see, you can pass arguments to the decorator like any function using this trick. You can even use  if you wish. But remember decorators are called . Just when Python imports the script. You can't dynamically set the arguments afterwards. When you do \"import x\", , so you can't\nchange anything.Okay, as a bonus, I'll give you a snippet to make any decorator accept generically any argument. After all, in order to accept arguments, we created our decorator using another function. We wrapped the decorator.Anything else we saw recently that wrapped function?Oh yes, decorators!Let\u2019s have some fun and write a decorator for the decorators:It can be used as follows:I know, the last time you had this feeling, it was after listening a guy saying: \"before understanding recursion, you must first understand recursion\". But now, don't you feel good about mastering this?The  module was introduced in Python 2.5. It includes the function , which copies the name, module, and docstring of the decorated function to its wrapper. (Fun fact:  is a decorator! \u263a) What can I use decorators for? Seem cool and powerful, but a practical example would be great. Well, there are 1000 possibilities. Classic uses are extending a function behavior from an external lib (you can't modify it), or for debugging (you don't want to modify it because it\u2019s temporary). You can use them to extend several functions in a DRY\u2019s way, like so:Of course the good thing with decorators is that you can use them right away on almost anything without rewriting. DRY, I said:Python itself provides several decorators: , , etc. This really is a large playground.Alternatively, you could write a factory function which return a decorator which wraps the return value of the decorated function in a tag passed to the factory function. For example:This enables you to write:orPersonally I would have written the decorator somewhat differently:which would yield:Don't forget the construction for which decorator syntax is a shorthand:It looks like the other people have already told you how to solve the problem. I hope this will help you understand what decorators are.Decorators are just syntactical sugar.Thisexpands to    And of course you can return lambdas as well from a decorator function:Python decorators add extra functionality to another functionAn italics decorator could be likeNote that a function is defined inside a function.\nWhat it basically does is replace a function with the newly defined one. For example, I have this classNow say, I want both functions to print \"---\" after and before they are done.\nI could add a print \"---\" before and after each print statement.\nBut because I don't like repeating myself, I will make a decoratorSo now I can change my class to For more on decorators, check\nAnother way of doing the same thing:Or, more flexibly:You  make two separate decorators that do what you want as illustrated directly below. Note the use of  in the declaration of the  function which supports the decorated function having multiple arguments (which isn't really necessary for the example  function, but is included for generality).For similar reasons, the  decorator is used to change the meta attributes of the wrapped function to be those of the one being decorated. This makes error messages and embedded function documentation () be those of the decorated function instead of 's.However it would be better in this case, since the two are so similar to one another, for you to instead make a generic one that was actually a \u2014in other words, a decorator that makes other decorators. That way there would be less code repetition ().To make the code more readable, you can assign a more descriptive name to the factory-generated decorators:or even combine them like this:A decorator takes the function definition and creates a new function that executes this function and transforms the result.is eqivarent to:Thisis eqivalent to this\n    def do2(number):\n        return chr(number)65 <=> 'a'To understand the decorator, it is important to notice, that decorator created a new function do which is inner that executes func and transforms the result.You want the following function, when called:To return:To most simply do this, make decorators that return lambdas (anonymous functions) that close over the function (closures) and call it:Now use them as desired:and now:But we seem to have nearly lost the original function. To find it, we'd need to dig into the closure of each lambda, one of which is buried in the other:So if we put documentation on this function, or wanted to be able to decorate functions that take more than one argument, or we just wanted to know what function we were looking at in a debugging session, we need to do a bit more with our wrapper.We have the decorator  from the  module in the standard library! It is unfortunate that there's still some boilerplate, but this is about as simple as we can make it. In Python 3, you also get  and  assigned by default.So now:And now:So we see that  makes the wrapping function do almost everything except tell us exactly what the function takes as arguments. There are other modules that may attempt to tackle the problem, but the solution is not yet in the standard library.To explain decorator in a simpler way:With:When do:You really do:Speaking of the counter example - as given above, the counter will be shared between all functions that use the decorator:That way, your decorator can be reused for different functions (or used to decorate the same function multiple times: ), and the counter variable will remain private to each. Here is a simple example of chaining decorators.  Note the last line - it shows what is going on under the covers.The output looks like:You can also write decorator in ClassResult:  This question has been answered to buggery, granted. But I have an alternate solution for anyone interested in it.It allows you to use one decorator that will then go on to decorate your function/class with decorators that you give as arguments for the decorator.So in your case, you would use:If in needed arguments (like, makeItalic needed 2 and 3 as arguments) then you would:"},
{"link": "https://stackoverflow.com//questions/53513/best-way-to-check-if-a-list-is-empty", "qbody": "For example, if passed the following:How do I check to see if  is empty?Using the implicit booleanness of the empty list is quite pythonic.The pythonic way to do it is from the :I prefer it explicitly:This way it's 100% clear that  is a sequence (list) and we want to test its size. My problem with  is that it gives the false impression that  is a boolean variable. updated to Python 3.Other people seem to be generalizing your question beyond just s, so I thought I'd add a caveat for a different type of sequence that a lot of people might use.  You need to be careful with numpy arrays, because other methods that work fine for s fail for numpy arrays.  I explain why below, but in short, the  is to use .The \"pythonic\" way fails with numpy arrays because numpy tries to cast the array to an array of s, and  tries to evaluate all of those s at once for some kind of aggregate truth value.  But this doesn't make any sense, so you get a :But at least the case above tells you that it failed.  If you happen to have a numpy array with exactly one element, the  statement will \"work\", in the sense that you don't get an error.  However, if that one element happens to be  (or , or , ...), the  statement will incorrectly result in :But clearly  exists and is not empty!  This result is not what you wanted.For example,returns 1, even though the array has zero elements.As explained in the , the correct method in all cases where you know you have a numpy array is to use :If you're not sure whether it might be a , a numpy array, or something else, you should combine this approach with  to make sure the right test is used for each type.  Not very \"pythonic\", but it turns out that python itself isn't pythonic in this sense either...An empty list is itself considered false in true value testing (see ):@Daren ThomasYour duckCollection should implement  or  so the if a: will work without problems. is right:  is the right way to do it.  is right that this is in the PEP 8 style guide. But what none of the answers explain is why it's a good idea to follow the idiom\u2014even if you personally find it's not explicit enough or confusing to Ruby users or whatever.Python code, and the Python community, has very strong idioms. Following those idioms makes your code easier to read for anyone experienced in Python. And when you violate those idioms, that's a strong signal.It's true that  doesn't distinguish empty lists from , or numeric 0, or empty tuples, or empty user-created collection types, or empty user-created not-quite-collection types, or single-element NumPy array acting as scalars with falsey values, etc. And sometimes it's important to be explicit about that. And in that case, you know  you want to be explicit about, so you can test for exactly that. For example,  means \"anything falsey except None\", while  means \"only empty sequences\u2014and anything besides a sequence is an error here\", and so on. Besides testing for exactly what you want to test, this also signals to the reader that this test is important.But when you don't have anything to be explicit about, anything other than  is misleading the reader. You're signaling something as important when it isn't. (You may also be making the code less flexible, or slower, or whatever, but that's all less important.) And if you  mislead the reader like this, then when you  need to make a distinction, it's going to pass unnoticed because you've been \"crying wolf\" all over your code.I have seen the below as preferred, as it will catch the null list as well: for Python lists, strings, dicts, and sets. Python internally keeps track of the number of elements in these containers.JavaScript .No one seems to have addressed questioning your  to test the list in the first place.  Because you provided no additional context, I can imagine that you may not need to do this check in the first place, but are unfamiliar with list processing in Python.I would argue that the  way is to not check at all, but rather to just process the list.  That way it will do the right thing whether empty or full.This has the benefit of handling any contents of , while not requiring a specific check for emptiness.  If  is empty, the dependent block will not execute and the interpreter will fall through to the next line.If you do actually need to check the array for emptiness, the other answers are sufficient.I had written:which was voted -1. I'm not sure if that's because readers objected to the strategy or thought the answer wasn't helpful as presented. I'll pretend it was the latter, since---whatever counts as \"pythonic\"---this is the correct strategy. Unless you've already ruled out, or are prepared to handle cases where  is, for example, , you need a test more restrictive than just . You could use something like this:the first test is in response to @Mike's answer, above. The third line could also be replaced with:if you only want to accept instances of particular types (and their subtypes), or with:You can get away without the explicit type check, but only if the surrounding context already assures you that  is a value of the types you're prepared to handle, or if you're sure that types you're not prepared to handle are going to raise errors (e.g., a  if you call  on a value for which it's undefined) that you're prepared to handle. In general, the \"pythonic\" conventions seem to go this last way. Squeeze it like a duck and let it raise a DuckError if it doesn't know how to quack. You still have to  about what type assumptions you're making, though, and whether the cases you're not prepared to handle properly really are going to error out in the right places. The Numpy arrays are a good example where just blindly relying on  or the boolean typecast may not do precisely what you're expecting.Python is very uniform about the treatment of emptiness. Given the following:You simply check list a with an \"if\" statement to see if it is empty.  From what I have read and been taught, this is the \"Pythonic\" way to see if a list or tuple is empty.From  on truth value testing:All values other than what is listed here are considered As can be seen, empty list  is , so doing what would be done to a boolean value sounds most efficient:Here are a few ways you can check if a list is empty: The pretty simple pythonic way:In Python,  such as lists,tuples,sets,dicts,variables etc are seen as . One could simply treat the list as a predicate (). And  a  value would indicate that it's non-empty. A much explicit way: using the  to find the length and check if it equals to : Or comparing it to an anonymous empty list: Another yet  way to do is using  and :some methods what i use:I prefer the following:Readable and you don't have to worry about calling a function like  to iterate through the variable. Although I'm not entirely sure what the BigO notation of something like this is... but Python's so blazingly fast I doubt it'd matter unless  was gigantic.There is of course alsoYou could also do :It is sometimes good to test for  and for emptiness separately as those are two different states. The code above produces the following output:Although it's worth nothing that  is falsy. So if you don't want to separate test for -ness, you don't have to do that. produces expected\nSee the examplesTry: executes the first statement if  is not an empty sequence, , , or Any empty  to False in Python:This based on  for dictionaries.Check the length of the list, if it's zero, the list is emptyBeing inspired by @dubiousjim's solution, I propose to use an additional general check of whether is it something iterableNote: a string is considered to be iterable. - add  if you want the empty string to be excludedTest:Another way, which is not listed in the previous answers and my not be the \"best way\", to check if a  is empty or not, is by using the special method  which will return an  which represent the size of the current list in memory in bytes.Example:As we can see, the  a  is superior than the  of an .So, we can check if a list is empty or not, for example, like this way:The  of an empty ,  and  are:A Python list is considered False when it is empty and True when it is not empty.\nThe following will work quite nicelyAlso This will also work for any python sequences.You can even try using bool() like thisI love this way for checking list is empty or not. Very handy and useful.The preferred way to check if any list, dictionary, set, string or tuple is empty in Python is to simply use an if statement to check it.you can use try and except as it is cheaper than if else construct"},
{"link": "https://stackoverflow.com//questions/273192/how-can-i-create-a-directory-if-it-does-not-exist", "qbody": "What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:Somehow, I missed  (thanks kanja, Blair, and Douglas). This is what I have now:Is there a flag for \"open\", that makes this happen automatically?I see two answers with good qualities, each with a small flaw, so I will give my take on it:Try , and consider  for the creation.As noted in comments and elsewhere, there's a race condition - if the directory is created between the  and the  calls, the  will fail with an . Unfortunately, blanket-catching  and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.One option would be to trap the  and examine the embedded error code, if one knew what's what (on my OS, 13 seems to indicate that permission is denied, and 17 that the file exists - it's not clear that that's even remotely portable, but is explored in ). Alternatively, there could be a second , but suppose another created the directory after the first check, then removed it before the second one - we could still be fooled. Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.Using try except and the right error code from errno module gets rid of the race condition and is cross-platform:In other words, we try to create the directories, but if they already exist we ignore the error. On the other hand, any other error gets reported. For example, if you create dir 'a' beforehand and remove all permissions from it, you will get an  raised with  (Permission denied, error 13).While a naive solution may first use  followed by , the solution above reverses the order of the two operations. In doing so, it prevents a common race condition having to do with a duplicated attempt at creating the directory, and also disambiguates files from directories.Note that capturing the exception and using  is of limited usefulness because , i.e. , is raised for both files and directories. It is more reliable simply to check if the directory exists.Per an , the following also works.  creates the nested directory, and does nothing if the directory already exists. This also works in Python 3.Per , a severe limitation of the above technique is that it works only once per python process for a given path. In other words, if you use it to create a directory, then delete the directory from inside or outside Python, then use  again to recreate the same directory,  will simply silently use its invalid cached info of having previously created the directory, and will not actually make the directory again. In contrast,  doesn't rely on any such cache. This limitation may be okay for some applications.If using Python 3.2+, an optional  parameter is available, with a default value of . It does not exist in Python 2.x up to 2.7. One can therefore simply specify  in Python 3.2+ to avoid raising an exception if the directory already exists. As such, there is, no need for manual exception handling as with Python 2.7.Credit: This recursively creates the directory and does not raise an exception if the directory already exists.With regard to the directory's , please refer to the documentation if you care about it.I would personally recommend that you use  to test instead of .If you have:And a foolish user input:... You're going to end up with a directory named  when you pass that argument to  if you test with .Check out :  (It makes sure the complete path exists.)  To handle the fact the directory might exist, catch OSError.I have put the following down. It's not totally foolproof though.Now as I say, this is not really foolproof, because we have the possiblity of failing to create the directory, and another process creating it during that period.You give a particular file at a certain path and you pull the directory from the file path. Then after making sure you have the directory, you attempt to open a file for reading. To comment on this code:We want to avoid overwriting the builtin function, . Also,  or perhaps  is probably a better semantic name than  so this would be better written:Your end goal is to open this file, you initially state, for writing, but you're essentially approaching this goal (based on your code) like this, which opens the file for :Why would you make a directory for a file that you expect to be there and be able to read? Just attempt to open the file.If the directory or file isn't there, you'll get an  with an associated error number:  will point to the correct error number regardless of your platform. You can catch it if you want, for example:This is  what you're wanting.In this case, we probably aren't facing any race conditions. So just do as you were, but note that for writing, you need to open with the  mode (or  to append). It's also a Python best practice to use the context manager for opening files.However, say we have several Python processes that attempt to put all their data into the same directory. Then we may have contention over creation of the directory. In that case it's best to wrap the  call in a try-except block.Try the  functionIn Python 3.4 you can also use the :Starting from Python 3.5,  has an  flag:This recursively creates the directory and does not raise an exception if the directory already exists.The direct answer to this is, assuming a simple situation where you don't expect other users or processes to be messing with your directory: if making the directory is subject to race conditions (i.e. if after checking the path exists, something else may have already made it) do this:But perhaps an even better approach is to sidestep the resource contention issue, by using temporary directories via :Here's the essentials from the online doc:The  suggests the use of the . This means that the codeis better than the alternativeThe documentation suggests this exactly because of the race condition discussed in this thread. In addition, as others mention here, there is a performance advantage in querying once instead of twice the OS. Finally, the argument placed forward, potentially, in favour of the second code in some cases --when the developer knows the environment the application is running-- can only be advocated in the special case that the program has set up a private environment for itself (and other instances of the same program).Even in that case, this is a bad practice and can lead to long useless debugging. For example, the fact we set the permissions for a directory should not leave us with the impression permissions are set appropriately for our purposes. A parent directory could be mounted with other permissions. In general, a program should always work correctly and the programmer should not expect one specific environment.I saw  and 's answers and thought of this variation. What do you think?For a one-liner solution, you can use :From the : You can use Note that it will create the ancestor directories as well. It works for Python 2 and 3.In ,  supports setting . The default setting is , which means an  will be raised if the target directory already exists. By setting  to ,  (directory exists) will be ignored and the directory will not be created.In ,  doesn't support setting . You can use the approach in :You can use os.listdir for this:I use ,  is a python3 script that can be used to check if a directory exists, create one if it does not exist, and delete it if it does exist (If desired).\nIt prompts users for input of the directory, and can be easily modified-p does all the work for you, why go into all this try/catch stuff when both linux and windows powershell have mkdir -p for years. The only reason to do the check separately is if you want to print the info to a log or screen.If you consider the following: means a directory (path) exists AND is a directory. So for me this way does what I need. So I can make sure it is folder (not a file) and exists."},
{"link": "https://stackoverflow.com//questions/613183/sort-a-python-dictionary-by-value", "qbody": "I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.I can sort on the keys, but how can I sort based on the values?Note: I have read Stack Overflow question  and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.It is not possible to sort a dict, only to get a representation of a dict that is sorted. Dicts are inherently orderless, but other types, such as lists and tuples, are not. So you need a sorted representation, which will be a list\u2014probably a list of tuples.For instance, will be a list of tuples sorted by the second element in each tuple. .And for those wishing to sort on keys instead of values:Well, it is actually possible to do a \"sort by dictionary values\". Recently I had to do that in a Code Golf (Stack Overflow question ). Abridged, the problem was of the kind: given a text, count how often each word is encountered and display a list of the top words, sorted by decreasing frequency. If you construct a dictionary with the words as keys and the number of occurrences of each word as value, simplified here as:then you can get a list of the words, ordered by frequency of use with  - the sort iterates over the dictionary keys, using the number of word occurrences as a sort key . I am writing this detailed explanation to illustrate what people often mean by \"I can easily sort a dictionary by key, but how do I sort by value\" - and I think the OP was trying to address such an issue. And the solution is to do sort of list of the keys, based on the values, as shown above.You could use:This will sort the dictionary by the values of each entry within the dictionary from smallest to largest.Dicts can't be sorted, but you can build a sorted list from them.A sorted list of dict values:A list of (key, value) pairs, sorted by value:In recent Python 2.7, we have the new  type, which remembers the order in which the items were added.To make a new ordered dictionary from the original, sorting by the values:The OrderedDict behaves like a normal dict:It can often be very handy to use . For example, you have a dictionary of 'name' as keys and 'score' as values and you want to sort on 'score':sorting with lowest score first:sorting with highest score first:Now you can get the name and score of, let's say the second-best player (index=1) very Pythonically like this:Whilst I found the accepted answer useful, I was also surprised that it hasn't been updated to reference  from the standard library  module as a viable, modern alternative - designed to solve exactly this type of problem.The official  documentation offers a very similar example too, but using a lambda for the sort function:Pretty much the same as Hank Gay's answer;In Python 2.7, simply do:copy-paste from : Enjoy ;-)I had the same problem, I solved it like this:(people who answer: \"It is not possible to sort a dict\" did not read the question!!\nIn fact \"I can sort on the keys, but how can I sort based on the values?\" clearly means that he wants a list of the keys sorted according to the value of their values.)Please notice that the order is not well defined (keys with the same value will be in an arbitrary order in the output list)You can use a lambda function to sort things up by value and store them processed inside a variable, in this case  with  the original dictionary.Good news, so the OP's original use case of mapping pairs retrieved from a database with unique string ids as keys and numeric values as values into a builtin python v3.6+ dict, should now respect the insert order.If say the resulting 2 column table expression from a database query like:would be stored in two python tuples k_seq and v_seq (aligned by numerical index and with the same length of course), then:Allow to output later as:yielding in this case (for the new python 3.6+ builtin dict!):in the same ordering per value of v.Where in the python 3.5 install on my machine it currently yields:As proposed in 2012 by Raymond Hettinger (cf. Mail on python-dev with subject ) and now (in 2016) announced in a mail by Victor Stinner to python-dev with subject  due to the fix/implementation of issue 27350  in Python 3.6 we will now be able, to use a built-in dict to maintain insert order! !: Hopefully this will lead to a thin layer OrderedDict implementation as a first step. As @JimFasarakis-Hilliard indicated, some see  use cases for the OrderedDict type also in the future.\nI think the Python community at large will carefully inspect, if this will stand the test of time, and what the next steps will be.Time to rethink our coding habits to not miss the possibilities opened by stable ordering of:The first because it eases dispatch in the implementation of functions and methods in some cases.The second as it encourages to more easily use dict's as intermediate storage in processing pipelines.Raymond Hettinger kindly provided documentation explaining \"\" - from his San Francisco Python Meetup Group presentation 2016-DEC-08.And maybe quite some stackoverflow high decorated question and answer pages will receive variants of this info and many high quality answers will require a per version update too.As @ajcr rightfully notes: \"The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon.\" (from the ) not nit picking,  the citation was cut a bit pessimistic ;-). It continues as \" (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5).\"So as in some human languages (e.g. German), usage shapes the language, and the will now has been declared ... in You can use the . Note, this will work for both numeric and non-numeric values.You can create an \"inverted index\", alsoNow your inverse has the values; each value has a list of applicable keys.If values are numeric you may also use Counter from collectionsThis is the code:Here are the results: Technically, dictionaries aren't sequences, and therefore can't be sorted. You can do something likeassuming performance isn't a huge deal.UPDATE: Thanks to the commenters for pointing out that I made this way too complicated in the beginning.Why not try this approach. Let us define a dictionary called mydict with the following data:If one wanted to sort the dictionary by keys, one could do something like:This should return the following output:On the other hand, if one wanted to sort a dictionary by value (as is asked in the question), one could do the following:The result of this command (sorting the dictionary by value) should return the following:You can use a  which is a dictionary that's permanently sorted by value.If you use ,  or  then you'll iterate in sorted order by value.It's implemented using the  datastructure.This returns the list of key-value pairs in the dictionary, sorted by value from highest to lowest:For the dictionary sorted by key, use the following:The return is a list of tuples because dictionaries themselves can't be sorted.This can be both printed or sent into further computation.Use  from :If your values are integers, and you use Python 2.7 or newer, you can use  instead of . The  method will give you all items, sorted by the value.Iterate through a dict and sort it by its values in descending order:This works in 3.1.x:You can use the sorted function of PythonThus you can use:Visit this link for more information on sorted function: For the sake of completeness, I am posting a solution using . Note, this method will work for both numeric and non-numeric valuesI came up with this one, For Python 3.x:  replacing .Or try with !Here is a solution using zip on .  A few lines down this link (on Dictionary view objects) is:So we can do the following:"},
{"link": "https://stackoverflow.com//questions/38987/how-to-merge-two-python-dictionaries-in-a-single-expression", "qbody": "I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The  method would be what I need, if it returned its result instead of modifying a dict in-place.How can I get that final merged dict in z, not x?(To be extra-clear, the last-one-wins conflict-handling of  is what I'm looking for as well.)Say you have two dicts and you want to merge them into a new dict without altering the original dicts:The desired result is to get a new dictionary () with the values merged, and the second dict's values overwriting those from the first.A new syntax for this, proposed in  and , is And it is indeed a single expression. It is now showing as implemented in the , and it has now made its way into  document.However, since many organizations are still on Python 2, you may wish to do this in a backwards compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:In both approaches,  will come second and its values will replace 's values, thus  will point to  in our final result.If you are not yet on Python 3.5, or need to write backward-compatible code, and you want this in a , the most performant while correct approach is to put it in a function:and then you have a single expression:You can also make a function to merge an undefined number of dicts, from zero to a very large number:This function will work in Python 2 and 3 for all dicts. e.g. given dicts  to :and key value pairs in  will take precedence over dicts  to , and so on.Don't use what you see in the formerly accepted answer:In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict.  because you're adding two  objects together, not two lists - and you would have to explicitly create them as lists, e.g. . This is a waste of resources and computation power. Similarly, taking the union of  in Python 3 ( in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, This example demonstrates what happens when values are unhashable:Here's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:Another hack you should not use:This uses the  constructor, and is very fast and memory efficient (even slightly more-so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic. Here's an example of the usage being .Dicts are intended to take hashable keys (e.g. frozensets or tuples), but From the , Guido van Rossum, the creator of the language, wrote:and It is my understanding (as well as the understanding of the ) that the intended usage for  is for creating dicts for readability purposes, e.g.:instead of Again, it doesn't work for 3 when keys are non-strings. The implicit calling contract is that namespaces take ordinary dicts, while users must only pass keyword arguments that are strings. All other callables enforced it.  broke this consistency in Python 2:This inconsistency was bad given other implementations of Python (Pypy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.These approaches are less performant, but they will provide correct behavior.\nThey will be  performant than  and  or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they  respect the order of precedence (latter dicts have precedence)You can also chain the dicts manually inside a dict comprehension:or in python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced): will chain the iterators over the key-value pairs in the correct order:I'm only going to do the performance analysis of the usages known to behave correctly. The following is done on Ubuntu 14.04In Python 2.7 (system Python):In Python 3.5 (deadsnakes PPA):In your case, what you can do is:This will, as you want it, put the final dict in , and make the value for key  be properly overridden by the second () dict's value:If you use Python 3, it is only a little more complicated.  To create :An alternative:Another, more concise, option:: this has become a popular answer, but it is important to point out that if  has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also, . So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely.This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or , depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit.In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item.In terms of :IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions.In a follow-up answer, you asked about the relative performance of these two alternatives:On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative  is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the  module that comes with Python.Example 1: identical dictionaries mapping 20 consecutive integers to themselves: wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but  always seems to come out ahead.  (If you get inconsistent results for the  test, try passing in  with a number larger than the default 3.)Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa: wins by about a factor of 10.  That's a pretty big win in my book!After comparing those two, I wondered if 's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better:A few quick tests, e.g.lead me to conclude that  is somewhat faster than , but not nearly as fast as .  Definitely not worth all the extra typing.This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the  method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows:A typical result:In other words,  and  seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't....In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses  in lots of places; optimizing its operations is a big deal.You could also write this asas Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand.I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call.In Python 3, you can use  which groups multiple dicts or other mappings together to create a single, updateable view:The best version I could think while not using copy would be:It's faster than  but not as fast as , at least on CPython. This version also works in Python 3 if you change  to , which is automatically done by the 2to3 tool.Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out.Demonstration:Outputs:Thanks rednaw for edits.For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last.Python 3.5 (PEP 448) allows a nicer syntax option:Or even While the question has already been answered several times,\nthis simple solution to the problem has not been listed yet.It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change.Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life  himself!  Someone else suggested half of this, but did not put it in a function.gives:If you think lambdas are evil then read no further.\nAs requested, you can write the fast and memory-efficient solution with one expression:As suggested above, using two lines or writing a function is probably a better way to go.In python3, the  method , but rather a , which acts like a set. In this case you'll need to take the set union since concatenating with  won't work:For python3-like behavior in version 2.7, the  method should work in place of :I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows).A couple more points for python 3. First, note that the  trick won't work in python 3 unless the keys in  are strings.Also, Raymond Hettinger's Chainmap  is pretty elegant, since it can take an arbitrary number of dicts as arguments, but  it looks like it sequentially looks through a list of all the dicts for each lookup:This can slow you down if you have a lot of lookups in your application:So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups.Abuse leading to a one-expression solution for :You said you wanted one expression, so I abused  to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe.You could also do this of course if you don't care about copying it:Even though the answers were good for this  dictionary, none of the methods defined here actually do a deep dictionary merge.Examples follow:One would expect a result of something like this:Instead, we get this:The 'one' entry should have had 'depth_2' and 'extra' as items inside its dictionary if it truly was a merge.Using chain also, does not work:Results in:The deep merge that rcwesick gave also creates the same result.Yes, it will work to merge the sample dictionaries, but none of them are a generic mechanism to merge.  I'll update this later once I write a method that does a true merge.Simple solution using itertools that preserves order (latter dicts have precedence)And it's usage:Drawing on ideas here and elsewhere I've comprehended a function:Usage (tested in python 3):You could use a lambda instead.The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12.\nIn that light, I present the following:Be pythonic. Use a : has bad performance. See Using  a dict comprehension, you maygivesNote the syntax for  in comprehension This can be done with a single dict comprehension:In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short.For Python 2 :For Python 3:It gives output:It's so silly that  returns nothing.\nI just use a simple helper function to solve the problem:Examples:This should solve your problem."},
{"link": "https://stackoverflow.com//questions/394809/does-python-have-a-ternary-conditional-operator", "qbody": "If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?Yes, it was  in version 2.5.\nThe syntax is:First  is evaluated, then either  or  is returned based on the  value of \nIf  evaluates to   is returned, else  is returned. For example:Keep in mind that it's frowned upon by some Pythonistas for several reasons:If you're having trouble remembering the order, then remember that if you read it out loud, you (almost) say what you mean. For example,  is read aloud as .Official documentation:You can index into a tuple: needs to return  or .\nIt might be safer to always implement it as:or you can use the built-in  to assure a  value:For versions prior to 2.5, there's the trick:It can give wrong results when  \n has a false boolean value.\nAlthough it does have the benefit of evaluating expressions left to right, which is clearer in my opinion. if  else From :New since version 2.5.@up:Unfortunately, thesolution doesn't have short-circuit behaviour; thus both falseValue and trueValue are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both trueValue and falseValue could be methods and have side-effects).One solution to this would be(execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties.And so the story goes - choosing between 3 mentioned solutions is a trade-off between having the short-circuit feature, using at least python 2.5 (IMHO not a problem anymore) and not being prone to \"trueValue-evaluates-to-false\" errors.An operator for a conditional expression in Python was added in 2006 as part of . Its form differ from common  operator and it's:which is equivalent to:Here is example:Another syntax which can be used (compatible with versions before 2.5):where operands are .Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages):or explicitly constructed dictionary:Another (less reliable), but simpler method is to use  and  operators:however this won't work if  would be .As possible workaround is to make  and  lists or tuples as in the following:or:If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of , for example:For Python 2.5 and newer there is a specific syntax:In older Pythons a ternary operator is not implemented but it's possible to simulate it.Though, there is a potential problem, which if  evaluates to  and  evaluates to  then  is returned instead of . If you want this behavior the method is OK, otherwise use this:which can be wrapped by:and used this way:It is compatible with all Python versions.You might often findbut this lead to problem when on_true == 0where you would expect for a  normal ternary operator this resultAbsolutely, and it is incredibly easy to understand. Yes. From the :The part of interest is:So, a ternary conditional operation is of the form: will be lazily evaluated (that is, evaluated only if  is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.)Note that every  must be followed with an . People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else:which raises a .\nSo the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use expression2 as a filter - notes that the following is legal Python: works as a filter for the list comprehension, and is  a ternary conditional operator.You may find it somewhat painful to write the following: will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use 's shortcutting behavior:which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax.Here I just try to show some important difference in  between a couple of programming languages.Now you can see the beauty of python language. its highly readable and maintainable.Simulating the python ternary operator.For exampleoutput:More a tip than an answer (don't need to repeat the obvious for the hundreth time), but I sometimes use it as a oneliner shortcut in such constructs:, becomes:Some (many :) may frown upon it as unpythonic (even, ruby-ish :), but I personally find it more natural - i.e. how you'd express it normally, plus a bit more visually appealing in large blocks of code.Yes.There is a ternary option as stated in other answers, but you can also simulate it using \"or\" if you are checking against a boolean or None value:"},
{"link": "https://stackoverflow.com//questions/89228/calling-an-external-command-in-python", "qbody": "How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?Look at the  in the standard library:The advantage of  vs  is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). The  recommend the  module over the alternative os.system():The \"\" section in the  documentation may have some helpful recipes.Official documentation on the  module:Here's a summary of the ways to call external programs and the advantages and disadvantages of each:The  module should probably be what you use.Finally please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it.  if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code:and imagine that the user enters \"my mama didnt love me && rm -rf /\".I typically use:You are free to do what you want with the  data in the pipe.  In fact, you can simply omit those parameters ( and ) and it'll behave like .Some hints on detaching the child process from the calling one (starting the child process in background).Suppose you want to start a long task from a CGI-script, that is the child process should live longer than the CGI-script execution process.The classical example from the subprocess module docs is:The idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example.My target platform was freebsd, but the development was on windows, so I faced the problem on windows first.On windows (win xp), the parent process will not finish until the longtask.py has finished its work. It is not what you want in CGI-script. The problem is not specific to Python, in PHP community the problems are the same.The solution is to pass DETACHED_PROCESS flag to the underlying CreateProcess function in win API.\nIf you happen to have installed pywin32 you can import the flag from the win32process module, otherwise you should define it yourself:/*  @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */On freebsd we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in CGI-script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following:I have not checked the code on other platforms and do not know the reasons of the behaviour on freebsd. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet.I'd recommend using the subprocess module instead of os.system because it does shell escaping for you and is therefore much safer: If you want to return the results of the command, you can use . However, this is deprecated since version 2.6 in favor of the , which other answers have covered well.Note that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant docs on the 'os' and 'sys' modules. There are a bunch of functions (exec* , spawn*) that will do similar things.Check the \"pexpect\" Python library, too.It allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like:I always use  for this things like:But this seem to be a good tool: .Look an example:If what you need is the output from the command you are calling,\nthen you can use  (Python 2.7+).Also note the  parameter.This is how I run my commands. This code has everything you need pretty muchUse :It is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write.If you do not mind external dependencies, use :It is the best  wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by .Another popular library is :However,  dropped Windows support, so it's not as awesome as it used to be. Install by . is the recommended approach  if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See .)Here's some examples from .Run a process:Raise on failed run:Capture output:I recommend trying . It's a wrapper for subprocess, which in turn  the older modules and functions. Envoy is subprocess for humans.Example usage from :Pipe stuff around too:Without the output of the result:With output of the result:There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is  (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them.Hopefully this will help you make a decision on which library to use :)Subprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better.os is used for \"operating system dependent functionality\". It can also be used to call external commands with  and  (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use .sh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times.plumbum is a library for \"script-like\" Python programs. You can call programs like functions as in . Plumbum is useful if you want to run a pipeline without the shell.pexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix.fabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH)envoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the  module. contains wrapper functions for , but it has been removed from Python 3 since  is a better alternative.The edit was based on J.F. Sebastian's comment.There is also ...or for a very simple command: is OK, but kind of dated.  It's also not very secure.  Instead, try .   does not call sh directly and is therefore more secure than .Get more information . has been superseded by the  module. Use subproccess instead.There is another difference here which is not mentioned above. executes the  as a subprocess. In my case, I need to execute file  which needs to communicate with another program . I tried subprocess, execution was successful. However  could not comm w/ .\neverything normal when I run both from the terminal.One more: \n(NOTE: kwrite behaves different from other apps. If you try below with firefox results will not be the same)If you try , program flow freezes until user closes kwrite. To overcome that I tried instead . This time program continued to flow but kwrite became the subprocess of the konsole.Anyone runs the kwrite not being a subprocess (i.e. at the system monitor it must be appear at the leftmost edge of the tree) is convenient if you don't want to test return values. It throws an exception on any error. does not allow you to store results, so if you want to store results in some list or something  works.Use:For the more  functions,  is the documentation.I tend to use  together with  (to handle escaping of quoted strings):Shameless plug, I wrote a library for this :P\nIt's basically a wrapper for popen and shlex for now. It also supports piping commands so you can chain commands easier in Python. So you can do things like:You can use Popen, and then you can check the procedure's status:Check out .To fetch the network id from the openstack neutron:Output of Output of Under Linux, in case you would like to call an external command that will execute independently (will keep running after the python script terminates), you can use a simple queue as  or the  commandAn example with task spooler:Notes about task spooler (): Here are my two cents: In my view, this is the best practice when dealing with external commands...These are the return values from the execute method...This is the execute method...In Windows you can just import the  module and run external commands by calling ,  and  as below:Output:"},
{"link": "https://stackoverflow.com//questions/419163/what-does-if-name-main-do", "qbody": "What does the  do?When the Python interpreter reads a source file, it executes all of the code found in it.  Before executing the code, it will define a few special variables.  For example, if the python interpreter is running that module (the source file) as the main program, it sets the special  variable to have a value .  If this file is being imported from another module,  will be set to the module's name.In the case of your script, let's assume that it's executing as the main function, e.g. you said something likeon the command line.  After setting up the special variables, it will execute the  statement and load those modules.  It will then evaluate the  block, creating a function object and creating a variable called  that points to the function object.  It will then read the  statement and see that  does equal , so it will execute the block shown there.One of the reasons for doing this is that sometimes you write a module (a  file) where it can be executed directly.  Alternatively, it can also be imported and used in another module.  By doing the main check, you can have that code only execute when you want to run the module as a program and not have it execute when someone just wants to import your module and call your functions themselves.See  for some extra details.When your script is run by passing it as a command to the Python interpreter,all of the code that is at indentation level 0 gets executed.  Functions and classes that are defined are, well, defined, but none of their code gets ran.  Unlike other languages, there's no  function that gets run automatically - the  function is implicitly all the code at the top level.In this case, the top-level code is an  block.   is a built-in variable which evaluate to the name of the current module.  However, if a module is being run directly (as in  above), then  instead is set to the string .  Thus, you can test whether your script is being run directly or being imported by something else by testingIf that code is being imported into another module, the various function and class definitions will be imported, but the  code won't get run.  As a basic example, consider the following two scripts:Now, if you invoke the interpreter asThe output will beIf you run  instead:You getThus, when module  gets loaded, its  equals  instead of .The simplest explanation for the  variable (imho) is the following:Create the following files.andRunning them will get you this output:As you can see, when a module is imported, Python sets  in this module to the module's name.As you can see, when a file is executed, Python sets  in this file to .The global variable, , in the module that is the entry point to your program, is . So, code in this  block will only run if that module is the entry point to your program.Why do we need this?Say you're writing a Python script designed to be used as a module:You  test the module by adding this call of the function to the bottom:and running it (on a command prompt) with something like:However, if you want to import the module to another script:On import, the  function would be called, so you'd probably comment out your call of the function at the bottom. And then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome.The  variable points to the namespace wherever the Python interpreter happens to be at the moment. Inside an imported module, it's the name of that module. But inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its .So if you check before executing:With the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script). There's a Pythonic way to improve on this, though. What if we want to run this business process from outside the module? If we put the code we want to exercise as we develop and test in a function like this and then do our check for  immediately after:We now have a final function for the end of our module that will run if we run the module as the primary module. It will allow the module and its functions and classes to be imported into other scripts without running the  function, and will also allow the module (and its functions and classes) to be called when running from a different  module, i.e. That text states: is the part that runs when the script is run from (say) the command line using a command like . is a global variable (in Python, global actually means on the ) that exists in all namespaces. It is typically the module's name (as a  type).As the only special case, however, in whatever Python process you run, as in mycode.py:the otherwise anonymous global namespace is assigned the value of  to its . Thus, including will cause your script's uniquely defined  function to run. Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides:When there are certain statements in our module (), we want to be executed when it 'll be running as main (not imported), in that case we can place those statements (test-cases, print statements) under this if block. As by default (when module running as main, not imported) the  variable is set to , and when it'll be imported the  variable 'll get a different value, most probably the name of the module ().\nThis is helpful in running different variants of a modules together, and seperating their specific input & output statements and also if any test-cases. , use this ' ' block to prevent (certain) code from being run when  the module is imported.Let's look at the answer in a more abstract way:Suppose we have this code in x.py:Blocks A and B are run when we are running \"x.py\".But just block A (and not B) is run when we are running another module, \"y.py\" for example, in which x.y is imported and the code is run from there (like when a function in \"x.py\" is called from y.py).When you run Python interactively the local  variable is assigned a value of . Likewise, when you execute a Python module from the command line, rather than importing it into another module, its  attribute is assigned a value of , rather than the actual name of the module. In this way, modules can look at their own  value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules:Lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers.Take this example:File \"ab.py\":Second file \"xy.py\":When you execute xy.py, you import . The import statement runs the module immediately on import, so ab's operations get executed before the remainder of xy's. Once finished with ab, it continues with xy. The interpreter keeps track of which scripts are running with . When you run a script - no matter what you've named it - the interpreter calls it . That's how it keeps track of which script is the master file, the script that gets returned to after an external call to another script. (The 'home' script, you might say.) Any other script that's called from this 'main' script is assigned its filename as its . Hence, the line  is the interpreter's test to determine if it's running on the script it's looking at (parsing), or if it's temporarily peeking into another script. This gives the programmer flexibility to have the script behave differently if it's called externally.To understand what's happening, focus first on the unindented lines and the order they appear in the scripts. Remember that function - or  - blocks don't do anything by themselves until they're called. What the interpreter might think if mumbled to itself:The bottom two lines mean: \"If this is the 'main' or home script, execute the function called . That's why you'll see a  block up top, which contains the main flow of the script's functionality.Remember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the  function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script.Again, there will be exceptions, but common practice is that  doesn't usually get called externally. So you may be wondering one more thing: if we're not calling , why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run by themselves. They're then later called somewhere else in the body of the script. Which brings me to this:Yes, that's right. These separate functions  be called from an in-line script that's not contained inside a  function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read. But that's a script that probably can't have its functions called externally, because if it did it would start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there could be conflicting variables.I should say as an aside,  contains an answer by @kindall that finally helped me to understand - the Why, not the How. Unfortunately it's been marked as a duplicate of , which I think is a mistake.It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance.It could be written in several ways, another is:I am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about . It is a (great!) convention for invoking a main function in Python files.There are a number of variables that the system (Python interpreter) provides for source files (modules).  You can get their values anytime you want, so, let us focus on the  variable/attribute:When Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.)Before the interpreter executes the source code file though, it defines a few special variables for that file;  is one of those special variables that Python automatically defines for each source code file.If Python is loading this source code file as the main program (i.e. the file you run), then it sets the special  variable for this file to have a value .If this is being imported from another module,  will be set to that module's name.So, in your example in part:means that the code block:will be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of  will not equal to \"\" in that particular instance.Hope this helps out.Put Simply  is a variable defined for each script, that defines whether the script is being run as the main module or it is being run as an imported module. So if we have two scripts;and ;The output from executing script1 is;and the output from executing script2 is;As you can see;  tells us which code is the 'main' module.\nThis is great because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library. Say you write a python script that does something great and you implement a boatload of functions that are useful for other purposes, if I want to use them I can just import your script and use them without executing your program(given that your code only executes within the   context). Whereas in C/C++ you would have to portion out those pieces into a seperate module that then includes the file. Picture the situation below; The arrows are import links. For three modules each trying to include the previous modules code there are six files(nine, counting the implementation files) and five links , this makes it difficult to include other code into a c project unless it is compiled specifically as a library. Now picture it for python;You write a module, If someone wants to utilize your code they just import it and the  variable can help to seperate the executable portion of the program from the library part. is basically Top-level script environment, it specifies the interpreter that ('I have the highest priority to be executed first').' is the name of the scope in which top-level code executes. A module\u2019s  is set equal to '' when read from standard input, a script, or from an interactive prompt.I think it's best to break the answer in depth and in simple words: : Every module in Python has a special attribute called .\nIt is a built-in variable that returns the name of the module. : Like other programming languages, Python too has an execution entry point i.e. main. ''  Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its  is set to . Thus,the value of   attribute is set to   when the module is run as main program. Otherwise the value of   is set to contain the name of the module.Reference: output for the above is  the above statement is gets true and print direct method suppose if they imported this class in other class it doesnt print direct method .because while importing it will  set   "},
{"link": "https://stackoverflow.com//questions/82831/how-do-i-check-whether-a-file-exists-using-python", "qbody": "How do I check whether a file exists, without using the  statement?You can also use if you need to be sure it's a file.Starting with Python 3.4, the  offers an object-oriented approach (backported to  in Python 2.7):To check a directory, do:To check whether a  object exists independently of whether is it a file or directory, use :You can also use  in a  block:You have the  function:This returns  for both files and directories but you can instead use  to test if it's a file specifically. It follows symlinks.Unlike ,  will return  for directories.\nSo depending on if you want only plain files or also directories, you'll use  or . Here is a simple REPL output.Use  with :This is the simplest way to check if a file exists. Just  the file existed when you checked doesn't  that it will be there when you need to open it.Prefer the try statement. It's considered better style and avoids race conditions.Don't take my word for it. There's plenty of support for this theory. Here's a couple: has an object-oriented path module: .  Using this new module, you can check whether a file exists like this:You can (and usually should) still use a  block when opening files:The pathlib module has lots of cool stuff in it: convenient globbing, checking file's owner, easier path joining, etc.  It's worth checking out.  If you're on an older Python (version 2.6 or later), you can still install pathlib with pip:Importing  makes it easier to navigate and perform standard actions with your operating system. For reference also see If you need high-level operations, use .Python 3.4 gives us the  context manager (previously the  context manager), which does semantically exactly the same thing in fewer lines, while also (at least superficially) meeting the original ask to avoid a  statement:Usage:For earlier Pythons, you could roll your own , but without a  will be much more verbose than with. I do believe  that can be applied to prior to Python 3.4 because it uses a context manager instead:Easier with a try:from the :But if you examine the  of this function, you'll see it actually does use a try statement:All it's doing is using the given path to see if it can get stats on it,  catching  and then checking if it's a file if it didn't raise the exception.If you intend to do something with the file, I would suggest directly attempting it with a try-except to avoid a race condition:Available for Unix and Windows is , but to use you must pass flags, and it does not differentiate between files and directories. This is more used to test if the real invoking user has access in an elevated privilege environment:It also suffers from the same race condition problems as . From the :It doesn't seem like there's a meaningful functional difference between try/except and , so you should use which one makes sense.If you want to read a file, if it exists, doBut if you just wanted to rename a file if it exists, and therefore don't need to open it, doIf you want to write to a file, if it doesn't exist, doIf you need file locking, that's a different matter.Testing for files and folders with ,  and Assuming that the \"path\" is a valid path, this table shows what is returned by each function for files and folders:You can also test if a file is a certain type of file using  to get the extension (if you don't already know it)You could try this (safer):The ouput would be:Then, depending on the result, your program can just keep running from there or you can code to stop it if you want.Although I always recommend using  and  statements, here are a few possibilities for you (my personal favourite is using ):I should also mention that there are two ways that you will not be able to verify the existence of a file. Either the issue will be  or . If you catch an , set the  (like my first option), and then type in  so that you can hopefully determine your issue. I hope it helps! :)In 2016 the best way is still using :Or in Python 3 you can use :Additionally, :Being , , and  the flags to test for permissions ().In Python 3.4 the language provides a new module to manage files:SRC: Just to add to the confusion, it seems that the try: open() approach suggested previously doesn't work in Python, as file access isn't exclusive, not even when writing to files, c.f. .Here's a 1 line Python command for the Linux command line environment. I find this VERY HANDY since I'm not such a hot Bash guy.I hope this is helpful.Adding one more slight variation which isn't exactly reflected in the other answers.This will handle the case of the  being  or empty string.Adding a variant based on suggestion from Shahbaz\nAdding a variant based on suggestion from Peter Wood\nYou can write Brian's suggestion without the . is part of Python 3.4. In older releases you can quickly write your own suppress:You can use the \"OS\" library of Python:This is helpful when checking for several files. Or you want to do a set intersection/ subtraction with an existing list.I'm the author of a package that's been around for about 10 years, and it has a function that addresses this question directly. Basically, if you are on a non-Windows system, it uses  to access .  However, if you are on Windows, it replicates  with an efficient filesystem walker.The code itself does not use a  block\u2026 except in determining the operating system and thus steering you to the \"Unix\"-style  or the hand-buillt . Timing tests showed that the  was faster in determining the OS, so I did use one there (but nowhere else).And the doc\u2026The implementation, if you care to look, is here:\nTo check if a file exists, You can use the following open method to check if a file exists + readable:In 2016, this is still arguably the easiest way to check if both a file exists and if it is a file: is actually just a helper method that internally uses  and  underneath. This  is a lower-level method that will provide you with detailed information about files, directories, sockets, buffers, and more.  However, this approach will not lock the file in any way and therefore your code can become vulnerable to \"\" () bugs.So raising exceptions is considered to be an acceptable, and Pythonic, approach for flow control in your program. And one should consider handling missing files with IOErrors, rather than  statements ().If the file is for opening you could use one of the following techniques:"},
{"link": "https://stackoverflow.com//questions/100003/what-is-a-metaclass-in-python", "qbody": "What are metaclasses? What do you use them for?A metaclass is the class of a class. Like a class defines how an instance of the class behaves, a metaclass defines how a class behaves. A class is an instance of a metaclass.While in Python you can use arbitrary callables for metaclasses (like  shows), the more useful approach is actually to make it an actual class itself.  is the usual metaclass in Python. In case you're wondering, yes,  is itself a class, and it is its own type. You won't be able to recreate something like  purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass .A metaclass is most commonly used as a class-factory. Like you create an instance of the class by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal  and  methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry, or even replace the class with something else entirely.When the  statement is executed, Python first executes the body of the  statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the  attribute of the class-to-be (if any) or the  global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.However, metaclasses actually define the  of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods, in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class.  is an example of a method on the  metaclass. You can also define the normal 'magic' methods, like ,  and , to implement or change how the class behaves.Here's an aggregated example of the bits and pieces:Before understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:But classes are more than that in Python. Classes are objects too.Yes, objects. As soon as you use the keyword , Python executes it and creates\nan OBJECT. The instructioncreates in memory an object with the name \"ObjectCreator\". . But still, it's an object, and therefore:e.g.:Since classes are objects, you can create them on the fly, like any object.First, you can create a class in a function using :But it's not so dynamic, since you still have to write the whole class yourself.Since classes are objects, they must be generated by something.When you use the  keyword, Python creates this object automatically. But as\nwith most things in Python, it gives you a way to do it manually.Remember the function ? The good old function that lets you know what \ntype an object is:Well,  has a completely different ability, it can also create classes on the fly.  can take the description of a class as parameters, \nand return a class.(I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backwards \ncompatibility in Python) works this way:e.g.:can be created manually this way:You'll notice that we use \"MyShinyClass\" as the name of the class\nand as the variable to hold the class reference. They can be different,\nbut there is no reason to complicate things. accepts a dictionary to define the attributes of the class. So:Can be translated to:And used as a normal class:And of course, you can inherit from it, so:would be:Eventually you'll want to add methods to your class. Just define a function\nwith the proper signature and assign it as an attribute.And you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.You see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.This is what Python does when you use the keyword , and it does so by using a metaclass.Metaclasses are the 'stuff' that creates classes.You define classes in order to create objects, right?But we learned that Python classes are objects.Well, metaclasses are what create these objects. They are the classes' classes,\nyou can picture them this way:You've seen that  lets you do something like this:It's because the function  is in fact a metaclass.  is the \nmetaclass Python uses to create all classes behind the scenes.Now you wonder why the heck is it written in lowercase, and not ?Well, I guess it's a matter of consistency with , the class that creates\nstrings objects, and  the class that creates integer objects.  is\njust the class that creates class objects.You see that by checking the  attribute. Everything, and I mean everything, is an object in Python. That includes ints, \nstrings, functions and classes. All of them are objects. And all of them have\nbeen created from a class:Now, what is the  of any  ?So, a metaclass is just the stuff that creates class objects.You can call it a 'class factory' if you wish. is the built-in metaclass Python uses, but of course, you can create your\nown metaclass.You can add a  attribute when you write a class:If you do so, Python will use the metaclass to create the class .Careful, it's tricky.You write  first, but the class object  is not created\nin memory yet.Python will look for  in the class definition. If it finds it,\nit will use it to create the object class . If it doesn't, it will use\n to create the class.Read that several times.When you do:Python does the following:Is there a  attribute in ?If yes, create in memory a class object (I said a class object, stay with me here), with the name  by using what is in .If Python can't find , it will look for a  at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes). Then if it can't find any  at all, it will use the 's (the first parent) own metaclass (which might be the default ) to create the class object.Be careful here that the  attribute will not be inherited, the metaclass of the parent () will be. If  used a  attribute that created  with  (and not ), the subclasses will not inherit that behavior.Now the big question is, what can you put in  ?The answer is: something that can create a class.And what can create a class? , or anything that subclasses or uses it.The main purpose of a metaclass is to change the class automatically,\nwhen it's created.You usually do this for APIs, where you want to create classes matching the\ncurrent context.Imagine a stupid example, where you decide that all classes in your module\nshould have their attributes written in uppercase. There are several ways to \ndo this, but one way is to set  at the module level.This way, all classes of this module will be created using this metaclass, \nand we just have to tell the metaclass to turn all attributes to uppercase.Luckily,  can actually be any callable, it doesn't need to be a\nformal class (I know, something with 'class' in its name doesn't need to be \na class, go figure... but it's helpful).So we will start with a simple example, by using a function.Now, let's do exactly the same, but using a real class for a metaclass:But this is not really OOP. We call  directly and we don't override\nor call the parent . Let's do it:You may have noticed the extra argument . There is\nnothing special about it:  always receives the class it's defined in, as first parameter. Just like you have  for ordinary methods which receive the instance as first parameter, or the defining class for class methods.Of course, the names I used here are long for the sake of clarity, but like\nfor , all the arguments have conventional names. So a real production\nmetaclass would look like this:We can make it even cleaner by using , which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):That's it. There is really nothing more about metaclasses.The reason behind the complexity of the code using metaclasses is not because\nof metaclasses, it's because you usually use metaclasses to do twisted stuff\nrelying on introspection, manipulating inheritance, vars such as , etc.Indeed, metaclasses are especially useful to do black magic, and therefore\ncomplicated stuff. But by themselves, they are simple:Since  can accept any callable, why would you use a class\nsince it's obviously more complicated?There are several reasons to do so:Now the big question. Why would you use some obscure error prone feature?Well, usually you don't:The main use case for a metaclass is creating an API. A typical example of this is the Django ORM.It allows you to define something like this:But if you do this:It won't return an  object. It will return an , and can even take it directly from the database.This is possible because  defines  and \nit uses some magic that will turn the  you just defined with simple statements\ninto a complex hook to a database field. Django makes something complex look simple by exposing a simple API\nand using metaclasses, recreating code from this API to do the real job\nbehind the scenes.First, you know that classes are objects that can create instances.Well in fact, classes are themselves instances. Of metaclasses.Everything is an object in Python, and they are all either instances of classes\nor instances of metaclasses.Except for . is actually its own metaclass. This is not something you could\nreproduce in pure Python, and is done by cheating a little bit at the implementation\nlevel.Secondly, metaclasses are complicated. You may not want to use them for \nvery simple class alterations. You can change classes by using two different techniques:99% of the time you need class alteration, you are better off using these.But 99% of the time, you don't need class alteration at all.Metaclasses are the secret sauce that make 'class' work. The default metaclass for a new style object is called 'type'.Metaclasses take 3 args. '', '' and ''Here is where the secret starts. Look for where name, bases and the dict come from in this example class definition.Lets define a metaclass that will demonstrate how '' calls it.And now, an example that actually means something, this will automatically make the variables in the list \"attributes\" set on the class, and set to None.Note that the magic behaviour that 'Initalised' gains by having the metaclass  is not passed onto a subclass of Initalised.Here is an even more concrete example, showing how you can subclass 'type' to make a metaclass that performs an action when the class is created. This is quite tricky:One use for metaclasses is adding new properties and methods to an instance automatically.For example, if you look at , their definition looks a bit confusing. It looks as if you are only defining class properties:However, at runtime the Person objects are filled with all sorts of useful methods. See the  for some amazing metaclassery.Others have explained how metaclasses work and how they fit into the Python type system. Here's an example of what they can be used for. In a testing framework I wrote, I wanted to keep track of the order in which classes were defined, so that I could later instantiate them in this order. I found it easiest to do this using a metaclass.Anything that's a subclass of  then gets a class attribute  that records the order in which the classes were defined.I think the ONLamp introduction to metaclass programming is well written and gives a really good introduction to the topic despite being several years old already.In short: A class is a blueprint for the creation of an instance, a metaclass is a blueprint for the creation of a class. It can be easily seen that in Python classes need to be first-class objects too to enable this behavior.I've never written one myself, but I think one of the nicest uses of metaclasses can be seen in the . The model classes use a metaclass approach to enable a declarative style of writing new models or form classes. While the metaclass is creating the class, all members get the possibility to customize the class itself.The thing that's left to say is: If you don't know what metaclasses are, the probability that you  is 99%.A class is to an instance as a metaclass is to a class. Put another way, a class is an instance of a metaclass.Put a third way, a metaclass is a class's class.Still hopelessly confused? So was I, until I learned the following and demonstrated how one can actually use metaclasses:When you create a class definition, for example, like this,it's the same as functionally calling  with the appropriate arguments and assigning the result to a variable of that name:Note, some things automatically get added to the , i.e., the namespace:The  of the object we created, in both cases, is . Here's the default  of classes:One of the most valuable things we can do by default in writing a Python object is to provide it with a good . When we call  we learn that there's a good test for a  that also requires a test for equality - . The following simple implementation of  and  for class instances of our type class provides us with a demonstration that may improve on the default  of classes:So now when we create an object with this metaclass, the  echoed on the command line provides a much less ugly sight than the default:With a  defined for the class instance, we have a stronger ability to debug our code.If, for example, we want to know in what order a class's methods are created in, we could provide an ordered dict as the namespace of the class. We would do this with  which : And usage:And now we have a record of the order in which these methods (and other class attributes) were created:Note, this example was adapted from the . So what we did was instantiate a metaclass by creating a class. We can also treat the metaclass as we would any other class. It has a method resolution order:And it has approximately the correct  (which we can no longer eval unless we can find a way to represent our functions.):There are (at this point) two key methods in a metaclass: lets you supply a custom mapping (such as an ) to be used as the namespace while the class is being created.  You must return an instance of whatever namespace you choose.  If you don't implement  a normal  is used. is responsible for the actual creation/modification of the final class.A bare-bones, do-nothing-extra metaclass would like:A simple example:Say you want some simple validation code to run on your attributes -- like it must always be an  or a .  Without a metaclass, your class would look something like:As you can see, you have to repeat the name of the attribute twice.  This makes typos possible along with irritating bugs.A simple metaclass can address that problem:This is what the metaclass would look like (not using  since it is not needed):A sample run of:produces::  This example is simple enough it could have also been accomplished with a class decorator, but presumably an actual metaclass would be doing much more.The 'ValidateType' class for reference:A metaclass is a class that tells how (some) other class should be created.This is a case where I saw metaclass as a solution to my problem:\nI had a really complicated problem, that probably could have been solved differently, but I chose to solve it using a metaclass.  Because of the complexity, it is one of the few modules I have written where the comments in the module surpass the amount of code that has been written.  Here it is...If you've done Python programming for more than a few months you'll eventually stumble upon code that looks like this:The latter is possible when you implement the  magic method on the class.The  method is invoked when an instance of a class is used as a callable. But as we've seen from previous answers a class itself is an instance of a metaclass, so when we use the class as a callable (i.e. when we create an instance of it) we're actually calling its metaclass's  method. At this point most Python programmers are a bit confused because they've been told that when creating an instance like this  you're calling it's  method. Some who've dug a bit deeper know that before  there's . Well, today another layer of truth is being revealed, before  there's the metaclass's .Let's study the method call chain from specifically the perspective of creating an instance of a class.This is a metaclass that logs exactly the moment before an instance is created and the moment it's about to return it.This is a class that uses that metaclass And now let's create an instance of The code above doesn't actually do anything other than logging the task and then delegating the actual work to the parent (i.e. keeping the default behavior). So with  being 's parent class, we can imagine that this would be the pseudo implementation of :We can see that the metaclass's  method is the one that's called first. It then delegates creation of the instance to the class's  method and initialization to the instance's . It's also the one that ultimately returns the instance.From the above it stems that the metaclass's  is also given the opportunity to decide whether or not a call to  or  will eventually be made. Over the course of its execution it could actually return an object that hasn't been touched by either of these methods. Take for example this approach to the singleton pattern:Let's observe what happens when repeatedly trying to create an object of type  is actually a  -- a class that creates another classes.\nMost  are the subclasses of . The  receives the  class as its first argument and provide access to class object with details as mentioned below:Notice that the class was not instantiated at any time; the simple act of creating the class triggered execution of the .The  function gets you the type of an object. To use a metaclass:A metaclass is essentially an abstract base class--a concept taught in most intermediate computer programming courses."}
][
{"link": "https://stackoverflow.com//questions/231767/what-does-the-yield-keyword-do-in-python", "qbody": "What is the use of the  keyword in Python? What does it do?For example, I'm trying to understand this code:And this is the caller:What happens when the method  is called?\nIs a list returned? A single element? Is it called again? When will subsequent calls stop?To understand what  does, you must understand what  are. And before generators come .When you create a list, you can read its items one by one. Reading its items one by one is called iteration: is an . When you use a list comprehension, you create a list, and so an iterable:Everything you can use \"\" on is an iterable; , , files...These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.Generators are iterators, but . It's because they do not store all the values in memory, :It is just the same except you used  instead of . BUT, you  perform  a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one. is a keyword that is used like , except the function will return a generator.Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.To master , you must understand that  The function only returns the generator object, this is a bit tricky :-)Then, your code will be run each time the  uses the generator.Now the hard part:The first time the  calls the generator object created from your function, it will run the code in your function from the beginning until it hits , then it'll return the first value of the loop. Then, each other call will run the loop you have written in the function one more time, and return the next value, until there is no value to return.The generator is considered empty once the function runs but does not hit  anymore. It can be because the loop had come to an end, or because you do not satisfy an  anymore.Generator:Caller:This code contains several smart parts:Usually we pass a list to it:But in your code it gets a generator, which is good because:And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples and generators! This is called duck typing and is one of the reason why Python is so cool. But this is another story, for another question...You can stop here, or read a little bit to see an advanced use of a generator:It can be useful for various things like controlling access to a resource.The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?\nChain two generators? Group values in a nested list with a one liner?  without creating another list?Then just .An example? Let's see the possible orders of arrival for a 4 horse race:Iteration is a process implying iterables (implementing the  method) and iterators (implementing the  method).\nIterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.More about it in this article about .When you see a function with  statements, apply this easy trick to understand what will happen:This trick may give you an idea of the logic behind the function, but what actually happens with  is significantly different that what happens in the list based approach. In many cases the yield approach will be a lot more memory efficient and faster too. In other cases this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more...First, the  - when you writePython performs the following two steps:The truth is Python performs the above two steps anytime it wants to  the contents of an object - so it could be a for loop, but it could also be code like  (where  is a Python list).Here  is an  because it implements the iterator protocol. In a user defined class, you can implement the  method to make instances of your class iterable. This method should return an . An iterator is an object with a  method. It is possible to implement both  and  on the same class, and have  return . This will work for simple cases, but not when you want two iterators looping over the same object at the same time.So that's the iterator protocol, many objects implement this protocol:Note that a  loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls . Built-in lists return their items one by one, dictionaries return the  one by one, files return the  one by one, etc. And generators return... well that's where  comes in:Instead of  statements, if you had three  statements in  only the first would get executed, and the function would exit. But  is no ordinary function. When  is called, it  return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the  loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the  it previously returned from, executes the next line of code, in this case a  statement, and returns that as the next item. This happens until the function exits, at which point the generator raises , and the loop exits. So the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing  and  methods to keep the  loop happy. At the other end however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode.Usually you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class  that keeps state in instance members and performs the next logical step in it's  (or  in Python 3) method. Depending on the logic, the code inside the  method may end up looking very complex and be prone to bugs. Here generators provide a clean and easy solution.Think of it this way:An iterator is just a fancy sounding term for an object that has a next() method.  So a yield-ed function ends up being something like this:Original version:This is basically what the python interpreter does with the above code:For more insight as to what's happening behind the scenes, the for loop can be rewritten to this:Does that make more sense or just confuse you more?  :) I should note that this IS an oversimplification for illustrative purposes.  :) Forgot to throw the StopIteration exceptionThe  keyword is reduced to two simple facts:In a nutshell: , and  the generator should incrementally spit out.Let's define a function  that's just like Python's . Calling  RETURNS A GENERATOR:To force the generator to immediately return its pending values, you can pass it into  (just like you could any iterable):The above example can be thought of as merely creating a list which you append to and return:There is one major difference, though; see the last section.An iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so:To get a better feel for generators, you can play around with the  module (be sure to use  rather than  when warranted). For example, you might even use generators to implement infinitely-long lazy lists like . You could implement your own , or alternatively do so with the  keyword in a while-loop.Please note: generators can actually be used for many more things, such as  or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find.This is how the \"Python iteration protocol\" works. That is, what is going on when you do . This is what I describe earlier as a \"lazy, incremental list\".The built-in function  just calls the objects  function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the  function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that...Normally, most people would not care about the following distinctions and probably want to stop reading here.In Python-speak, an  is any object which \"understands the concept of a for-loop\" like a list , and an  is a specific instance of the requested for-loop like . A  is exactly the same as any iterator, except for the way it was written (with function syntax).When you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself.Thus, in the unlikely event that you are failing to do something like this...... then remember that a generator is an ; that is, it is one-time-use. If you want to reuse it, you should call  again. If you need to use the result twice, convert the result to a list and store it in a variable . Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use  if absolutely necessary, since the copyable iterator Python  standards proposal has been deferred. is just like  - it returns whatever you tell it to.  The only difference is that the next time you call the function, execution starts from the last call to the  statement.In the case of your code, the function  is acting like an iterator so that when you extend your list, it adds one element at a time to the new list. calls an iterator until it's exhausted.  In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list.There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this:Then I can use it in other code like this:It really helps simplify some problems, and makes some things easier to work with.  is only legal inside of a function definition, and The idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is  at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield. provides an \neasy way of , defined by the following two methods: \n and  (Python 2) or  (Python 3).  Both of those methods\nmake an object an iterator that you could type-check with the  Abstract Base \nClass from the  module.The generator type is a sub-type of iterator:And if necessary, we can type-check like this:A feature of an  , you can't reuse or reset it:You'll have to make another if you want to use its functionality again (see footnote 2):One can yield data programmatically, for example:The above simple generator is also equivalent to the below - as of Python 3.3 (and not available in Python 2), you can use :However,  also allows for delegation to subgenerators, \nwhich will be explained in the following section on cooperative delegation with sub-coroutines. forms an expression that allows data to be sent into the generator (see footnote 3)Here is an example, take note of the  variable, which will point to the data that is sent to the generator:First, we must queue up the generator with the builtin function, . It will \ncall the appropriate  or  method, depending on the version of\nPython you are using:And now we can send data into the generator. (.) :Now, recall that  is available in Python 3. This allows us to delegate\ncoroutines to a subcoroutine:And now we can delegate functionality to a sub-generator and it can be used\nby a generator just as above:You can read more about the precise semantics of  in The  method raises  at the point the function \nexecution was frozen. This will also be called by  so you \ncan put any cleanup code where you handle the :You can also throw an exception which can be handled in the generator\nor propagated back to the user:I believe I have covered all aspects of the following question:It turns out that  does a lot. I'm sure I could add even more \nthorough examples to this. If you want more or have some constructive criticism, let me know by commenting\nbelow.In :An  is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with , but you can't return a value.In : For those who prefer a minimal working example, meditate on this interactive  session:Yield gives you a generator. As you can see, in the first case foo holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called. In the second case, bar just gives you a generator. A generator is an iterable--which means you can use it in a for loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through. Again, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :)This is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things.There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators.  Here is the PL theory answer:The  statement in python returns a generator.  A generator in python is a function that returns  (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on).Continuations in programming languages theory are a much more fundamental kind of computation, but they are not often used because they are extremely hard to reason about and also very difficult to implement.  But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state are saved the current values of variables and the operations that have yet to be performed, and so on. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out.Continuations, in this more general form, can be implemented in two ways. In the  way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored.In continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows:In this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger)The rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read.Now let's talk about generators in python. Generators are a specific subtype of continuation. Whereas  (i.e., the program's call stack), . Although, this definition is slightly misleading for certain use cases of generators. For instance:This is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e., ). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration.To reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand ).But you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style: Whenever  is called, it tells the function to return a continuation.  When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode  (i.e., not pseudocode but not code) the generator's  method is basically as follows: where  keyword is actually syntactic sugar for the real generator function, basically something like:Remember that this is just pseudocode and the actual implementation of generators in python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the  keyword.It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as  if you're familiar with those.There's an  which explains it reasonably well (for Python) as far as I can see.The key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values - . Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself.An example in plain language. I will provide a correspondence between high-level human concepts to low-level python concepts.I want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following:This is what a generator does (a function that contains a ); it starts executing, pauses whenever it does a , and when asked for a  value it continues from the point it was last. It fits perfectly by design with the iterator protocol of python, which describes how to sequentially request for values.The most famous user of the iterator protocol is the  command in python. So, whenever you do a:it doesn't matter if  is a list, a string, a dictionary or a generator  like described above; the result is the same: you read items off a sequence one by one.Note that ining a function which contains a  keyword is not the only way to create a generator; it's just the easiest way to create one.For more accurate information, read about , the  and  in the Python documentation.While a lot of answers show why you'd use a  to create a generator, there are more uses for .  It's quite easy to make a coroutine, which enables the passing of information between two blocks of code.  I won't repeat any of the fine examples that have already been given about using  to create a generator.To help understand what a  does in the following code, you can use your finger to trace the cycle through any code that has a .  Every time your finger hits the , you have to wait for a  or a  to be entered.  When a  is called, you trace through the code until you hit the \u2026 the code on the right of the  is evaluated and returned to the caller\u2026 then you wait.  When  is called again, you perform another loop through the code.  However, you'll note that in a coroutine,  can also be used with a \u2026 which will send a value from the caller  the yielding function. If a  is given, then  receives the value sent, and spits it out the left hand side\u2026 then the trace through the code progresses until you hit the  again (returning the value at the end, as if  was called).For example:There is another  use and meaning (since python 3.3):moreover  will introduce (since python 3.5):to avoid coroutines confused with regular generator (today  is used in both).I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already.Also, note that  can be used in coroutines as the dual of their use in generator functions.  Although it isn't the same use as your code snippet,  can be used as an expression in a function.  When a caller sends a value to the method using the  method, then the coroutine will execute until the next  statement is encountered.Generators and coroutines are a cool way to set up data-flow type applications.  I thought it would be worthwhile knowing about the other use of the  statement in functions.This was my first aha-moment with yield. is a sugary way to say Same behavior:Different behavior:Yield is : you can only iterate through once. Conceptually the yield-function returns an ordered container of things. But it's revealing that we call any function with a yield in it a . And the term for what it returns is an .Yield is , it puts off computation until you need it. A function with a yield in it  when you call it. The iterator object it returns uses  to maintain the function's internal context. Each time you call  on the iterator (as happens in a for-loop), execution inches forward to the next yield. (Or , which raises  and ends the series.)Yield is . It can do infinite loops:If you need  and the series isn't humongous, just pass the iterator to Brilliant choice of the word  because  apply:...provide the next data in the series....relinquish CPU execution until the iterator advances.Here are some  as if Python did not provide syntactic sugar for them (or in a language without native syntax, like ). Snippets from that link is below. (because )Here is a simple example:output :I am not a Python developer, but it looks to me  holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work.Seems to me an interesting and nice ability :D From a programming viewpoint, the iterators are implemented as  To implement iterators/generators/thread pools for concurrent execution/etc as thunks (also called anonymous functions), one uses messages sent to a closure object, which has a dispatcher, and the dispatcher answers to \"messages\".\"\" is a message sent to a closure, created by \"\" call.There are lots of ways to implement this computation.  I used mutation but it is easy to do it without mutation, by returning the current value and the next yielder.Here is a demonstration which uses the structure of R6RS but the semantics is absolutely identical as in python, it's the same model of computation, only a change in syntax is required to rewrite it in python.Here is a mental image of what  does.I like to think of a thread as having a stack (even when it's not implemented that way).When a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again.With a  function, when its code begins to run (i.e. after the function is called, returning a generator object, whose  method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the  statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular  statement).So it's a kind of a frozen function that the generator is hanging onto.When  is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage.Compare the following examples:When we call the second function, it behaves very differently to the first. The  statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with.Calling  doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the  prefix for readability.)The  and  fields are where the frozen state is stored. Exploring them with , we can confirm that our mental model above is credible.Like every answer suggests,  is used for creating a sequence generator. It's used for generating some sequence dynamically. Eg. While reading a file line by line on a network, you can use the  function as follows:You can use it in your code as follows :The execution control will be transferred from getNextLines() to the for loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time.Thus in short, a function with the following codewill print I hope this helps you. is like a return element for a function. The difference is, that the  element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling .A  in a function will return a single value.If you want  use .More importantly,  is a  i.eIt will run the code in your function from the beginning until it hits . Then, it\u2019ll return the first value of the loop. \nThen, every other call will run the loop you have written in the function one more time, returning the next value until there is no value to return.(My below answer only speaks from the perspective of using Python generator, not the , which involves some tricks of stack and heap manipulation.)When  is used instead of a  in a python function, that function is turned into something special called . That function will return an object of  type.  Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function  as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a  exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about  but this  from the  is the most digestable.(Now I want to talk about the rationale behind , and the  based on my own understanding. I hope this can help you grasp the  of iterator and generator. Such concept shows up in other languages as well such as C#.)As I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this  approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand. . There are 2 approaches to wrap such metadata.Either way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you.The  keyword simply collects returning results. Think of  like Most questions regarding the  statement and the semantics/functionality that it introduces are present in . The collective knowledge from all previous answers is amazing but I'll add an answer that references the official presentation.So first of, the form of the  statement:consist of the   along with an optional . Syntactically yield can only appear inside a function definition and its presence alone is responsible for tranforming a function into a generator object:So after you define your generator you're left with a generator function that is waiting to be called: So parameters are bound in the same way as they do for all callable but the body of the generator object is not executed, what happens is:We get back an object that comforms to the  this means that the  object implements  and  and as such can be used in  loops like any object that supports iteration. The key difference that  makes is here, specifically:So everything  the  is executed and then execution stops, at that point what happens is: So in the case of a  loop:  the value of  is going to be equal to  as previously stated.But \"frozen\" you may ask, what does that mean? This is further explained as: So state is retained when  is encountered thereby allowing consequent calls to  to continue smoothly. When a  call is made the generator is going to execute everything until it finds another  statement. That cicle is repeated until no  (i.e control flows off the end of the generator) or a  is found in which case a  exception is raised signalling that the generator has been exhausted.Many people use  rather than  but in some cases  can be more efficient and easier to work with.Here is an example which  is definitely best for:Both functions do the same thing but  uses 3 lines instead of 5 and has one less variable to worry about.As you can see both functions do the same thing, the only difference is  gives a list and  gives a generatorA real life example would be something like reading a file line by line or if you just want to make a generatorAt a glance, the yield statement is used to define generators, replacing the return of a function to provide a result to its caller without destroying local variables. Unlike a function, where on each call it starts with new set of variables, a generator will resume the execution where it was left off.About Python Generators\nSince the yield keyword is only used with generators, it makes sense to recall the concept of generators first.The idea of generators is to calculate a series of results one-by-one on demand (on the fly). In the simplest case, a generator can be used as a list, where each element is calculated lazily. Let's compare a list and a generator that do the same thing - return powers of two:Iterating over the list and the generator looks completely the same. However, although the generator is iterable, it is not a collection and thus has no length. Collections (lists, tuples, sets, etc) keep all values in memory and we can access them whenever needed. A generator calculates the values on the fly and forgets them, so it does not have any overview about the own result set.Generators are especially useful for memory-intensive tasks, where there is no need to keep all of the elements of a memory-heavy list accessible at the same time. Calculating a series of values one-by-one can also be useful in situations where the complete result is never needed, yielding intermediate results to the caller until some requirement is satisfied and further processing stops.Using the Python \"yield\" keyword\nA good example is a search task, where typically there is no need to wait for all results to be found. Performing a file-system search, a user would be happier to receive results on-the-fly, rather the wait for a search engine to go through every single file and only afterwards return results. Are there any people who really navigate through all Google search results until the last page?Since a search functionality cannot be created using list-comprehensions, we are going to define a generator using a function with the yield statement/keyword. The yield instruction should be put into a place where the generator returns an intermediate result to the caller and sleeps until the next invocation occurs. So far the most practical aspects of Python generators have been described. For more detailed info and an interesting discussion take a look at the Python Enhancement Proposal 255, which discusses the feature of the language in detail.Happy Pythoning!\nIn summary, the  statement transforms your function into a factory that produces a special object called a  which wraps around the body of your original function. When the  is iterated, it executes your function  until it reaches the next  then suspends execution and evaluates to the value passed to . It repeats this process on each iteration until the path of execution exits the function. For instance;simply outputs ;The power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculationsSay you wanted to create a your own  function that produces an iterable range of numbers, you could do it like so,and use it like this;but this is ineffecient becauseLuckily Guido and his team were generous enough to develop generators so we could just do this;Now upon each iteration a function on the generator called  executes the function until it either reaches a 'yield' statement in which it stops and  'yields' the value or reaches the end of the function. In this case on the first call,  executes up to the yield statement and yield 'n', on the next call it will execute the  increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function. Yet another TL;DR:  returns the next element of the list:  will compute the next element on the fly (execute code)You can see the yield/generator as a way to manually run the  from outside (like continue loop 1 step), by calling next, however complex the flow.NOTE: the generator is  a normal function, it remembers previous state like local variables (stack), see other answers or articles for detailed explanation, the generator can only be .\nYou could do without  but it would not be as nice, so it can be considered 'very nice' language sugar."},
{"link": "https://stackoverflow.com//questions/423379/using-global-variables-in-a-function-other-than-the-one-that-created-them", "qbody": "If I create a global variable in one function, how can I use that variable in another function?\nDo I need to store the global variable in a local variable of the function which needs its access?You can use a global variable in other functions by declaring it as  in each function that assigns to it:I imagine the reason for it is that, since global variables are so dangerous, Python wants to make sure that you really know that's what you're playing with by explicitly requiring the  keyword.See other answers if you want to share a global variable across modules.If I'm understanding your situation correctly, what you're seeing is the result of how Python handles local (function) and global (module) namespaces.Say you've got a module like this:You might expecting this to print 42, but instead it prints 5.  As has already been mentioned, if you add a '' declaration to , then  will print 42.What's going on here is that Python assumes that any name that is , anywhere within a function, is local to that function unless explicitly told otherwise.  If it is only  from a name, and the name doesn't exist locally, it will try to look up the name in any containing scopes (e.g. the module's global scope).When you assign 42 to the name , therefore, Python creates a local variable that shadows the global variable of the same name.  That local goes out of scope and is  when  returns; meanwhile,  can never see anything other than the (unmodified) global name.  Note that this namespace decision happens at compile time, not at runtime -- if you were to read the value of  inside  before you assign to it, you'd get an , because Python has already decided that it must be a local variable but it has not had any value associated with it yet.  But by using the '' statement, you tell Python that it should look elsewhere for the name instead of assigning to it locally.(I believe that this behavior originated largely through an optimization of local namespaces -- without this behavior,  Python's VM would need to perform at least three name lookups each time a new name is assigned to inside a function (to ensure that the name didn't already exist at module/builtin level), which would significantly slow down a very common operation.)You may want to explore the notion of . In Python, the  is the natural place for  data:A specific use of global-in-a-module is described here - :Python uses a simple heuristic to decide which scope it should load a variable from, between local and global.  If a variable name appears on the left hand side of an assignment, but is not declared global, it is assumed to be local.  If it does not appear on the left hand side of an assignment, it is assumed to be global.  See how baz, which appears on the left side of an assignment in , is the only  variable.If you want to refer to a global variable in a function, you can use the  keyword to declare which variables are global. You don't have to use it in all cases (as someone here incorrectly claims) - if the name referenced in an expression cannot be found in local scope or scopes in the functions in which this function is defined, it is looked up among global variables.However, if you assign to a new variable not declared as global in the function, it is implicitly declared as local, and it can overshadow any existing global variable with the same name.Also, global variables are useful, contrary to some OOP zealots who claim otherwise - especially for smaller scripts, where OOP is overkill.In addition to already existing answers and to make this more confusing:Source: .With parallel execution, global variables can cause unexpected results if you don't understand what is happening. Here is an example of using a global variable within multiprocessing. We can clearly see that each process works with its own copy of the variable:We can create a global with the following function:Writing a function does not actually run its code. So we call the  function:You can just use it, so long as you don't expect to change which object it points to: For example, and now we can use the global variable:To point the global variable at a different object, you are required to use the global keyword again:Note that after writing this function, the code actually changing it has still not run:So after calling the function:we can see that the global variable has been changed. The  name now points to :Note that \"global\" in Python is not truly global - it's only global to the module level. So it is only available to functions written in the modules in which it is global. Functions remember the module in which they are written, so when they are exported into other modules, they still look in the module in which they were created to find global variables.If you create a local variable with the same name, it will overshadow a global variable:But using that misnamed local variable does not change the global variable:Note that you should avoid using the local variables with the same names as globals unless you know precisely what you are doing and have a very good reason to do so. I have not yet encountered such a reason.You're not actually storing the global in a local variable, just creating a local reference to the same object that your original global reference refers to. Remember that pretty much everything in Python is a name referring to an object, and nothing gets copied in usual operation.If you didn't have to explicitly specify when an identifier was to refer to a predefined global, then you'd presumably have to explicitly specify when an identifier is a new local variable instead (for example, with something like the 'var' command seen in JavaScript). Since local variables are more common than global variables in any serious and non-trivial system, Python's system makes more sense in most cases.You  have a language which attempted to guess, using a global variable if it existed or creating a local variable if it didn't. However, that would be very error-prone. For example, importing another module could inadvertently introduce a global variable by that name, changing the behaviour of your program.As it turns out the answer is always simple.Here is a small sample module. It is is a way to show it in a main definition:Here is a way to show it in a main definition:This simple code works just like that, and it will execute. I hope it helps.You need to reference the global variable in every function you want to use.As follows:What you are saying is to use the method like this:But the better way is to use the global variable like this:Both give the same output.Try this:Following on and as an add on, use a file to contain all global variables all declared locally and then 'import as':.....Writing to explicit elements of a global array does not apparently need the global declaration, though writing to it \"wholesale\" does have that requirement:In case you have a local variable with the same name, you might want to use the ."},
{"link": "https://stackoverflow.com//questions/739654/how-to-make-a-chain-of-function-decorators", "qbody": "How can I make two decorators in Python that would do the following?...which should return:I'm not trying to make  this way in a real application - just trying to understand how decorators and decorator chaining works.Check out  to see how decorators work. Here is what you asked for:If you are not into long explanations, see .To understand decorators, you must first understand that functions are objects in Python. This has important consequences. Let\u2019s see why with a simple example :Keep this in mind. We\u2019ll circle back to it shortly. Another interesting property of Python functions is they can be defined inside another function!Okay, still here? Now the fun part...You\u2019ve seen that functions are objects. Therefore, functions:That means that .There\u2019s more! If you can  a function, you can pass one as a parameter:Well, you just have everything needed to understand decorators. You see, decorators are \u201cwrappers\u201d, which means that  without modifying the function itself.How you\u2019d do it manually:Now, you probably want that every time you call ,  is called instead. That\u2019s easy, just overwrite  with the function returned by :The previous example, using the decorator syntax:Yes, that\u2019s all, it\u2019s that simple.  is just a shortcut to:Decorators are just a pythonic variant of the . There are several classic design patterns embedded in Python to ease development (like iterators).Of course, you can accumulate decorators:Using the Python decorator syntax:The order you set the decorators MATTERS:As a conclusion, you can easily see how to answer the question:You can now just leave happy, or burn your brain a little bit more and see advanced uses of decorators.One nifty thing about Python is that methods and functions are really the same.  The only difference is that methods expect that their first argument is a reference to the current object (). That means you can build a decorator for methods the same way! Just remember to take  into consideration:If you\u2019re making general-purpose decorator--one you\u2019ll apply to any function or method, no matter its arguments--then just use :Great, now what would you say about passing arguments to the decorator itself? This can get somewhat twisted, since a decorator must accept a function as an argument. Therefore, you cannot pass the decorated function\u2019s arguments directly to the decorator.Before rushing to the solution, let\u2019s write a little reminder: It\u2019s exactly the same. \"\" is called. So when you , you are telling Python to call the function 'labelled by the variable \"\"'. This is important! The label you give can point directly to the decorator\u2014. Let\u2019s get evil. \u263aNo surprise here. Let\u2019s do EXACTLY the same thing, but skip all the pesky intermediate variables:Let\u2019s make it :Hey, did you see that? We used a function call with the \"\" syntax! :-)So, back to decorators with arguments. If we can use functions to generate the decorator on the fly, we can pass arguments to that function, right?Here it is: a decorator with arguments. Arguments can be set as variable:As you can see, you can pass arguments to the decorator like any function using this trick. You can even use  if you wish. But remember decorators are called . Just when Python imports the script. You can't dynamically set the arguments afterwards. When you do \"import x\", , so you can't\nchange anything.Okay, as a bonus, I'll give you a snippet to make any decorator accept generically any argument. After all, in order to accept arguments, we created our decorator using another function. We wrapped the decorator.Anything else we saw recently that wrapped function?Oh yes, decorators!Let\u2019s have some fun and write a decorator for the decorators:It can be used as follows:I know, the last time you had this feeling, it was after listening a guy saying: \"before understanding recursion, you must first understand recursion\". But now, don't you feel good about mastering this?The  module was introduced in Python 2.5. It includes the function , which copies the name, module, and docstring of the decorated function to its wrapper. (Fun fact:  is a decorator! \u263a) What can I use decorators for? Seem cool and powerful, but a practical example would be great. Well, there are 1000 possibilities. Classic uses are extending a function behavior from an external lib (you can't modify it), or for debugging (you don't want to modify it because it\u2019s temporary). You can use them to extend several functions in a DRY\u2019s way, like so:Of course the good thing with decorators is that you can use them right away on almost anything without rewriting. DRY, I said:Python itself provides several decorators: , , etc. This really is a large playground.Alternatively, you could write a factory function which return a decorator which wraps the return value of the decorated function in a tag passed to the factory function. For example:This enables you to write:orPersonally I would have written the decorator somewhat differently:which would yield:Don't forget the construction for which decorator syntax is a shorthand:It looks like the other people have already told you how to solve the problem. I hope this will help you understand what decorators are.Decorators are just syntactical sugar.Thisexpands to    And of course you can return lambdas as well from a decorator function:Python decorators add extra functionality to another functionAn italics decorator could be likeNote that a function is defined inside a function.\nWhat it basically does is replace a function with the newly defined one. For example, I have this classNow say, I want both functions to print \"---\" after and before they are done.\nI could add a print \"---\" before and after each print statement.\nBut because I don't like repeating myself, I will make a decoratorSo now I can change my class to For more on decorators, check\nAnother way of doing the same thing:Or, more flexibly:You  make two separate decorators that do what you want as illustrated directly below. Note the use of  in the declaration of the  function which supports the decorated function having multiple arguments (which isn't really necessary for the example  function, but is included for generality).For similar reasons, the  decorator is used to change the meta attributes of the wrapped function to be those of the one being decorated. This makes error messages and embedded function documentation () be those of the decorated function instead of 's.However it would be better in this case, since the two are so similar to one another, for you to instead make a generic one that was actually a \u2014in other words, a decorator that makes other decorators. That way there would be less code repetition ().To make the code more readable, you can assign a more descriptive name to the factory-generated decorators:or even combine them like this:A decorator takes the function definition and creates a new function that executes this function and transforms the result.is eqivarent to:Thisis eqivalent to this\n    def do2(number):\n        return chr(number)65 <=> 'a'To understand the decorator, it is important to notice, that decorator created a new function do which is inner that executes func and transforms the result.You want the following function, when called:To return:To most simply do this, make decorators that return lambdas (anonymous functions) that close over the function (closures) and call it:Now use them as desired:and now:But we seem to have nearly lost the original function. To find it, we'd need to dig into the closure of each lambda, one of which is buried in the other:So if we put documentation on this function, or wanted to be able to decorate functions that take more than one argument, or we just wanted to know what function we were looking at in a debugging session, we need to do a bit more with our wrapper.We have the decorator  from the  module in the standard library! It is unfortunate that there's still some boilerplate, but this is about as simple as we can make it. In Python 3, you also get  and  assigned by default.So now:And now:So we see that  makes the wrapping function do almost everything except tell us exactly what the function takes as arguments. There are other modules that may attempt to tackle the problem, but the solution is not yet in the standard library.To explain decorator in a simpler way:With:When do:You really do:Speaking of the counter example - as given above, the counter will be shared between all functions that use the decorator:That way, your decorator can be reused for different functions (or used to decorate the same function multiple times: ), and the counter variable will remain private to each. Here is a simple example of chaining decorators.  Note the last line - it shows what is going on under the covers.The output looks like:You can also write decorator in ClassResult:  This question has been answered to buggery, granted. But I have an alternate solution for anyone interested in it.It allows you to use one decorator that will then go on to decorate your function/class with decorators that you give as arguments for the decorator.So in your case, you would use:If in needed arguments (like, makeItalic needed 2 and 3 as arguments) then you would:"},
{"link": "https://stackoverflow.com//questions/273192/how-can-i-create-a-directory-if-it-does-not-exist", "qbody": "What is the most elegant way to check if the directory a file is going to be written to exists, and if not, create the directory using Python? Here is what I tried:Somehow, I missed  (thanks kanja, Blair, and Douglas). This is what I have now:Is there a flag for \"open\", that makes this happen automatically?I see two answers with good qualities, each with a small flaw, so I will give my take on it:Try , and consider  for the creation.As noted in comments and elsewhere, there's a race condition - if the directory is created between the  and the  calls, the  will fail with an . Unfortunately, blanket-catching  and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.One option would be to trap the  and examine the embedded error code, if one knew what's what (on my OS, 13 seems to indicate that permission is denied, and 17 that the file exists - it's not clear that that's even remotely portable, but is explored in ). Alternatively, there could be a second , but suppose another created the directory after the first check, then removed it before the second one - we could still be fooled. Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.Using try except and the right error code from errno module gets rid of the race condition and is cross-platform:In other words, we try to create the directories, but if they already exist we ignore the error. On the other hand, any other error gets reported. For example, if you create dir 'a' beforehand and remove all permissions from it, you will get an  raised with  (Permission denied, error 13).While a naive solution may first use  followed by , the solution above reverses the order of the two operations. In doing so, it prevents a common race condition having to do with a duplicated attempt at creating the directory, and also disambiguates files from directories.Note that capturing the exception and using  is of limited usefulness because , i.e. , is raised for both files and directories. It is more reliable simply to check if the directory exists.Per an , the following also works.  creates the nested directory, and does nothing if the directory already exists. This also works in Python 3.Per , a severe limitation of the above technique is that it works only once per python process for a given path. In other words, if you use it to create a directory, then delete the directory from inside or outside Python, then use  again to recreate the same directory,  will simply silently use its invalid cached info of having previously created the directory, and will not actually make the directory again. In contrast,  doesn't rely on any such cache. This limitation may be okay for some applications.If using Python 3.2+, an optional  parameter is available, with a default value of . It does not exist in Python 2.x up to 2.7. One can therefore simply specify  in Python 3.2+ to avoid raising an exception if the directory already exists. As such, there is, no need for manual exception handling as with Python 2.7.Credit: This recursively creates the directory and does not raise an exception if the directory already exists.With regard to the directory's , please refer to the documentation if you care about it.I would personally recommend that you use  to test instead of .If you have:And a foolish user input:... You're going to end up with a directory named  when you pass that argument to  if you test with .Check out :  (It makes sure the complete path exists.)  To handle the fact the directory might exist, catch OSError.I have put the following down. It's not totally foolproof though.Now as I say, this is not really foolproof, because we have the possiblity of failing to create the directory, and another process creating it during that period.You give a particular file at a certain path and you pull the directory from the file path. Then after making sure you have the directory, you attempt to open a file for reading. To comment on this code:We want to avoid overwriting the builtin function, . Also,  or perhaps  is probably a better semantic name than  so this would be better written:Your end goal is to open this file, you initially state, for writing, but you're essentially approaching this goal (based on your code) like this, which opens the file for :Why would you make a directory for a file that you expect to be there and be able to read? Just attempt to open the file.If the directory or file isn't there, you'll get an  with an associated error number:  will point to the correct error number regardless of your platform. You can catch it if you want, for example:This is  what you're wanting.In this case, we probably aren't facing any race conditions. So just do as you were, but note that for writing, you need to open with the  mode (or  to append). It's also a Python best practice to use the context manager for opening files.However, say we have several Python processes that attempt to put all their data into the same directory. Then we may have contention over creation of the directory. In that case it's best to wrap the  call in a try-except block.Try the  functionIn Python 3.4 you can also use the :Starting from Python 3.5,  has an  flag:This recursively creates the directory and does not raise an exception if the directory already exists.The direct answer to this is, assuming a simple situation where you don't expect other users or processes to be messing with your directory: if making the directory is subject to race conditions (i.e. if after checking the path exists, something else may have already made it) do this:But perhaps an even better approach is to sidestep the resource contention issue, by using temporary directories via :Here's the essentials from the online doc:The  suggests the use of the . This means that the codeis better than the alternativeThe documentation suggests this exactly because of the race condition discussed in this thread. In addition, as others mention here, there is a performance advantage in querying once instead of twice the OS. Finally, the argument placed forward, potentially, in favour of the second code in some cases --when the developer knows the environment the application is running-- can only be advocated in the special case that the program has set up a private environment for itself (and other instances of the same program).Even in that case, this is a bad practice and can lead to long useless debugging. For example, the fact we set the permissions for a directory should not leave us with the impression permissions are set appropriately for our purposes. A parent directory could be mounted with other permissions. In general, a program should always work correctly and the programmer should not expect one specific environment.I saw  and 's answers and thought of this variation. What do you think?For a one-liner solution, you can use :From the : You can use Note that it will create the ancestor directories as well. It works for Python 2 and 3.In ,  supports setting . The default setting is , which means an  will be raised if the target directory already exists. By setting  to ,  (directory exists) will be ignored and the directory will not be created.In ,  doesn't support setting . You can use the approach in :You can use os.listdir for this:I use ,  is a python3 script that can be used to check if a directory exists, create one if it does not exist, and delete it if it does exist (If desired).\nIt prompts users for input of the directory, and can be easily modified-p does all the work for you, why go into all this try/catch stuff when both linux and windows powershell have mkdir -p for years. The only reason to do the check separately is if you want to print the info to a log or screen.If you consider the following: means a directory (path) exists AND is a directory. So for me this way does what I need. So I can make sure it is folder (not a file) and exists."},
{"link": "https://stackoverflow.com//questions/613183/sort-a-python-dictionary-by-value", "qbody": "I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.I can sort on the keys, but how can I sort based on the values?Note: I have read Stack Overflow question  and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.It is not possible to sort a dict, only to get a representation of a dict that is sorted. Dicts are inherently orderless, but other types, such as lists and tuples, are not. So you need a sorted representation, which will be a list\u2014probably a list of tuples.For instance, will be a list of tuples sorted by the second element in each tuple. .And for those wishing to sort on keys instead of values:Well, it is actually possible to do a \"sort by dictionary values\". Recently I had to do that in a Code Golf (Stack Overflow question ). Abridged, the problem was of the kind: given a text, count how often each word is encountered and display a list of the top words, sorted by decreasing frequency. If you construct a dictionary with the words as keys and the number of occurrences of each word as value, simplified here as:then you can get a list of the words, ordered by frequency of use with  - the sort iterates over the dictionary keys, using the number of word occurrences as a sort key . I am writing this detailed explanation to illustrate what people often mean by \"I can easily sort a dictionary by key, but how do I sort by value\" - and I think the OP was trying to address such an issue. And the solution is to do sort of list of the keys, based on the values, as shown above.You could use:This will sort the dictionary by the values of each entry within the dictionary from smallest to largest.Dicts can't be sorted, but you can build a sorted list from them.A sorted list of dict values:A list of (key, value) pairs, sorted by value:In recent Python 2.7, we have the new  type, which remembers the order in which the items were added.To make a new ordered dictionary from the original, sorting by the values:The OrderedDict behaves like a normal dict:It can often be very handy to use . For example, you have a dictionary of 'name' as keys and 'score' as values and you want to sort on 'score':sorting with lowest score first:sorting with highest score first:Now you can get the name and score of, let's say the second-best player (index=1) very Pythonically like this:Whilst I found the accepted answer useful, I was also surprised that it hasn't been updated to reference  from the standard library  module as a viable, modern alternative - designed to solve exactly this type of problem.The official  documentation offers a very similar example too, but using a lambda for the sort function:Pretty much the same as Hank Gay's answer;In Python 2.7, simply do:copy-paste from : Enjoy ;-)I had the same problem, I solved it like this:(people who answer: \"It is not possible to sort a dict\" did not read the question!!\nIn fact \"I can sort on the keys, but how can I sort based on the values?\" clearly means that he wants a list of the keys sorted according to the value of their values.)Please notice that the order is not well defined (keys with the same value will be in an arbitrary order in the output list)You can use a lambda function to sort things up by value and store them processed inside a variable, in this case  with  the original dictionary.Good news, so the OP's original use case of mapping pairs retrieved from a database with unique string ids as keys and numeric values as values into a builtin python v3.6+ dict, should now respect the insert order.If say the resulting 2 column table expression from a database query like:would be stored in two python tuples k_seq and v_seq (aligned by numerical index and with the same length of course), then:Allow to output later as:yielding in this case (for the new python 3.6+ builtin dict!):in the same ordering per value of v.Where in the python 3.5 install on my machine it currently yields:As proposed in 2012 by Raymond Hettinger (cf. Mail on python-dev with subject ) and now (in 2016) announced in a mail by Victor Stinner to python-dev with subject  due to the fix/implementation of issue 27350  in Python 3.6 we will now be able, to use a built-in dict to maintain insert order! !: Hopefully this will lead to a thin layer OrderedDict implementation as a first step. As @JimFasarakis-Hilliard indicated, some see  use cases for the OrderedDict type also in the future.\nI think the Python community at large will carefully inspect, if this will stand the test of time, and what the next steps will be.Time to rethink our coding habits to not miss the possibilities opened by stable ordering of:The first because it eases dispatch in the implementation of functions and methods in some cases.The second as it encourages to more easily use dict's as intermediate storage in processing pipelines.Raymond Hettinger kindly provided documentation explaining \"\" - from his San Francisco Python Meetup Group presentation 2016-DEC-08.And maybe quite some stackoverflow high decorated question and answer pages will receive variants of this info and many high quality answers will require a per version update too.As @ajcr rightfully notes: \"The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon.\" (from the ) not nit picking,  the citation was cut a bit pessimistic ;-). It continues as \" (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5).\"So as in some human languages (e.g. German), usage shapes the language, and the will now has been declared ... in You can use the . Note, this will work for both numeric and non-numeric values.You can create an \"inverted index\", alsoNow your inverse has the values; each value has a list of applicable keys.If values are numeric you may also use Counter from collectionsThis is the code:Here are the results: Technically, dictionaries aren't sequences, and therefore can't be sorted. You can do something likeassuming performance isn't a huge deal.UPDATE: Thanks to the commenters for pointing out that I made this way too complicated in the beginning.Why not try this approach. Let us define a dictionary called mydict with the following data:If one wanted to sort the dictionary by keys, one could do something like:This should return the following output:On the other hand, if one wanted to sort a dictionary by value (as is asked in the question), one could do the following:The result of this command (sorting the dictionary by value) should return the following:You can use a  which is a dictionary that's permanently sorted by value.If you use ,  or  then you'll iterate in sorted order by value.It's implemented using the  datastructure.This returns the list of key-value pairs in the dictionary, sorted by value from highest to lowest:For the dictionary sorted by key, use the following:The return is a list of tuples because dictionaries themselves can't be sorted.This can be both printed or sent into further computation.Use  from :If your values are integers, and you use Python 2.7 or newer, you can use  instead of . The  method will give you all items, sorted by the value.Iterate through a dict and sort it by its values in descending order:This works in 3.1.x:You can use the sorted function of PythonThus you can use:Visit this link for more information on sorted function: For the sake of completeness, I am posting a solution using . Note, this method will work for both numeric and non-numeric valuesI came up with this one, For Python 3.x:  replacing .Or try with !Here is a solution using zip on .  A few lines down this link (on Dictionary view objects) is:So we can do the following:"},
{"link": "https://stackoverflow.com//questions/53513/best-way-to-check-if-a-list-is-empty", "qbody": "For example, if passed the following:How do I check to see if  is empty?Using the implicit booleanness of the empty list is quite pythonic.The pythonic way to do it is from the :I prefer it explicitly:This way it's 100% clear that  is a sequence (list) and we want to test its size. My problem with  is that it gives the false impression that  is a boolean variable. updated to Python 3.Other people seem to be generalizing your question beyond just s, so I thought I'd add a caveat for a different type of sequence that a lot of people might use.  You need to be careful with numpy arrays, because other methods that work fine for s fail for numpy arrays.  I explain why below, but in short, the  is to use .The \"pythonic\" way fails with numpy arrays because numpy tries to cast the array to an array of s, and  tries to evaluate all of those s at once for some kind of aggregate truth value.  But this doesn't make any sense, so you get a :But at least the case above tells you that it failed.  If you happen to have a numpy array with exactly one element, the  statement will \"work\", in the sense that you don't get an error.  However, if that one element happens to be  (or , or , ...), the  statement will incorrectly result in :But clearly  exists and is not empty!  This result is not what you wanted.For example,returns 1, even though the array has zero elements.As explained in the , the correct method in all cases where you know you have a numpy array is to use :If you're not sure whether it might be a , a numpy array, or something else, you should combine this approach with  to make sure the right test is used for each type.  Not very \"pythonic\", but it turns out that python itself isn't pythonic in this sense either...An empty list is itself considered false in true value testing (see ):@Daren ThomasYour duckCollection should implement  or  so the if a: will work without problems. is right:  is the right way to do it.  is right that this is in the PEP 8 style guide. But what none of the answers explain is why it's a good idea to follow the idiom\u2014even if you personally find it's not explicit enough or confusing to Ruby users or whatever.Python code, and the Python community, has very strong idioms. Following those idioms makes your code easier to read for anyone experienced in Python. And when you violate those idioms, that's a strong signal.It's true that  doesn't distinguish empty lists from , or numeric 0, or empty tuples, or empty user-created collection types, or empty user-created not-quite-collection types, or single-element NumPy array acting as scalars with falsey values, etc. And sometimes it's important to be explicit about that. And in that case, you know  you want to be explicit about, so you can test for exactly that. For example,  means \"anything falsey except None\", while  means \"only empty sequences\u2014and anything besides a sequence is an error here\", and so on. Besides testing for exactly what you want to test, this also signals to the reader that this test is important.But when you don't have anything to be explicit about, anything other than  is misleading the reader. You're signaling something as important when it isn't. (You may also be making the code less flexible, or slower, or whatever, but that's all less important.) And if you  mislead the reader like this, then when you  need to make a distinction, it's going to pass unnoticed because you've been \"crying wolf\" all over your code.I have seen the below as preferred, as it will catch the null list as well: for Python lists, strings, dicts, and sets. Python internally keeps track of the number of elements in these containers.JavaScript .No one seems to have addressed questioning your  to test the list in the first place.  Because you provided no additional context, I can imagine that you may not need to do this check in the first place, but are unfamiliar with list processing in Python.I would argue that the  way is to not check at all, but rather to just process the list.  That way it will do the right thing whether empty or full.This has the benefit of handling any contents of , while not requiring a specific check for emptiness.  If  is empty, the dependent block will not execute and the interpreter will fall through to the next line.If you do actually need to check the array for emptiness, the other answers are sufficient.I had written:which was voted -1. I'm not sure if that's because readers objected to the strategy or thought the answer wasn't helpful as presented. I'll pretend it was the latter, since---whatever counts as \"pythonic\"---this is the correct strategy. Unless you've already ruled out, or are prepared to handle cases where  is, for example, , you need a test more restrictive than just . You could use something like this:the first test is in response to @Mike's answer, above. The third line could also be replaced with:if you only want to accept instances of particular types (and their subtypes), or with:You can get away without the explicit type check, but only if the surrounding context already assures you that  is a value of the types you're prepared to handle, or if you're sure that types you're not prepared to handle are going to raise errors (e.g., a  if you call  on a value for which it's undefined) that you're prepared to handle. In general, the \"pythonic\" conventions seem to go this last way. Squeeze it like a duck and let it raise a DuckError if it doesn't know how to quack. You still have to  about what type assumptions you're making, though, and whether the cases you're not prepared to handle properly really are going to error out in the right places. The Numpy arrays are a good example where just blindly relying on  or the boolean typecast may not do precisely what you're expecting.Python is very uniform about the treatment of emptiness. Given the following:You simply check list a with an \"if\" statement to see if it is empty.  From what I have read and been taught, this is the \"Pythonic\" way to see if a list or tuple is empty.From  on truth value testing:All values other than what is listed here are considered As can be seen, empty list  is , so doing what would be done to a boolean value sounds most efficient:Here are a few ways you can check if a list is empty: The pretty simple pythonic way:In Python,  such as lists,tuples,sets,dicts,variables etc are seen as . One could simply treat the list as a predicate (). And  a  value would indicate that it's non-empty. A much explicit way: using the  to find the length and check if it equals to : Or comparing it to an anonymous empty list: Another yet  way to do is using  and :some methods what i use:I prefer the following:Readable and you don't have to worry about calling a function like  to iterate through the variable. Although I'm not entirely sure what the BigO notation of something like this is... but Python's so blazingly fast I doubt it'd matter unless  was gigantic.There is of course alsoYou could also do :It is sometimes good to test for  and for emptiness separately as those are two different states. The code above produces the following output:Although it's worth nothing that  is falsy. So if you don't want to separate test for -ness, you don't have to do that. produces expected\nSee the examplesTry: executes the first statement if  is not an empty sequence, , , or Any empty  to False in Python:This based on  for dictionaries.Check the length of the list, if it's zero, the list is emptyBeing inspired by @dubiousjim's solution, I propose to use an additional general check of whether is it something iterableNote: a string is considered to be iterable. - add  if you want the empty string to be excludedTest:Another way, which is not listed in the previous answers and my not be the \"best way\", to check if a  is empty or not, is by using the special method  which will return an  which represent the size of the current list in memory in bytes.Example:As we can see, the  a  is superior than the  of an .So, we can check if a list is empty or not, for example, like this way:The  of an empty ,  and  are:A Python list is considered False when it is empty and True when it is not empty.\nThe following will work quite nicelyAlso This will also work for any python sequences.You can even try using bool() like thisI love this way for checking list is empty or not. Very handy and useful.The preferred way to check if any list, dictionary, set, string or tuple is empty in Python is to simply use an if statement to check it.you can use try and except as it is cheaper than if else construct"},
{"link": "https://stackoverflow.com//questions/89228/calling-an-external-command-in-python", "qbody": "How can I call an external command (as if I'd typed it at the Unix shell or Windows command prompt) from within a Python script?Look at the  in the standard library:The advantage of  vs  is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). The  recommend the  module over the alternative os.system():The \"\" section in the  documentation may have some helpful recipes.Official documentation on the  module:Here's a summary of the ways to call external programs and the advantages and disadvantages of each:The  module should probably be what you use.Finally please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it.  if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code:and imagine that the user enters \"my mama didnt love me && rm -rf /\".I typically use:You are free to do what you want with the  data in the pipe.  In fact, you can simply omit those parameters ( and ) and it'll behave like .Some hints on detaching the child process from the calling one (starting the child process in background).Suppose you want to start a long task from a CGI-script, that is the child process should live longer than the CGI-script execution process.The classical example from the subprocess module docs is:The idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example.My target platform was freebsd, but the development was on windows, so I faced the problem on windows first.On windows (win xp), the parent process will not finish until the longtask.py has finished its work. It is not what you want in CGI-script. The problem is not specific to Python, in PHP community the problems are the same.The solution is to pass DETACHED_PROCESS flag to the underlying CreateProcess function in win API.\nIf you happen to have installed pywin32 you can import the flag from the win32process module, otherwise you should define it yourself:/*  @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */On freebsd we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in CGI-script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following:I have not checked the code on other platforms and do not know the reasons of the behaviour on freebsd. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet.I'd recommend using the subprocess module instead of os.system because it does shell escaping for you and is therefore much safer: If you want to return the results of the command, you can use . However, this is deprecated since version 2.6 in favor of the , which other answers have covered well.Note that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant docs on the 'os' and 'sys' modules. There are a bunch of functions (exec* , spawn*) that will do similar things.Check the \"pexpect\" Python library, too.It allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like:I always use  for this things like:But this seem to be a good tool: .Look an example:If what you need is the output from the command you are calling,\nthen you can use  (Python 2.7+).Also note the  parameter.This is how I run my commands. This code has everything you need pretty muchUse :It is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write.If you do not mind external dependencies, use :It is the best  wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by .Another popular library is :However,  dropped Windows support, so it's not as awesome as it used to be. Install by . is the recommended approach  if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See .)Here's some examples from .Run a process:Raise on failed run:Capture output:I recommend trying . It's a wrapper for subprocess, which in turn  the older modules and functions. Envoy is subprocess for humans.Example usage from :Pipe stuff around too:Without the output of the result:With output of the result:There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is  (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them.Hopefully this will help you make a decision on which library to use :)Subprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better.os is used for \"operating system dependent functionality\". It can also be used to call external commands with  and  (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use .sh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times.plumbum is a library for \"script-like\" Python programs. You can call programs like functions as in . Plumbum is useful if you want to run a pipeline without the shell.pexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix.fabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH)envoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the  module. contains wrapper functions for , but it has been removed from Python 3 since  is a better alternative.The edit was based on J.F. Sebastian's comment.There is also ...or for a very simple command: is OK, but kind of dated.  It's also not very secure.  Instead, try .   does not call sh directly and is therefore more secure than .Get more information . has been superseded by the  module. Use subproccess instead.There is another difference here which is not mentioned above. executes the  as a subprocess. In my case, I need to execute file  which needs to communicate with another program . I tried subprocess, execution was successful. However  could not comm w/ .\neverything normal when I run both from the terminal.One more: \n(NOTE: kwrite behaves different from other apps. If you try below with firefox results will not be the same)If you try , program flow freezes until user closes kwrite. To overcome that I tried instead . This time program continued to flow but kwrite became the subprocess of the konsole.Anyone runs the kwrite not being a subprocess (i.e. at the system monitor it must be appear at the leftmost edge of the tree) is convenient if you don't want to test return values. It throws an exception on any error. does not allow you to store results, so if you want to store results in some list or something  works.Use:For the more  functions,  is the documentation.I tend to use  together with  (to handle escaping of quoted strings):Shameless plug, I wrote a library for this :P\nIt's basically a wrapper for popen and shlex for now. It also supports piping commands so you can chain commands easier in Python. So you can do things like:You can use Popen, and then you can check the procedure's status:Check out .To fetch the network id from the openstack neutron:Output of Output of Under Linux, in case you would like to call an external command that will execute independently (will keep running after the python script terminates), you can use a simple queue as  or the  commandAn example with task spooler:Notes about task spooler (): Here are my two cents: In my view, this is the best practice when dealing with external commands...These are the return values from the execute method...This is the execute method...In Windows you can just import the  module and run external commands by calling ,  and  as below:Output:"},
{"link": "https://stackoverflow.com//questions/38987/how-to-merge-two-python-dictionaries-in-a-single-expression", "qbody": "I have two Python dictionaries, and I want to write a single expression that returns these two dictionaries, merged.  The  method would be what I need, if it returned its result instead of modifying a dict in-place.How can I get that final merged dict in z, not x?(To be extra-clear, the last-one-wins conflict-handling of  is what I'm looking for as well.)Say you have two dicts and you want to merge them into a new dict without altering the original dicts:The desired result is to get a new dictionary () with the values merged, and the second dict's values overwriting those from the first.A new syntax for this, proposed in  and , is And it is indeed a single expression. It is now showing as implemented in the , and it has now made its way into  document.However, since many organizations are still on Python 2, you may wish to do this in a backwards compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:In both approaches,  will come second and its values will replace 's values, thus  will point to  in our final result.If you are not yet on Python 3.5, or need to write backward-compatible code, and you want this in a , the most performant while correct approach is to put it in a function:and then you have a single expression:You can also make a function to merge an undefined number of dicts, from zero to a very large number:This function will work in Python 2 and 3 for all dicts. e.g. given dicts  to :and key value pairs in  will take precedence over dicts  to , and so on.Don't use what you see in the formerly accepted answer:In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict.  because you're adding two  objects together, not two lists - and you would have to explicitly create them as lists, e.g. . This is a waste of resources and computation power. Similarly, taking the union of  in Python 3 ( in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, This example demonstrates what happens when values are unhashable:Here's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:Another hack you should not use:This uses the  constructor, and is very fast and memory efficient (even slightly more-so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic. Here's an example of the usage being .Dicts are intended to take hashable keys (e.g. frozensets or tuples), but From the , Guido van Rossum, the creator of the language, wrote:and It is my understanding (as well as the understanding of the ) that the intended usage for  is for creating dicts for readability purposes, e.g.:instead of Again, it doesn't work for 3 when keys are non-strings. The implicit calling contract is that namespaces take ordinary dicts, while users must only pass keyword arguments that are strings. All other callables enforced it.  broke this consistency in Python 2:This inconsistency was bad given other implementations of Python (Pypy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.These approaches are less performant, but they will provide correct behavior.\nThey will be  performant than  and  or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they  respect the order of precedence (latter dicts have precedence)You can also chain the dicts manually inside a dict comprehension:or in python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced): will chain the iterators over the key-value pairs in the correct order:I'm only going to do the performance analysis of the usages known to behave correctly. The following is done on Ubuntu 14.04In Python 2.7 (system Python):In Python 3.5 (deadsnakes PPA):In your case, what you can do is:This will, as you want it, put the final dict in , and make the value for key  be properly overridden by the second () dict's value:If you use Python 3, it is only a little more complicated.  To create :An alternative:Another, more concise, option:: this has become a popular answer, but it is important to point out that if  has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also, . So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely.This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or , depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit.In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item.In terms of :IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions.In a follow-up answer, you asked about the relative performance of these two alternatives:On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative  is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the  module that comes with Python.Example 1: identical dictionaries mapping 20 consecutive integers to themselves: wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but  always seems to come out ahead.  (If you get inconsistent results for the  test, try passing in  with a number larger than the default 3.)Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa: wins by about a factor of 10.  That's a pretty big win in my book!After comparing those two, I wondered if 's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better:A few quick tests, e.g.lead me to conclude that  is somewhat faster than , but not nearly as fast as .  Definitely not worth all the extra typing.This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the  method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows:A typical result:In other words,  and  seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't....In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses  in lots of places; optimizing its operations is a big deal.You could also write this asas Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand.I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call.In Python 3, you can use  which groups multiple dicts or other mappings together to create a single, updateable view:The best version I could think while not using copy would be:It's faster than  but not as fast as , at least on CPython. This version also works in Python 3 if you change  to , which is automatically done by the 2to3 tool.Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out.Demonstration:Outputs:Thanks rednaw for edits.For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last.Python 3.5 (PEP 448) allows a nicer syntax option:Or even While the question has already been answered several times,\nthis simple solution to the problem has not been listed yet.It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change.Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life  himself!  Someone else suggested half of this, but did not put it in a function.gives:If you think lambdas are evil then read no further.\nAs requested, you can write the fast and memory-efficient solution with one expression:As suggested above, using two lines or writing a function is probably a better way to go.In python3, the  method , but rather a , which acts like a set. In this case you'll need to take the set union since concatenating with  won't work:For python3-like behavior in version 2.7, the  method should work in place of :I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows).A couple more points for python 3. First, note that the  trick won't work in python 3 unless the keys in  are strings.Also, Raymond Hettinger's Chainmap  is pretty elegant, since it can take an arbitrary number of dicts as arguments, but  it looks like it sequentially looks through a list of all the dicts for each lookup:This can slow you down if you have a lot of lookups in your application:So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups.Abuse leading to a one-expression solution for :You said you wanted one expression, so I abused  to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe.You could also do this of course if you don't care about copying it:Even though the answers were good for this  dictionary, none of the methods defined here actually do a deep dictionary merge.Examples follow:One would expect a result of something like this:Instead, we get this:The 'one' entry should have had 'depth_2' and 'extra' as items inside its dictionary if it truly was a merge.Using chain also, does not work:Results in:The deep merge that rcwesick gave also creates the same result.Yes, it will work to merge the sample dictionaries, but none of them are a generic mechanism to merge.  I'll update this later once I write a method that does a true merge.Simple solution using itertools that preserves order (latter dicts have precedence)And it's usage:Drawing on ideas here and elsewhere I've comprehended a function:Usage (tested in python 3):You could use a lambda instead.The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12.\nIn that light, I present the following:Be pythonic. Use a : has bad performance. See Using  a dict comprehension, you maygivesNote the syntax for  in comprehension This can be done with a single dict comprehension:In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short.For Python 2 :For Python 3:It gives output:It's so silly that  returns nothing.\nI just use a simple helper function to solve the problem:Examples:This should solve your problem."},
{"link": "https://stackoverflow.com//questions/419163/what-does-if-name-main-do", "qbody": "What does the  do?When the Python interpreter reads a source file, it executes all of the code found in it.  Before executing the code, it will define a few special variables.  For example, if the python interpreter is running that module (the source file) as the main program, it sets the special  variable to have a value .  If this file is being imported from another module,  will be set to the module's name.In the case of your script, let's assume that it's executing as the main function, e.g. you said something likeon the command line.  After setting up the special variables, it will execute the  statement and load those modules.  It will then evaluate the  block, creating a function object and creating a variable called  that points to the function object.  It will then read the  statement and see that  does equal , so it will execute the block shown there.One of the reasons for doing this is that sometimes you write a module (a  file) where it can be executed directly.  Alternatively, it can also be imported and used in another module.  By doing the main check, you can have that code only execute when you want to run the module as a program and not have it execute when someone just wants to import your module and call your functions themselves.See  for some extra details.When your script is run by passing it as a command to the Python interpreter,all of the code that is at indentation level 0 gets executed.  Functions and classes that are defined are, well, defined, but none of their code gets ran.  Unlike other languages, there's no  function that gets run automatically - the  function is implicitly all the code at the top level.In this case, the top-level code is an  block.   is a built-in variable which evaluate to the name of the current module.  However, if a module is being run directly (as in  above), then  instead is set to the string .  Thus, you can test whether your script is being run directly or being imported by something else by testingIf that code is being imported into another module, the various function and class definitions will be imported, but the  code won't get run.  As a basic example, consider the following two scripts:Now, if you invoke the interpreter asThe output will beIf you run  instead:You getThus, when module  gets loaded, its  equals  instead of .The simplest explanation for the  variable (imho) is the following:Create the following files.andRunning them will get you this output:As you can see, when a module is imported, Python sets  in this module to the module's name.As you can see, when a file is executed, Python sets  in this file to .The global variable, , in the module that is the entry point to your program, is . So, code in this  block will only run if that module is the entry point to your program.Why do we need this?Say you're writing a Python script designed to be used as a module:You  test the module by adding this call of the function to the bottom:and running it (on a command prompt) with something like:However, if you want to import the module to another script:On import, the  function would be called, so you'd probably comment out your call of the function at the bottom. And then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome.The  variable points to the namespace wherever the Python interpreter happens to be at the moment. Inside an imported module, it's the name of that module. But inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its .So if you check before executing:With the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script). There's a Pythonic way to improve on this, though. What if we want to run this business process from outside the module? If we put the code we want to exercise as we develop and test in a function like this and then do our check for  immediately after:We now have a final function for the end of our module that will run if we run the module as the primary module. It will allow the module and its functions and classes to be imported into other scripts without running the  function, and will also allow the module (and its functions and classes) to be called when running from a different  module, i.e. That text states: is the part that runs when the script is run from (say) the command line using a command like . is a global variable (in Python, global actually means on the ) that exists in all namespaces. It is typically the module's name (as a  type).As the only special case, however, in whatever Python process you run, as in mycode.py:the otherwise anonymous global namespace is assigned the value of  to its . Thus, including will cause your script's uniquely defined  function to run. Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides:When there are certain statements in our module (), we want to be executed when it 'll be running as main (not imported), in that case we can place those statements (test-cases, print statements) under this if block. As by default (when module running as main, not imported) the  variable is set to , and when it'll be imported the  variable 'll get a different value, most probably the name of the module ().\nThis is helpful in running different variants of a modules together, and seperating their specific input & output statements and also if any test-cases. , use this ' ' block to prevent (certain) code from being run when  the module is imported.Let's look at the answer in a more abstract way:Suppose we have this code in x.py:Blocks A and B are run when we are running \"x.py\".But just block A (and not B) is run when we are running another module, \"y.py\" for example, in which x.y is imported and the code is run from there (like when a function in \"x.py\" is called from y.py).When you run Python interactively the local  variable is assigned a value of . Likewise, when you execute a Python module from the command line, rather than importing it into another module, its  attribute is assigned a value of , rather than the actual name of the module. In this way, modules can look at their own  value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules:Lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers.Take this example:File \"ab.py\":Second file \"xy.py\":When you execute xy.py, you import . The import statement runs the module immediately on import, so ab's operations get executed before the remainder of xy's. Once finished with ab, it continues with xy. The interpreter keeps track of which scripts are running with . When you run a script - no matter what you've named it - the interpreter calls it . That's how it keeps track of which script is the master file, the script that gets returned to after an external call to another script. (The 'home' script, you might say.) Any other script that's called from this 'main' script is assigned its filename as its . Hence, the line  is the interpreter's test to determine if it's running on the script it's looking at (parsing), or if it's temporarily peeking into another script. This gives the programmer flexibility to have the script behave differently if it's called externally.To understand what's happening, focus first on the unindented lines and the order they appear in the scripts. Remember that function - or  - blocks don't do anything by themselves until they're called. What the interpreter might think if mumbled to itself:The bottom two lines mean: \"If this is the 'main' or home script, execute the function called . That's why you'll see a  block up top, which contains the main flow of the script's functionality.Remember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the  function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script.Again, there will be exceptions, but common practice is that  doesn't usually get called externally. So you may be wondering one more thing: if we're not calling , why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run by themselves. They're then later called somewhere else in the body of the script. Which brings me to this:Yes, that's right. These separate functions  be called from an in-line script that's not contained inside a  function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read. But that's a script that probably can't have its functions called externally, because if it did it would start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there could be conflicting variables.I should say as an aside,  contains an answer by @kindall that finally helped me to understand - the Why, not the How. Unfortunately it's been marked as a duplicate of , which I think is a mistake.It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance.It could be written in several ways, another is:I am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about . It is a (great!) convention for invoking a main function in Python files.There are a number of variables that the system (Python interpreter) provides for source files (modules).  You can get their values anytime you want, so, let us focus on the  variable/attribute:When Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.)Before the interpreter executes the source code file though, it defines a few special variables for that file;  is one of those special variables that Python automatically defines for each source code file.If Python is loading this source code file as the main program (i.e. the file you run), then it sets the special  variable for this file to have a value .If this is being imported from another module,  will be set to that module's name.So, in your example in part:means that the code block:will be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of  will not equal to \"\" in that particular instance.Hope this helps out.Put Simply  is a variable defined for each script, that defines whether the script is being run as the main module or it is being run as an imported module. So if we have two scripts;and ;The output from executing script1 is;and the output from executing script2 is;As you can see;  tells us which code is the 'main' module.\nThis is great because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library. Say you write a python script that does something great and you implement a boatload of functions that are useful for other purposes, if I want to use them I can just import your script and use them without executing your program(given that your code only executes within the   context). Whereas in C/C++ you would have to portion out those pieces into a seperate module that then includes the file. Picture the situation below; The arrows are import links. For three modules each trying to include the previous modules code there are six files(nine, counting the implementation files) and five links , this makes it difficult to include other code into a c project unless it is compiled specifically as a library. Now picture it for python;You write a module, If someone wants to utilize your code they just import it and the  variable can help to seperate the executable portion of the program from the library part. is basically Top-level script environment, it specifies the interpreter that ('I have the highest priority to be executed first').' is the name of the scope in which top-level code executes. A module\u2019s  is set equal to '' when read from standard input, a script, or from an interactive prompt.I think it's best to break the answer in depth and in simple words: : Every module in Python has a special attribute called .\nIt is a built-in variable that returns the name of the module. : Like other programming languages, Python too has an execution entry point i.e. main. ''  Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its  is set to . Thus,the value of   attribute is set to   when the module is run as main program. Otherwise the value of   is set to contain the name of the module.Reference: output for the above is  the above statement is gets true and print direct method suppose if they imported this class in other class it doesnt print direct method .because while importing it will  set   "},
{"link": "https://stackoverflow.com//questions/394809/does-python-have-a-ternary-conditional-operator", "qbody": "If Python does not have a ternary conditional operator, is it possible to simulate one using other language constructs?Yes, it was  in version 2.5.\nThe syntax is:First  is evaluated, then either  or  is returned based on the  value of \nIf  evaluates to   is returned, else  is returned. For example:Keep in mind that it's frowned upon by some Pythonistas for several reasons:If you're having trouble remembering the order, then remember that if you read it out loud, you (almost) say what you mean. For example,  is read aloud as .Official documentation:You can index into a tuple: needs to return  or .\nIt might be safer to always implement it as:or you can use the built-in  to assure a  value:For versions prior to 2.5, there's the trick:It can give wrong results when  \n has a false boolean value.\nAlthough it does have the benefit of evaluating expressions left to right, which is clearer in my opinion. if  else From :New since version 2.5.@up:Unfortunately, thesolution doesn't have short-circuit behaviour; thus both falseValue and trueValue are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both trueValue and falseValue could be methods and have side-effects).One solution to this would be(execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties.And so the story goes - choosing between 3 mentioned solutions is a trade-off between having the short-circuit feature, using at least python 2.5 (IMHO not a problem anymore) and not being prone to \"trueValue-evaluates-to-false\" errors.An operator for a conditional expression in Python was added in 2006 as part of . Its form differ from common  operator and it's:which is equivalent to:Here is example:Another syntax which can be used (compatible with versions before 2.5):where operands are .Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages):or explicitly constructed dictionary:Another (less reliable), but simpler method is to use  and  operators:however this won't work if  would be .As possible workaround is to make  and  lists or tuples as in the following:or:If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of , for example:For Python 2.5 and newer there is a specific syntax:In older Pythons a ternary operator is not implemented but it's possible to simulate it.Though, there is a potential problem, which if  evaluates to  and  evaluates to  then  is returned instead of . If you want this behavior the method is OK, otherwise use this:which can be wrapped by:and used this way:It is compatible with all Python versions.You might often findbut this lead to problem when on_true == 0where you would expect for a  normal ternary operator this resultAbsolutely, and it is incredibly easy to understand. Yes. From the :The part of interest is:So, a ternary conditional operation is of the form: will be lazily evaluated (that is, evaluated only if  is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.)Note that every  must be followed with an . People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else:which raises a .\nSo the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use expression2 as a filter - notes that the following is legal Python: works as a filter for the list comprehension, and is  a ternary conditional operator.You may find it somewhat painful to write the following: will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use 's shortcutting behavior:which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax.Here I just try to show some important difference in  between a couple of programming languages.Now you can see the beauty of python language. its highly readable and maintainable.Simulating the python ternary operator.For exampleoutput:More a tip than an answer (don't need to repeat the obvious for the hundreth time), but I sometimes use it as a oneliner shortcut in such constructs:, becomes:Some (many :) may frown upon it as unpythonic (even, ruby-ish :), but I personally find it more natural - i.e. how you'd express it normally, plus a bit more visually appealing in large blocks of code.Yes.There is a ternary option as stated in other answers, but you can also simulate it using \"or\" if you are checking against a boolean or None value:"},
{"link": "https://stackoverflow.com//questions/100003/what-is-a-metaclass-in-python", "qbody": "What are metaclasses? What do you use them for?A metaclass is the class of a class. Like a class defines how an instance of the class behaves, a metaclass defines how a class behaves. A class is an instance of a metaclass.While in Python you can use arbitrary callables for metaclasses (like  shows), the more useful approach is actually to make it an actual class itself.  is the usual metaclass in Python. In case you're wondering, yes,  is itself a class, and it is its own type. You won't be able to recreate something like  purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass .A metaclass is most commonly used as a class-factory. Like you create an instance of the class by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal  and  methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry, or even replace the class with something else entirely.When the  statement is executed, Python first executes the body of the  statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the  attribute of the class-to-be (if any) or the  global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.However, metaclasses actually define the  of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods, in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class.  is an example of a method on the  metaclass. You can also define the normal 'magic' methods, like ,  and , to implement or change how the class behaves.Here's an aggregated example of the bits and pieces:Before understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:But classes are more than that in Python. Classes are objects too.Yes, objects. As soon as you use the keyword , Python executes it and creates\nan OBJECT. The instructioncreates in memory an object with the name \"ObjectCreator\". . But still, it's an object, and therefore:e.g.:Since classes are objects, you can create them on the fly, like any object.First, you can create a class in a function using :But it's not so dynamic, since you still have to write the whole class yourself.Since classes are objects, they must be generated by something.When you use the  keyword, Python creates this object automatically. But as\nwith most things in Python, it gives you a way to do it manually.Remember the function ? The good old function that lets you know what \ntype an object is:Well,  has a completely different ability, it can also create classes on the fly.  can take the description of a class as parameters, \nand return a class.(I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backwards \ncompatibility in Python) works this way:e.g.:can be created manually this way:You'll notice that we use \"MyShinyClass\" as the name of the class\nand as the variable to hold the class reference. They can be different,\nbut there is no reason to complicate things. accepts a dictionary to define the attributes of the class. So:Can be translated to:And used as a normal class:And of course, you can inherit from it, so:would be:Eventually you'll want to add methods to your class. Just define a function\nwith the proper signature and assign it as an attribute.And you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.You see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.This is what Python does when you use the keyword , and it does so by using a metaclass.Metaclasses are the 'stuff' that creates classes.You define classes in order to create objects, right?But we learned that Python classes are objects.Well, metaclasses are what create these objects. They are the classes' classes,\nyou can picture them this way:You've seen that  lets you do something like this:It's because the function  is in fact a metaclass.  is the \nmetaclass Python uses to create all classes behind the scenes.Now you wonder why the heck is it written in lowercase, and not ?Well, I guess it's a matter of consistency with , the class that creates\nstrings objects, and  the class that creates integer objects.  is\njust the class that creates class objects.You see that by checking the  attribute. Everything, and I mean everything, is an object in Python. That includes ints, \nstrings, functions and classes. All of them are objects. And all of them have\nbeen created from a class:Now, what is the  of any  ?So, a metaclass is just the stuff that creates class objects.You can call it a 'class factory' if you wish. is the built-in metaclass Python uses, but of course, you can create your\nown metaclass.You can add a  attribute when you write a class:If you do so, Python will use the metaclass to create the class .Careful, it's tricky.You write  first, but the class object  is not created\nin memory yet.Python will look for  in the class definition. If it finds it,\nit will use it to create the object class . If it doesn't, it will use\n to create the class.Read that several times.When you do:Python does the following:Is there a  attribute in ?If yes, create in memory a class object (I said a class object, stay with me here), with the name  by using what is in .If Python can't find , it will look for a  at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes). Then if it can't find any  at all, it will use the 's (the first parent) own metaclass (which might be the default ) to create the class object.Be careful here that the  attribute will not be inherited, the metaclass of the parent () will be. If  used a  attribute that created  with  (and not ), the subclasses will not inherit that behavior.Now the big question is, what can you put in  ?The answer is: something that can create a class.And what can create a class? , or anything that subclasses or uses it.The main purpose of a metaclass is to change the class automatically,\nwhen it's created.You usually do this for APIs, where you want to create classes matching the\ncurrent context.Imagine a stupid example, where you decide that all classes in your module\nshould have their attributes written in uppercase. There are several ways to \ndo this, but one way is to set  at the module level.This way, all classes of this module will be created using this metaclass, \nand we just have to tell the metaclass to turn all attributes to uppercase.Luckily,  can actually be any callable, it doesn't need to be a\nformal class (I know, something with 'class' in its name doesn't need to be \na class, go figure... but it's helpful).So we will start with a simple example, by using a function.Now, let's do exactly the same, but using a real class for a metaclass:But this is not really OOP. We call  directly and we don't override\nor call the parent . Let's do it:You may have noticed the extra argument . There is\nnothing special about it:  always receives the class it's defined in, as first parameter. Just like you have  for ordinary methods which receive the instance as first parameter, or the defining class for class methods.Of course, the names I used here are long for the sake of clarity, but like\nfor , all the arguments have conventional names. So a real production\nmetaclass would look like this:We can make it even cleaner by using , which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):That's it. There is really nothing more about metaclasses.The reason behind the complexity of the code using metaclasses is not because\nof metaclasses, it's because you usually use metaclasses to do twisted stuff\nrelying on introspection, manipulating inheritance, vars such as , etc.Indeed, metaclasses are especially useful to do black magic, and therefore\ncomplicated stuff. But by themselves, they are simple:Since  can accept any callable, why would you use a class\nsince it's obviously more complicated?There are several reasons to do so:Now the big question. Why would you use some obscure error prone feature?Well, usually you don't:The main use case for a metaclass is creating an API. A typical example of this is the Django ORM.It allows you to define something like this:But if you do this:It won't return an  object. It will return an , and can even take it directly from the database.This is possible because  defines  and \nit uses some magic that will turn the  you just defined with simple statements\ninto a complex hook to a database field. Django makes something complex look simple by exposing a simple API\nand using metaclasses, recreating code from this API to do the real job\nbehind the scenes.First, you know that classes are objects that can create instances.Well in fact, classes are themselves instances. Of metaclasses.Everything is an object in Python, and they are all either instances of classes\nor instances of metaclasses.Except for . is actually its own metaclass. This is not something you could\nreproduce in pure Python, and is done by cheating a little bit at the implementation\nlevel.Secondly, metaclasses are complicated. You may not want to use them for \nvery simple class alterations. You can change classes by using two different techniques:99% of the time you need class alteration, you are better off using these.But 99% of the time, you don't need class alteration at all.Metaclasses are the secret sauce that make 'class' work. The default metaclass for a new style object is called 'type'.Metaclasses take 3 args. '', '' and ''Here is where the secret starts. Look for where name, bases and the dict come from in this example class definition.Lets define a metaclass that will demonstrate how '' calls it.And now, an example that actually means something, this will automatically make the variables in the list \"attributes\" set on the class, and set to None.Note that the magic behaviour that 'Initalised' gains by having the metaclass  is not passed onto a subclass of Initalised.Here is an even more concrete example, showing how you can subclass 'type' to make a metaclass that performs an action when the class is created. This is quite tricky:One use for metaclasses is adding new properties and methods to an instance automatically.For example, if you look at , their definition looks a bit confusing. It looks as if you are only defining class properties:However, at runtime the Person objects are filled with all sorts of useful methods. See the  for some amazing metaclassery.Others have explained how metaclasses work and how they fit into the Python type system. Here's an example of what they can be used for. In a testing framework I wrote, I wanted to keep track of the order in which classes were defined, so that I could later instantiate them in this order. I found it easiest to do this using a metaclass.Anything that's a subclass of  then gets a class attribute  that records the order in which the classes were defined.I think the ONLamp introduction to metaclass programming is well written and gives a really good introduction to the topic despite being several years old already.In short: A class is a blueprint for the creation of an instance, a metaclass is a blueprint for the creation of a class. It can be easily seen that in Python classes need to be first-class objects too to enable this behavior.I've never written one myself, but I think one of the nicest uses of metaclasses can be seen in the . The model classes use a metaclass approach to enable a declarative style of writing new models or form classes. While the metaclass is creating the class, all members get the possibility to customize the class itself.The thing that's left to say is: If you don't know what metaclasses are, the probability that you  is 99%.A class is to an instance as a metaclass is to a class. Put another way, a class is an instance of a metaclass.Put a third way, a metaclass is a class's class.Still hopelessly confused? So was I, until I learned the following and demonstrated how one can actually use metaclasses:When you create a class definition, for example, like this,it's the same as functionally calling  with the appropriate arguments and assigning the result to a variable of that name:Note, some things automatically get added to the , i.e., the namespace:The  of the object we created, in both cases, is . Here's the default  of classes:One of the most valuable things we can do by default in writing a Python object is to provide it with a good . When we call  we learn that there's a good test for a  that also requires a test for equality - . The following simple implementation of  and  for class instances of our type class provides us with a demonstration that may improve on the default  of classes:So now when we create an object with this metaclass, the  echoed on the command line provides a much less ugly sight than the default:With a  defined for the class instance, we have a stronger ability to debug our code.If, for example, we want to know in what order a class's methods are created in, we could provide an ordered dict as the namespace of the class. We would do this with  which : And usage:And now we have a record of the order in which these methods (and other class attributes) were created:Note, this example was adapted from the . So what we did was instantiate a metaclass by creating a class. We can also treat the metaclass as we would any other class. It has a method resolution order:And it has approximately the correct  (which we can no longer eval unless we can find a way to represent our functions.):There are (at this point) two key methods in a metaclass: lets you supply a custom mapping (such as an ) to be used as the namespace while the class is being created.  You must return an instance of whatever namespace you choose.  If you don't implement  a normal  is used. is responsible for the actual creation/modification of the final class.A bare-bones, do-nothing-extra metaclass would like:A simple example:Say you want some simple validation code to run on your attributes -- like it must always be an  or a .  Without a metaclass, your class would look something like:As you can see, you have to repeat the name of the attribute twice.  This makes typos possible along with irritating bugs.A simple metaclass can address that problem:This is what the metaclass would look like (not using  since it is not needed):A sample run of:produces::  This example is simple enough it could have also been accomplished with a class decorator, but presumably an actual metaclass would be doing much more.The 'ValidateType' class for reference:A metaclass is a class that tells how (some) other class should be created.This is a case where I saw metaclass as a solution to my problem:\nI had a really complicated problem, that probably could have been solved differently, but I chose to solve it using a metaclass.  Because of the complexity, it is one of the few modules I have written where the comments in the module surpass the amount of code that has been written.  Here it is...If you've done Python programming for more than a few months you'll eventually stumble upon code that looks like this:The latter is possible when you implement the  magic method on the class.The  method is invoked when an instance of a class is used as a callable. But as we've seen from previous answers a class itself is an instance of a metaclass, so when we use the class as a callable (i.e. when we create an instance of it) we're actually calling its metaclass's  method. At this point most Python programmers are a bit confused because they've been told that when creating an instance like this  you're calling it's  method. Some who've dug a bit deeper know that before  there's . Well, today another layer of truth is being revealed, before  there's the metaclass's .Let's study the method call chain from specifically the perspective of creating an instance of a class.This is a metaclass that logs exactly the moment before an instance is created and the moment it's about to return it.This is a class that uses that metaclass And now let's create an instance of The code above doesn't actually do anything other than logging the task and then delegating the actual work to the parent (i.e. keeping the default behavior). So with  being 's parent class, we can imagine that this would be the pseudo implementation of :We can see that the metaclass's  method is the one that's called first. It then delegates creation of the instance to the class's  method and initialization to the instance's . It's also the one that ultimately returns the instance.From the above it stems that the metaclass's  is also given the opportunity to decide whether or not a call to  or  will eventually be made. Over the course of its execution it could actually return an object that hasn't been touched by either of these methods. Take for example this approach to the singleton pattern:Let's observe what happens when repeatedly trying to create an object of type  is actually a  -- a class that creates another classes.\nMost  are the subclasses of . The  receives the  class as its first argument and provide access to class object with details as mentioned below:Notice that the class was not instantiated at any time; the simple act of creating the class triggered execution of the .The  function gets you the type of an object. To use a metaclass:A metaclass is essentially an abstract base class--a concept taught in most intermediate computer programming courses."},
{"link": "https://stackoverflow.com//questions/82831/how-do-i-check-whether-a-file-exists-using-python", "qbody": "How do I check whether a file exists, without using the  statement?You can also use if you need to be sure it's a file.Starting with Python 3.4, the  offers an object-oriented approach (backported to  in Python 2.7):To check a directory, do:To check whether a  object exists independently of whether is it a file or directory, use :You can also use  in a  block:You have the  function:This returns  for both files and directories but you can instead use  to test if it's a file specifically. It follows symlinks.Unlike ,  will return  for directories.\nSo depending on if you want only plain files or also directories, you'll use  or . Here is a simple REPL output.Use  with :This is the simplest way to check if a file exists. Just  the file existed when you checked doesn't  that it will be there when you need to open it.Prefer the try statement. It's considered better style and avoids race conditions.Don't take my word for it. There's plenty of support for this theory. Here's a couple: has an object-oriented path module: .  Using this new module, you can check whether a file exists like this:You can (and usually should) still use a  block when opening files:The pathlib module has lots of cool stuff in it: convenient globbing, checking file's owner, easier path joining, etc.  It's worth checking out.  If you're on an older Python (version 2.6 or later), you can still install pathlib with pip:Importing  makes it easier to navigate and perform standard actions with your operating system. For reference also see If you need high-level operations, use .Python 3.4 gives us the  context manager (previously the  context manager), which does semantically exactly the same thing in fewer lines, while also (at least superficially) meeting the original ask to avoid a  statement:Usage:For earlier Pythons, you could roll your own , but without a  will be much more verbose than with. I do believe  that can be applied to prior to Python 3.4 because it uses a context manager instead:Easier with a try:from the :But if you examine the  of this function, you'll see it actually does use a try statement:All it's doing is using the given path to see if it can get stats on it,  catching  and then checking if it's a file if it didn't raise the exception.If you intend to do something with the file, I would suggest directly attempting it with a try-except to avoid a race condition:Available for Unix and Windows is , but to use you must pass flags, and it does not differentiate between files and directories. This is more used to test if the real invoking user has access in an elevated privilege environment:It also suffers from the same race condition problems as . From the :It doesn't seem like there's a meaningful functional difference between try/except and , so you should use which one makes sense.If you want to read a file, if it exists, doBut if you just wanted to rename a file if it exists, and therefore don't need to open it, doIf you want to write to a file, if it doesn't exist, doIf you need file locking, that's a different matter.Testing for files and folders with ,  and Assuming that the \"path\" is a valid path, this table shows what is returned by each function for files and folders:You can also test if a file is a certain type of file using  to get the extension (if you don't already know it)You could try this (safer):The ouput would be:Then, depending on the result, your program can just keep running from there or you can code to stop it if you want.Although I always recommend using  and  statements, here are a few possibilities for you (my personal favourite is using ):I should also mention that there are two ways that you will not be able to verify the existence of a file. Either the issue will be  or . If you catch an , set the  (like my first option), and then type in  so that you can hopefully determine your issue. I hope it helps! :)In 2016 the best way is still using :Or in Python 3 you can use :Additionally, :Being , , and  the flags to test for permissions ().In Python 3.4 the language provides a new module to manage files:SRC: Just to add to the confusion, it seems that the try: open() approach suggested previously doesn't work in Python, as file access isn't exclusive, not even when writing to files, c.f. .Here's a 1 line Python command for the Linux command line environment. I find this VERY HANDY since I'm not such a hot Bash guy.I hope this is helpful.Adding one more slight variation which isn't exactly reflected in the other answers.This will handle the case of the  being  or empty string.Adding a variant based on suggestion from Shahbaz\nAdding a variant based on suggestion from Peter Wood\nYou can write Brian's suggestion without the . is part of Python 3.4. In older releases you can quickly write your own suppress:You can use the \"OS\" library of Python:This is helpful when checking for several files. Or you want to do a set intersection/ subtraction with an existing list.I'm the author of a package that's been around for about 10 years, and it has a function that addresses this question directly. Basically, if you are on a non-Windows system, it uses  to access .  However, if you are on Windows, it replicates  with an efficient filesystem walker.The code itself does not use a  block\u2026 except in determining the operating system and thus steering you to the \"Unix\"-style  or the hand-buillt . Timing tests showed that the  was faster in determining the OS, so I did use one there (but nowhere else).And the doc\u2026The implementation, if you care to look, is here:\nTo check if a file exists, You can use the following open method to check if a file exists + readable:In 2016, this is still arguably the easiest way to check if both a file exists and if it is a file: is actually just a helper method that internally uses  and  underneath. This  is a lower-level method that will provide you with detailed information about files, directories, sockets, buffers, and more.  However, this approach will not lock the file in any way and therefore your code can become vulnerable to \"\" () bugs.So raising exceptions is considered to be an acceptable, and Pythonic, approach for flow control in your program. And one should consider handling missing files with IOErrors, rather than  statements ().If the file is for opening you could use one of the following techniques:"},
{"link": "https://stackoverflow.com//questions/275018/how-can-i-remove-chomp-a-newline-in-python", "qbody": "What is the Python equivalent of Perl's  function, which removes the last character of a value?Try the method  (see doc  and )Python's  method strips  kinds of trailing whitespace by default, not just one newline as Perl does with .To strip only newlines:There are also the methods  and :And I would say the \"pythonic\" way to get lines without trailing newline characters is splitlines().The canonical way to strip end-of-line (EOL) characters is to use the string rstrip() method removing any trailing \\r or \\n.  Here are examples for Mac, Windows, and Unix EOL characters.Using '\\r\\n' as the parameter to rstrip means that it will strip out any trailing combination of '\\r' or '\\n'.  That's why it works in all three cases above.This nuance matters in rare cases.  For example, I once had to process a text file which contained an HL7 message.  The HL7 standard requires a trailing '\\r' as its EOL character.  The Windows machine on which I was using this message had appended its own '\\r\\n' EOL character.  Therefore, the end of each line looked like '\\r\\r\\n'.  Using rstrip('\\r\\n') would have taken off the entire '\\r\\r\\n' which is not what I wanted.  In that case, I simply sliced off the last two characters instead.Note that unlike Perl's  function, this will strip all specified characters at the end of the string, not just one:Note that rstrip doesn't act exactly like Perl's chomp() because it doesn't modify the string. That is, in Perl:results in  being .but in Python:will mean that the value of  is  . Even  doesn't always give the same result, as it strips all whitespace from the end of the string, not just one newline at most.I might use something like this:I think the problem with  is that you'll probably want to make sure the line separator is portable. (some antiquated systems are rumored to use ). The other gotcha is that  will strip out repeated whitespace. Hopefully  will contain the right characters. the above works for me.You may use . This will strip all newlines from the end of the string, not just one.will remove all newlines at the end of the string . The assignment is needed because  returns a new string instead of modifying the original string. Careful with : That will only chomp the newline characters for the platform where your Python is being executed. Imagine you're chimping the lines of a Windows file under Linux, for instance:Use  instead, as Mike says above.or you could always get geekier with regexps :)have fun!you can use strip:demo:An  simply uses .Perl's  function removes one linebreak sequence from the end of a string only if it's actually there.Here is how I plan to do that in Python, if  is conceptually the function that I need in order to do something useful to each line from this file:rstrip doesn't do the same thing as chomp, on so many levels. Read  and see that chomp is very complex indeed.However, my main point is that chomp removes at most 1 line ending, whereas rstrip will remove as many as it can.Here you can see rstrip removing all the newlines:A much closer approximation of typical Perl chomp usage can be accomplished with re.sub, like this:I don't program in Python, but I came across an  at python.org advocating S.rstrip(\"\\r\\n\") for python 2.2 or later.workaround solution for special case:if the newline character is the last character (as is the case with most file inputs), then for any element in the collection you can index as follows: to slice out your newline character. If your question is to clean up all the line breaks in a multiple line str object (oldstr), you can split it into a list according to the delimiter '\\n' and then join this list into a new str(newstr).    This would replicate exactly perl's chomp (minus behavior on arrays) for \"\\n\" line terminator:(Note: it does not modify string 'in place'; it does not strip extra trailing whitespace; takes \\r\\n in account)Here we go Official Complete Documentation  Just use : orYou don't need any of this complicated stuffA catch all:There are three types of line endings that we normally encounter: ,  and . A rather simple regular expression in , namely , is able to catch them all.(And we , am I right?)With the last argument, we limit the number of occurences replaced to one, mimicking chomp to some extent. Example:... where  is .I find it convenient to have be able to get the chomped lines via in iterator, parallel to the way you can get the un-chomped lines from a file object. You can do so with the following code:Sample usage:If you are concerned about speed (say you have a looong list of strings) and you know the nature of the newline char, string slicing is actually faster than rstrip. A little test to illustrate this:Output:It looks like there is not a perfect analog for perl's .  In particular,  cannot handle multi-character newline delimiters like . However,  does .\nFollowing  on a different question, you can combine  and  to remove/replace all newlines from a string :The following removes  newline (as chomp would, I believe). Passing  as the  argument to splitlines retain the delimiters.  Then, splitlines is called again to remove the delimiters on just the last \"line\": "},
{"link": "https://stackoverflow.com//questions/2225038/determine-the-type-of-an-object", "qbody": "Is there a simple way to determine if a variable is a list, dictionary, or something else? I am getting an object back that may be either type and I need to be able to tell the difference.To get the type of an object, you can use the built-in  function. Passing an object as the only parameter will return the type object of that object:This of course also works for custom types:Note that  will only return the immediate type of the object, but won\u2019t be able to tell you about type inheritance.To cover that, you should use the  function. This of course also works for built-in types: is usually the preferred way to ensure the type of an object because it will also accept derived types. So unless you actually need the type object (for whatever reason), using  is preferred over .The second parameter of  also accepts a tuple of types, so it\u2019s possible to check for multiple types at once.  will then return true, if the object is of any of those types:You can do that using :It might be more Pythonic to use a ... block. That way, if you have a class which quacks like a list, or quacks like a dict, it will behave properly regardless of what its type  is.To clarify, the preferred method of \"telling the difference\" between variable types is with something called : as long as the methods (and return types) that a variable responds to are what your subroutine expects, treat it like what you expect it to be. For example, if you have a class that overloads the bracket operators with  and , but uses some funny internal scheme, it would be appropriate for it to behave as a dictionary if that's what it's trying to emulate.The other problem with the  checking is that if  is a subclass of , it evaluates to  when, programmatically, you would hope it would be . If an object is a subclass of a list, it should work like a list: checking the type as presented in the other answer will prevent this. ( will work, however).On instances of object you also have the:attribute. Here is a sample taken from Python 3.3 consoleBeware that in python 3.x and in New-Style classes (aviable optionally from Python 2.6) class and type have been merged and this can sometime lead to unexpected results. Mainly for this reason my favorite way of testing types/classes is to the  built in function.You can use  or .Be warned that you can clobber  or any other type by assigning a variable in the current scope of the same name.Above we see that  gets reassigned to a string, therefore the test:...fails.To get around this and use  more cautiously:While the questions is pretty old, I stumbled across this while finding out a proper way myself, and I think it still needs clarifying,  (did not check on Python 3, but since the issue arises with classic classes which are gone on such version, it probably doesn't matter).Here I'm trying to answer the title's question: ? Other suggestions about using or not using isinstance are fine in many comments and answers, but I'm not addressing those concerns.The main issue with the  approach is that :Executing this snippet would yield:Which, I argue, is not what most people would expect.The  approach is the most close to correctness, but it won't work in one crucial case: when the passed-in object is an old-style  (not an instance!), since those objects lack such attribute.This is the smallest snippet of code I could think of that satisfies such legitimate question in a consistent fashion:Determine the type of an object with Although it works, avoid double underscore attributes like  - they're not semantically public, and, while perhaps not in this case, the builtin functions usually have better behavior.Well that's a different question, don't use type - use :This covers the case where your user might be doing something clever or sensible by subclassing  - according to the principle of Liskov Substitution, you want to be able to use subclass instances without breaking your code - and  supports this. Even better, you might look for a specific Abstract Base Class from  or :Or, perhaps best of all, use duck-typing, and don't explicitly type-check your code. Duck-typing supports Liskov Substitution with more elegance and less verbosity. As an aside to the previous answers, it's worth mentioning the existence of  which contains several abstract base classes (ABCs) that complement duck-typing.For example, instead of explicitly checking if something is a list with: you could, if you're only interested in seeing if the object you have allows getting items, use :if you're strictly interested in objects that allow getting, setting  deleting items (i.e  sequences), you'd opt for .Many other ABCs are defined there,  for objects that can be used as maps, , , et cetera. A full list of all these can be seen in "},
{"link": "https://stackoverflow.com//questions/36901/what-does-double-star-and-star-do-for-parameters", "qbody": "In the following method definitions, what does the  and  do for ?The  and  is a common idiom to allow arbitrary number of arguments to functions as described in the section  in the Python documentation.The  will give you all function parameters :The  will give you all \n except for those corresponding to a formal parameter as a dictionary.Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:Another usage of the  idiom is to  when calling a function.In Python 3 it is possible to use  on the left side of an assignment (), though it gives a list instead of a tuple in this context:Also Python 3 adds new semantic (refer ):Such function accepts only 3 positional arguments, and everything after  can only be passed as keyword arguments.It's also worth noting that you can use * and ** when calling functions as well. This is a shortcut that allows you to pass multiple arguments to a function directly using either a list/tuple or a dictionary. For example, if you have the following function:You can do things like:The single * means that there can be any number of extra positional arguments.  can be invoked like . In the body of foo() param2 is a sequence containing 2-5.The double ** means there can be any number of extra named parameters.  can be invoked like . In the body of bar() param2 is a dictionary containing {'a':2, 'b':3 }With the following code:the output isThey allow for  and for  any number of arguments, positional () and keyword (). allows for any number of optional positional arguments (parameters), which will be assigned to a tuple named .  allows for any number of optional keyword arguments (parameters), which will be in a dict named .You can (and should) choose any appropriate name, but if the intention is for the arguments to be of non-specific semantics,  and  are standard names.You can also use  and  to pass in parameters from lists (or any iterable) and dicts (or any mapping), respectively.The function recieving the parameters does not have to know that they are being expanded. For example, Python 2's xrange does not explicitly expect , but since it takes 3 integers as arguments:As another example, we can use dict expansion in :You can have  after the  - for example, here,  must be given as a keyword argument - not positionally:Usage:Also,  can be used by itself  to indicate that keyword only arguments follow, without allowing for unlimited positional arguments.Here,  again must be an explicitly named, keyword argument:And we can no longer accept unlimited positional arguments because we don't have :Again, more simply, here we require  to be given by name, not positionally:In this example, we see that if we try to pass  positionally, we get an error:We must explicitly pass the  parameter as a keyword argument. (typically said \"star-args\") and  (stars can be implied by saying \"kwargs\", but be explicit with \"double-star kwargs\") are common idioms of Python for using the  and  notation. These specific variable names aren't required (e.g. you could use  and ), but a departure from convention is likely to enrage your fellow Python coders. We typically use these when we don't know what our function is going to receive or how many arguments we may be passing, and sometimes even when naming every variable separately would get very messy and redundant (but this is a case where usually explicit is better than implicit).The following function describes how they can be used, and demonstrates behavior. Note the named  argument will be consumed by the second positional argument before :We can check the online help for the function's signature, with , which tells us Let's call this function with  which prints:We can also call it using another function, into which we just provide : prints:OK, so maybe we're not seeing the utility yet. So imagine you have several functions with redundant code before and/or after the differentiating code. The following named functions are just pseudo-code for illustrative purposes.We might be able to handle this differently, but we can certainly extract the redundancy with a decorator, and so our below example demonstrates how  and  can be very useful:And now every wrapped function can be written much more succinctly, as we've factored out the redundancy:And by factoring out our code, which  and  allows us to do, we reduce lines of code, improve readability and maintainability, and have sole canonical locations for the logic in our program. If we need to change any part of this structure, we have one place in which to make each change.Let us first understand what are positional arguments and keyword arguments.\nBelow is an example of function definition with So this is a function definition with positional arguments.\nYou can call it with keyword/named arguments as well:Now let us study an example of function definition with :You can call this function with positional arguments as well:So we now know function definitions with positional as well as keyword arguments.Now let us study the '*' operator and '**' operator.Please note these operators can be used in 2 areas:a) b) The use of '*' operator and '**' operator in  Let us get straight to an example and then discuss it.So remember when the '*' or '**' operator is used in a  -'*' operator unpacks data structure such as a list or tuple  into arguments needed by function definition.'**' operator unpacks a dictionary into arguments needed by function definition.Now let us study the '*' operator use in .\nExample:In function  the '*' operator packs the received arguments into a tuple.Now let us see an example of '**' used in function definition:In function  The '**' operator packs the received arguments into a dictionary.So remember:In a  the '*'  data structure of tuple or list into positional or keyword arguments to be received by function definition.In a  the '**'  data structure of dictionary into positional or keyword arguments to be received by function definition.In a  the '*'  positional arguments into a tuple.In a  the '**'  keyword arguments into a dictionary. and  have special usage in the function argument list. \nimplies that the argument is a list and  implies that the argument\nis a dictionary. This allows functions to take arbitrary number of\nargumentsFrom the Python documentation:In Python 3.5, you can also use this syntax in , , , and  displays (also sometimes called literals). See .It also allows multiple iterables to be unpacked in a single function call.(Thanks to mgilson for the PEP link.)In addition to function calls, *args and **kwargs are useful in class hierarchies and also avoid having to write  method in Python. Similar usage is seen in frameworks like Django code.For example,A subclass can then beThe subclass then be called as Also, a subclass with a new attribute which makes sense only to that subclass instance can call the Base class  to offload the attributes setting.\nThis is done through *args and **kwargs. kwargs mainly used so that code is readable using named arguments. For example,which can be instatiated asThe complete code is I want to give an example which others haven't  mentioned* can also unpack a An example from Python3 Documentunzip_x will be [1, 2, 3], unzip_y will be [4, 5, 6]The zip() receives multiple iretable args, and return a generator. A good example of using both in a function is:This example would help you remember ,  and even  and inheritance in Python at once."},
{"link": "https://stackoverflow.com//questions/493819/python-join-why-is-it-string-joinlist-instead-of-list-joinstring", "qbody": "This has always confused me. It seems like this would be nicer:Than this:Is there a specific reason it is like this?It's because any iterable can be joined, not just lists, but the result and the \"joiner\" are always strings.E.G:Because the  method is in the string class, instead of the list class?I agree it looks funny.See :This was discussed in the  thread in the Python-Dev achive, and was accepted by Guido. This thread began in Jun 1999, and  was included in Python 1.6 (which supported Unicode) was released in Sep 2000. Python 2.0 (supported  methods including ) was released in Oct 2000.Here are some additional thoughts (my own, and my friend's):Guido's decision is recorded in a , deciding on :I agree that it's counterintuitive at first, but there's a good reason. Join can't be a method of a list because:There are actually two join methods (Python 3.0):If join was a method of a list, then it would have to inspect its arguments to decide which one of them to call. And you can't join byte and str together, so the way they have it now makes sense. This is because  is a \"string\" method! It creates a string from any iterable. If we stuck the method on lists, what about when we have iterables that aren't lists? What if you have a tuple of strings? If this were a  method, you would have to cast every such iterator of strings as a  before you could join the elements into a single string! For example:Let's roll our own list join method:And to use it, note that we have to first create a list from each iterable to join the strings in that iterable, wasting both memory and processing power:So we see we have to add an extra step to use our list method, instead of just using the builtin string method:The algorithm Python uses to create the final string with  actually has to pass over the iterable twice, so if you provide it a generator expression, it has to materialize it into a list first before it can create the final string. Thus, while passing around generators is usually better than list comprehensions,  is an exception:Nevertheless, the  operation is still semantically a \"string\" operation, so it still makes sense to have it on the  object than on miscellaneous iterables.Think of it as the natural orthogonal operation to split.I understand why it is applicable to anything iterable and so can't easily be implemented  on list.For readability, I'd like to see it in the language but I don't think that is actually feasible - if iterability were an interface then it could be added to the interface but it is just a convention and so there's no central way to add it to the set of things which are iterable.Primarily because the result of a  is a string.The sequence (list or tuple or whatever) doesn't appear in the result, just a string.  Because the result is a string, it makes sense as a method of a string."},
{"link": "https://stackoverflow.com//questions/2720014/upgrading-all-packages-with-pip", "qbody": "Is it possible to upgrade all Python packages at one time with ?Note that there is  for this on the official issue tracker.There isn't a built-in flag yet, but you can useNote: there are infinite potential variations for this. I'm trying to keep this answer short and simple, but please do suggest variations in the comments!Relevant edits:You can use the following Python code. Unlike , this will not print warnings and FIXME errors.To upgrade all local packages; you could use : is a fork of . See  mentioned by .  package works but  package no longer works. works on Windows .Works on Windows. Should be good for others too.\n($ is whatever directory you're in, in command prompt. eg. C:/Users/Username>)dothen doIf you have a problem with a certain package stalling the upgrade (numpy sometimes), just go to the directory ($), comment out the name (add a # before it) and run the upgrade again. You can later uncomment that section back.Windows version after consulting excellent  for  by Rob van der WoudeYou can just print the packages that are outdatedThe following one-liner might prove of help: keeps going if an error occurs. If you need more \"fine grained\" control over what is omitted and what raises an error you should not add the  flag and explicitly define the errors to ignore, by \"piping\" the following line for each separate error:Here is an example:This option seems to me more straightforward and readable:( selects the first word of the line (separated by a space))And this version allows for the suppression of warning message from :( removes line containing a given pattern. In my case the warning messages include \"Could not\" and \"ignored\" respectively)From  :however you need to get yolk first:This seems more concise.Explanation: gets lines like theseIn ,  sets \"space\" as the delimiter,  means to get the first column. So the above lines becomes:then pass them to  to run the command, , with each line as appending arguments limits the number of arguments passed to each command  to be 1One-liner version of @Ramana's answer.`when using a virtualenv and if you just want to upgrade packages  to your virtualenv, you may want to do:You can try this :@Ramana's worked the best for me, of those here, but I had to add a few catches:The  check excludes my development packages, because they are not located in the system site-packages directory. The try-except simply skips packages that have been removed from PyPI.@endolith: I was hoping for an easy , too, but it doesn't look like pip was meant to be used by anything but the command line (the docs don't mention the internal API, and the pip developers didn't use docstrings).Sent through ; in the meantime use this pip library solution I wrote:This seemed to work for me...I used  with a space afterwards to properly separate the package names.The rather amazing yolk makes this easy.For more info on yolk: It can do lots of things you'll probably find useful.Windows Powershell solutionMy script:I had the same problem with upgrading. Thing is, i never upgrade all packages. I upgrade only what i need, because project may break.Because there was no easy way for upgrading package by package, and updating the requirements.txt file, i wrote this  which  for the packages chosen (or all packages).Activate your virtualenv (important, because it will also install the new versions of upgraded packages in current virtualenv). into your project directory, then run:If the requirements are placed in a non-standard location, send them as arguments:If you already know what package you want to upgrade, simply send them as arguments:If you need to upgrade to  pre-release / post-release version, add  argument to your command.Full disclosure: I wrote this package.Here is my variation on rbp's answer, which bypasses \"editable\" and development distributions. It shares two flaws of the original: it re-downloads and reinstalls unnecessarily; and an error on one package will prevent the upgrade of every package after that.Related bug reports, a bit disjointed after the migration from bitbucket:I have tried the code of Ramana and I found out on Ubuntu you have to write  for each command. Here is my script which works fine on ubuntu 13.10:Isn't this more effective?here is another way of doing with a script in pythonHere is a scripts that only updates the outdated packages.    I've been using  lately. It's simple and to the point. It updates your  file to reflect the upgrades and you can then upgrade with your  file as usual.For pip3 use this:For pip, just remove the 3s as such:This solution is well designed and tested, whereas there are problems with even the most popular solutions.The above command uses the simplest and most portable pip syntax in combination with sed and sh to overcome these issues completely.  Details of sed operation can be scrutinized with the commented version.[1] Tested and regularly used in a Linux 4.8.16-200.fc24.x86_64 cluster and tested on five other Linux/Unix flavors.  It also runs on Cygwin64 installed on Windows 10.  Testing on iOS is needed.[2] To see the anatomy of the command more clearly, this is the exact equivalent of the above pip3 command with comments: [3] Upgrading a Python or PIP component that is also used in the upgrading of a Python or PIP component can be a potential cause of a deadlock or package database corruption.or even:Works fast as it is not constantly launching a shell.  I would love to find the time to get this actually using the list outdated to speed things up still more.Here is my variation:I took @Ramana's answer and made it pip3 friendly."},
{"link": "https://stackoverflow.com//questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks", "qbody": "I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.I was looking for something useful in  but I couldn't find anything obviously useful. Might've missed it, though.Related question: Here's a generator that yields the chunks you want:If you're using Python 2, you should use  instead of :Also you can simply use list comprehension instead of write a function. Python 3:Python 2 version:If you want something super simple:Directly from the (old) Python documentation (recipes for itertools):The current version, as suggested by J.F.Sebastian:I guess Guido's time machine works\u2014worked\u2014will work\u2014will have worked\u2014was working again.These solutions work because  (or the equivalent in the earlier version) creates  iterator, repeated  times in the list.  then effectively performs a round-robin of \"each\" iterator; because this is the same iterator, it is advanced by each such call, resulting in each such zip-roundrobin generating one tuple of  items.Here is a generator that work on arbitrary iterables:Example:I know this is kind of old but I don't why nobody mentioned :I'm surprised nobody has thought of using 's :Demo:This works with any iterable and produces output lazily. It returns tuples rather than iterators, but I think it has a certain elegance nonetheless. It also doesn't pad; if you want padding, a simple variation on the above will suffice:Demo:Like the -based solutions, the above  pads. As far as I know, there's no one- or two-line itertools recipe for a function that  pads. By combining the above two approaches, this one comes pretty close:Demo:I believe this is the shortest chunker proposed that offers optional padding. Simple yet elegantor if you prefer:I saw the most awesome Python-ish answer in a  of this question:You can create n-tuple for any n.It also has a lot more things, including all the recipes in the itertools documentation.None of these answers are evenly sized chunks, they all leave a runt chunk at the end, so they're not completely balanced. If you were using these functions to distribute work, you've built-in the prospect of one likely finishing well before the others, so it would sit around doing nothing while the others continued working hard.For example, the current top answer ends with:I just hate that runt at the end!Others, like , and  both return: . The 's are just padding, and rather inelegant in my opinion. They are NOT evenly chunking the iterables.Why can't we divide these better?Here's a balanced solution, adapted from a function I've used in production (Note in Python 3 to replace  with ):And I created a generator that does the same if you put it into a list:And finally, since I see that all of the above functions return elements in a contiguous order (as they were given):To test them out:Which prints out:Notice that the contiguous generator provide chunks in the same length patterns as the other two, but the items are all in order, and they are as evenly divided as one may divide a list of discrete elements.If you had a chunk size of 3 for example, you could do:source:\nI would use this when my chunk size is fixed number I can type, e.g. '3', and would never change.A generator expression:eg.I like the Python doc's version proposed by tzot and J.F.Sebastian a lot,\n but it has two shortcomings:I'm using this one a lot in my code:UPDATE: A lazy chunks version:If you know list size:If you don't (an iterator):In the latter case, it can be rephrased in a more beautiful way if you can be sure that the sequence always contains a whole number of chunks of given size (i.e. there is no incomplete last chunk).The  library has the  function for this:At this point, I think we need a , just in case...In python 2:In python 3:Also, in case of massive Alien invasion, a  might become handy:usage:Where AA is array, SS is chunk size. For example:You may also use  function of  library as:You can install  via pip:.Consider using  piecesfor example:Another more explicit version.code:result:heh, one line versionI realise this question is old (stumbled over it on Google), but surely something like the following is far simpler and clearer than any of the huge complex suggestions and only uses slicing:See Python3If you are into brackets - I picked up a book on Erlang :)"},
{"link": "https://stackoverflow.com//questions/36932/how-can-i-represent-an-enum-in-python", "qbody": "I'm mainly a C# developer, but I'm currently working on a project in Python.How can I represent the equivalent of an Enum in Python?  Enums have been added to Python 3.4 as described in .  It has also been  on pypi.  For more advanced Enum techniques try the  (2.7, 3.3+, same author as . Code is not perfectly compatible between py2 and py3, e.g. you'll need ).Installing  (no numbers) will install a completely different and incompatible version.or equivalently:In earlier versions, one way of accomplishing enums is:which is used like so:You can also easily support automatic enumeration with something like this:and used like so:Support for converting the values back to names can be added this way:This overwrites anything with that name, but it is useful for rendering your enums in output.  It will throw KeyError if the reverse mapping doesn't exist.  With the first example:Before PEP 435, Python didn't have an equivalent but you could implement your own.Myself, I like keeping it simple (I've seen some horribly complex examples on the net), something like this ...In Python 3.4 (), you can make Enum the base class.  This gets you a little bit of extra functionality, described in the PEP.  For example, enum values are distinct from integers.If you don't want to type the values, use the following shortcut:Here is one implementation:Here is its usage:If you need the numeric values, here's the quickest way:In Python 3.x you can also add a starred placeholder at the end, which will soak up all the remaining values of the range in case you don't mind wasting memory and cannot count:The best solution for you would depend on what you require from your  .If you need the  as only a list of  identifying different , the solution by  (above) is great:Using a  also allows you to set any :In addition to the above, if you also require that the items belong to a  of some sort, then embed them in a class:To use the enum item, you would now need to use the container name and the item name:For long lists of enum or more complicated uses of enum, these solutions will not suffice. You could look to the recipe by Will Ware for  published in the . An online version of that is available . has the interesting details of a proposal for enum in Python and why it was rejected.The typesafe enum pattern which was used in Java pre-JDK 5 has a\nnumber of advantages. Much like in Alexandru's answer, you create a\nclass and class level fields are the enum values; however, the enum\nvalues are instances of the class rather than small integers. This has\nthe advantage that your enum values don't inadvertently compare equal\nto small integers, you can control how they're printed, add arbitrary\nmethods if that's useful and make assertions using isinstance:A recent  pointed out there are a couple of enum libraries in the wild, including:An Enum class can be a one-liner.How to use it (forward and reverse lookup, keys, values, items, etc.)Python doesn't have a built-in equivalent to , and other answers have ideas for implementing your own (you may also be interested in the  in the Python cookbook).However, in situations where an  would be called for in C, I usually end up : because of the way objects/attributes are implemented, (C)Python is optimized to work very fast with short strings anyway, so there wouldn't really be any performance benefit to using integers. To guard against typos / invalid values you can insert checks in selected places.(One disadvantage compared to using a class is that you lose the benefit of autocomplete)So, I agree. Let's not enforce type safety in Python, but I would like to protect myself from silly mistakes. So what do we think about this?It keeps me from value-collision in defining my enums.There's another handy advantage: really fast reverse lookups:Use it like this:  if you just want unique symbols and don't care about the values, replace this line:  with this:I prefer to define enums in Python like so:It's more bug-proof than using integers since you don't have to worry about ensuring that the integers are unique (e.g. if you said Dog = 1 and Cat = 1 you'd be screwed).It's more bug-proof than using strings since you don't have to worry about typos (e.g.\nx == \"catt\" fails silently, but x == Animal.Catt is a runtime exception).On 2013-05-10, Guido agreed to accept  into the Python 3.4 standard library. This means that Python finally has builtin support for enumerations!There is a backport available for Python 3.3, 3.2, 3.1, 2.7, 2.6, 2.5, and 2.4.  It's on Pypi as .Declaration:Representation:Iteration:Programmatic access:For more information, refer to . Official documentation will probably follow soon.Hmmm... I suppose the closest thing to an enum would be a dictionary, defined either like this:orThen, you can use the symbolic name for the constants like this:There are other options, like a list of tuples, or a tuple of tuples, but the dictionary is the only one that provides you with a \"symbolic\" (constant string) way to access the \nvalue.Edit: I like Alexandru's answer too!Another, very simple, implementation of an enum in Python, using :or, alternatively,Like the method above that subclasses , this allows:But has more flexibility as it can have different keys and values. This allowsto act as is expected if you use the version that fills in sequential number values.What I use:How to use:So this gives you integer constants like state.PUBLISHED and the two-tuples to use as choices in Django models.davidg recommends using dicts.  I'd go one step further and use sets:Now you can test whether a value matches one of the values in the set like this:like dF, though, I usually just use string constants in place of enums.This is the best one I have seen: \"First Class Enums in Python\"It gives you a class, and the class contains all the enums. The enums can be compared to each other, but don't have any particular value; you can't use them as an integer value. (I resisted this at first because I am used to C enums, which are integer values. But if you can't use it as an integer, you can't use it as an integer by mistake so overall I think it is a win.) Each enum is a unique value. You can print enums, you can iterate over them, you can test that an enum value is \"in\" the enum. It's pretty complete and slick.Edit (cfi): The above link is not Python 3 compatible. Here's my port of enum.py to Python 3:From Python 3.4 there will be official support for enums. You can find documentation and examples .I have had occasion to need of an Enum class, for the purpose of decoding a binary file format. The features I happened to want is concise enum definition, the ability to freely create instances of the enum by either integer value or string, and a useful esentation.  Here's what I ended up with:A whimsical example of using it:Key features:Keep it simple:Then:I really like Alec Thomas' solution (http://stackoverflow.com/a/1695250):It's elegant and clean looking, but it's just a function that creates a class with the specified attributes.With a little modification to the function, we can get it to act a little more 'enumy':This creates an enum based off a specified type. In addition to giving attribute access like the previous function, it behaves as you would expect an Enum to with respect to types.  It also inherits the base class.For example, integer enums:Another interesting thing that can be done with this method is customize specific behavior by overriding built-in methods:The new standard in Python is , so an Enum class will be available in future versions of Python:However to begin using it now you can install the  that motivated the PEP:Then you :If you name it, is your problem, but if not creating objects instead of values allows you to do this:When using other implementations sited here (also when using named instances in my example) you must be sure you never try to compare objects from different enums. For here's a possible pitfall:Yikes!Alexandru's suggestion of using class constants for enums works quite well. I also like to add a dictionary for each set of constants to lookup a human-readable string representation. This serves two purposes: a) it provides a simple way to pretty-print your enum and b) the dictionary logically groups the constants so that you can test for membership.The enum package from  provides a robust implementation of enums. An earlier answer mentioned PEP 354; this was rejected but the proposal was implemented \n.Usage is easy and elegant:This solution is a simple way of getting a class for the enumeration defined as a list (no more annoying integer assignments):enumeration.py:example.py:While the original enum proposal, , was rejected years ago, it keeps coming back up. Some kind of enum was intended to be added to 3.2, but it got pushed back to 3.3 and then forgotten. And now there's a  intended for inclusion in Python 3.4. The reference implementation of PEP 435 is .As of April 2013, there seems to be a general consensus that  should be added to the standard library in 3.4\u2014as long as people can agree on what that \"something\" should be. That's the hard part. See the threads starting  and , and a half dozen other threads in the early months of 2013.Meanwhile, every time this comes up, a slew of new designs and implementations appear on PyPI, ActiveState, etc., so if you don't like the FLUFL design, try a .Here's an approach with some different characteristics I find valuable:and most importantly !Based closely on .Many doctests included here to illustrate what's different about this approach.I had need of some symbolic constants in pyparsing to represent left and right associativity of binary operators.  I used class constants like this:Now when client code wants to use these constants, they can import the entire enum using:The enumerations are unique, they can be tested with 'is' instead of '==', they don't take up a big footprint in my code for a minor concept, and they are easily imported into the client code.  They don't support any fancy str() behavior, but so far that is in the  category.Here is a variant on :"},
{"link": "https://stackoverflow.com//questions/735975/static-methods-in-python", "qbody": "Is it possible to have static methods in Python so I can call them without initializing a class, like:Yep, using the  decoratorNote that some code might use the old method of defining a static method, using  as a function rather than a decorator. This should only be used if you have to support ancient versions of Python (2.2 and 2.3)This is entirely identical to the first example (using ), just not using the nice decorator syntaxFinally, use  sparingly! There are very few situations where static-methods are necessary in Python, and I've seen them used many times where a separate \"top-level\" function would have been clearer.:I think that Steven is actually right. To answer the original question, then, in order to set up a class method, simply assume that the first argument is not going to be a calling instance, and then make sure that you only call the method from the class.(Note that this answer refers to Python 3.x. In Python 2.x you'll get a  for calling the method on the class itself.)For example:In this code, the \"rollCall\" method assumes that the first argument is not an instance (as it would be if it were called by an instance instead of a class). As long as \"rollCall\" is called from the class rather than an instance, the code will work fine. If we try to call \"rollCall\" from an instance, e.g.:however, it would cause an exception to be raised because it would send two arguments: itself and -1, and \"rollCall\" is only defined to accept one argument.Incidentally, rex.rollCall() would send the correct number of arguments, but would also cause an exception to be raised because now n would be representing a Dog instance (i.e., rex) when the function expects n to be numerical.This is where the decoration comes in:\nIf we precede the \"rollCall\" method withthen, by explicitly stating that the method is static, we can even call it from an instance. Now, would work. The insertion of @staticmethod before a method definition, then, stops an instance from sending itself as an argument.You can verify this by trying the following code with and without the @staticmethod line commented out.Yes, check out the  decorator:You don't really need to use the  decorator. Just declaring a method (that doesn't expect the self parameter) and call it from the class. The decorator is only there in case you want to be able to call it from an instance as well (which was not what you wanted to do)Mostly, you just use functions though...Yes, static methods can be created like this (although it's a bit more  to use underscores instead of CamelCase for methods):The above uses the decorator syntax. This syntax is equivalent to This can be used just as you described:A builtin example of a static method is  in Python 3, which was a function in the  module in Python 2.Another option that can be used as you describe is the , the difference is that the classmethod gets the class as an implicit first argument, and if subclassed, then it gets the subclass as the implicit first argument.Note that  is not a required name for the first argument, but most experienced Python coders will consider it badly done if you use anything else.These are typically used as alternative constructors. A builtin example is :Aside from the particularities of how  behave, there is a certain kind of beauty you can strike with them when it comes to organizing your module-level code..........It now becomes a bit more intuitive and self-documenting in which context certain components are meant to be used and it pans out ideally for naming distinct test cases as well as having a straightforward approach to how test modules map to actual modules under tests for purists.I frequently find it viable to apply this approach to organizing a project's utility code. Quite often, people immediately rush and create a  package and end up with 9 modules of which one has 120 LOC and the rest are two dozen LOC at best. I prefer to start with this and convert it to a package and create modules only for the beasts that truly deserve them:Perhaps the simplest option is just to put those functions outside of the class:Using this method, functions which modify or use internal object state (have side effects) can be kept in the class, and the reusable utility functions can be moved outside.Let's say this file is called . To use these, you'd call  instead of .If you really need a static method to be part of the class, you can use the  decorator."},
{"link": "https://stackoverflow.com//questions/1712227/how-to-get-the-size-of-a-list", "qbody": "How do I get the number of elements in the list?The  function can be used with a lot of types in  - both built-in types and library types.While this may not be useful due to the fact that it'd make a lot more sense as being \"out of the box\" functionality, a fairly simple hack would be to build a class with a  property:You can use it like so:Essentially, it's exactly identical to a list object, with the added benefit of having an OOP-friendly  property.As always, your mileage may vary.To find the size of a list, use the builtin function, :And now:returns 3. is implemented with , from the data model :And we can also see that  is a method of lists:returns 3.And in fact we see we can get this information for all of the described types:Answering your question as the examples also given previously:Besides  you can also use  (requires python 3.4+). For normal  both are equivalent but  makes it possible to get the length of a list-iterator, which could be useful in certain circumstances:But  is by definition only a \"hint\", so most of the time  is better.I've seen several answers suggesting accessing . This is alright when dealing with built-in classes like  but it could lead to problems with custom classes because  (and ) implement some safety checks. For example both do not allow negative lengths or lengths that exceed a certain value (the  value). So it's always safer to use the  function instead of the  method!If you need to know MEMORY USAGE of a given type, you can use the function sys.getsizeofThis function works fine for native python types\nBut if you need to analyse complex structures, have a look at .The Python  function is enough for determining a list's size. There is also the  function you can use."},
{"link": "https://stackoverflow.com//questions/663171/is-there-a-way-to-substring-a-string-in-python", "qbody": "Is there a way to substring a string in Python, to get a new string from the 3rd character to the end of the string?Maybe like ?If leaving the second part means 'till the end', if you leave the first part, does it start from the start?Python calls this concept \"slicing\" and it works on more than just strings. Take a look  for a comprehensive introduction.Just for completeness as nobody else has mentioned it.  The third parameter to an array slice is a step.  So reversing a string is as simple as:Or selecting alternate characters would be:The ability to step forwards and backwards through the string maintains consistency with being able to array slice from the start or end.Substr() normally (i.e. PHP, Perl) works this way: So the parameters are beginning and LENGTHBut Python's behaviour is different, it expects beginning and one after END (!).  So the correct replacement for Substr(s, beginning, LENGTH) isA common way to achieve this is by String slicing.  gives you a substring from index a to (b - 1)One example seems to be missing here: full (shallow) copy.This is a common idiom for creating a copy of sequence types (not of interned strings).  Shallow copies a list, See .Yes there is. Your example is very close: .. leave off the second index to go to the endYou've got it right there except for \"end\".  Its called slice notation.  Your example should read.If you leave out the second param it is implicitly the end of the string.Maybe I missed it, but I couldn't find a complete answer on this page to the original question(s) because variables are not further discussed here. So I had to go on searching.Since I'm not yet allowed to comment, let me add my conclusion here. I'm sure I was not the only one interested in it when accessing this page:  If you leave the first part, you get   And if you left the : in the middle as well you got the simplest substring, which would be the 5th character (count starting with 0, so it's the blank in this case):I would like to add two points to the discussion: No one mention about using hardcode indexes itself can be a mess. In order to avoid that, python offers a built-in object . If we want to know how many money I got left. Normal solution:Using slices:You can notice using slice you gain readabilityhere is some method to do sub string.using slicing and dicing."},
{"link": "https://stackoverflow.com//questions/17271319/how-do-i-install-pip-on-macos-or-os-x", "qbody": "I spent most of the day yesterday searching for a clear answer for installing  (package manager for Python). I can't find a good solution.How do I install it?All you need to do isYou can install it through Homebrew on OS X.  Why would you install Python with Homebrew?Homebrew is something of a package manager for OS X.  Find more details on the .  Once Homebrew is installed, run the following to install the latest Python, Pip & Setuptools:: All you have to do is:MacOS comes with  installed. But to make sure that you have  installed open the terminal and run the following command.If this command returns a version number that means  exists. That also means you already have access to  considering you are using .\u2139\ufe0f Now, all you have to do is run the following command.After that,  will be installed and you'll be able to use it for installing other packages.Let me know if you have any problems installing  this way.Complimentary GIF.Cheers! On Mac: is available on OS X via .\nOpen a terminal and type:When prompted for a password enter your normal login password.\nAfter the installation has completed you should be able to use  as expected.   The simplest solution is to follow the .Basically, this consists in:The main advantage of that solution is that it install pip for the python version that has been used to run , which means that if you use the default OS X installation of python to run  you will install pip for the python install from the system.Most solutions that use a package manager (homebrew or macport) on OS X create a redundant installation of python in the environment of the package manager which can create inconsistencies in your system since, depending on what you are doing, you may call one installation of python instead of another.I'm surprised no-one has mentioned this - it's a built-in way to install pip, without external tools or scripts:Works in pretty much the same way as , but worth knowing anyway.Installing a separate copy of Python is a popular option, even though Python already comes with MacOS. You take on the responsibility to make sure you're using the copy of Python you intend. But, the benefits are having the latest Python release and some protection from hosing your system if things go badly wrong.To install Python using :Now confirm that we're working with our newly installed Python:...should show a symbolic link to a path with \"Cellar\" in it like:Pip should be installed along with Python. You might want to upgrade it by typing:Now you're ready to install any of the 50,000+ packages on .Formerly, I've used . But, the docs warn that get-pip.py does not coordinate with package managers and may leave your system in an inconsistent state. Anyway, there's no need, given that pip is now .Note that pip isn't the only package manager for Python. There's also easy_install. It's no good to mix the two, so don't do it.Finally, if you have both Python 2 and 3 installed,  will point to whichever Python you installed last. Get in the habit of explicitly using either  or , so you're sure which Python is getting the new library.Happy hacking!You should install Brew first:Then brew install PythonThen  will workNEW 2016 December: This worked for me on  (El Capitan):Mac comes with , but not with pip.Requirements:With this I got these errors (but I've solved them in step 3):The directory  or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want .The directory  or its parent directory is not owned by the current user and caching wheels has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want .Finally you can install an app like:: If you install , pip will be installed automatically.You need only to upgrade pip, but before that you need create a virtual environment to work with Python 3. You can use a project folder or any folder:Check the versions:To deactivate the environment:Download this file: Then simply typeMake sure you are on the same directory as get-pip.py or you supply the correct path for that file.For details, you can visit: or,  Then update your PATH to include py27-pip bin directory (you can add this in ~/.bash_profile\nPATH=/opt/local/Library/Frameworks/Python.framework/Versions/2.7/bin:$PATHpip will be available in new terminal window.To install or upgrade , download  from Then run the following:\nFor example:Download python setup tools from the below website:Use the tar file.Once you download, go to the downloaded folder and run Once you do that,you will have easy_install.Use the below then to install pip:Install python3 first, then use pip3 to install packages.python3 will be installed, and pip is shipped with it. To use pip to install some package, run the followingNotice it's pip3 because you want to use python3.I recommend Anaconda to you. It`s the leading open data science platform powered by Python. There are many basic packages installed. "},
{"link": "https://stackoverflow.com//questions/68645/static-class-variables-in-python", "qbody": "Is it possible to have static class variables or methods in python? What syntax is required to do this?Variables declared inside the class definition, but not inside a method are class or static variables:As @ points out, this creates a class-level \"i\" variable, but this is distinct from any instance-level \"i\" variable, so you could haveThis is different from C++ and Java, but not so different from C#, where a static member can't be accessed using a reference to an instance.See .@Steve Johnson has already answered regarding , also documented under .@beidy recommends s over staticmethod, as the method then receives the class type as the first argument, but I'm still a little fuzzy on the advantages of this approach over staticmethod. If you are too, then it probably doesn't matter.@Blair Conrad said static variables declared inside the class definition, but not inside a method are class or \"static\" variables:There are a few gotcha's here. Carrying on from the example above:Notice how the instance variable  got out of sync with the \"static\" class variable when the attribute  was set directly on . This is because  was re-bound within the  namespace, which is distinct from the  namespace. If you want to change the value of a \"static\" variable, you must change it within the scope (or object) where it was originally defined. I put \"static\" in quotes because Python does not really have static variables in the sense that C++ and Java do.Although it doesn't say anything specific about static variables or methods, the  has some relevant information on . @Steve Johnson also answered regarding static methods, also documented under \"Built-in Functions\" in the Python Library Reference.@beid also mentioned classmethod, which is similar to staticmethod. A classmethod's first argument is the class object. Example:As the other answers have noted, static and class methods are easily accomplished using the built-in decorators:As usual, the first argument to  is bound to the class instance object. In contrast, the first argument to  is  (e.g., in this case, ). For , none of the arguments are bound, and having arguments at all is optional. However, implementing \"static variables\" (well,  static variables, anyway, if that's not a contradiction in terms...) is not as straight forward. As millerdev , the problem is that Python's class attributes are not truly \"static variables\". Consider: This is because the line  has added a new instance attribute  to  instead of changing the value of the  class  attribute.  expected static variable behavior, i.e., syncing of the attribute between multiple instances (but  with the class itself; see \"gotcha\" below), can be achieved by turning the class attribute into a property:Now you can do:The static variable will now remain in sync . (NOTE: That is, unless a class instance decides to define its own version of ! But if someone decides to do THAT, they deserve what they get, don't they???)Note that technically speaking,  is still not a 'static variable' at all; it is a , which is a special type of descriptor. However, the  behavior is now equivalent to a (mutable) static variable synced across all class instances. For immutable static variable behavior, simply omit the  setter:Now attempting to set the instance  attribute will return an : Note that the above methods only work with  of your class - they will  work . So for example: The line  produces an error, because the  attribute of  and  are two different objects. Many people will find this surprising. However, it should not be. If we go back and inspect our  class definition (the second version), we take note of this line: Clearly, the member  of  must be a  object, which is the type of object returned from the  function. If you find the above confusing, you are most likely still thinking about it from the perspective of other languages (e.g. Java or c++). You should go study the  object, about the order in which Python attributes are returned, the descriptor protocol, and the method resolution order (MRO). I present a solution to the above 'gotcha' below; however I would suggest - strenuously - that you do not try to do something like the following until - at minimum - you thoroughly understand why  causes an error. I present the (Python 3) solution below for informational purposes only. I am not endorsing it as a \"good solution\". I have my doubts as to whether emulating the static variable behavior of other languages in Python is ever actually necessary. However, regardless as to whether it is actually useful, the below should help further understanding of how Python works. A metaclass is the class of a class. The default metaclass for all classes in Python (i.e., the \"new style\" classes post Python 2.3 I believe) is . For example: However, you can define your own metaclass like this: And apply it to your own class like this (Python 3 only):Below is a metaclass I have created which attempts to emulate \"static variable\" behavior of other languages. It basically works by replacing the default getter, setter, and deleter with versions which check to see if the attribute being requested is a \"static variable\". A catalog of the \"static variables\" is stored in the  attribute. All attribute requests are initially attempted to be resolved using a substitute resolution order. I have dubbed this the \"static resolution order\", or \"SRO\". This is done by looking for the requested attribute in the set of \"static variables\" for a given class (or its parent classes). If the attribute does not appear in the \"SRO\", the class will fall back on the default attribute get/set/delete behavior (i.e., \"MRO\"). You can also add class variables to classes on the flyAnd class instances can change class variablesPersonally I would use a classmethod whenever I needed a static method. Mainly because I get the class as an argument.or use a decoratorFor static properties.. Its time you look up some python definition.. variable can always change. There are two types of them mutable and immutable.. Also, there are class attributes and instance attributes.. Nothing really like static attributes in the sense of java & c++Why use static method in pythonic sense, if it has no relation whatever to the class! If I were you, I'd either use classmethod or define the method independent from the class.One special thing to note about static properties & instance properties, shown in the example below:This means before assigning the value to instance property, if we try to access the property thru' instance, the static value is used. .Static methods in python are called s. Take a look at the following codeNotice that when we call the method , we get an error. This is because it requires that method be called on an instance of this class. The method  is set as a classmethod using the  .Just for kicks and giggles, we could call  on the class by passing in an instance of the class, like so:You could also enforce a class to be static using metaclass.Then whenever by accident you try to initialize  you'll get an StaticClassError.When define some member variable outside any member method, the variable can be either static or non-static depending on how the variable is expressed. For example:The results areIt is possible to have  class variables, but probably not worth the effort.Here's a proof-of-concept written in Python 3 -- if any of the exact details are wrong the code can be tweaked to match just about whatever you mean by a :and in use:and some tests:To avoid any potential confusion, I would like to contrast static variables and immutable objects.Some primitive object types like integers, floats, strings, and touples are immutable in Python. This means that the object that is referred to by a given name cannot change if it is of one of the aforementioned object types. The name can be reassigned to a different object, but the object itself may not be changed.Making a variable static takes this a step further by disallowing the variable name to point to any object but that to which it currently points. (Note: this is a general software concept and not specific to Python; please see others' posts for information about implementing statics in Python).Absolutely Yes,\n  Python by itself don't have any static data member explicitly, but We can have by doing so outputexplanationIn regards to this , for a  static variable, you can use a descriptor. Here's an example:resulting in ...You can always raise an exception if quietly ignoring setting value ( above) is not your thing. If you're looking for a C++, Java style static class variable:Have a look at  and the official docs  for more information about descriptors. The best way I found is to use another class. You can create an object and then use it on other objects.With the example above, I made a class named .This class should present the static var  (Private Static Var). class represented the regular class we need to use.Now I made an object for one flag (). This flag will be sent as reference to all the regular objects.All these objects are being added to the list .This Script Results:For anyone using a class factory with  and up use the  keyword to add it to the scope / context of the class being created like so:"},
{"link": "https://stackoverflow.com//questions/1720421/how-to-append-list-to-second-list-concatenate-lists", "qbody": "How do I concatenate two lists in Python?Example:Expected outcome:Python makes this ridiculously easy.It's also possible to create a generator that simply iterates over the items in both lists.  This allows you to chain lists (or any iterable) together for processing without copying the items to a new list:You can use sets to obtain merged list of unique valuesYou could also use  in order to add a  add the end of another one:This is quite simple, I think it was even shown in the :You could simply use the  or  operator as follows:Or:Also, if you want the values in the merged list to be unique you can do:Even though this is an old answer, another alternative has been introduced via the acceptance of  which deserves mentioning. The PEP, titled , generally reduced some syntactic restrictions when using the starred  expression in Python; with it, joining two lists (applies to any iterable) can now also be done with:This functionality ; from testing it in  I don't belive it has been backported to previous versions in the  family. In unsupported versions a  is going to be raised.The  to this approach is that you really don't need lists in order to perform it, anything that is iterable will do. As stated in the PEP:So while addition with  would raise a  due to type mismatch:The following won't:because it will first unpack the contents of the iterables and then simply create a  from the contents.It's worth noting that the  function accepts variable number of arguments:If an iterable (tuple, list, generator, etc.) is the input, the  class method may be used:This question directly asks about joining two lists. However it's pretty high in search even when you are looking for a way of joining many lists (including the case when you joining zero lists). Consider this more generic approach:Will output:Note, this also works correctly when  is  or .Consider better alternative suggested by Patrick Collins in the comments:With Python 3.3+ you can use :Or, if you want to support an arbitrary number of iterators:If you want to merge the two lists in sorted form, you can use merge function from the heapq library.If you don't want to or can't use the plus operator (), you can uses the   function:If you need to merge two ordered lists with complicated sorting rules, you might have to roll it yourself like in the following code (using a simple sorting rule for readability :-) ).As a more general way for more lists you can put them within a list and use  function which based on  answer is the best way for flatting a nested list :Joining two lists in Python:If you don't want any duplication:You could use the  method defined on  objects: The above code, does not preserve order, removes duplicate from each list (but not from the concatenated list)Yes, it's that simple.. This gives a new list that is the concatenation of  and .As already pointed out by many,  is the way to go if one needs to apply  to both lists. In my case, I had a label and a flag which were different from one list to the other, so I needed something slightly more complex. As it turns out, behind the scenes  simply does the following:(see ), so I took inspiration from here and wrote something along these lines:The main points to understand here are that lists are just a special case of iterable, which are objects like any other; and that  loops in python can work with tuple variables, so it is simple to loop on multiple variables at the same time. lst1 = [1,2]lst2 = [3,4]def list_combinationer(Bushisms, are_funny):list_combinationer(lst1, lst2)[1,2,3,4]you just take the values of the first and second and  add them to one variable. if I:I will have:"},
{"link": "https://stackoverflow.com//questions/2612802/how-to-clone-or-copy-a-list", "qbody": "What are the options to clone or copy a list in Python?Using  then modifies  every time  changes.\nWhy is this?With , you don't actually have two lists. The assignment just copies the reference to the list, not the actual list, so both  and  refer to the same list after the assignment.To actually copy the list, you have various possibilities:Result:Felix already provided an excellent answer, but I thought I'd do a speed comparison of the various methods:So the fastest is list slicing. But be aware that ,  and , unlike  and the python version don't copy any lists, dictionaries and class instances in the list, so if the originals change, they will change in the copied list too and vice versa.(Here's the script if anyone's interested or wants to raise any issues:): Added new-style, old-style classes and dicts to the benchmarks, and made the python version much faster and added some more methods including list expressions and .I've  that Python 3.3+  method, which should be as fast as slicing:There are two semantic ways to copy a list. A shallow copy creates a new list of the same objects, a deep copy creates a new list containing equivalent objects.A shallow copy only copies the list itself, which is a container of references to the objects in the list. If the objects contained themselves are mutable and one is changed, the change will be reflected in both lists. There are different ways to do this in Python 2 and 3. The Python 2 ways will also work in Python 3.In Python 2, the idiomatic way of making a shallow copy of a list is with a complete slice of the original:You can also accomplish the same thing by passing the list through the list constructor, but using the constructor is less efficient:In Python 3, lists get the  method:In Python 3.5: is a pointer to the actual list in memory. When you say  you're not making a copy, you're just adding another name that points at that original list in memory. We can have similar issues when we make copies of lists. The list is just an array of pointers to the contents, so a shallow copy just copies the pointers, and so you have two different lists, but they have the same contents. To make copies of the contents, you need a deep copy.To make a :To demonstrate how this allows us to make new sub-lists:And so we see that the deep copied list is an entirely different list from the original. You could roll your own function - but don't. You're likely to create bugs you otherwise wouldn't have by using the standard library's deepcopy function.You may see this used as a way to deepcopy, but don't do it:In 64 bit Python 2.7:on 64 bit Python 3.5:This answer is only for Python 2. I haven't upgraded to Python 3 yet. There are many answers already that tell you how to make a proper copy, but none of them say why your original 'copy' failed. Python doesn't store values in variables; it binds names to objects. Your original assignment took the object referred to by  and bound it to  as well. No matter which name you use there is still only one list, so changes made when referring to it as  will persist when referring to it as . Each of the other answers to this question give you different ways of creating a new object to bind to . Each element of a list acts like a name, in that each element binds non-exclusively to an object. A shallow copy creates a new list whose elements bind to the same objects as before.To take your list copy one step further, copy each object that your list refers to, and bind those element copies to a new list. This is not yet a deep copy, because each element of a list may refer to other objects, just like the list is bound to its elements. To recursively copy every element in the list, and then each other object referred to by each element, and so on: perform a deep copy. See  for more information about corner cases in copying.Use Python's idiom for doing this is All of the other contributors gave  answers, which work when you have a single dimension (leveled) list, however of the methods mentioned so far, only  works to clone/copy a list and not have it point to the nested  objects when you are working with multidimensional, nested lists (list of lists). While  refers to it in his answer, there is a little bit more to the issue and possibly a workaround using built-ins that might prove a faster alternative to .While ,  and for Py3k  work for single-leveled lists, they revert to pointing at the  objects nested within the  and the , and changes to one of the  objects are perpetuated in the other. As others have stated, there   performance issues using the  module and  . Basically what this does is make a representation of  as a string and then evaluates the string as if it were the object that the string represents. By doing this, no link to the original  object is made. A new  object is created and each variable points to its own independent object. Here is an example using a 2 dimensional nested list.If you then check the contents of each list, for example a 4 by 3 list, Python will return While this probably isn't the canonical or syntactically correct way to do it, it seems to work well. I haven't tested performance, but I am going to guess that  and  will have less overhead to run than  will. Unlike other languages have , python has .means give the list(object) a name \"a\", the just gives the same object a new name \"b\", so whenever you do something with a, the object changes and therefore b changes. The only way to make a  copy of a is to  like other answers have said.You can see more about this Here are the timing results using Python 3.6.0. Keep in mind these times are relative to one another, not absolute.I stuck to only doing shallow copies, and also added some new methods that weren't possible in Python2, such as  (the Python3 ) and  ():We can see the old winner still comes out on top, but not really by a huge amount, considering the increased readability of the Python3  approach. They all work for sliceable objects, a few work for any iterable, but only  works for any Python object.Here is the testing code for interested parties ():Another method (that I feel is fairly readable) is to turn it into a string and then switch it back to a list."},
{"link": "https://stackoverflow.com//questions/287871/print-in-terminal-with-colors-using-python", "qbody": "How can I output colored text to the terminal, in Python?\nWhat is the best Unicode symbol to represent a solid block?This somewhat depends on what platform you are on. The most common way to do this is by printing ANSI escape sequences. For a simple example, here's some python code from the :To use code like this, you can do something like This will work on unixes including OS X, linux and windows (provided you use , or in Windows 10 provided you enable ). There are ansi codes for setting the color, moving the cursor, and more.If you are going to get complicated with this (and it sounds like you are if you are writing a game), you should look into the \"curses\" module, which handles a lot of the complicated parts of this for you. The  is a good introduction.If you are not using extended ASCII (i.e. not on a PC), you are stuck with the ascii characters below 127, and '#' or '@' is probably your best bet for a block. If you can ensure your terminal is using a IBM , you have many more options. Characters 176, 177, 178 and 219 are the \"block characters\".Some modern text-based programs, such as \"Dwarf Fortress\", emulate text mode in a graphical mode, and use images of the classic PC font. You can find some of these bitmaps that you can use on the  see ().The  has more resources for doing graphics in text mode.Hmm.. I think got a little carried away on this answer. I am in the midst of planning an epic text-based adventure game, though. Good luck with your colored text!I'm surprised no one has mentioned the . Usage is pretty simple:It may not be sophisticated enough, however, for game programming and the \"colored blocks\" that you want to do...The answer is  for all cross-platform coloring in Python.Print a string that starts a color/style, then the string, then end the color/style change with :Get a table of format options for shell text with following code:You want to learn about ANSI escape sequences. Here's a brief example:For more info see For a block character, try a unicode character like \\u2588:Putting it all together:My favorite way is with the  library (full disclosure: I wrote it). For example:To print colored bricks, the most reliable way is to print spaces with background colors. I use this technique to draw the progress bar in :You can print in specific locations as well:If you have to muck with other terminal capabilities in the course of your game, you can do that as well. You can use Python's standard string formatting to keep it readable:The nice thing about Blessings is that it does its best to work on all sorts of terminals, not just the (overwhelmingly common) ANSI-color ones. It also keeps unreadable escape sequences out of your code while remaining concise to use. Have fun!Try this simple code On Windows you can use module 'win32console' (available in some Python distributions) or module 'ctypes' (Python 2.5 and up) to access the Win32 API.To see complete code that supports both ways, see the  from .ctypes example:generated a class with all the colors using a for loop to iterate every combination of color up to 100, then wrote a class with python colors. Copy and paste as you will, GPLv2 by me:I have wrapped @joeld answer into a module with global functions that I can use anywhere in my code.file: log.py     use as follows:I use the colorama module for coloured terminal printing in Python. A link is here Some example code of printing red and green text:I used colorama to write a basic Matrix programInstallation on Ubuntu (your distribution install command may be different)Stupidly simple based on @joeld's answerThen justDefine a string that starts a color and a string that ends the color, then print your text with the start string at the front and the end string at the end.This produces the following in , in  with a Zenburn-style color scheme:Through experemintation, we can get more colors:Note:  and  are blinking.This way we can create a full color collection:Here is the code to generate the test:For Windows you cannot print to console with colors unless you're using the win32api.For Linux it's as simple as using print, with the escape sequences outlined here:For the character to print like a box, it really depends on what font you are using for the console window. The pound symbol works well, but it depends on the font:uses ANSI  Make your function :-Call function :- Note :- not required any module note how well the  keyword mixes with modifiers like these that need to be reset (using Python 3 and Colorama):You can use the Python implementation of the curses library:\nAlso, run this and you'll find your box:You could use :.If you are programming a game perhaps you would like to change the background color and use only spaces? For example:Here's a curses example:while i find  answer useful, i modified it a bit. this  is the resultin addition you can wrap common usages:I ended up doing this, I felt it was cleanest: If you are using Windows, then here you go!If you are using  snapshot:(I generally use colored output for debugging on runserver terminal so I added it.)Give it a Try!! provides a portable support for building text UI and animations:Asciicast:Yet another pypi module that wraps the python 3 print function:It's usable in python 2.x if you also .I wrote a simple module, available at:\nIt works with Windows, Mac OS X and Linux.\nIt uses ANSI for Linux and Mac, but native calls to console functions on Windows.\nYou have colors, cursor positioning and keyboard input. It is not a replacement for curses, but can be very useful if you need to use in simple scripts or ASCII games.Your terminal most probably uses Unicode (typically UTF-8 encoded) characters, so it's only a matter of the appropriate font selection to see your favorite character. Unicode char U+2588, \"Full block\" is the one I would suggest you use.Try the following:Examine the file later with your favourite viewer. is the module you want to use. Check this .I wrote a module that handles colors in Linux/OSX/Windows. It supports all 16 colors on all platforms, you can set foreground and background colors at different times, and the string objects give sane results for things like len() and .capitalize()."},
{"link": "https://stackoverflow.com//questions/3277503/how-do-i-read-a-file-line-by-line-into-a-list", "qbody": "How do I read every line of a file in Python and store each line as an element in a list? I want to read the file line by line and append each line to the end of the list.I'm guessing that you meant  and not array.See :or with stripping the newline character:This is more explicit than necessary, but does what you want.This will yield an \"array\" of lines from the file.If you want the  included:If you do not want  included:You could simply do the following, as has been suggested:Note that this approach has 2 downsides:1) You store all the lines in memory. In the general case, this is a very bad idea. The file could be very large, and you could run out of memory. Even if it's not large, it is simply a waste of memory.2) This does not allow processing of each line as you read them. So if you process your lines after this, it is not efficient (requires two passes rather than one).A better approach for the general case would be the following:Where you define your process function any way you want. For example:(The implementation of the  class is left as an exercise for you).This will work nicely for any file size and you go through your file in just 1 pass. This is typically how generic parsers will work.if you don't care about closing the file, this one-liner works:The  way:Using  (recommended):This should encapsulate the open command. First and foremost, you should focus on opening your file and reading its contents in an efficient and pythonic way. Here is an example of the way I personally DO NOT prefer:Instead, I prefer the below method of opening files for both reading and writing as it\nis very clean, and does not require an extra step of closing the file\nonce you are done using it. In the statement below, we're opening the file\nfor reading, and assigning it to the variable 'infile.'  Once the code within\nthis statement has finished running, the file will be automatically closed.Now we need to focus on bringing this data into a  because they are iterable, efficient, and flexible.  In your case, the desired goal is to bring each line of the text file into a separate element. To accomplish this, we will use the  method as follows:I'd do it like this.Here's one more option by using list comprehensions on files;This should be more efficient way as the most of the work is done inside the Python interpreter.Another option is , for example:This will make  a NumPy array with as many rows as are in your file.If you'd like to read a file from the command line or from stdin, you can also use the  module:Pass files to it like so:Read more here: A simple way is to:In one line, that would give:Now variable out is a list (array) of what you want. You could either do:oryou'll get the same results.Just use the splitlines() functions. Here is an example.In the output you will have the list of lines.A real easy way:If you want to make it a fully-fledged program, type this in:For some reason, it doesn't read .py files properly.To my knowledge Python doesn't have a native array data structure. But it does support the list data structure which is much simpler to use than an array.Could also use the loadtxt command in numpy. This checks for fewer conditions than genfromtxt so it may be faster. Use this: is a dataframe type, and uses values to get ndarray. You can also get a list by using .If you want to are faced with a  and want to  (imagine you are in a Topcoder/Hackerrank coding competition), you might read a considerably bigger chunk of lines into a memory buffer at one time, rather than just iterate line by line at file level.:put this code (save it as read_txt.py) in the same dir and execute it: python read_txt.pyyou will get thisif you are in the console and you'll get thisYou can just open your file for reading using\nfile1=open(\"filename\",\"r\")\nand for reading use\nlines=file1.readlines()\nThe list lines will contain all your lines as individual elements and you can call a specific element using lines[\"linenumber-1\"] as python starts its counting from 0.This should answer your question. The replace function will act as delimiter to strip the file.\"textFileLines\" is the array you wantedHow about:Declare a Unix-like method:And just invoke it to get the file content."},
{"link": "https://stackoverflow.com//questions/379906/parse-string-to-float-or-int", "qbody": "In Python, how can I parse a numeric string like  to its corresponding float value, ? Or parse the string  to an integer, ?I just want to know how to parse a float string to a float, and (separately) an int string to an int.A longer and more accurate name for this function could be: You think you know what numbers are? You are not so good as you think! Not big surprise.This is another method which deserves to be mentioned here, :That is, a safe 'eval'You should consider the possibility of commas in the string representation of a number, for cases like   which throws an exception. Instead, use methods in  to convert the strings to numbers and interpret commas correctly. The  method converts to a float in one step once the locale has been set for the desired number convention. In the United States and the UK, commas can be used as a thousands separator.  In this example with American locale, the comma is handled properly as a separator:In the ,  commas are used for decimal marks instead of periods.  In this example with French locale, the comma is correctly handled as a decimal mark:The method  is also available, but the argument should be an integer.Users  and  are correct, but keep in mind if you know the string is an integer (for example, 545) you can call int(\"545\") without first casting to float.If your strings are in a list, you could use the map function as well. It is only good if they're all the same type.The question seems a little bit old. But let me suggest a function, parseStr, which makes something similar, that is, returns integer or float and if a given ASCII string cannot be converted to none of them it returns it untouched. The code of course might be adjusted to do only what you want:It's good that you ask to do these separately. If you're mixing them, you may be setting yourself up for problems later. The simple answer is:Conversions from various bases, and you should know the base in advance (10 is the default). Note you can prefix them with what Python expects for its literals (see below) or remove the prefix:If you don't know the base in advance, but you do know they will have the correct prefix, Python can infer this for you if you pass  as the base:If your motivation is to have your own code clearly represent hard-coded specific values, however, you may not need to convert from the bases - you can let Python do it for you automatically with the correct syntax.You can use the apropos prefixes to get automatic conversion to integers with . These are valid for Python 2 and 3:Binary, prefix Octal, prefix Hexadecimal, prefix This can be useful when describing binary flags, file permissions in code, or hex values for colors - for example, note no quotes:If you see an integer that starts with a 0, in Python 2, this is (deprecated) octal syntax.It is bad because it looks like the value should be . So in Python 3, it now raises a :Convert your Python 2 octals to octals that work in both 2 and 3 with the  prefix:If you aren't averse to third-party modules, you could check out the  module. It provides a function called  that does exactly what this question is asking for and does it faster than a pure-Python implementation: and The  parser can help you figure out what datatype your string is. Use , and then you can use  to test for type:You need to take into account rounding to do this properly.I.e. int(5.1) => 5\n     int(5.6) => 5  -- wrong, should be 6 so we do int(5.6 + 0.5) => 6 of \nThis will try to parse a string and return either  or  depending on what the string represents.\nIt might rise parsing exceptions or .Use:This is the most Pythonic way I could come up with. Use:Here's another interpretation of your question (hint: it's vague). It's possible you're looking for something like this:It works like this...Theoretically, there's an injection vulnerability. The string could, for example be . Without any background on where the string comes from, however, the possibility is theoretical speculation.  Since the question is vague, it's not at all clear if this vulnerability actually exists or not."},
{"link": "https://stackoverflow.com//questions/6470428/catch-multiple-exceptions-in-one-line-except-block", "qbody": "I know that I can do:I can also do this:But if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:Is there any way that I can do something like this (since the action to take in both exceptions is to ):Now this really won't work, as it matches the syntax for:So, my effort to catch the two distinct exceptions doesn't exactly come through.Is there a way to do this?From :Separating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using .To do this in a manner currently and forward compatible with Python, you need to separate the Exceptions with commas and wrap them with parentheses to differentiate from earlier syntax that assigned the exception instance to a variable name by following the Exception type to be caught with a comma. Here's an example of simple usage: I'm currently wrapping the  in my interactive command-line  program with a catch for KeyboardInterrupt and EOFError so that the user can leave an interactive keyboard input session semi-gracefully with + or +:I'm specifying these exceptions to avoid hiding bugs, which if I encounter I expect the full stack trace from.This is documented here: You can assign the exception to a variable, ( is common, but you might prefer a more verbose variable if you have long exception handling or your IDE only highlights selections larger than that, as mine does.) The instance has an args attribute. Here is an example:Note that in Python 3, the  object falls out of scope when the  block is concluded.You may see code that assigns the error with a comma. This usage, the only form available in Python 2.5 and earlier, is deprecated, and if you wish your code to be forward compatible in Python 3, you should update the syntax to use the new form:For python 2.5 and earlier versions, the correct syntax is:Where  is the Exception instance.From :"},
{"link": "https://stackoverflow.com//questions/510348/how-can-i-make-a-time-delay-in-python", "qbody": "I would like to know how to put a time delay in a Python script.Here is another example where something is run once a minute:You can use the sleep() function in the time module. It can take a float argument for sub second resolution.Please read , which can help you further:A bit of fun with sleepy generator.The question is about time delay. It can be fixed time, but in some cases we might need a delay measured since last time. Here is one possible solutions:The situation can be, we want to do something as regularly as possible and we do not want to bother with all the ,  stuff all around our code.Following code () defines  gerenaratorand running it we see:We can also use it directly in a loop:and running it we might see:As we see, this buzzer is not too rigid and allow us to catch up regular sleepy intervals even if we oversleep and get out of regular schedule.N.B. (Just in case you haven't heard of it, tkinter is an interactive tool which you can import. Basically, you can create buttons and boxes and popups and stuff that appear as windows which you manipulate with code.)If you use tkinter, DO NOT USE TIME.SLEEP() because it will muck up your program. This happened to me. Instead, use root.after() and replace the values for however many seconds, with a milliseconds. E.g, time.sleep(1) is equivalent to root.after(1000) on tkinter.Otherwise, time.sleep(), which many answers have pointed out, is the way to go."},
{"link": "https://stackoverflow.com//questions/3294889/iterating-over-dictionaries-using-for-loops", "qbody": "I am a bit puzzled by the following code:What I don't understand is the  portion. How does Python recognize that it needs only to read the key from the dictionary? Is  a special word in Python? Or is it simply a variable? is just a variable name.  will simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:For Python 2.x:For Python 3.x:To test for yourself, change the word  to .For Python 3.x,  has been replaced with simply , which returns a set-like view backed by the dict, like  but even better. \nThis is also available in 2.7 as . The operation  will work for both 2 and 3, but in 2 it will return a list of the dictionary's  pairs, which will not reflect changes to the dict that happen after the  call. If you want the 2.x behavior in 3.x, you can call .It's not that key is a special word, but that dictionaries implement the iterator protocol.  You could do this in your class, e.g. see  for how to build class iterators.In the case of dictionaries, it's implemented at the C level.  The details are available in .  In particular, the section titled \"Dictionary Iterators\":Iterating over a  iterates through its keys in no particular order, as you can see here:For your example, it is a better idea to use :This gives you a list of tuples. When you loop over them like this, each tuple is unpacked into  and  automatically:Using  and  as variable names when looping over a  is quite common if the body of the loop is only a few lines. For more complicated loops it may be a  good idea to use more descriptive names:It's a good idea to get into the habit of using format strings:When you iterate through dictionaries using the -syntax, it always iterates over the keys (the values are accessible using ).To iterate over key-value pairs, use .  is simply a variable.You can do this:... or better,This is a very common looping idiom.  is an operator. For when to use  and when it must be  see .You can use this:To iterate over keys, it is slower but better to use . If you tried to do something like this:it would create a runtime error because you are changing the keys while the program is running. If you are absolutely set on reducing time, use the  way, but you have been warned ;). I have a use case where I have to iterate through the dict to get the key, value pair, also the index indicating where I am. This is how I do it:Note that the parentheses around the key, value is important, without the parentheses, you get an ValueError \"not enough values to unpack\"."},
{"link": "https://stackoverflow.com//questions/415511/how-to-get-current-time-in-python", "qbody": "What is the module/method used to get current time?And just the time:The same but slightly more compact:See the  for more info.To save typing, you can import the  object from the  module:Then remove the leading  from all the above.You can use :    Similar to , but use the  function for a quick-n-dirty, slightly more human readable format:For this example, the output will be like this: The format for  is at:\nDoThere is some difference for Unix and Windows platforms.The  module provides functions that tells us the time in \"seconds since the epoch\" as well as other utilities.This is the format you should get timestamps in for saving in databases. It is a simple floating point number that can be converted to an integer. It is also good for arithmetic in seconds, as it represents the number of seconds since Jan 1, 1970 00:00:00, and it is memory light relative to the other representations of time we'll be looking at next:This timestamp does not account for leap-seconds, so it's not linear - leap seconds are ignored. So while it is not equivalent to the international UTC standard, it is close, and therefore quite good for most cases of record-keeping. This is not ideal for human scheduling, however. If you have a future event you wish to take place at a certain point in time, you'll want to store that time with a string that can be parsed into a datetime object or a serialized datetime object (these will be described later).You can also represent the current time in the way preferred by your operating system (which means it can change when you change your system preferences, so don't rely on this to be standard across all systems, as I've seen others expect). This is typically user friendly, but doesn't typically result in strings one can sort chronologically:You can hydrate timestamps into human readable form with  as well:This conversion is also not good for record-keeping (except in text that will only be parsed by humans - and with improved Optical Character Recognition and Artificial Intelligence, I think the number of these cases will diminish).The  module is also quite useful here:The  is a class method that returns the current time. It uses the  without the timezone info (if not given, otherwise see timezone aware below). It has a representation (which would allow you to recreate an equivalent object) echoed on the shell, but when printed (or coerced to a ), it is in human readable (and nearly ISO) format, and the lexicographic sort is equivalent to the chronological sort:You can get a datetime object in UTC time, a global standard, by doing this:UTC is a time standard that is nearly equivalent to the GMT timezone. (While GMT and UTC do not change for Daylight Savings Time, their users may switch to other timezones, like British Summer Time, during the Summer.) However, none of the datetime objects we've created so far can be easily converted to various timezones. We can solve that problem with the  module:Equivalently, in Python 3 we have the  class with a utc  instance attached, which also makes the object timezone aware (but to convert to another timezone without the handy  module is left as an exercise to the reader):And we see we can easily convert to timezones from the original utc object.You can also make a naive datetime object aware with the  timezone  method, or by replacing the tzinfo attribute (with , this is done blindly), but these are more last resorts than best practices:The  module allows us to make our  objects timezone aware and convert the times to the hundreds of timezones available in the  module.One could ostensibly serialize this object for UTC time and store  in a database, but it would require far more memory and be more prone to error than simply storing the Unix Epoch time, which I demonstrated first. The other ways of viewing times are much more error prone, especially when dealing with data that may come from different time zones. You want there to be no confusion as to which timezone a string or serialized datetime object was intended for.If you're displaying the time with Python for the user,  works nicely, not in a table (it doesn't typically sort well), but perhaps in a clock. However, I personally recommend, when dealing with time in Python, either using Unix time, or a timezone aware UTC  object. That outputs the current GMT in the specified format. There is also a localtime() method. This  has more details.All good suggestions, but I find it easiest to use  myself:This gives a nicely formatted string representation of current local time.why not just keep things simple. If you need current time as a  object:I'll contribute to this because  is in the documentation but not yet here\n(this is mighty similar to @Ray Vega's answer):Quickest way isThis is what I ended up going with: Also, this table is a necessary reference for choosing the appropriate format codes to get the date formatted just the way you want it (from Python \"datetime\" documentation ).Why not ask the , the official timekeeper of the United States Navy?If you live in the D.C. area (like me) the latency might not be too bad... returns the current time as a naive datetime object that represents time in the local timezone. That value may be ambiguous e.g., during DST transitions (\"fall back\"). To avoid ambiguity either UTC timezone should be used:Or a timezone-aware object that has the corresponding timezone info attached (Python 3.2+):Try the arrow module from or the utc versionto change it's output add .format()for a specific timezone?an hour agoor if you want the gist.You can use the time module.The use of the captial  gives the full year, using  would give You could also use to give a more lengthy time.do  or any variables including the package, you can get all the attributes and methods associated to the variable.This is what i use to get the time without having to format , some people dont like the split method but it is useful here :Will print in HH:MM:SS formatI am a simple man and i want time with milliseconds. Simple way to get them:But i want , right? Shortest way to get them:Add or remove zeroes from the last multiplication to adjust number of decimal points, or just:date will print date and time will print time."},
{"link": "https://stackoverflow.com//questions/952914/making-a-flat-list-out-of-list-of-lists-in-python", "qbody": "I wonder whether there is a shortcut to make a simple list out of list of lists in Python.I can do that in a for loop, but maybe there is some cool \"one-liner\"? I tried it with , but I get an error.is faster than the shortcuts posted so far. ( is the list to flatten.)Here is a the corresponding function:For evidence, as always, you can use the  module in the standard library:Explanation: the shortcuts based on  (including the implied use in ) are, of necessity,  when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So (for simplicity and without actual loss of generality) say you have L sublists of I items each: the first I items are copied back and forth L-1 times, the second I items L-2 times, and so on; total number of copies is I times the sum of x for x from 1 to L excluded, i.e., .The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.You can use :or, on Python >=2.6, use  which doesn't require unpacking the list:This approach is arguably more readable than  and appears to be faster too:Note that only works on lists of lists. For lists of lists of lists, you'll need another solution.@Nadia: You have to use much longer lists. Then you see the difference quite strikingly!\nMy results for where:The  method in your example modifies  instead of returning a useful value (which  expects).A faster way to do the  version would be The sum version is still running for more than a minute and it hasn't done processing yet!For medium lists:Using small lists and timeit: number=1000000Why do you use extend?This should work fine.There seems to be a confusion with ! When you add two lists together, the correct term for that is , not add.  is what you need to use.If you're thinking functional, it is as easy as this::You see reduce respects the sequence type, so when you supply a tuple, you get back a tuple. let's try with a list::Aha, you get back a list.How about performance::from_iterable is pretty fast! But it's no comparison to reduce with concat.Here is a general approach that applies to lists of lists, numbers strings, and other mixed containers types.This solution employs Python 3's powerful  keyword, which extracts items from sub-generators.    UPDATE: Now supports strings.  REF: solution modified from The reason your function didn't work: the extend extends array in-place and doesn't return it. You can still return x from lambda, using some trick:Note: extend is more efficient than + on lists.An bad feature of Anil's function above is that it requires the user to always manually specify the second argument to be an empty list . This should instead be a default. Due to the way Python objects work, these should be set inside the function, not in the arguments.Here's a working function:Testing:One can also use NumPy's :Edit 11/02/2016: Only works when sublists have identical dimensions.Fastest solution I have found (for large list anyway):Done! You can of course turn it back into a list by executing list(l)If you want to flatten a data-structure where you don't know how deep it's nested you could use It's a generator so you need to cast the result to a  or explicitly iterate over it.To flatten only one level and if each of the items is itself iterable you can also use  which itself is just a thin wrapper around :Consider installing the  package.It ships with an implementation for  (, from the ):As of version 2.4, you can flatten more complicated, nested iterables with  (, contributed by  abarnet).If you are willing to give up a tiny amount of speed for a cleaner look, then you could use  or :You can find out more here in the docs  and Simple code for  package fanIt solves all flatten problems (none list item or complex nesting)You can install  with pipCleaned up @Deleet exampleExample: "},
{"link": "https://stackoverflow.com//questions/1024847/add-new-keys-to-a-dictionary", "qbody": "Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an  method.I feel like consolidating info about Python dictionaries:Feel free to add more!Yeah, it's pretty easy. Just do the following:Yes it is possible, and it does have a method that implements this, but you don't want to use it directly.To demonstrate how and how not to use it, let's create an empty dict with the dict literal, :To update this dict with a single new key and value, you can use  that provides for item assignment:  is now:We can also update the dict with multiple values efficiently as well using .  We may be unnecessarily creating an extra  here, so we hope our  has already been created and came from or was used for another purpose: is now:Another efficient way of doing this with the update method is with keyword arguments, but since they have to be legitimate python words, you can't have spaces or special symbols or start the name with a number, but many consider this a more readable way to create keys for a dict, and here we certainly avoid creating an extra unnecessary :and  is now:So now we have covered three Pythonic ways of updating a . There's another way of updating a  that you shouldn't use, which uses the  method. Here's an example of how one might use the  method to add a key-value pair to a , and a demonstration of the poor performance of using it:So we see that using the subscript notation is actually much faster than using . Doing the Pythonic thing, that is, using the language in the way it was intended to be used, usually is both more readable and computationally efficient.If you want to add a dictionary within a dictionary you can do it this way. Example: Add a new entry to your dictionary & sub dictionary Python requires that you first add a sub  before adding entries.The orthodox syntax is , but if your keyboard is missing the square bracket keys you could do:In fact, defining  and  methods is how you can make your own class support the  square bracket syntax. See you can create onegives addresses  methods of merging dictionaries  and .Here are some of the more straightforward methods (tested in Python 3)..., the  dictionary would contain only that one element...This is equivalent to...results in This is exactly how I would do it:\n    # fixed data with sapceThis works for me. Enjoy!we can add new keys to dictionary by this way:Here is the Example:Output:It has a update method which you can use like this:"},
{"link": "https://stackoverflow.com//questions/101268/hidden-features-of-python", "qbody": "What are the lesser-known but useful features of the Python programming language?In case you're thinking it's doing , which comes out as , and then comparing , which is also , then no, that's really not what happens (see the last example.) It's really translating into , and , but with less typing and each term is only evaluated once.Regular expressions are a great feature of python, but debugging them can be a pain, and it's all too easy to get a regex wrong.Fortunately, python can print the regex parse tree, by passing the undocumented, experimental, hidden flag  (actually, 128) to .Once you understand the syntax, you can spot your errors.  There we can see that I forgot to escape the  in .Of course you can combine it with whatever flags you want, like commented regexes:Wrap an iterable with enumerate and it will yield the item along with its index.For example:References:If you write you can get out the generator and assign it to x. Now it means you can doThe advantage of this is that you don't need intermediate storage, which you would need if you didIn some cases this can lead to significant speed up.You can append many if statements to the end of the generator, basically replicating nested for loops:For instance:The  function repeatedly calls  and yields its result until  is returned. Instead, you should use a sentinel value denoting \"not given\" and replace with the mutable you'd like as default:. For example having this function:You can:If you don't like using whitespace to denote scopes, you can use the C-style {} by issuing:The step argument in slice operators. For example:The special case  is a useful idiom for 'x reversed'. allow to wrap a function or method in another function that can add functionality, modify arguments or results, etc. You write decorators one line above the function definition, beginning with an \"at\" sign (@).Example shows a  decorator that prints the decorated function's arguments before calling it:The for...else syntax (see  )The \"else\" block will be normally executed at the end of the for loop, unless the break is called.The above code could be emulated as follows:From 2.5 onwards dicts have a special method  that is invoked for missing items:There is also a dict subclass in  called  that does pretty much the same but calls a function without arguments for not existing items:I recommend converting such dicts to regular dicts before passing them to functions that don't expect such subclasses.  A lot of code uses  and catches KeyErrors to check if an item exists which would add a new item to the dict.The right-hand side of the assignment is an expression that creates a new tuple. The left-hand side of the assignment immediately unpacks that (unreferenced) tuple to the names  and .After the assignment, the new tuple is unreferenced and marked for garbage collection, and the values bound to  and  have been swapped.As noted in the ,In Python you can split a regular expression over multiple lines, name your matches and insert comments.Example verbose syntax (from ):Example naming matches (from )You can also verbosely write a regex without using  thanks to string literal concatenation.You can unpack a list or a dictionary as function arguments using  and .For example:Very useful shortcut since lists, tuples and dicts are widely used as containers.ROT13 is a valid encoding for source code, when you use the right coding declaration at the top of the code file:which is exactly the same asProbably not the most useful thing, but nice to know.: Fixed name of new type, should be  to be the exact same thing as with  statement.: Adjusted the title to more accurately describe the feature.Introduced in , a  is an object that acts as a run-time context for a suite of statements.Since the feature makes use of new keywords, it is introduced gradually: it is available in Python 2.5 via the  directive. Python 2.6 and above (including Python 3) has it available by default.I have used the  a lot because I think it's a very useful construct, here is a quick demo:What's happening here behind the scenes, is that the  calls the special  and  methods on the file object. Exception details are also passed to  if any exception was raised from the with statement body, allowing for exception handling to happen there.What this does for you in this particular case is that it guarantees that the file is closed when execution falls out of scope of the  suite, regardless if that occurs normally or whether an exception was thrown. It is basically a way of abstracting away common exception-handling code.Other common use cases for this include locking with threads and database transactions. Dictionaries have a 'get()' method. If you do d['key'] and key isn't there, you get an exception. If you do d.get('key'), you get back None if 'key' isn't there. You can add a second argument to get that item back instead of None, eg: d.get('key', 0).It's great for things like adding up numbers:They're the magic behind a whole bunch of core Python features. When you use dotted access to look up a member (eg, x.y), Python first looks for the member in the instance dictionary. If it's not found, it looks for it in the class dictionary. If it finds it in the class dictionary, and the object implements the descriptor protocol, instead of just returning it, Python executes it. A descriptor is any class that implements the , , or  methods.Here's how you'd implement your own (read-only) version of property using descriptors:and you'd use it just like the built-in property():Descriptors are used in Python to implement properties, bound methods, static methods, class methods and slots, amongst other things. Understanding them makes it easy to see why a lot of things that previously looked like Python 'quirks' are the way they are.Raymond Hettinger has  that does a much better job of describing them than I do.It does exactly what it sounds like: \"assign 3 to x if y is 1, otherwise assign 2 to x\". Note that the parens are not necessary, but I like them for readability. You can also chain it if you have something more complicated:Though at a certain point, it goes a little too far.Note that you can use if ... else in any expression. For example:Here func1 will be called if y is 1 and func2, otherwise. In both cases the corresponding function will be called with arguments arg1 and arg2.Analogously, the following is also valid:where class1 and class2 are two classes.Example extracted from the Python documentation:% -formatting takes a dictionary (also applies %i/%s etc. validation).And since locals() is also a dictionary, you can simply pass that as a dict and have % -substitions from your local variables. I think this is frowned upon, but simplifies things..To add more python modules (espcially 3rd party ones), most people seem to use PYTHONPATH environment variables or they add symlinks or directories in their site-packages directories. Another way, is to use *.pth files. Here's the official python doc's explanation:Exception  clause:The use of the else clause is better than adding additional code to the try clause because it avoids accidentally catching an exception that wasn\u2019t raised by the code being protected by the try ... except statement.See :The 'raise' statement with no arguments inside an error handler tells Python to re-raise the exception , allowing you to say \"oh, sorry, sorry, I didn't mean to catch that, sorry, sorry.\"If you wish to print, store or fiddle with the original traceback, you can get it with sys.exc_info(), and printing it like Python would is done with the 'traceback' module.:You will also have to set a PYTHONSTARTUP environment variable.Nested list comprehensions and generator expressions:These can replace huge chunks of nested-loop code.More detail from the standard library reference: "},
{"link": "https://stackoverflow.com//questions/101754/is-there-a-way-to-run-python-on-android", "qbody": "We are working on an  version and this platform has a nice Python API. However, there is nothing official about Python on Android, but since  exists, is there a way to let the snake and the robot work together?One way is to use :  There is also the new  (ASE) project. It looks awesome, and it has some integration with native Android components. An example  -- \"here\u2019s a barcode scanner written in six lines of Python code:There's also  written by a Google employee.The examples include a complete game packaged in an APK, which is pretty interesting. I've posted instructions and a patch for cross compiling Python 2.7.2 for Android, you can get it at my blog here: EDIT: I've open sourced , my 2D Game Engine, it's Python/SDL based and it cross compiles for Android. Even if you don't use it for games, you might get useful ideas from the code and the builder utility (named Schafer, after Tim...you know who).As a  lover and Android programmer, I am sad to say this is not really a good way to go. There are two problems.One problem is that there is a lot more than just a programming language to the Android development tools. A lot of the Android graphics involve XML files to configure the display, similar to HTML. The built-in java objects are really integrated with this XML layout, and it's a lot easier than writing your own code to go from logic to bitmap.The other problem is that the G1 (and probably other Android devices for the near future) are really not that fast. 200 MHz processors, and RAM is very limited. Even in Java you have to do a decent amount of rewriting-to-avoid-more-object-creation if you want to make your app perfectly smooth. Python is going to be too slow for a while still on mobile devices. does what you want. You can easily install it directly onto your device from their site, and do not need root.It supports a range of languages; Python is the most mature. By default, it uses Python 2.6, but there is a  you can use instead. I have used that port for all kinds of things on a Galaxy S2 and it worked fine.SL4A provides a port of their  library for each supported language. The library provides an interface to the underlying Android API through a single  object.Each language has pretty much the same API. You can even use the JavaScript API inside webviews.For user interfaces, you have three options:You can mix options, so you can have a webview for the main interface, and still use native dialogues.There is a third party project named . It builds on SL4A, and throws in some other useful stuff.QPython gives you a nicer UI to manage your installation, and includes a little, touchscreen code editor, a Python shell, and a PIP shell for package management. They also have a Python 3 port. Both versions are available from the Play Store, free of charge. QPython also bundles libraries from a bunch of Python on Android projects, including Kivy, so it is not just SL4A.Note that QPython still develop their fork of SL4A (though, not much to be honest). The main SL4A project itself is pretty much dead.Not at the moment and you would be lucky to get Jython to work soon. If you're planning to start your development now you would be better off with just sticking to Java for now on.Using SL4A (which has already been mentioned by itself in other answers) you can  a full-blown  instance (other  are likely candidates as well).  SL4A doesn't allow you to do native UI components (buttons, scroll bars, and the like), but it does support .  A WebView is basically nothing more than a striped down web browser pointed at a fixed address. I believe the native Gmail app uses a WebView instead of going the regular widget route.  This route would have some interesting features:I use the QPython application. It has an editor, a console, and you can run your Python programs with it. The application is free, and the link is .I want to post this as an extension to what  has already answered ()It has been years since then, and  has also  to , the biggest selling point of  in my opinion is its cross-platform compatibility, you can code and test under your local environment , you can also build, debug and package your app to run in your  devices.With 's own  language, one can easily code and build the GUI interface easily (it's just like Java XML, but rather than TextView etc.,  has its own  for the similar translation), which is in my opinion quite easy to adopt.Currently  and  are most recommended tools to build/package your apps. Having tried them both and I can firmly say that they make building Android apps with Python a breeze. Users who feel comfortable in their console/terminal/command prompt should have no problems using them, and their guides are well documented, too.Futhermore,  is another big selling point of Kivy, provided that you can use the same code base with little changes required to test-run on your  device, via  Homebrew tools, although  are required for the build before running on their devices (AFAIK iOS Simulator in Xcode currently doesn't work for the x86-architecture build). There are also some dependency issues which required manually compiled and fiddled around in Xcode to have a successful build, but wouldn't be too difficult to resolve and people in  are really helpful too.With all being said, users with good Python knowledge should have no problem picking up the basics in weeks (if not days) to build some simple apps.Also worth mentioning is that you can  your Python modules with the build so users can really make use of many existing libraries Python bring us, like  &  etc. through .The last but no the least, if you are going to use  for more serious/commercial projects, you may find existing modules not satisfactory to what are expected. There are some workable solutions too, with the \"work in progress\" of  for Andoird, and , users can now access to Java/Objective-C classes through those modules to control some of the native APIs.My experience in Kivy is that it will find its best fit with seasonal Python programmers and some serious programmer who wants rapid development or simple code base maintenance. It runs well in multiple platforms, albeit not really at the level of  feeling. From the  site:Yet another attempt: This one embed directly the Python interpretter in your app apk.You can run your Python code using . sl4a supports Python, , , , BeanShell, JavaScript, , and shell script.You can learn sl4a .There's also python-on-a-chip possibly running mosync: Didn't see this posted here, but you can do it with Pyside and Qt now that Qt works on Android thanks to Necessitas.It seems like quite a kludge at the moment but could be a viable route eventually...Another option if you are looking for 3.4.2 or 3.5.1 is this archive on GitHub.   or It currently supports Python 3.4.2 or 3.5.1 and the 10d version of the NDK.  It can also support 3.3 and 9c, 11c and 12It's nice in that you simply download it, run make and you get the .so or the .aI currently use this to run raw Python on android devices. With a couple modifications to the build files you can also make x86 and armeabi 64 bitYou can use  application:Note that apt install python install python 3.\nfor python 2 you shoud call apt install python2.Some demos here: And also the github page: One more option seems to be  which citing the docs is:According to  it is actively developed, although it is difficult to find examples of working Android apps or tutorial on how to cross-compile all the required libraries to Android. It is an interesting project to keep in mind though!You can use :It has a Python Console, Editor, as well as Package Management / InstallersIt's an open source project with both Python 2 and Python 3 implementations. You can download the source and the Android .apk files directly from github.QPython 2: QPython 3: There is an app called QPython3 in playstore which can be used for both editing and running python script.Another app called Termux in which you can install python using command"},
{"link": "https://stackoverflow.com//questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary", "qbody": "I wanted to test if a key exists in a dictionary before updating the value for the key.\nI wrote the following code:I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary? is the intended way to test for the existence of a key in a .If you wanted a default, you can always use :... and if you wanted to always ensure a default value for any key you can use  from the  module, like so:... but in general, the  keyword is the best way to do it.You don't have to call keys:That will be much  as it uses the dictionary's hashing as opposed to doing a linear search, which calling keys would do.You can test for the presence of a key in a dictionary, using the  keyword:A common use for checking the existence of a key in a dictionary before mutating it is to default-initialize the value (e.g. if your values are lists, for example, and you want to ensure that there is an empty list to which you can append when inserting the first value for a key). In cases such as those, you may find the  type to be of interest.In older code, you may also find some uses of , a deprecated method for checking the existence of keys in dictionaries (just use , instead).You can shorten this:However, this is at best a cosmetic improvement. Why do you believe this is not the best way?I would recommend using the  method instead.  It sounds like it will do everything you want.For additional info on speed execution of the accepted answer's proposed methods (10m loops):Therefore using  or  are recommended against .Just an FYI adding to Chris. B (best answer):Works as well; the reason is that calling  returns  which is what  does behind the scenes (when constructing a dictionary), hence the name \"Factory Function\" in the documentation.For checking you can use  method If you want a value then you can use  methodIf you want a tuple or list or dictionary or any string  as a default value as return value, then use  methodWhat about using EAFP (easier to ask forgiveness than permission):See other SO posts: orWon't print boo for the values in the dict, but accomplishes the goal by printing the value of key1 to confirm it's existence instead.Read More: Use of try/block instead of 'in' or 'if':Dictionary in python has a get('key', default) method. So you can just set a default value in case there is no key. \nEasiest one is if you know which key(key name) is to look for:or you can also do simply as:Python dictionary has the method called . This method will return True if the dictionary has the key else returns False."},
{"link": "https://stackoverflow.com//questions/576169/understanding-python-super-with-init-methods", "qbody": "I'm trying to understand . From the looks of it, both child classes can be created just fine. I'm curious as to what difference there actually is between the following child classes: lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of  can happen. See the  if you haven't already.Note that the syntax changed in Python 3.0: you can just say  instead of  which IMO is quite a bit nicer.It's been noted that in Python 3.0+ you can use to make your call, which is concise and does not require you to reference the parent OR class names explicitly, which can be handy. I just want to add that for Python 2.7 or under, you can achieve the same name-insensitive approach by writing  instead of the class name, i.e.This unfortunately does not necessarily work if you want to inherit the constructor from the superclass. For example:Here I have a class , which is a sub-class of . Say I don't want to write a separate constructor for  because the constructor for  is good enough, but for whatever reason I want to implement a Square so I can reimplement some other method.When I create a  using , Python calls the constructor for  because I haven't given  its own constructor. However, in the constructor for , the call  is going to return the superclass of , so it calls the constructor for  again. This is how the infinite loop happens, as was mentioned by @S_C. In this case, when I run  I am calling the constructor for  but since I give it no arguments, I will get an error.The reason we use  is so that child classes that may be using cooperative multiple inheritance will call the correct next parent class function in the Method Resolution Order (MRO).The primary difference in this code is that you get a layer of indirection in the  with , which uses the current class to determine the next class's  to look up in the MRO.I illustrate this difference in an answer at the , which demonstrates  and .Here's code that's actually closely equivalent to  (how it's implemented in C, minus some checking and fallback behavior, and translated to Python):Written a little more like native Python:If we didn't have the  object, we'd have to write this manual code everywhere (or recreate it!) to ensure that we call the proper next method in the Method Resolution Order!The current second to top answer on this question suggests calling super like this:This is  wrong.  lets us look up the next parent in the MRO (see the first section of this answer) for child classes. If you tell  we're in the child instance's method, it will then lookup the next method in line (probably this one) resulting in recursion, probably causing a logical failure (in the answerer's example, it does) or a  when the recursion depth is exceeded.I am at a loss as to why an answer that doesn't work has been so upvoted.It's rather hand-wavey and doesn't tell us much, but the point of  is not to avoid writing the parent class. The point is to ensure that the next method in line in the method resolution order (MRO) is called. This becomes important in multiple inheritance.I'll explain here.And let's create a dependency that we want to be called after the Child:Now remember,  uses super,  does not:And  does not call the UserDependency method:But , because  uses , does!:Super has no side effectsworks as expectedgets into infinite recursion.Just a heads up... with Python 2.7, and I believe ever since  was introduced in version 2.2, you can only call  if one of the parents inherit from a class that eventually inherits  ().Personally, as for python 2.7 code, I'm going to continue using  until I actually get the advantage of using .There isn't, really.  looks at the next class in the MRO (method resolution order, accessed with ) to call the methods. Just calling the base  calls the base . As it happens, the MRO has exactly one item-- the base. So you're really doing the exact same thing, but in a nicer way with  (particularly if you get into multiple inheritance later).The main difference is that  will unconditionally call  whereas  will call  is \n(which may differ from what you expect). If you add a  that uses multiple inheritance: then  for  instances. Now  will point to  if  is a  instance.You have inserted  in between  and . And you can take advantage of it with So if you are designed your classes so that they can be used in a Cooperative Multiple Inheritance scenario, you use  because you don't really know who is going to be the ancestor at runtime. The  and  explain this pretty well.  "},
{"link": "https://stackoverflow.com//questions/176918/finding-the-index-of-an-item-given-a-list-containing-it-in-python", "qbody": "For a list  and an item in the list , what's the cleanest way to get its index (1) in Python?Reference: One thing that is really helpful in learning Python is to use the interactive help function:which will often lead you to the method you are looking for.I'm honestly surprised no one has mentioned  yet:This can be more useful than index if there are duplicates in the list, because index() only returns the first occurrence, while enumerate returns all occurrences.As a list comprehension:Here's also another small solution with  (which is pretty much the same approach as enumerate):This is more efficient for larger lists than using : returns the  index of value!To get all indexes:A problem will arise if the element is not in the list. This function handles the issue:You have to set a condition to check if the element you're searching is in the listAll of the proposed functions here reproduce inherent language behavior but obscure what's going on.Why write a function with exception handling if the language provides the methods to do what you want itself?If you want all indexes, then you can use numpy:It is clear, readable solution.Simply you can go withall indexes with zip functionAnother optionA variant on the answer from FMc and user7177 will give a dict that can return all indices for any entry:You could also use this as a one liner to get all indices for a single entry. There are no guarantees for efficiency, though I did use set(a) to reduce the number of times the lambda is called.This solution is not as powerful as others, but if you're a beginner and only know about loops it's still possible to find the first index of an item while avoiding the ValueError:And now, for something completely different, checking for the existence of the item before getting the index.  The nice thing about this approach is the function always returns a list of indices -- even if it is an empty list.  It works with strings as well.When pasted into an interactive python window:This accounts for if the string is not in the list too, if it isn't in the list then location = -1"},
{"link": "https://stackoverflow.com//questions/1436703/difference-between-str-and-repr-in-python", "qbody": "What is the difference between  and  in ?Alex summarized well but, surprisingly, was too succinct.First, let me reiterate the main points in Alex\u2019s post:This is mostly a surprise because Python\u2019s defaults tend to be fairly useful. However, in this case, having a default for  which would act like:would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if  is defined, and  is not, the object will behave as though .This means, in simple terms: almost every object you implement should have a functional  that\u2019s usable for understanding the object. Implementing  is optional: do that if you need a \u201cpretty print\u201d functionality (for example, used by a report generator).Let me come right out and say it \u2014 I do not believe in debuggers. I don\u2019t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature \u2014 most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is aBut you have to do the last step \u2014 make sure every object you implement has a useful repr, so code like that can just work. This is why the \u201ceval\u201d thing comes up: if you have enough information so , that means you know everything there is to know about . If that\u2019s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about  anyway. I usually use an eval-like format: . It does not mean that you can actually construct MyClass, or that those are the right constructor arguments \u2014 but it is a useful form to express \u201cthis is everything you need to know about this instance\u201d.Note: I used  above, not . You always want to use  [or  formatting character, equivalently] inside  implementation, or you\u2019re defeating the goal of repr. You want to be able to differentiate  and .Specifically, it is not intended to be unambiguous \u2014 notice that . Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be \"2010/4/12 15:35:22\", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class \u2014 as long is it supports readability, it is an improvement.This seems surprising, doesn\u2019t it? It is a little, but how readable wouldbe? Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you\u2019re printing a list, just(you can probably also figure out what to do about dictionaries.Implement  for any class you implement. This should be second nature. Implement  if you think it would be useful to have a string version which errs on the side of more readability in favor of more ambiguity.Unless you specifically act to ensure otherwise, most classes don't have helpful results for either:As you see -- no difference, and no info beyond the class and object's .  If you only override one of the two...:as you see, if you override , that's ALSO used for , but not vice versa.Other crucial tidbits to know:  on a built-on container uses the , NOT the , for the items it contains. And, despite the words on the subject found in typical docs, hardly anybody bothers making the  of objects be a string that  may use to build an equal object (it's just too hard, AND not knowing how the relevant module was actually imported makes it actually flat out impossible).So, my advice: focus on making  reasonably human-readable, and  as unambiguous as you possibly can, even if that interferes with the fuzzy unattainable goal of making 's returned value acceptable as input to !My rule of thumb:   is for developers,  is for customers.: representation of python object usually eval will convert it back to that object: is whatever you think is that object in text forme.g.Here is a good example:Read this documentation for repr:Here is the documentation for str: (read as \"dunder (double-underscore) string\") and  (read as \"dunder-repper\" (for \"representation\")) are both special methods that return strings based on the state of the object.  provides backup behavior if  is missing. So one should first write a  that allows you to reinstantiate an equivalent object from the string it returns e.g. using  or by typing it in character-for-character in a Python shell. At any time later, one can write a  for a user-readable string representation of the instance, when one believes it to be necessary.If you print an object, or pass it to , , or , then if a  method is defined, that method will be called, otherwise,  will be used. The  method is called by the builtin function  and is what is echoed on your python shell when it evaluates an expression that returns an object. Since it provides a backup for , if you can only write one, start with Here's the builtin help on :That is, for most objects, if you type in what is printed by , you should be able to create an equivalent object. The default object  is () something like:That means by default you'll print the module the object is from, the class name, and the hexadecimal representation of its location in memory - for example:This information isn't very useful, but there's no way to derive how one might accurately create a canonical representation of any given instance, and it's better than nothing, at least telling us how we might uniquely identify it in memory.Let's look at how useful it can be, using the Python shell and  objects. First we need to import the  module:If we call  in the shell, we'll see everything we need to recreate an equivalent datetime object. This is created by the datetime :If we print a datetime object, we see a nice human readable (in fact, ISO) format. This is implemented by datetime's :It is a simple matter to recreate the object we lost because we didn't assign it to a variable by copying and pasting from the  output, and then printing it, and we get it in the same human readable output as the other object:As you're developing, you'll want to be able to reproduce objects in the same state, if possible. This, for example, is how the datetime object defines  (). It is fairly complex, because of all of the attributes needed to reproduce such an object:If you want your object to have a more human readable representation, you can implement  next. Here's how the datetime object () implements , which it easily does because it already has a function to display it in ISO format:This is a critique of another answer here that suggests setting .Setting  is silly -  is a fallback for  and a , written for developers usage in debugging, should be written before you write a .You need a  only when you need a textual representation of the object.Define  for objects you write so you and other developers have a reproducible example when using it as you develop. Define  when you need a human readable string representation of it. In all honesty,  is never used. If you find yourself using it, you should stop, because  is dangerous, and strings are a very inefficient way to serialize your objects (use  instead). Therefore, I would recommend setting . The reason is that  calls  on the elements (I consider this to be one of the biggest design flaws of Python that was not addressed by Python 3). An actual  will probably not be very helpful as the output of . To qualify this, in my experience, the most useful use case of the  function is to put a string inside another string (using string formatting). This way, you don't have to worry about escaping quotes or anything. But note that there is no  happening here. From  by effbot: \"computes the \"informal\" string representation of an object. This differs from  in that it does not have to be a valid Python expression: a more convenient or concise representation may be used instead.\"To put it simply: is used in to show a string representation of your object  by others. is used to show a string representation of  object.Let's say I want to create a  class where the string representation of a fraction is '(1/2)' and the object (Fraction class) is to be represented as 'Fraction (1,2)'So we can create a simple Fraction class:Apart from all the answers given, I would like to add few points :-1)  is invoked when you use object with print statement. In case, if  is missing, then print invokes  of object.2)  is invoked when you simply write object's name on interactive python console and press enter.3)  of containers, when invoked will execute  method of its contained elements. - Creates a new string object from the given object. - Returns the canonical string representation of the object.The differences:When print() is called on the result of decimal.Decimal(23) / deci- mal.Decimal(\"1.05\") the raw number is printed; this output is in  which can be achieved with __str __(). If we simply enter the expression we get a decimal.Decimal output\u2014this output is in  which can be achieved with __repr __(). All Python objects have two output forms. String form is designed to be human-readable. Representational form is designed to produce output that if fed to a Python interpreter would (when possible) re- produce the represented object, the  call of a  calls the contained objects' , the  representation of an object. Although the formal representation is harder to read than an informal one, it is unambiguous and more robust against bugs.Excellent answers are already cover the difference between  and , which for me boils down to the former being readable even by an end user, and the latter being as useful as possible to developers. Given that, I find that the default implementation of  often fails to achieve this goal because it  information useful to developers.For this reason, if I have a simple enough , I generally just try to get the best of both worlds with something like:On page 358 of the book  by Hans Petter Langtangen, it clearly states that So, I prefer to understand them asfrom the user point of view\nalthough this is a misunderstanding i made when learning python.A small but good example is also given on the same page as follows:From the book: Fluent PythonOne aspect that is missing in other answers. It's true that in general the pattern is:Unfortunately, this differentiation is flawed, because the Python REPL and also IPython use  for printing objects in a REPL console (see related questions for  and ). Thus, projects which are targeted for interactive console work (e.g., Numpy or Pandas) have started to ignore above rules and provide a human-readable  implementation instead."},
{"link": "https://stackoverflow.com//questions/509211/explain-slice-notation", "qbody": "I need a good explanation (references are a plus) on Python's slice notation. To me, this notation needs a bit of picking up. It looks extremely powerful, but I haven't quite got my head around it.It's pretty simple really:There is also the  value, which can be used with any of the above:The key point to remember is that the  value represents the first value that is  in the selected slice. So, the difference beween  and  is the number of elements selected (if  is 1, the default).The other feature is that  or  may be a  number, which means it counts from the end of the array instead of the beginning. So:Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for  and  only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.The tutorial talks about it:(Scroll down a bit until you get to the part about slicing.)  The ASCII art diagram is helpful too for remembering how slices work:Enumerating the possibilities allowed by the grammar:Of course, if , then the end point will be a little lower than .Extended slicing (with commas and ellipses) are mostly used only by special data structures (like Numpy); the basic sequences don't support them.The answers above don't discuss slice assignment:This may also clarify the difference between slicing and indexing.In short, the colons () in subscript notation () make slice notation - which has the optional arguments, , , :Python slicing is a computationally fast way to methodically access parts of your data. In my opinion, to be even an intermediate Python programmer, it's one aspect of the language that it is necessary to be familiar with.To begin with, let's define a few terms:You can make any of these positive or negative numbers. The meaning of the positive numbers is straightforward, but for negative numbers, just like indexes in Python, you count backwards from the end for the  and , and for the , you simply decrement your index. This example is , but I've modified it slightly to indicate which item in a sequence each index references:To use slice notation with a sequence that supports it, you must include at least one colon in the square brackets that follow the sequence (which actually .)Slice notation works like this:And recall that there are defaults for , , and , so to access the defaults, simply leave out the argument.Slice notation to get the last nine elements from a list (or any other sequence that supports it, like a string) would look like this:When I see this, I read the part in the brackets as \"9th from the end, to the end.\" (Actually, I abbreviate it mentally as \"-9, on\")The full notation is and to substitute the defaults (actually when  is negative, 's default is , so  for stop really just means it goes to whichever end step takes it to):The , ,  is what tells Python you're giving it a slice and not a regular index. That's why the idiomatic way of making a shallow copy of lists in Python 2 isAnd clearing them is with:(Python 3 gets a  and  method.)You may find it useful to separate forming the slice from passing it to the  method (). Even if you're not new to it, it keeps your code more readable so that others that may have to read your code can more readily understand what you're doing.However, you can't just assign some integers separated by colons to a variable. You need to use the slice object:The second argument, , is required, so that the first argument is interpreted as the  argument . You can then pass the slice object to your sequence:Since slices of Python lists create new objects in memory, another important function to be aware of is . Typically you'll want to iterate over a slice, not just have it created statically in memory.  is perfect for this. A caveat, it doesn't support negative arguments to , , or , so if that's an issue you may need to calculate indices or reverse the iterable in advance.The fact that list slices make a copy is a feature of lists themselves. If you're slicing advanced objects like a Pandas DataFrame, it may return a view on the original, and not a copy. And a couple of things that weren't immediately obvious to me when I first saw the slicing syntax:Easy way to reverse sequences!And if you wanted, for some reason, every second item in the reversed sequence:Found this great table at In Python 2.7Slicing in PythonUnderstanding index assignment is very important.When you say [a:b:c], you are saying depending on the sign of c (forward or backward), start at a and end at b (excluding element at bth index). Use the indexing rule above and remember you will only find elements in this range:But this range continues in both directions infinitely:For example:If your choice of a, b, and c allows overlap with the range above as you traverse using rules for a,b,c above you will either get a list with elements (touched during traversal) or you will get an empty list.One last thing: if a and b are equal, then also you get an empty list:After using it a bit I realise that the simplest description is that it is exactly the same as the arguments in a for loop...any of them are optionalthen the negative indexing just needs you to add the length of the string to the negative indices to understand it.This works for me anyway...I find it easier to remember how it's works, then I can figure out any specific start/stop/step combination.It's instructive to understand  first:Begin from , increment by , do not reach .  Very simple.The thing to remember about negative step is that  is always the excluded end, whether it's higher or lower. If you want same slice in opposite order, it's much cleaner to do the reversal separately: e.g.  slices off one char from left, two from right, then reverses. (See also .)Sequence slicing is same, except it first normalizes negative indexes, and can never go outside the sequence:: The code below had a bug with \"never go outside the sequence\" when abs(step)>1; I  I patched it to be correct, but it's hard to understand.Don't worry about the  details - just remember that omitting  and/or  always does the right thing to give you the whole sequence.Normalizing negative indexes first allows start and/or stop to be counted from the end independently:  despite .\nThe normalization is sometimes thought of as \"modulo the length\" but note it adds the length just once: e.g.  is just the whole string.I hope this will help you to model the list in Python.Reference: I use the \"an index points between elements\" method of thinking about it myself, but one way of describing it which sometimes helps others get it is this:X is the index of the first element you want.\nY is the index of the first element you  want.Python slicing notation:The notation extends to (numpy) matrices and multidimensional arrays.  For example, to slice entire columns you can use:Slices hold references, not copies, of the array elements.  If you want to make a separate copy an array, you can use .This is just for some extra info...\nConsider the list below Few other tricks for reversing the list:See abc's answer aboveYou can also use slice assignment to remove one or more elements from a list:As a general rule, writing code with a lot of hardcoded index values leads to a readability\nand maintenance mess. For example, if you come back to the code a year later, you\u2019ll\nlook at it and wonder what you were thinking when you wrote it. The solution shown\nis simply a way of more clearly stating what your code is actually doing.\nIn general, the built-in slice() creates a slice object that can be used anywhere a slice\nis allowed. For example:If you have a slice instance s, you can get more information about it by looking at its\ns.start, s.stop, and s.step attributes, respectively. For example:This is how I teach slices to newbies:Wiki Python has this amazing picture which clearly distinguishes indexing and slicing.It is a list with 6 elements in it. To understand slicing better, consider that list as a set of six boxes placed together. Each box has an alphabet in it.Indexing is like dealing with the contents of box. You can check contents of any box. But You can't check contents of multiple boxes at once. You can even replace contents of the box. But You can't place 2 balls in 1 box or replace 2 balls at a time.Slicing is like dealing with boxes itself. You can pickup first box and place it on another table. To pickup the box all You need to know is the position of beginning  & ending of the box.You can even pickup first 3 boxes or last 2 boxes or all boxes between 1 & 4. So, You can pick any set of boxes if You know beginning & ending. This positions are called start & stop positions.The interesting thing is that You can replace multiple boxes at once. Also You can place multiple boxes where ever You like.Till now You have picked boxes continuously. But some times You need to pickup discretely. For example You can pickup every second box. You can even pickup every third box from the end. This value is called step size. This represents the gap between Your successive pickups. The step size should be positive if You are picking boxes from the beginning to end and vice versa.When slicing if You leave out any parameter, Python tries to figure it out automatically.If You check source code of CPython, You will find a function called PySlice_GetIndicesEx which figures out indices to a slice for any given parameters. Here is the logical equivalent code in Python.This function takes a Python object & optional parameters for slicing and returns start, stop, step & slice length for the requested slice.This is the intelligence that is present behind slices. Since Python has inbuilt function called slice, You can pass some parameters & check how smartly it calculates missing parameters. This post is originally written in my blog To make it simple, remember and here is how it works:Another import thing:  And if they are omitted, their default value will be used: ,, accordingly.So possible variations are:NOTE: If (considering only when ), python will return a empty slice .The above part explains the core features on how slice works, it will work on most occasions. However there can be pitfalls you should watch out, and this part explains them.The very first thing confuses python learners is that  \nDon't panic: For example:Make things more confusing is that  : when step is negative, the default value for  to (while  does not equal to , because  contains ). For example:Be surprised: If the index is out of range, python will try its best set the index to  or  according to the situation. For example:Let's finish this answer with examples explains everything we have discussed:To get a certain piece of an iterable (like a list), here is an example:In this example, a positive number for number 1 is how many components you take off the front. A negative number is the exact opposite, how many you keep from the end. A positive number for number 2 indicates how many components you intend to keep from the beginning, and a negative is how many you intend to take off from the end. This is somewhat counter intuitive, but you are correct in supposing that list slicing is extremely useful.My brain seems happy to accept that  contains the -th item. I might even say that it is a 'natural assumption'.But occasionally a doubt creeps in and my brain asks for reassurance that it does not contain the -th element.In these moments I rely on this simple theorem:This pretty property tells me that  does not contain the -th item because it is in .Note that this theorem is true for any  at all. For example, you can check thatreturns .You can run this script and experiment with it, below is some samples that I got from the script.When using a negative step, notice that the answer is shifted to the right by 1.The answers above don't discuss multi-dimentional array slicing:The \":2\" before comma operates on the first dimension and the \"0:3:2\" after the comma operates on the second dimension."},
{"link": "https://stackoverflow.com//questions/986006/how-do-i-pass-a-variable-by-reference", "qbody": "The Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'Is there something I can do to pass the variable by actual reference?Arguments are . The rationale behind this is twofold:So:To make it even more clear, let's have some examples. Output:Since the parameter passed in is a reference to , not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.Output:Since the  parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The  was a copy of the  reference, and we had  point to a new list, but there was no way to change where  pointed.Output:Again, since the  parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The  was a copy of the  reference, and we had  point to a new string, but there was no way to change where  pointed.I hope this clears things up a little. It's been noted that this doesn't answer the question that @David originally asked, \"Is there something I can do to pass the variable by actual reference?\". Let's work on that.As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:Although this seems a little cumbersome.The problem comes from a misunderstanding of what variables are in Python. If you're used to most traditional languages, you have a mental model of what happens in the following sequence:You believe that  is a memory location that stores the value , then is updated to store the value . That's not how things work in Python. Rather,  starts as a reference to an object with the value , then gets reassigned as a reference to an object with the value . Those two objects may continue to coexist even though  doesn't refer to the first one anymore; in fact they may be shared by any number of other references within the program.When you call a function with a parameter, a new reference is created that refers to the object passed in. This is separate from the reference that was used in the function call, so there's no way to update that reference and make it refer to a new object. In your example: is a reference to the string object . When you call  you create a second reference  to the object. Inside the function you reassign the reference  to a different string object , but the reference  is separate and does not change.The only way around this is to pass a mutable object. Because both references refer to the same object, any changes to the object are reflected in both places.It is neither pass-by-value or pass-by-reference - it is call-by-object. See this, by Fredrik Lundh: Here is a significant quote:In your example, when the  method is called--a  is created for it; and  becomes a name, within that namespace, for the string object . That object then has a name in two namespaces. Next,  binds  to a new string object, and thus the method's namespace forgets about . Finally, that namespace is forgotten, and the string  along with it.I found the other answers rather long and complicated, so I created this simple diagram to explain the way Python treats variables and parameters.\nThink of stuff being passed  instead of by reference/by value. That way, it is allways clear, what is happening as long as you understand what happens during normal assignment.So, when passing a list to a function/method, the list is assigned to the parameter name. Appending to the list will result in the list being modified. Reassigning the list  the function will not change the original list, since:Since immutable types cannot be modified, they  like being passed by value - passing an int into a function means assigning the int to the functions parameter. You can only ever reassign that, but it won't change the originial variables value.Technically, . I am going to repeat  to support my statement.Python always uses pass-by-reference values. There isn't any exception. Any variable assignment means copying the reference value. No exception. Any variable is the name bound to the reference value. Always.You can think about a reference value as the address of the target object. The address is automatically dereferenced when used. This way, working with the reference value, it seems you work directly with the target object. But there always is a reference in between, one step more to jump to the target.Here is the example that proves that Python uses passing by reference:If the argument was passed by value, the outer  could not be modified. The green are the target objects (the black is the value stored inside, the red is the object type), the yellow is the memory with the reference value inside -- drawn as the arrow. The blue solid arrow is the reference value that was passed to the function (via the dashed blue arrow path). The ugly dark yellow is the internal dictionary. (It actually could be drawn also as a green ellipse. The colour and the shape only says it is internal.)You can use the  built-in function to learn what the reference value is (that is, the address of the target object).In compiled languages, a variable is a memory space that is able to capture the value of the type. In Python, a variable is a name (captured internally as a string) bound to the reference variable that holds the reference value to the target object. The name of the variable is the key in the internal dictionary, the value part of that dictionary item stores the reference value to the target.Reference values are hidden in Python. There isn't any explicit user type for storing the reference value. However, you can use a list element (or element in any other suitable container type) as the reference variable, because all containers do store the elements also as references to the target objects. In other words, elements are actually not contained inside the container -- only the references to elements are.Effbot (aka Fredrik Lundh) has described Python's variable passing style as call-by-object:  Objects are allocated on the heap and pointers to them can be passed around anywhere.  Hope that clarifies the issue for you. (edit - Blair has updated his enormously popular answer so that it is now accurate)I think it is important to note that the current post with the most votes (by Blair Conrad), while being correct with respect to its result, is misleading and is borderline incorrect based on its definitions.  While there are many languages (like C) that allow the user to either pass by reference or pass by value, Python is not one of them.David Cournapeau's answer points to the real answer and explains why the behavior in Blair Conrad's post seems to be correct while the definitions are not.To the extent that Python is pass by value, all languages are pass by value since some piece of data (be it a \"value\" or a \"reference\") must be sent. However, that does not mean that Python is pass by value in the sense that a C programmer would think of it.If you want the behavior, Blair Conrad's answer is fine.  But if you want to know the nuts and bolts of why Python is neither pass by value or pass by reference, read David Cournapeau's answer.A simple trick I normally use is to just wrap it in a list:(Yeah I know this can be inconvenient, but sometimes it is simple enough to do this.)The key to understanding parameter passing is to stop thinking about \"variables\". There are names and objects in Python and together they\nappear like variables, but it is useful to always distinguish the three.That is all there is to it. Mutability is irrelevant for this question.Example: This binds the name  to an object of type integer that holds the value 1.This binds the name  to the same object that the name  is currently bound to.\nAfterwards, the name  has nothing to do with the name  any more.See sections  and  in the Python 3 language reference.So in the code shown in the question, the statement  binds the name  (in the scope of function ) to the object that holds the value  and the assignment  (in the body of function ) assigns that same name again: to some other object (that happens to hold a string as well but could have been something else entirely).You got some really good answers here.In this case the variable titled  in the method  is assigned a reference to , and you immediately assign a string to . It's no longer pointing to . The following code snippet shows what would happen if you modify the data structure pointed to by  and , in this case a list:I'm sure someone else could clarify this further.Python\u2019s pass-by-assignment scheme isn\u2019t quite the same as C++\u2019s reference parameters option, but it turns out to be very similar to the argument-passing model of the C language (and others) in practice:As you can state you need to have a mutable object, but let me suggest you to check over the global variables as they can help you or even solve this kind of issue!example:A lot of insights in answers here, but i think an additional point is not clearly mentioned here explicitly.   Quoting from python documentation   \"In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the function\u2019s body, it\u2019s assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as \u2018global\u2019.\nThough a bit surprising at first, a moment\u2019s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you\u2019d be using global all the time. You\u2019d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects.\"Even when passing a mutable object to a function this still applies. And to me clearly explains the reason for the difference in behavior between assigning to the object and operating on the object in the function.gives:The assignment to an global variable that is not declared global therefore creates a new local object and breaks the link to the original object.Here is the simple (I hope) explanation of the concept  used in Python.\nWhenever you pass an object to the function, the object itself is passed (object in Python is actually what you'd call a value in other programming languages) not the reference to this object. In other words, when you call:The actual object - [0, 1] (which would be called a value in other programming languages) is being passed. So in fact the function  will try to do something like:which obviously will not change the object passed to the function. If the function looked like this:Then the call would result in:which obviously will change the object.  explains it well.There is a little trick to pass an object by reference, even though the language doesn't make it possible. It works in Java too, it's the list with one item. ;-)It's an ugly hack, but it works. ;-PAside from all the great explanations on how this stuff works in Python, I don't see a simple suggestion for the problem. As you seem to do create objects and instances, the pythonic way of handling instance variables and changing them is the following:In instance methods, you normally refer to  to access instance attributes. It is normal to set instance attributes in  and read or change them in instance methods. That is also why you pass  als the first argument to .Another solution would be to create a static method like this:I used the following method to quickly convert a couple of Fortran codes to Python.  True, it's not pass by reference as the original question was posed, but is a simple work around in some cases.While pass by reference is nothing that fits well into python and should be rarely used there are some workarounds that actually can work to get the object currently assigned to a local variable or even reassign a local variable from inside of a called function.The basic idea is to have a function that can do that access and can be passed as object into other functions or stored in a class.One way is to use  (for global variables) or  (for local variables in a function) in a wrapper function.The same idea works for reading and eting a variable.For just reading there is even a shorter way of just using  which returns a callable that when called returns the current value of x. This is somewhat like \"call by name\" used in languages in the distant past.Passing 3 wrappers to access a variable is a bit unwieldy so those can be wrapped into a class that has a proxy attribute:Pythons \"reflection\" support makes it possible to get a object that is capable of reassigning a name/variable in a given scope without defining functions explicitly in that scope:Here the  class wraps a dictionary access. So attribute access to  is translated to a item access in the passed dictionary. By passing the result of the builtin  and the name of a local variable this ends up accessing a local variable. The python documentation as of 3.5 advises that changing the dictionary might not work but it seems to work for me.given the way python handles values and references to them, the only way you can reference an arbitrary instance attribute is by name:in real code you would, of course, add error checking on the dict lookup."},
{"link": "https://stackoverflow.com//questions/522563/accessing-the-index-in-python-for-loops", "qbody": "How do I access the index itself for a list like the following?When I loop through it using a  loop, how do I access the loop index, from 1 to 5 in this case?Using an additional state variable, such as an index variable (which you would normally use in languages such as C or PHP), is considered non-pythonic.The better option is to use the built-in function , available in both Python 2 and 3:Check out  for more.Use :And note that indexes start at zero, so you would get 0 to 4 with this. If you want the count, I explain that below.What you are asking for is the Pythonic equivalent of the following, which is the algorithm most programmers of lower-level languages would use:Or in languages that do not have a for-each loop:or sometimes more commonly (but unidiomatically) found in Python:Python's  reduces the visual clutter by hiding the accounting for the indexes, and encapsulating the iterable into another iterable (an  object) that yields a two-item tuple of the index and the item that the original iterable would provide. That looks like this:This code sample is fairly well the  example of the difference between code that is idiomatic of Python and code that is not. Idiomatic code is sophisticated (but not complicated) Python, written in the way that it was intended to be used. Idiomatic code is expected by the designers of the language, which means that usually this code is not just more readable, but also more efficient.Even if you don't need indexes as you go, but you need a count of the iterations (sometimes desirable) you can start with  and the final number will be your count.The count seems to be more what you intend to ask for (as opposed to index) when you said you wanted from 1 to 5.To break these examples down, say we have a list of items that we want to iterate over with an index:Now we pass this iterable to enumerate, creating an enumerate object:We can pull the first item out of this iterable that we would get in a loop with the  function:And we see we get a tuple of , the first index, and , the first item:we can use what is referred to as \"\" to extract the elements from this two-tuple:and when we inspect , we find it refers to the first index, 0, and  refers to the first item, .So do this:It's pretty simple to start it from  other than :Important hint, though a little misleading, since  will be a   here.\nGood to go.Old fashioned way:List comprehension:This way you can extend a list. Extend means you can add multiple values at a time.To append this list you have to write the code given below:This way you can add a single value at a time. If you write  so this will create a sub list for this element.According to this discussion: Loop counter iterationThe current idiom for looping over the indices makes use of the built-in 'range' function:Looping over both elements and indices can be achieved either by the old idiom or by using the new 'zip' built-in function[2]:orvia I don't know if the following is pythonic or not, but it uses the Python function  and prints the enumerator and the value.First of all, the indexes will be from 0 to 4. Programming languages start counting from 0; don't forget that or you will come across an index out of bounds exception. All you need in the for loop is a variable counting from 0 to 4 like so:Keep in mind that I wrote 0 to 5 because the loop stops one number before the max. :)To get the value of an index useThe fastest way to access indexes of list within loop in  is to use the  for small lists and  for medium and huge size lists.Please see  which can be used to iterate over list and access index value and  (which I suppose would be useful for you) in code samples below:See performance metrics for each method below:As the result, using  method is the fastest one up to list with 1000 items. For list with size > 10 000 items  is the winner.Adding some useful links below:You can do it with this code:Use this code if you need to reset the index value at the end of the loop:"},
{"link": "https://stackoverflow.com//questions/1132941/least-astonishment-and-the-mutable-default-argument", "qbody": "Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:Python novices would expect this function to always return a list with only one element: . The result is instead very different, and very astonishing (for a novice):A manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?): Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function or \"together\" with it?Doing the binding inside the function would mean that  is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the  line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.Actually, this is not a design flaw, and it is not because of internals, or performance.\nIt comes simply from the fact that functions in Python are first-class objects, and not only a piece of code.As soon as you get to think into this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of \"member data\" and therefore their state may change from one call to the other - exactly as in any other object.In any case, Effbot has a very nice explanation of the reasons for this behavior in .\nI found it very clear, and I really suggest reading it for a better knowledge of how function objects work.Suppose you have the following codeWhen I see the declaration of eat, the least astonishing thing is to think that if the first parameter is not given, that it will be equal to the tuple However, supposed later on in the code, I do something likethen if default parameters were bound at function execution rather than function declaration then I would be astonished (in a very bad way) to discover that fruits had been changed.  This would be more astonishing IMO than discovering that your  function above was mutating the list.The real problem lies with mutable variables, and all languages have this problem to some extent. Here's a question: suppose in Java I have the following code:Now, does my map use the value of the  key when it was placed into the map, or does it store the key by reference?  Either way, someone is astonished; either the person who tried to get the object out of the  using a value identical to the one they put it in with, or the person who can't seem to retrieve their object even though the key they're using is literally the same object that was used to put it into the map (this is actually why Python doesn't allow its mutable built-in data types to be used as dictionary keys).Your example is a good one of a case where Python newcomers will be surprised and bitten.  But I'd argue that if we \"fixed\" this, then that would only create a different situation where they'd be bitten instead, and that one would be even less intuitive. Moreover, this is always the case when dealing with mutable variables; you always run into cases where someone could intuitively expect one or the opposite behavior depending on what code they're writing.I personally like Python's current approach: default function arguments are evaluated when the function is defined and that object is always the default. I suppose they could special-case using an empty list, but that kind of special casing would cause even more astonishment, not to mention be backwards incompatible.AFAICS no one has yet posted the relevant part of the :I know nothing about the Python interpreter inner workings (and I'm not an expert in compilers and interpreters either) so don't blame me if I propose anything unsensible or impossible.Provided that python objects  I think that this should be taken into account when designing the default arguments stuff.\nWhen you instantiate a list:you expect to get a  list referenced by .Why should the a=[] ininstantiate a new list on function definition and not on invocation?\nIt's just like you're asking \"if the user doesn't provide the argument then  a new list and use it as if it was produced by the caller\".\nI think this is ambiguous instead:user, do you want  to default to the datetime corresponding to when you're defining or executing ?\nIn this case, as in the previous one, I'll keep the same behaviour as if the default argument \"assignment\" was the first instruction of the function (datetime.now() called on function invocation).\nOn the other hand, if the user wanted the definition-time mapping he could write:I know, I know: that's a closure. Alternatively Python might provide a keyword to force definition-time binding:Well, the reason is quite simply that bindings are done when code is executed, and the function definition is executed, well... when the functions is defined.Compare this:This code suffers from the exact same unexpected happenstance. bananas is a class attribute, and hence, when you add things to it, it's added to all instances of that class. The reason is exactly the same.It's just \"How It Works\", and making it work differently in the function case would probably be complicated, and in the class case likely impossible, or at least slow down object instantiation a lot, as you would have to keep the class code around and execute it when objects are created.Yes, it is unexpected. But once the penny drops, it fits in perfectly with how Python works in general. In fact, it's a good teaching aid, and once you understand why this happens, you'll grok python much better.That said it should feature prominently in any good Python tutorial. Because as you mention, everyone runs into this problem sooner or later.I used to think that creating the objects at runtime would be the better approach.  I'm less certain now, since you do lose some useful features, though it may be worth it regardless simply to prevent newbie confusion.  The disadvantages of doing so are:If call-time evaluation is used, then the expensive function is called every time your function is used without an argument.  You'd either pay an expensive price on each call, or need to manually cache the value externally, polluting your namespace and adding verbosity.A useful trick is to bind parameters of a lambda to the  binding of a variable when the lambda is created.  For example:This returns a list of functions that return 0,1,2,3... respectively.  If the behaviour is changed, they will instead bind  to the  value of i, so you would get a list of functions that all returned .The only way to implement this otherwise would be to create a further closure with the i bound, ie:Consider the code:We can get information about the arguments and defaults using the  module, which This information is very useful for things like document generation, metaprogramming, decorators etc.Now, suppose the behaviour of defaults could be changed so that this is the equivalent of:However, we've lost the ability to introspect, and see what the default arguments .  Because the objects haven't been constructed, we can't ever get hold of them without actually calling the function.  The best we could do is to store off the source code and return that as a string.This behavior is easy explained by:So:What you're asking is why this:isn't internally equivalent to this:except for the case of explicitly calling func(None, None), which we'll ignore.In other words, instead of evaluating default parameters, why not store each of them, and evaluate them when the function is called?One answer is probably right there--it would effectively turn every function with default parameters into a closure.  Even if it's all hidden away in the interpreter and not a full-blown closure, the data's got to be stored somewhere.  It'd be slower and use more memory.1)  The so-called problem of \"Mutable Default Argument\" is in general a special example demonstrating that:\n\"All functions with this problem ,\"\nThat is against the rules of functional programming, usually undesiderable and should be fixed both together.Example::  a \nAn absolutely safe solution is to  or  the input object first and then to do whatever with the copy.Many builtin mutable types have a copy method like  or  or can be copied easy like  or . Every object can be also copied by  or more thorough by  (the latter useful if the mutable object is composed from mutable objects). Some objects are fundamentally based on side effects like \"file\" object and can not be meaningfully reproduced by copy. Example problem for It shouldn't be neither saved in any  attribute of an instance returned by this function. (Assuming that  attributes of instance should not be modified from outside of this class or subclasses by convention. i.e.  is a private attribute )Conclusion:\nInput parameters objects shouldn't be modified in place (mutated) nor they should not be binded into an object returned by the function. (If we prefere programming without side effects which is strongly recommended. see  (The first two paragraphs are relevent in this context.)\n.)2)\nOnly if the side effect on the actual parameter is required but unwanted on the default parameter then the useful solution is    3) In some cases is .I'm  surprised no one has performed the insightful introspection offered by Python ( and  apply) on callables. Given a simple little function  defined as:When Python encounters it, the first thing it will do is compile it in order to create a  object for this function. While this compilation step is done, . As the top answer mentioned: the list  can now be considered a  of the function .So, let's do some introspection, a before and after to examine how the list gets expanded  the function object. I'm using  for this, for Python 2 the same applies (use  or  in Python 2; yes, two names for the same thing).After Python executes this definition it will take any default parameters specified ( here) and  (relevant section: Callables):     O.k, so an empty list as the single entry in , just as expected. Let's now execute this function:Now, let's see those  again:  The value inside the object changes! Consecutive calls to the function will now simply append to that embedded  object:So, there you have it, the reason why this  happens, is because default arguments are part of the function object. There's nothing weird going on here, it's all just a bit surprising.To further verify that the list in  is the same as that used in the function  you can just change your function to return the  of the list  used inside the function body. Then, compare it to the list in  (position  in ) and you'll see how these are indeed refering to the same list instance:All with the power of introspection!  To verify that Python evaluates the default arguments during compilation of the function, try executing the following:as you'll notice,  is called before the process of building the function and binding it to the name  is made.This actually has nothing to do with default values, other than that it often comes up as an unexpected behaviour when you write functions with mutable default values.No default values in sight in this code, but you get exactly the same problem.The problem is that  is  a mutable variable passed in from the caller, when the caller doesn't expect this. Code like this would be fine if the function was called something like ; then the caller would be calling the function in order to modify the value they pass in, and the behaviour would be expected. But such a function would be very unlikely to take a default argument, and probably wouldn't return the list (since the caller already has a reference to that list; the one it just passed in).Your original , with a default argument, shouldn't be modifying  whether it was explicitly passed in or got the default value. Your code should leave mutable arguments alone unless it is clear from the context/name/documentation that the arguments are supposed to be modified. Using mutable values passed in as arguments as local temporaries is an extremely bad idea, whether we're in Python or not and whether there are default arguments involved or not.If you need to destructively manipulate a local temporary in the course of computing something, and you need to start your manipulation from an argument value, you need to make a copy.It's a performance optimization.  As a result of this functionality, which of these two function calls do you think is faster?I'll give you a hint.  Here's the disassembly (see ):As you can see, there  a performance benefit when using immutable default arguments.  This can make a difference if it's a frequently called function or the default argument takes a long time to construct.  Also, bear in mind that Python isn't C.  In C you have constants that are pretty much free.  In Python you don't have this benefit.This behavior is not surprising if you take the following into consideration:The role of  has been covered extensively in this thread.  is likely the astonishment causing factor, as this behavior is not \"intuitive\" when coming from other languages. is described in the Python . In an attempt to assign a value to a read-only class attribute:Look back to the original example and consider the above points:Here  is an object and  is an attribute of  (available at ). Since  is a list,  is mutable and is thus a read-write attribute of . It is initialized to the empty list as specified by the signature when the function is instantiated, and is available for reading and writing as long as the function object exists. Calling  without overriding a default uses that default's value from . In this case,  is used for  within function object's code scope. Changes to  change , which is part of the  object and persists between execution of the code in .Now, compare this to the example from the documentation on , such that the function signature defaults are used every time the function is executed:Taking  and  into account, one can see why this accomplishes the the desired behavior: Already busy topic, but from what I read here, the following helped me realizing how it's working internally:A simple workaround using NoneThe solutions here are:The second option is nice because users of the function can pass in a callable, which may be already existing (such as a )the shortest answer would probably be \"definition is execution\", therefore the whole argument makes no strict sense. as a more contrived example, you may cite this:hopefully it's enough to show that not executing the default argument expressions at the execution time of the def statement isn't easy or doesn't make sense, or both.i agree it's a gotcha when you try to use default constructors, though.I sometimes exploit this behavior as an alternative to the following pattern:If  is only used by , I like the following pattern as a replacement:I've used this for instantiating client classes that access external resources, and also for creating dicts or lists for memoization.Since I don't think this pattern is well known, I do put a short comment in to guard against future misunderstandings.You can get round this by replacing the object (and therefore the tie with the scope):Ugly, but it works.When we do this:... we assign the argument  to an  list, if the caller does not pass the value of a.To make things simpler for this discussion, let's temporarily give the unnamed list a name. How about  ?At any time, if the caller doesn't tell us what  is, we reuse .If  is mutable (modifiable), and  ends up modifying it, an effect we notice the next time  is called without specifying .So this is what you see (Remember,  is initialized to []):Now,  is [5].Calling  again modifies  again:Specifying  when calling  ensures  is not touched.So,  is still .It may be true that:it is entirely consistent to hold to both of the features above and still make another point:The other answers, or at least some of them either make points 1 and 2 but not 3, or make point 3 and downplay points 1 and 2. It may be true that switching horses in midstream here would be asking for significant breakage, and that there could be more problems created by changing Python to intuitively handle Stefano's opening snippet. And it may be true that someone who knew Python internals well could explain a minefield of consequences. The existing behavior is not Pythonic, and Python is successful because very little about the language violates the principle of least astonishment anywhere  this badly. It is a real problem, whether or not it would be wise to uproot it. It is a design flaw. If you understand the language much better by trying to trace out the behavior, I can say that C++ does all of this and more; you learn a lot by navigating, for instance, subtle pointer errors. But this is not Pythonic: people who care about Python enough to persevere in the face of this behavior are people who are drawn to the language because Python has far fewer surprises than other language. Dabblers and the curious become Pythonistas when they are astonished at how little time it takes to get something working--not because of a design fl--I mean, hidden logic puzzle--that cuts against the intuitions of programmers who are drawn to Python because it .I am going to demonstrate an alternative structure to pass a default list value to a function (it works equally well with dictionaries).  As others have extensively commented, the list parameter is bound to the function when it is defined as opposed to when it is executed.  Because lists and dictionaries are mutable, any alteration to this parameter will affect other calls to this function.  As a result, subsequent calls to the function will receive this shared list which may have been altered by any other calls to the function.  Worse yet, two parameters are using this function's shared parameter at the same time oblivious to the changes made by the other.:You can verify that they are one and the same object by using :Per Brett Slatkin's \"Effective Python: 59 Specific Ways to Write Better Python\",  (p. 48)This implementation ensures that each call to the function either receives the default list or else the list passed to the function.:There may be legitimate use cases for the 'Wrong Method' whereby the programmer intended the default list parameter to be shared, but this is more likely the exception than the rule.This \"bug\" gave me a lot of overtime work hours! But I'm beginning to see a potential use of it (but I would have liked it to be at the execution time, still)I'm gonna give you what I see as a useful example.prints the followingDefault arguments get evaluated at the time the function is compiled into a function object. When used by the function, multiple times by that function, they are and remain the same object. When they are mutable, when mutated (for example, by adding an element to it) they remain mutated on consecutive calls.They stay mutated because they are the same object each time.Here's a demonstration - you can verify that they are the same object each time they are referenced by and running it with :This order of execution is frequently confusing to new users of Python. If you understand the Python execution model, then it becomes quite expected. But this is why the usual instruction to new users is to create their default arguments like this instead:This uses the None singleton as a sentinel object to tell the function whether or not we've gotten an argument other than the default. If we get no argument, then we actually want to use a new empty list, , as the default.As the  says:I think the answer to this question lies in how python pass data to parameter (pass by value or by reference), not mutability or how python handle the \"def\" statement.A brief introduction. First, there are two type of data types in python, one is simple elementary data type, like numbers, and another data type is objects. Second, when passing data to parameters, python pass elementary data type by value, i.e., make a local copy of the value to a local variable, but pass object by reference, i.e., pointers to the object.Admitting the above two points, let's explain what happened to the python code. It's only because of passing by reference for objects, but has nothing to do with mutable/immutable, or arguably the fact that \"def\" statement is executed only once when it is defined.[] is an object, so python pass the reference of [] to , i.e.,  is only a pointer to [] which lies in memory as an object. There is only one copy of [] with, however, many references to it. For the first foo(), the list [] is changed to  by append method. But Note that there is only one copy of the list object and this object now becomes . When running the second foo(), what effbot webpage says (items is not evaluated any more) is wrong.  is evaluated to be the list object, although now the content of the object is . This is the effect of passing by reference! The result of foo(3) can be easily derived in the same way.To further validate my answer, let's take a look at two additional codes.====== No. 2 ======== is an object, so is  (the former is mutable while the latter is immutable. But the mutability has nothing to do with the question). None is somewhere in the space but we know it's there and there is only one copy of None there. So every time foo is invoked, items is evaluated (as opposed to some answer that it is only evaluated once) to be None, to be clear, the reference (or the address) of None. Then in the foo, item is changed to [], i.e., points to another object which has a different address. ====== No. 3 =======The invocation of foo(1) make items point to a list object [] with an address, say, 11111111. the content of the list is changed to  in the foo function in the sequel, but the address is not changed, still 11111111. Then foo(2,[]) is coming. Although the [] in foo(2,[]) has the same content as the default parameter [] when calling foo(1), their address are different! Since we provide the parameter explicitly,  has to take the address of this new , say 2222222, and return it after making some change. Now foo(3) is executed. since only  is provided, items has to take its default value again. What's the default value? It is set when defining the foo function: the list object located in 11111111. So the items is evaluated to be the address 11111111 having an element 1. The list located at 2222222 also contains one element 2, but it is not pointed by items any more. Consequently, An append of 3 will make  [1,3]. From the above explanations, we can see that the  webpage recommended in the accepted answer failed to give a relevant answer to this question. What is more, I think a point in the effbot webpage is wrong. I think the code regarding the UI.Button is correct:Each button can hold a distinct callback function which will display different value of . I can provide an example to show this:If we execute  we'll get 7 as expected, and  will gives 9, another value of .A very subtle issue being pointed out here. Thanks for all the insights.I ran into a similar problem and found a fix for this.  Now, independent of the number of times you call, this will work as \"expected\"Just change the function to be:"},
{"link": "https://stackoverflow.com//questions/3437059/does-python-have-a-string-contains-substring-method", "qbody": "I'm looking for a  or  method in Python.I want to do:You can use the :If it's just a substring search you can use .You do have to be a little careful with , , and  though, as they are substring searches. In other words, this:It would print  Similarly,  would evaluate to . This may or may not be what you want. is the normal use, as @Michael says -- it relies on the  operator, more readable and faster than a method call.If you truly need a method instead of an operator (e.g. to do some weird  for a very peculiar sort...?), that would be .  But since your example is for use in an , I guess you don't really mean what you say;-).  It's not good form (nor readable, nor efficient) to use special methods directly -- they're meant to be used, instead, through the operators and builtins that delegate to them.No, there isn't any  method, but there is the  operator:Here is a more complex working example:Basically, you want to find a substring in a string in python. There are two ways to search for a substring in a string in Python.You can use the Python's  operator to check for a substring. It's quite simple and intuitive. It will return  if the substring was found in the string else .The second method is to use the  method. Here, we call the  method on the string in which substring is to found. We pass the substring to the find() method and check its return value. If its value is other than -1, the substring was found in the string, otherwise not. The value returned is the index where substring was found.I would recommend you to use the first method as it is more Pythonic and intuitive.Yes, but Python has a comparison operator that you should use instead, because the language intends its usage, and other programmers will expect you to use it. That keyword is , which is used as a comparison operator:The opposite (complement), which the original question asks for, is :This is semantically the same as  but it's much more readable and explicitly provided for in the language as a readability improvement.As promised, here's the  method:returns . You could also call this function from the instance of the superstring:But don't. Methods that start with underscores are considered semantically private. The only reason to use this is when extending the  and  functionality (e.g. if subclassing ): and now:Also, avoid the following string methods:Other languages may have no methods to directly test for substrings, and so you would have to use these types of methods, but with Python, it is more efficient to use the  comparison operator:And now we see that using  -is much faster than the below:So apparently there is nothing similar for vector-wise comparison. An obvious Python way to do so would be:Another way to find whether a string contains a few characters or not with the Boolean return value (i.e.  or `False):In Python there are two simple ways you can achieve this: takes two \"arguments\", one on the left() and one on the right, and returns  if the left argument is contained within the rightside argument and if not,it returns .Output:The  method returns the position of the string within the string or -1 if it's not found. But simply check if the position is not -1.Output:Here is your answer:For checking if it is false:OR:Here are a few useful examples that speak for themselves concerning the  method:Caveat. Lists are iterables, and the  method acts on iterables, not just strings."},
{"link": "https://stackoverflow.com//questions/3207219/how-do-i-list-all-files-of-a-directory", "qbody": "How can I list all files of a directory in Python and add them to a list? will get you everything that's in a directory - files and directories.If you want  files, you could either filter this down using :or you could use  which will yield two lists for each directory it visits - splitting into files and dirs for you. If you only want the top directory you can just break the first time it yieldsAnd lastly, as that example shows, adding one list to another you can either use  or Personally, I prefer I prefer using the  module, as it does pattern matching and expansion.Will return a list with the queried files:will return a list of all files and directories in \"somedirectory\".A one-line solution to get  (no subdirectories):or absolute pathnames:If you'd like, you can open and read the contents, or focus only on files with the extension \".dat\" like in the code below:It's the same as in Python 3 (except the print)I really liked , suggesting that you use , from the module of the same name. This allows you to have pattern matching with s.But as other people pointed out in the comments,  can get tripped up over inconsistent slash directions. To help with that, I suggest you use the  and  functions in the  module, and perhaps the  function in the  module, as well.As examples:The above is terrible - the path has been hardcoded and will only ever work on Windows between the drive name and the s being hardcoded into the path.The above works better, but it relies on the folder name  which is often found on Windows and not so often found on other OSs. It also relies on the user having a specific name, .This works perfectly across all platforms.Another great example that works perfectly across platforms and does something a bit different:Hope these examples help you see the power of a few of the functions you can find in the standard Python library modules.Since version 3.4 there are builtin  for this which are a lot more efficient than :: According to , the aim of the  library is to provide a simple hierarchy of classes to handle filesystem paths and the common operations users do over them. : Note that  use  instead of  from version 3.5 and it's speed got increased by 2-20 times according to .Let me also recommend reading ShadowRanger's comment below.You should use  module for listing directory content. returns all the contents of the directory. We iterate over the result and append to the list.os.listdir returns a list containing the names of the entries in the directory given by path. If you are looking for a Python implementation of , this is a recipe I use rather frequently:So I made a PyPI  out of it and there is also a . I hope that someone finds it potentially useful for this code.Python 3.5 introduced new, faster method for walking through the directory - .Example:List all files in a directory:Here, you get list of all files in a directory.If you care about performance, try , for Python 2.x, you may need to install it manually. Examples:This save a lot of time when you need to scan a huge directory, you do not need to buffer a huge list, just fetch one by one. And also you can do it recursively:Use this function if you want to different file type or get full directory.By using  library.Using generatorsHere is a simple example:Here is the example returning list of files with absolute paths:Documentation:  and  for Python 2,  and  for Python 3."},
{"link": "https://stackoverflow.com//questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python", "qbody": "What is the difference between a function decorated with  and one decorated with ?Maybe a bit of example code will help: Notice the difference in the call signatures of ,  and :Below is the usual way an object instance calls a method. The object instance, , is implicitly passed as the first argument., the class of the object instance is implicitly passed as the first argument instead of .You can also call  using the class. In fact, if you define something to be\na classmethod, it is probably because you intend to call it from the class rather than from a class instance.  would have raised a TypeError, but  works just fine:One use people have found for class methods is to create ., neither  (the object instance) nor   (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:Staticmethods are used to group functions which have some logical connection with a class to the class. is just a function, but when you call  you don't just get the function,\nyou get a \"partially applied\" version of the function with the object instance  bound as the first argument to the function.  expects 2 arguments, while  only expects 1 argument. is bound to . That is what is meant by the term \"bound\" below:With ,  is not bound to , rather the class  is bound to .Here, with a staticmethod, even though it is a method,  just returns\na good 'ole function with no arguments bound.  expects 1 argument, and\n expects 1 argument too.And of course the same thing happens when you call  with the class  instead.A staticmethod is a method that knows nothing about the class or instance it was called on. It just gets the arguments that were passed, no implicit first argument. It is basically useless in Python -- you can just use a module function instead of a staticmethod.A classmethod, on the other hand, is a method that gets passed the class it was called on, or the class of the instance it was called on, as first argument. This is useful when you want the method to be a factory for the class: since it gets the actual class it was called on as first argument, you can always instantiate the right class, even when subclasses are involved. Observe for instance how , a classmethod, returns an instance of the subclass when called on a subclass:Basically  makes a method whose first argument is the class it's called from (rather than the class instance),  does not have any implicit arguments. is a short article on this question@decorators were added in python 2.4 If you're using python < 2.4 you can use the classmethod() and staticmethod() function.For example, if you want to create a factory method (A function returning an instance of a different implementation of a class depending on what argument it gets) you can do something like:Also observe that this is a good example for using a classmethod and a static method,\nThe static method clearly belongs to the class, since it uses the class Cluster internally.\nThe classmethod only needs information about the class, and no instance of the object.Another benefit of making the  method a classmethod is so a subclass can decide to change it's implementation, maybe because it is pretty generic and can handle more than one type of cluster, so just checking the name of the class would not be enough.You may have seen Python code like this pseudocode, which demonstrates the signatures of the various method types and provides a docstring to explain each:First I'll explain the . This may be better called an \"\". When an instance method is used, it is used as a partial function (as opposed to a total function, defined for all values when viewed in source code) that is, when used, the first of the arguments is predefined as the instance of the object, with all of its given attributes. It has the instance of the object bound to it, and it must be called from an instance of the object. Typically, it will access various attributes of the instance.For example, this is an instance of a string:if we use the instance method,  on this string, to join another iterable,\nit quite obviously is a function of the instance, in addition to being a function of the iterable list, :The static method does  take the instance as an argument. Yes it is very similar to a module level function. However, a module level function must live in the module and be specially imported to other places where it is used. If it is attached to the object, however, it will follow the object conveniently through importing and inheritance as well.An example is the  static method, moved from the  module in Python 3.  It makes a translation table suitable for consumption by . It does seem rather silly when used from an instance of a string, as demonstrated below, but importing the function from the  module is rather clumsy, and it's nice to be able to call it from the class, as in In python 2, you have to import this function from the increasingly deprecated string module:A class method is a similar to a static method in that it takes an implicit first argument, but instead of taking the instance, it takes the class. Frequently these are used as alternative constructors for better semantic usage and it will support inheritance.The most canonical example of a builtin classmethod is . It is used as an alternative constructor of dict, (well suited for when you know what your keys are and want a default value for them.)When we subclass dict, we can use the same constructor, which creates an instance of the subclass.See the  for other similar examples of alternative constructors, and see also the official Python documentation on  and .I think a better question is \"When would you use @classmethod vs @staticmethod?\"@classmethod allows you easy access to private members that are associated to the class definition. this is a great way to do singletons, or factory classes that control the number of instances of the created objects exist.@staticmethod provides marginal performance gains, but I have yet to see a productive use of a static method within a class that couldn't be achieved as a standalone function outside the class.To decide whether to use  or  you have to look inside your method. . On the other hand if your method does not touch any other parts of the class then use @staticmethod. just disables the default function as method descriptor.  classmethod wraps your function in a container callable that passes a reference to the owning class as first argument:As a matter of fact,  has a runtime overhead but makes it possible to access the owning class.  Alternatively I recommend using a metaclass and putting the class methods on that metaclass: is one good link for this topic, and summary it as following. function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It\u2019s definition is immutable via inheritance. function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance, can be overridden by subclass. That\u2019s because the first argument for  function must always be  (class).: when this method is called, we pass the class as the first argument instead of the instance of that class (as we normally do with methods). This means you can use the class and its properties inside that method rather than a particular instance. when this method is called, we don't pass an instance of the class to it (as we normally do with methods). This means you can put a function inside a class but you can't access the instance of that class (this is useful when your method does not use the instance).Another consideration with respect to staticmethod vs classmethod comes up with inheritance.  Say you have the following class:And you then want to override  in a child class:This works, but note that now the  implementation in the child class () can no longer take advantage of anything specific to that class.  For example, say  had a method called  that you want to use in the  implementation of :The workaround here would be to call  in , but then you're repeating yourself (if the name of  changes, you'll have to remember to update that  method).To me, this is a slight violation of the , since a decision made in  is impacting your ability to refactor common code in a derived class (ie it's less open to extension).  If  were a  we'd be fine:Gives: In , a classmethod receives a class as the implicit first argument. The class of the object instance is implicitly passed as the first argument. This can be useful\nwhen one wants the method to be a factory of the class as it gets the actual class (which called the method) as the first argument, one can instantiate the right class, even if subclasses are also concerned.A staticmethod is just a function defined inside a class. It does not  know anything about the class or instance it was called on and only gets  the arguments that were passed without any implicit first argument.\nExample:staticmethods are used to group functions which have some logical connection with a class to the class.I will try to explain the basic difference using an example.1 - we can directly call static and classmethods without initializing2- Static method cannot call self method but can call other static and classmethod3- Static method belong to class and will not use object at all.4- Class method are not bound to an object but to a class.A quick hack-up ofotherwise identical methods in iPython reveals that  yields marginal performance gains (in the nanoseconds), but otherwise it seems to serve no function. Also, any performance gains will probably be wiped out by the additional work of processing the method through  during compilation (which happens prior to any code execution when you run a script).For the sake of code readability I'd avoid  unless your method will be used for loads of work, where the nanoseconds count."},
{"link": "https://stackoverflow.com//questions/252703/append-vs-extend", "qbody": "What's the difference between the list methods  and ?: Appends object at end.gives you: : Extends list by appending elements from the iterable.gives you:  adds an element to a list,  concatenates the first list with another list (or another iterable not necessarily a list.)From .And in this context it can also be good to remember that strings are also iterable.The  method appends an object to the end of the list.Whatever the object is, whether a number, a string, another list, or something else, it gets added onto the end of  as a single entry on the list. So keep in mind that a list is an object. If you append another list onto a list, the first list will be a single object at the end of the list (which may not be what you want):The  method extends a list by appending elements from an iterable:So with extend, each element of the iterable gets appended onto the list. For example:Keep in mind that a string is an iterable, so if you extend a list with a string, you'll append each character as you iterate over the string (which may not be what you want):Both  and  operators are defined for . They are semantically similar to extend. creates a third list in memory, so you can return the result of it, but it requires that the second iterable be a list.  modifies the list in-place (it  the in-place operator, and lists are mutable objects, as we've seen) so it does not create a new list. It also works like extend, in that the second iterable can be any kind of iterable.Append has , O(1). Extend has time complexity, O(k). Iterating through the multiple calls to  adds to the complexity, making it equivalent to that of extend, and since extend's iteration is implemented in C, it will always be faster if you intend to append successive items from an iterable onto a listYou may wonder what is more performant, since append can be used to achieve the same outcome as extend. The following functions do the same thing:So let's time them:We see that  can run much faster than , and it is semantically clearer, so it is preferred  If you only have a single element to add to the list, use . appends a single element.  appends a list of elements.Note that if you pass a list to append, it still adds one element:The following two snippets are semantically equivalent:andThe latter may be faster as the loop is implemented in C.You can use \"+\" for returning extend, instead of extending in place.Similarly  for in place behavior, but with slight differences from  & . One of the biggest differences of  from  and  is when it is used in function scopes, see .The append() method adds a single item to the end of the list. The extend() method takes one argument, a list, and appends each of the items of the argument to the original list. (Lists are implemented as classes. \u201cCreating\u201d a list is really instantiating a class. As such, a list has methods that operate on it.)From append(object) - Updates the list by adding an object to the list.extend(list) - Essentially concatenates 2 lists. can be used with an iterator argument. Here is an example. You wish to make a list out of a list of lists this way:fromyou wantYou may use  to do so. This method's output is an iterator. It's implementation is equivalent toBack to our example, we can do and get the wanted list.Here is how equivalently  can be used with an iterator argument:This is the equivalent of  and  using the  operator:An interesting point that has been hinted, but not explained, is that extend is faster than append. For any loop that has append inside should be considered to be replaced by list.extend(processed_elements).Bear in mind that apprending new elements might result in the realloaction of the whole list to a better location in memory. If this is done several times because we are appending 1 element at a time, overall performance suffers. In this sense, list.extend is analogous to \"\".join(stringlist).: It is basically used in Python to add one element.: Where extend(), is used to merge two lists or insert multiple elements in one list.Append adds the entire data at once. The whole data will be added to the newly created index. On the other hand, , as it name suggests, extends the current array. For exampleWith  we get:While on  we get:append:output : [1,2,3,4,5,[\"a\",\"b\",\"c\",\"d\",\"e\"]]extend :output : [1,2,3,4,5,\"a\",\"b\",\"c\",\"d\",\"e\"]The method \"append\" adds its parameter as a  to the list, while \"extend\" gets a list and adds its content.for example,  I hope I can make a useful supplement to this question. If your list stores a specific type object, for example , here is a situation that  method is not suitable: In a  loop and and generating an  object every time and using  to store it into your list, it will fail. The exception is like below:But if you use the  method, the result is OK. Because every time using the  method, it will always treat it as a list or any other collection type, iterate it, and place it after the previous list. A specific object can not be iterated, obviously.extend(L) extends the list by appending all the items in the given list L."},
{"link": "https://stackoverflow.com//questions/4750806/how-do-i-install-pip-on-windows", "qbody": " is a replacement for . But should I install  using  on Windows?  Is there a better way?Good news!  (released March 2014) and  (released December 2014) ship with Pip. This is the best feature of any Python release. It makes the community's wealth of libraries accessible to everyone. Newbies are no longer excluded from using community libraries by the prohibitive difficulty of setup. In shipping with a package manager, Python joins , , , , --almost every other contemporary language with a majority open-source community. Thank you Python.Of course, that doesn't mean Python packaging is problem solved. The experience remains frustrating. I discuss this .And, alas for everyone using Python 2.7.8 or earlier (a sizable portion of the community). There's no plan to ship Pip to you. Manual instructions follow.Flying in the face of its  motto, Python ships without a package manager. To make matters worse, Pip was--until recently--ironically difficult to install.Per :Download , being careful to save it as a  file rather than . Then, run it from the command prompt:You possibly need an administrator command prompt to do this. Follow  (Microsoft TechNet).The official documentation tells users to install Pip and each of its dependencies from source. That's tedious for the experienced, and prohibitively difficult for newbies.For our sake, Christoph Gohlke prepares Windows installers () for popular Python packages. He builds installers for all Python versions, both 32 and 64 bit. You need toFor me, this installed Pip at . Find  on your computer, then add its folder (for example, ) to your path (Start / Edit environment variables). Now you should be able to run  from the command line. Try installing a package:There you go (hopefully)! Solutions for common problems are given below:If you work in an office, you might be behind a HTTP proxy. If so, set the environment variables . Most Python applications (and other free software) respect these. Example syntax:If you're really unlucky, your proxy might be a Microsoft  proxy. Free software can't cope. The only solution is to install a free software friendly proxy that forwards to the nasty proxy. Python modules can be part written in C or C++. Pip tries to compile from source. If you don't have a C/C++ compiler installed and configured, you'll see this cryptic error message.You can fix that by  such as  or . Microsoft actually ship one specifically for use with Python. Or try .Often though it's easier to check  for your package.\n--  -- use setuptools as distribute is deprecated.As you mentioned pip doesn't include an independent installer, but you can install it with its predecessor easy_install.So:You are done. Now you can use  to easily install packages as in Linux :)1) If you have installed Python 3.4 or later, pip is included with Python and should already be working on your system.2) If you are running a version below Python 3.4 or if pip was not installed with Python 3.4 for some reason, then you'd probably use pip's official installation script . The pip installer now grabs setuptools for you, and works regardless of architecture (32-bit or 64-bit).The installation  and involve:I'll leave the two sets of old instructions below for posterity.For Windows editions of the  variety - 64-bit Windows + Python used to require a separate installation method due to ez_setup, but I've tested the new distribute method on 64-bit Windows running 32-bit Python and 64-bit Python, and you can now use the same method for all versions of Windows/Python 2.7X: using :The last step will not work unless you're either in the directory  is located in (C:\\Python27\\Scripts would be the default for Python 2.7), or you have that directory added to your path. using ez_setup: --After this, you may continue with: These answers are outdated or otherwise wordy and difficult.If you've got Python 3.4+ or 2.7.9+, it will be  on Windows.  Otherwise, in short:The new binaries  (and the deprecated ) will be found in the  folder (or similar), which is likely not in your  variable.  I recommend adding it.Python 3.4, which  was released in March 2014, comes with  included:\n\nSo since the release of Python 3.4, the up-to-date way to install pip on Windows is to just install Python.\nWhen sticking to all defaults during installation, pip will be installed to\n.When I have to use Windows, I use ActivePython, which automatically adds everything to your PATH and includes a package manager called  which provides  package management making it faster and simpler to install packages. and  aren't exactly the same thing, so there are some things you can get through  but not  .My recommendation is that you get  and don't worry about the huge hassle of getting everything set up for Python on Windows. Then, you can just use .In case you want to use  you have to check the  option in the ActiveState installer. After installation you only need to logoff and log on again, and  will be available on the commandline, because it is contained in the ActiveState installer  option and the paths have been set by the installer for you already.  will also be available, but you do not have to use it.The up-to-date way is to use Windows' package manager .Once this is installed, all you have to do is open a command prompt and run the following the three commands below, which will install Python 2.7, easy_install and pip. It will automatically detect whether you're on x64 or x86 Windows.All of the other Python packages on the Chocolatey Gallery can be found .Python 2.7.9 and later (on the Python 2 series), and Python 3.4 and later include pip by default, so you may have pip already.If you don't, run this one line command on your prompt (which may require administrator access):It will install . If  is not already installed,  will install it for you too.As mentioned in comments, the above command will download code from the Pip source code repository at , and dynamically run it at your environment. So be noticed that this is a shortcut of the steps download, inspect and run, . If you trust Pip, proceed without doubt.Be sure that your Windows environment variable PATH includes Python's folders (for Python 2.7.x default install:  and , for Python 3.3x:  and , and so on).I've built Windows installers for both  and  here (the goal being to use  without having to either bootstrap with  or save and run Python scripts):On Windows, simply download and install first , then  from the above links. The  link above does contain stub  installers, and these are currently 32-bit only. I haven't tested the effect on 64-bit Windows.The process to redo this for new versions is not difficult, and I've included it here for reference.In order to get the stub  files, you need to have a Visual C++ compiler (it is apparently compilable with MinGW as well)The following works for Python 2.7. Save this script and launch it:  \n  \nPip is installed, then add the path to your environment : FinallyAlso you need Microsoft  to get the good compiler and avoid these kind of messages when installing packages:If you have a 64-bit version of Windows 7, you may read  to successfully install the Python executable package (issue with registry entries).To install pip  on Python 2.x, easy_install appears to be the best solution as Adri\u00e1n states.However the  for pip recommend using  since every virtualenv has pip installed in it automatically.  This does not require root access or modify your system Python installation.Installing virtualenv still requires easy_install though.To use pip, it is not mandatory that you need to install pip in the system directly. You can use it through . What you can do is follow these steps:We normally need to install Python packages for one particular project. So, now create a project folder, let\u2019s say myproject.Now create a virtual environment, let\u2019s say  as follows, inside the  folder:It will show you:Now your virtual environment, , is created inside your project folder. You might notice, pip is now installed inside you virtual environment. All you need to do is activate the virtual environment with the following command.You will see the following at the command prompt:Now you can start using pip, but make sure you have activated the virtualenv looking at the left of your prompt.This is one of the easiest way to install pip i.e. inside virtual environment, but you need to have virtualenv.py file with you.For more ways to install pip/virtualenv/virtualenvwrapper, you can refer to .I just wanted to add one more solution for those having issues installing setuptools from Windows 64-bit. The issue is discussed in this bug on python.org and is still unresolved as of the date of this comment. A simple workaround is mentioned and it works flawlessly. One registry change did the trick for me.Link: Solution that worked for me...:Add this registry setting for 2.6+ versions of Python:This is most likely the registry setting you will already have for Python 2.6+:Clearly, you will need to replace the 2.6 version with whatever version of Python you are running.The best way I found so far, is just two lines of code:It was tested on Windows 8 with , Cmd, and  Bash ().And you probably want to add the path to your environment. It's somewhere like .  should already be included in , but if for whatever reason it is not there, you can use the following one-liner.PS:Can't believe there are so many lengthy (perhaps outdated?) answers out there. Feeling thankful to them but, please up-vote this short answer to help more new comers! comes with  included, among .Here how to install pip with easy way.I use the cross-platform  package manager from continuum.io on Windows and it is reliable.  It has virtual environment management and a fully featured shell with common utilities (e.g. conda, pip). also comes with binaries for libraries with non-Python dependencies, e.g. , , etc.  This proves useful particularly on Windows as it can be  hard to correctly compile C dependencies.I wrote  that wraps both the ez_setup.py and get-pip.py install scripts that were mentioned in Gringo Suave's answer (and runs a pip install --upgrade setuptools for the latest setuptools version once pip is installed).Clone the repository with:Or download a .zip archive:And then run the pipinstall.py script in the top level of the repository directory:This will give you the latest releases for both applications.  It's safe to remove the script repository after the install.I had some issues installing in different ways when I followed instructions here. I think it's very tricky to install in every Windows environment in the same way. In my case I need Python 2.6, 2.7 and 3.3 in the same machine for different purposes so that's why I think there're more problems.\nBut the following instructions worked perfectly for me, so might be depending on your environment you should try this one:Also, due to the different environments I found incredible useful to use Virtual Environments, I had websites that use different libraries and it's much better to encapsulate them into a single folder, check out the instructions, briefly if PIP is installed you just install VirtualEnv:Into the folder you have all your files runAnd seconds later you have a virtual environment with everything in venv folder, to activate it run venv/Scripts/activate.bat (deactivate the environment is easy, use deactivate.bat). Every library you install will end up in venv\\Lib\\site-packages and it's easy to move your whole environment somewhere.The only downside I found is some code editors can't recognize this kind of environments, and you will see warnings in your code because imported libraries are not found. Of course there're tricky ways to do it but it would be nice editors keep in mind Virtual Environments are very normal nowadays.Hope it helps.Guide link: Note: Make sure scripts path like this (C:\\Python27\\Scripts) is added int %PATH% environment variable as well.It's very simple:(Make sure your Python and Python script directory (for example,  and ) are in the PATH.)Working as of Feb 04 2014 :):If you have tried installing pip through the Windows installer file from  as suggested by @Colonel Panic, you might have installed the pip package manager successfully, but you might be unable to install any packages with pip. You might also have got the same SSL error as I got when I tried to install  if you look in the pip.log file:The problem is an issue with an old version of  being incompatible with pip 1.3.1 and above versions. The easy workaround for now, is to install pip 1.2.1, which does not require :Installing Pip on Windows:Now try to install any package using pip.For example, to install the  package using pip, run this from cmd:Whola!  will be successfully installed and you will get a success message.Just download setuptools-15.2.zip (md5), from here  , and run ez_setup.py.Alternatively, you can get  which is an all-in-one installer for pip and  on Windows and its GUI. is already installed if you're using Python 2 >=2.7.9 or Python 3 >=3.4 binaries downloaded from , but you'll need to upgrade pip.On Windows upgrade can be done easily Go to Python command line and run below Python commandpython -m pip install -U pipInstalling with get-pip.pyDownload  in the same folder or any other folder of your choice. I am assuming you will download it in the same folder from you have python.exe file and run this command Pip's  is pretty clean and simple.Using this you should be able to get started with Pip in under two minutes.you have to get the get_pip.py file search it on google copy   from there and  save it locally in c drive in pip directory I think the question makes it seem like the answer is simpler than it really is. Running of pip will sometimes require native compilation of a module (64-bit Numpy is a common example of that). In order for pip's compilation to succeed, you need Python which was compiled with the same version of MSVC as the one pip is using. Standard Python distributions are compiled with MSVC 2008. You can install an Express version of VC2008, but it is not maintained. Your best bet is to get an express version of a later MSVC and compile Python. Then PIP and Python will be using the same MSVC version.How to install pip:There is also an issue with  on . After installation, the output of  command is always empty, no matters what commands/options do you use (even  doesn't produce any output).If it's your case, just install the development version of Cygwin's package  called . Without that package using of  causes a segfault. And  uses that package, so the segfault is the cause of an empty output of  on Cygwin x64. On 32 bit Cygwin it's working fine even without that package.You can read some details there: "}
]