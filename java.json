[
{"body": "Here is a piece of C++ code that seems very peculiar. For some strange reason, sorting the data miraculously makes the code almost six times faster.Initially, I thought this might be just a language or compiler anomaly. So I tried it in Java.With a somewhat similar but less extreme result.My first thought was that sorting brings the data into the cache, but then I thought how silly that is because the array was just generated.Consider a railroad junction:\nNow for the sake of argument, suppose this is back in the 1800s - before long distance or radio communication.You are the operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want. And then you set the switch appropriately.Is there a better way? You guess which direction the train will go!, the train will never have to stop.\n, the train will spend a lot of time stopping, backing up, and restarting. At the processor level, it is a branch instruction:You are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path.Is there a better way? You guess which direction the branch will go!, the execution will never have to stop.\n, you spend a lot of time stalling, rolling back, and restarting.This is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment.So how would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every 3 times, you guess the same... This is more or less how branch predictors work.Most applications have well-behaved branches. So modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless.Further reading: .Notice that the data is evenly distributed between 0 and 255. \nWhen the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement.This is very friendly to the branch predictor since the branch consecutively goes the same direction many times.\nEven a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction.However, when the data is completely random, the branch predictor is rendered useless because it can't predict random data.\nThus there will probably be around 50% misprediction. (no better than random guessing)If the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance.Replace:with:This eliminates the branch and replaces it with some bitwise operations.C++ - Visual Studio 2010 - x64 ReleaseJava - Netbeans 7.1.1 JDK 7 - x64Observations:A general rule of thumb is to avoid data-dependent branching in critical loops. (such as in this example)This goes to show that even mature modern compilers can vary wildly in their ability to optimize code...With a sorted array, the condition  is first  for a streak of values, then becomes  for all later values. That's easy to predict. With an unsorted array, you pay for the branching cost.The reason why performance improves drastically when the data is sorted is that the branch prediction penalty is removed, as explained beautifully in 's answer.Now, if we look at the codewe can find that the meaning of this particular  branch is to add something when a condition is satisfied. This type of branch can be easily transformed into a  statement, which would be compiled into a conditional move instruction: , in an  system. The branch and thus the potential branch prediction penalty is removed.In , thus , the statement, which would compile directly (without any optimization) into the conditional move instruction in , is the ternary operator . So we rewrite the above statement into an equivalent one:While maintaining readability, we can check the speedup factor.On an Intel -2600K @ 3.4\u00a0GHz and Visual Studio 2010 Release Mode, the benchmark is (format copied from Mysticial):The result is robust in multiple tests. We get a great speedup when the branch result is unpredictable, but we suffer a little bit when it is predictable. In fact, when using a conditional move, the performance is the same regardless of the data pattern.Now let's look more closely by investigating the  assembly they generate. For simplicity, we use two functions  and . uses the conditional branch : uses the ternary operator :On a x86-64 machine,  generates the assembly below. uses much less code due to the usage of instruction . But the real gain is that  does not involve branch jumps, , which would have a significant performance penalty if the predicted result is not right.So why does a conditional move perform better?In a typical  processor, the execution of an instruction is divided into several stages. Roughly, we have different hardware to deal with different stages. So we do not have to wait for one instruction to finish to start a new one. This is called .In a branch case, the following instruction is determined by the preceding one, so we cannot do pipelining. We have to either wait or predict.In a conditional move case, the execution conditional move instruction is divided into several stages, but the earlier stages like  and  does not depend on the result of the previous instruction; only latter stages need the result. Thus, we wait a fraction of one instruction's execution time. This is why the conditional move version is slower than the branch when prediction is easy.The book  explains this in detail. You can check Section 3.6.6 for , entire Chapter 4 for , and Section 5.11.2 for a special treatment for .Sometimes, some modern compilers can optimize our code to assembly with better performance, sometimes some compilers can't (the code in question is using Visual Studio's native compiler). Knowing the performance difference between branch and conditional move when unpredictable can help us write code with better performance when the scenario gets so complex that the compiler can not optimize them automatically.If you are curious about even more optimizations that can be done to this code, consider this... Starting with the original loop:With loop interchange, we can safely change this loop to:Then, you can see that the \"if\" conditional is constant throughout the execution of the \"i\" loop, so you can hoist the \"if\" out:Then, you see that the inner loop can be collapsed into one single expression, assuming the floating point model allows it (/fp:fast is thrown, for example)That one is 100,000x faster than before (-8No doubt some of us would be interested in ways of identifying code that is problematic for the CPU's branch-predictor. The Valgrind tool  has a branch-predictor simulator, enabled by using the  flag. Running it over the examples in this question, with the number of outer loops reduced to 10000 and compiled with , gives these results:Drilling down into the line-by-line output produced by  we see for the loop in question:This lets you easily identify the problematic line - in the unsorted version the  line is causing 164,050,007 mispredicted conditional branches () under cachegrind's branch-predictor model, whereas it's only causing 10,006 in the sorted version.Alternatively, on Linux you can use the performance counters subsystem to accomplish the same task, but with native performance using CPU counters.It can also do source code annotation with dissassembly.See  for more details.Just read up on the thread and I feel an answer is missing. A common way to eliminate branch prediction that I've found to work particularly good in managed languages is a table lookup instead of using a branch. (although I haven't tested it in this case)This approach works in general if:Pfew, so what the hell is that supposed to mean?From a processor perspective, your memory is slow. To compensate for the difference in speed, they build in a couple of caches in your processor (L1/L2 cache) that compensate for that. So imagine that you're doing your nice calculations and figure out that you need a piece of memory. The processor will get his 'load' operation and loads the piece of memory into cache - and then uses the cache to do the rest of the calculations. Because memory is relatively slow, this 'load' will slow down your program. Like branch prediction, this was optimized in the Pentium processors: the processor predicts that it needs to load a piece of data and attempts to load that into the cache before the operation actually hits the cache. As we've already seen, branch prediction sometimes goes horribly wrong -- in the worst case scenario you need to go back and actually wait for a memory load, which will take forever ().Fortunately for us, if the memory access pattern is predictable, the processor will load it in its fast cache and all is well.First thing we need to know is what is ? While smaller is generally better, a rule of thumb is to stick to lookup tables that are <=4096 bytes in size. As an upper limit: if your lookup table is larger than 64K it's probably worth reconsidering.So we've figured out that we can create a small table. Next thing to do is get a lookup function in place. Lookup functions are usually small functions that use a couple of basic integer operations (and, or, xor, shift, add, remove and perhaps a multiply). What you want is to have your input translated by the lookup function to some kind of 'unique key' in your table, which then simply gives you the answer of all the work you wanted it to do.In this case: >=128 means we can keep the value, <128 means we get rid of it. The easiest way to do that is by using an 'AND': if we keep it, we AND it with 7FFFFFFF ; if we want to get rid of it, we AND it with 0. Notice also that 128 is a power of 2 -- so we can go ahead and make a table of 32768/128 integers and fill it with one zero and a lot of 7FFFFFFFF's.You might wonder why this works well in managed languages. After all, managed languages check the boundaries of the arrays with a branch to ensure you don't mess up...Well, not exactly... :-)There has been quite some work on eliminating this branch for managed languages. For example:in this case it's obvious to the compiler that the boundary condition will never hit. At least the Microsoft JIT compiler (but I expect Java does similar things) will notice this and remove the check all together. WOW - that means no branch. Similarly, it will deal with other obvious cases.If you run into trouble with lookups on managed languages - the key is to add a  to your lookup function to make the boundary check predictable - and watch it going faster.As data is distributed between 0 and 255 when array is sorted, around first half of the iterations will not enter the if-statement (if statement shared below).Question is what make the above statement not execute in certain case as in case of sorted data? Here comes the \"Branch predictor\" a branch predictor is a digital circuit that tries to guess which way a branch (e.g. an if-then-else structure) will go before this is known for sure. The purpose of the branch predictor is to improve the flow in the instruction pipeline. Branch predictors play a critical role in achieving high effective performance!The performance of an if-statement depends on whether its condition has a predictable pattern. If the condition is always true or always false, the branch prediction logic in the processor will pick up the pattern. On the other hand, if the pattern is unpredictable, the if-statement will be much more expensive.Let\u2019s measure the performance of this loop with different conditions:Here are the timings of the loop with different True-False patterns:A \u201c\u201d true-false pattern can make an if-statement up to six times slower than a \u201c\u201d pattern! Of course, which pattern is good and which is bad depends on the exact instructions generated by the compiler and on the specific processor.So there is no doubt about impact of branch prediction on performance!One way to avoid branch prediction errors is to build a lookup table, and index it using the data.  Stefan de Bruijn discussed that in his answer.But in this case, we know values are in the range [0, 255] and we only care about values >= 128.  That means we can easily extract a single bit that will tell us whether we want a value or not: by shifting the data to the right 7 bits, we are left with a 0 bit or a 1 bit, and we only want to add the value when we have a 1 bit.  Let's call this bit the \"decision bit\".By using the 0/1 value of the decision bit as an index into an array, we can make code that will be equally fast whether the data is sorted or not sorted.  Our code will always add a value, but when the decision bit is 0, we will add the value somewhere we don't care about.  Here's the code:This code wastes half of the adds, but never has a branch prediction failure.  It's tremendously faster on random data than the version with an actual if statement.But in my testing, an explicit lookup table was slightly faster than this, probably because indexing into a lookup table was slightly faster than bit shifting.  This shows how my code sets up and uses the lookup table (unimaginatively called  for \"LookUp Table\" in the code).  Here's the C++ code:In this case the lookup table was only 256 bytes, so it fit nicely in cache and all was fast.  This technique wouldn't work well if the data was 24-bit values and we only wanted half of them... the lookup table would be far too big to be practical.  On the other hand, we can combine the two techniques shown above: first shift the bits over, then index a lookup table.  For a 24-bit value that we only want the top half value, we could potentially shift the data right by 12 bits, and be left with a 12-bit value for a table index.  A 12-bit table index implies a table of 4096 values, which might be practical.EDIT: One thing I forgot to put in.The technique of indexing into an array, instead of using an  statement, can be used for deciding which pointer to use.  I saw a library that implemented binary trees, and instead of having two named pointers ( and  or whatever) had a length-2 array of pointers, and used the \"decision bit\" technique to decide which one to follow.  For example, instead of:this library would do something like:Here's a link to this code: , In the sorted case, you can do better than relying on successful branch prediction or any branchless comparison trick: completely remove the branch.Indeed, the array is partitioned in a contiguous zone with  and another with . So you should find the partition point with a dichotomic search (using  comparisons), then do a straight accumulation from that point.Something like (unchecked)or, slightly more obfuscatedA yet faster approach, that gives an  solution for both sorted or unsorted is:  (assuming a truly uniform distribution, 16384 samples with expected value 191.5) The above behavior is happening because of Branch prediction.To understand branch prediction one must first understand :Any instruction is broken into sequence of steps so that different steps can be executed concurrently in parallel. This technique is known as instruction pipeline and this is used to increase throughput in modern processors. To understand this better please see this .Generally modern processors have quite long pipelines, but for ease let's consider these 4 steps only.\nMoving back to the above question let's consider the following instructions:Without branch prediction the following would occur:To execute instruction B or instruction C the processor will have to wait till the instruction A doesn't reach till EX stage in the pipeline, as the decision to go to instruction B or instruction C depends on the result of instruction A. So the pipeline will look like this.\n\nAs a result of waiting for the result of instruction A, the total CPU cycles spent in the above case (without branch prediction; for both true and false) is 7.Branch predictor will tries to guess which way a branch (an if-then-else structure) will go before this is known for sure. It will not wait for the instruction A to reach the EX stage of the pipeline, but it will guess the decision and go onto that instruction (B or C in case of our example).\nIf it is later detected that the guess was wrong then the partially executed instructions are discarded and the pipeline starts over with the correct branch, incurring a delay. \nThe time that is wasted in case of a branch misprediction is equal to the number of stages in the pipeline from the fetch stage to the execute stage. Modern microprocessors tend to have quite long pipelines so that the misprediction delay is between 10 and 20 clock cycles. The longer the pipeline the greater the need for a good .In the OP's code, the first time when the conditional, the branch predictor does not have any information to base up prediction, so first time it will randomly choose the next instruction. Later in the for loop it can base the prediction on the history. \nFor an array sorted in ascending order, there are three possibilities:Let us assume that the predictor will always assume the true branch on the first run.So in the first case it will always take the true branch since historically all its predictions are correct.\nIn the 2nd case, initially it will predict wrong, but after a few iterations it will predict correctly.\nIn the 3rd case it will initially predict correctly till the elements are less than 128. After which it will fail for some time and the correct itself when it see branch prediction failure in history. In all these cases the failure will be too less in number and as a result only few times it will need to discard the partially executed instructions and start over with the correct branch, resulting in less CPU cycles. But in case of random unsorted array, the prediction will need to discard the partially executed instructions and start over with the correct branch most of the time and result in more CPU cycles compared to the sorted array.An official answer would be fromYou can also see from this lovely  why the branch predictor gets confused.Each element in the original code is a random valueso the predictor will change sides as the  blow.On the other hand, once it's sorted, the predictor will first move into a state of strongly not taken and when the values change to the high value the predictor will in three runs through change all the way from strongly not taken to strongly taken.In the same line (I think this was not highlighted by any answer) it's good to mention that sometimes (specially in software where the performance matters\u2014like in the Linux kernel) you can find some if statements like the following:or similarly:Both  and  are in fact macros that are defined by using something like the GCC's  to help the compiler insert prediction code to favour the condition taking into account the information provided by the user. GCC supports other builtins that could change the behavior of the running program or emit low level instructions like clearing the cache, etc. See  that goes through the available GCC's builtins.Normally this kind of optimizations are mainly found in hard-real time applications or embedded systems where execution time matters and it's critical. For example, if you are checking for some error condition that only happens 1/10000000 times, then why not inform the compiler about this? This way, by default, the branch prediction would assume that the condition is false.Frequently used Boolean operations in C++ produce many branches in compiled program. If these branches are inside loops and are hard to predict they can slow down execution significantly. Boolean variables are stored as 8-bit integers with the value  for  and  for .Boolean variables are overdetermined in the sense that all operators that have Boolean variables as input check if the inputs have any other value than  or , but operators that have Booleans as output can produce no other value than  or . This makes operations with Boolean variables as input less efficient than necessary.\nConsider example:This is typically implemented by the compiler in the following way:This code is far from optimal. The branches may take a long time in case of mispredictions. The Boolean operations can be made much more efficient if it is known with certainty that the operands have no other values than  and . The reason why the compiler does not make such an assumption is that the variables might have other values if they are uninitialized or come from unknown sources. The above code can be optimized if  and  have been initialized to valid values or if they come from operators that produce Boolean output. The optimized code looks like this: is used instead of  in order to make it possible to use the bitwise operators ( and ) instead of the Boolean operators ( and ). The bitwise operators are single instructions that take only one clock cycle. The OR operator () works even if  and  have other values than  or . The AND operator () and the EXCLUSIVE OR operator () may give inconsistent results if the operands have other values than  and . can not be used for NOT. Instead, you can make a Boolean NOT on a variable which is known to be  or  by XOR'ing it with :can be optimized to: cannot be replaced with  if  is an expression that should not be evaluated if  is  (  will not evaluate ,  will). Likewise,  can not be replaced with  if  is an expression that should not be evaluated if  is .Using bitwise operators is more advantageous if the operands are variables than if the operands are comparisons:is optimal in most cases (unless you expect the  expression to generate many branch mispredictions).This question has already been answered excellently many times over. Still I'd like to draw the group's attention to yet another interesting analysis.Recently this example (modified very slightly) was also used as a way to demonstrate how a piece of code can be profiled within the program itself on Windows. Along the way, the author also shows how to use the results to determine where the code is spending most of its time in both the sorted & unsorted case. Finally the piece also shows how to use a little known feature of the HAL (Hardware Abstraction Layer) to determine just how much branch misprediction is happening in the unsorted case.The link is here:\ntry n do it anything\nIf you are curious about even more optimisations that can be done to this code, consider this... Starting with the original loop:With loop interchange, we can safely change this loop to:Then, you can see that the \"if\" conditional is constant throughout the execution of the \"i\" loop, so you can hoist the \"if\" out:Then, you see that the inner loop can be collapsed into one single expression, assuming the floating point model allows it (/fp:fast is thrown, for example)That one is 100,000x faster than before "},
{"body": "I'm trying to install the Android SDK on my Windows 7 x64 System.  is installed, but the Android SDK setup refuses to proceed, because it doesn't find the JDK installation.Is this a known issue? And is there a solution?Press  when you get the notification and then . This time it will find the JDK. Actual SETUP:Install the x64 JDK, and try the back-next option first, and then try setting  like the error message says, but if that doesn't work for you either, then try this:Do as it says, set  in your environment variables, but in the path use forward slashes instead of backslashes.Seriously.For me it failed when  was  but worked fine when it was  - drove me nuts!If this is not enough, also add to the beginning of the Environment Variable   Updated values in System Environment Variables:I found the solution and it's beautifully stupid. I found .Press the  button on the SDK error screen that tells you that the EXE couldn't detect the JDK. Then press .Who would have thought that would happen?It seems like it doesn't work without 32 bit JDK.\nJust install it and be happy...I downloaded the .zip archive instead and ran , and it worked like a charm. You had the same issue with the .exe otherwise.Warning: As a commenter mentioned, don't try this on a Windows\u00a07! I tested it with Windows\u00a0XP 64 bit.As the posted solution does NOT work for all (including me, myself, and I), I want to leave a note for those seeking for another way (without registry hacking, etc.) to solve this on a Windows 64 bit system. Just add PATH (capital letters!!) to your environment Variables and set the value to your JDK-Path.I added JDK to the existing \"Path\" which did not work, like it didn't with JAVA_HOME or the \"Back\"-Solution. Adding it to \"PATH\" finally did the trick.I hope this might be helpful for somebody.All you need are the following two registry entries. It appears as if whoever posted the other registry stuff basically just copied all the keys from  into ,\nwhich obviously isn't an ideal solution because most of the keys aren't needed.Non of these solutions worked for me. I fixed it by temporarily changing the filename of  to None of the solutions here worked for the 64-bit version.Putting the JDK path before the c:\\windows\\system32\\ path in your environment variables solves the problem. Otherwise the 32-bit java.exe is found before the 64-bit JDK version.After reading a couple of blog posts, it does seem to be even an easier fix by clicking  when the installer says couldn't find the JDK, and then simply click  again and magically it finds the JDK. No registry messing around or re-downloading etc..Adding JAVA_HOME environment variable (under ) did the trick for me. \nClicking \"Back\" and \"Next\" buttons didn't work.Windows 7 Professional x64, JDK 1.7.0_04 (64 bit, I don't have x86 version installed)I think that installer tries to find JDK in specific (1.6?) version and if it can't find it, checks JAVA_HOME which was not set in my case. I have another computer (the same system but with JDK 1.6 x64) and it worked without JAVA_HOME variable.I copied the Java.exe from to and it worked.I'm using 64 bit Windows 8.Setting the  environment variable to instead of fixed it for me.This registry fix worked  like a charm on my Windows 7 x64 setup:  Press  and .  will be enabled.The guy above who put this: \"I experienced this problem too, but none of the answers helped. What I did,  This was in fact the correct answer.For this SDK to install this is what I did. I am running the latest Microsoft OS Windows 8.This is what I did and it worked for me. =)Try downloading and installing the zipped version rather than the .exe installer.Also, ! Worked for me with backslash fix.I had the same problem and solved it by installing the x86 version of the JDK (on Windows\u00a0XP x64).I had the same problem, tried all the solutions but nothing worked. The problem is with Windows 7 installed is 64 bit and all the software that you are installing should be 32 bit. Android SDK itself is 32 bit and it identifies only 32 bit JDK. So install following software.I tried it and all works fine.I experienced this problem too, but none of the answers helped. What I did, I removed the last backslash from the JAVA_HOME variable and it started working. Also, remember not to include the bin folder in the path.Android SDK is 32 bit app, and it requires the 32 bit of JDK to work... the 64 bit JDK won't make any use for it...1-Simply done the \"JAVA_HOME\" environment variable thing.2-Right-Click on Android SDK and from compatibletiy Tab Select windows 7 and administrator.3-Run it again.Simply put your java bin path in front of your PATH environment.PATH beforePATH afterAnd now the Android SDK installer is working.BTW, I'm running Win7 x64.Yeah install the 32 bit version of the Java SE SDK (or any of the combinations). That should help solve your problem.For installer_r21.1-windows.exe on Windows 8 x 64 what worked for me was setting up my user environment variable JAVA_HOME to C:\\Program Files\\Java\\jdk1.7.0_10.\nHope this helps you all! :)You will have to download the 32-bit SDK version because Win7 64-bit is not supported only Windows Server 2003 has a supported 64-bit version.  During the download of Java SDK pick \"Windows\" as your platform and not \"Windowsx64\".\nOnce I did this android SDK installed like a charm.  Hope this helps.I'm running a 64-bit version of Windows 7 and I was getting this issue when attempting to install Android Studio 1.0 using the executable from:I tried all the listed solutions and several different versions of JDK 1.7 and 1.8 -- no dice. I went with installing the zipped version of the application and it worked like a charm:Still baffled by this problem; especially since beta versions of Android Studio worked just fine.The above methods did not work for me in Windows 8 Pro.Just set the path to Where C is your drive in which you have installed the JDK.Don't forget the backward slash at the end.I tried several posted solutions and then it took a system reboot before it started working, which may have been because I had just installed the JDK.  Here are all the things I had going on - not sure which ones were essential:"},
{"body": "I came across some Java code that had the following structure:I know that in C++ I can assign a parameter a default value.  For example:Does Java support this kind of syntax?  Are there any reasons why this two step syntax is preferable?No, the structure you found is how Java handles it (that is, with overloading instead of default parameters).For constructors,  Item 1 tip (Consider static factory methods instead of constructors) if the overloading is getting complicated. For other methods, renaming some cases or using a parameter object can help. This is when you have enough complexity that differentiating is difficult. A definite case is where you have to differentiate using the order of parameters, not just number and type.No, but you can use the , as described in .As described in the linked answer, the Builder Pattern lets you write code likein which some fields can have default values or otherwise be optional.There are several ways to simulate default parameters in Java:Please note that you can combine any of these approaches to achieve a desirable result.Sadly, no.Unfortunately, yes.could be written in Java 1.5 as:But whether or not you should depend on how you feel about the compiler generating afor each call.For multiple defaultable parameters:could be written in Java 1.5 as:This matches C++ syntax, which only allows defaulted parameters at the end of the parameter list.  Beyond syntax, there is a difference where this has run time type checking for passed defaultable parameters and C++ type checks them during compile.No, but you can very simply emulate them. What in C++ was:In Java, it will be an overloaded function:Earlier was mentioned, that default parameters caused ambiguous cases in function overloading. That is simply not true, we can see in the case of the C++: yes, maybe it can create ambiguous cases, but these problem can be easily handled. It simply wasn't developed in Java, probably because the creators wanted a much simpler language as C++ was - if they had right, is another question. But most of us don't think he uses Java because of its simplicity.You can do this is in Scala, which runs on the JVM and is compatible with Java programs.\ni.e.I might be stating the obvious here but why not simply implement the \"default\" parameter yourself?for the default you would ether usefunc(\"my string\");and if you wouldn't like to use the default, you would usefunc(\"my string\", false);No. In general Java doesn't have much (any) syntactic sugar, since they tried to make a simple language.It is not supported but there are several options like using parameter object pattern with some syntax sugar:In this sample we construct  with default values and override them in class instance initialization section No. You can achieve the same behavior by passing an Object which has smart defaults. But again it depends what your case is at hand.Try this solution:There are half a dozen or better issues such as this, eventually you arrive at the static factory pattern ... see the crypto api for that. Sort difficult to explain, but think of it this way: If you have a constructor, default or otherwise, the only way to propagate state beyond the curly braces is either to have a Boolean isValid; ( along with the null as default value v failed constructor ) or throw an exception which is never informative when getting it back from field users.Code Correct be damned, I write thousand line constructors and do what I need. I find using isValid at object construction - in other words, two line constructors - but for some reason I am migrating to the static factory pattern. I just seems you can do a lot if you in a method call, there are still sync() issues but defaults can be 'substituted' better ( safer )I think what we need to do here is address the issue of null as default value vis-a-vis something String one=new String(\"\"); as a member variable, then doing a check for null before assigning string passed to the constructor. Very remarkable the amount of raw, stratospheric computer science done in Java.C++ and so on has vendor libs, yes. Java can outrun them on large scale servers due to it's massive toolbox. Study static initializer blocks, stay with us.A similar approach to  that works in Java 8 is to use an interface with default getters. This will be more whitespace verbose, but is mockable, and it's great for when you have a bunch of instances where you actually want to draw attention to the parameters.This is how I did it ... it's not as convenient perhaps as having an 'optional argument' against your defined parameter, but it gets the job done:Notice I can invoke the same method name with either just a string or I can invoke it with a string and a boolean value. In this case, setting wipeClean to true will replace all of the text in my TextArea with the provided string. Setting wipeClean to false or leaving it out all together simply appends the provided text to the TextArea.Also notice I am not repeating code in the two methods, I am merely adding the functionality of being able to reset the TextArea by creating a new method with the same name only with the added boolean.I actually think this is a little cleaner than if Java provided an 'optional argument' for our parameters since we would need to then code for default values etc. In this example, I don't need to worry about any of that. Yes, I have added yet another method to my class, but it's easier to read in the long run in my humble opinion.You may use  to automatically generate the builder with default values.Just add @GenerateMethodInvocationBuilder to the class, or interface, and the @Default to parameters in methods where you want default values. A builder will be generated at compile time, using the default values that you specified with your annotations.And then you can invoke the methods.Or set any of the default values to something else.NO, But we have alternative in the form of function overloading.called when no parameter passedcalled when \"a\" parameter was passedcalled when parameter b passed"},
{"body": "I understood, I think, that a \"Bean\" is a Java class with properties and getters/setters. As much as I understand, it is the equivalent of a C struct. Is that true?Also, is there a real  difference between a bean and a regular class? Is there any special definition or an interface?Basically, why is there a term for this?: If you can be so kind and add information regarding the  interface, and what it means, to your answer, I'd be very grateful.A JavaBean is just a That's it. It's just a convention.  Lots of libraries depend on it though....With respect to , from the :In other words, serializable objects can be written to streams, and hence files, object databases, anything really.  Also, there is no syntactic difference between a JavaBean and another class -- a class defines a JavaBean if it follows the standards.There is a term for it because the standard allows libraries to programmatically do things with class instances you define in a predefined way. For example, if a library wants to stream any object you pass into it, it knows it can because your object is serializable (assuming the lib requires your objects be proper JavaBeans). There's a term for it to make it sound special.  The reality is nowhere near so mysterious.Basically, a \"Bean\":Update:As for :  That is nothing but a \"marker interface\" (an interface that doesn't declare any functions) that tells Java that the implementing class consents to (and implies that it is capable of) \"serialization\" -- a process that converts an instance into a stream of bytes.  Those bytes can be stored in files, sent over a network connection, etc, and have enough info to allow a JVM (at least, one that knows about the object's type) to reconstruct the object later -- possibly in a different instance of the application, or even on a whole other machine!Of course, in order to do that, the class has to abide by certain limitations.  Chief among them is that all instance fields must be either primitive types (int, bool, etc), instances of some class that is also serializable, or marked as  so that Java won't try to include them.  (This of course means that  fields will not survive the trip over a stream.  A class that has  fields should be prepared to reinitialize them if necessary.)A class that can not abide by those limitations should not implement  (and, IIRC, the Java compiler won't even  it do so.)JavaBeans are Java classes which adhere to an extremely simple coding convention.\nAll you have to do is to Properties of JavaBeansA JavaBean is a Java object that satisfies certain programming conventions: Example of JavaBeansJava Beans are using for less code and more work approach... \nJava Beans are used throughout Java EE as a universal contract for runtime discovery and access. For example, JavaServer Pages (JSP) uses Java Beans as data transfer objects between pages or between servlets and JSPs. Java EE's JavaBeans Activation Framework uses Java Beans for integrating support for MIME data types into Java EE. The Java EE Management API uses JavaBeans as the foundation for the instrumentation of resources to be managed in a Java EE environment. About Serialization:In object serialization an object can be represented as a sequence of bytes that includes the object's data as well as information about the object's type and the types of data stored in the object.After a serialized object has been written into a file, it can be read from the file and deserialized that is, the type information and bytes that represent the object and its data can be used to recreate the object in memory.You will find Serialization useful when deploying your project across multiple servers since beans will be persisted and transferred across them.As per the Wikipedia:For more information follow this Explanation with an example.As for the Serialization, see the .Fields should be private for prevent outer classes to easily modify those fields.\nInstead of directly accesing to those fields, usuagly getter/setter methods are used.A public constructor without any argument.Getter and setter methods for accesing private fields.Regarding the second part of your question, Serialization is a persistence mechanism used to store objects as a sequence of signed bytes. Put less formally, it stores the state of an object so you can retrieve it later, by de-serialization.They are serializable, have a zero-argument constructor, and allow access to properties using getter and setter methods. The name \"Bean\" was given to encompass this standard, which aims to create reusable software components for Java. The objects that form the backbone of your application and that are managed by the Spring IoC container are called beans. A bean is an object that is instantiated, assembled, and otherwise managed by a Spring IoC container. Otherwise, a bean is simply one of many objects in your application. \n .Java Beans is a standard, and its basic syntax requirements have been clearly explained by the other answers.However, IMO, it is more than a simple syntax standard. The real meaning or intended usage of Java Beans is, together with various tool supports around the standard,  to facilitate code reuse and component-based software engineering, i.e. enable developers to build applications by assembling existing components (classes) and without having to write any code (or only have to write a little glue code). Unfortunately this technology is way under-estimated and under-utilized by the industry, which can be told from the answers in this thread.If you read Oracle's , you can get a better understanding in that.To understand JavaBean you need to notice the followings:\nJavaBean is a conceptual stuff and can not represent a class of specific thingsJavaBean is a development tool can be visualized in the operation of reusable software componentsJavaBean is based on the Sun JavaBeans specification and can be  reusable components. Its biggest feature is the re-usability.A Java Bean is a java class [conceptual] that should follow following conventions:It is a reusable software component. It can encapsulate many object into one object so that same object can be accessed from multiples places and is a step towards easy maintenance of code. are just ordinary Java classes that follow certain conventions - you don't need special tools to create them.There are two primary conventions that must be followed in creating Java Bean classes:"},
{"body": "What's the advantage of using getters and setters - that only get and set - instead of simply using public fields for those variables?If getters and setters are ever doing more than just the simple get/set, I can figure this one out very quickly, but I'm not 100% clear on how:is any worse than:Whereas the former takes a lot less boilerplate code.\n rather than directly exposing fields of a class - beyond just the argument of encapsulation and making future changes easier. Because 2 weeks (months, years) from now when you realize that your setter needs to do  than just set the value, you'll also realize that the property has been used directly in 238 other classes :-)A public field is not worse than a getter/setter pair that does nothing except returning the field and assigning to it. First, it's clear that (in most languages) there is no functional difference. Any difference must be in other factors, like maintainability or readability.An oft-mentioned advantage of getter/setter pairs, isn't. There's this claim that you can change the implementation and your clients don't have to be recompiled. Supposedly, setters let you add functionality like validation later on and your clients don't even need to know about it. However, adding validation to a setter is a change to its preconditions, , which was, quite simply, \"you can put anything in here, and you can get that same thing later from the getter\".So, now that you broke the contract, changing every file in the codebase is something you should want to do, not avoid. If you avoid it you're making the assumption that all the code assumed the contract for those methods was different.If that should not have been the contract, then the interface was allowing clients to put the object in invalid states.  If that field could not really be set to anything from the start, why wasn't the validation there from the start?This same argument applies to other supposed advantages of these pass-through getter/setter pairs: if you later decide to change the value being set, you're breaking the contract. If you override the default functionality in a derived class, in a way beyond a few harmless modifications (like logging or other non-observable behaviour), you're breaking the contract of the base class. That is a violation of the Liskov Substitutability Principle, which is seen as one of the tenets of OO.If a class has these dumb getters and setters for every field, then it is a class that has no invariants whatsoever, . Is that really object-oriented design? If all the class has is those getters and setters, it's just a dumb data holder, and dumb data holders should look like dumb data holders:Adding pass-through getter/setter pairs to such a class adds no value. Other classes should provide meaningful operations, not just operations that fields already provide. That's how you can define and maintain useful invariants.There are reasons to use getters and setters, but if those reasons don't exist, making getter/setter pairs in the name of false encapsulation gods is not a good thing. Valid reasons to make getters or setters include the things often mentioned as the potential changes you can make later, like validation or different internal representations. Or maybe the value should be readable by clients but not writable (for example, reading the size of a dictionary), so a simple getter is a nice choice. But those reasons should be there when you make the choice, and not just as a potential thing you may want later. This is an instance of YAGNI ().Lots of people talk about the advantages of getters and setters but I want to play devil's advocate. Right now I'm debugging a very large program where the programmers decided to make everything getters and setters. That might seem nice, but its a reverse-engineering nightmare.Say you're looking through hundreds of lines of code and you come across this:It's a beautifully simply piece of code until you realize its a setter. Now, you follow that setter and find that it also sets person.firstName, person.lastName, person.isHuman, person.hasReallyCommonFirstName, and calls person.update(), which sends a query out to the database, etc. Oh, that's where your memory leak was occurring.Understanding a local piece of code at first glance is an important property of good readability that getters and setters tend to break. That is why I try to avoid them when I can, and minimize what they do when I use them.There are many reasons. My favorite one is when you need to change the behavior or regulate what you can set on a variable. For instance, lets say you had a setSpeed(int speed) method. But you want that you can only set a maximum speed of 100. You would do something like:Now what if EVERYWHERE in your code you were using the public field and then you realized you need the above requirement? Have fun hunting down every usage of the public field instead of just modifying your setter.My 2 cents :)One advantage of accessors and mutators is that you can perform validation.For example, if  was public, I could easily set it to  and then someone else could try to call a method on the object. But it's not there anymore! With a  method, I could ensure that  was never set to .Accessors and mutators also allow for encapsulation - if you aren't supposed to see the value once its set (perhaps it's set in the constructor and then used by methods, but never supposed to be changed), it will never been seen by anyone. But if you can allow other classes to see or change it, you can provide the proper accessor and/or mutator.In a pure object-oriented world getters and setters is a . Read this article: . In a nutshell, they encourage programmers to think about objects as of data structures, and this type of thinking is pure procedural (like in COBOL or C). In an object-oriented language there are no data structures, but only objects that expose behavior (not attributes/properties!)You may find more about them in Section 3.5 of  (my book about object-oriented programming).Depends on your language.  You've tagged this \"object-oriented\" rather than \"Java\", so I'd like to point out that ChssPly76's answer is language-dependent.  In Python, for instance, there is no reason to use getters and setters.  If you need to change the behavior, you can use a property, which wraps a getter and setter around basic attribute access.  Something like this:Well i just want to add that even if sometimes they are necessary for the encapsulation and security of your variables/objects, if we want to code a real Object Oriented Program, then we need to , cause sometimes we depend a lot on them when is not really necessary and that makes almost the same as if we put the variables public.Thanks, that really clarified my thinking. Now here is (almost) 10 (almost) good reasons NOT to use getters and setters:The last three I'm just leaving (N/A or D/C)...Getter and setter methods are public interfaces to access private class members.The encapsulation mantra is to make fields private and methods public.Even though the getter and setter methods do not add new functionality, we can change our mind come back later to make that methodAnywhere a value can be used, a method that returns that value can be added. Instead of:useSuppose we need to store the details of this . This  has the fields ,  and . Doing this involves creating methods for ,  and . Now if we need create another person, it becomes necessary to create the methods for , ,  all over again.Instead of doing this, we can create a bean  with getter and setter methods.  So tomorrow we can just create objects of this Bean  whenever we need to add a new person (see the figure). Thus we are reusing the fields and methods of bean class, which is much better.I know it's a bit late, but I think there are some people who are interested in performace :)I've done a little performance test. I wrote a class \"NumberHolder\" which, well, holds an Integer. You can either read that Integer by using the getter method\n or by directly accessing the number by using . My programm reads the number 1,000,000,000 times, via both ways. That process is repeated five times and the time is printed. I've got the following result:(Time 1 is the direct way, Time 2 is the getter)You see, the getter is (almost) always a bit faster. Then I tried with different numbers of cycles. Instead of 1 million, I used 10 million and 0.1 million.\nThe results:10 million cycles: With 10 million cycles, the times are almost the same.\nHere are 100 thousand (0.1 million) cycles:Also with different amounts of cycles, the getter is a little bit faster than the regular way. I hope this helped you! :)By the way, I am a german seventh grade, using my own knowledge and Google Translator. So don't be so strict with my english ;)It can be useful for lazy-loading.  Say the object in question is stored in a database, and you don't want to go get it unless you need it.  If the object is retrieved by a getter, then the internal object can be null until somebody asks for it, then you can go get it on the first call to the getter.I had a base page class in a project that was handed to me that was loading some data from a couple different web service calls, but the data in those web service calls wasn't always used in all child pages.  Web services, for all of the benefits, pioneer new definitions of \"slow\", so you don't want to make a web service call if you don't have to.I moved from public fields to getters, and now the getters check the cache, and if it's not there call the web service.  So with a little wrapping, a lot of web service calls were prevented.So the getter saves me from trying to figure out, on each child page, what I will need.  If I need it, I call the getter, and it goes to find it for me if I don't already have it.I spent quite a while thinking this over for the Java case, and I believe the real reasons are:In other words, the only way you can specify a field in an interface is by providing a method for writing a new value and a method for reading the current value.  Those methods are the infamous getter and setter....Don't use getters setters unless needed for your current delivery I.e. Don't think too much about what would happen in the future, if any thing to be changed its a change request in most of the production applications, systems.Think simple, easy, add complexity when needed.I would not take advantage of ignorance of business owners of deep technical know how just because I think it's correct or I like the approach.I have massive system written without getters setters only with access modifiers and some methods to validate n perform biz logic. If you absolutely needed the. Use anything.One aspect I missed in the answers so far, the access specification:One of the basic principals of OO design: It gives you many benefits, one of which being that you can change the implementation of the getter/setter behind the scenes but any consumer of that value will continue to work as long as the data type remains the same.EDIT: I answered this question because there are a bunch of people learning programming asking this, and most of the answers are very technically competent, but they're not as easy to understand if you're a newbie. We were all newbies, so I thought I'd try my hand at a more newbie friendly answer.The two main ones are polymorphism, and validation. Even if it's just a stupid data structure.Let's say we have this simple class:A very simple class that holds how much liquid is in it, and what its capacity is (in milliliters).What happens when I do:Well, you wouldn't expect that to work, right?\nYou want there to be some kind of sanity check. And worse, what if I never specified the maximum capacity? Oh dear, we have a problem.But there's another problem too. What if bottles were just one type of container? What if we had several containers, all with capacities and amounts of liquid filled? If we could just make an interface, we could let the rest of our program accept that interface, and bottles, jerrycans and all sorts of stuff would just work interchangably. Wouldn't that be better? Since interfaces demand methods, this is also a good thing.We'd end up with something like:Great! And now we just change Bottle to this:I'll leave the definition ofthe BottleOverflowException as an exercise to the reader.Now notice how much more robust this is. We can deal with any type of container in our code now by accepting LiquidContainer instead of Bottle. And how these bottles deal with this sort of stuff can all differ. You can have bottles that writer their state to disk when it changes, or bottles that save on SQL databases or GNU knows what else.And all these can have different ways to handle various whoopsies. The Bottle just checks and if it's overflowing it throws a RuntimeException. But that might be the wrong thing to do. \n(There is a useful discussion to be had about error handling, but I'm keeping it very simple here on purpose. People in comments will likely point out the flaws of this simplistic approach. ;) )And yes, it seems like we go from a very simple idea to getting much better answers quickly.There's also the third thing that not everyone has addressed: Getters and setters use method calls. That means that they look like normal methods everywhere else does. Instead of having weird specific syntax for DTOs and stuff, you have the same thing everywhere.In languages which don't support \"properties\" (C++, Java) or require recompilation of clients when changing fields to properties (C#), using get/set methods is easier to modify. For example, adding validation logic to a setFoo method will not require changing the public interface of a class.In languages which support \"real\" properties (Python, Ruby, maybe Smalltalk?) there is no point to get/set methods.From a object orientation design standpoint both alternatives can be damaging to the maintenance of the code by weakening the encapsulation of the classes. For a discussion you can look into this excellent article:  Getter and setter methods are accessor methods, meaning that they are generally a public interface to change private class members. You use getter and setter methods to define a property. You access getter and setter methods as properties outside the class, even though you define them within the class as methods. Those properties outside the class can have a different name from the property name in the class.There are some advantages to using getter and setter methods, such as the ability to let you create members with sophisticated functionality that you can access like properties. They also let you create read-only and write-only properties.Even though getter and setter methods are useful, you should be careful not to overuse them because, among other issues, they can make code maintenance more difficult in certain situations. Also, they provide access to your class implementation, like public members. OOP practice discourages direct access to properties within a class.When you write classes, you are always encouraged to make as many as possible of your instance variables private and add getter and setter methods accordingly. This is because there are several times when you may not want to let users change certain variables within your classes. For example, if you have a private static method that tracks the number of instances created for a specific class, you don't want a user to modify that counter using code. Only the constructor statement should increment that variable whenever it's called. In this situation, you might create a private instance variable and allow a getter method only for the counter variable, which means users are able to retrieve the current value only by using the getter method, and they won't be able to set new values using the setter method. Creating a getter without a setter is a simple way of making certain variables in your class read-only.Code .   is great for when .  Eventually all classes should be sort of \"miniprograms\" that have a well-defined interface .That said,  isn't about setting down that final version of the class as if you're pressing some cast iron statue on the first try.  While you're working with it, code is more like clay.   as you develop it and learn more about the problem domain you are solving.  During development classes may interact with each other than they should (dependency you plan to factor out), merge together, or split apart.  So I think the debate boils down to people not wanting to religiously writeSo you have:Instead ofNot only is  visually noisy, it gives this illusion that  is somehow a more complex process than it really is.  How you (as the class writer) regard the sanctity of  is particularly confusing to a user of your class if it has a passthru setter -- then it looks like you're putting up these gates to \"protect\" something you insist is valuable, (the sanctity of ) but yet even you concede 's protection isn't worth much by the ability for anyone to just come in and   to whatever value they want, without you even peeking at what they are doing.So I program as follows (assuming an \"agile\" type approach -- ie when I write code not knowing  what it will be doing/don't have time or experience to plan an elaborate waterfall style interface set):1) Start with all public members for basic objects with data and behavior.  This is why in all my C++ \"example\" code you'll notice me using  instead of  everywhere.2) When an object's internal behavior for a data member becomes complex enough, (for example, it likes to keep an internal  in some kind of order), accessor type functions are written.  Because I'm programming by myself, I don't always set the member  right away, but somewhere down the evolution of the class the member will be \"promoted\" to either  or .3) Classes that are fully fleshed out and have strict rules about their internals (ie  know exactly what they are doing, and you are not to \"fuck\" (technical term) with its internals) are given the  designation, default private members, and only a select few members are allowed to be .I find this approach allows me to avoid sitting there and religiously writing getter/setters when a lot of data members get migrated out, shifted around, etc. during the early stages of a class's evolution.There is a good reason to consider using accessors is there is no property inheritance. See next example:Output:You should use getters and setters when:So this is very rarely a general OO question; it's a language-specific question, with different answers for different languages (and different use cases).From an OO theory point of view, getters and setters are useless. The interface of your class is what it does, not what its state is. (If not, you've written the wrong class.) In very simple cases, where what a class does is just, e.g., represent a point in rectangular coordinates,* the attributes are part of the interface; getters and setters just cloud that. But in anything but very simple cases, neither the attributes nor getters and setters are part of the interface.Put another way: If you believe that consumers of your class shouldn't even know that you have a  attribute, much less be able to change it willy-nilly, then giving them a  method is the last thing you want to do.But nobody is ever doing general OO design. They're doing design, and implementation, in a specific language. And in some languages, getters and setters are far from useless.If your language doesn't have properties, then the only way to represent something that's conceptually an attribute, but is actually computed, or validated, etc., is through getters and setters.Even if your language does have properties, there may be cases where they're insufficient or inappropriate. For example, if you want to allow subclasses to control the semantics of an attribute, in languages without dynamic access, a subclass can't substitute a computed property for an attribute.As for the \"what if I want to change my implementation later?\" question (which is repeated multiple times in different wording in both the OP's question and the accepted answer): If it really is a pure implementation change, and you started with an attribute, you can change it to a property without affecting the interface. Unless, of course, your language doesn't support that. So this is really just the same case again.Also, it's important to follow the idioms of the language (or framework) you're using. If you write beautiful Ruby-style code in C#, any experienced C# developer other than you is going to have trouble reading it, and that's bad. Some languages have stronger cultures around their conventions than others.\u2014and it may not be a coincidence that Java and Python, which are on opposite ends of the spectrum for how idiomatic getters are, happen to have two of the strongest cultures.Beyond human readers, there will be libraries and tools that expect you to follow the conventions, and make your life harder if you don't. Hooking Interface Builder widgets to anything but ObjC properties, or using certain Java mocking libraries without getters, is just making your life more difficult. If the tools are important to you, don't fight them.One other use (in languages that support properties) is that setters and getters can imply that an operation is non-trivial.  Typically, you want to avoid doing anything that's computationally expensive in a property. and  are used to implement two of the fundamental aspects of Object Oriented Programming which are: Suppose we have an Employee class:Here the implementation details of Full Name is hidden from the user and is not accessible directly to the user, unlike a public attribute.   Additionally, this is to \"future-proof\" your class. In particular, changing from a field to a property is an ABI break, so if you do later decide that you need more logic than just \"set/get the field\", then you need to break ABI, which of course creates problems for anything else already compiled against your class.In an object oriented language the methods, and their access modifiers, declare the interface for that object. Between the constructor and the accessor and mutator methods it is possible for the developer to control access to the internal state of an object. If the variables are simply declared public then there is no way to regulate that access.I would just like to throw the idea of annotation : @getter and @setter. With @getter, you should be able to obj = class.field but not class.field = obj. With @setter, vice versa. With @getter and @setter you should be able to do both. This would preserve encapsulation and reduce the time by not calling trivial methods at runtime.I can think of one reason why you wouldn't just want everything public.For instance, variable you never intended to use outside of the class could be accessed, even irdirectly via chain variable access (i.e.  object.item.origin.x ).  By having mostly everything private, and only the stuff you want to extend and possibly refer to in subclasses as protected, and generally only having static final objects as public, then you can control what other programmers and programs can use in the API and what it can access and what it can't by using setters and getters to access the stuff you want the program, or indeed possibly other programmers who just happen to use your code, can modify in your program.  "},
{"body": "What is the main difference between  and ?\nIs there any performance issues when deciding on any one of these? is synchronized,  is not.  is faster than  because it's not .Here's a simple benchmark test:A  gives the numbers of  for  vs  for .Basically, StringBuffer methods are synchronized while StringBuilder are not.The operations are \"almost\" the same, but using synchronized methods in a single thread is overkill.That's pretty much about it.Quote from :So it was made to substitute it.The same happened with Vector and ArrayList. came first.  Sun was concerned with correctness under all conditions, so they made it synchronized to make it thread-safe just in case. came later.  Most of the uses of  were single-thread and unnecessarily paying the cost of the synchronization.Since  is a  for  without the synchronization, there would not be differences between any examples.If you  trying to share between threads, you can use , but consider whether higher-level synchronization is necessary, e.g. perhaps instead of using StringBuffer, should you synchronize the methods that use the StringBuilder.First lets see the :\nBoth StringBuilder and StringBuffer are mutable. That means you can change the content of them, with in the same location.:\nStringBuffer is mutable and synchronized as well. Where as StringBuilder is mutable but not synchronized by default.:\nWhen some thing is synchronized, then multiple threads can access, and modify it with out any problem or side effect.\nStringBuffer is synchronized, so you can use it with multiple threads with out any problem.\nStringBuilder : When you need a string, which can be modifiable, and only one thread is accessing and modifying it.\nStringBuffer : When you need a string, which can be modifiable, and multiple threads are accessing and modifying it. : Don't use StringBuffer unnecessarily, i.e., don't use it if only one thread is modifying and accessing it because it has lot of locking and unlocking code for synchronization which will unnecessarily take up CPU time. Don't use locks unless it is required. In single threads, , thanks to JVM optimisations. And in multithreading, you can't use safely a StringBuilder.Here is my test : Results :\nstrings: 319740\nBuffers : \nBuilder : 7 !So Builders are faster than Buffers, and WAY faster than strings concatenation.\nNow let's use an  for multiple threads :Now StringBuffers take  for 100000 appends. It's not the same test, but compared to the previous 37 ms, you can safely assume that . The reason is that the JIT/hotspot/compiler/something makes optimizations when it detects that there is  need for checking locks.But , because a concurrent thread tries to add something where it should not. Conclusion is that you don't have to chase StringBuffers. And where you have threads, think about what they are doing, before trying to gain a few nanoseconds.StringBuilder was introduced in Java 1.5 so it won't work with earlier JVMs.From the :StringBuilder class provides an API compatible with StringBuffer, but with no guarantee of synchronization. This class is designed for use as a drop-in replacement for StringBuffer in places where the string buffer was being used by a single thread (as is generally the case). Where possible, it is recommended that this class be used in preference to StringBuffer as it will be faster under most implementations. Here are the differences, i have noticed :StringBuffer :-StringBuilder:-Common thing :- and  are almost the same. The difference is that  is synchronized and  is not. Although,  is faster than , the difference in performance is very little.  is a SUN's replacement of . It just avoids synchronization from all the public methods. Rather than that, their functionality is the same.Example of good usage:If your text is going to change and is used by multiple threads, then it is better to use . If your text is going to change but is used by a single thread, then use .StringBuilder is not thread safe. String Buffer is. More info .EDIT: As for performance , after  kicks in , StringBuilder is the winner. However , for small iterations , the performance difference is negligible.StringBuffer\n - Synchronized hence threadsafe\n - thread safe hence slow\n - StringBuilder\n - Introduced in java 5.0\n - Asynchronous hence fast & efficient\n - User explicitly need to synchronized it, if he wants\n - You can replace it will StringBuilder without a any other change The  explains the difference:StringBuffer is mutable means one can change the value of the object . The object created through StringBuffer is stored in the heap .  StringBuffer  has the same methods as the StringBuilder , but each method in StringBuffer is synchronized that is StringBuffer is thread safe .because of this it does not allow  two threads to simultaneously access the same method . Each method can be accessed by one thread at a time .But being thread safe has disadvantages too as the performance of the StringBuffer hits due to thread safe property . Thus  StringBuilder is faster than the StringBuffer when calling the same methods of each class.StringBuffer value can be changed , it means it can be assigned to the new value . Nowadays its a most common interview question ,the differences between the above classes .\nString Buffer can be converted to the string by using\ntoString() method.StringBuilder  is same as the StringBuffer , that is it stores the object in heap and it can also be modified . The main difference between the StringBuffer and StringBuilder is that StringBuilder is also not thread safe. \nStringBuilder is fast as it is not thread safe .Resource:  (introduced in Java 5) is identical to , except its methods are not synchronized.  This means it has better performance than the latter, but the drawback is that it is not thread-safe.Read  for more details. is an immutable. is a mutable and synchronized.  is also mutable but its not synchronized.A simple program illustrating the difference between StringBuffer and StringBuilder:StringBuilder is  much faster than StringBuffer because It's non synchronized.Let take programmatically look how much StringBuilder faster than StringBuffer is synchronized, but  is not. As a result,  is faster than .\nis mutable. It can change in terms of length and content. StringBuffers are thread-safe, meaning that they have synchronized methods to control access so that only one thread can access a StringBuffer object's synchronized code at a time. Thus, StringBuffer objects are generally safe to use in a multi-threaded environment where multiple threads may be trying to access the same StringBuffer object at the same time.\nThe StringBuilder class is very similar to StringBuffer, except that its access is not synchronized so that it is not thread-safe. By not being synchronized, the performance of StringBuilder can be better than StringBuffer. Thus, if you are working in a single-threaded environment, using StringBuilder instead of StringBuffer may result in increased performance. This is also true of other situations such as a StringBuilder local variable (ie, a variable within a method) where only one thread will be accessing a StringBuilder object.StringBuffer is mutable means one can change the value of the object . The object created through StringBuffer is stored in the heap . StringBuffer  has the same methods as the StringBuilder , but each method in StringBuffer is synchronized that is StringBuffer is thread safe . StringBuilder  is same as the StringBuffer , that is it stores the object in heap and it can also be modified . The main difference between the StringBuffer and StringBuilder is that StringBuilder is not thread safe. \nStringBuilder is fast as it is not thread safe .  StringBuffer is used to store character strings that will be changed (String objects cannot be changed). It automatically expands as needed. Related classes: String, CharSequence.StringBuilder was added in Java 5. It is identical in all respects to StringBuffer except that it is not synchronized, which means that if multiple threads are accessing it at the same time, there could be trouble. For single-threaded programs, the most common case, avoiding the overhead of synchronization makes the StringBuilder very slightly faster.Better use StringBuilder since it is not synchronized and therefor better performance. StringBuilder is a drop-in replacement of the older StringBuffer.This link will make you understand the concepts of not only  and  but also their association and difference with  class. This will make you understand when to use which class.\nThere are no basic differences between StringBuilder and StringBuffer, only a few differences exist between them. In StringBuffer the methods are synchronized. This means that at a time only one thread can operate on them. If there are more than one thread then the second thread will have to wait for the first one to finish and the third one will have to wait for the first and second one to finish and so on. This makes the process very slow and hence the performance in case of StringBuffer is low.On the other hand StringBuilder is non synchronized. This means that at a time multiple threads can operate on the same StrinBuilder object at the same time. This makes the process very fast and hence performance of StringBuilder is high.Check the internals of synchronized append method of  and non-synchronized append method of .::Since append is ,  has performance overhead compared to  in multi-threading scenario. As long as you are not sharing buffer among multiple threads, use , which is fast due to absence of  in append methods.Since  is synchronized, it needs some extra effort, hence based on perforamance, its a bit slow than . :It is recommended to use StringBuilder whenever possible because it is faster than StringBuffer. However, if the thread safety is necessary, the best option is StringBuffer objects.String is an immutable object which means the value cannot be changed where as StringBuffer is mutable.The StringBuffer is Synchronized hence thread safe where as StringBuilder is not and suitable for only single threaded instances.Every method present in StringBuffer is Synchronized.\nhence at a time only one thread is allowed to operate StringBuffer object.\nIt Increases waiting time of a Thread and Creates Performance problems\nto overcome this problem SUN People intoduced StringBuilder in 1.5 version."},
{"body": "Recently I ran into this error in my web application:It's a typical Hibernate/JPA + IceFaces/JSF application running on Tomcat 6 and JDK 1.6.\nApparently this can occur after redeploying an application a few times.What causes it and what can be done to avoid it?\nHow do I fix the problem?The solution was to add these flags to JVM command line when Tomcat is started:You can do that by shutting down the tomcat service, then going into the Tomcat/bin directory and running tomcat6w.exe. Under the \"Java\" tab, add the arguments to the \"Java Options\" box. Click \"OK\" and then restart the service.If you get an error  you should run:where  is the name of the server as viewed in services.mscSource: orx's comment on .You better try  rather than . I can not tell the precise use of this memory pool, but it have to do with the number of classes loaded into the JVM. (Thus enabling class unloading for tomcat can resolve the problem.) If your applications generates and compiles classes on the run it is more likely to need a memory pool bigger than the default. App server PermGen errors that happen after multiple deployments are most likely caused by references held by the container into your old apps' classloaders. For example, using a custom log level class will cause references to be held by the app server's classloader. You can detect these inter-classloader leaks by using modern (JDK6+) JVM analysis tools such as jmap and jhat to look at which classes continue to be held in your app, and redesigning or eliminating their use. Usual suspects are databases, loggers, and other base-framework-level libraries.See , and especially its .Common mistakes people make is thinking that heap space and permgen space are same, which is not at all true.  You could have lot of space remaining in the heap but still can run out of memory in permgen. Common causes of OutofMemory in PermGen is ClassLoader. Whenever a class is loaded into JVM, all its meta data, along with Classloader, is kept on PermGen area and they will be garbage collected when the Classloader which loaded them is ready for garbage collection. In Case Classloader has a memory leak than all classes loaded by it will remain in memory and cause permGen outofmemory once you repeat it a couple of times.  The classical example is . Now there are two ways to solve this:\n1. Find the cause of Memory Leak or if there is any memory leak.\n2. Increase size of PermGen Space by using JVM param  and .You can also check  in Java for more details.Use the command line parameter  for a Sun JVM (obviously substituting 128 for whatever size you need).Try  and if it persists, try I   (you can experiment which works best) to  as I'm using eclipse ide. In most of JVM,  is around  which runs out of memory if there are too many classes or huge number of Strings in the project.For eclipse, it is also described at . : Double Click on the tomcat server at  Tab :  and add  to the end of existing . I've been butting my head against this problem while deploying and undeploying a complex web application too, and thought I'd add an explanation and my solution.When I deploy an application on Apache Tomcat, a new ClassLoader is created for that app. The ClassLoader is then used to load all the application's classes, and on undeploy, everything's supposed to go away nicely. However, in reality it's not quite as simple.One or more of the classes created during the web application's life holds a static reference which, somewhere along the line, references the ClassLoader. As the reference is originally static, no amount of garbage collecting will clean this reference up - the ClassLoader, and all the classes it's loaded, are here to stay.And after a couple of redeploys, we encounter the OutOfMemoryError.Now this has become a fairly serious problem. I could make sure that Tomcat is restarted after each redeploy, but that takes down the entire server, rather than just the application being redeployed, which is often not feasible. So instead I've put together a solution in code, which works on Apache Tomcat 6.0. I've not tested on any other application servers, and must stress that .I'd also like to say that personally I hate this code, and that . The only time this should be used is if there's an external library your code is dependent on (In my case, it was a RADIUS client) that doesn't provide a means to clean up its own static references.Anyway, on with the code. This should be called at the point where the application is undeploying - such as a servlet's destroy method or (the better approach) a ServletContextListener's contextDestroyed method.Alternatively, you can switch to JRockit which handling permgen differently then sun's jvm.  It generally has better performance as well.I had the problem we are talking about here, my scenario is eclipse-helios + tomcat + jsf and what you were doing is making a deploy a simple application to tomcat. I was showing the same problem here, solved it as follows. In eclipse go to  tab double click on the registered server in my case tomcat 7.0, it opens my file server General registration information. On the section  click on the link  , this opens the execution of server options in the Arguments tab in VM arguments added in the end these two entriesand ready.The simplest answer these days is to use Java 8.  It no longer reserves memory exclusively for PermGen space, allowing the PermGen memory to co-mingle with the regular memory pool.Keep in mind that you will have to remove all non-standard  JVM startup parameters if you don't want Java 8 to complain that they don't do anything.The first thing one can do is to make the size of the permanent generation heap space bigger. This cannot be done with the usual \u2013Xms(set initial heap size) and \u2013Xmx(set maximum heap size) JVM arguments, since as mentioned, the permanent generation heap space is entirely separate from the regular Java Heap space, \nand these arguments set the space for this regular Java heap space. However, there are similar arguments which can be used(at least with the Sun/OpenJDK jvms) to make the size of the permanent generation heap bigger:Default is 64m.Another way to take care of that for good is to allow classes to be unloaded so your PermGen never runs out:Stuff like that worked magic for me in the past. One thing though, there\u2019s a significant performance trade off in using those, since permgen sweeps will  make like an extra 2 requests for every request you make or something along those lines. You\u2019ll need to balance your use with the tradeoffs.You can find the details of this error.Perm gen space error occurs due to use large space rather then jvm provided space to executed the code. The best solution for this problem in UNIX operating systems is to change some configuration on bash file. Following steps solve the problem.Run command  on terminal.Create  variable with following value:Save the bash file. Run command exec bash on terminal. Restart the server.I hope this approach will work on your problem. If you use a Java version lower than 8 this issue occurs sometimes. But if you use Java 8 the problem never occurs.The  space message indicates that the Permanent Generation\u2019s area in memory is exhausted. Any Java applications is allowed to use a limited amount of memory. The exact amount of memory your particular application can use is specified during application startup.The JDK 8 HotSpot JVM is now using native memory for the representation of class metadata and is called Metaspace; similar to the Oracle JRockit and IBM JVM's.The good news is that it means no more  space problems and no need for you to tune and monitor this memory space anymore using .Increasing Permanent Generation size or tweaking GC parameters will NOT help if you have a real memory leak. If your application or some 3rd party library it uses, leaks class loaders the only real and permanent solution is to find this leak and fix it. There are number of tools that can help you, one of the recent is , which has just released a new version with the required capabilities.Also if you are using log4j in your webapp, check this paragraph in log4j .It seems that if you are using , you cause memory leaks when you undeploy your webapp. I have a combination of Hibernate+Eclipse RCP, tried using  and  and it seems to be working for me.I tried several answers and the only thing what finally did the job was this configuration for the compiler plugin in the pom:hope this one helps. resolved this for me as well; however, I noticed that the servlet restart times were much worse, so while it was better in production, it was kind of a drag in development.The configuration of the memory depends on the nature of your app.What are you doing?What's the amount of transactions precessed?How much data are you loading?etc.etc.etcProbably you could profile your app and start cleaning up some modules from your app. Tomcat has hot deploy but it consumes memory. Try restarting your container once in a while.  Also you will need to know the amount of memory needed to run in production mode, this seems a good time for that research. They Say that the latest rev of Tomcat (6.0.28 or 6.0.29) handles the task of redeploying servlets  better.I run into exactly the same problem, but unfortunately none of the suggested solutions really worked for me. The problem did not happen during deployment, and I was neither doing any hot deployments.In my case the problem occurred every time at the same point during the execution of my web-application, while connecting (via hibernate) to the database. (also mentioned earlier) did provide enough insides to resolve the problem. Moving the jdbc-(mysql)-driver out of the WEB-INF and into the jre/lib/ext/ folder seems to have solved the problem. This is not the ideal solution, since upgrading to a newer JRE would require you to reinstall the driver.\nAnother candidate that could cause similar problems is log4j, so you might want to move that one as wellSet . Later on you may also try increasing . Hope it'll work. The same works for me. Setting only  didn't worked for me.\"They\" are wrong because I'm running 6.0.29 and have the same problem even after setting all of the options. As Tim Howland said above, these options only put off the inevitable. They allow me to redeploy 3 times before hitting the error instead of every time I redeploy.In case you are getting this in the eclipse IDE, even after setting the parameters \n, , etc, still if you are getting the same error, it most likely is that the eclipse is using a buggy version of JRE which would have been installed by some third party applications and set to default. These buggy versions do not pick up the PermSize parameters and so no matter whatever you set, you still keep getting these memory errors. So, in your eclipse.ini add the following parameters:  Also make sure you set the default JRE in the preferences in the eclipse to the correct version of java.The only way that worked for me was with the JRockit JVM. I have MyEclipse 8.6.The JVM's heap stores all the objects generated by a running Java program. Java uses the  operator to create objects, and memory for new objects is allocated on the heap at run time. Garbage collection is the mechanism of automatically freeing up the memory contained by the objects that are no longer referenced by the program.I was having similar issue.\nMine is JDK 7 + Maven 3.0.2 + Struts 2.0 + Google GUICE dependency injection based project.Whenever i tried running  command, it was showing following error and  occured I tried all the above useful tips and tricks but unfortunately none worked for me.\nWhat worked for me is described step by step below :=>Hope it helps, happy programming :)First step in such case is to check whether the GC is allowed to unload classes from PermGen. The standard JVM is rather conservative in this regard \u2013 classes are born to live forever. So once loaded, classes stay in memory even if no code is using them anymore. This can become a problem when the application creates lots of classes dynamically and the generated classes are not needed for longer periods. In such a case, allowing the JVM to unload class definitions can be helpful. This can be achieved by adding just one configuration parameter to your startup scripts:By default this is set to false and so to enable this you need to explicitly set the following option in Java options. If you enable CMSClassUnloadingEnabled, GC will sweep PermGen too and remove classes which are no longer used. Keep in mind that this option will work only when UseConcMarkSweepGC is also enabled using the below option. So when running ParallelGC or, God forbid, Serial GC, make sure you have set your GC to CMS by specifying:Assigning Tomcat more memory is NOT the proper solution.The correct solution is to do a cleanup after the context is destroyed and recreated (the hot deploy). The solution is to stop the memory leaks.If your Tomcat/Webapp Server is telling you that failed to unregister drivers (JDBC), then unregister them. This will stop the memory leaks. You can create a ServletContextListener and configure it in your web.xml. Here is a sample ServletContextListener:And here you configure it in your web.xml:"},
{"body": "I am relatively new to Java, and often find that I need to sort a  on the values. Since the values are not unique, I find myself converting the  into an , and sorting that array through  with a  that sorts on the value associated with the key. Is there an easier way?Here's a generic-friendly version you're free to use:And an associated JUnit4 test so you don't have to take my word for it:Java 7 VersionJava 8 Version. This will sort according to the value in ascending order; for descending order, it is just possible to uncomment the call to . If you intend to use the code provided, be sure to read the comments as well to be aware of the implications. For example, values can no longer be retrieved by their key. ( always returns .)It seems much easier than all of the foregoing. Use a TreeMap as follows:Output:I would use   to do this - if your values are  then you can useWhich will create a function (object) for the map [that takes any of the keys as input, returning the respective value], and then apply natural (comparable) ordering to them [the values].If they're not comparable, then you'll need to do something along the lines ofThese may be applied to a TreeMap (as  extends ), or a : If you are going to use a TreeMap, remember that if a comparison == 0, then the item is already in the list (which will happen if you have multiple values that compare the same).  To alleviate this, you could add your key to the comparator like so (presuming that your keys and values are ):= Note that this will still not work if your keys compare to 0, but this should be sufficient for most  items (as ,  and  are often in sync...)See  and .So now that we've got a comparator that does what we want, we need to get a result from it. Now this will most likely work work, but:Point 1 is a bit of a deal-breaker for me; google collections is incredibly lazy (which is good: you can do pretty much every operation in an instant; the real work is done when you start using the result), and this requires copying a  map!Don't worry though; if you were obsessed enough with having a \"live\" map sorted in this manner, you could solve not one but both(!) of the above issues with something crazy like the following:When we put, we ensure that the hash map has the value for the comparator, and then put to the TreeSet for sorting. But before that we check the hash map to see that the key is not actually a duplicate. Also, the comparator that we create will also include the key so that duplicate values don't delete the non-duplicate keys (due to == comparison).\nThese 2 items are  for ensuring the map contract is kept; if you think you don't want that, then you're almost at the point of reversing the map entirely (to ).The constructor would need to be called as From Java 8 offers a new answer: convert the entries into a stream, and use the comparator combinators from Map.Entry:This will let you consume the entries sorted in ascending order of value.  If you want descending value, simply reverse the comparator:If the values are not comparable, you can pass an explicit comparator:You can then proceed to use other stream operations to consume the data. For example, if you want the top 10 in a new map:Or print to :Sorting the keys requires the Comparator to look up each value for each comparison. A more scalable solution would use the entrySet directly, since then the value would be immediately available for each comparison (although I haven't backed this up by numbers).Here's a generic version of such a thing:There are ways to lessen memory rotation for the above solution. The first ArrayList created could for instance be re-used as a return value; this would require suppression of some generics warnings, but it might be worth it for re-usable library code. Also,  the Comparator does not have to be re-allocated at every invocation.Here's a more efficient albeit less appealing version:Finally, if you need to continously access the sorted information (rather than just sorting it once in a while), you can use an additional multi map. Let me know if you need more details...The commons-collections library contains a solution called . Or, you could have a look at the Google Collections API. It has  which you could use.And if you don't want to use these framework... they come with source code.I've looked at the given answers, but a lot of them are more complicated than needed or remove map elements when several keys have same value.Here is a solution that I think fits better:Note that the map is sorted from the highest value to the lowest.With Java 8, you can use the  to do it in a significantly less verbose way:To accomplish this with the new features in Java 8:The entries are ordered by their values using the given comparator. Alternatively, if your values are mutually comparable, no explicit comparator is needed:The returned list is a snapshot of the given map at the time this method is called, so neither will reflect subsequent changes to the other. For a live iterable view of the map:The returned iterable creates a fresh snapshot of the given map each time it's iterated, so barring concurrent modification, it will always reflect the current state of the map.While I agree that the constant need to sort a map is probably a smell, I think the following code is the easiest way to do it without using a different data structure.}And here is an embarrassingly incomplete unit test:}The result is a sorted list of Map.Entry objects, from which you can obtain the keys and values.Create customized comparator and use it while creating new TreeMap object.Use the below code in your main funcOutput:Use a generic comparator such as :The answer voted for the most does not work when you have 2 items that equals.\nthe TreeMap leaves equal values out.the exmaple:\nunsorted mapresultsSo leaves out E!!For me it worked fine to adjust the comparator, if it equals do not return 0 but -1.in the example:now it returns:unsorted map:results:as a response to Aliens (2011 nov. 22):\nI Am using this solution for a map of Integer Id's and names, but the idea is the same, so might be the code above is not correct (I will write it in a test and give you the correct code), this is the code for a Map sorting, based on the solution above:and this is the test class (I just tested it, and this works for the Integer, String Map:here is the code for the Comparator of a Map:and this is the testcase for this:of cource you can make this a lot more generic, but I just needed it for 1 case (the Map)Instead of using  as some do I'd suggest using . Actually what  does is something like this:It just calls  on the list and then uses . This way all the map entries will be copied three times: once from the map to the temporary list (be it a LinkedList or ArrayList), then to the temporary array and finally to the new map.My solution ommits this one step as it does not create unnecessary LinkedList. Here is the code, generic-friendly and performance-optimal:This is a variation of Anthony's answer, which doesn't work if there are duplicate values:Note that it's rather up in the air how to handle nulls. One important advantage of this approach is that it actually returns a Map, unlike some of the other solutions offered here.Major problem. If you use the first answer (Google takes you here), change the comparator to add an equal clause, otherwise you cannot get values from the sorted_map by keys:This is just too complicated. Maps were not supposed to do such job as sorting them by Value. The easiest way is to create your own Class so it fits your requirement.In example lower you are supposed to add TreeMap a comparator at place where * is. But by java API it gives comparator only keys, not values. All of examples stated here is based on 2 Maps. One Hash and one new Tree. Which is odd.The example:So change the map into a set this way:You will create class ,and the Comparator class:This way you can easily add more dependencies.And as the last point I'll add simple iterator:There are a lot of answers for this question already, but none provided me what I was looking for, a map implementation that returns keys and entries sorted by the associated value, and maintains this property as keys and values are modified in the map. Two   ask for this specifically. I cooked up a generic friendly example that solves this use case. This implementation does not honor all of the contracts of the Map interface, such as reflecting value changes and removals in the sets return from keySet() and entrySet() in the original object. I felt such a solution would be too large to include in a Stack Overflow answer. If I manage to create a more complete implementation, perhaps I will post it to Github and then to it link in an updated version of this answer.Based on @devinmoore code, a map sorting methods using generics and supporting both ascending and descending ordering.Here is an OO solution (i.e., doesn't use  methods):Hereby donated to the public domain.Afaik the most cleaner way is utilizing collections to sort map on value:Since  for values that can be equal, I used this:You might want to put  in a , but if you're only going to iterate over it right away, that's superfluous...Some simple changes in order to have a sorted map with pairs that have duplicate values. In the compare method (class ValueComparator) when values are equal do not return 0 but return the result of comparing the 2 keys. Keys are distinct in a map so you succeed to keep duplicate values (which are sorted by keys by the way). So the above example could be modified like this:I've merged the solutions of user157196 and Carter Page:If you have duplicate keys and only a small set of data (<1000) and your code is not performance critical you can just do the following: is the input to the code.The variable  will contain the data in decending order when iterated over. To change order just change > to a < in the if statement.Is not the fastest sort but does the job without any additional dependencies.For sure the solution of Stephen is really great, but for those who can't use Guava:Here's my solution for sorting by value a map.\nThis solution handle the case where there are twice the same value etc...The exec:\nThe output:Hope it will help some folksYou can try Guava's multimaps:As a result you get a map from original values to collections of keys that correspond to them. This approach can be used even if there are multiple keys for the same value.Depending on the context, using  which rememebers the order in which items are placed into the map.  Otherwise, if you need to sort values based on their natural ordering, I would recommend maintaining a separate List which can be sorted via .When I'm faced with this, I just create a list on the side. If you put them together in a custom Map implementation, it'll have a nice feel to it... You can use something like the following, performing the sort only when needed. (Note: I haven't really tested this, but it compiles... might be a silly little bug in there somewhere)(If you want it sorted by both keys and values, have the class extend TreeMap, don't define the accessor methods, and have the mutators call super.xxxxx instead of map_.xxxx)"},
{"body": "I know that Java enums are compiled to classes with private constructors and a bunch of public static members. When comparing two members of a given enum, I've always used , e.g.However, I just came across come code that uses the equals operator  instead:Which operator is the one I should be using?Both are technically correct. If you look at the source code for , it simply defers to .I use , however, as that will be null safe.Yes: enums have tight instance controls that allows you to use  to compare instances. Here's the guarantee provided by the language specification:This guarantee is strong enough that Josh Bloch recommends, that if you insist on using the singleton pattern, the best way to implement it is to use a single-element  (see: ; also )As a reminder, it needs to be said that generally,  is NOT a viable alternative to . When it is, however (such as with ), there are two important differences to consider:Bloch specifically mentions that immutable classes that have proper control over their instances can guarantee to their clients that  is usable.  is specifically mentioned to exemplify.To summarize, the arguments for using  on  are:Using  to compare two enum values works because there is only one object for each enum constant.On a side note, there is actually no need to use  to write null safe code if you write your  like this:This is a best practice known as  that you definitely should follow.As others have said, both  and  work in most cases. The compile time certainty that you're not comparing completely different types of Objects that others have pointed out is valid and beneficial, however the particular kind of bug of comparing objects of two different compile time types would also be found by FindBugs (and probably by Eclipse/IntelliJ compile time inspections), so the Java compiler finding it doesn't add that much extra safety.However:I actually think that the Java language should have defined == on Objects to call .equals() on the left hand value, and introduce a separate operator for object identity, but that's not how Java was defined.In summary, I still think the arguments are in favor of using  for  types. Here is a crude timing test to compare the two:Comment out the IFs one at a time. Here are the two compares from above in disassembled byte-code:The first (equals) performs a virtual call and tests the return boolean from the stack. The second (==) compares the object addresses directly from the stack. In the first case there is more activity.I ran this test several times with both IFs one at a time. The \"==\" is ever so slightly faster.In case of enum both are correct and right!!I prefer to use  instead of :Other reason, in addition to the others already discussed here, is you could introduce a bug without realizing it. Suppose you have this enums which is exactly the same but in separated pacakges (it's not common, but it could happen)::Then suppose you use the equals like next in  which is  but you import the second enum () instead the first without realizing it:So you will get allways  due is a different enum although you expect true because  is . And it could be be a bit difficult to see.So, if you instead use the operator  you will have a compilation error:Using anything other than  to compare enum constants is nonsense. It's like  \u2013 don't do it!However, there was a nasty bug (BugId ) in Sun JDK 6u10 and earlier that might be interesting for historical reasons. This bug prevented proper use of  on deserialized enums, although this is arguably somewhat of a corner case.Enums are classes that return one instance (like singletons) for each enumeration constant declared by  (immutable) so that  operator could be used to check their equality rather than using  methodI want to complement polygenelubricants answer:I personally prefer equals(). But it lake the type compatibility check. Which I think is an important limitation.To have type compatibility check at compilation time, declare and use a custom function in your enum.With this, you got all the advantage of both solution: NPE protection, easy to read code and type compatibility check at compilation time.I also recommend to add an UNDEFINED value for enum.In short, both have pros and cons.On one hand, it has advantages to use , as described in the other answers.On the other hand, if you for any reason replace the enums with a different approach (normal class instances), having used  bites you. (BTDT.)I would like to explicitly highlight this specific difference between the  operator and  method:The  method is meant to check whether  of the object(s) the reference variable(s) involved refer(s) to are the same.The  operator checks whether the reference variable(s) involved refer(s) .It's up to the implementing class to provide this differentiation as needed by the application. Otherwise the default behavior will be as provided by the  class (in Java) where as explained in :"},
{"body": "The following code produces the output \"Hello World!\" (no really, try it).The reason for this is that the Java compiler parses the Unicode character  as a new line and gets transformed into:Thus resulting into a comment being \"executed\".Since this can be used to \"hide\" malicious code or whatever an evil programmer can conceive, ?Why is this allowed by the Java specification?Unicode decoding takes place before any other lexical translation. The key benefit of this is that it makes it trivial to go back and forth between ASCII and any other encoding. You don't even need to figure out where comments begin and end!As stated in  this allows any ASCII based tool to process the source files:This gives a fundamental guarantee for platform independence (independence of supported character sets) which has always been a key goal for the Java platform. Being able to write any Unicode character anywhere in the file is a neat feature, and especially important in comments, when documenting code in non-latin languages. The fact that it can interfere with the semantics in such subtle ways is just an (unfortunate) side-effect.There are many gotchas on this theme and  by Joshua Bloch and Neal Gafter included the following variant:(This program turns out to be a plain \"Hello World\" program.)In the solution to the puzzler, they point out the following:Source: Since this hasn\u2019t addressed yet, here an explanation, why the translation of Unicode escapes happens before any other source code processing:The idea behind it was that it allows lossless translations of Java source code between different character encodings. Today, there is widespread Unicode support, and this doesn\u2019t look like a problem, but back then it wasn\u2019t easy for a developer from a western country to receive some source code from his Asian colleague containing Asian characters, make some changes (including compiling and testing it) and sending the result back, all without damaging something.So, Java source code can be written in any encoding and allows a wide range of characters within identifiers, character and  literals and comments. Then, in order to transfer it losslessly, all characters not supported by the target encoding are replaced by their Unicode escapes.This is a reversible process and the interesting point is that the translation can be done by a tool which doesn\u2019t need to know anything about the Java source code syntax as the translation rule is not dependent on it. This works as the translation to their actual Unicode characters inside the compiler happens independently to the Java source code syntax as well. It implies that you can perform an arbitrary number of translation steps in both directions without ever changing the meaning of the source code.This is the reason for another weird feature which hasn\u2019t even mentioned: the  syntax:When a translation tool is escaping characters and encounters a sequence that is already an escaped sequence, it should insert an additional  into the sequence, converting  to . The meaning doesn\u2019t change, but when converting into the other direction, the tool should just remove one  and replace only sequences containing a single  by their Unicode characters. That way, even Unicode escapes are retained in their original form when converting back and forth. I guess, no-one ever used that feature\u2026I'm going to completely ineffectually add the point, just because I can't help myself and I haven't seen it made yet, that the question is invalid since it contains a hidden premise which is wrong, namely that the code is in a comment!In Java source code \\u000d is equivalent in every way to an ASCII CR character. It is a line ending, plain and simple, wherever it occurs. The formatting in the question is misleading, what that sequence of characters actually syntactically corresponds to is:IMHO the most correct answer is therefore: the code executes because it isn't in a comment; it's on the next line. \"Executing code in comments\" is not allowed in Java, just like you would expect.Much of the confusion stems from the fact that syntax highlighters and IDEs aren't sophisticated enough to take this situation into account. They either don't process the unicode escapes at all, or they do it after parsing the code instead of before, like  does.The  escape terminates a comment because  escapes are uniformly converted to the corresponding Unicode characters  the program is tokenized.  You could equally use  instead of  to  a comment.This is a bug in your IDE, which should syntax-highlight the line to make it clear that the  ends the comment.This is also a design error in the language.  It can't be corrected now, because that would break programs that depend on it.   escapes should either be converted to the corresponding Unicode character by the compiler only in contexts where that \"makes sense\" (string literals and identifiers, and probably nowhere else) or they should have been forbidden to generate characters in the U+0000\u2013007F range, or both.  Either of those semantics would have prevented the comment from being terminated by the  escape, without interfering with the cases where  escapes are useful\u2014note that that  use of  escapes inside comments as a way to encode comments in a non-Latin script, because the text editor could take a broader view of where  escapes are significant than the compiler does.  (I am not aware of any editor or IDE that will display  escapes as the corresponding characters in  context, though.)There is a similar design error in the C family, where backslash-newline is processed before comment boundaries are determined, so e.g.I bring this up to illustrate that it happens to be easy to make this particular design error, and not realize that it's an error until it is too late to correct it, if you are used to thinking about tokenization and parsing the way compiler programmers think about tokenization and parsing.  Basically, if you have already defined your formal grammar and then someone comes up with a syntactic special case \u2014 trigraphs, backslash-newline, encoding arbitrary Unicode characters in source files limited to ASCII, whatever \u2014 that needs to be wedged in, it's easier to add a transformation pass  the tokenizer than it is to redefine the tokenizer to pay attention to where it makes sense to use that special case. For pedants: I am aware that this aspect of C was 100% intentional, with the rationale \u2014 I am not making this up \u2014 that it would allow you to mechanically force-fit code with arbitrarily long lines onto punched cards.  It was still an incorrect design decision.This was an intentional design choice that goes all the way back to the original design of Java.To those folks who ask \"who wants Unicode escapes in comments?\", I presume they are folks whose native language uses the Latin character set. In other words, it is inherent in the original design of Java that folks could use arbitrary Unicode characters wherever legal in a Java program, most typically in comments and strings.It is arguably a shortcoming in programs (like IDEs) used to view the source text that such programs cannot interpret the Unicode escapes and display the corresponding glyph.I agree with @zwol that this is a design mistake; but I'm even more critical of it. escape is useful in string and char literals; and that's the only place that it should exist. It should be handled the same way as other escapes like ; and   mean exactly .There is absolutely no point of having  in comments - nobody can read that.Similarly, there's no point of using  in other part of the program. The only exception is probably in public APIs that are coerced to contain some non-ascii chars - what's the last time we've seen that?The designers had their reasons in 1995, but 20 years later, this appears to be a wrong choice.The only people who can answer why Unicode escapes were implemented as they were are the people who wrote the specification.A plausible reason for this is that there was the desire to allow the entire BMP as possible characters of Java source code. This presents a problem though:This is incredibly difficult when Unicode escapes enter the fray: it creates a whole load of new lexer rules.The easy way out is to do lexing in two steps: first search and replace all Unicode escapes with the character it represents, and then parse the resulting document as if Unicode escapes don't exist.The upside to this is that it's easy to specify, so it makes the specification simpler, and it's easy to implement.The downside is, well, your example."},
{"body": "In Java, arrays don't override , so if you try to print one directly, you get weird output including the memory location:But usually we'd actually want something more like . What's the simplest way of doing that? Here are some example inputs and outputs:Since Java 5 you can use  or  for arrays within arrays. Note that the  version calls  on each object in the array. The output is even decorated in the exact way you're asking.Examples:Output:Output:Output:Output:Always check the standard libraries first.  Try:or if your array contains other arrays as elements:This is nice to know, however, as for \"always check the standard libraries first\" I'd never have stumbled upon the trick of --since I was concentrating on the type of myarray to see how to do this. I didn't want to have to iterate through the thing: I wanted an easy call to make it come out similar to what I see in the Eclipse debugger and myarray.toString() just wasn't doing it.In JDK1.8 you can use aggregate operations and a lambda expression:If you're using Java 1.4, you can instead do:(This works in 1.5+ too, of course.)Starting with Java 8, one could also take advantage of the  method provided by the  to print out array elements, without the brackets, and separated by a delimiter of choice (which is the space character for the example shown below):The output will be \"Hey there amigo!\". only prints on one line. To actually get a table to print as a two dimensional table, I had to do this: It seems like the  method should take a separator string, but unfortunately it doesn't.Prior to Java 8 we could have used  to print one dimensional array and  for multi-dimensional arrays. We have got the option of  and  in Java 8 which can also be used for the printing the array.The output is:\nJust in case we want to print multi-dimensional array we can use  as:Now the point to observe is that the method , which in case of  returns us  and then method  maps each element of stream with the contents of a mapped stream produced by applying the provided mapping function to each element.The output is:As a direct answer, , using the  and  methods, is simply the best.Below I try to list some of the other methods suggested, attempting to improve a little, with the most notable addition being the use of the  operator, using a  , to mimic what the  is doing.Using regular  loop is the simplest way of printing array in my opinion.\nHere you have a sample code based on your intArrayIt gives output as yours\n    1, 2, 3, 4, 5Resource: There's one additional way if your array is of type char[]:prints A simplified shortcut I've tried is this:It will printNo loops required in this approach and it is best for small arrays onlyIt should always work whichever JDK version you use:It will work if the  contains Objects. If the  contains primitive types, you can use wrapper classes instead storing the primitive directly as..Example: Replace it with:Yes ! this is to be mention that converting an array to an object array OR to use the Object's array is costly and may slow the execution. it happens by the nature of java called autoboxing.   So only for printing purpose, It should not be used. we can make a function which takes an array as parameter and prints the desired format asI came across this post in  recently. It's not very convenient writing , then importing  all the time. Printing an array directly gives the internal representation and the hashCode. Now, all classes have  as the parent-type. So, why not hack the ? Without modification, the Object class looks like this:What if this is changed to:This modded class may simply be added to the class path by adding the following to the command line: .Now, with the availability of  since Java 5, the  can easily be changed to  to add support for arrays that contain other arrays.I found this to be a quite useful hack and it would be great if Java could simply add this. I understand potential issues with having very large arrays since the string representations could be problematic. Maybe pass something like a or a  for such eventualities. To add to all the answers, printing the object as a JSON string is also an option.Using Jackson:Using Gson:Using org.apache.commons.lang3.StringUtils.join(*) methods can be an option\nFor example:I used the following dependency You could loop through the array,  printing out each item, as you loop. For example:Output:In java 8 it is easy. there are two keywordsIf you want to print all elements in the array in the same line, then just use  instead of  i.e. Another way without method reference just use:for each loop can also be used to print elements of array:The simplest way to print an array is to use a for-loop:"},
{"body": "Is there anything like .NET's  in Java? has it. Or you could throw an .I think the  is what you are looking for.You could do it yourself (thats what I did) - in order to not be bothered with exception handling, you simply extend the RuntimeException, your class could look something like this:You could extend it to take a message - but if you use the method as I do (that is, as a reminder, that there is still something to be implemented), then usually there is no need for additional messages.I dare say, that I only use this method, while I am in the process of developing a system, makes it easier for me to not lose track of which methods are still not implemented properly :)No there isn't and it's probably not there, because there are very few valid uses for it. I would think twice before using it. Also, it is indeed easy to create yourself.Please refer to  about why it's even in .NET.I guess  comes close, although it doesn't say the operation is just not implemented, but unsupported even. That could imply no valid implementation is possible. Why would the operation be unsupported? Should it even be there? \nInterface segregation or Liskov substitution issues maybe?If it's work in progress I'd go for , but I've never caught myself defining a concrete method and then leave it for so long it makes it into production and there would be a need for such an exception."},
{"body": "I have a string like this: I want to remove the whitespaces in the string. I tried  but this removes only whitespaces before and after the whole string. I also tried  but then the  also gets removed.How can I achieve a string with: removes all whitespaces and non-visible characters (e.g., tab, ). and  produce the same result.The second regex is 20% faster than the first one, but as the number consecutive spaces increases, the first one performs better than the second one.Assign the value to a variable, if not used directly: = Anything that is a word character = Anything that isn't a word character (including punctuation etc) = Anything that is a space character (including space, tab characters etc) = Anything that isn't a space character (including both letters and numbers, as well as punctuation etc)(Edit: As pointed out, you need to escape the backslash if you want  to reach the regex engine, resulting in .)The most correct answer to the question is:I just adapted this code from the other answers. I'm posting it because besides being exactly what the question requested, it also demonstrates that  as some of the answers sort of imply.(Experienced Java developers might say \"of course, you can't actually modify a String\", but the target audience for this question may well not know this.)How about . Refer .If you prefer utility classes to regexes, there is a method  in StringUtils in the Spring Framework.You've already got the correct answer from Gursel Koca but I believe that there's a good chance that this is not what you really want to do. How about parsing the key-values instead?One way to handle String manipulations is StringUtils from Apache commons.You can find it .\ncommons-lang includes lots more and is well supported.You should useinstead of:This way, it will work with more than one spaces between each string. \nThe + sign in the above regex means \"one or more \\s\"If you need to remove unbreakable spaces too, you can upgrade your code like this :You can do it so simply by//it work fine with any spaces \n*don't forget space in sting b means \"non word character\". The pattern for whitespace characters is . This is well documented in the .In java we can do following operation:for this you need to import following packages to your program:i hope it will help you.The easiest way to do this is by using the  class of  library such as \"\" for example.Use the static method \"\" on your input string & it will return you a string after removing all the white spaces from it. I tried your example string \"\" & it returned me exactly the string that you wanted - \"\". Hope this helps.there are many ways to solve this problem.\nyou can use split function or replace function of Strings.for more info refer smilliar problem Using Pattern And Matcher it is more Dynamic.First with space, second without space. Then it is done. This works for me and locates ll white spaces, not just spaces of a certain size.TRY THIS You can achieve this without using replaceAll() or any Predefined Method in Java.\nthis way is preferred:-public class RemoveSpacesFromString {}Use The code you want isThis will remove all the white spaces."},
{"body": "How do I add local jar files (not yet part of the Maven repository) directly in my project's library sources?Install the JAR into your local Maven repository as follows:You can add local dependencies directly (as mentioned in ) like this:Firstly I would like to give credit for this answer to anonymous stackoverflow user - I am pretty sure I've seen similar answer here before - but now I cannot find it. The best option for having local jar files as a dependency is to create local maven repository. Such repo is nothing else than proper directory structure with pom files in it. On my example:\nI have master project on  location and subroject1 is on then I am creating mvn repository in:\nIn pom file in subproject1 located  repository needs to be specified which would take file path as an url parameter:Dependency can be specified as for any other repository. This makes your pom repository independent. For instance once desired jar is available in maven central you just need to delete it from your local repo and it will be pulled from default repo. The last but not least thing to do is to add jar file to local repository using -DlocalRepositoryPath switch like here:Onece jar file is installed such mvn repo can be committed to code repository and whole set up is system independent. ()I agree that having JARs committed to source code repo is not a good practice but in real life quick and dirty solution sometimes is better than full blown nexus repo to host one jar that you cannot publish. Create a new folder, let's say  at the root of your Maven project.Just add a local repo inside your  of your :Then for each external jar you want to install, go at the root of your project and execute:Yes , you can have but its not good idea.Instead install all these jars to maven reposI'd like such solution - use  in pom file:In this case you can perform  and jar will be installed in local maven repo. Now this jar is available during any maven step on this machine (do not forget to include this dependency as any other maven dependency in pom with  tag). It is also possible to bind jar install not to  step, but any other step you like.One way is to upload it to your own Maven repository manager (such as Nexus). It's good practice to have an own repository manager anyway.Another nice way I've recently seen is to include the Maven Install Plugin in your build lifecycle: You declare in the POM to install the files to the local repository. It's a little but small overhead and no manual step involved.Of course you can add jars to that folder. But maybe it does not what you want to achieve...If you need these jars for compilation, check this related question: Also, before anyone suggests it, do NOT use the system scope.The preferred way would be to create your own remote repository.See  for details on how to do it.\nHave a look at the '' section.Also take a look at....  This is the default but I've found in some cases explicitly setting that scope also Maven to find local libraries in the local repository.I want to share a code where you can upload a folder full of jars. It's useful when a provider doesn't have a public repository and you need to add lots of libraries  manually. I've decided to build a .bat instead of call directly to maven because It could be Out of Memory errors. It was prepared for a windows environment but is easy to adapt it to linux OS:After run this main from any IDE, run the update_repo_maven.bat.THIS ANSWER IS ONLY FOR ECLIPSE USERS:If you are using Eclipse, place the jar in lib/, right click on the jar name and click \"add to build path\". \nEclipse will create a \"referenced libraries\" and place the jar for youIt resolved the import of the jar right away in the program for me Note that it is NOT necessarily a good idea to use a local repo.\nIf this project is shared with others then everyone else will have problems and questions when it doesn't work, and the jar won't be available even in your source control system!Although the shared repo is the best answer, if you cannot do this for some reason then embedding the jar is better than a local repo. Local-only repo contents can cause lots of problems, especially over time.This is a short syntax for newer versions:It works when the JAR was built by Apache Maven - the most common case. Then it'll contain a pom.xml in a subfolder of the META-INF directory, which will be read by default.Source: On your local repository you can install your jar by issuing the commandsFollow this useful   to do the same from mkyoung's website. You can also check To install third party jar, Please call the command like below"},
{"body": "How might I convert an  object to a  array in Java?For example:The  method without passing any argument returns . So you have to pass an array as an argument, which will be filled with the data from the list, and returned. You can pass an empty array as well, but you can also pass an array with the desired size.: Originally the code above used . However,  reveals that due to JVM optimizations, using  is better now.An alternative in Java 8:Using copyOf, ArrayList to arrays might be done also.You can use the  method for :Or you can manually add the elements to an array:Hope this helps!In Java 8:in case some extra manipulation of the data is desired, for which the user wants a function, this approach is not perfect (as it requires passing the class of the element as second parameter), but works:import java.util.ArrayList;\nimport java.lang.reflect.Array; solution to covert any  to : You must  method.By using  method of ArrayList you can get .\nCast that  to \nHere the sample code:This is enough:"},
{"body": "I've always been told  to represent money with  or  types, and this time I pose the question to you: why? I'm sure there is a very good reason, I simply do not know what it is.Because floats and doubles cannot accurately represent the base 10 multiples we use for money. This issue isn't just for Java, it's for any programming language that uses native floating-point types, as it stems from how computers handle floating-point numbers by default.This is how an  floating-point number works: it dedicates a bit for the sign, a few bits to store an exponent for the base, and the rest for a multiple of that elevated base. This leads to numbers like 10.25 being represented in a form similar to 1025 * 10; except that instead of the base being 10, for s and s, it's two, so that would be 164 * 2. (That's still not exactly how they are represented in hardware, but this is simple enough and the math holds the same way.)Even in base 10, this notation cannot accurately represent most simple fractions. For instance, with most calculators, 1/3 results in a repeating 0.333333333333, with as many 3's as the digital display allows, because you just can't write 1/3 in decimal notation. However, for the purpose of money (at least for countries whose money value is within an order of magnitude of the US dollar), in most scenarios all you need is to be able to store multiples of 10, so we don't really care if 1/3 doesn't have an exact representation as an integer times a power of 10, and even the cheapest calculators handle cents just fine.The problem with floats and doubles is that the  of money-like numbers don't have an exact representation as a integer times a power of two. In fact, the only fractions of a hundred between 0/100 and 100/100 (which are significant when dealing with money because they're integer cents) that can be represented exactly as an IEEE-754 binary floating-point number are 0, 0.25, 0.5, 0.75 and 1. All the others are off by a small amount.Representing money as a  or  will probably look good at first as the software rounds off the tiny errors, but as you perform more additions, subtractions, multiplications and divisions on inexact numbers, you'll lose more and more precision as the errors add up. This makes floats and doubles inadequate for dealing with money, where perfect accuracy for multiples of base 10 powers is required.A solution that works in just about any language is to use integers instead, and count cents. For instance, 1025 would be $10.25. Several languages also have built-in types to deal with money. Among others, Java  has the  class, and C# has the  type.This is not a matter of accuracy, nor is it a matter of precision.  It is a matter of meeting the expectations of humans who use base 10 for calculations instead of base 2.  For example, using doubles for financial calculations does not produce answers that are \"wrong\" in a mathematical sense, but it can produce answers that are not what is expected in a financial sense.Even if you round off your results at the last minute before output, you can still occasionally get a result using doubles that does not match expectations.Using a calculator, or calculating results by hand, 1.40 * 165 = 231 exactly.  However, internally using doubles, on my compiler / operating system environment, it is stored as a binary number close to 230.99999... so if you truncate the number, you get 230 instead of 231.  You may reason that rounding instead of truncating would have given the desired result of 231.  That is true, but rounding always involves truncation.  Whatever rounding technique you use, there are still boundary conditions like this one that will round down when you expect it to round up.  They are rare enough that they often will not be found through casual testing or observation.  You may have to write some code to search for examples that illustrate outcomes that do not behave as expected.Assume you want to round something to the nearest penny.  So you take your final result, multiply by 100, add 0.5, truncate, then divide the result by 100 to get back to pennies.  If the internal number you stored was 3.46499999.... instead of 3.465, you are going to get 3.46 instead 3.47 when you round the number to the nearest penny.  But your base 10 calculations may have indicated that the answer should be 3.465 exactly, which clearly should round up to 3.47, not down to 3.46.  These kinds of things happen occasionally in real life when you use doubles for financial calculations.  It is rare, so it often goes unnoticed as an issue, but it happens.If you use base 10 for your internal calculations instead of doubles, the answers are always exactly what is expected by humans, assuming no other bugs in your code.Floats and doubles are approximate. If you create a BigDecimal and pass a float into the constructor you see what the float actually equals:this probably isn't how you want to represent $1.01.The problem is that the IEEE spec doesn't have a way to exactly represent all fractions, some of them end up as repeating fractions so you end up with approximation errors. Since accountants like things to come out exactly to the penny, and customers will be annoyed if they pay their bill and after the payment is processed they owe .01 and they get charged a fee or can't close their account, it's better to use exact types like decimal (in C#) or java.math.BigDecimal in Java.It's not that the error isn't controllable if you round: . It's just easier not to have to round in the first place. Most applications that handle money don't call for a lot of math, the operations consist of adding things or allocating amounts to different buckets. Introducing floating point and rounding just complicates things.I'm troubled by some of these responses.  I think doubles and floats have a place in financial calculations.  Certainly, when adding and subtracting non-fractional monetary amounts there will be no loss of precision when using integer classes or BigDecimal classes.  But when performing more complex operations, you often end up with results that go out several or many decimal places, no matter how you store the numbers.  The issue is how you present the result.If your result is on the borderline between being rounded up and rounded down, and that last penny really matters, you should be probably be telling the viewer that the answer is nearly in the middle - by displaying more decimal places.The problem with doubles, and more so with floats, is when they are used to combine large numbers and small numbers.  In java,results inThe result of floating point number is not exact, which makes them unsuitable for any financial calculation which requires exact result and not approximation. float and double are designed for engineering and scientific calculation and many times doesn\u2019t produce exact result also result of floating point calculation may vary from JVM to JVM. Look at below example of BigDecimal and double primitive which is used to represent money value, its quite clear that floating point calculation may not be exact and one should use BigDecimal for financial calculations.Output:While it's true that floating point type can represent only approximatively decimal data, it's also true that if one rounds numbers to the necessary precision before presenting them, one obtains the correct result. Usually.Usually because the double type has a precision less than 16 figures. If you require better precision it's not a suitable type. Also approximations can accumulate.It must be said that even if you use fixed point arithmetic you still have to round numbers, were it not for the fact that BigInteger and BigDecimal give errors if you obtain periodic decimal numbers. So there is an approximation also here.For example COBOL, historically used for financial calculations, has a maximum precision of 18 figures. So there is often an implicit rounding.Concluding, in my opinion the double is unsuitable mostly for its 16 digit precision, which can be insufficient, not because it is approximate.Consider the following output of the subsequent program. It shows that after rounding double give the same result as BigDecimal up to precision 16.As said earlier \"Representing money as a double or float will probably look good at first as the software rounds off the tiny errors, but as you perform more additions, subtractions, multiplications and divisions on inexact numbers, you\u2019ll lose more and more precision as the errors add up. This makes floats and doubles inadequate for dealing with money, where perfect accuracy for multiples of base 10 powers is required.\"JSR 354 provides an API for representing, transporting, and performing comprehensive calculations with Money and Currency. You can download it from this link: An example of creating a MonetaryAmount and printing it to the console looks like this::When using the reference implementation API, the necessary code is much simpler:The API also supports calculations with MonetaryAmounts:CurrencyUnit and MonetaryAmountMonetaryAmount has various methods that allow accessing the assigned currency, the numeric amount, its precision and more:MonetaryAmounts can be rounded using a rounding operator:When working with collections of MonetaryAmounts, some nice utility methods for filtering, sorting and grouping are available.Custom MonetaryAmount operationsResources: See Also: I'll risk being downvoted, but I think the unsuitability of floating point numbers for currency calculations is overrated. As long as you make sure you do the cent-rounding correctly and have enough significant digits to work with in order to counter the binary-decimal representation mismatch explained by zneak, there will be no problem.People calculating with currency in Excel have always used double precision floats (there is no currency type in Excel) and I have yet to see anyone complaining about rounding errors.Of course, you have to stay within reason; e.g. a simple webshop would probably never experience any problem with double precision floats, but if you do e.g. accounting or anything else that requires adding a large (unrestricted) amount of numbers, you wouldn't want to touch floating point numbers with a ten foot pole.If your computation involves various steps, arbitrary precision arithmetic won't cover you 100%.The only reliable way to use perfect representation of results(Use a custom Fraction data type that will batch division operations to the last step) and only convert to a decimal notation in last step.Arbitrary precision won't help because there always can be numbers that has so much decimal places, or some results such as 0.6666666... No arbitrary representation will cover the last example. So you will have small errors in each step.This errors will add-up, may eventually become not easy to ignore anymore. This is called .Some example... this works (actually don't work as expected), on almost any programming language... I've tried with Delphi, VBScript, Visual Basic, JavaScript and now with Java/Android:OUTPUT:I prefer using Integer or Long to represent currency.  BigDecimal junks up the source code too much.You just have to know that all your values are in cents.  Or the lowest value of whatever currency you're using.Many of the answers posted to this question discuss IEEE and the standards surrounding floating-point arithmetic.Coming from a non-computer science background (physics and engineering), I tend to look at problems from a different perspective. For me, the reason why I wouldn't use a double or float in a mathematical calculation is that I would lose too much information.What are the alternatives? There are many (and many more of which I am not aware!).BigDecimal in Java is native to the Java language.\nApfloat is another arbitrary-precision library for Java.The decimal data type in C# is Microsoft's .NET alternative for 28 significant figures.SciPy (Scientific Python) can probably also handle financial calculations (I haven't tried, but I suspect so).The GNU Multiple Precision Library (GMP) and the GNU MFPR Library are two free and open-source resources for C and C++.There are also numerical precision libraries for JavaScript(!) and I think PHP which can handle financial calculations.There are also proprietary (particularly, I think, for Fortran) and open-source solutions as well for many computer languages.I'm not a computer scientist by training. However, I tend to lean towards either BigDecimal in Java or decimal in C#. I haven't tried the other solutions I've listed, but they are probably very good as well.For me, I like BigDecimal because of the methods it supports. C#'s decimal is very nice, but I haven't had the chance to work with it as much as I'd like. I do scientific calculations of interest to me in my spare time, and BigDecimal seems to work very well because I can set the precision of my floating point numbers. The disadvantage to BigDecimal? It can be slow at times, especially if you're using the divide method.You might, for speed, look into the free and proprietary libraries in C, C++, and Fortran.I've reached to a pretty nice precision just dealing with cents.Here is the class:"},
{"body": "I have some questions regarding the usage and significance of the  keyword. The  keyword is all about different threads reading and writing to the same variables, objects and resources.  This is not a trivial topic in , but here is a quote from Sun: When you have two threads that are reading and writing to the same 'resource', say a variable named , you need to ensure that these threads access the variable in an atomic way.  Without the  keyword, your thread 1 may not see the change thread 2 made to , or worse, it may only be half changed.  This would not be what you logically expect.Again, this is a non-trivial topic in .  To learn more, explore topics here on SO and the Interwebs  about:Keep exploring these topics until the name  becomes permanently associated with the term  in your brain.  Well, I think we had enough of theoretical explanations, so consider this codeNote:  blocks the next thread's call to method test() as long as the previous thread's execution is not finished. Threads can access this method one at a time. Without  all threads can access this method simultaneously.When a thread calls the synchronized method 'test' of the object (here object is an instance of 'TheDemo' class) it acquires the lock of that object, any new thread cannot call ANY synchronized method of the same object as long as previous thread which had acquired the lock does not release the lock.Similar thing happens when any static synchronized method of the class is called. The thread acquires the lock associated with the class(in this case any non static synchronized method of an instance of that class can be called by any thread because that object level lock is still available). Any other thread will not be able to call any static synchronized method of the class as long as the class level lock is not released by the thread which currently holds the lock.The  keyword prevents concurrent access to a block of code or object by multiple Threads.  By default, a  is , so only one thread can access the table at a time.  On usage of  constructs like ,you must build thread safety features in your code to prevent memory consistency errors. means that in a multi threaded environment, an object having   method(s)/block(s) does not let two threads to access the  method(s)/block(s) of code at the same time. This means that one thread can't read while another thread updates it.The second thread will instead wait until the first thread completes its execution. The overhead is speed, but the advantage is guaranteed consistency of data.If your application is single threaded though,  blocks does not provide benefits.The  keyword causes a thread to obtain a lock when entering the method, so that only one thread can execute the method at the same time (for the given object instance, unless it is a static method).This is frequently called making the class thread-safe, but I would say this is a euphemism. While it is true that synchronization protects the internal state of the Vector from getting corrupted, this does not usually help the user of Vector much. Consider this:Even though the methods involved are synchronized, because they are being locked and unlocked individually, two unfortunately timed threads can create a vector with two elements.So in effect, you have to synchronize in your application code as well.Because method-level synchronization is a) expensive when you don't need it and b) insufficient when you need synchronization, there are now un-synchronized replacements (ArrayList in the case of Vector).More recently, the concurrency package has been released, with a number of clever utilities that take care of multi-threading issues.Synchronized keyword in Java has to do with thread-safety, that is, when multiple threads read or write the same variable.\nThe synchronized keyword is used to define a block of code where multiple threads can access the same variable in a safe way.Syntax-wise the  keyword takes an  as it's parameter (called ), which is then followed by a .Adding  keyword to a method definition is equal to the entire method body being wrapped in a synchronized code block with the  being   and  .\nWithout synchronization, it is not guaranteed in which order the reads and writes happen, possibly leaving the variable with garbage.\nIt is not enough to complete a write operation in a thread before (wall-clock time) another thread reads it, because hardware could have cached the value of the variable, and the reading thread would see the cached value instead of what was written to it.Thus in Java's case, you have to follow the Java Memory Model to ensure that threading errors do not happen.\nThink of it as a kind of turnstile like you might find at a football ground. There are parallel steams of people wanting to get in but at the turnstile they are 'synchronised'. Only one person at a time can get through. All those wanting to get through will do, but they may have to wait until they can go through.Threads communicate primarily by sharing access to fields and the objects reference fields refer to. This form of communication is extremely efficient, but makes two kinds of errors possible: . The tool needed to prevent these errors is synchronization. Synchronized blocks or methods prevents thread interference and make sure that data is consistent. At any point of time, only one thread can access a synchronized block or method () by acquiring a lock. Other thread(s) will wait for release of lock to access . Once the lock is released by current owner thread with  call, one of thread(s) will acquire the lock to access  guarded by  keyword.Methods are synchronized when you add  to method definition or declaration. You can also synchronize a particular block of code with-in a method. It means that only one thread can access  by acquiring a lock. Unless this thread calls , all other thread(s) will have to wait to acquire a lock. They don't have access to enter  with out acquiring lock.This can't be done with a magic. It's programmer  responsibility to identify  in application and guard it accordingly. Java provides a framework to guard your application, but where and what all sections to be guarded is the responsibility of programmer.More details from java documentation . By convention, a thread that needs exclusive and consistent access to an object's fields has to acquire the object's intrinsic lock before accessing them, and then release the intrinsic lock when it's done with them.A thread is said to own the intrinsic lock between the time it has acquired the lock and released the lock.  The other thread will block when it attempts to acquire the lock.Making methods synchronized has two :When one thread is executing a synchronized method for an object, all other threads that invoke synchronized methods for the same object block (suspend execution) until the first thread is done with the object.This guarantees that changes to the state of the object are visible to all threads.Look for other alternatives to synchronization in :To my understanding synchronized basically means that the compiler write a monitor.enter and monitor.exit around your method. As such it may be thread safe depending on how it is used (what I mean is you can write an object with synchronized methods that isn't threadsafe depending on what your class does).I know that you have already gotten your answer . I write this, only to help the people who have the same question and are looking up this page for an answer . \nhere is an  explanation from  : \nConsider the following code : if  is an instance of    then making these methods synchronized has two effects:synchronized simple means no two threads can access the block/method simultaneously. When we say any block/method of a class is synchronized it means only one thread can access them at a time. Internally the thread which tries to access it first take a lock on that object and as long as this lock is not available no other thread can access any of the synchronized methods/blocks of that instance of the class.Note another thread can access a method of the same object which is not defined to be synchronized. A thread can release the lock by calling: ArrayList is non-synchronized which means multiple threads can work on ArrayList at the same time. For e.g. if one thread is performing an add operation on ArrayList, there can be an another thread performing remove operation on ArrayList at the same time in a multithreaded environmentwhile Vector is synchronized. This means if one thread is working on Vector, no other thread can get a hold of it. Unlike ArrayList, only one thread can perform an operation on vector at a timeSynchronized simply means that multiple threads if associated with single object can prevent dirty read and write if synchronized block is used on particular object. To give you more clarity , lets take an example :We've created two MyRunnable class objects , runnable1 being shared with thread 1 and thread 3 & runnable2 being shared with thread 2 only.\nNow when t1 and t3 starts without synchronized being used , PFB output which suggest that both threads 1 and 3 simultaneously affecting var value where for thread 2 , var has its own memory.Using Synchronzied, thread 3 waiting for thread 1 to complete in all scenarios. There are two locks acquired , one on runnable1 shared by thread 1 and thread 3 and another on runnable2 shared by thread 2 only.synchronized is a keyword in Java which is used to make happens before relationship in multithreading environment to avoid memory inconsistency and thread interference error."},
{"body": "Maven2 is driving me crazy during the experimentation / quick and dirty mock-up phase of development.  I have a  file that defines the dependencies for the web-app framework I want to use, and I can quickly generate starter projects from that file. However, sometimes I want to link to a 3rd party library that doesn't already have a  file defined, so rather than create the  file for the 3rd party lib by hand and install it, and add the dependency to my , I would just like to tell Maven: \"In addition to my defined dependencies, include any jars that are in  too.\"  It seems like this ought to be simple, but if it is, I am missing something.Any pointers on how to do this are greatly appreciated. Short of that, if there is a simple way to point maven to a  directory and easily create a  with all the enclosed jars mapped to a single dependency which I could then name / install and link to in one fell swoop would also suffice.Most of the answers you'll find around the internet will suggest you to either install the dependency to your local repository or specify a \"system\" scope in the  and distribute the dependency with the source of your project. But both of these solutions are actually flawed.When you install a dependency to your local repository it remains there. Your distribution artifact will do fine as long as it has access to this repository. The problem is in most cases this repository will reside on your local machine, so there'll be no way to resolve this dependency on any other machine. Clearly making your artifact depend on a specific machine is not a way to handle things. Otherwise this dependency will have to be locally installed on every machine working with that project which is not any better.The jars you depend on with the \"System Scope\" approach neither get installed to any repository or attached to your target packages. That's why your distribution package won't have a way to resolve that dependency when used. That I believe was the reason why the use of system scope even got deprecated. Anyway you don't want to rely on a deprecated feature.After putting this in your :for each artifact with a group id of form  Maven will include the following location inside your project dir in its search for artifacts:To elaborate more on this you can read .Instead of creating this structure by hand I recommend to use a Maven plugin to install your jars as artifacts. So, to install an artifact to an in-project repository under  folder execute:If you'll choose this approach you'll be able to simplify the repository declaration in  to:Since executing installation command for each lib is kinda annoying and definitely error prone, I've created a  which automatically installs all the jars from a  folder to a project repository, while automatically resolving all metadata (groupId, artifactId and etc.) from names of files. The script also prints out the dependencies xml for you to copy-paste in your .When you'll have your in-project repository created you'll have solved a problem of distributing the dependencies of the project with its source, but since then your project's target artifact will depend on non-published jars, so when you'll install it to a repository it will have unresolvable dependencies. To beat this problem I suggest to include these dependencies in your target package. This you can do with either the  or better with the . The official documentaion on OneJar is easy to grasp.set scope == system and just make up a groupId, artifactId, and versionYou may create local repository on your projectFor example if you have  folder in project structureThat is all.For detailed information: Note: When using the System scope (), Maven needs absolute paths.If your jars are under your project's root, you'll want to prefix your systemPath values with ${basedir}.You really ought to get a framework in place via a repository and identifying your dependencies up front. Using the system scope is a common mistake people use, because they \"don't care about the dependency management.\" The trouble is that doing this you end up with a perverted maven build that will not show maven in a normal condition. You would be better off following an approach like .This is what I have done, it also works around the package issue and it works with checked out code.I created a new folder in the project in my case I used , but feel free to use In my POM I had a dependency that is not in any public maven repositoriesI then created the following directories  and copied the JAR file into that folder.I created the following POM file to represent the downloaded file (this step is optional, but it removes a WARNING) and helps the next guy figure out where I got the file to begin with.Two optional files I create are the SHA1 checksums for the POM and the JAR to remove the missing checksum warnings.Finally I add the following fragment to my pom.xml that allows me to refer to the local repository has command line usage to install a jar into the local repository, POM is optional but you will have to specify the GroupId, ArtifactId, Version and Packaging (all the POM stuff).This is how we add or install a local jari gave some default groupId and artifactId because they are mandatory :)Using  is a terrible idea for reasons explained by others, installing the file manually to your local repository makes the build unreproducible, and using  is not a good idea either because (1) that may not be a well-formed  URL (e.g. if the project is checked out in a directory with unusual characters), (2) the result is unusable if this project\u2019s POM is used as a dependency of someone else\u2019s project.Assuming you are unwilling to upload the artifact to a public repository, Simeon\u2019s suggestion of a helper module does the job. But there is an easier way now\u2026Use . Does exactly what you were asking for, with none of the drawbacks of the other approaches.I found another way to do this, see here from a To summarize (sorry about some copy & paste)After having really long discussion with CloudBees guys about properly maven packaging of such kind of JARs, they made an interesting good proposal for a solution:Creation of a fake Maven project which attaches a pre-existing JAR as a primary artifact, running into belonged POM install:install-file execution. Here is an example of such kinf of POM: But in order to implement it, existing project structure should be changed. First, you should have in mind that for each such kind of JAR there should be created different fake Maven project (module). And there should be created a parent Maven project including all sub-modules which are : all JAR wrappers and existing main project. The structure could be : When parent running via mvn:install or mvn:packaging is forced and sub-modules will be executed. That could be concerned as a minus here, since project structure should be changed, but offers a non static solution at the endWhat seems simplest to me is just configure your maven-compiler-plugin to include your custom jars. This example will load any jar files in a lib directory. The problem with  is that the dependencies' jars won't get distributed along your artifacts as transitive dependencies. Try what I've posted here: Then declare dependencies as usual.And please read the footer note.If you want a quick and dirty solution, you can do the following (though I do not recommend this for anything except test projects, maven will complain in length that this is not proper).Add a dependency entry for each jar file you need, preferably with a perl script or something similar and copy/paste that into your pom file.A strange solution I found: using Eclipse cheers,\nBalintEven though it does not exactly fit to your problem, I'll drop this here. My requirements were:Let's talk about (3) first: Just having the jars in a folder and somehow merging them into the final jar will not work for here, since the IDE will not understand this. This means all libraries have to be installed properly. However, I dont want to have everyone installing it using \"mvn install-file\".In my project I needed metawidget. Here we go:Every time you have a new library, just add a new execution and tell everyone to build the project again (you can improve this process with project hierachies).To install the 3rd party jar which is not in maven repository use maven-install-plugin.Below are steps:Below is the e.g one I used it for simonsite log4jBelow is the reference link:For those that didn't find a good answer here, this is what we are doing to get a jar with all the necessary dependencies in it. This answer () mentions to use the Maven Assembly plugin but doesn't actually give an example in the answer. And if you don't read all the way to the end of the answer (it's pretty lengthy), you may miss it. Adding the below to your pom.xml will generate This doesn't answer how to add them to your POM, and may be a no brainer, but would just adding the lib dir to your classpath work? I know that is what I do when I need an external jar that I don't want to add to my Maven repos. Hope this helps.What works in our project is what Archimedes Trajano wrote, but we had in our .m2/settings.xml something like this:and the * should be changed to central. So if his answer doesn't work for you, you should check your settings.xmlI alluded to some python code in a comment to the answer from @alex lehmann's , so am posting it here.A  batch solution (based on Alex's answer):Execute it like this: .\nThen open  and copy its content as dependencies.In my case, I only needed the libraries to compile my code, and this solution was the best for that purpose.I just wanted a quick and dirty workaround... I couldn't run the script from Nikita Volkov: syntax error + it requires a strict format for the jar names.I made this Perl script which works with whatever format for the jar file names, and it generates the dependencies in an xml so it can be copy pasted directly in a pom.If you want to use it, make sure you understand what the script is doing, you may need to change the  folder and the value for the  or ..."},
{"body": "What issues / pitfalls must be considered when overriding  and ? () must define an equivalence relation (it must be , , and ). In addition, it must be  (if the objects are not modified, then it must keep returning the same value). Furthermore,  must always return false. () must also be  (if the object is not modified in terms of , it must keep returning the same value).The  between the two methods is:If you override one, then you should override the other.Use the same set of fields that you use to compute  to compute .Use the excellent helper classes  and  from the  library. An example:When using a hash-based  or  such as , , , , or , make sure that the hashCode() of the key objects that you put into the collection never changes while the object is in the collection. The bulletproof way to ensure this is to make your keys immutable, .There are some issues worth noticing if you're dealing with classes that are persisted using an Object-Relationship Mapper (ORM) like Hibernate, if you didn't think this was unreasonably complicated already!If your objects are persisted using an ORM, in many cases you will be dealing with dynamic proxies to avoid loading object too early from the data store. These proxies are implemented as subclasses of your own class. This means that will return . For example:ORMs usually use the getters to force loading of lazy loaded objects. This means that  will be  if  is lazy loaded, even if  forces loading and returns \"John Doe\". In my experience, this crops up more often in  and .Persistent objects often use a  field to hold the key of the object. This field will be automatically updated when an object is first saved. Don't use an id field in . But you can use it in .A pattern I often use isBut: you cannot include  in . If you do, when an object is persisted, its  changes. If the object is in a , you'll \"never\" find it again.In my  example, I probably would use  for  and  plus  (just for paranoia) for . It's okay if there are some risk of \"collisions\" for , but never okay for .A clarification about the .This statement is the result of  being inheritance unfriendly. The JLS (Java language specification) specifies that if  then  must also return . If you omit that statement inheriting classes that override  (and change its behavior) will break this specification.Consider the following example of what happens when the statement is omitted:Doing  Also,  result give out true, as it should.This looks all very good, but look what happens if we try to use both classes:Obviously, this is wrong.If you want to ensure the symmetric condition. a=b if b=a and the Liskov substitution principle call  not only in the case of  instance, but check after for  instance:Which will output:Where, if  is not a reference of , then it might be a be a reference of class  (because you extend it), in this case you call  .For an inheritance-friendly implementation, check out Tal Cohen's solution, Summary:In his book  (Addison-Wesley, 2001), Joshua Bloch claims that \"There is simply no way to extend an instantiable class and add an aspect while preserving the equals contract.\"  Tal disagrees.His solution is to implement equals() by calling another nonsymmetric blindlyEquals() both ways.  blindlyEquals() is overridden by subclasses, equals() is inherited, and never overridden.Example:Note that equals() must work across inheritance hierarchies if the  is to be satisfied.Still amazed that none recommended the guava library for this. There are two methods in super class as java.lang.Object. We need to override them to custom object.Equal objects must produce the same hash code as long as they are equal, however unequal objects need not produce distinct hash codes.If you want get more, please check this link as This is another example,\nHave Fun! @.@There are a couple of ways to do your check for class equality before checking member equality, and I think both are useful in the right circumstances.I use #1 in a  equals implementation, or when implementing an interface that prescribes an algorithm for equals (like the  collection interfaces\u2014the right way to check with with  or whatever interface you're implementing). It's generally a bad choice when equals can be overridden because that breaks the symmetry property.Option #2 allows the class to be safely extended without overriding equals or breaking symmetry.If your class is also , the  and  methods should be consistent too. Here's a template for the equals method in a  class:For equals, look into  by . I love it very much. She's also a great FAQ about . View her other articles  (scroll down to \"Core Java\"), where she also goes on with Part-2 and \"mixed type comparison\". Have fun reading them!equals() method is used to determine the equality of two objects.as int value of 10 is always equal to 10. But this equals() method is about equality of two objects. When we say object, it will have properties. To decide about equality those properties are considered. It is not necessary that all properties must be taken into account to determine the equality and with respect to the class definition and context it can be decided. Then the equals() method can be overridden.we should always override hashCode() method whenever we override equals() method. If not, what will happen? If we use hashtables in our application, it will not behave as expected. As the hashCode is used in determining the equality of values stored, it will not return the right corresponding value for a key.Default implementation given is hashCode() method in Object class uses the internal address of the object and converts it into integer and returns it.Example Code Output:Logically we have: \u21d2 But  vice-versa!One gotcha I have found is where two objects contain references to each other (one example being a parent/child relationship with a convenience method on the parent to get all children).\nThese sorts of things are fairly common when doing Hibernate mappings for example.If you include both ends of the relationship in your hashCode or equals tests it's possible to get into a recursive loop which ends in a StackOverflowException.\nThe simplest solution is to not include the getChildren collection in the methods."},
{"body": "What is an efficient way to implement a singleton pattern in Java?Use an enum:Joshua Bloch explained this approach in his  talk at Google I/O 2008: . Also see slides 30-32 of his presentation (): An  says: Depending on the usage, there are several \"correct\" answers.Since java5 the best way to do it is to use an enum:Pre java5, the most simple case is:Let's go over the code. First, you want the class to be final. In this case, I've used the  keyword to let the users know it is final. Then you need to make the constructor private to prevent users to create their own Foo. Throwing an exception from the constructor prevents users to use reflection to create a second Foo. Then you create a  field to hold the only instance, and a  method to return it. The Java specification makes sure that the constructor is only called when the class is first used.When you have a very large object or heavy construction code AND also have other accessible static methods or fields that might be used before an instance is needed, then and only then you need to use lazy initialization.You can use a  to load the instance. The code would then look like:Since the line  is only executed when the class FooLoader is actually used, this takes care of the lazy instantiation, and is it guaranteed to be thread safe.When you also want to be able to serialize your object you need to make sure that deserialization won't create a copy.The method  will make sure the only instance will be returned, even when the object was serialized in a previous run of your program.The solution posted by Stu Thompson is valid in Java5.0 and later. But I would prefer not to use it because I think it is error prone.It's easy to forget the volatile statement and difficult to understand why it is necessary. Without the volatile this code would not be thread safe anymore due to the double-checked locking antipattern. See more about this in paragraph 16.2.4 of . In short: This pattern (prior to Java5.0 or without the volatile statement) could return a reference to the Bar object that is (still) in an incorrect state.This pattern was invented for performance optimization. But this is really not a real concern anymore. The following lazy initialization code is fast and -more importantly- easier to read.Thread safe in Java 5+:: Pay attention to the  modifier here.  :)  It is important because without it, other threads are not guaranteed by the JMM (Java Memory Model) to see changes to its value.  The synchronization  take care of that--it only serializes access to that block of code.: \n@Bno 's answer details the approach recommended by Bill Pugh (FindBugs) and is arguable better.  Go read and vote up his answer too. I have just summarized all of the awesome answers and wrote it in my words.While implementing Singleton we have 2 options\n1. Lazy loading\n2. Early loadingLazy loading adds bit overhead(lots of to be honest) so use it only when you have a very large object or heavy construction code AND also have other accessible static methods or fields that might be used before an instance is needed, then and only then you need to use lazy initialization.Otherwise choosing early loading is a good choice.Most simple way of implementing Singleton is Everything is good except its early loaded singleton. Lets try lazy loaded singletonSo far so good but our hero will not survive while fighting alone with multiple evil threads who want many many instance of our hero.\nSo lets protect it from evil multi threadingbut it is not enough to protect out hero, Really!!! This is the best we can/should do to help our hero  This is called \"Double-Checked Locking idiom\". It's easy to forget the volatile statement and difficult to understand why it is necessary.\nFor details :  Now we are sure about evil thread but what about the cruel serialization? We have to make sure even while de-serialiaztion no new object is createdThe method  will make sure the only instance will be returned, even when the object was serialized in a previous run of our program.Finally we have added enough protection  against threads and serialization but our code is looking bulky and ugly. Lets give our hero a make overYes this is our very same hero :)\nSince the line  is only executed when the class  is actually used, this takes care of the lazy instantiation, and is it guaranteed to be thread safe.And we have came so far, here is the best way to achieve everything we did is best possible way Which internally will be treated like  That's it no more fear of serialization, threads and ugly code. Also . -Joshua Bloch in \"Effective Java\"      Now you might have realized why ENUMS are considered as best way to implement Singleton and thanks for your patience :)\nUpdated it on my . Forget , it's too problematic. This is the simplest solution:Make sure that you really need it. Do a google for \"singleton anti-pattern\" to see some arguments against it. There's nothing inherently wrong with it I suppose but it's just a mechanism for exposing some global resource/data so make sure that this is the best way. In particular I've found dependency injection more useful particularly if you are also using unit tests because DI allows you to use mocked resources for testing purposes.Don't forget the Singleton is only a Singleton for the Classloader that loaded it. If you are using multiple loaders (Containers) each COULD have its own version of the Singleton.I'm mystified by some of the answers that suggest DI as an alternative to using singletons; these are unrelated concepts. You can use DI to inject either singleton or non-singleton (e.g. per-thread) instances. At least this is true if you use Spring 2.x, I can't speak for other DI frameworks.So my answer to the OP would be (in all but the most trivial sample code) to:This approach gives you a nice decoupled (and therefore flexible and testable) architecture where whether to use a singleton is an easily reversible implementation detail (provided any singletons you use are threadsafe, of course).Really consider why you need a singleton before writing it. There is a quasi-religious debate about using them which you can quite easily stumble over if you google singletons in Java.Personally I try to avoid singletons as often as possible for many reasons, again most of which can be found by googling singletons. I feel that quite often singletons are abused because they're easy to understand by everybody, they're used as a mechanism for getting \"global\" data into an OO design and they are used because it is easy to circumvent object lifecycle management (or really thinking about how you can do A from inside B). Look at things like Inversion of Control (IoC) or Dependency Injection (DI) for a nice middleground.If you really need one then wikipedia has a good example of a proper implementation of a singleton.Following are 3 different approaches1) Enum2) Double checked Locking /Lazy loading3) Static factory methodI use the Spring Framework to manage my singletons.  It doesn't enforce the \"singleton-ness\" of the class (which you can't really do anyway if there are multiple class loaders involved) but provides a really easy way to build and configure different factories for creating different types of objects.Wikipedia has some  of singletons, also in Java. The Java 5 implementation looks pretty complete, and is thread-safe (double-checked locking applied).If you do not need lazy loading then simply tryIf you want lazy loading and you want your Singleton to be thread-safe, try the double-checking pattern As the double checking pattern is not guaranteed to work (due to some issue with compilers, I don't know anything more about that.), you could also try to synchronize the whole getInstance-method or create a registry for all your Singletons. Lazy loading, thread safe with blocking, low performance because of .Lazy loading, thread safe with non-blocking, high performance.I would say Enum singleton Singleton using enum in Java is generally way to declare enum singleton. Enum singleton may contain instance variable and instance method. For simplicity's sake, also note that if you are using any instance method than you need to ensure thread safety of that method if at all it affect the state of object.The use of an enum is very easy to implement and has no drawbacks regarding serializable objects, which have to be circumvented in the other ways.You can access it by , much easier than calling  method on Singleton.Another problem with conventional Singletons are that once you implement  interface, they no longer remain Singleton because  method always return a new instance  like constructor in Java. This can be avoided by using  and discarding newly created instance by replacing with singleton like below This can become even more complex if your Singleton Class maintain state, as you need to make them transient, but with in Enum Singleton, Serialization is guaranteed by JVM.You need  idiom if you need to load the instance variable of a class lazily. \nIf you need to load a static variable or a singleton lazily, you need  idiom. In addition, if the singleton needs to be seriliazble, all other fields needs to be transient and readResolve() method needs to be implemented in order to maintain the singleton object invariant. Otherwise, each time the object is deserialized, a new instance of the object will be created. What readResolve() does is replace the new object read by readObject(), which forced that new object to be garbage collected as there is no variable referring to it.For JSE 5.0 and above take the Enum approach, otherwise use static singleton holder approach ( (a lazy loading approach described by Bill Pugh). Latter solution is also thread-safe without requiring special language constructs (i.e. volatile or synchronized).Various ways to make singleton object:The simplest way to implement a Singleton that is thread-safe is using an EnumThis code works since the introduction of Enum in Java 1.5If you want to code a \u201cclassic\u201d singleton that works in a multithreaded environment (starting from Java 1.5) you should use this one.This is not thread-safe before 1.5 because the implementation of the volatile keyword was different.This implementation instantiates the singleton when the class is loaded and provides thread safety.This is how to implement a simple :This is how to properly lazy create your :Another argument often used against Singletons are their testability problems. Singletons are not easily mockable for testing purposes. If this turns out to be a problem, I like to make the following slight modification:The added  method allows setting a mockup implementation of the singleton class during testing:This also works with early initialization approaches:This has the drawback of exposing this functionality to the normal application too. Other developers working on that code could be tempted to use the \u00b4setInstance\u00b4 method to alter alter a specific function and thus changing the whole application behaviour, therefore this method should contain at least a good warning in it's javadoc.Still, for the possibility of mockup-testing (when needed), this code exposure may be an acceptable price to pay.simplest singleton classI still think after java 1.5, enum is the best available singleton implementation available as it also ensures that even in the multi threaded environments - only one instance is created.and you are done !!!Have a look at this post.From the best answer's \"Singleton\" section,You can also learn the example of Singleton from Java native classes themselves.To achieve this ( TRUE Singleton) ,Useful links: All answers in this post + : Initialization-on-demand holder idiom from wikipedia articleDemonstration of various methods of achieving Singletonoutput:Sometimes a simple \"\" is not enough. Just think of some basic data insertion you want to do.On the other hand you would have to synchronize any method that instantiates the singleton variable as such. Synchronisation is not bad as such, but it can lead to performance issues or locking (in very very rare situations using this example. The solution isNow what happens? The class is loaded via the class loader. Directly after the class was interpreted from a byte Array, the VM executes the  - block. that's the whole secret: The static-block is only called once, the time the given class (name) of the given package is loaded by this one class loader.As we have added the Synchronized keyword before getInstance, we have avoided the race condition in the case when two threads call the getInstance at the same time."},
{"body": "I want to access my current working directory using OutPut:  My output is not correct because C drive is not my current directory.\nNeed help in this regard.This will print a See: Using  and , you can do the following to show what Java thinks is your current path. This for 7 and on, and uses NIO.This outputs  that in my case is where I ran the class from. Constructing paths in a relative way, by not using a leading separator to indicate you are constructing an absolute path, will use this relative path as the starting point.The following works on Java 7 and up (see  for documentation).What makes you think that  is not your current directory? The  property is explicitly to be \"User's current working directory\".To put it another way, unless you start Java from the command line,  probably is your CWD. That is, if you are double-clicking to start your program, the CWD is unlikely to be the directory that you are double clicking from.: It appears that this is only true for old windows and/or Java versions. This is the solution for megenerally, as a File object:you may want to have full qualified string like \"D:/a/b/c\" doing:Use . This works fine in JAR files as well. You can obtain  by  and the  in turn can be obtained by .I'm on Linux and get same result for both of these approaches:I hope you want to access the current directory including the package i.e. If your Java program is in  and you want to print until  then you can try the following code: This code is only tested in Windows with Oracle JRE.On  when you run a  file from , these both will return the same : , no matter, where youre jar file is. It depends just on what current directory are you using with your terminal, when you start the jar file.If your  with  would be called , then try:This will return a  with  of the  file.I had   files in the same directory . I wanted from the one  file to start the other  file which is in the same directory.The problem is that when you start it from the  the current directory is .\ud83c\udf42..\ud83c\udf42:None of the answers posted here worked for me.  Here is what did work:Edit:  The final version in my code:assume that you're trying to run your project inside eclipse, or netbean or stand alone from command line. I have write a method to fix itTo use, everywhere you want to get base path to read file, you can pass your anchor class to above method, result may be the thing you need :DBest,Using Windows user.dir returns the directory as expected, but NOT when you start your application with elevated rights (run as admin), in that case you get C:\\WINDOWS\\system32Current working directory is defined differently in different Java implementations. For certain version prior to Java 7 there was no consistent way to get the working directory. You could work around this by launching Java file with  and defining a variable to hold the infoSomething likeThat's not quite right, but you get the idea. Then ...Here's what I did to get the current working directory of my JavaFX app running on Windows 7 (Java 8).this is current directory name    this is current directory path"},
{"body": "I'm looking to make my code more readable as well as use tooling like IDE code inspection and/or static code analysis (FindBugs and Sonar) to avoid NullPointerExceptions.  Many of the tools seem incompatible with each others' // annotation and listing all of them in my code would be terrible to read.  Any suggestions of which one is the 'best'?  Here is the list of equivalent annotations I've found:I very much like the , which is an implementation of type annotations () which is used to implement defect checkers like a nullness checker.  I haven't really tried any others to offer any comparison, but I've been happy with this implementation.I'm not affiliated with the group that offers the software, but I am a fan.Four things I like about this system:I use the IntelliJ one, because I'm mostly concerned with IntelliJ flagging things that might produce a NPE. I agree that it's frustrating not having a standard annotation in the JDK. There's talk of adding it, it might make it into Java 7. In which case there will be one more to choose from!According to the  JSR-308 type annotations are deferred to Java 8.  JSR-305 annotations are not even mentioned.  There is a bit of info on the state of JSR-305 in an  of the latest JSR-308 draft.  This includes the observation that JSR-305 annotations seem to be abandoned.  The JSR-305 page also shows it as \"inactive\".In the mean time, the pragmatic answer is to use the annotation types that are supported by the most widely used tools ... and be prepared to change them if the situation changes.In fact, JSR-308 does not define any annotation types/classes, and it looks like they think it is out of scope.  (And they are right, given the existence of JSR-305).However, if JSR-308 really looks like making it into Java 8, it wouldn't surprise me if interest in JSR-305 revived.  AFAIK, the JSR-305 team hasn't formally abandoned their work.  They have just been quiet for 2+ years.It is interesting that Bill Pugh (the tech lead for JSR-305) is one of the guy behind FindBugs.For Android projects you should use  and . These and other helpful Android-specific annotations are available in the .From :JSR305 and FindBugs are authored by the same person. Both are poorly maintained but are as standard as it gets and are supported by all major IDEs. The good news is that they work well as-is.Here is how to apply @Nonnull to all classes, methods and fields by default.\nSee  and 2. Add the annotation to each package: : As of December 12th, 2012  is listed as \"Dormant\". According to the documentation:It looks like   making it into JDK 8 and although the JSR does not define @NotNull, the accompanying  does. At the time of this writing, the Maven plugin is unusable due to this bug: If anyone is just looking for the IntelliJ classes: you can get them from the maven repository withJust pointing out that the Java Validation API () doesn't come with a  annotation, which is very valuable in a static analysis context. It makes sense for runtime bean validation as this is the default for any non-primitive field in Java (i.e. nothing to validate/enforce). For the purposes stated that should weigh towards the alternatives.Eclipse has also its own annotations.See at  for details.Since Oracle decided not to standardize @NonNull (and @Nullable) for the moment, I'm afraid there is no good answer. All we can do is to find a pragmatic solution and mine is as follows:From a purely stylistic standpoint I would like to avoid any reference to IDE, framework or any toolkit except Java itself.This rules out:Which leaves us with either javax.validation.constraints or javax.annotation.\nThe former comes with JEE. If this is better than javax.annotation, which  might come eventually with JSE or never at all, is a matter of debate.\nI personally prefer javax.annotation because I wouldn't like the JEE dependency.This leaves us withwhich is also the shortest one.There is only one syntax which would even be better: java.annotation.Nullable. As other packages graduated\nfrom javax to java in the past, the javax.annotation would\nbe a step in the right direction.I was hoping that they all have basically the same trivial implementation,\nbut a detailed analysis showed that this is not true.First for the similarities:The @NonNull annotations all have the line except for The @Nullable annotations all have the lineexcept for (again) the org.jetbrains.annotations with their trivial implementation.For the differences:A striking one is thatall have runtime annotations  (@Retention(RUNTIME), whileare only compile time (@Retention(CLASS)).As described in  the impact of runtime annotations\nis smaller than one might think, but they have the benefit\nof enabling tools to do runtime checks in addition to the\ncompile time ones. Another important difference is  in the code the annotations can be used.\nThere are two different approaches. Some packages use JLS 9.6.4.1 style contexts. The following table gives an overview:org.eclipse.jdt.annotation, javax.annotation and org.checkerframework.checker.nullness.qual use the contexts defined in \nJLS 4.11, which is in my opinion the right way to do it.This leaves us with in this round.To help you to compare further details yourself I list the code of every annotation below.\nTo make comparison easier I removed comments, imports and the @Documented annotation.\n(they all had @Documented except for the classes from the Android package).\nI reordered the lines and @Target fields and normalized the qualifications.For completeness, here are the @Nullable implementations:The following two packages have no @Nullable, so I list them separately\nlombok has a pretty boring @NonNull.\nIn javax.validation.constraints the @NonNull is actually a @NotNull\nand it has a longish implementation.Form my experience javax.annotation is at least supported by Eclipse and the Checker Framework out of the box.My ideal annotation would be the java.annotation syntax with the Checker Framework implementation.If you don't intend to use the Checker Framework  the  (JSR-305) is still your best bet for the time being.If you are willing to buy into the Checker Framework just use\ntheir org.checkerframework.checker.nullness.qual.While waiting for this to be sorted out upstream (Java 8?), you could also just define your own project-local  and  annotations. This can be useful also in case you're working with Java SE, where   by default.This would admittedly largely be for decorative or future-proofing purposes, since the above obviously doesn't in and of itself add any support for the static analysis of these annotations.Unfortunately,  will not add more values than this project local Not Null suggestion here will not come with a single default annotation or its own  framework.\nSimilar to Find-bugs or , this JSR is poorly maintained by a small bunch of mostly academic teams. No commercial power behind it, thus  launches  (Early Draft Review at ) NOW, while  is supposed to ship in less than 6 months:-O\nSimilar to  btw. but unlike  has taken charge of that now away from its founders to minimize harm it'll do to the Java Platform.Every project, vendor and academic class like the ones behind the  and  will create its own proprietary checker annotation.Making source code incompatible for years to come, until a few popular compromises could be found and maybe added to  or , or via frameworks like  or ;-)If you're developing for android, you're  tied to Eclipse (edit: at time of writing, not anymore), which has its own annotations.  It's included in Eclipse 3.8+ (Juno), but disabled by default.You can enable it at Preferences > Java > Compiler > Errors/Warnings > Null analysis (collapsable section at the bottom).Check \"Enable annotation-based null analysis\" has recommendations on settings.  However, if you have external projects in your workspace (like the facebook SDK), they may not satisfy those recommendations, and you probably don't want to fix them with each SDK update ;-)I use:This answer is Android specific. Android has support package called . This provides  of  annotations and also provides  like ,  etc.To add  package, add the following dependency in your build.gradle:and then use:There is another way to do this in Java 8.\nI am doing 2 things to accomplish what I needed:Example:So my question is, do we even need to annotate when using java 8? Edit: I found out later that some consider a bad practice to use  in arguments, there is a good discussion with pros and cons here If you are working on a big project, you may be better of creating   and/or  annotations.For example:If you use the correct , then the annotations . From that point of view, it is just an  thing. Even though this is not a strict science, I think it makes most sense to use an  class for it.Doesn't sun have their own now? What's this:\nThis seems to be packaged with all the versions of Java I've used within the last few years. As mentioned in the comments below, you probably don't want to use these. In that case, my vote is for the IntelliJ jetbrains annotations!Another option is the annotations provided with ANTLR 4. Following , the artifact containing the  and  annotations includes an annotation processor that produces compile-time errors and/or warnings in the event one of these attributes is misused (for example, if both are applied to the same item, or if  is applied to item with a primitive type). The annotation processor provides additional assurance during the software development process that the information conveyed by the application of these annotations is accurate, including in cases of method inheritance.Distinguish between static analysis and runtime analysis. Use static analysis for internal stuff, and runtime analysis for the public boundaries of your code.For things that should not be null:For things that may be null (No runtime check required):This should give the best result: warnings in the IDE, errors by Findbugs and checkerframework, meaningful runtime exceptions.Some explanations:If you are building your application using Spring Framework I would suggest using  comming from  packaged in following dependency:The main advantage of this annotation is that Spring provides support for both method parameters and class fields annotated with . All you need to do to enable support is:Example:When you try calling method doSomething and pass null as the parameter value, spring (by means of HibernateValidator) will throw . No need for manuall work here.You can also validate return values.Another important benefit of  comming for Beans Validation Framework is that at the moment it is still developed and new features are planned for new version 2.0.What about ? There is nothing like that in Beans Validation 1.1. Well, I could arguee that if you decide to use  than everything which is NOT annotated with  is effectively \"nullable\", so the  annotation is useless."},
{"body": "I have an  in Java for the cardinal & intermediate directions:How can I write a  loop that iterates through each of these  values?You can call the  method on your enum.This  method is . So it is not listed on  doc. Enum#values():You can do this as follows:Prior to Java 8 we need to print the values using for loop, like:But in Java 8 we can also make use of lambda and streams ():If you don't care about the order this should work:Java8 from Java5+ Try to use a for each"},
{"body": "Given the 2  implementations below, which one is preferred:or?More importantly, given we have only 3 properties it might not make a difference, but at what point would you switch from  concat to  ?Version 1 is preferable because it is shorter and  - no performance difference whatsoever.At the point where you're concatenating in a loop - that's usually when the compiler can't substitute  by itself.The key is whether you are writing a single concatenation all in one place or accumulating it over time.For the example you gave, there's no point in explicitly using StringBuilder. (Look at the compiled code for your first case.)But if you are building a string e.g. inside a loop, use StringBuilder.To clarify, assuming that hugeArray contains thousands of strings, code like this:is very time- and memory-wasteful compared with:I prefer:...because it's short and readable.I would  optimize this for speed unless you use it inside a loop with a very high repeat count  have measured the performance difference.I agree, that if you have to output a lot of parameters, this form can get confusing (like one of the comments say). In this case I'd switch to a more readable form (perhaps using  of apache-commons - taken from the answer of matt b) and ignore performance again.In most cases, you won't see an actual difference between the two approaches, but it's easy to construct a worst case scenario like this one:The output is:The problem is that to += append to a string reconstructs a new string, so it costs something linear to the length of your strings (sum of both).So - to your question:The second approach would be faster, but it's less readable and harder to maintain.\nAs I said, in your specific case you would probably not see the difference.I also had clash with my boss on the fact whether to use append or +.As they are using Append(I still cant figure out as they say every time a new object is created).\nSo I thought to do some R&D.Although I love Michael Borgwardt explaination but just wanted to show an explanation if somebody will really need to know in future.and disassembly of above class comes out asFrom the above two codes you can see Michael is right.In each case only one SB object is created.Since Java 1.5, simple one line concatenation with \"+\" and StringBuilder.append() generate exactly the same bytecode.So for the sake of code readability, use \"+\".2 exceptions : Using latest version of Java(1.8) the disassembly() shows the optimization introduced by compiler.  as well  will generate very similar code. However, it will be worthwhile inspecting the behaviour if we are using  in a for loop.Java: ByteCode:( loop excerpt)Java:ByteCdoe:( loop excerpt)There is a bit of  though. In first case, where  was used, new  is created for each for loop iteration and generated result is stored by doing a  call(29 through 41). So you are generating intermediate Strings that your really do not need while using  operator in  loop.Apache Commons-Lang has a  class which is super easy to use. It does a nice job of both handling the append-logic as well as formatting of how you want your toString to look.Will return output that looks like .Or in a more condensed form using chaining:Or if you want to use reflection to include every field of the class:You can also customize the style of the ToString if you want.For performance reasons, the use of  ( concatenation) is discouraged. The reason why is: Java  is an immutable, every time a new concatenation is done a new  is created (the new one has a different fingerprint from the older one already  ). Creating new strings puts pressure on the GC and slows down the program: object creation is expensive. Below code should make it more practical and clear at the same time. Results for a run are reported below. Not considering the results for 1 concatenation (JIT was not yet doing its job), even for 10 concatenations the performance penalty is relevant; for thousands of concatenations, the difference is huge. Lessons learned from this very quick experiment (easily reproducible with the above code): never use the  to concatenate strings together, even in very basic cases where a few concatenations are needed (as said, creating new strings is expensive anyway and puts pressure on the GC). In Java 9 the version 1 should be faster because it is converted to  call. More details can be found in :Make the toString method as readable as you possibly can!The sole exception for this in my book is if you can  to me that it consumes significant resources :)  (Yes, this means profiling)Also note that the Java 5 compiler generates faster code than the handwritten \"StringBuffer\" approach used in earlier versions of Java.  If you use \"+\" this and future enhancements comes for free.Can I point out that if you're going to iterate over a collection and use StringBuilder, you may want to check out  and  (in different flavours) ? Regardless of performance, it'll save you having to create StringBuilders and for loops for what seems like the  time.I compared four different approach to compare the performance. I exactly don't know what happens to gc, but the important thing for me is time. Compiler is important factor here.I used jdk1.8.0_45 under window8.1 platform.There seems to be some debate whether using StringBuilder is still needed with current compilers. So I thought I'll give my 2 cents of experience. I have a  result set of 10k records (yes, I need all of them in one batch.) Using the + operator takes about 5 minutes on my machine with . Using  takes less than a second for the same query. So the difference is huge. Inside a loop  is much faster. For simple strings like that I prefer to use In order, I would say the preferred method of constructing a string is using StringBuilder, String#concat(), then the overloaded + operator.  StringBuilder is a significant performance increase when working large strings just like using the + operator is a large decrease in performance (exponentially large decrease as the String size increases).  The one problem with using .concat() is that it can throw NullPointerExceptions."},
{"body": "How are JSP and Servlet related to each other? Is JSP some kind of Servlet? How are JSP and JSF related to each other? Is JSF some kind of prebuild UI based JSP like ASP.NET-MVC?JSP is a  running on the server machine which allows you to write template text in client side languages (like HTML, CSS, JavaScript, ect.). JSP supports , which are backed by pieces of Java code that let you control the page flow or output dynamically. A well-known taglib is . JSP also supports , which can be used to access backend data (via attributes available in the page, request, session and application scopes), mostly in combination with taglibs.When a JSP is requested for the first time or when the web app starts up, the servlet container will compile it into a class extending  and use it during the web app's lifetime. You can find the generated source code in the server's work directory. In for example , it's the  directory. On a JSP request, the servlet container will execute the compiled JSP class and send the generated output (usually just HTML/CSS/JS) through the web server over a network to the client side, which in turn displays it in the web browser.Servlet is a  running on the server machine, which intercepts requests made by the client and generates/sends a response. A well-known example is the  which provides methods to hook on  requests using the popular  such as  and . You can configure s to listen to a certain HTTP URL pattern, which is configurable in , or more recently with , with  annotation.When a Servlet is first requested or during web app startup, the servlet container will create an instance of it and keep it in memory during the web app's lifetime. The same instance will be reused for every incoming request whose URL matches the servlet's URL pattern. You can access the request data by  and handle the response by . Both objects are available as method arguments inside any of the overridden methods of , such as  and .JSF is a  which is built on top of the Servlet API and provides  via taglibs which can be used in JSP or any other Java based view technology such as . Facelets is much more suited to JSF than JSP. It namely provides great  such as , while JSP basically only offers the  for templating, so that you're forced to create custom components with raw Java code (which is a bit opaque and a lot of tedious work in JSF) when you want to replace a repeated group of components with a single component. Since JSF 2.0, JSP has been deprecated as view technology in favor of Facelets.As being a MVC () framework, JSF provides the  as the sole request-response . It takes all the standard and tedious HTTP request/response work from your hands, such as gathering user input, validating/converting them, putting them in model objects, invoking actions and rendering the response. This way you end up with basically a JSP or Facelets (XHTML) page for  and a JavaBean class as . The JSF components are used to bind the view with the model (such as your ASP.NET web control does) and the  uses the  to do all the work.See See JSP is a specialized kind of servlet.JSF is a set of tags you can use with JSP.JSP and JSF both looks same, As Per Application Requirements goes, JSP is more suited for request - response based applications. JSF is targetted for richer event based Web applications. I see event as much more granular than request/response. JSP page is converted to servlet, and it has only minimal behaviour.JSF page is converted to components tree(by specialized FacesServlet) and it follows component lifecycle defined by spec. [  ]There are also situations where you can favor JSP over JSF. The application nature should be the deciding factor to choose the technology. If you have a rich GUI interaction and lot of Java scripting needed then favor JSF. Basically if your GUI app architecture is like Component oriented & even driven like Swing then JSF is the best.If the application is just a plain form submitting, not much of GUI interaction needed, then JSP could do well if learning a new tech is an overhead and also complex framework is unnecessary.Servlet - it's java server side layer.that is true that JSP is converted into servlet at the time of execution, and JSF is totally new thing in order to make the webpage more readable as JSF allows to write all the programming structures in the form of tag.The basic difference between Servlets and JSP is that in Servlets we write java code and in that we embed HTML code and there is just reverse case with JSP .\nIn JSP we write HTML code and in that we embed java code using tags provided by JSP. is java technology which enables Web developers and designers to rapidly develop and easily maintain, information-rich, dynamic Web pages that leverage existing business systems.  JSP technology separates the user interface from content generation, enabling designers to change the overall page layout without altering the underlying dynamic content. is the first non JSP page declaration language designed for  which provided a simpler and more powerful programming model to JSF developers as compare to JSP. It resolves different issues occurs in JSP for web applications development. Here is a table that compares the features of scriplets and facelets:\nJSF is an advanced framework wherein its very easy to implement Model-View-Controller (MVC) based architecture for projects. Main advantage of JSF over JSP is the easy dynamic rendering of the components on the browser based upon conditions and easy integration of ajax events.The front end of the JSF application i.e. xhtml files are the ones which are shown to the user via browser. These xhtml files internally invoke managed beans e.g. controllers wherein actual application logic is written.The controllers internally invoke various services which communicate with database (using Hibernate or JPA API). This is how the flow happens in short.JSF is also used in combination with RichFaces which is a framework for giving rich look and feel to your web application. JSF + RichFaces + Hibernate/JPA is a good technology to learn for sure !Jsp is also having in built servlet code which don't need any external compilation it can be run directly run. Changes will take effect in jsp directly in a browser.Servlet need to be compiled (i.e it will have specific class creation)Jsf is a view component of MVC FrameworkJSP stands for JAVA SERVER PAGE........ \njsp is not a servlet.\nJsp uses code and HTML tag both in itself you dont need to make a HTML and a servlet seprately.Jsp are playing magnificent role in web application.\nServlet is a java class plays an role to make your HTML page from static to dynamic .JSPs are the View component of MVC (Model View Controller).  The Controller takes the incoming request and passes it to the Model, which might be a bean that does some database access.  The JSP then formats the output using HTML, CSS and JavaScript, and the output then gets sent back to the requester.JSP have it's own life cycle\njsp_init()\njsp_service()\njsp_destroyAfter first request JSP convert to .java file. There is three type of tag we are using\n1.)ScriptlessHere developer can declare all those things which developer want to take the data  2.)Expression tagHere developer can use some print related data3.)DeclarationHere developer can declare some method related data.Servlet have it's own life cycle.After first request container will read the data from web.xml file\nthen after out welcome fill will be display.\nNow onward after performing action it will search the url and after this process it will search the particular servlet there it self. service operation will perform.JSF have it's own ui and it's life cycle can perform in six way,For ui here for table here we are using panel grid and there is different faces for this that is."},
{"body": "What is the difference between ,  and  in Java? \nI don't see any difference in the output as all the three has  and . What are s?All three classes implement the  interface and offer mostly the same functionality. The most important difference is the order in which iteration through the entries will happen: is the generic name for hash-based maps. In the context of the Java API,\n is an obsolete class from the days of Java 1.1 before the collections framework existed. It should not be used anymore, because its API is cluttered with obsolete methods that duplicate functionality, and its methods are synchronized (which can decrease performance and is generally useless). Use  instead of Hashtable. I prefer visual presentation: All three represent mapping from unique keys to values, and therefore implement the  interface.Just some more input from my own experience with maps, on when I would use each one:See where each class is in the class hierarchy in the following diagram (). TreeMap implements  and  while  doesn't. is obsolete and the corresponding  class should be used.\nLook at how performance varying..\nTree map which is an implementation of Sorted map. The complexity of the put, get and containsKey operation is O(log n) due to the Natural ordering@Amit:  is an interface whereas  is a class which implements the  interface. That means if follows the protocol which  asks its implementers to do.\nA tree unless implemented as search tree, can't give you ordered data because tree can be any kind of tree. So to make TreeMap work like Sorted order, it implements SortedMap ( e.g, Binary Search Tree - BST, balanced BST like AVL and R-B Tree , even Ternary Search Tree - mostly used for iterative searches in ordered way ).In NUT-SHELL\n : gives data in O(1) , no ordering : gives data in O(log N), base 2. with ordered keys : is Hash table with linked list (think of indexed-SkipList) capability to store data in the way it gets inserted in the tree. Best suited to implement LRU ( least recently used ).Let me put it simple:These are different implementations of the same interface. Each implementation has some advantages and some disadvantages (fast insert, slow search) or vice versa.For details look at the javadoc of , , .All offer a key->value map and a way to iterate through the keys. The most important distinction between\nthese classes are the time guarantees and the ordering of the keys.Imagine you passed an empty TreeMap, HashMap, and LinkedHashMap into the following function:The output for each will look like the results below.For HashMap, the output was, in my own tests, { 0, 1, -1}, but it could be any ordering. There is no guarantee on the\nordering.\nTreemap,the output was,{ -1, 0, 1}\nLinkedList,the output was,{ 1, -1, 0}All three classes ,  and  implements  interface, and represents mapping from unique key to values. Ref: \ncan contain one null key.HashMap maintains no order. TreeMap can not contain any null key.TreeMap maintains ascending order.LinkedHashMap can be used to maintain insertion order, on which keys are inserted into Map or it can also be used to maintain an access order, on which keys are accessed.::1) HashMap map = new HashMap();2) TreeMap map = new TreeMap();3) LinkedHashMap map = new LinkedHashMap();"},
{"body": "As part of my requirement I need to convert the given decimal value which is measured in 10ms ticks into seconds. Example values are: 437540, 1207959583, 9468Need some help in how to convert this value into seconds using Java?There are 1000ms in a second.  is . Divide the number of  ticks by  and you'll have the number of seconds."},
{"body": "Is there a function built into Java that capitalizes the first character of each word in a String, and does not affect the others?Examples:*( would be find too, but I don't expect it to be THAT smart.)A quick look at the  reveals only  and , which of course do not provide the desired behavior. Naturally, Google results are dominated by those two functions. It seems like a wheel that must have been invented already, so it couldn't hurt to ask so I can use it in the future.  (from )(Note: if you need  to become , then use  instead)If you're only worried about the first letter of the first word being capitalized:The following method converts all the letters into upper/lower case, depending on their position near a space or other special chars.Try this very simple wayexample givenString=\"ram is good boy\"Output will be: Ram Is Good BoyI've written a small Class to capitalize all the words in a String. Optional , each one with its behavior (capitalize before, after, or both, to handle cases like );Optional ; Don't breaks with .Output: Note: first letter will always be capitalized (edit the source if you don't want that).Please share your comments and help me to found bugs or to improve the code... Code:Using  make it very simple.Use the Split method to split your string into words, then use the built in string functions to capitalize each word, then append together. Pseudo-code (ish)In the end string looks something like\n\"The Sentence You Want To Apply Caps To\"This might be useful if you need to capitalize titles. It capitalizes each substring delimited by , except for specified strings such as  or . I haven't ran it yet because it's late, should be fine though. Uses Apache Commons  at one point. You can substitute it with a simple loop if you wish.im using this function i think is faster in performance.: HelloThere are many how to convert the first letter of the first word being capitalized. I have an idea. It's very simple:Here is a simple functionIf I'm not too late to the party here's my answer:This is just another way of doing it:Resuable Method for intiCap}I'm not sure how to use this SO answer box yet, but here is my solution.  I ran across this problem tonight and decided to search it. I found an answer by Neelam Singh that was almost there so I decided to fix the issue (broke on empty strings) and causes system crash.  The method you are looking for is named capString(String s) below. \nIt turns \"It's only 5am here\" into \"It's Only 5am Here\". The code is pretty well commented, so enjoy. Cheers!package com.lincolnwdaniel.interactivestory.model;public class StringS {}I made a solution in Java 8 that is imho more readable.The Gist for this solution can be found here. I decided to add one more solution for capitalizing words in a string:Function:Example call:Result:Did you mean ?For those of you using Velocity in your MVC, you can use the  method from .The Short and Precise way is as follows: without error if you try and change the name value to the three of values .Error freethis one work for Surname case..\nwith different type of separator, and keep the same sepator\njean-frederic  --> Jean-Frederic\njean frederic  --> Jean Fredericthe code work with GWT client side.If you prefer Guava...try this I had a requirement to make a generic toString(Object obj) helper class function, where I had to convert the fieldnames into methodnames - getXXX() of the passed Object. Here is the code And my toString() utility is like this"},
{"body": "I have a Spring  class () that has an  field (), but the field is  when I try to use it. The logs show that both the  bean and the  bean are being created, but I get a  whenever I try to call the  method on my service bean. Why isn't Spring autowiring the field?Controller class:Service class:Service bean that should be autowired in  but it isn't:When I try to , I get this exception:The field annotated  is  because Spring doesn't know about the copy of  that you created with  and didn't know to autowire it. has three main logical components: a registry (called the ) of components (beans) that are available to be used by the application, a configurer system that injects objects' dependencies into them by matching up the dependencies with beans in the context, and a dependency solver that can look at a configuration of many different beans and determine how to instantiate and configure them in the necessary order.The IoC container isn't magic, and it has no way of knowing about Java objects unless you somehow inform it of them. When you call , the JVM instantiates a copy of the new object and hands it straight to you--it never goes through the configuration process. There are three ways that you can get your beans configured.I have posted all of this code, using Spring Boot to launch, at ; you can look at a full running project for each approach to see everything you need to make it work. The most preferable option is to let Spring autowire all of your beans; this requires the least amount of code and is the most maintainable. To make the autowiring work like you wanted, also autowire the  like this:If you need to create a new instance of your service object for different requests, you can still use injection by using .If you really need objects created with  to be autowired, you can  to inject your objects. This approach inserts code into your object's constructor that alerts Spring that it's being created so that Spring can configure the new instance. This requires a bit of configuration in your build (such as compiling with ) and turning on Spring's runtime configuration handlers ( with the JavaConfig syntax). This approach is used by the Roo Active Record system to allow  instances of your entities to get the necessary persistence information injected.This approach is suitable only for interfacing with legacy code in special situations. It is nearly always preferable to create a singleton adapter class that Spring can autowire and the legacy code can call, but it is possible to directly ask the Spring application context for a bean.To do this, you need a class to which Spring can give a reference to the  object:Then your legacy code can call  and retrieve the beans it needs:If you are not coding a web application, make sure your class in which @Autowiring is done is a spring bean. Typically, spring container won't be aware of the class which we might think of as a spring bean. We have to tell the Spring container about our spring classes.This can be achieved by configuring in appln-contxt or  is to annotate class as  and please do not create the annotated class using new operator.\nMake sure you get it from Appln-context as below.I once encountered the same issue when I was not quite used to . The  field of one of my beans is null at runtime.The root cause is, instead of using the auto-created bean maintained by the Spring IoC container (whose  field is  properly injected), I am  my own instance of that bean type and using it. Of course this one's  field is null because Spring has no chance to inject it.Your problem is new (object creation in java style)With annotation , ,  beans are created in the\n    application context of Spring when server is started. But when we create objects \n    using new operator the object is not registered in  application context which  is already created. For Example Employee.java class i have used.Check this out:Actually you should use either JVM managed Objects or Spring managed Object to invoke methods.\nfrom your above code in your controller class you are creating new object to call your service class which have auto wired object.so it won't work that way. solution is make this MileageFeeCalculator as autowired object in Controller itself.Change your Controller class like below.I make Spring inject  in this bean:You can put this code also in the main application class if you want.Other classes can use it like this:In this way  (also intantiated with ) and .It seems to be rare case but here is what happened to me:We used  instead of  which is javaee standard supported by spring. Every places it worked fine and the beans injected correctly, instead of one place. The bean injection seems the sameAt last we found that the error was that we (actually, the eclipse ide out complete feature) imported  instead of  !So to summarize, make sure that your annotations (, ,  ,... ) have correct packages!Another solution would be putting call:\n\nTo MileageFeeCalculator constructor like this:You can also fix this issue using @Service annotation on service class and passing the required bean classA as a parameter to the other beans classB constructor and annotate the constructor of classB with @Autowired. Sample snippet here :I think you have missed to instruct spring to scan classes with annotation. You can use  on the configuration class of your spring application to instruct spring to scan. etc annotations add meta description.\n Spring only injects instances of those classes which are either created as bean or marked with annotation.Classes marked with annotation need to be identified by spring before injecting,  instruct spring look for the classes marked with annotation. When Spring finds  it searches for the related bean, and injects the required instance.Adding annotation only, does not fix or facilitate the dependency injection, Spring needs to know where to look for."},
{"body": "I receive following error when I save the object using Hibernate You should include  (if using xml) or  (if using annotations) on your collection mapping.This happens because you have a collection in your entity, and that collection has one or more items which are not present in the database. By specifying the above options you tell hibernate to save them to the database when saving their parent.I believe this might be just repeat answer, but just to clarify, I got this on a  mapping as well as a .  In both cases, it was the fact that the  object I was adding to the  wasn't saved in the database yet.  So when I added the  to the , then saved the , Hibernate would toss the  message when saving the Parent.Adding in the  on the  reference to the  solved the problem in both cases.  This saved the  and the .Sorry for any repeat answers, just wanted to further clarify for folks.This happens when saving an object when Hibernate thinks it needs to save an object that is associated with the one you are saving. I had this problem and did not want to save changes to the referenced object so I wanted the cascade type to be NONE. The trick is to ensure that the ID and VERSION in the referenced object is set so that Hibernate does not think that the referenced object is a new object that needs saving. This worked for me.Look through all of the relationships in the class you are saving to work out the associated objects (and the associated objects of the associated objects) and ensure that the ID and VERSION is set in all objects of the object tree.Or, if you want to use minimal \"powers\" (e.g. if you don't want a cascade delete) to achieve what you want, use This isn't the only reason for the error. I encountered it just now for a typo error in my coding, which I believe, set a value of an entity which was already saved.I spotted the error by finding exactly which variable caused the error (in this case ). I used a  around the whole block of code that saved the entity and printed the traces.This occurred for me when persisting an entity in which the existing record in the database had a NULL value for the field annotated with @Version (for optimistic locking). Updating the NULL value to 0 in the database corrected this.If your collection is nullable just try: In my case it was caused by not having  on the  side of the bidirectional relationship. To be more precise, I had  on  side and did not have it on . Adding  to  resolved the issue.\n side: (caused the problem) (fixed by adding )To add my 2 cents, I got this same issue when I m accidentally sending  as the ID. Below code depicts my scenario .Here I m setting the existing department id to a new employee instance without actually getting the department entity first, as I don't want to another select query to fire.In some scenarios,  PKID is coming as  from calling method and I m getting the same error. i get this error when i use but it works with no problem when I use One other possible reason: in my case, I was attempting to save the child before saving the parent, on a brand new entity.The code was something like this in a User.java model:The setNewPassword() method creates a PasswordHistory record and adds it to the history collection in User. Since the create() statement hadn't been executed yet for the parent, it was trying to save to a collection of an entity that hadn't yet been created. All I had to do to fix it was to move the setNewPassword() call after the call to create().Simple way of solving this issue is save the both entity.\nfirst save the child entity and then save the parent  entity.\nBecause parent entity is depend on child entity for the foreign key value.Below simple exam of one to one relationshipbeside all other good answers, this could happen if you use  to persist an object and accidentally forget to use merged reference of the object in the parent class. consider the following exampleIn this case, you merge  but forget to use merged object of . to solve the problem you must rewrite the code like this.There is another possibility that can cause this error in hibernate. You may set an unsaved reference of your object  to an attached entity  and want to persist object . Even in this case, you will get the aforementioned error.Don't use  until you really have to.  and  have bidirectional  relation. Then the following code would work fine  while if the object is just a \"new\" one, then it would throw the same error.One possible cause of the error is the inexistence of the setting of the value of the parent entity ; for example for a department-employees relationship you have to write this in order to fix the error :"},
{"body": "Why doesn't Java include support for unsigned integers?  It seems to me to be an odd omission, given that they allow one to write code that is less likely to produce overflows on unexpectedly large input.  Furthermore, using unsigned integers can be a form of self-documentation, since they indicate that the value which the unsigned int was intended to hold is never supposed to be negative.  Lastly, in some cases, unsigned integers can be more efficient for certain operations, such as division.  What's the downside to including these?This is from an , about simplicity:Reading between the lines, I think the logic was something like this:Mostly, I'd say it was a reasonable decision. Possibly, I would have:Still, with a bit of kludging, operations on unsigned values up to 32 bits aren't tooo bad, and most people don't need unsigned 64-bit division or comparison.This is an older question and pat did briefly mention char, I just thought I should expand upon this for others who will look at this down the road. Let's take a closer look at the Java primitive types: - 8-bit signed integer - 16-bit signed integer - 32-bit signed integer - 64-bit signed integer - 16-bit character (unsigned integer)Although  does not support  arithmetic, it essentially can be treated as an  integer. You would have to explicitly cast arithmetic operations back into , but it does provide you with a way to specify  numbers.Yes, there isn't direct support for unsigned integers (obviously, I wouldn't have to cast most of my operations back into char if there was direct support). However, there certainly exists an unsigned primitive data type. I would liked to have seen an unsigned byte as well, but I guess doubling the memory cost and instead use char is a viable option.With JDK8 there are new APIs for  and  which provide helper methods when treating  and  values as unsigned values.Additionally,  provides a number of helper methods to do similar things for at the integer types which helps close the gap left by the lack of native support for  integers.As soon as signed and unsigned ints are mixed in an expression things start to get messy and you probably  lose information. Restricting Java to signed ints only really clears things up. I\u2019m glad I don\u2019t have to worry about the whole signed/unsigned business, though I sometimes do miss the 8th bit in a byte.This guy says because the C standard defines operations involving unsigned and signed ints to be treated as unsigned. This could cause negative signed integers to roll around into a large unsigned int, potentially causing bugs.Java does have unsigned types, or at least one:  char is an unsigned short.  So whatever excuse Gosling throws up it's really just his ignorance why there are no other unsigned types.Also Short types:  shorts are used all the time for multimedia.  The reason is you can fit 2 samples in a single 32-bit unsigned long and vectorize many operations.   Same thing with 8-bit data and unsigned byte.  You can fit 4 or 8 samples in a register for vectorizing.I think Java is fine as it is, adding unsigned would complicate it without much gain.\nEven with the simplified model most Java programmers don't know how the basic numeric types behave, just read the book \"Java Puzzlers\" and you will know what I mean.As for practical advice:If your values are somewhat arbitrary size and don't fit into int, use long.\nIf they don't fit into long use BigInteger.Use the smaller types only for arrays when you need to save space.If you need exactly 64/32/16/8 bits, use long/int/short/byte and stop worrying about the sign, except for division and comparison.See also  answer.With  it does have some support for them.We may yet see full support of unsigned types in Java despite Gosling's concerns.I know this post is too old; however for your interest, in Java 8 and later, you can use the int data type to represent an unsigned 32-bit integer, which has a minimum value of 0 and a maximum value of 2-1. Use the Integer class to use int data type as an unsigned integer and Static methods like compareUnsigned, divideUnsigned etc have been added to the Integer class to support the arithmetic operations for unsigned integers.I've heard stories that they were to be included close to the orignal Java release. Oak was the precursor to Java, and in some spec documents there was mention of usigned values. Unfortunately these never made it into the Java language. As far as anyone has been able to figure out they just didn't get implemented, likely due to a time constraint.I once took a C++ course with someone on the C++ standards committee who implied that Java made the right decision to avoid having unsigned integers because (1) most programs that use unsigned integers can do just as well with signed integers and this is more natural in terms of how people think, and (2) using unsigned integers results in lots easy to create but difficult to debug issues such as integer arithmetic overflow and losing significant bits when converting between signed and unsigned types. If you mistakenly subtract 1 from 0 using signed integers it often more quickly causes your program to crash and makes it easier to find the bug than if it wraps around to 2^32 - 1, and compilers and static analysis tools and runtime checks have to assume you know what you're doing since you chose to use unsigned arithmetic. Also, negative numbers like -1 can often represent something useful, like a field being ignored/defaulted/unset while if you were using unsigned you'd have to reserve a special value like 2^32 - 1 or something similar.Long ago, when memory was limited and processors did not automatically operate on 64 bits at once, every bit counted a lot more, so having signed vs unsigned bytes or shorts actually mattered a lot more often and was obviously the right design decision. Today just using a signed int is more than sufficient in almost all regular programming cases, and if your program really needs to use values bigger than 2^31 - 1, you often just want a long anyway. Once you're into the territory of using longs, it's even harder to come up with a reason why you really can't get by with 2^63 - 1 positive integers. Whenever we go to 128 bit processors it'll be even less of an issue.Because  type is pure evil.The fact that in C  produces  is even more evil.Here is a snapshot of the problem that burned me more than once:Have you noticed the bug yet? I confess I only saw it after stepping in with the debugger. Because  is of unsigned type  the entire expression  evaluates as . That expression is intended to be a  position of the th ray from the middle one: the 1st ray from the middle one on the left side would have position -1, the 1st one on the right would have position +1, etc. After taking abs value and multiplying by the  angle I would get the angle between th ray and the middle one.Unfortunately for me the above expression contained the evil unsigned and instead of evaluating to, say, -1, it evaluated to 2^32-1. The subsequent conversion to  sealed the bug.After a bug or two caused by misuse of  arithmetic one has to start wondering whether the extra bit one gets is worth the extra trouble. I am trying, as much as feasible, to avoid any use of  types in arithmetic, although still use it for non-arithmetic operations such as binary masks.I can think of one unfortunate side-effect. In java embedded databases, the number of ids you can have with a 32bit id field is 2^31, not 2^32 (~2billion, not ~4billion).The reason IMHO is because they are/were too lazy to implement/correct that mistake. \nSuggesting that C/C++ programmers does not understand unsigned, structure, union, bit flag... Is just preposterous.Ether you were talking with a basic/bash/java programmer on the verge of beginning programming a la C, without any real knowledge this language or you are just talking out of your own mind. ;)when you deal every day on format either from file or hardware you begin to question, what in the hell they were thinking.A good example here would be trying to use an unsigned byte as a self rotating loop. \nFor those of you who do not understand the last sentence, how on earth you call yourself a programmer. DC"},
{"body": "I am trying to use a  method of a string. But if I place %1, %2, etc. in the string, java.util.UnknownFormatConversionException is thrown pointing to a confusing Java source code piece:From this I understand that  char is forbidden. If so, then what should I use for argument placeholders?I use  2.8.While all the previous responses are correct, they're all in Java. Here's a Scala example:I also have a blog post about  that might be useful.You don't need to use numbers to indicate positioning.  By default, the position of the argument is simply the order in which it appears in the string.Here's an example of the proper way to use this:You will always use a  followed by some other characters to let the method know how it should display the string.    is probably the most common, and it just means that the argument should be treated as a string.I won't list every option, but I'll give a few examples just to give you an idea: just uses a , so for a full description of the options you can see the .And, as BalusC mentions, you will see in the documentation that is possible to change the default argument ordering if you need to.   However, probably the only time you'd need / want to do this is if you are using the same argument more than once.Instead of looking at the source code, you should read the javadoc  and .You specify the format of the value after the %. For instance for decimal integer it is , and for String it is :Output: To do what you tried (use an argument index), you use: ,Output:You can use this;Output: Also note that Scala extends String with a number of methods (via implicit conversion to a WrappedString brought in by Predef) so you could also do the following:The official reference is the class .In Scala 2.10Here is a list of formatters used with String.format()This is a list of what  can do. The same goes for Although @Londo mentioned Scala's \"s\" string interpolator, I think Scala's  is more relevant to the original question. The example used a few time in other responses could also be written (since Scala 2.10) this way:The connection to the original question is to be aware that:The nice thing about string interpolation is that it lets you see which variable is being substituted directly into the string instead of having to match it with the arguments to the  method.In scala , for string Interpolation we have  that saves the day and make our life much easy: You want to define a function that takes input name and age and says Hello With the name and says its age.\nThat can be written like this:Hence , When you call this function: like this :Its output would be :You can write the code to change it in the same line, like if you want to add 10 years to the age ! then function could be :And now the output would be :"},
{"body": "What's the most idiomatic way in Java to verify that a cast from  to  does not lose any information?This is my current implementation:A new method has been added with  to do just that. Will throw an ArithmeticException in case of overflow. See:  Several other overflow safe methods have been added to Java 8. They end with . Examples: I think I'd do it as simply as:I think that expresses the intent more clearly than the repeated casting... but it's somewhat subjective.Note of potential interest - in C# it would just be:With Google Guava's  class, your method can be changed to:From the linked docs:Incidentally, you don't need the  wrapper, unless you want to leave it in place for changing out the functionality without extensive refactoring of course.With BigDecimal:here is a solution, in case you don't care about value in case it is bigger then needed ;)I claim that the obvious way to see whether casting a value changed the value would be to cast and check the result. I would, however, remove the unnecessary cast when comparing. I'm also not too keen on one letter variable names (exception  and , but not when they mean row and column (sometimes respectively)).However, really I would want to avoid this conversion if at all possible. Obviously sometimes it's not possible, but in those cases  is almost certainly the wrong exception to be throwing as far as client code is concerned.My first approach was:But that merely just casts the long to an int, potentially creating new  instances or retrieving them from the Long pool.The drawbacksSo this can be considered even worse than just casting the  to .Java integer types are represented as signed. With an input between 2 and 2 (or -2 and -2) the cast would succeed but your test would fail. What to check for is whether all of the high bits of the  are all the same:but Long can not exceed the maximum :)One other solution can be: I have tried this for cases where the client is doing a POST and the server DB understands only Integers while the client has a Long. "},
{"body": "I was looking at the Proxy Pattern, and to me it seems an awful lot like the Decorator, Adapter, and Bridge patterns. Am I misunderstanding something? What's the difference? Why would I use the Proxy pattern versus the others? How have you used them in the past in real world projects?Proxy, Decorator, Adapter, and Bridge are all variations on \"wrapping\" a class.  But their uses are different..So are their structures.My take on the subject. All four patterns have a lot in common, all four are sometimes informally called wrappers, or wrapper patterns. All use composition, wrapping subject and delegating the execution to the subject at some point, do mapping one method call to another one. They spare client the necessity of having to construct a different object and copy over all relevant data. If used wisely, they save memory and processor.  By promoting loose coupling they make once stable code less exposed to inevitable changes and better readable for fellow developers.Adapter adapts subject (adaptee) to a different interface. This way we can add object be placed to a collection of nominally different types. Adapter expose only relevant methods to client, can restrict all others, revealing usage intents for particular contexts, like adapting external library, make it appear less general and more focused on our application needs. Adapters increase readability and self description of our code.Adapters shields one team from volatile code from other teams; a life savior tool when dealing with offshore teams ;-)Less mentioned purpose it to prevent the subject class from excess of annotations. With so many frameworks based on annotations this becomes more important usage then ever.Adapter helps to get around Java limitation of only single inheritance. It can combine several adaptees under one envelope giving impression of multiple inheritance.Code wise, Adapter is \u201cthin\u201d. It should not add much code to the adaptee class, besides simply calling the adaptee method and occasional data conversions necessary to make such calls.There are not many good adapter examples in JDK or basic libraries. Application developers create Adapters, to adapt libraries to application specific interfaces.Decorator not only delegate, not only maps one method to another, they do more, they modify behaviour of some subject methods, it can decide not call subject method at all, delegate to a different object, a helper object.Decorators typically add (transparently) functionality to wrapped object like logging, encryption, formatting, or compression to subject. This New functionality may bring a lot of new code. Hence, decorators are usually much \u201cfatter\u201d then Adapters. Decorator must be a sub-class of subject's interface. They can be used transparently instead of its subjects. See BufferedOutputStream, it is still OutputStream and can be used as such. That is a major technical difference from Adapters.Text book examples of whole decorators family is readily in JDK - the Java IO. All classes like ,  and  are decorators of . They can be onion layered, where one one decorator is decorated again, adding more functionality. Proxy is not a typical wrapper. The wrapped object, the proxy subject, may not yet exist at the time of proxy creation. Proxy often creates it internally. It may be a heavy object created on demand, or it is remote object in different JVM or different network node and even a non-Java object, a component in native code. It does not have to necessary wrap or delegate to another object at all.Most typical examples are remote proxies, heavy object initializers and access proxies.Facade is closely associated with design Principle of Least Knowledge (Law of Demeter).\nFacade is very similar to Adapter. They both wrap, they both map one object to another, but they differ in the intent. Facade flattens complex structure of a subject, complex object graph, simplifying access to a complex structure. Facade wraps a complex structure, providing a flat interface to it. This prevents client object from being exposed to inner relations in subject structure hence promoting loose coupling.More complex variant of Adapter pattern where not only implementation varies but also abstraction. It adds one more indirection to the delegation. The extra delegation is the bridge. It decouples Adapter even from adapting interface. It increases complexity more than any other of the other wrapping patterns, so apply with care.Pattern differences are also obvious when looking at their constructors.Real life example \u2013 . Purpose of this adapter is mapping of a simple flat class to more complex structure required externally and to prevent \"polluting\" subject class with excessive annotations.There's a great deal of overlap in many of the GoF patterns. They're all built on the power of polymorphism and sometimes only really differ in intent. (strategy vs. state)My understanding of patterns increased 100 fold after reading .I highly recommend it!They are quite similar, and the lines between them are quite gray. I suggest you read the  and  entries in the c2 wiki.The entries and discussions there are quite extensive, and they also link to other relevant articles. By the way, the c2 wiki is excellent when wondering about the nuances between different patterns.To sum the c2 entries up, I would say a decorator adds/changes behavior, but a proxy has more to do with access control (lazy instantiation, remote access, security etc). But like I said, the lines between them are gray, and I see references to proxies that could easily be viewed as decorators and vice versa.All good answers from experts have already explained what does each pattern stands for.I will  key points.e.g. (with chaining ) : e.g.:  package classes.e.g.  ( returns a )e.g. Collection classes in .  implemented by .Have a look at great SE questions/articles regarding examples of various design patterns All of the four patterns involve wrapping inner object/class with outer one, so they are very similar structurally. I would outline difference by the purpose:And by interface variation between inner and outer objects:I use it quite often when consuming web services.  The Proxy Pattern should probably be renamed to something more pragmatic, like 'Wrapper Pattern\".  I also have a library that is a Proxy to MS Excel.  It makes it very easy to automate Excel, without having to worry about background details such as what version is installed (if any). Speaking detail implementation, I find a difference between Proxy and Decorator, Adapter, Facade ... In common implementation of these patterns there's a target object wrapped by a enclosing object. Client uses enclosing object instead of target object. And the target object actually play an important part inside some of methods of enclosing object. However, in case of Proxy, enclosing object can play some methods by itself, it just initialize target object when client calls some methods that it needs target object take part in. This is lazy initialization. In case of other patterns, enclosing object is virtually based on target object. So target object is always initialized along with enclosing object in constructors/setters.Another thing, a proxy does exactly what a target does whereas other patterns add more functionality to target. This is quote from \nDefinitions belongs to book. Examples belongs to me. - Doesn\u2019t alter the interface, but adds responsibility. Assume you have a car interface,\nwhen you implement this for different model of the car (s, sv, sl) you may need to  for some models. Like has sunroof, airbag etc.. - Converts one interface to another. You have a car interface and you would like it to act like jeep. So you take the car, modify it and turn into a jeep.  - Makes an interface simpler.  Assume you have car, airplane, ship interfaces. Actually all you need is a class which sends people from one location to another. You want facade to decide what vehicle to use. Then you collect all those  under 1 umbrella and let it decide/delegate to keep it simple.Head First: \"A facade not only simplifies an interface, it decouples a client from a subsystem \nof components.\nFacades and adapters may wrap multiple classes, but a facade\u2019s intent is to simplify, while \nan adapter\u2019s is to convert the interface to something different.\"I would like to add examples to Bill Karwing answer (which is great btw.)\nI add also some key differences of implementation, that I feel are missingQuoted parts are from answer of [ (Bill Karwing)ProxyClass and ObjectClass that is proxied, should implement same interface, so they are interchangable DecoratorClass should(could) implement extended interface of ObjectClass. So the ObjectClass could be replaced by DecoratorClass, but not vice versa. Adapter provides a different interface to its subject. Proxy provides the same interface. Decorator provides an enhanced interface.Most of the information in this answer is from , which I recommend as an  for design patterns.I believe code will give a clear ideas (to complement others answers as well). Please see below, (Focus the types that a class implements and wraps)Design pattern is not mathematics, it is combination of art and software engineering. There is nothing like for this requirment you have to use proxy, bridge etc. Design patterns are created to solve the problems. If you anticipate a design problem, then use it. Based on experience, you will come to know for specific problem, which pattern to use. If you are good in solid design principles, you would have implemented design pattern without knowing it is pattern. Common example is statergy and factory patternsHence concentrate more on solid desighn principles, clean coding principles and ttd"},
{"body": "How can I achieve this?Everything I have tried so far always returns type  rather than the specific type used.As others mentioned, it's only possible via reflection in certain circumstances.If you really need the type, this is the usual (type-safe) workaround pattern:I have seen something like thisin the  ExampleGenerics are not  at run-time. This means the information is not present at run-time.Adding generics to Java while mantaining backward compatibility was a tour-de-force (you can see the seminal paper about it: ).There is a rich literature on the subject, and some people are  with the current state, some says that actually it's a  and there is no real need for it. You can read both links, I found them quite interesting.Sure, you can.Java does not  the information at run time, for backwards compatibility reasons.  But the information is  as metadata and can be accessed via reflection (but it is still not used for type-checking).From the official API:, for your scenario I would not use reflection.  I'm personally more inclined to use that for framework code.  In your case I would just add the type as a constructor param.Use Guava.A while back, I posted some full-fledge examples including abstract classes and subclasses .Note: this requires that you instantiate a  of  so it can bind the type parameter correctly. Otherwise it'll just return the type as .Java generics are mostly compile time, this means that the type information is lost at runtime.will be compiled to something likeTo get the type information at runtime you have to add it as an argument of the ctor.Example:Technique described in this  works for me.In short quick and dirty example:I dont think you can, Java uses type erasure when compiling so your code is compatible with applications and libraries that were created pre-generics.From the Oracle Docs:I used follow approach:This is my solution:Here is working solution!!!NOTES:\n\n 1. Has to be extended with typed class  ()\n\n 2. Has to be created as anonymous implementation ()   I think there is another elegant solution.What you want to do is (safely) \"pass\" the type of the generic type parameter up from the concerete class to the superclass.If you allow yourself to think of the class type as \"metadata\" on the class, that suggests the Java method for encoding metadata in at runtime:  annotations.First define a custom annotation along these lines:You can then have to add the annotation to your subclass.Then you can use this code to get the class type in  your base class:Some limitations of this approach are:You can't.  If you add a member variable of type T to the class (you don't even have to initialise it), you could use that to recover the type.Just in case you use store a variable using the generic type you can easily solve this problem adding a getClassType method as follows:I use the provided class object later to check if it is an instance of a given class, as follows:Here is my trick:To complete some of the answers here, I had to get the ParametrizedType of MyGenericClass, no matter how high is the hierarchy, with the help of recursion:Here's one way, which I've had to use once or twice:Along withI found this to be a simple understandable and easily explainable  solutionYou don't need a constructor.Here is my solutionNo matter how many level does your class hierarchy has,\nthis solution still works, for example:In this case, getMyType() = java.lang.String"},
{"body": "I have created the following function for checking the connection status:When I shut down the server for testing the execution waits a long time at lineDoes anyone know how to set the timeout in order to avoid waiting too long?Thanks!In my example two timeouts are set. The connection timeout throws \"java.net.SocketTimeoutException: Socket is not connected\" and the socket timeout \"java.net.SocketTimeoutException: The operation timed out\".If you want to set the Parameters of any existing HTTPClient (e.g. DefaultHttpClient or AndroidHttpClient) you can use the function .To set settings on the client:I've used this successfully on JellyBean, but should also work for older platforms ....HTHIf your are using Jakarta's  then you can do something like:If you're using the default http client, here's how to do it using the default http params:Original credit goes to For those saying that the answer of @kuester2000 does not work, please be aware that HTTP requests, first try to find the host IP with a DNS request and then makes the actual HTTP request to the server, so you may also need to set a timeout for the DNS request. If your code worked without the timeout for the DNS request it's because you are able to reach a DNS server or you are hitting the Android DNS cache. By the way you can clear this cache by restarting the device.This code extends the original answer to include a manual DNS lookup with a custom timeout:Used method:This class is from . Go and check the remarks if you will use it.If you are using the , call :you can creat HttpClient instance by the way with Httpclient-android-4.3.5,it can work well.An option is to use the  client, from Square.In the build.gradle, include this line: For example, if you want to set a timeout of 60 seconds, do this way:ps: If your minSdkVersion is greater than 8, you can use . So, you can simply use:For more details about the units, see ."},
{"body": "I have a poorly designed class in a 3rd-party  and I need to access one of its  fields. For example,\nwhy should I need to choose private field is it necessary?How can I use reflection to get the value of ?In order to access private fields, you need to get them from the class's  fields and then make them accessible:: as has been commented by , both accessing the field, setting it as accessible and retrieving the value will all throw s, although the only  exceptions you need to be mindful of are commented above.The  would be thrown if you asked for a field by a name which did not correspond to a declared field. The  would be thrown if the field was not accessible (for example, if it is private and has not been made accessible via missing out the  line.The s which may be thrown are either s (if the JVM's  will not allow you to change a field's accessibility), or s, if you try and access the field on an object not of the field's class's type:Try  from apache commons-lang3:Reflection isn't the only way. An alternative solution is to extract the class from the .jar, decompile it using (say)  or , change the field (or add an accessor), and recompile it against the original .jar. Then put the new .class ahead of the  in the classpath, or reinsert it in the . (the jar utility allows you to extract and reinsert to an existing .jar)This requires the  not to be signed, of course.One other option that hasn't been mentioned yet: use .  Groovy allows you to access private instance variables as a side effect of the design of the language.  Whether or not you have a getter for the field, you can just use As oxbow_lakes mentions, you can use reflection to get around the access restrictions (assuming your SecurityManager will let you).That said, if this class is so badly designed that it makes you resort to such hackery, maybe you should look for an alternative. Sure this little hack might be saving you a few hours now, but how much will it cost you down the road?Use the Soot Java Optimization framework to directly modify the bytecode.\nSoot is completely written in Java and works with new Java versions.Using the  you can access all the  fields and methods of one class to another .But as per the    in the section  they recommended that : here is following code snapts to demonstrate basic concepts of  Reflection1.javaReflection2.javaHope it will help.Just an additional note about reflection: I have observed in some special cases, when several classes with the same name exist in different packages, that reflection as used in the top answer may fail to pick the correct class from the object. So if you know what is the package.class of the object, then it's better to access its private field values as follows:(This is the example class that was not working for me)You need to do the following:"},
{"body": "Coming from C++ to Java, the obvious unanswered question is why didn't Java include operator overloading?Isn't  much simpler than ?Is there a known reason for this, valid arguments for  allowing operator overloading? Is the reason arbitrary, or lost to time?Assuming you wanted to overwrite the previous value of the object referred to by 'a', then a member function would have to be invoked.In C++, this expression tells the compiler to create 3 objects on the stack, perform addition, and  the resultant value from the temporary object into the existing object 'a'.However, in java, operator= doesn't perform value copy for reference types, and users can only create new reference types, not value types.  So for a user-defined type named 'Complex', assignment means to copy a reference to an existing value.consider instead:In C++, this copies the value, so the comparison will result not-equal.  In Java, operator= performs reference copy, so 'a' and 'b' are now referring to the same value.  As a result, the comparison will produce 'equal', since the object will compare equal to itself.The difference between copies and references only adds to the confusion of operator overloading.  As Sebastian mentioned, Java and C# both have to deal with value and reference equality separately -- operator+ would likely deal with values and objects, but operator= is already implemented to deal with references.In C++, you should only be dealing with one kind of comparison at a time, so it can be less confusing.  For example, on Complex, operator= and operator== are both working on values -- copying values and comparing values respectively.  There are a lot of posts complaining about operator overloading.I felt I had to clarify the \"operator overloading\" concepts, offering an alternative viewpoint on this concept.This argument is a fallacy.It is as easy to obfuscate code in C or Java through functions/methods than it is in C++ through operator overloads:For another example, let's see the  in Java:You are supposed to clone the object implementing this interface. But you could lie. And create a different object. In fact, this interface is so weak you could return another type of object altogether, just for the fun of it:As the  interface can be abused/obfuscated, should it be banned on the same grounds C++ operator overloading are supposed to be?We could overload the  method of a  class to have it return the stringified hour of the day. Should the  overloading be banned, too? We could sabotage  to have it return a random value, modify the operands... etc. etc. etc..Now that we know that code can be sabotaged even through the pristine Java methods, we can ask ourselves about the real use of operator overloading in C++?We'll compare below, for different cases, the \"same\" code in Java and C++, to have an idea of which kind of coding style is clearer.Please note that A and B could be of any type in C++, as long as the operator overloads are provided. In Java, when A and B are not primitives, the code can become very confusing, even for primitive-like objects (BigInteger, etc.)...In Java, we see that for each container to do the same thing (access its content through an index or identifier), we have a different way to do it, which is confusing.In C++, each container uses the same way to access its content, thanks to operator overload.The examples below use a  object, found using the first links found on Google for \"\" and \"\":And this is not limited to matrices. The  and  classes of Java suffer from the same confusing verbosity, whereas their equivalent in C++ are as clear as built-in types.Ok, in Java you can use  too... But, wait a second: This is operator overloading, isn't it? Isn't it cheating???:-DThe same generic code modifying operands should be usable both for built-ins/primitives (which have no interfaces in Java), standard objects (which could not have the right interface), and user-defined objects.For example, calculating the average value of two values of arbitrary types:Now that we have seen fair comparisons between C++ code using operator overloading, and the same code in Java, we can now discuss \"operator overloading\" as a concept.Indeed, the signification of , , , etc. changes depending on the types of the operands (numerics, vectors, quantum wave functions, matrices, etc.).Most of us, as part of our science courses, learned multiple significations for operators, depending on the types of the operands. Did we find them confusing, them?This is the most important part of operator overloading: Like in mathematics, or in physics, the operation depends on its operands' types.So, know the type of the operand, and you will know the effect of the operation.In C, the real behavior of an operator will change according to its operands. For example, adding two integers is different than adding two doubles, or even one integer and one double. There is even the whole pointer arithmetic domain (without casting, you can add to a pointer an integer, but you cannot add two pointers...).In Java, there is no pointer arithmetics, but someone still found string concatenation without the  operator would be ridiculous enough to justify an exception in the \"operator overloading is evil\" creed.It's just that you, as a C (for historical reasons) or Java (for , see below) coder, you can't provide your own.In C++, operator overloading for built-in types is not possible (and this is a good thing), but  types can have  operator overloads.As already said earlier, in C++, and to the contrary to Java, user-types are not considered second-class citizens of the language, when compared to built-in types. So, if built-in types have operators, user types should be able to have them, too.The truth is that, like the , ,  methods are for Java (), C++ operator overloading is so much part of C++ that it becomes as natural as the original C operators, or the before mentioned Java methods.Combined with template programming, operator overloading becomes a well known design pattern. In fact, you cannot go very far in STL without using overloaded operators, and overloading operators for your own class.Operator overloading should strive to respect the semantics of the operator. Do not subtract in a  operator (as in \"do not subtract in a  function\", or \"return crap in a  method\").Cast overloading can be very dangerous because they can lead to ambiguities. So they should really be reserved for well defined cases. As for  and , do not ever overload them unless you really know what you're doing, as you'll lose the the short circuit evaluation that the native operators  and  enjoy.Because James Gosling said so:Please compare Gosling's text above with Stroustrup's below:Some objects would greatly benefit from operator overloading (concrete or numerical types, like BigDecimal, complex numbers, matrices, containers, iterators, comparators, parsers etc.).In C++, you can profit from this benefit because of Stroustrup's humility. In Java, you're simply screwed because of Gosling's .The reasons for not adding operator overloading now in Java could be a mix of internal politics, allergy to the feature, distrust of developers (you know, the saboteur ones that seem to haunt Java teams...), compatibility with the previous JVMs, time to write a correct specification, etc..So don't hold your breath waiting for this feature...Yeah...While this is far from being the only difference between the two languages, this one never fails to amuse me.Apparently, the C# folks, with their , got it right at first try.Despite all the FUD against used defined operator overloading, the following languages support it: , , , , , , , , , , C++, , , , , , , , , , ...So many languages, with so many different (and sometimes opposing) philosophies, and yet they all agree on that point.Food for thoughts...James Gosling likened designing Java to the following:You can read the Basically operator overloading is great for a class that models some kind of point, currency or complex number. But after that you start running out of examples fast.Another factor was the abuse of the feature in C++ by developers overloading operators like '&&', '||', the cast operators and of course 'new'. The complexity resulting from combining this with pass by value and exceptions is well covered in the  book.Check out Boost.Units: It provides zero-overhead Dimensional analysis through operator overloading. How much clearer can this get?would actually output \"Energy = 4 J\" which is correct. has operator overloading, and runs in the JVM. If you don't mind the performance hit (which gets smaller everyday). It's automatic based on method names. e.g., '+' calls the 'plus(argument)' method.Well you can really shoot yourself in the foot with operator overloading. It's like with pointers people make stupid mistakes with them and so it was decided to take the scissors away.At least I think that's the reason.\nI'm on your side anyway. :)The Java designers decided that operator overloading was more trouble than it was worth. Simple as that.In a language where every object variable is actually a reference, operator overloading gets the additional hazard of being quite illogical - to a C++ programmer at least. Compare the situation with C#'s == operator overloading and Object.Equals and Object.ReferenceEquals (or whatever it's called).I think this may have been a conscious design choice to force developers to create functions whose names clearly communicate their intentions. In C++ developers would overload operators with functionality that would often have no relation to the commonly accepted nature of the given operator, making it nearly impossible to determine what a piece of code does without looking at the definition of the operator.Saying  that operator overloading leads to logical errors of type that operator does not match the operation logic, it's like saying nothing. The same type of error will occur if function name is inappropriate for operation logic - so what's the solution: drop the ability of function usage!? \n This is a comical answer - \"Inappropriate for operation logic\", every parameter name, every class, function or whatever can be logicly inappropriate.\nI think that this option should be available in respectable programing language, and those that think that it's unsafe - hey no bothy says you have to use it. \nLets take the C#. They drooped the pointers but hey - there is 'unsafe code' statement - program as you like on your own risk.Technically, there is operator overloading in every programming language that can deal with different types of numbers, e.g. integer and real numbers. Explanation: The term overloading means that there are simply several implementations for one function. In most programming languages different implementations are provided for the operator +, one for integers, one for reals, this is called operator overloading.Now, many people find it strange that Java has operator overloading for the operator + for adding strings together, and from a mathematical standpoint this would be strange indeed, but seen from a programming language's developer's standpoint, there is nothing wrong with adding builtin operator overloading for the operator + for other classes e.g. String. However, most people agree that once you add builtin overloading for + for String, then it is generally a good idea to provide this functionality for the developer as well.A completely disagree with the fallacy that operator overloading obfuscates code, as this is left for the developer to decide. This is na\u00efve to think, and to be quite honest, it is getting old.+1 for adding operator overloading in Java 8.Some people say that operator overloading in Java would lead to obsfuscation. Have those people ever stopped to look at some Java code doing some basic maths like increasing a financial value by a percentage using BigDecimal ? .... the verbosity of such an exercise becomes its own demonstration of obsfuscation. Ironically, adding operator overloading to Java would allow us to create our own Currency class which would make such mathematical code elegant and simple (less obsfuscated).Assuming Java as the implementation language then a, b, and c would all be references to type Complex with initial values of null. Also assuming that Complex is immutable as the mentioned  and similar immutable , I'd I think you mean the following, as you're assigning the reference to the Complex returned from adding b and c, and not comparing this reference to a.Sometimes it would be nice to have operator overloading, friend classes and multiple inheritance.However I still think it was a good decision. If Java would have had operator overloading then we could never be sure of operator meanings without looking through source code. At present that's not necessary. And I think your example of using methods instead of operator overloading is also quite readable. If you want to make things more clear you could always add a comment above hairy statements."},
{"body": "I need to implement 256 bit AES encryption, but all the examples I have found online use a \"KeyGenerator\" to generate a 256 bit key, but I would like to use my own passkey. How can I create my own key? I have tried padding it out to 256 bits, but then I get an error saying that the key is too long. I do have the unlimited jurisdiction patch installed, so thats not the problem :)Ie. The KeyGenerator looks like this ...I was actually padding the password out to 256 bytes, not bits, which is too long. The following is some code I am using now that I have some more experience with this.The \"TODO\" bits you need to do yourself :-)Share the  (a ) and  (a \u20148 bytes selected by a  makes a good salt\u2014which doesn't need to be kept secret) with the recipient out-of-band. Then to derive a good key from this information:The magic numbers (which could be defined as constants somewhere) 65536 and 256 are the key derivation iteration count and the key size, respectively.The key derivation function is iterated to require significant computational effort, and that prevents attackers from quickly trying many different passwords. The iteration count can be changed depending on the computing resources available. The key size can be reduced to 128 bits, which is still considered \"strong\" encryption, but it doesn't give much of a safety margin if attacks are discovered that weaken AES.Used with a proper block-chaining mode, the same derived key can be used to encrypt many messages. In CBC, a random initialization vector (IV) is generated for each message, yielding different cipher text even if the plain text is identical. CBC may not be the most secure mode available to you (see AEAD below); there are many other modes with different security properties, but they all use a similar random input. In any case, the outputs of each encryption operation are the cipher text  the initialization vector:Store the  and the . On decryption, the  is regenerated in exactly the same way, using using the password with the same salt and iteration parameters. Initialize the cipher with this key  the initialization vector stored with the message:Java 7 included API support for AEAD cipher modes, and the \"SunJCE\" provider included with OpenJDK and Oracle distributions implements these beginning with Java 8. One of these modes is strongly recommended in place of CBC; it will protect the integrity of the data as well as their privacy.A  with the message \"Illegal key size or default parameters\" means that the cryptography strength  limited; the unlimited strength jurisdiction policy files are not in the correct location. In a JDK, they should be placed under  Based on the problem description, it sounds like the policy files are not correctly installed. Systems can easily have multiple Java runtimes; double-check to make sure that the correct location is being used.It's provides a simple abstraction for encryption and seems to match what's required here,A look at the  reveals a structure similar to . As noted in the question, this also requires the  (else you'll encounter ).  It's downloadable for ,  and . And sample output,After reading through erickson's suggestions, and gleaning what I could from a couple other postings and this example , I've attempted to update Doug's code with the recommended changes. Feel free to edit to make it better.Some notes: This uses a 128 bit encryption key - java apparently won't do 256 bit encryption out-of-the-box. Implementing 256 requires installing some extra files into the java install directory. Also, I'm not a crypto person. Take heed.I've implemented the erickson's answer in a really simple class:\n\nIf you get the  you have to install the Java Cryptography Extension (JCE) unlimited strength jurisdiction policy files:Just place the jars in your Generating your own key from a byte array is easy:But creating a 256-bit key isn't enough. If the key generator cannot generate 256-bit keys for you, then the  class probably doesn't support AES 256-bit either. You say you have the unlimited jurisdiction patch installed, so the AES-256 cipher should be supported (but then 256-bit keys should be too, so this might be a configuration problem).A workaround for lack of AES-256 support is to take some freely available implementation of AES-256, and use it as a custom provider. This involves creating your own  subclass and using it with . But this can be an involved process.What I've done in the past is hash the key via something like SHA256, then extract the bytes from the hash into the key byte[].After you have your byte[] you can simply do:Adding to @Wufoo's edits, the following version uses InputStreams rather than files to make working with a variety of files easier. It also stores the IV and Salt in the beginning of the file, making it so only the password needs to be tracked. Since the IV and Salt do not need to be secret, this makes life a little easier.Consider using First make sure you have  files installed before your proceed so that you can use 256-bit AES keys.Then do the following:You can now use the encryptor to encrypt your message. You can also perform streaming encryption if you'd like. It automatically generates and prepends a secure IV for your convenience.If it's a file that you wish to compress take a look at this answer\n for an even simpler approach.Use this class for encryption. It works.}And these are ivBytes and a random key;"},
{"body": "I want to know the difference between the specified error and the exception.What is the reason for getting each of them and any thought process on how to deal with such errors?While working on a project. If we are modifying the existing code to include the new jar file I get to face these exceptions.\nSometimes they will come in client side or server side for a java app distributed through webstart.Possible reasons I have come across:But as of now I am dealing with hit and trial method to get things working.Need more clarity and understanding regarding this.The difference from the Java API Specifications is as follows.For :For :So, it appears that the  occurs when the source was successfully compiled, but at runtime, the required  files were not found. This may be something that can happen in the distribution or production of JAR files, where not all the required  files were included.As for , it appears that it may stem from trying to make reflective calls to classes at runtime, but the classes the program is trying to call is does not exist.The difference between the two is that one is an  and the other is an . With  is an  and it arises from the Java Virtual Machine having problems finding a class it expected to find. A program that was expected to work at compile-time can't run because of  files not being found, or is not the same as was produced or encountered at compile-time. This is a pretty critical error, as the program cannot be initiated by the JVM.On the other hand, the  is an , so it is somewhat expected, and is something that is recoverable. Using reflection is can be error-prone (as there is some expectations that things may not go as expected. There is no compile-time check to see that all the required classes exist, so any problems with finding the desired classes will appear at runtime.A ClassNotFoundException is thrown when the reported class is not found by the ClassLoader. This typically means that the class is missing from the CLASSPATH. It could also mean that the class in question is trying to be loaded from another class which was loaded in a parent classloader and hence the class from the child classloader is not visible. This is sometimes the case when working in more complex environments like an App Server (WebSphere is infamous for such classloader issues).People often tend to confuse  with  however there's an important distinction. For example an exception (an error really since  is a subclass of java.lang.Error) likedoes not mean that the ActiveMQConnectionFactory class is not in the CLASSPATH. Infact its quite the opposite. It means that the class ActiveMQConnectionFactory was found by the ClassLoader however when trying to load the class, it ran into an error reading the class definition. This typically happens when the class in question has static blocks or members which use a Class that's not found by the ClassLoader. So to find the culprit, view the source of the class in question (ActiveMQConnectionFactory in this case) and look for code using static blocks or static members. If you don't have access the the source, then simply decompile it using JAD.On examining the code, say you find a line of code like below, make sure that the class SomeClass in in your CLASSPATH.Tip : To find out which jar a class belongs to, you can use the web site jarFinder . This allows you to specify a class name using wildcards and it searches for the class in its database of jars. jarhoo  allows you to do the same thing but its no longer free to use.If you would like to locate the which jar a class belongs to in a local path, you can use a utility like jarscan (  ). You just specify the class you'd like to locate and the root directory path where you'd like it to start searching for the class in jars and zip files.NoClassDefFoundError is a linkage error basically. It occurs when you try and instantiate an object (statically with \"new\") and it's not found when it was during compilation.ClassNotFoundException is more general and is a runtime exception when you try to use a class that doesn't exist. For example, you have a parameter in a function accepts an interface and someone passes in a class that implements that interface but you don't have access to the class. It also covers case of dynamic class loading, such as using loadClass() or Class.forName().A NoClassDefFoundError (NCDFE) happens when your code runs \"new Y()\" and it can't find the Y class.It may simply be that Y is missing from your class loader like the other comments suggest, but it could be that the Y class isn't signed or has an invalid signature, or that Y is loaded by a different classloader not visible to your code, or even that Y depends on Z which couldn't be loaded for any of the above reasons.If this happens, then the JVM will remember the result of loading X (NCDFE) and it will simply throw a new NCDFE every time you ask for Y without telling you why:The code simply tries to instantiate a new \"b\" class twice, other than that, it doesn't have any bugs, and it doesn't do anything.Compile the code with , Then run a by invoking  -- it should just print out two lines of text, and it should run fine without errors.Then delete the \"a$b.class\" file (or fill it with garbage, or copy a.class over it) to simulate the missing or corrupted class.  Here's what happens:The first invocation results in a ClassNotFoundException (thrown by the class loader when it can't find the class), which must be wrapped in an unchecked NoClassDefFoundError, since the code in question () should just work.The second attempt will of course fail too, but as you can see the wrapped exception is no more, because the ClassLoader seems to remember failed class loaders.  You see only the NCDFE with absolutely no clue as to what really happened.So if you ever see a NCDFE with no root cause, you need to see if you can track back to the very first time the class was loaded to find the cause of the error.From : : occurs when class loader could not find the required class in class path. So, basically you should check your class path and add the class in the classpath. : this is more difficult to debug and find the reason. This is thrown when at compile time the required classes are present, but at run time the classes are changed or removed or class's static initializes threw exceptions. It means the class which is getting loaded is present in classpath, but one of the classes which are required by this class are either removed or failed to load by compiler. So you should see the classes which are dependent on this class.:Now after compiling both the classes, if you delete Test1.class file and run Test class, it will throw: thrown when an application tries to load in a class through its name, but no definition for the class with the specified name could be found.: thrown if the Java Virtual Machine tries to load in the definition of a class and no definition of the class could be found.They're closely related. A  is thrown when Java went looking for a particular class by name and could not successfully load it. A  is thrown when Java went looking for a class that was linked into some existing code, but couldn't find it for one reason or another (e.g., wrong classpath, wrong version of Java, wrong version of a library) and is thoroughly fatal as it indicates that something has gone Badly Wrong.If you've got a C background, a CNFE is like a failure to / and an NCDFE is a problem with the linker; in the second case, the class files concerned should never have been actually compiled in the configuration you're trying to use them.Example #1:If  doesn't exist in any of the classpaths, then It throws .Example #2:If  existed while compiling B, but not found while execution, then It throws .Both are run time exceptions.Difference Between ClassNotFoundException Vs NoClassDefFoundError is thrown when there is attempt to load the class by referencing it via a String. For example the parameter to in Class.forName() is a String, and this raises the potential of invalid binary names being passed to the classloader.The ClassNotFoundException is thrown when a potentially invalid binary name is encountered; for instance, if the class name has the '/' character, you are bound to get a ClassNotFoundException. It is also thrown when the directly referenced class is not available on the classpath.On the other hand,  is thrown In short, a NoClassDefFoundError is usually thrown on new() statements or method invocations that load a previously absent class (as opposed to the string-based loading of classes for ClassNotFoundException), when the classloader is unable to find or load the class definition(s).Eventually, it is upto the ClassLoader implementation to throw an instance of ClassNotFoundException when it is unable to load a class. Most custom classloader implementations perform this since they extend the URLClassLoader. Usually classloaders do not explicitly throw a NoClassDefFoundError on any of the method implementations - this exception is usually thrown from the JVM in the HotSpot compiler, and not by the classloader itself.Given the Class loader sussystem actions:This is an article that helped me a lot to understand the difference: So a  is a root cause of .\nAnd a  is a special case of type loading error, that occurs at  step.Add one possible reason in practise:In practise,  may be thrown , e.g, you submit a timer task and in the timer task it throws , while in most cases, your program only catches . Then the  main loop is ended without any information. A similar Error to NoClassDefFoundError is , when your static initializer or the initializer for a static variable throws an exception. Exceptions occurs during the execution of program. A programmer can handle these exception by try catch block. We have two types of exceptions. Checked exception which throws at compile time. Runtime Exceptions which are thrown at run time, these exception usually happen because of bad programming.  These are not exceptions at all, it is beyond the scope of programmer. These errors are usually thrown by JVM.   I remind myself the following again and again when I need to refresh is a checked exception that occurs when we tell JVM to load a class by its string name using Class.forName() or ClassLoader.findSystemClass() or ClassLoader.loadClass() methods and mentioned class is not found in the classpath.Most of the time, this exception occurs when you try to run an application without updating the classpath with required JAR files. For Example, You may have seen this exception when doing the JDBC code to connect to your database i.e.MySQL but your classpath does not have JAR for it. error occurs when JVM tries to load a particular class that is the part of your code execution (as part of a normal method call or as part of creating an instance using the new keyword) and that class is not present in your classpath but was present at compile time because in order to execute your program you need to compile it and if you are trying use a class which is not present compiler will raise compilation error.Below is the brief descriptionYou can read  for more details."},
{"body": "There is an online file (such as ) I need to grab and save to a directory. I know there are several methods for grabbing and reading online files (URLs) line-by-line, but is there a way to just download and save the file using Java?Give a try to :Using  is  much more efficient than a simple loop that reads from the source channel and writes to this channel. Many operating systems can transfer bytes directly from the source channel into the filesystem cache without actually copying them.Check more about it .: The third parameter in transferFrom is the maximum number of bytes to transfer.   will transfer at most 2^31 bytes,  will allow at most 2^63 bytes (larger than any file in existence). Use apache , just one line code:Simpler nio usage:You'll need to handle exceptions, probably external to this method.Downloading a file requires you to read it, either way you will have to go through the file in some way.  Instead of line by line, you can just read it by bytes from the stream:When using  use the following method to download a file from the Internet and save it to some directory:Documentation .This answer is almost exactly like selected answer but with two enhancements:  it's a method and it closes out the FileOutputStream object:Personally, I've found  to be more than capable of everything I've needed to do with regards to this.   is a great tutorial on using HttpClientThis is another java7 variant based on  with usage of try-with statement:There is an issue with simple usage of:if you need to download and save very large files, or in general if you need automatic retries in case connection is dropped.What I suggest in such cases is Apache HttpClient along with org.apache.commons.io.FileUtils. For example:It's possible to download the file with with Apache's  instead of . This code allows you to download a file in Java according to its URL and save it at the specific destination.In contrast to the single line of code:this code will give you more control over a process and let you specify not only time outs but  and  values, which are critical for many web-sites.There is method $.fetch() in  library.Code example:To summarize (and somehow polish and update) previous answers. The three following methods are practically equivalent. (I added explicit timeouts because I think they are a must, nobody wants a download to freeze forever when the connection is lost.)I don't find significant differences, all seem right to me. They are safe and efficient. (Differences in speed seem hardly relevant - I write 180Mb from local server to a SSD disk in times that fluctuate around 1.2 to 1.5 segs). They don't require external libraries. All work with arbitrary sizes and (to my experience) HTTP redirections.Additionally, all throw  if the resource is not found (error 404, typically), and  if the DNS resolution failed; other IOException correspond to errors during transmission.(Marked as community wiki, feel free to add info or corrections)There are many elegant and efficient answers here. But the conciseness can make us lose some useful information. In particular, one , and one might want to treat differently some kind of network-related errors - for example, to decide if we should retry the download.Here's a method that does not throw Exceptions for network errors (only for truly exceptional problems, as malformed url or problems writing to the file)Give it a try. It works for me perfectly."},
{"body": "Which of the following is better practice in Java 8?Java 8:Java 7:I have lots of for loops that could be \"simplified\" with lambdas, but is there really any advantage of using them including performance and readability?I'll also extend this question to longer methods - I know that you cant return or break the parent function from a lambda and this should be mentioned to if they are compared, but is there anything else to be considered?The advantage comes into account when the operations can be executed in parallel. (See  - the section about internal and external iteration)\nfor my answer I assumed joins implementing the  interface. If joins implements only the  interface this is no longer true. The better practice is to use . Besides violating the  principle, the new-fangled  has at least the following deficiencies:As you can see, I'm not a big fan of the forEach() except in cases when it makes sense.Particularly offensive to me is the fact that  does not implement  (despite actually having method ) and cannot be used in a for-each, only with a forEach(). I recommend casting Streams into Iterables with . A better alternative is to use  which fixes a number of Stream API problems, including implementing .That said,  is useful for the following:Articles I used for reference: Looks like some of the original proposals for lambdas (such as ) solved some of the issues I mentioned (while adding their own complications, of course).When reading this question one can get the impression, that  in combination with lambda expressions is a shortcut/replacement for writing a traditional for-each loop. This is simply not true. This code from the OP:is  intended as a shortcut for writingand should certainly not be used in this way. Instead it is intended as a shortcut (although it is  exactly the same) for writingAnd it is as a replacement for the following Java 7 code:Replacing the body of a loop with a functional interface, as in the examples above, makes your code more explicit: You are saying that (1) the body of the loop does not affect the surrounding code and control flow, and (2) the body of the loop may be replaced with a different implementation of the function, without affecting the surrounding code. Not being able to access non final variables of the outer scope is not a deficit of functions/lambdas, it is a  that distinguishes the semantics of  from the semantics of a traditional for-each loop. Once one gets used to the syntax of , it makes the code more readable, because you immediately get this additional information about the code.Traditional for-each loops will certainly stay  (to avoid the overused term \"\") in Java. But this doesn't mean, that  should be considered bad practice or bad style. It is always good practice, to use the right tool for doing the job, and this includes mixing traditional for-each loops with , where it makes sense.Since the downsides of  have already been discussed in this thread, here are some reasons, why you might probably want to use : can be implemented to be faster than for-each loop, because the iterable knows the best way to iterate its elements, as opposed to the standard iterator way. So the difference is loop internally or loop externally. For example  may be simply implemented as as opposed to the for-each loop which requires a lot of scaffolding However, we also need to account for two overhead costs by using , one is making the lambda object, the other is invoking the lambda method. They are probably not significant.see also  for comparing internal/external iterations for different use cases.:  was the fastest.I felt I should add my results from benchmarking iteration.\nI took a very simple approach (no benchmarking frameworks) and benchmarked 5 different methods:The list in this class shall be iterated over and have some  applied to all it's members, each time via a different method.\nin the Main class I run the tested method three times to warm up the JVM. I then run the test method 1000 times summing the time it takes for each iteration method (using ). After that's done i divide that sum by 1000 and that's the result, average time.\nexample:I ran this on a i5 4 core CPU, with java version 1.8.0_05execution time: 4.21 msexecution time: 5.95 msexecution time: 3.11 msexecution time: 2.79 msexecution time: 3.6 msOne of most upleasing functional 's limitations is lack of checked exceptions support.One  is to replace terminal  with plain old foreach loop:Here is list of most popular questions with other workarounds on checked exception handling within lambdas and streams:I feel that I need to extend my comment a bit...That's probably the most notable aspect. FP became popular due to what you can get avoiding side-effects. I won't delve deep into what pros\\cons you can get from this, since this is not related to the question.However, I will say that the iteration using Iterable.forEach is inspired by FP and rather result of bringing more FP to Java (ironically, I'd say that there is no much use for forEach in pure FP, since it does nothing except introducing side-effects).In the end I would say that it is rather a matter of taste\\style\\paradigm you are currently writing in.From performance point of view there is no promised notable benefits from using Iterable.forEach over foreach(...).According to official  :... i.e. docs pretty much clear that there will be no implicit parallelism. Adding one would be LSP violation.Now, there are \"parallell collections\" that are promised in Java 8, but to work with those you need to me more explicit and put some extra care to use them (see mschenk74's answer for example).BTW: in this case  will be used, and it doesn't guarantee that actual work will be done in parallell (depends on underlying collection). might be not that obvious and a little stretched at a glance but there is another facet of style and readability perspective.First of all - plain old forloops are plain and old. Everybody already knows them.Second, and more important - you probably want to use Iterable.forEach only with one-liner lambdas. If \"body\" gets heavier - they tend to be not-that readable.\nYou have 2 options from here - use inner classes (yuck) or use plain old forloop.\nPeople often gets annoyed when they see the same things (iteratins over collections) being done various vays/styles in the same codebase, and this seems to be the case.Again, this might or might not be an issue. Depends on people working on code."},
{"body": "How do I properly set the default character encoding used by the JVM (1.5.x) programmatically?I have read that  used to be the way to go for older JVMs... I don't have that luxury for reasons I wont get into.I have tried:And the property gets set, but it doesn't seem to cause the final getBytes call below to use UTF8:Unfortunately, the  property has to be specified as the JVM starts up; by the time your main method is entered, the character encoding used by  and the default constructors of  and  has been permanently cached.As  in a special case like this, the environment variable   be used to specify this property, but it's normally done like this: will reflect changes to the  property, but most of the code in the core Java libraries that need to determine the default character encoding do not use this mechanism.When you are encoding or decoding, you can query the  property or  to find the current default encoding, and use the appropriate method or constructor overload to specify it.From the  documentation\u2026By setting the (Windows) environment variable  to , the (Java)  property will be set automatically every time a JVM is started. You will know that the parameter has been picked up because the following message will be posted to :I have a hacky way that definitely works!!This way you are going to trick JVM which would think that charset is not set and make it to set it again to UTF-8, on runtime!I think a better approach than setting the platform's default character set, especially as you seem to have restrictions on affecting the application deployment, let alone the platform, is to call the much safer . That way your application is not dependent on things beyond its control.I personally feel that  should be deprecated, as it has caused serious problems in a number of cases I have seen, where the developer did not account for the default charset possibly changing.I can't answer your original question but I would like to offer you some advice -- don't depend on the JVM's default encoding.  It's always best to explicitly specify the desired encoding (i.e. \"UTF-8\") in your code.  That way, you know it will work even across different systems and JVM configurations.Try this : We were having the same issues.  We methodically tried several suggestions from this article (and others) to no avail.  We also tried adding the -Dfile.encoding=UTF8 and nothing seemed to be working.  For people that are having this issue, the following article finally helped us track down describes how the locale setting can break unicode/UTF-8 in Java/TomcatSetting the locale correctly in the ~/.bashrc file worked for us.Not clear on what you do and don't have control over at this point. If you can interpose a different OutputStream class on the destination file, you could use a subtype of OutputStream which converts Strings to bytes under a charset you define, say UTF-8 by default. If modified UTF-8 is suffcient for your needs, you can use :If this approach is not feasible, it may help if you clarify here exactly what you can and can't control in terms of data flow and execution environment (though I know that's sometimes easier said than determined). Good luck.I have tried a lot of things, but the sample code here works perfect.\nThe crux of the code is:We set there two system properties together and it makes the system take everything into utf8"},
{"body": "I'm trying to use a constant instead of a string literal in this piece of code: appears in the code rather often, and would be much better to refer to some  variable instead. Do you know where I can find such a variable in JDK?BTW, on a second thought, such constants are bad design: In Java 1.7+,  defines constants for  including . Now I use  constant from .The  library (which I'd highly recommend anyway, if you're doing work in Java) has a  class with static fields like , , etc.Since Java 7 you should just use  instead for comparable constants.Note that these constants aren't strings, they're actual  instances. All standard APIs that take a charset name also have an overload that take a  object which you should use instead.In case this page comes up in someones web search, as of Java 1.7 you can now use  to get access to constant definitions of standard charsets.There are none (at least in the standard Java library). Character sets vary from platform to platform so there isn't a standard list of them in Java.There are some 3rd party libraries which contain these constants though. One of these is Guava (Google core libraries): You can use  API or  property.But if you want your own constant, you'll need to define it yourself.This constant is available (among others as: , , etc.) in the class  as well.If you are using  for Java/Android you can use the following constant:"},
{"body": "I want to have a Class object, but I want to force whatever class it represents to extend class A and implement interface B.I can do:Or:but I can't do both.  Is there a way to do this?Actually, you  do what you want.  If you want to provide multiple interfaces or a class plus interfaces, you have to have your wildcard look something like this:See the  at sun.com, specifically the  section, at the bottom of the page.  You can actually list more than one interface if you wish, using  for each one that you need.This can get arbitrarily complicated.  To demonstrate, see the JavaDoc declaration of , which (wrapped onto two lines) is:why so complicated?  As said in the Java Generics FAQ: .It looks like this doesn't work for variable declaration, but it does work when putting a generic boundary on a class.  Thus, to do what you want, you may have to jump through a few hoops.  But you can do it.  You can do something like this, putting a generic boundary on your class and then:to get  that has the restriction that you want.  For more information and examples, check out page 3 of .  Note, in , the class name must come first, and interfaces follow.  And of course you can only list a single class.You can't do it with \"anonymous\" type parameters (ie, wildcards that use ), but you can do it with \"named\" type parameters. Simply declare the type parameter at method or class level."},
{"body": "I am getting the following error when trying to get a JSON request and process it:Here is the JSON I am trying to send:In Controller, I have the following method signature:AllApplesDO is a wrapper of ApplesDO :ApplesDO:I think that Jackson is unable to convert JSON into Java objects for subclasses. Please help with the configuration parameters for Jackson to convert JSON into Java Objects. I am using Spring Framework.EDIT: Included the major bug that is causing this problem in the above sample class - Please look accepted answer for solution.So, finally I realized what the problem is. It is not a Jackson configuration issue as I doubted.Actually the problem was in  Class:There was a custom constructor defined for the class making it the default constructor. Introducing a dummy constructor has made the error to go away:This happens for these reasons:I would like to add another solution to this that does not require a dummy constructor. Since dummy constructors are a bit messy and subsequently confusing. We can provide a safe constructor and by annotating the constructor arguments we allow jackson to determine the mapping between constructor parameter and field.so the following will also work. Note the string inside the annotation must match the field name.When I ran into this problem, it was a result of trying to use an inner class to serve as the DO. Construction of the inner class (silently) required an instance of the enclosing class -- which wasn't available to Jackson.In this case, moving the inner class to its own .java file fixed the problem.Can you please test this structure. If I remember correct you can use it this way:Second, please add default constructor to each class it also might help.: Add a default constructor for each class you used as a mapping class. You missed this and issue arise!\nSimply add default constructor and it should work.If you start annotating constructor, you must annotate all fields.Notice, my Staff.name field is mapped to \"ANOTHER_NAME\" in JSON string.Failing custom jackson Serializers/Deserializers could also be the problem. Though it's not your case, it's worth mentioning.I faced the same exception and that was the case.You must realize what options Jackson has available for deserialization. In Java, method argument names are not present in compiled code. That's why Jackson can't generally use constructors to create a well defined object with everything already set.So, if there is an empty constructor and there are also setters, it uses the empty constructor and setters. If there are no setters, some dark magic (reflections) is used to do it.If you want to use constructor with Jackson, you must use the annotations as mentioned by @PiersyP in his answer. You can also use builder pattern. If you encounter some exceptions, good luck. Error handling in Jackson sucks big time, it's hard to understand that gibberish in error messages.You have to create dummy empty constructor in our model class.So while mapping json, it set by setter method."},
{"body": "Just to be clear, I'm not looking for the MIME type.Let's say I have the following input: I'd like a way to break this input up, specifically into  for the extension.  Is there any built in way to do this in Java?  I would like to avoid writing my own parser.In this case, use  from Here is an example of how to use it (you may specify either full path or just file name):Do you really need a \"parser\" for this?Assuming that you're dealing with simple Windows-like file names, not something like .Btw, for the case that a directory may have a '.', but the filename itself doesn't (like ), you can doIf you use  library, you can resort to  utility class. It has a specific method, . For instance:In addition you may also obtain the filename with a similar function, :If on Android, you can use this:In order to take into account file names without characters  the dot, you have to use that slight variation of the accepted answer:My dirty and may tiniest using :Note that first  is greedy so it will grab most possible characters as far as it can and then just last dot and file extension will be left.If you plan to use Apache commons-io,and just want to check the file's extension and then do some operation,you can use ,here is a snippet:How about (using Java 1.5 RegEx):How about JFileChooser? It is not straightforward as you will need to parse its final output...which is a MIME type...OK...I forget that you don't want to know its MIME type.Interesting code in the following link:\nRelated question:\nHere's a method that handles  properly, even in a path with dots in directory names: is created to make finding  quicker since it won't have to search the whole string if there are some slashes in it.The  inside the original  is reused, adding no garbage there, and .Here I made a small method (however not that secure and doesnt check for many errors), but if it is only you that is programming a general java-program, this is more than enough to find the filetype. This is not working for complex filetypes, but those are normally not used as much. This is a tested methodAnd test case:extension should have \".txt\" in it when run.Getting File Extension from File NameHere's the version with Optional as a return value (cause you can't be sure the file has an extension)... also sanity checks... How about  version:or with null extension supported:result for *nix:\nfor windows, parsePath(\"c:\\windows\\readme.txt\"):\nJust a regular-expression based alternative. Not that fast, not that good. This particular question gives me a lot trouble then i found a very simple solution for this problem which i'm posting here.That's it.You can use the Java7 feature from java.io packageRefer the below code snippetJava has a built-in way of dealing with this, in the , that may work for your needs:Note that this static method uses the specifications  to retrieve \"content type,\" which can vary.let 'name' be the name of the file with extension file."},
{"body": "I want to convert a  object to a  in Java.The format is  In Java, Convert a Date to a String using a format string:From Commons-lang  is full of goodies (if you have commons-lang in your classpath)The modern way is with the java.time classes that now supplant the troublesome old legacy date-time classes.First convert your  to an . The  class represents a moment on the timeline in  with a resolution of  (up to nine (9) digits of a decimal fraction).Conversions to/from java.time are performed by new methods added to the old classes.Both your  and  are in . If you want to see the date and time as UTC, so be it. Call  to generate a String in standard  format.For other formats, you need to transform your  into the more flexible .To get a String in your desired format, specify a . You could specify a custom format. But I would use one of the predefined formatters (), and replace the  in its output with a SPACE.By the way I do not recommend this kind of format where you purposely lose the  or time zone information. Creates ambiguity as to the meaning of that string\u2019s date-time value.Also beware of data loss, as any fractional second is being ignored (effectively truncated) in your String\u2019s representation of the date-time value.To see that same moment through the lens of some particular region\u2019s , apply a  to get a .To generate a formatted String, do the same as above but replace  with .If executing this code a very large number of times, you may want to be a bit more efficient and avoid the call to . Dropping that call also makes your code shorter. If so desired, specify your own formatting pattern in your own  object. Cache this instance as a constant or member for reuse.Apply that formatter by passing the instance.The  framework is built into Java 8 and later. These classes supplant the troublesome old date-time classes such as , , & .The  project, now in , advises migration to java.time.To learn more, see the . And search Stack Overflow for many examples and explanations.Much of the java.time functionality is back-ported to Java 6 & 7 in  and further adapted to  in  (see ).The  project extends java.time with additional classes. This project is a proving ground for possible future additions to java.time.Why don't you use Joda (org.joda.time.DateTime)?\nIt's basically a one-liner.Altenative one-liners in plain-old java:This uses  instead of  which is not thread-safe, btw.Slightly more repetitive but needs just one statement. \nThis may be handy in some cases.It looks like you are looking for .Format: yyyy-MM-dd kk:mm:ssThe easiest way to use it is as following:where \"yyyy-MM-dd'T'HH:mm:ss\" is the format of the reading dateoutput: Sun Apr 14 16:11:48 EEST 2013Notes: HH vs hh\n- HH refers to 24h time format\n- hh refers to 12h time formatIf you only need the time from the date, you can just use the feature of String.This will automatically cut the time part of the String and save it inside the .Here are examples of using new  to format  :It is nice about  that it can be efficiently cached as it is thread-safe (unlike )..Credits:Let's try thisOr a utility functionFrom "},
{"body": "How do you kill a thread in Java?See this .  It goes into detail about why this was a bad method and what should be done to safely stop threads in general.  The way they recomend is to use a shared variable as a flag which asks the background thread to stop.  This variable can then be set by a different object requesting the thread terminate.  Generally you don't..You ask it to interrupt whatever it is doing using A good explanation of why is in the javadoc In Java threads are not killed, but the stopping of a thread is done in a . The thread is asked to terminate and the thread can then shutdown gracefully.Often a  field is used which the thread periodically checks and terminates when it is set to the corresponding value.I  use a  to check whether the thread should . If you use  as a field modifier, this will work reliable, but if your code becomes more complex, for instead uses other blocking methods inside the  loop, it might happen, that your code will  at all or at least  as you might want.Every thread has already a boolean flag  and you should make use of it. It can be implemented like this:Source code taken from . Since the  method is public you can let another thread invoke this method as you wanted.There is also a poorly named static method  which clears the interrupted status of the current thread.One way is by setting a class variable and using it as a sentinel.Set an external class variable, i.e. flag = true in the above example. Set it to false to 'kill' the thread.There is a way how you can do it. But if you had to use it, either you are a bad programmer or you are using a code written by bad programmers. So, you should think about stopping being a bad programmer or stopping using this bad code.\nThis solution is only for situations when THERE IS NO OTHER WAY.The question is rather vague. If you meant \u201chow do I write a program so that a thread stops running when I want it to\u201d, then various other responses should be helpful. But if you meant \u201cI have an emergency with a server I cannot restart right now and I just need a particular thread to die, come what may\u201d, then you need an intervention tool to match monitoring tools like .For this purpose I created . See its instructions for usage.I want to add several observations, based on the comments that have accumulated.There is of course the case where you are running some kind of not-completely-trusted code. (I personally have this by allowing uploaded scripts to execute in my Java environment. Yes, there are security alarm bell ringing everywhere, but it's part of the application.) In this unfortunate instance you first of all are merely being hopeful by asking script writers to respect some kind of boolean run/don't-run signal. Your only decent fail safe is to call the stop method on the thread if, say, it runs longer than some timeout.But, this is just \"decent\", and not absolute, because the code could catch the ThreadDeath error (or whatever exception you explicitly throw), and not rethrow it like a gentlemanly thread is supposed to do. So, the bottom line is AFAIA there is no absolute fail safe. I'd vote for .As for instance you have a long lasting operation (like a network request).\nSupposedly you are waiting for a response, but it can take time and the user navigated to other UI.\nThis waiting thread is now a) useless b) potential problem because when he will get result, it's completely useless and he will trigger callbacks that can lead to number of errors.All of that and he can do response processing that could be CPU intense. And you, as a developer, cannot even stop it, because you can't throw  lines in all code.So the inability to forcefully stop a thread it weird.There is no way to gracefully kill a thread.You can try to interrupt the thread, one commons strategy is to use a poison pill to message the thread to stop itself}Attempts of abrupt thread termination are well-known bad programming practice and evidence of poor application design. All threads in the multithreaded application explicitly and implicitly share the same process state and forced to cooperate with each other to keep it consistent, otherwise your application will be prone to the bugs which will be really hard to diagnose. So, it is a responsibility of developer to provide an assurance of such consistency via careful and clear application design.There are two main right solutions for the controlled threads terminations:Good and detailed explanation of the issues related to the abrupt threads termination as well as examples of wrong and right solutions for the controlled threads termination can be found here:Here are a couple of good reads on the subject:"},
{"body": "I've been programming in C# and Java recently and I am curious where the best place is to initialize my class fields.Should I do it at declaration?:or in a constructor?:I'm really curious what some of you veterans think is the best practice. I want to be consistent and stick to one approach.My rules:In C# it doesn't matter. The two code samples you give are utterly equivalent. In the first example the C# compiler (or is it the CLR?) will construct an empty constructor and initialise the variables as if they were in the constructor.\nIf there is already a constructor then any initialisation \"above\" will be moved into the top of it.In terms of best practice the former is less error prone than the latter as someone could easily add another constructor and forget to chain it.The semantics of C# differs slightly from Java here. In C# assignment in declaration is performed before calling the superclass constructor. In Java it is done immediately after which allows 'this' to be used (particularly useful for anonymous inner classes), and means that the semantics of the two forms really do match.If you can, make the fields final.I think there is one caveat. I once committed such an error: Inside of a derived class, I tried to \"initialize at declaration\" the fields inherited from an abstract base class. The result was that there existed two sets of fields, one is \"base\" and another is the newly declared ones, and it cost me quite some time to debug.The lesson: to initialize  fields, you'd do it inside of the constructor.Assuming the type in your example, definitely prefer to initialize fields in the constructor. The exceptional cases are:I always think of the field listing at the top of a class as the table of contents (what is contained herein, not how it is used), and the constructor as the introduction. Methods of course are chapters.What if I told you, it depends?I in general initialize everything and do it in a consistent way. Yes it's overly explicit but it's also a little easier to maintain. If we are worried about performance, well then I initialize only what has to be done and place it in the areas it gives the most bang for the buck.In a real time system, I question if I even need the variable or constant at all.And in C++ I often do next to no initialization in either place and move it into an Init() function. Why? Well, in C++ if you're initializing something that can throw an exception during object construction you open yourself to memory leaks.In Java, an initializer with the declaration means the field is always initialized the same way, regardless of which constructor is used (if you have more than one) or the parameters of your constructors (if they have arguments), although a constructor might subsequently change the value (if it is not final). So using an initializer with a declaration suggests to a reader that the initialized value is the value that the field has , regardless of which constructor is used and regardless of the parameters passed to any constructor. Therefore use an initializer with the declaration only if, and always if, the value for all constructed objects is the same.There are many and various situations.The situation is clear. I just need to prepare my list and prevent an exception from being thrown when someone adds an item to the list.I exactly know what values I want to have by default or I need to use some other logic.orSometimes I expect an empty list by default with a possibility of adding values through another constructor.There is a slight performance benefit to setting the value in the declaration.  If you set it in the constructor it is actually being set twice (first to the default value, then reset in the ctor).  I normally try the constructor to do nothing but getting the dependencies and initializing the related instance members with them. This will make you life easier if you want to unit test your classes.If the value you are going to assign to an instance variable does not get influenced by any of the parameters you are going to pass to you constructor then assign it at declaration time.The design of C# suggests that inline initialization is preferred, or it wouldn't be in the language. Any time you can avoid a cross-reference between different places in the code, you're generally better off.There is also the matter of consistency with static field initialization, which needs to be inline for best performance. The Framework Design Guidelines for  say this:\"Consider\" in this context means to do so unless there's a good reason not to. In the case of static initializer fields, a good reason would be if initialization is too complex to be coded inline.Being consistent is important, but this is the question to ask yourself:\n\"Do I have a constructor for anything else?\"Typically, I am creating models for data transfers that the class itself does nothing except work as housing for variables.In these scenarios, I usually don't have any methods or constructors. It would feel silly to me to create a constructor for the exclusive purpose of initializing my lists, especially since I can initialize them in-line with the declaration.So as many others have said, it depends on your usage. Keep it simple, and don't make anything extra that you don't have to."},
{"body": "I need to figure out how to get or make a build number for my Android application. I need the build number to display in the UI. Do I have to do something with ?Use:And you can get the version code by using thisIf you're using the Gradle plugin/Android Studio, , version code and version name are available statically in . , and not another :No Context object needed!Also make sure to specify them in your  file instead of the .Slightly shorter version if you just want the version name. Yep, it's that easy now.I kept getting an empty string for  because I wasn't setting the  in my Grade build file (I migrated from ANT to Gradle). So, here are instructions for ensuring you're setting your  via Gradle.And since you've set the  and  in the  file now, you can also remove them from your  file, if they are there.There are two parts you need:\nandroid:versionCode \nandroid:versionNameversionCode is a number, and every version of the app you submit to the Market needs to have a higher number then the last.VersionName is a string, and can be anything you want it to be.  This is where you define your app as \"1.0\" or \"2.5\" or \"2 Alpha EXTREME!\" or whatever.Example:\nTo access it in code, do something like:Here is a , based on the solution of scottyab (edited by Xavi). It shows how to get the context first, if it's not provided by your method. Furthermore it uses multiple lines instead of calling multiple methods per line. This makes it easier when you have to debug your application.Now that you received the version name in the String , you can set it to a TextView or whatever you like.. If you're using PhoneGap, then create a custom PhoneGap plugin:Create a new class in your app's package:In the plugins.xml, add the following line:In your , add the following code:Then, you can get the versionName attribute by doing:Derived from  and .A very simple way is :Always do it with  block:I have SOLVE this by using Preference class. Here is the method for getting the version code:If you want to use it on xml then add below line on your gradle file:And then use it on your xml like this:For xamarin users, use this code to get version name and code1) VersionName2) VersionCodeSomeone who does\u2019t need  BuildConfig info for application's UI however wants to use these info for setting a CI job configuration or others, like me.There is a automatically generated file, BuildConfig.java, under your project directory as long as you build your project successfully.{WORKSPACE}/build/generated/source/buildConfig/{debug|release}/{PACKAGE}/BuildConfig.javaSplit information you need by python script or other tools. Here\u2019s an example:Please excuse my limited English ability, but hope this helps.First:and then use this:try this one: This code was mentioned above in pieces but here it is again all included. You need a try/catch block because it may throw a \"NameNotFoundException\".I hope this simplifies things for someone down the road. :)"},
{"body": "What is the best connection pooling library available for Java/JDBC?I'm considering the 2 main candidates (free / open-source): I've read a lot about them in blogs and other forums but could not reach a decision.Are there any relevant alternatives to these two?DBCP is out of date and not production grade. Some time back we conducted an in-house analysis of the two, creating a test fixture which generated load and concurrency against the two to assess their suitability under real life conditions. DBCP consistently generated exceptions into our test application and struggled to reach levels of performance which C3P0 was more than capable of handling without any exceptions. C3P0 also robustly handled DB disconnects and transparent reconnects on resume whereas DBCP never recovered connections if the link was taken out from beneath it. Worse still DBCP was returning Connection objects to the application for which the underlying transport had broken. Since then we have used C3P0 in 4 major heavy-load consumer web apps and have never looked back. It turns out that after many years of sitting on a shelf, the Apache Commons folk have taken  and it is now, once again, an actively developed project. Thus my original post may be out of date. That being said, I haven't yet experienced this new upgraded library's performance, nor heard of it being de-facto in any recent app framework, yet.I invite you to try out  -- it's free, open source, and faster than the available alternatives (see benchmark section).Disclaimer: I'm the author so you could say I'm biased :-)WallaceUPDATE: As of March 2010, still around 35% faster than the new rewritten Apache DBCP (\"tomcat jdbc\") pool. See dynamic benchmark link in benchmark section.Update #2: (Dec '13) After 4 years at the top, there's now a much faster competitor : Update #3: (Sep '14) Please consider BoneCP to be deprecated at this point, recommend switching to HikariCP.Update #4: (April '15) -- I no longer own the domain jolbox.com, but the new owner has kept the old content so beware.I was having trouble with DBCP when the connections times out so I trialled c3p0.  I was going to release this to production but then started performance testing.  I found that c3p0 performed terribly.  I couldn't configure it to perform well at all.  I found it twice as slow as DBCP.I then tried the .This was twice as fast as c3p0 and fixed other issues I was having with DBCP.  I spent a lot of time investigating and testing the 3 pools.  My advice if you are deploying to Tomcat is to use the new Tomcat JDBC pool.For the auto-reconnect issue with DBCP, has any tried using the following 2 configuration parameters?Have been using DBCP for a couple of years now in production. It is stable, survives DB server reboot. Just configure it properly. It only requires a handful of parameters to be specified so don't be lazy. Here is a snippet from our system production code which lists parameters that we explicitly set to make it work:Another alternative, Proxool, is mentioned in .You might be able to find out why Hibernate bundles c3p0 for its default connection pool implementation?Unfortunately they are all out of date. DBCP has been updated a bit recently, the other two are 2-3 years old, with many outstanding bugs.Here are some articles that show that DBCP has significantly higher performance than C3P0 or Proxool. Also in my own experience c3p0 does have some nice features, like prepared statement pooling and is more configurable than DBCP, but DBCP is plainly faster in any environment I have used it in.Difference between dbcp and c3p0? Absolutely nothing! (A Sakai developers blog)\nSee also the like to the JavaTech article \"Connection Pool Showdown\" in the comments on the blog post.Dbcp is production ready if configured properly.It is for example used on a commerce Website of 350000 visitors/ day and with pools of 200 connections.It handles very well timeouts provided you configure it correctly.Version 2 is on progress and it has a background which makes it reliable since Many\nProduction problems have been tackled.We use it for our batch server solution and it has been running hundreds of batches That work on millions of lines in database.Performance tests run by tomcat jdbc pool show it has better performance than cp30.Another alternative is .Here is the comparison Just got done wasting a day and a half with DBCP. Even though I'm using the latest DBCP release, I ran into exactly the same problems as  did. I would not recommend DBCP at all, especially it's knack of throwing connections out of the pool when the DB goes away, its inability to reconnect when the DB comes back and its inability to dynamically add connection objects back into the pool (it hangs forever on a post JDBCconnect I/O socket read)I'm switching over to C3P0 now. I've used that in previous projects and it worked and performed like a charm.c3p0 is good when we are using mutithreading projects. In our projects we used simultaneously multiple thread executions by using DBCP, then we got connection timeout if we used more thread executions. So we went with c3p0 configuration.A good alternative which is easy to use is . \"A Java-based database connection pooling utility, supporting time-based expiry, statement caching, connection validation, and easy configuration using a pool manager.\" "},
{"body": "What is the difference between:and The annotation  indicates that this entity is the  of the relationship (that is: the corresponding table has a column with a foreign key to the referenced table), whereas the attribute  indicates that the entity in this side is the inverse of the relationship, and the owner resides in the \"other\" entity. This also means that you can access the other table from the class which you've annotated with \"mappedBy\" (fully bidirectional relationship).In particular, for the code in the question the correct annotations would look like this: The question was about using  on the  side (rare case). And the point here is in  (column name) along with .According to :Since  (almost) always the  of a bidirectional relationship in the JPA spec, the one to many association is annotated by @OneToMany(mappedBy=...)Troop has a bidirectional one to many relationship with Soldier through the troop property. You don't have to (must not) define any physical mapping in the mappedBy side.To map a bidirectional one to many, with the , you have to remove the mappedBy element and set the many to one @JoinColumn as insertable and updatable to false. This solution is not optimized and will produce some additional UPDATE statements.The annotation  ideally should always be used in the Parent side (Company class) of the bi directional relationship, in this case it should be in Company class pointing to the member variable 'company' of the Child class (Branch class) The annotation  is used to specify a mapped column for joining an entity association, this annotation can be used in any class (Parent or Child) but it should ideally be used only in one side (either in parent class or in Child class not in both) here in this case i used it in the Child side (Branch class) of the bi directional relationship indicating the foreign key in the Branch class.below is the working example :I'd just like to add that  does not always have to be related to the  as  answer suggests.  You can combine  with  even if the parent table has no table data pointing to the child table.It seems to only be available in  though.  It's useful for situations where you want the child class to just contain the ID of the parent, not a full on reference."},
{"body": "I read  and thought that would easily be solved (not that it isn't solvable without) if one could write: I'm not sure if it is useful in many cases, but I wonder  it isn't and if something like this exists in other languages.What do you guys think?\nTo clarify: yes I know, that's impossible in Java and I don't really miss it. This is nothing I expected to work and was surprised getting a compiler error. I just had the idea and like to discuss it.It violates encapsulation. You shouldn't be able to bypass the parent class's behaviour. It makes sense to sometimes be able to bypass your  class's behaviour (particularly from within the same method) but not your parent's. For example, suppose we have a base \"collection of items\", a subclass representing \"a collection of red items\" and a subclass of that representing \"a collection of big red items\". It makes sense to have:That's fine - RedItems can always be confident that the items it contains are all red. Now suppose we  able to call super.super.add():Now we could add whatever we like, and the invariant in  is broken.Does that make sense?I think Jon Skeet has the correct answer. I'd just like to add that you  access shadowed variables from superclasses of superclasses by casting :which produces the output:(example from the )However, this  because method calls are determined based on the runtime type of the object.I think the following code allow to use super.super...super.method() in most case.\n(even if it's uggly to do that)Usage :I don't have enough reputation to comment so I will add this to the other answers.Jon Skeet answers excellently, with a beautiful example. Matt B has a point: not all superclasses have supers. Your code would break if you called a super of a super that had no super. Object oriented programming (which Java is) is all about objects, not functions. If you want task oriented programming, choose C++ or something else. If your object doesn't fit in it's super class, then you need to add it to the \"grandparent class\", create a new class, or find another super it does fit into. Personally, I have found this limitation to be one of Java's greatest strengths. Code is somewhat rigid compared to other languages I've used, but I always know what to expect. This helps with the \"simple and familiar\" goal of Java. In my mind, calling super.super is not simple or familiar. Perhaps the developers felt the same? In addition to the very good points that others have made, I think there's another reason: what if the superclass does not have a superclass?Since every class naturally extends (at least) ,  will always refer to a method in the superclass. But what if your class only extends  - what would  refer to then? How should that behavior be handled - a compiler error, a NullPointer, etc?I think the primary reason why this is not allowed is that it violates encapsulation, but this might be a small reason too.There's some good reasons to do this. You might have a subclass which has a method which is implemented incorrectly, but the parent method is implemented correctly. Because it belongs to a third party library, you might be unable/unwilling to change the source. In this case, you want to create a subclass but override one method to call the super.super method.As shown by some other posters, it is possible to do this through reflection, but it should be possible to do something like(SuperSuperClass this).theMethod();I'm dealing with this problem right now - the quick fix is to copy and paste the superclass method into the subsubclass method :)I think if you overwrite a method and want to all the super-class version of it (like, say for ), then you virtually always want to call the direct superclass version first, which one will call its superclass version in turn if it wants. I think it only makes rarely sense (if at all. i can't think of a case where it does) to call some arbitrary superclass' version of a method. I don't know if that is possible at all in Java. It can be done in C++:At a guess, because it's not used that often.  The only reason I could see using it is if your direct parent has overridden some functionality and you're trying to restore it back to the original.Which seems to me to be against OO principles, since the class's direct parent should be more closely related to your class than the grandparent is.I would put the super.super method body in another method, if possibleOr if you cannot change the super-super class, you can try this:In both cases, theresults to \"I am super super\"Here's a little something I'm using every time I need to call a method from a grandparent or grand.grandparent or grand.grand.grand....you get the idea.Say you have class A which instantiates class B which instantiates class C like so A->B->C1.create a private static A variable in A class;\n2.inside the constructor of A, set the instance variable to this;\n3. create a public static method in A class, which returns the instance of A class;\n4. use this method from any children necessary in order to access any public method from A;}After you can go to child class C or whatever and use it like so:It would seem to be possible to at least get the class of the superclass's superclass, though not necessarily the instance of it, using reflection; if this might be useful, please consider the Javadoc at run:\nA\nBUILD SUCCESSFUL (total time: 0 seconds)I have had situations like these when the architecture is to build common functionality in a common CustomBaseClass which implements on behalf of several derived classes.\nHowever, we need to circumvent common logic for specific method for a specific derived class. In such cases, we must use a super.super.methodX implementation.We achieve this by introducing a boolean member in the CustomBaseClass, which can be used to selectively defer custom implementation and yield to default framework implementation where desirable.However, with good architecture principles followed in framework as well as app, we could avoid such situations easily, by using hasA approach, instead of isA approach. But at all times it is not very practical to expect well designed architecture in place, and hence the need to get away from solid design principles and introduce hacks like this.\nJust my 2 cents...@Jon Skeet Nice explanation. \nIMO if some one wants to call super.super method then one must be want to ignore the behavior of immediate parent, but want to access the grand parent behavior.\nThis can be achieved through instance Of. As below codeHere is driver class,Output of this will be Class B printClass behavior will be ignored in this case.\nI am not sure about is this a ideal or good practice to achieve super.super, but still it is working.Output: Printed in the GrandDadIf you think you are going to be needing the superclass, you could reference it in a variable for that class. For example:Should print out:IMO, it's a clean way to achieve  behavior in Java.Output:\nCalling of super.super.method() make sense when you can't change code of base class. This often happens when you are extending an existing library.Ask yourself first, why are you extending that class? If answer is \"because I can't change it\" then you can create exact package and class in your application, and rewrite naughty method or create delegate:For instance, you can create  class in your application so this class should be loaded before the real one from jar. Then rewrite methods or constructors. This is absolute hack, and it is highly NOT recommended to use but it's WORKING! Using of this approach is dangerous because of possible issues with class loaders. Also this may cause issues each time you will update library that contains overwritten class.I think this is a problem that breaks the inheritance agreement. \nBy extending a class  you obey / agree  its behavior, features \nWhilst when calling , you want to break your own obedience  agreement.. However,  there  may happen situations when you feel the need to call  -  usually a bad design sign,  in your code or in the code you inherit ! \nIf the  and  classes cannot be refactored (some legacy code), then opt for composition over inheritance.\nEncapsulation breaking is when you  some methods by breaking the encapsulated code.\nThe methods  designed not to be overridden are marked\n .It is simply easy to do. For instance:C subclass of B and B subclass of A. Both of three have method methodName() for example.public abstract class A {}public class B extends A {}public class C extends B {}Run class C Output will be:\nClass A\nClass CInstead of output:\nClass A\nClass B\nClass C"},
{"body": "In C#, I can use the  statement to rethrow an exception while preserving the stack trace:Is there something like this in Java ()?will simply rethrow the exception you've caught (obviously the surrounding method has to permit this via its signature etc.). The exception will maintain the original stack trace.I would prefer:You can also wrap the exception in another one AND keep the original stack trace by passing in the Exception as a Throwable as the cause parameter:In Java is almost the same:In Java, you just throw the exception you caught, so  rather than just . Java maintains the stack trace.something like thisThis is a concrete example where the method throws an . The  means  can only hold an exception thrown from the try block. Additional reading material can be found  and ."},
{"body": "So I have tried to add my local .jar file dependency to my build.gradle file:And you can see that I added the .jar files into the referencedLibraries folder here: But the problem is that when I run the command: gradle build on the command line I get the following error:Here is my entire repo: If you really need to take that .jar from a local directory, Add next to your module gradle (Not the app gradle file):However, being a standard .jar in an actual maven repository, why don't you try this?According to , use a relative path for a local jar dependency as follows:You could also do this which would include all JARs in the local repository.  This way you wouldn't have to specify it every time.The accepted answer is good, however, I would have needed various library configurations within my multi-project Gradle build to use the same 3rd-party Java library. Adding '' to the '' path element within my '' closure meant each sub-project referenced the same '' directory, and  a version local to that sub-project:EDIT by Quizzie: changed \"${rootProject.projectDir}\" to \"$rootProject.projectDir\" (works in the newest Gradle version).A simple way to do this is it will compile all the .jar files in your libs directory in App.You can try reusing your local Maven repository for Gradle:I couldn't get the suggestion above at  to work.  This worked for me though.  For a file  that I stored in a  directory in the root of the project:The Question already has been answered in detail. I still want to add something that seems very surprising for me:The \"gradle dependencies\" task does not list any file dependencies. Even though you might think so, as they have been specified in the \"dependencies\" block after all..So don't rely on the output of this to check whether your referenced local lib files are working correctly.Goto File -> Project Structure -> Modules -> app -> Dependencies Tab -> Click on +(button) -> Select File Dependency - > Select jar file in the lib folderThis steps will automatically add your dependency to graldeVery Simple The best way to do it is to add this in your build.gradle file and hit the sync option The solution which worked for me is the usage of fileTree in build.gradle file.\nKeep the .jar which need to add as dependency in libs folder. The give the below code in dependenices block in build.gradle:An other way:Add library in the tree view. Right click on this one. Select menu \"Add As Library\".\nA dialog appear, let you select module. OK and it's done."},
{"body": "HashSet is based on HashMap.If we look at  implementation, everything is been managed under . is used as a key of .And we know that  is not thread safe. That is why we have  in Java.Based on this, I am confused that Is there anything else that I am missing? I need to use  in a multi-threaded environment.Also, If I want to create my own  can I achieve it by just replacing the  to  and leaving the rest as is?There's no built in type for  because you can always  a set from a map. Since there are many types of maps, you use a method to produce a set from a given map (or map class).Prior to Java 8, you produce a concurrent hash set backed by a concurrent hash map, by using In Java 8 (pointed out by @Matt), you can get a concurrent hash set  via . This is a bit simpler than the old  which required you to pass in an empty map object. But it is specific to .Anyway, the Java designers could have created a new set interface every time a new map interface was created, but that pattern would be impossible to enforce when third parties create their own maps. It is better to have the static methods that derive new sets; that approach always works, even when you create your own map implementations.With  15 you can also simply use:It looks like Java provides a concurrent Set implementation with its .  A  is just a special kind of set implementation.  It still implements the Serializable, Cloneable, Iterable, Collection, NavigableSet, Set, SortedSet interfaces.  This might work for you if you only need the Set interface. You can use guava's  to get one. Java 6 also has that method in As pointed by  the best way to obtain a concurrency-able HashSet is by means of This worked for me and I haven't seen anybody really pointing to it. This is less efficient than the currently aproved solution, as Eugene points out, since it just wraps your set into a synchronized decorator, while a  actually implements low-level concurrency and it can back your Set just as fine. So thanks to Mr. Stepanenkov for making that clear.Like  mentioned it is as easy as:Why not use: CopyOnWriteArraySet from java.util.concurrent?"},
{"body": "I was reading Java's  source code and noticed some comparisons in if-statements.In Java 7, the method  usesIn Java 6,  didn't exist. The method  however usesWhat was the reason behind the change? Was it a performance issue or just a style? I could imagine that comparing against zero is faster, but performing a complete subtraction just to check whether it's negative seems a bit overkill to me. Also in terms of bytecode, this would involve two instructions ( and ) instead of one (). and  can mean two different things. Consider the following code:When run, this will only print . What happens is that  is clearly false, but  overflows and becomes , which is negative.Now, having said that, consider that the array has a length that is really close to . The code in  goes like this: is really close to  so  (which is ) might overflow and become  (i.e. negative). Then, subtracting   back into a positive number.This check ensures that the  is not executed. If the code were written as , it would be  in this case (since  is negative) so the  would be forced to  regardless of the .This overflow case is handled by the next if. When  has overflowed, this will be :  is defined as  and  is . The  is therefore rightly handled:  method returns  or .NB: this is what the  comment in this method is saying.I found :In Java 6, if you use the API as:And  overflows (this becomes negative),  will return false and you may mistakenly assume that the  was increased by .Looking at the code:If  is quite large, this will overflow, and  will be a negative number. A comparison like  will incorrectly evaluate  and the  will fail to grow.Instead, the code as written ( returns false) will allow the negative value of  to be further evaluated in the next line, resulting in recalculating  by invoking  () to allow for the  to grow up to .This is what the  comment is trying to communicate, though rather obliquely.So, bottom line, the new comparison protects against allocating an  larger than the predefined  while allowing it to grow right up to that limit if needed.The two forms behave exactly the same unless the expression  overflows, in which case they are opposite.  If  is a large negative, and  is a large positive, then  is clearly true, but  will overflow to become positive, so  is false.If you're familiar with x86 assembly code, consider that  is implemented by a , which branches around the body of the if statement when SF = OF.  On the other hand,  will act like a , which branches when SF = 0.  Hence, these behave differently precisely when OF = 1."},
{"body": "My application  has the following flow screens :Now I have a common   button in each screens() I want that when user clicks on the log out button(from any screen), all the screens will be finished and a new screen  will open . I have tried nearly all  to achieve this.\nI also go through some answers in stackoverflow, but not being able to solve the problem.\nMy application is on Android 1.6 so not being able to use  Is there any way to solve the issue ?Use: This will clear all the activities on top of home. Assuming you are finishing the login screen when the user logs in and home is created and afterwards all the screens from 1 to 5 on top of that one. The code i posted will return you to home screen finishing all the other activites. You can add an extra in the intent and read that in the home screen activity and finish it also (maybe launch login screen again from there or something).I am not sure but you can also try going to login with this flag. I don't know how the activities will be ordered in that case. So don't know if it will clear the ones below the screen you are on including the one you are currently on but its definitely the way to go.Hope this helps. You may try . It will totally clears all previous activity(s) and start new activity. Before launching your new Activity, simply add the following code:Or if you want it to work in previous versions of Android:, they should press a button which loads the first Activity that runs when your application starts, clear all the other activities, then have the last remaining activity finish. Have the following code run when the user presses the exit button. In my case,  is the first activity in my program to run.The above code clears all the activities except for . Then put the following code inside the 's , to listen for when  is recreated and the 'EXIT' signal was passed:Android tries hard to discourage you from having an \"exit\" button in your application, because they want the user to never care about whether or not the programs they use are running in the background or not. The Android OS developers want your program to be able to survive an unexpected shutdown and power off of the phone, and when the user restarts the program, they pick up right where they left off. So the user can receive a phone call while they use your application, and open maps which requires your application to be freed for more resources. When the user resumes your application, they pick up right where they left off with no interruption. This exit button is usurping power from the activity manager, potentially causing problems with the automatically managed android program life cycle.This Will work for all Android versions. Where  the class added in Android Support library. Use the following for activityremove CLEAR_TASK flag for fragment use.I hope this may use for some people.From :Finish this activity as well as all activities immediately below it in the current task that have the same affinity. This is typically used when an application can be launched on to another task (such as from an ACTION_VIEW of a content type it understands) and the user has used the up navigation to switch out of the current task and in to its own task. In this case, if the user has navigated down into any other activities of the second application, all of those should be removed from the original task as part of the task switch.Note that this finish does not allow you to deliver results to the previous activity, and an exception will be thrown if you are trying to do so.A solution I implemented for this (I think I found it on Stack\u00a0Overflow somewhere, but I don't remember, so thanks to whoever did that in the first place):From any of your activities do this:Then in your LoginActivity, overwrite onKeyDown:For logout button on last screen of app, use this code on logout button listener to finish all open previous activities, and your problem is solved.    i have same problem\nyou can use  , like this :this code work for me .Android api If your application has minimum sdk version 16 then you can use Finish this activity as well as all activities immediately below it in the current task that have the same affinity.This is work for me In Top Payment screen remove all back-stack activits,Log in->Home->screen 1->screen 2->screen 3->screen 4->screen 5on screen 4 (or any other) -> If you are using  in your previous activities, just override  and call the  method inside it in all activities.. This will do the job...When user click on the logout button then write the following code:And also when after login if you call new activity do not use finish();for API >= 15 to API 23\nsimple solution.If you log in the user in  and from there you go to the other screens, use Simply, when you go from the login screen, not when finishing the login screen.And then in all forward activities, use this for logout:It works perfectly.I found this way, it'll clear all history and exitI found this solution to work on every device despite API level (even for < 11)On a side note, good to know\nThis answer works ()whereas this doesn't work  and doesn't append any new flags while  does.So this will also work"},
{"body": "I was using IntelliJ-IDEA IDE , I want to create a jar file from java compiled class files. but I not found command or file, How to create a jar file (like eclipse java archive export)\nthen you should press  or click the plus icon and create new artifact choose --> Next goto  --> choose your artifact.source:\nYou didn't specify your IDEA version. Before 9.0 use , in IDEA 9.0 use .In intellij8 I was using a specific plugin \"Jar Tool\" that is configurable and allows to pack a JAR archive."},
{"body": "Since I use Maven I have been able to build and install in my local repository projects that have incomplete java doc tags (for example, a missing parameter). However, since I migrated to Java 8 (1.8.0-ea-b90) Maven is absolutely strict about missing documentation tags and show me lots of JavaDoc errors related to JavaDoc problems when I try to build or install a project where the JavaDoc is not \"perfect\". Some of the projects I am trying to compile and install in my local repository are third party projects from which I do not have control. So the workaround of just fixing all the javadocs in all these projects does not seem to be feasable in my scenario.This is a small part of the output I see when I execute  in my project:The JavaDoc plugin is configured like this in my POM:As I said before, everything is working fine if I go back to Java 7. \nMaybe is this a bug related to Maven running in Java 8 ?\nHow could I make it work (i.e., being able to build the Javadoc of the project and install its code in my local repository) with Java 8 ?\nI have tested with both Maven 3.0.3 and 3.0.5 in OSX.If I change my JavaDoc plugin configuration with  (thanks Martin):Then the project is installed in my local repository. However, the javadoc jar is still not generated:A fragment of the output I see in the console with this new configuration is:Any workaround about how to build the sources, install the project and generate the Java doc jar in one step as it was working with Java 7 ?The best solution would be to fix the javadoc errors. If for some reason that is not possible (ie: auto generated source code) then you can disable this check., which is summarized as:This is enabled by default, and will run a whole lot of checks before generating Javadocs. You need to turn this off for Java 8 as specified . You'll have to add this to your maven configuration:The easiest approach to get things working with both java 8 and java 7 is to use a profile in the build:Here is the most concise way I am aware of to ignore doclint warnings regardless of java version used. There is no need to duplicate plugin configuration in multiple profiles with slight modifications.Tested on oracle/open jdk 6, 7 and 8.Add into the global properties section in the pom file:The common solution provided here in the other answers (adding that property in the plugins section) did not work for some reason. Only by setting it globally I could build the javadoc jar successfully.Overriding  configuration only, does not fix the problem with  (used e.g during the release stage). Here's what I had to do:I don't think just turning off DocLint is a good solution, at least not long term. It is good that Javadoc has become a bit more strict so the right way to fix the build problem is to . Yes, you'll ultimately need to fix those source code files.Here are the things to look out for that you could previously get away with:You'll simply have to fix your source code files and keep building your Javadoc until it can build without a failure. Cumbersome yes, but personally I like when I have brought my projects up to DocLint level because it means I can be more confident that the Javadoc I produce is actually what I intend.There's of course the problem if you are generating Javadoc on some source code you've not produced yourself, for example because it comes from some code generator, e.g. . Strange that Oracle didn't prepare their own tools for JDK8 compliance before actually releasing JDK8. It seems . Only in this particular case I suggest to turn off DocLint as documented elsewhere on this page.Just add that to your POM and you're good to go.This is basically  plus .You could try setting the  property (see ) to :As you can see from the docs, the default value is .Since it depends on the version of your JRE which is used to run the maven command you propably dont want to disable  per default in your pom.xmlHence, from command line you can use the switch .Example: I'm not sure if this is going to help, but even i faced the exact same problem very recently with  version.  After reading through the above answers i have just added the maven option through command line and it worked for me.  So, just sharing here.I'm using java , haven't tried with java 1.7  bin/mkdistro.sh -DskipTests   "},
{"body": "I want to join a  with a glue string. Is there a function for this? has a  class which has a  function which will join arrays together to make a .For example:Generates the following :[EDIT: Update for Java8]Starting from Java8 it is possible to use  , too.Generates the same :If you were looking for what to use in android, it is:for example:You could easily write such a function in about ten lines of code:In Java 8 you can use 1) Stream API :2) new String.join method:  3) java.util.StringJoiner class: A little mod instead of using substring():Java 8 added a new static method to  which does exactly what you want:Using it:Results in:Google guava's library also has . You can see the String[] example also from the API.As already described in the api, beware of the immutability of the builder methods.It can accept an array of objects so it'll work in your case. In my previous experience, i tried joining a Stack which is an iterable and it works fine.Sample from me :prints out : Given:Then as an alternative to coobird's answer, where the glue is \", \":Or to concatenate with a different string, such as \" &amp; \".However... this one ONLY works if you know that the values in the array or list DO NOT contain the character string \", \".If you are using the  then you have the  class:Not in core, no. A search for \"java array join string glue\" will give you some code snippets on how to achieve this though.e.g.If you've landed here looking for a quick array-to-string conversion, try .Just for the  challenge, here are mines ;)Nothing built-in that I know of.Apache  has a class called  which contains many join functions.This is how I do it.A similar alternativeMy spin.Do you like my 3-lines way using only String class's methods?To get \"str1, str2\" from \"str1\", \"str2\", \"\" :Also you can add extra null-checkIn case you're using Functional Java library and for some reason can't use Streams from Java 8 (which might be the case when using Android + Retrolambda plugin), here is a functional solution for you:Note that it's not the most efficient approach, but it does work good for small lists.I do it this way using a StringBuilder:java.util.Arrays has an 'asList' method. Together with the java.util.List/ArrayList API this gives you all you need:;"},
{"body": "Edited:\nI need to change the values of several variables as they run several times thorugh a timer. I need to keep updating the values with every iteration through the timer. I cannot set the values to final as that will prevent me from updating the values however I am getting the error I describe in the initial question below:I had previously written what is below:Java doesn't support true , even though using an anonymous class like you are using here (new TimerTask() { ... }) looks like a kind of closure. - This is why it doesn't work:The variables lastPrice and price are local variables in the main() method. The object that you create with the anonymous class might last until after the main() method returns.When the main() method returns, local variables (such as lastPrice and price) will be cleaned up from the stack, so they won't exist anymore after main() returns.But the anonymous class object references these variables. Things would go horribly wrong if the anonymous class object tries to access the variables after they have been cleaned up.By making lastPrice and price , they are not really variables anymore, but constants. The compiler can then just replace the use of lastPrice and price in the anonymous class with the values of the constants (at compile time, ofcourse), and you won't have the problem with accessing non-existent variables anymore.Other programming languages that do support closures do it by treating those variables specially - by making sure they don't get destroyed when the method ends, so that the closure can still access the variables.@Ankur: You could do this:To avoid strange side-effects with closures in java variables referenced by an anonymous delegate must be marked as final, so to refer to lastPrice and price within the timer task they need to be marked as final.This obviously won't work for you because you wish to change them, in this case you should look at encapsulating them within a class.now just create a new Foo as final and call .tick from the timer.You can only access final variables from the containing class when using an anonymous class.  Therefore you need to declare the variables being used final (which is not an option for you since you are changing  and ), or don't use an anonymous class.So your options are to create an actual inner class, in which you can pass in the variables and use them in a normal fashionor:There is a quick (and in my opinion ugly) hack for your  and  variable which is to declare it like soand in your anonymous class you can set the value like thisGood explanations for why you can't do what you're trying to do already provided. As a solution, maybe consider:Seems like probably you could do a better design than that, but the idea is that you could group the updated variables inside a class reference that doesn't change.With anonymous classes, you are actually declaring a \"nameless\" nested class. For nested classes, the compiler generates a new standalone public class with a constructor that will take all the variables it uses as arguments (for \"named\" nested classes, this is always an instance of the original/enclosing class). This is done because the runtime environment has no notion of nested classes, so there needs to be a (automatic) conversion from a nested to a standalone class. Take this code for example:That won't work, because this is what the compiler does under the hood:The original anonymous class is replaced by some standalone class that the compiler generates (code is not exact, but should give you a good idea):As you can see, the standalone class holds a reference to the shared object, remember that everything in java is pass-by-value, so even if the reference variable 'shared' in EnclosingClass gets changed, the instance it points to is not modified, and all other reference variables pointing to it (like the one in the anonymous class: Enclosing$1), will not be aware of this. This is the main reason the compiler forces you to declare this 'shared' variables as final, so that this type of behavior won't make it into your already running code. Now, this is what happens when you use an instance variable inside an anonymous class (this is what you should do to solve your problem, move your logic to an \"instance\" method or a constructor of a class):This compiles fine, because the compiler will modify the code, so that the new generated class Enclosing$1 will hold a reference to the instance of EnclosingClass where it was instantiated (this is only a representation, but should get you going):Like this, when the reference variable 'shared' in EnclosingClass gets reassigned, and this happens before the call to Thread#run(), you'll see \"other hello\" printed twice, because now EnclosingClass$1#enclosing variable will keep a reference to the object of the class where it was declared, so changes to any attribute on that object will be visible to instances of EnclosingClass$1.For more information on the subject, you can see this excelent blog post (not written by me): When I stumble upon this issue, I just pass the objects to the inner class through the constructor. If I need to pass primitives or immutable objects (as in this case), a wrapper class is needed.Edit: Actually, I don't use an anonymous class at all, but a proper subclass:You cannot refer to non-final variables because Java Language Specification says so. From 8.1.3:\n\"Any local variable, formal method parameter or exception handler parameter used but not declared in an inner class must be declared final.\" \nI can see only part of your code - according to me scheduling modification of local variables is a strange idea. Local variables cease to exist when you leave the function. Maybe static fields of a class would be better?I just wrote something to  something along the . \nI found the best thing to do was to let  all the objects and then in your implemented method use that constructor objects. However, if you are writing a generic interface class, then you have to pass an Object, or better a list of Objects. This could be done by Object[] or even better,  because it is easier to call.See my example piece just below.Please see this post about Java closures that supports this out of the box:\nVersion 1 supports passing of non-final closures with autocasting:\nIf you want to change a value in a method call within an anonymous class, that \"value\" is actually a . So, if you use Guava, you can writeOne solution I have noticed isn't mentioned (unless I missed it, if I did please correct me), is the use of a class variable. Ran into this issue attempting to run a new thread within a method: . Calling  from the following will work. You do not necessarily have to declare it , just need to change the scope of the variable so it is not collected before the innerclass. This is unless of course your process is huge and changing the scope might create some sort of conflict. I didn't want to make my variable final as it was in no way a final/constant.If the variable required to be final, cannot be then you can assign the value of the variable to another variable and make THAT final so you can use it instead.use ClassName.this.variableName to reference the non-final variableCan you make , , and  fields of the anonymous inner class?The main concern is whether a variable inside the anonymous class instance can be resolved at run-time. It is not a must to make a variable final as long as it is guaranteed that the variable is inside the run-time scope. For example, please see the two variables _statusMessage and _statusTextView inside updateStatus() method.what worked for me is just define the variable outside this function of your.Just before main function declare i.e.Declare the variable as a static and reference it in the required method using className.variableyou can just declare the variable outside the outer class. After this, you will be able to edit the variable from within the inner class. I sometimes face similar problems while coding in android so I declare the variable as global and it works for me.Just an another explanation. Consider this example belowHere Output will bem1 Completes Thread t runningThread t runningThread t running................Now method m1() completes and we assign reference variable o to null , Now Outer Class Object is eligible for GC but Inner Class Object is still exist who has (Has-A) relationship with Thread object which is running. Without existing Outer class object there is no chance of existing m1() method and without existing m1() method there is no chance of existing its local variable but if Inner Class Object uses the local variable of m1() method then everything is self explanatory.To solve this we have to create a copy of local variable and then have to copy then into the heap with Inner class object, what java does for only final variable because they are not actually variable they are like constants(Everything happens at compile time only not at runtime).To solve the problem above, different languages make different decisions.for Java, the solution is as what we see in this article.for C#, the solution is allow side-effects and capture by reference is the only option.for C++11, the solution is to allow the programmer make the decision. They can choose to capture by value or by reference. If capturing by value, no side-effects would occur because the variable referenced is actually different. If capture by reference, side-effects may occur but the programmer should realize it.Because it's confusing if the variable isn't final, as the changes to it won't be picked up in the anonymous class.Just make the variables 'price' and 'lastPrice' final.-- EditOops, and you'll also need to not assign to them, obviously, in your function. You'll need new local variables. Anyway, I suspect someone has given you a better answer by now."},
{"body": "I have a Spring MVC web app which uses Spring Security.  I want to know the username of the currently logged in user.  I'm using the code snippet given below .  Is this the accepted way?  I don't like having a call to a static method inside this controller - that defeats the whole purpose of Spring, IMHO.  Is there a way to configure the app to have the current SecurityContext, or current Authentication, injected instead?  If you are using , the easiest way is:A lot has changed in the Spring world since this question was answered. Spring has simplified getting the current user in a controller. For other beans, Spring has adopted the suggestions of the author and simplified the injection of 'SecurityContextHolder'. More details are in the comments.This is the solution I've ended up going with.  Instead of using  in my controller, I want to inject something which uses  under the hood but abstracts away that singleton-like class from my code.  I've found no way to do this other than rolling my own interface, like so:Now, my controller (or whatever POJO) would look like this:And, because of the interface being a point of decoupling, unit testing is straightforward. In this example I use Mockito:The default implementation of the interface looks like this:And, finally, the production Spring config looks like this:It seems more than a little silly that Spring, a dependency injection container of all things, has not supplied a way to inject something similar.  I understand  was inherited from acegi, but still.  The thing is, they're so close - if only  had a getter to get the underlying  instance (which is an interface), you could inject that.  In fact, I even  to that effect.One last thing - I've just substantially changed the answer I had here before.  Check the history if you're curious but, as a coworker pointed out to me, my previous answer would not work in a multi-threaded environment.  The underlying  used by  is, by default, an instance of , which stores s in a .  Therefore, it is not necessarily a good idea to inject the  directly into a bean at initialization time - it may need to be retrieved from the  each time, in a multi-threaded environment, so the correct one is retrieved.To make it just show up in your JSP pages, you can use the Spring Security Tag Lib:To use any of the tags, you must have the security taglib declared in your JSP:Then in a jsp page do something like this:NOTE: As mentioned in the comments by @SBerg413, you'll need to add to the \"http\" tag in the security.xml config for this to work.I agree that having to query the SecurityContext for the current user stinks, it seems a very un-Spring way to handle this problem.I wrote a static \"helper\" class to deal with this problem; it's dirty in that it's a global and static method, but I figured this way if we change anything related to Security, at least I only have to change the details in one place:I get authenticated user by\nHttpServletRequest.getUserPrincipal();Example:If you are using Spring Security ver >= 3.2, you can use the  annotation:Here,  is a custom object that implements  that is returned by a custom .More information can be found in the  chapter of the Spring Security reference docs.In Spring 3+ you have have following options.Option 1 : Option 2 : Option 3:Option 4 : Fancy one : Yes, statics are generally bad - generally, but in this case, the static is the most secure code you can write.  Since the security context associates a Principal with the currently running thread, the most secure code would access the static from the thread as directly as possible.  Hiding the access behind a wrapper class that is injected provides an attacker with more points to attack.  They wouldn't need access to the code (which they would have a hard time changing if the jar was signed), they just need a way to override the configuration, which can be done at runtime or slipping some XML onto the classpath.  Even using annotation injection in the signed code would be overridable with external XML.  Such XML could inject the running system with a rogue principal.  This is probably why Spring is doing something so un-Spring-like in this case.I would just do this:For the last Spring MVC app I wrote, I didn't inject the SecurityContext holder, but I did have a base controller that I had two utility methods related to this  ... isAuthenticated() & getUsername(). Internally they do the static method call you described.At least then it's only in once place if you need to later refactor.You could use Spring AOP aproach.\nFor example if you have some service, that needs to know current principal. You could introduce custom annotation i.e. @Principal , which indicate that this Service should be principal dependent.Then in your  advice, which I think needs to extend MethodBeforeAdvice, check that particular service has @Principal annotation and inject Principal name, or set it to 'ANONYMOUS' instead.The only problem is that even after authenticating with Spring Security, the user/principal bean doesn't exist in the container, so dependency-injecting it will be difficult.  Before we used Spring Security we would create a session-scoped bean that had the current Principal, inject that into an \"AuthService\" and then inject that Service into most of the other services in the Application.  So those Services would simply call authService.getCurrentUser() to get the object.  If you have a place in your code where you get a reference to the same Principal in the session, you can simply set it as a property on your session-scoped bean.The best solution if you are using Spring 3 and need the authenticated principal in your controller is to do something like this:Try thisI am using the  annotation in  classes as well as in  annotated ones. Ex.:Where  is the class i use for logged users services, and extends from . Something like:Really easy.Define  as a dependency in your controller method and spring will inject the current authenticated user in your method at invocation.this is old question but still we have different way to get user name during July-2016 using Spring 4, Boot, Security, OAuth2 and Angular2 \nPlease correct me if I'm wrong because I'm looking for simple solutionI like to share my way of supporting user details on freemarker page.\nEverything is very simple and working perfectly!You just have to place Authentication rerequest on  (page after form-login)\nThis is my Controler method for that page:And this is my ftl code:And that's it, username will appear on every page after authorisation."},
{"body": "Which annotation,  () or  (Spring specific) should I be using when using DI?I have successfully used both in the past,  and My instinct is to stick with the  tag since it's been ratified by the jsr people.  Anyone have strong thoughts on this?In spring pre-3.0 it doesn't matter which one.In spring 3.0 there's support for the standard () annotation  - use it, with a combination of . Note that spring now also supports the  meta-annotation:So you can haveorAnd then:This makes less use of String-names, which can be misspelled and are harder to maintain.As for the original question: both, without specifying any attributes of the annotation, perform injection by type. The difference is:Both  (or ) and  work equally well. But there is a conceptual difference or a difference in the meaningSo, basically these are two quite distinct concepts. Unfortunately the Spring-Implementation of  has a built-in fallback, which kicks in when resolution by-name fails. In this case, it falls back to the -kind resolution by-type. While this fallback is convenient, IMHO it causes a lot of confusion, because people are unaware of the conceptual difference and tend to use  for type-based autowiring.The primary difference is,  is a spring annotation. Whereas  is specified by the JSR-250, as you pointed out yourself. So the latter is part of Java whereas the former is Spring specific.Hence, you are right in suggesting that, in a sense. I found folks use  with  because it is more powerful. Moving from some framework to some other is considered very unlikely, if not myth, especially in the case of Spring.I would like to emphasize one comment from  on  to this question. The comment brings a useful link: . I encourage you to read it entirely, however here is a quick summary of its usefulness: and Avoid  annotations unless you want to create a list of similar beans. For example you may want to mark a set of rules with a specific  annotation. This approach makes it simple to inject a group of rule classes into a list that can be used for processing data.Scan specific packages for components . While this will result in more  configurations it reduces the chance that you\u2019ll add unnecessary components to your Spring context. This is what I got from the  :-Both of them are equally good. The advantage of using Resource is in future if you want to another DI framework other than spring, your code changes will be much simpler. Using Autowired your code is tightly coupled with springs DI.@Autowired + @Qualifier will work only with spring DI, if you want to use some other DI in future @Resource is good option.other difference which I found very significant is @Qualifier does not support dynamic bean wiring, as @Qualifier does not support placeholder, while @Resource does it very well.For example:\nif you have an interface with multiple implementations like thiswith @Autowired & @Qualifier you need to set specific child implementation \nlike which does not provide placeholder while with @Resource you can put placeholder and use property file to inject specific child implementation likewhere service.name is set in property file as  Hope that helps someone :) is often used by high-level objects, defined via JNDI.  or  will be used by more common beans.As far as I know, it's not a specification, nor even a convention. It's more the logical way standard code will use these annotations.As a note here:\n and   work with   annotation. So, there are difference."},
{"body": "I have an interface which returns .I would like to manipulate that result using the Java 8 Stream API.However Iterable can't \"Stream\". Any better idea how to use streams (without converting Iterable to List)?There's a much better answer than using  directly, which is both easier and gets a better result.   has a  method, so you should just use that to get your spliterator.  In the worst case, its the same code (the default implementation uses ), but in the more common case, where your  is already a collection, you'll get a better spliterator, and therefore better stream performance (maybe even good parallelism.)  Its also less code: As you can see, getting a stream from an Iterable (see ) is not very painful.  If you can use Guava library, since version 21, you can useYou can easily create a  out of an  or :I would like to suggest using  library, it hides spliterator magic behind the Seq.seq(iterable) call and also provides a whole bunch of additional useful functionality.I've created this class:I think it's perfectly readable because you don't have to think about spliterators and booleans (isParallel).A very simple work-around for this issue is to create a  extending  that holds a  method.Now any of your s can be trivially made streamable just by declaring them  instead of ."},
{"body": "I'm trying to understand how the concepts of ,  and  in the Java heap terminology, and more specifically the interactions between the three generations.My questions are:This seems like a common misunderstanding. In Oracle's JVM, the permanent generation is not part of the heap. It's a separate space for class definitions and related data. In Java 6 and earlier, interned strings were also stored in the permanent generation. In Java 7, interned strings are stored in the main object heap.Here is a .I like the descriptions given for each space in Oracle's :Java uses generational garbage collection. This means that if you have an object foo (which is an instance of some class), the more garbage collection events it survives (if there are still references to it), the further it gets promoted. It starts in the young generation (which itself is divided into multiple spaces - Eden and Survivor) and would eventually end up in the tenured generation if it survived long enough. : It is place where lived for short period and divided into two spaces: : This pool is basically contain tenured and virtual\n   (reserved) space and will be holding those objects which survived\n   after garbage collection from Young Generation. This memory pool as name also says contain permanent class metadata and descriptors information so PermGen space always reserved for classes and those that is tied to the classes for example static members. (Virtual or reserved) : If you are using HotSpot Java VM this includes code cache area that containing memory which will be used for compilation and storage of native code.The Java virtual machine is organized into three generations: a young generation, an old generation, and a permanent generation. Most objects are initially allocated in the young generation. The old generation contains objects that have survived some number of young generation collections, as well as some large objects that may be allocated directly in the old generation. The permanent generation holds objects that the JVM finds convenient to have the garbage collector manage, such as objects describing classes and methods, as well as the classes and methods themselves.The  is where all new objects are allocated and aged. When the young generation fills up, this causes a minor garbage collection. A young generation full of dead objects is collected very quickly. Some surviving objects are aged and eventually move to the old generation.The  is used to store long surviving objects. Typically, a threshold is set for young generation object and when that age is met, the object gets moved to the old generation. Eventually the old generation needs to be collected. This event is called a The  contains metadata required by the JVM to describe the classes and methods used in the application. The permanent generation is populated by the JVM at runtime based on classes in use by the application. parameters will be ignored nowImage source & oracle technetwork tutorial article: \"\" in above article explains the interactions between them with many diagrams. Have a look at summary diagram: is a very good survey on garbage collectors. It defines the basic concepts and terminology of garbage collection and includes many explanatory drawings. It is a \"must read\" for anybody who is interested in how automatic memory allocation works; reading it will make it much easier for you to read and understand the various documents that others have pointed at.(What that document lacks is any information about post-1993 research on garbage collectors, especially the whole business of multi-core systems. Still, you have to learn to walk before learning to run.)Assuming you're talking about the Sun JDK/OpenJDK, see the page on the OpenJDK website on .  There are a couple of links to even more information at the bottom.Although it is about tuning I can't resist recommend this  take a look at chapter 3 and go in depth if you like.Memory in SunHotSpot JVM is organized into three generations: young generation, old generation and permanent generation. FYI: The permanent gen is not considered a part of the Java heap.\n      Objects(except the large ones) are first allocated to the young generation. If an object remain alive after x no. of garbage collection cycles it gets promoted to the old/tenured gen. Hence we can say that the young gen contains the short lived objects while the old gen contains the objects having a long life. The permanent gen does not interact with the other two generations."},
{"body": "How do I import a jar in Eclipse?You can add a jar in Eclipse by right-clicking on the Project \u2192 Build Path \u2192 Configure Build Path. Under Libraries tab, click Add Jars or Add External JARs and give the Jar. A quick demo .The above solution is obviously a \"Quick\" one. However, if you are working on a project where you need to commit files to the source control repository, I would recommend adding Jar files to a dedicated library folder within your source control repository and referencing few or all of them as mentioned above.Adding external Jar is not smart in case you want to change the project location in filesystem.The best way is to add the jar to build path so your project will compile if exported:Two choices:1/ From the project:2/ If you have already other jar imported, from the directory \"References Libraries\":Both will lead you to this screen where you can mange your libraries:Here are the steps:Just a comment on importing jars into Eclipse (plug-in development) projects:In case you are developing Eclipse plug-ins, it makes sense to use Eclipse's native bundling mechanism instead of just importing the jar into a plug-in project. Eclipse (or better its underlying OSGi runtime, Equinox) uses so-called bundles which contain some more information than plain jars (e.g., version infos, dependencies to other bundles, exported packages; see the MANIFEST.MF file). Because of this information, OSGi bundles can be dynamically loaded/unloaded and there is automatic dependency resolution available in an OSGi/Eclipse runtime. Hence, using OSGi bundles instead of plain jars (contained inside another OSGi bundle) has some advantages. (BTW: Eclipse plug-ins are the same thing as OSGi bundles.)There is a good chance that somebody already bundled a certain (3rd party) library as an OSGi bundle. You might want to take a look at the following bundle repositories:Eclipse -> Preferences -> Java -> Build Path -> User Libraries -> New(Name it) -> Add external Jars(I recommend dragging your new libraries into the eclipse  folder before any of these steps to keep everything together, that way if you reinstall Eclipse or your OS you won't have to rwlink anything except the JDK) Now select the jar files you want. Click OK. Right click on your project and choose Build Path -> Add LibraryFYI just code and then right click and Source->Organize Imports"},
{"body": "I hope this question is not considered too basic for this forum, but we'll see. I'm wondering how to refactor some code for better performance that is getting run a bunch of times.Say I'm creating a word frequency list, using a Map (probably a HashMap), where each key is a String with the word that's being counted and the value is an Integer that's incremented each time a token of the word is found.In Perl, incrementing such a value would be trivially easy:But in Java, it's much more complicated. Here the way I'm currently doing it:Which of course relies on the autoboxing feature in the newer Java versions. I wonder if you can suggest a more efficient way of incrementing such a value. Are there even good performance reasons for eschewing the Collections framework and using a something else instead?Update: I've done a test of several of the answers. See below.I've gotten a lot of good answers to this question--thanks folks--so I decided to run some tests and figure out which method is actually fastest. The five methods I tested are these:Here's what I did...I'll present the results first and the code below for those who are interested.The  method was, as expected, the slowest, so I'll give the speed of each method in comparison to the speed of that method.It would appear that only the MutableInt method and the Trove method are significantly faster, in that only they give a performance boost of more than 10%. However, if threading is an issue, AtomicLong might be more attractive than the others (I'm not really sure). I also ran TestForNull with  variables, but the difference was negligible.Note that I haven't profiled memory usage in the different scenarios. I'd be happy to hear from anybody who has good insights into how the MutableInt and Trove methods would be likely to affect memory usage.Personally, I find the MutableInt method the most attractive, since it doesn't require loading any third-party classes. So unless I discover problems with it, that's the way I'm most likely to go.Here is the crucial code from each method.A little research in 2016: , Best results per method (smaller is better):Time\\space results:\n@Hank GayAs a follow-up to my own (rather useless) comment: Trove looks like the way to go. If, for whatever reason, you wanted to stick with the standard JDK,  and  can make the code a  bit nicer, though YMMV.will leave  as the value in the map for . Realistically, increased friendliness to threading is all that this approach has to recommend it.It's always a good idea to look at the  for this kind of thing. In this case a  will do the trick:There are Map-like methods for iterating over keys/entries, etc. Internally the implementation currently uses a , so you will not incur boxing costs....at least in some cases. They have this nice . Especially nice because you are dealing with  as value in your map.E.g.Also possible to add more then 1 to the value:You should be aware of the fact that your original attempt contains two potentially expensive operations on a map, namely  and . The former performs an operation potentially pretty similar to the latter, so you're doing the same work !If you look at the API for Map,  operations usually return  when the map does not contain the requested element.Note that this will make a solution likedangerous, since it might yield s. You should check for a  first.\n\n, and this is very important, that s  contain  by definition. So not every returned  says \"there is no such element\". In this respect,  behaves  from  in actually telling you  there is such an element. Refer to the API for details.\n\nFor your case, however, you might not want to distinguish between a stored  and \"noSuchElement\". If you don't want to permit s you might prefer a . Using a wrapper library as was already proposed in other answers might be a better solution to manual treatment, depending on the complexity of your application.To complete the answer (and I forgot to put that in at first, thanks to the edit function!), the best way of doing it natively, is to  into a  variable, check for  and  it back in with a . The variable should be  because it's immutable anyway. The compiler might not need this hint, but its clearer that way.If you do not want to rely on autoboxing, you should say something like  instead.Another way would be creating a mutable integer:of course this implies creating an additional object but the overhead in comparison to creating an Integer (even with Integer.valueOf) should not be so much.And that's how you increment a value with simple code.Benefit:Another way is to use merge method, but this is too much for just incrementing a value.Suggestion: you should care about code readability more than little performance gain in most of the time.Memory rotation may be an issue here, since every boxing of an int larger than or equal to 128 causes an object allocation (see Integer.valueOf(int)). Although the garbage collector very efficiently deals with short-lived objects, performance will suffer to some degree.If you know that the number of increments made will largely outnumber the number of keys (=words in this case), consider using an int holder instead. Phax already presented code for this. Here it is again, with two changes (holder class made static and initial value set to 1):If you need extreme performance, look for a Map implementation which is directly tailored towards primitive value types. jrudolph mentioned .By the way, a good search term for this subject is \"histogram\".OK, may be an old question, but there is a shorter way with Java 8 :What it does : if  do not exists, put  as value, otherwise  to the value linked to .\nMore information Are you sure that this is a bottleneck? Have you done any performance analysis?Try using the NetBeans profiler (its free and built into NB 6.1) to look at hotspots.Finally, a JVM upgrade (say from 1.5->1.6) is often a cheap performance booster. Even an upgrade in build number can provide good performance boosts. If you are running on Windows and this is a server class application, use -server on the command line to use the Server Hotspot JVM. On Linux and Solaris machines this is autodetected.There are a couple of approaches:And use put(\"word\", new My(\"Word\") ); Then you can check if it exists and increment when adding.Avoid rolling your own solution using lists, because if you get innerloop searching and sorting, your performance will stink. The first HashMap solution is actually quite fast, but a proper like that found in Google Collections is probably better.Counting words using Google Collections, looks something like this:Using the HashMultiset is quite elegent, because a bag-algorithm is just what you need when counting words.I think your solution would be the standard way, but - as you noted yourself - it is probably not the fastest way possible.You may look at . That is a library which contains all sorts of fast primitive Collections. Your example would use a  which has a method adjustOrPutValue which does exactly what you want.A variation on the MutableInt approach that might be even faster, if a bit of a hack, is to use a single-element int array: It would be interesting if you could rerun your performance tests with this variation.  It might be the fastest.Edit: The above pattern worked fine for me, but eventually I changed to use Trove's collections to reduce memory size in some very large maps I was creating -- and as a bonus it was also faster.One really nice feature is that the  class has a single  call that, depending on whether there is already a value at that key, will either put an initial value or increment the existing value.  This is perfect for incrementing:Google Collections HashMultiset :\n - quite elegant to use\n - but consume CPU and memoryBest would be to have a method like :  \n(elegant, and low cost)Such a method will compute hash and index only once,\nand then we could do what we want with the entry\n(either replace or update the value).More elegant:\n - take a \n - extend it so that  put a new Entry if needed\n - Entry could be your own object.\n-->   Instead of calling containsKey() it is faster just to call map.get and check if the returned value is null or not.\"put\" need \"get\" (to ensure no duplicate key).\nSo directly do a \"put\",\nand if there was a previous value, then do an addition:If count starts at 0, then add 1: (or any others values...) This code is not thread safe. Use it to build then use the map, not to concurrently update it.  In a loop, keep old value to become the new value of next loop.The various primitive wrappers, e.g.,  are immutable so there's really not a more concise way to do what you're asking  you can do it with something like . I can give that a go in a minute and update. BTW,   a part of the .I'd use Apache Collections Lazy Map (to initialize values to 0) and use MutableIntegers from Apache Lang as values in that map. Biggest cost is having to serach the map twice in your method. In mine you have to do it just once. Just get the value (it will get initialized if absent) and increment it.The  library's  datastructure has an  method in the latest trunk head:Example usage:This program prints \"2\".@Vilmantas Baranauskas: Regarding this answer, I would comment if I had the rep points, but I don't.  I wanted to note that the Counter class defined there is NOT thread-safe as it is not sufficient to just synchronize inc() without synchronizing value().  Other threads calling value() are not guaranteed to see the the value unless a happens-before relationship has been established with the update.  You can make use of  method in  interface provided in Java 8. The method  checks if the specified key is already associated with a value or not? If no associated value then it attempts to compute its value using the given mapping function. In any case it returns the current (existing or computed) value associated with the specified key, or null if the computed value is null.On a side note if you have a situation where multiple threads update a common sum you can have a look at  class.Under high contention, expected throughput of this class is significantly higher than , at the expense of higher space consumption.If you're using , you can use a . It will be the most efficient approach in terms of memory usage and it will also perform well in terms of execution speed. is backed by a  which stores primitive ints instead of  objects. This reduces memory overhead and improves execution speed. provides the API you'd need since it's a  that also allows you to query for the number of occurrences of an item.Here's an example from the . I am a committer for Eclipse Collections.I don't know how efficient it is but the below code works as well.You need to define a  at the beginning. Plus, you can make more than just increment with this method.output is"},
{"body": "I need to create a list with all names of the files in a folder.For example, if I have:I want to store them in a  with  as values.What's the best way to do it in Java ?PS: I'm on Mac OS XYou could do it like that:Do you want to only get JPEG files or all files?Create a  object, passing the directory path to the constructor. Use the  to retrieve an array of  objects for each file in the directory, and then call the  method to get the filename.Here's how to look in the .First, you're dealing with IO, so look in the  . There are two classes that look interesting:  and . When I clicked on the first, it showed me that there was a a  method in the  class. And the documentation for that method says:Scrolling up in the  JavaDoc, I see the constructors. And that's really all I need to be able to create a  instance and call  on it. Scrolling still further, I can see some information about how files are named in different operating systems."},
{"body": "What is the most accepted way to convert a  to an  in Java?^^PS : true = 1 and false = 0Using the ternary operator is the most simple, most efficient, and most readable way to do what you want. I encourage you to use this solution.However, I can't resist to propose an alternative, contrived, inefficient, unreadable solution.Hey, people like to vote for such cool answers !By the way, I often saw conversions from a boolean to an int for the sole purpose of doing a comparison of the two values (generally, in implementations of  method).  is the way to go in those specific cases.Java 7 introduced a new utility function that works with primitive types directly,  (Thanks )simpleThat depends on the situation. Often the most simple approach is the best because it is easy to understand:orBut sometimes it useful to use an Enum instead of a boolean flag. Let imagine there are synchronous and asynchronous processes:In Java, enum can have additional attributes and methods:If  and  mapping is what you want, you can do:If you want to obfuscate, use this:Lets play trick with . Default behavior of function: if both values are equal than it returns  otherwise .: As we know default return of Boolean.compare is -1 in case of mis-match so +1 make return value to  for  and  for If you use  (which I think a lot of projects use it), you can just use it like this:  method returns 1 if  is true, 0 otherwise"},
{"body": "OK, so the  annotation is good for marking that a test case shouldn't be run.However, sometimes I want to ignore a test based on runtime information.  An example might be if I have a concurrency test that needs to be run on a machine with a certain number of cores.  If this test were run on a uniprocessor machine, I don't think it would be correct to just pass the test (since it hasn't been run), and it certainly wouldn't be right to fail the test and break the build.So I want to be able to ignore tests at runtime, as this seems like the right outcome (since the test framework will allow the build to pass but record that the tests weren't run).  I'm fairly sure that the annotation won't give me this flexibility, and suspect that I'll need to manually create the test suite for the class in question.  However, the documentation doesn't mention anything about this and looking through the  it's also not clear how this would be done programmatically (i.e. how do I programatically create an instance of  or similar that is equivalent to that created by the  annotation?).If anyone has done something similar in the past, or has a bright idea of how else I could go about this, I'd be happy to hear about it.The JUnit way is to do this at run-time is .You can do it in a  method or in the test itself, but not in an  method. If you do it in the test itself, your  method will get run. To compare with the  annotation from , their sample code would look like this:Not to mention that it is much easier to capture and use the connection from the  method this way.You should checkout  project.  They have  annotation that performs conditional tests, like:[Code sample taken from their tutorial]In JUnit 4, another option for you may be to create an annotation to denote that the test needs to meet your custom criteria, then extend the default runner with your own and using reflection, base your decision on the custom criteria. It may look something like this:A quick note:  ignores rest of the steps but passes the test. \nTo fail the test, use  inside the conditional statement. Works same like  but fails the test."},
{"body": "What is the best way to use the values stored in an Enum as String literals?\nFor example:Then later I could use  to return its string representation as . Without having to keep calling .You can't. I think you have three options here. All three offer a solution but with a slightly different approach...    Every enum has both a name() and a valueOf(String) method. The former returns the string name of the enum, and the latter gives the enum value whose name is the string. Is this like what you're looking for?There's also a static valueOf(Class, String) on Enum itself, so you could also useYou could override the  method for each enum value. or . It doesn't get better than that, I'm afraidAs Benny Neugebauer mentions, you could overwrite the toString(). However instead overwriting the toString for each enum field I like more something like this:You could also add a static method to retrieve all the fields, to print them all, etc.\nSimply call getValue to obtain the string associated to each Enum itemYou can use  however you often don't need to do this.As far as I know, the only way to get the name would beIf you really need it this way, however, you could do:you can call like below whereever you want to get value as string from enum.This will return \"Mode1\" as String.You can simply use:Enum is just a little bit special class. Enums can store additional fields, implement methods etc. For exampleNow you can say:and see output: \nmy solution for your problem!For my enums I don't really like to think of them being allocated with 1 String each.  This is how I implement a toString() method on enums.after many tries I have come with this solutionIt is an easy way without creating interface, class or getter settersSo just to build on some of the above answers.. A lot of times i'll use enumerators to represent \"types\" of things obviously, but then those types also have additional attributes, like an int ID and a string Description. The below solution works well for me to give an enumerator a bit more usefulness for me....and i'm new to Java btw.. so if there's issues with this i'd love to knowI'm supprised that non of those anwsers consider Enum with an Attribute. Enum will be easy to readable for a programmer, and Attribute can contain a full name, or \"pointer\" to translation. That way you can repeat names between enums, and you have no warries for uniquness of string in attribute since they can be very long.Usage:"},
{"body": "\nWe have a Spring MVC-based RESTful API which contains sensitive information. The API should be secured, however sending the user's credentials (user/pass combo) with each request is not desirable. Per REST guidelines (and internal business requirements), the server must remain stateless. The API will be consumed by another server in a mashup-style approach.We've been banging our heads against the wall trying to make this work, so hopefully someone out there has already solved this problem. Given the above scenario, how might you solve this particular need?We managed to get this working exactly as described in the OP, and hopefully someone else can make use of the solution. Here's what we did:Set up the security context like so:As you can see, we've created a custom , which basically just returns a  if the request wasn't authenticated in the filter chain by our .::Obviously,  contains some privy (and very case-specific) code and can't be readily shared. Here's its interface:That ought to get you off to a good start. Happy coding. :)You might consider .  Essentially the protocol is as follows:All of this communication is made through headers, which, as jmort253 points out, is generally more secure than communicating sensitive material in the url parameters.Digest Access Authentication is supported by .  Notice that, although the docs say that you must have access to your client's plain-text password, you can  for your client.Regarding tokens carrying information, JSON Web Tokens () is a brilliant technology. The main concept is to embed information elements (claims) into the token, and then signing the whole token so that the validating end can verify that the claims are indeed trustworthy.I use this Java implementation:  There is also a Spring module (spring-security-jwt), but I haven't looked into what it supports."},
{"body": "The JUnit framework contains 2  classes (in different packages, obviously) and the methods on each appear to be very similar. Can anybody explain why this is?The classes I'm referring to are:  and .The old method (of Junit 3) was to mark the test-classes by extending junit.framework.TestCase. That inherited junit.framework.Assert itself and your test-class gained the ability to call the assert-methods this way.Since version 4 of junit, the framework uses Annotations for marking tests. So you no longer need to extend TestCase. But that means, the assert-methods aren't available. But you can make a static import of the new Assert-class. That's why all the assert-methods in the new class are static methods. So you can import it this way:After this static import, you can use this methods without prefix.At the redesign they also moved to the new package org.junit, that follows better the normal conventions for package-naming.JUnit 3.X: JUnit 4.X: Prefer the newest one, especially when running JDK5 and higher with annotation support.There is in fact a functional change:  will complain if you use the two-argument  with  or , while  will silently autobox it.I believe they are refactoring from  to  and  is maintained for backwards compatibility. I did a rough source code compare and there are no serious changes.Lot of comments were added in  and some refactorings are done.The only change is the comparison with Arrays. There are some code clean ups, but there's (imho) ."},
{"body": "When / what are the conditions when a  is created?Is it per a domain? For instance, if I have a Tomcat app server, and I deploy multiple web applications, will a different  be created per context (web application), or is it shared across web applications as long as they are the same domain?JSESSIONID cookie is created/sent when session is created. Session is created when your code calls  or  for the first time. If you just want to get the session, but not create it if it doesn't exist, use  -- this will return you a session or . In this case, new session is not created, and JSESSIONID cookie is not sent. (This also means that ... you and your code are in control  the session is created)Sessions are per-context:()Update: Every call to JSP page implicitly creates a new session if there is no session yet. This can be turned off with the  page directive, in which case session variable is not available on JSP page at all.Here is some information about one more source of the  cookie:I was just debugging some Java code that runs on a tomcat server. I was not calling  explicitly anywhere in my code but I noticed that a  cookie was still being set. I finally took a look at the generated Java code corresponding to a JSP in the work directory under Tomcat.It appears that, whether you like it or not, if you invoke a JSP from a servlet,  will get created!Added: I just found that by adding the following JSP directive:you can disable the setting of  by a JSP.CORRECTION: Please vote for Peter \u0160tibran\u00fd's answer - it is more correct and complete!A \"JSESSIONID\" is the unique id of the http session - . In the javadoc you will find the following sentence: \"Session information is scoped only to the current web application (ServletContext), so information stored in one context will not be directly visible in another.\"So when you first hit a site, a new session is created and bound to the SevletContext. If you deploy multiple applications, the session is not shared.You can also invalidate the current session and therefore create a new one. e.g. when switching from http to https (after login), it is a very good idea, to create a new session.Hope, this answers your question.Beware if your page is including other .jsp or .jspf (fragment)! If you don't set on them as well, the parent page will end up starting a new session and setting the JSESSIONID cookie.For .jspf pages in particular, this happens if you configured your web.xml with such a snippet:in order to enable scriptlets inside them.For links generated in a JSP with custom tags, I had to use in the JSP ANDin the Struts action"},
{"body": "I was thinking if exist a better/nicer way to negate a instanceof in Java.\nActually, I do something like:But, I think that should exist a \"beautiful\" syntax to do this.Someone know if it exists and how the syntax look like?\nBy beautiful, I might say something like this:No, there is no better way; yours is canonical.I don't know what you imagine when you say \"beautiful\", but what about this? I personally think it's worse than the classic form you posted, but somebody might like it...You could use the  method:... but it is still negated and pretty ugly.If you can use static imports, and your moral code allows themAnd then...This is just a fluent interface exercise, I'd never use that in real life code!\nGo for your classic way, it won't confuse anyone else reading your code!Usually you don't want just an  but an  clause as well.can be written asOr you can write the code so you don't need to know if its a String or not. e.g.can be written asok just my two cents, use a is string method:"},
{"body": "How can I transform a  value into an ? also does the trick:I also found the apache commons  class , so : Does it have to be specifically an InputStreamReader?  How about using ?Otherwise, you could use , but it's deprecated because of character conversion issues (which is why you should prefer StringReader).Same question as  - why not StringReader ?If it has to be InputStreamReader, then:Are you trying to get a)  functionality out of , or b)  functionality out of ?  You won't get b).   is not an .The purpose of  is to take an  - a source of bytes - and decode the bytes to chars in the form of a .  You already have your data as chars (your original String).  Encoding your String into bytes and decoding the bytes back to chars would be a redundant operation.If you are trying to get a  out of your source, use .If you are trying to get an  (which only gives you bytes), use apache commons  as suggested by other answers here."},
{"body": "Is there a Java equivalent for  in C#/.NET? Or any code to accomplish this?This static method combines one or more strings into a path.Rather than keeping everything string-based, you should use a class which is designed to represent a file system path.If you're using Java 7 or Java 8, you should strongly consider using ;  can be used to combine one path with another, or with a string. The  helper class is useful too. For example:If you need to cater for pre-Java-7 environments, you can use , like this:If you want it back as a string later, you can call . Indeed, if you really wanted to mimic , you could just write something like:In Java 7, you should use :While the NIO2 Path class may seem a bit redundant to File with an unnecessarily different API, it is in fact subtly more elegant and robust.Note that  (as suggested by someone else) doesn't have an overload taking a , and doing  is NOT the same thing as .  is more intelligent. From the :The sister function to  is the excellent :The main answer is to use File objects. However  does have a class  that can do this kind of thing, such as the  method.To enhance JodaStephen's answer, Apache Commons IO has FilenameUtils which does this.  Example (on Linux):It's platform independent and will produce whatever separators your system needs.I know its a long time since Jon's original answer, but I had a similar requirement to the OP. By way of extending Jon's solution I came up with the following, which will take one or more path segments takes as many path segments that you can throw at it.Here's a solution which handles multiple path parts and edge conditions:If you do not need more than strings, you can use to get "},
{"body": "I have a string that has two single quotes in it, the  character. In between the single quotes is the data I want.How can I write a regex to extract \"the data i want\" from the following text?Assuming you want the part between single quotes, use this regular expression with a :Example:Result:You don't need regex for this.Add apache commons lang to your project (), then use:Because you also ticked Scala, a solution without regex which easily deals with multiple quoted strings:as in javascript:the actual regexp is: if you use the non greedy modifier (as per another post) it's like this:it is cleaner.In Scala,There's a simple one-liner for this:By making the matching group optional, this also caters for quotes not being found by returning a blank in that case.See ."},
{"body": "What is the difference between , ,  & ?I was programming in Java and I encountered these phrases, what are the differences between them?The  (JVM) is the virtual machine that runs the Java bytecodes. The JVM doesn't understand Java source code, that's why you compile your  files to obtain  files that contain the bytecodes understood by the JVM. It's also the entity that allows Java to be a \"portable language\" (). Indeed, there are specific implementations of the JVM for different systems (Windows, Linux, MacOS, ), the aim is that with the same bytecodes they all give the same results.To explain the difference between JDK and JRE, the best is to read the  and consult the diagram:Note that Oracle is not the only one to provide JDKs.The  is the open-source implementation of the Java SE 7 JSR ().\nNow there is almost no difference between the Oracle JDK and the OpenJDK. Last year, Oracle took this decision :\n The differences are stated in this  :Depending on the used version, the VM can differ: OpenJDK is a specific JDK implementation.Java Developer Kit contains tools needed to develop the Java programs, and JRE to run the programs. The tools include compiler (javac.exe), Java application launcher (java.exe), Appletviewer, etc\u2026Compiler converts java code into byte code. Java application launcher opens a JRE, loads the class, and invokes its main method.You need JDK, if at all you want to write your own programs, and to compile them. For running java programs, JRE is sufficient.JRE is targeted for execution of Java files JRE = JVM + Java Packages Classes(like util, math, lang, awt,swing etc)+runtime libraries.JDK is mainly targeted for java development. I.e. You can create a Java file (with the help of Java packages), compile a Java file and run a java file.Java Runtime Environment contains JVM, class libraries, and other supporting files. It does not contain any development tools such as compiler, debugger, etc. Actually JVM runs the program, and it uses the class libraries, and other supporting files provided in JRE. If you want to run any java program, you need to have JRE installed in the systemThe Java Virtual Machine provides a platform-independent way of executing code;\nThat mean compile once in any machine and run it any where(any machine).As we all aware when we compile a Java file, output is not an \u2018exe\u2019 but it\u2019s a \u2018.class\u2019 file. \u2018.class\u2019 file consists of Java byte codes which are understandable by JVM. Java Virtual Machine interprets the byte code into the machine code depending upon the underlying operating system and hardware combination. It is responsible for all the things like garbage collection, array bounds checking, etc\u2026 JVM is platform dependent.The JVM is called \u201cvirtual\u201d because it provides a machine interface that does not depend on the underlying operating system and machine hardware architecture. This independence from hardware and operating system is a cornerstone of the write-once run-anywhere value of Java programs.There are different JVM implementations are there. These may differ in things like performance, reliability, speed, etc. These implementations will differ in those areas where Java specification doesn\u2019t mention how to implement the features, like how the garbage collection process works is JVM dependent, Java spec doesn\u2019t define any specific way to do this.A  is a virtual machine that can execute Java bytecode. It is the code execution component of the Java software platform.The  is an Oracle Corporation product aimed at Java developers. Since the introduction of Java, it has been by far the most widely used Java Software Development Kit (SDK)., is also referred to as the Java Runtime, Runtime Environment is a free and open source implementation of the Java programming language. It is the result of an effort Sun Microsystems began in 2006. The implementation is licensed under the GNU General Public License (GPL) with a linking exception.  (Java Development Kit) : (Java Runtime Environment)Java Runtime Environment contains JVM, class libraries, and other supporting files.\nJRE is targeted for execution of Java files. (Java Virtual Machine)The JVM  depending upon the underlying operating system and hardware combination. It is responsible for all the things like garbage collection, array bounds checking, etc\u2026 Java Virtual Machine provides a platform-independent way of executing code. is the virtual machine Java code executes on is the environment (standard libraries and JVM) required to run Java applications is the JRE with developer tools and documentation is an open-source version of the JDK, unlike the common JDK owned by OracleJava Virtual Machine (JVM)When you download JRE and install on your machine you got all the code required to create JVM. Java Virtual Machine is get created when you run a java program using java command e.g. java HelloWorld. JVM is responsible for converting byte code into machine specific code and that's why you have different JVM for Windows, Linux or Solaris but one JAR can run on all this operating system. Java Virtual machine is at heart of Java programming language and provide several feature to Java programmer including Memory Management and Garbage Collection, Security and other system level services. Java Virtual Machine can be customized e.g we can specify starting memory or maximum memory of heap size located inside JVM at the time of JVM creation. If we supplied invalid argument to java command it may refuse to create Java Virtual Machine by saying \"failed to create Java virtual machine: invalid argument\". In short Java Virtual Machine or JVM is the one who provides Platform independence to Java.Java Development Kit (JDK)JDK is also loosely referred as JRE but its lot more than JRE and it provides all the tools and executable require to compile debug and execute Java Program. Just like JRE, JDK is also platform specific and you need to use separate installer for installing JDK on Linux and Windows. Current Version of JDK is 1.7 which is also referred as Java7 and it contains javac (java compiler) based on programming rules of Java7 and Java which can execute java7 code with new features like String in Switch, fork-join framework or Automatic Resource Management. When you install JDK, installation folder is often referred as JAVA_HOME. All binaries are located inside JAVA_HOME/bin which includes javac, java and other binaries and they must be in your system PATH in order to compile and execute Java programs. For details on Path see how to set PATH for Java in Windows and UNIX.Java Runtime Environment (JRE)Java is every where in browser, in mobile, in TV or in set-top boxes and if you are into Java programming language than you know that Java code which is bundled in JAR (Java archive) file require Java virtual machine JVM to execute it. Now JVM is an executable or program like any other program and you can install that into your machine. You have seen browser often suggesting download JRE to run a Java Applet downloaded from Internet. Various version of JRE are available in java.oracle.com and most of the user who just want to execute Java program inside browser or standalone downloads JRE. All browsers including Internet Explorer, Firefox and Chrome can work with JRE.Another aspect worth mentioning: You will need it for development purposes like the name suggest.For example: a software company will have JDK install in their computer because they will need to develop new software which involves compiling and running their Java programs as well.So we can say that JDK = JRE + JVM.It's needed to run Java programs. You can't compile Java programs with it . For example: a regular computer user who wants to run some online games then will need JRE in his system to run Java programs. As you might know it run the bytecodes. It make Java platform independent because it executes the  file which you get after you compile the Java program regardless of whether you compile it on Windows, Mac or Linux.Well, like I said above. Now JDK is made by different company, one of them which happens to be an open source and free for public use is OpenJDK, while some others are Oracle Corporation's JRockit JDK or IBM JDK.However they all might appear the same to general user. If you are a Java programmer you will need JDK in your system and this package will include JRE and JVM as well but if you are normal user who like to play online games then you will only need JRE and this package will not have JDK in it.In other words JDK is grandfather JRE is father and JVM is their son.Java is the language and includes a strict and strongly typed syntax with which you should be very familiar by now.Java 2 Platform, Standard Edition, also known as J2SE, referred to the platform and included the classes in the java.lang and java.io packages, among others. It was the building block that Java applications were built upon.A Java Virtual Machine, or JVM, is a software virtual machine that runs compiled Java code. Because compiled Java code is merely bytecode, the JVM is responsible for compiling that bytecode to machine code before running it. (This is often called the Just In Time Compiler or JIT Compiler.) The JVM also takes care of memory management so that application code doesn\u2019t have to.The Java Development Kit, or JDK, was and remains the piece of software Java developers use to create Java applications. It contains a Java language compiler, a documentation generator, tools for working with native code, and (typically) the Java source code for the platform to enable debugging platform classes.The Java Runtime Environment, or JRE, was and remains the piece of software end users download to run compiled Java applications. It includes a JVM but does not contain any of the development tools bundled in the JDK. The JDK, however, does contain a JRE. - Compiles java to Byte Code. Consists of debuggers, Compilers etc - Executes the byte code. JVM is the one which makes java platform independent. But JVM varies for platforms   - JRE comprises of JVM along with java runtime libraries to execute java programs. : this actually means the byte code interpreter .It is platform dependent. For eg: in      Windows platform the '' or '' precess is the jvm process. : is a toolkit containing necessary libraries and utilities to develop and execute java program/application: is the execution environment for a java application.ie, it only support runtime dependencies including jvm for compiled program. If we want to compile a java program we need jdk. JVMJVM (Java Virtual Machine) is an abstract machine. It is a specification that provides runtime environment in which java bytecode can be executed.\nJVMs are available for many hardware and software platforms. JREJRE is an acronym for Java Runtime Environment.It is used to provide runtime environment.It is the implementation of JVM.It physically exists.It contains set of libraries + other files that JVM uses at runtime.JDKJDK is an acronym for Java Development Kit.It physically exists.It contains JRE + development tools.Link :- JVM : virtual machine of java. tells machine what to do with the Java Code. You cannot download JVM as is. It comes packaged in some other component.JRE: Some other component referred as above is the JRE. \nIt is JVM+ other jars to create runtime environmenyJDK: contains JRE(which in turn contains JVM). Once you get JDK you need not install JRE and JVM separately. It contains compiler which compiles your .java files to .class files Java Virtual Machine , actually executes the java bytecode.\nIt is the execution block on the JAVA platform. It converts the bytecode to the machine code. Java Runtime Environment , provides the minimum requirements for executing a Java application; it consists of the Java Virtual Machine (JVM), core classes, and supporting files. Java Development Kit, it has all the tools to develop your application software. It is as JRE+JVM  is a free and open source implementation of the Java Platform.In layman terms:- , where JDK is our complete package to work with Java, from creating compiling till running it.On the other hand JRE is just of running of code(Byte Code).Note:- Whether we are installing JDK or JRE, JVM would come bundled with both the packages and JVM is the part where JIT compiler converts the byte code into the machine specific code.Just read the article on In simple words :JVM : A specification which describes the the way/resources to run a java program. Actually executes the byte code and make java platform independent. In doing so, it is different for different platform. JVM for windows cannot work as JVM for UNIX.JRE : Implementation of JVM. (JVM + run time libraries)JDK : JRE + java compiler and other essential tools to build a java program from scratch: The complete package which you need to write and run java code: An independent implementation of JDK for making it much better: Converts Java code into bytecode and provides the specifications which tells how should a Java code be compiled, loaded, verified, checked for errors and executed.: Implementation of the JVM with which some Java libraries are used to Run the programJRE executes the application but JVM reads the instructions line by line so it's interpreter.JDK=JRE+Development ToolsJRE=JVM+Library Classes"},
{"body": "I'm trying to define my own exception class the easiest way, and this is what I'm getting:This is what Java compiler says:I had a feeling that this constructor has to be inherited from , isn't it?No, you don't \"inherit\" non-default constructors, you need to define the one taking a String in your class. Typically you use  in your constructor to invoke your parent constructor. For example, like this:A typical custom exception I'd define is something like this:I even create a template using Eclipse so I don't have to write all the stuff over and over again.If you use the new class dialog in Eclipse you can just set the Superclass field to  and check \"Constructors from superclass\" and it will generate the following:In response to the question below about not calling  in the defualt constructor, Oracle has :Reason for this is explained in the  article of the Java Platform which says: Exception class has two constructors If you inherit from Exception, you have to provide a constructor that takes a String as a parameter (it will contain the error message)."},
{"body": "Is there a way to iterate over Java SparseArray (for Android) ? I used  to easily get values by index. I could not find one.Seems I found the solution. I hadn't properly noticed the  function.So I'll go with something like this:If you don't care about the keys, then  can be used to while iterating through the sparse array to access the values directly.Ooor you just create your own ListIterator:For removing all the elements from  using the above looping leads to .To avoid this Follow the below code to remove all the elements from  using normal loopsSimple as Pie. Just make sure you fetch array size  actually perform the loop.Hope this helps.Here is simple  and  implementations for :If you want to iterate not only a value but also a key:It's useful to create utility methods that return  and :Now you can iterate :The answer is no because  doesn't provide it. As  put it, this thing doesn't provide any interfaces.You could loop from  and skip values that return , but that is about it.As I state in my comment, if you need to iterate use a  instead of a . For example, use a  which iterates in order by the key.The accepted answer has some holes in it. The beauty of the SparseArray is that it allows gaps in the indeces. So, we could have two maps like so, in a SparseArray...Notice the size here would be 2. If we iterate over size, we will only get values for the values mapped to index 0 and index 1. So the mapping with a key of 250 is not accessed. The best way to do this is to iterate over the size of your data set, then check those indeces with a get() on the array. Here is an example with an adapter where I am allowing batch delete of items.I think ideally the SparseArray family would have a getKeys() method, but alas it does not."},
{"body": "I am successfully using this code to send   requests with some parameters via  methodNow I may need to send the parameters (i.e. param1, param2, param3) via  method because they are very long.\nI was thinking to add an extra parameter to that method (i.e. String httpMethod).How can I change the code above as little as possible to be able to send paramters either via  or ?I was hoping that changingtowould have done the trick, but the parameters are still sent via GET method.Has  got any method that would help?\nIs there any helpful Java construct?Any help would be very much appreciated.In a GET request, the parameters are sent as part of the URL.In a POST request, the parameters are sent as a body of the request, after the headers.To do a POST with HttpURLConnection, you need to write the parameters to the connection after you have opened the connection.This code should get you started:Here is a simple example that submits a form then dumps the result page to . Change the URL and the POST params as appropriate, of course:If you want the result as a  instead of directly printed out do:I couldn't get  to actually do the post, so I ended up with this:I find  really cumbersome to use. And you have to write a lot of boilerplate, error prone code. I needed a lightweight wrapper for my Android projects and came out with a library which you can use as well: .The above example could be written like this:You can find a list of alternative libraries on the link provided.I see some other answers have given the alternative, I personally think that intuitively you're doing the right thing ;).  Sorry, at devoxx where several speakers have been ranting about this sort of thing.That's why I personally use Apache's HTTPClient/ libraries to do this sort of work, I find their API to be easier to use than Java's native HTTP support.  YMMV of course! I had the same issue. I wanted to send data via POST.\nI used the following code:I used Jsoup for parse:Try this pattern:i have read above answers and have created a utility class to simplify HTTP request. i hope it will help you.here i sent jsonobject as parameter //jsonobject={\"name\":\"lucifer\",\"pass\":\"abc\"}//serverUrl = \"\" //host=192.168.100.12 Hello pls use this class to improve your post method I took Boann's answer and used it to create a more flexible query string builder that supports lists and arrays, just like php's http_build_query method:Appears that you also have to call \"at least once\" (as well as ) for it to treat it as a POST.So the minimum required code is:You can even use \"GET\" style parameters in the urlString, surprisingly.  Though that might confuse things."},
{"body": " has no method for hasNext. I want to check if the resultSet has any valueis this the correct way That's correct, initially the 's cursor is pointing to before the first row, if the first call to  returns  then there was no data in the .If you use this method, you may have to call  immediately after to reset it, since it has positioned itself past the first row now.It should be noted however, that  below is a more elegant solution to this question. Assuming you are working with a newly returned  whose cursor is pointing before the first row, an easier way to check this is to just call . This avoids having to back-track if the data is to be read.As explained in the documentation, this returns false if the cursor is not before the first record or if .\u00a0you could always do the next up front, and just do a post loop checkYou would usually do something like this:If you want to report an empty set, add a variable counting the items read. If you only need to read a single item, then your code is adequate.That would work if you want to see if there are any rows in the result set yes. Note that  always moves to the next row, so if you are planning on doing any reading from the result set you need to take that into account.Usual usage with ResultSet (when simply reading) is:Which obviously won't work correctly if you invoked  once already to check if the result set was empty, so watch out for that. Although there are methods for \"backing up\", they are not supported for all types of result sets.Best to use ResultSet.next() along with the do {...} while() syntax for this.The \"check for any results\" call ResultSet.next() moves the cursor to the first row, so use the do {...} while() syntax to process that row while continuing to process remaining rows returned by the loop.This way you get to check for any results, while at the same time also processing any results returned.According to the most viable answer the suggestion is to use \"isBeforeFirst()\". .There's a method called \"\". It's less overkill to get the exact same result. You check whether there is something in your \"resultset\" and don't advance your cursor. The documentation states: \"(...) false if there are \".However, there's a difference between \"isBeforeFirst()\" and \"first()\". First generates an exception if done on a resultset from type \"forward only\". Compare the two throw sections: \n\nOkay, basically this means that you should use \"isBeforeFirst\" as long as you have a \"forward only\" type. Otherwise it's less overkill to use \"first()\". To be totally sure of rather the resultset is empty or not regardless of cursor position, I would do something like this: This function will return true if ResultSet is empty, false if not or throw an SQLException if that ResultSet is closed/uninitialized. also returns false for empty result set but since cursor is before first row anyways, this method seems more clear.This is a practical and easy read piece I believe.Because if ResultSet has no raw then  returns false.The best thing for to do is to check the first row so that when you intend to get the data you can avoid the mistake of skipping a row. Something like:    if (!resultSet.first() ) { System.out.println(\"no data\"); }By using resultSet.next() you can easily get the result, whether resultSet containing any value or notIt is better to re execute query because when we call  first row of ResultSet will be executed and after it inside  we'll get result from next line. So I think re-execution of query inside  is the better option. you can do something like thisI've been attempting to set the current row to the first index (dealing with primary keys). I would suggestWhen the ResultSet is populated, it points to before the first row. When setting it to the first row (indicated by ) it will return true denoting it was successfully placed at row 1, or false if the row does not exist. We can extrapolate this towhich sets the current row to position i and will fail if the row doesn't exist. This is just an alternative method toI created the following method to check if a ResultSet is empty.It is very important to have the following considerations: object must be setted to let to ResultSet object go at the end and go back to top.: ResultSet object can shift at the end and go back to top. Further can catch last changes.: We can read the ResultSet object data, but can not updated.I think the easiest way for checking result set is via  under package This will check for null as well as empty result set condition. For more detail information you can refer to the following doc. \nInitially, the result set object (rs) points to the BFR (before first record). Once we use rs.next(), the cursor points to the first record and the rs holds \"true\". Using the while loop you can print all the records of the table. After all the records are retrieved, the cursor moves to ALR (After last record) and it will be set to null. Let us consider that there are 2 records in the table.In short hand, we can also write the condition as while (rs.next()).    "},
{"body": "I just created sample BB app, which can allow to choose the date.After choosing the date, I need to convert that long value to String, so that I can easily store the date value somewhere in database.\nI am new to Java and Blackberry development.How should I convert this long value to String? Also I want to convert back to long from String. I think for that I can use ?See the : If your Long might be null and you don't want to get a 4-letter  string, you might use , like: EDIT:You reverse it using  but in this direction you need to catch Simple and works fine :-)This works:very simple,\njust concatenate the long to a string.1.2.Can convert the long into string object, cool shortcut for converting into string...but use of  is advisableor"},
{"body": "I saw this keyword for the first time and I was wondering if someone could explain to me what it does.A  statement without a label will re-execute from the condition the innermost  or  loop, and from the update expression of the innermost  loop.   It is often used to early-terminate a loop's processing and thereby avoid deeply-nested  statements.  In the following example  will get the next line, without processing the following statement in the loop. With a label,  will re-execute from the loop with the corresponding label, rather than the innermost loop.  This can be used to escape deeply-nested loops, or simply for clarity.  Sometimes  is also used as a placeholder in order to make an empty loop body more clear.The same statement without a label also exists in C and C++.  The equivalent in Perl is .This type of control flow is not recommended, but if you so choose you can also use  to simulate a limited form of .  In the following example the  will re-execute the empty  loop. is kind of like . Are you familiar with ? It's easier to think about them in contrast:Let's see an exampleThis would get the sum of only odd numbers from 1 to 100If you think of the body of a loop as a subroutine,  is sort of like . The same keyword exists in C, and serves the same purpose. Here's a contrived example:This will print out only the odd numbers.Generally, I see  (and ) as a warning that the code  use some refactoring, especially if the  or  loop declaration isn't immediately in sight. The same is true for  in the middle of a method, but for a slightly different reason.As others have already said,  moves along to the next iteration of the loop, while  moves out of the enclosing loop.These can be maintenance timebombs because there is no immediate link between the / and the loop it is continuing/breaking other than context; add an inner loop or move the \"guts\" of the loop into a separate method and you have a hidden effect of the / failing.IMHO, it's best to use them as a measure of last resort, and then to make sure their use is grouped together tightly at the start or end of the loop so that the next developer can  see the \"bounds\" of the loop in one screen., , and  (other than the One True Return at the end of your method) all fall into the general category of \"hidden GOTOs\". They place loop and function control in unexpected places, which then eventually causes bugs.As already mentioned  will skip processing the code below it and until the end of the loop. Then, you are moved to the  and run the next iteration if this condition still holds (or if there is a flag, to the denoted loop's condition).It must be highlighted that in the case of  you are moved to the condition at the bottom after a , not at the beginning of the loop.This is why a lot of people fail to correctly answer what the following code will generate.*If your answer is that  will contain odd numbers only 100%... you are wrong!Consider an If Else condition. A continue statement executes what is there in a condition and gets out of the condition i.e. jumps to next iteration or condition. But a Break leaves the loop. \nConsider the following Program. '    It will print: aa cc Out of the loop. If you use break in place of continue(After if.), it will just . If the condition \"bb\" equals ss is satisfied: \nFor Continue: It goes to next iteration i.e. \"cc\".equals(ss).\nFor Break: It comes out of the loop and prints \"Out of the loop. \""},
{"body": "For some reason, the OK button is not clickable when I try to create an AVD. Does anyone know what I'm doing wrong?Simply because  CPU/ABI says \"No system images installed for this target\". You need to install a system image.In the Android SDK Manager check that you have installed \"ARM EABI v7a System Image\" (for each Android version from 4.0 and on you have to install a system image to be able to run a virtual device)In your case only ARM system image exsits (Android 4.2). If you were running an older version, Intel has provided System Images (Intel x86 ATOM). You can check on the internet to see the comparison in performance between both.In my case (see image below) I haven't installed a System Image for Android 4.2, whereas I have installed ARM and Intel System Images for 4.1.2As long as I don't install the 4.2 System Image I would have the same problem as you. : This recent article  explains how to use/install correctly the intel system images to speed up the emulator.What I show in the picture is for Android 4.2, as it was the original question, but is true for every versions of Android.Of course (as @RedPlanet said), if you are developing for MIPS CPU devices you have to install the \"MIPS System Image\".Finally, as @SeanJA said,  to see the new installed images. But for me, I always restart a software which I updated to be sure it takes into account all the modifications, and I assume it is a good practice to do so.  Had to restart the Eclipse after completing the installation of ARM EABI v7a system image.This can happen when:For Ubuntu and running android-studio run to install the packages (these are not installed by default):I had the same problem while creating AVD with 4.2.2 images, I resolved it by doing the following :Hope this helps.  I had to move the folders inside a folder named \"default\" to the android-## folder so Eclipse could see the images.There is a new possible error for this one related to the latest Android Wear technology.  I was trying to get an emulator started for the wear SDK in preparation for next week.  The API level only supports it in the latest build of 4.4.2 KitKat.So if you are using something such as the wearable, it starts the default off still in Eclipse as 2.3.3 Gingerbread.  Be sure that your target matches the lowest possible supported target.  For the wearables its the latest 19 KitKat.I want to update this question with a screenshot of a recent Android Studio. It took a bit of poking around to find where to install new system images.You get to the SDK Manager through one of two paths.\nOption 1. Tools > Android > SDK Manager\nOption 2. Android Studio > Preferences > Appearance & Behavior > System Settings > Android SDK (This is for Mac; adapt for others.)In the pane \"SDK Platforms,\" check the \"Show Packages\" box to see the system images.Select the ones you want, click \"Apply\" and voil\u00e0! "},
{"body": "Recently I read through this\n. The document is all about defining  and  effectively and correctly, but I am not able to figure out why we need to override these two methods. How can I take the decision to implement these method efficiently?Joshua Bloch says on Effective JavaLet's try to understand it with an example of what would happen if we override  without overriding  and attempt to use a .Say we have a class like this and that two objects of  are equal if their  is equal (with  and  generated by eclipse)If only  is overriden, then when you call  first will hash to some bucket and when you call  it will hash to some other bucket (as they have a different ). So, although they are equal, as they don't hash to the same bucket, the map can't realize it and both of them stay in the map.Although it is not necessary to override  if we override , let's see what would happen in this particular case where we know that two objects of  are equal if their  is equal but we do not override .Imagine you have thisIf you only override  then when you call  it takes first, calculates its  and stores it in a given bucket. Then when you call  it should replace first with second  as per the  because they are equal (according to the business requirement).But the problem is that equals was not redefined, so when the map hashes  and iterates through the bucket looking if there is an object  such that  is true it won't find any as  will be .Hope it was clearCollections such as HashMap and HashSet use the hashcode value of an object to determine how the object should be stored in the collection, and the hashcode is used again to help locate the object\nin the collection.Hashing retrieval is a two-step process.here is a small example why we should overrride equals() and hashcode().Consider an Employee class which has two fields age and name.Now create a class, insert Employee object to a HashSet and test whether that object is present or not.Now remove the commented line from hashcode() and execute the same you will find below resultNow can you see why if two objects are considered equal, their hashcodes must\nalso be equal? Otherwise, you'd never be able to find the object since the default\nhashcode method in class Object virtually always comes up with a unique number\nfor each object, even if the equals() method is overridden in such a way that two\nor more objects are considered equal. It doesn't matter how equal the objects are if\ntheir hashcodes don't reflect that. So one more time: If two objects are equal, their\nhashcodes must be equal as well.By defining  and  consistently, you can improve the usability of your classes as keys in hash-based collections. As the API doc for hashCode explains: \"This method is supported for the benefit of hashtables such as those provided by .\" The best answer to your question about how to implement these methods efficiently is suggesting you to read Chapter 3 of .Simply put, the equals-method in Object check for reference equality, where as two instances of your class could still be semantically equal when the properties are equal. This is for instance important when putting your objects into a container that utilizes equals and hashcode, like  and . Let's say we have a class like:We create two instances with the same :Without overriding equals we are getting:Correct? Well maybe, if this is what you want. But let's say we want objects with the same id to be the same object, regardless if it's two different instances. We override the equals (and hashcode):As for implementing equals and hashcode I can recommend using Ok, Let me explain the concept in very simple words.Firstly from a broader perspective we have collections,and hashmap is one of the datastructure in the collections.To understand why we have to override the both equals and hashcode method, if need to first understand what is hashmap and what is does.A hashmap is a datastructure which stores key value pairs of data in array fashion. Lets say a[], where each element in 'a' is a key value pair.Also each index in the above array can be linked list thereby having more than one values at one index.Now why is a hashmap used?\nIf we have to search among  a large array then searching through each if them will not be efficient, so what hash technique tells us that lets pre process the array with some logic and group the elements based on that logic i.e. Hashingeg: we have array 1,2,3,4,5,6,7,8,9,10,11 and we apply a hash function mod 10 so 1,11 will be grouped in together. So if we had to search for 11 in previous array then we would have to iterate the complete array but when we group it we limit our scope of iteration thereby improving speed. That datastructure used to store all the above information can be thought of as a 2d array for simplicityNow apart from the above hashmap also tells that it wont add any Duplicates in it. And this is the main reason why we have to override the equals and hashcodeSo when its said that explain the internal working of hashmap , we need to find what methods the hashmap has and how does it follow the above rules which i explained aboveso the hashmap has method called as put(K,V) , and according to hashmap it should follow the above rules of efficiently distributing the array and not adding any duplicatesso what put does is that it will first generate the hashcode for the given key to decide which index the value should go in.if nothing is present at that index then the new value will be added over there, if something is already present over there then the new value should be added after the end of the linked list at that index. but remember no duplicates should be added as per the desired behavior of the hashmap. so lets say you have two Integer objects aa=11,bb=11.\nas every object derived from the object class, the default implementation for comparing two objects is that it compares the reference and not values inside the object. So in the above case both though semantically equal will fail the equality test, and possibility that two objects which same hashcode and same values will exists thereby creating duplicates. If we override then we could avoid adding duplicates.\nYou could also refer to  :If you only override hash-code method nothing will happen. Because it always return new  for each object  as an Object class. :If you only override equal method,  is true it means the  of a and b must be same but not happen. Because you did not override  method.Note :   method of Object class always return new  for each object.So when you need to use your object in the hashing based collection, must override both  and .Because if you do not override them you will be use the default implentation in Object.Given that instance equality and hascode values generally require knowledge of what makes up an object they generally will need to be redefined in your class to have any tangible meaning.In order to use our own class objects as keys in collections like HashMap, Hashtable etc.. , we should override both methods ( hashCode() and equals() ) by having an awareness on internal working of collection. Otherwise, it leads to wrong results which we are not expected.They are methods of java.lang.Object class which is the super class of all the classes (custom classes as well and others defined in java API).This method simply checks if two object references x and y refer to the same object. i.e. It checks if x == y. for any reference value x, x.equals(x) should return true. for any reference values x and y, x.equals(y) should return true if and only if y.equals(x) returns true. for any reference values x, y, and z, if x.equals(y) returns true and y.equals(z) returns true, then x.equals(z) should return true. for any reference values x and y, multiple invocations of x.equals(y) consistently return true or consistently return false, provided no information used in equals comparisons on the object is modified.This method returns the hash code value for the object on which this method is invoked. This method returns the hash code value as an integer and is supported for the benefit of hashing based collection classes such as Hashtable, HashMap, HashSet etc. This method must be overridden in every class that overrides the equals method.Whenever it is invoked on the same object more than once during an execution of a Java application, the hashCode method must consistently return the same integer, provided no information used in equals comparisons on the object is modified. This integer need not remain consistent from one execution of an application to another execution of the same application.If two objects are equal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce the same integer result.It is not required that if two objects are unequal according to the equals(java.lang.Object) method, then calling the hashCode method on each of the two objects must produce distinct integer results. However, the programmer should be aware that producing distinct integer results for unequal objects may improve the performance of hashtables.Resources: It is useful when using . The following is an excerpt from the :Joshua Bloch said it better than me in , so just Java puts a rule that So, if in our class we override equals we should override hashcode method also to fallow this rule.\nThese both methods  and  are used in  to store values as key-value pair.If we do override one and not the other , there is a possibility that the hashtable may not work as we want, if we use such object as key.Consider collection of balls in a bucket all in black color. Your Job is to color those balls as follows and use it for appropriate game,For Tennis - Yellow, Red.\nFor Cricket - WhiteNow bucket has balls in three colors Yellow, Red and White. And that now Coloring the balls - Hashing.\nChoosing the ball for game - Equals.If you did the coloring and some one chooses the ball for either cricket or tennis they wont mind the color!!!I was looking into the explanation \" If you only override hashCode then when you call  it takes first, calculates its hashCode and stores it in a given bucket. Then when you call  it should replace first with second as per the Map Documentation because they are equal (according to our definition).\" :I think 2nd time when we are adding in  then it should be the 'second' object like Assume you have class (A) that aggregates two other (B) (C), and you need to store instances of (A) inside hashtable. Default implementation only allows distinguishing of instances, but not by (B) and (C). So two instances of A could be equal, but default wouldn't allow you to compare them in correct way.  You can find a good tutorial here regarding significance of equals and hashcode methods.\n\nAdding to @Lombo 's answerThe default implementation of Object's equals() iswhich means two objects will be considered equal only if they have the same memory address which will be true only if you are\ncomparing an object with itself.But you might want to consider two objects the same if they have the same value for one\nor more of their properties (Refer the example given in @Lombo 's answer). So you will override  in these situations and you would give your own conditions for equality.Well.As long as you don't use  on your user-defined class,it is fine.\nBut some time in the future you might want to use  or  and if you don't  and , these Hash based collection won't work as intended.First of all,HashMap checks if the hashCode of  is the same as .\nOnly if the values are the same,it will proceed to check the equality in the same bucket.But here the hashCode is different for these 2 objects (because they have different memory address-from default implementation).\nHence it will not even care to check for equality.If you have a breakpoint inside your overridden equals() method,it wouldn't step in if they have different hashCodes.\n checks  and only if they are the same it would call your  method.Then you are missing the point of Hash based Collections.\nConsider the following :The following are the keys stored in the form of buckets.Say,you want to know if the map contains the key 10.\nWould you want to search all the buckets? or Would you want to search only one bucket?Based on the hashCode,you would identify that if 10 is present,it must be present in Bucket 1.\nSo only Bucket 1 will be searched !!In order to identity differences between two objects we need to override equals method.   hashCode produces integer in order to store object in data structures().Assume we have override equals method of Customer as above, \ncustomer1.equals(customer2);  // returns true by our own logicWhile working with data structure when we store object in buckets. If we use built-in hash technique, for above two customers it generates two different hashcode. So we are storing the same identical object in two different places. To avoid this kind of issues we should override the hashCode method also based on the following principles.  Both the methods are defined in Object class. And both are in its simplest implementation. So when you need you want add some more implementation to these methods then you have override in  your class. For Ex: eqauls() method in object only checks its equality on the reference. So if you need compare its state as well then you can override that as it is done in String class.The methods equals and hashcode are defined in the object class. By default if the equals method returns true, then the system will go further and check the value of the hash code. If the hash code of the 2 objects is also same only then the objects will be considered as same. So if you override only equals method, then even though the overridden equals method indicates 2 objects to be equal , the system defined hashcode may not indicate that the 2 objects are equal. So we need to override hash code as well.Please check the below link for proper and easy explanation:\nThe reason behind this:\nWhen your object fields can be null, implementing Object.equals can be a pain, because you have to check separately for null. Using Objects.equal lets you perform equals checks in a null-sensitive way, without risking a NullPointerException.\nif Both are overridden,Map<> if equals is not overriddenMap<> If hashCode is not overriddenMap<> HashCode Equal ContractIn the example below, if you comment out the override for equals or hashcode in the Person class, this code will fail to look up Tom's order. Using the default implementation of hashcode can cause failures in hashtable lookups.What I have below is a simplified code that pulls up people's order by Person. Person is being used as a key in the hashtable. method is used to get a unique integer for given object. This integer is used for determining the bucket location, when this object needs to be stored in some ,  like data structure. By default, Object\u2019s  method returns and integer representation of memory address where object is stored.The  method of objects is used when we insert them into a ,  or . More about  on Wikipedia.org for reference.To insert any entry in map data structure, we need both key and value. If both key and values are user define data types, the  of the key will be determine where to store the object internally. When require to lookup the object from the map also, the hash code of the key will be determine where to search for the object.The hash code only points to a certain \"area\" (or list, bucket etc) internally. Since different key objects could potentially have the same hash code, the hash code itself is no guarantee that the right key is found. The  then iterates this area (all keys with the same hash code) and uses the key's  method to find the right key. Once the right key is found, the object stored for that key is returned.So, as we can see, a combination of the  and  methods are used when storing and when looking up objects in a .NOTES: \nThere is no relationship between \"equals()\" and \"hashCode()\",\nbut the Java Doc says:You do this (override both equals() and hashCode() methods) for hash-code-based collections, like: HashMap, HashSet, etc.IMHO, it's as per the rule says - If two objects are equal then they should have same hash, i.e., equal objects should produce equal hash values.Given above, default equals() in Object is == which does comparison on the address, hashCode() returns the address in integer(hash on actual address) which is again distinct for distinct Object.If you need to use the custom Objects in the Hash based collections, you need to override both equals() and hashCode(), example If I want to maintain the HashSet of the Employee Objects, if I don't use stronger hashCode and equals I may endup overriding the two different Employee Objects, this happen when I use the age as the hashCode(), however I should be using the unique value which can be the Employee ID.[from Effective Java, by Joshua Bloch?]Isn't this the wrong way round?  Overriding hashCode likely implies you're writing a hash-key class, but overriding equals certainly does not. There are many classes that are not used as hash-keys, but do want a logical-equality-testing method for some other reason. If you choose \"equals\" for it, you may then be mandated to write a hashCode implementation by overzealous application of this rule. All that achieves is adding untested code in the codebase, an evil waiting to trip someone up in the future. Also writing code you don't need is anti-agile. It's just wrong (and an ide generated one will probably be incompatible with your hand-crafted equals). Surely they should have mandated an Interface on objects written to be used as keys? Regardless, Object should never have provided default hashCode() and equals() imho. It's probably encouraged many broken hash collections.But anyway, I think the \"rule\" is written back to front. In the meantime, I'll keep avoiding using \"equals\" for equality testing methods :-("},
{"body": "I have a bunch of .keystore files and need to find one with specific CN and alias. Is there a way to do it with keytool, jarsigner or some other tool? I found a way to check if specific keystore was used to sign a specific apk, but I also need to get the alias and certificate name in each of the files.You can run the following command to list the content of your keystore file:If you are looking for a specific alias, you can also specify it in the command:If the alias is not found, it will display an exception:In order to get all the details I had to add the -v option to romaintaz answer:You can run from Java code.Certificate class holds all information about the keystore.@prateek Hope this is what you looking for!  open source visual tool to manage keystores.In a bash-like environment you can use:This command consist of 3 parts. As stated above, the  part will list all trusted certificates with all the details and that's why the  part comes to filter only the alias information among those details. And finally in the  part you can search for a specific alias (or part of it). The  turns the case insensitive mode on. Thus the given command will yield all aliases containing the pattern 'foo', f.e. foo, 123_FOO, fooBar, etc. For more information .This will list all certificates:"},
{"body": "Is there a way to declare an unsigned int in Java?Or the question may be framed as this as well:\nWhat is the Java equivalent of unsigned?Java has no .You can define a  instead of an  if you need to store large values but there's no way to exclude negative values.However, as of Java SE 8, there are a few new methods in the  class which allow you to use the  data type :Note that  variables are still signed when declared but unsigned arithmetic is now possible by using those methods in the  class.There is an Whether a value in an int is signed or unsigned depends on how the bits are interpreted - Java interprets bits as a signed value (it doesn't have unsigned primitives).If you have an int that you want to interpret as an unsigned value (e.g. you read an int from a DataInputStream that you know contains an unsigned value) then you can do the following trick.Note, that it is important that the hex literal is a long literal, not an int literal - hence the 'l' at the end.We needed unsigned numbers to model MySQL's unsigned , , ,  in , which is why we have created , a minimalistic library offering wrapper types for unsigned integer numbers in Java. Example:All of these types extend  and can be converted into higher-order primitive types and . Hope this helps.(Disclaimer: I work for the company behind these libraries)For unsigned numbers you can use these classes from :They support various operations:The thing that seems missing at the moment are byte shift operators. If you need those you can use BigInteger from Java.Perhaps this is what you meant?Use  for 16 bit unsigned integers.You can use the Math.abs(number) function. It returns a positive number."},
{"body": "What is ? Is  an instance of anything? What set does  belong to?How is it represented in the memory?No, there is no type which  is an .This means that for any type  and , for any , where ,  is always .As the JLS quote above says, in practice you can simply pretend that it's \"merely a special literal that can be of any reference type\".In Java,  (this isn't always the case in other languages). Note also that by contract, it also has this special property (from ):It is also the  (for variables that have them) for all reference types:How this is used varies. You can use it to enable what is called  of fields, where a field would have its initial value of  until it's actually used, where it's replaced by the \"real\" value (which may be expensive to compute).There are also other uses. Let's take a real example from :This is a very common use pattern:  is used to denote non-existence of an object.Here's another usage example, this time from :So here,  would return  for each line, until it finally returns a  to signify the end. This allows you to process each line as follows:One can design the API so that the termination condition doesn't depend on  returning , but one can see that this design has the benefit of making things concise. Note that there is no problem with empty lines, because an empty line .Let's take another example, this time from :Here we start to see how using  can complicate things. The first statement says that if the key isn't mapped,  is returned. The second statement says that even if the key is mapped,  can  be returned.In contrast,  keeps things simpler by not permitting  keys and values; its , if returns , unambiguously means that the key isn't mapped.You can read through the rest of the APIs and find where and how  is used. Do keep in mind that they aren't always the  examples.Generally speaking,  are used as a special value to signify:In Java? None of your concern. And it's best kept that way.This is now borderline subjective. Some people say that  causes many programmer errors that could've been avoided. Some say that in a language that catches  like Java, it's good to use it because you will fail-fast on programmer errors. Some people avoid  by using , etc.This is a huge topic on its own, so it's best discussed as answer to another question.I will end this with a quote from the inventor of  himself,  (of quicksort fame):The  goes deeper; it's a recommended watch.No.  That is why  will return  for all classes .  (Don't be fooled by the fact that you can assign  to a variable whose type is an object type.  Strictly speaking, the assignment involves an implicit type conversion; see below.)It is the one and only member of the null type, where the null type is defined as follows:  See above.  In some contexts,  is used to denote \"no object\" or \"unknown\" or \"unavailable\", but these meanings are application specific.That is implementation specific, and you won't be able to see the representation of  in a pure Java program.  (But  is represented as a zero machine address / pointer in most if not all Java implementations.)It is nothing.No as it is nothing It can't be instance of any thing.No any setIf some reference points to it like:In heap memory some space assigned to new created object. And o will point to that assigned space in memory.Now This means now o will not point to that memory space of object.No it's not the instance of anything, instanceof will always be false.The null keyword is a literal that represents a null reference, . null is the default value of reference-type variables.Also maybe have a look at Null in Java(tm)In C and C++, \"NULL\" is a constant defined in a header file, with a value like:or:or:depending on the compiler and memory model options. NULL is not, strictly speaking, part of C/C++ itself.In Java(tm), \"null\" is not a keyword, but a special literal of the null type. It can be cast to any reference type, but not to any primitive type such as int or boolean. The null literal doesn't necessarily have value zero. And it is impossible to cast to the null type or declare a variable of this type.Null is not an instance of any class.However, you can assign null to variables of any (object or array) type: is a special value that is not an instance of any class. This is illustrated by the following program: is special value, it is not instance of anything. For obviously reason it cannot be  anything. has direct JVM support: three instructions are used to implement it: then mentions the effects of  on other instructions: it throws a  for many of them. also mentions  in generic terms:There are two major categories of types in Java:  and . Variables declared of a primitive type store values; variables declared of a reference type store references. In this case, the initialization statement declares a variables \u201cx\u201d. \u201cx\u201d stores String reference. It is  here. First of all, null is not a valid object instance, so there is no memory allocated for it. It is simply a value that indicates that the object reference is not currently referring to an object.An interesting way to see null in java in my opinion is to see it as something that DOES NOT denote an absence of information but simply as a literal value that can be assigned to a reference of any type. If you think about it if it denoted absence of information then for a1==a2 to be true doesn't make sense (in case they were both assigned a value of null) as they could really could be pointing to ANY object (we simply don't know what objects they should be pointing to)... By the way null == null returns true in java. If java e.g. would be like SQL:1999 then null==null would return unknown (a boolean value in SQL:1999 can take three values : true,false and unknown but in practise unknown is implemented as null in real systems)... "},
{"body": "I have;Is there a (easy) way to retrieve the generic type of the list?If those are actually fields of a certain class, then you can get them with a little help of reflection:You can also do that for parameter types and return type of methods.But if they're inside the same scope of the class/method where you need to know about them, then there's no point of knowing them, because you already have declared them yourself.Short answer: no.This is probably a duplicate, can't find an appropriate one right now.Java uses something called type erasure, which means at runtime both objects are equivalent. The compiler knows the lists contain integers or strings, and as such can maintain a type safe environment. This information is lost (on an object instance basis) at runtime, and the list only contain 'Objects'.You CAN find out a little about the class, what types it might be parametrized by, but normally this is just anything that extends \"Object\", i.e. anything. If you define a type asAClass.class will only contain the fact that the parameter A is bounded by MyClass, but more than that, there's no way to tell.You can do the same for method parameters as well:If you need to get the generic type of a returned type, I used this approach when I needed to find methods in a class which returned a  and then access their generic types:This outputs:Expanding on Steve K's answer:At runtime, no, you can't.However via reflection the type parameters  accessible. TryThe method  returns a Type object. In this case, it will be an instance of , which in turn has methods  (which will contain , in this case) and , which will return an array (in this case, of length one, containing either  or ).The generic type of a collection should only matter if it actually has objects in it, right? So isn't it easier to just do:There's no such thing as a generic type in runtime, but the objects inside at runtime are guaranteed to be the same type as the declared generic, so it's easy enough just to test the item's class before we process it.For finding generic type of one field:As others have said, the only correct answer is no, the type has been erased.If the list has a non-zero number of elements, you could investigate the type of the first element ( using it's getClass method, for instance ). That won't tell you the generic type of the list, but it would be reasonable to assume that the generic type was some superclass of the types in the list.I wouldn't advocate the approach, but in a bind it might be useful.Generally impossible, because  and  share the same runtime class.You might be able to reflect on the declared type of the field holding the list, though (if the declared type does not itself refer to a type parameter whose value you don't know).The type is erased so you will not be able to. See  and "},
{"body": "What is the best way of searching the whole classpath for an annotated class?I'm doing a library and I want to allow the users to annotate their classes, so when the Web application starts I need to scan the whole classpath for certain annotation.Do you know a library or a Java facility to do this?Edit: I'm thinking about something like the new functionality for Java EE 5 Web Services or EJB's. You annotate your class with  or  and the system finds these classes while loading so they are accessible remotely.Use  APIAnd another solution is .Quick review: I just released an uber-fast and lightweight classpath scanner  that does not call the classloader to load classes on the classpath in order to determine subclasses, superclasses, annotations etc., but rather reads the classfile binary headers directly (inspired by, but simpler than, rmueller's classpath scanner, linked in another comment).My classpath scanner can find classes on the classpath that extend a given superclass, that implement a given interface, or that have a given class annotation, and can find files within the classpath of any type whose path matches a given regular expression.Here is an example of usage:The scanner also records the latest last-modified timestamp of any file or directory encountered, and you can see if that latest last-modified timestamp has increased (indicating that something on the classpath has been updated) by calling:This can be used to enable dynamic class-reloading if something on the classpath is updated, for example to support hot-replace of route handler classes in a webserver. The above call is several times faster than the original call to scan(), since only modification timestamps need to be checked.If you want a really  (no dependencies, simple API, 15 kb jar file) and  solution, take a look at  found at  Disclaimer: I am the author.You can use Java Pluggable Annotation Processing API to write annotation processor which will be executed during the compilation process and will collect all annotated classes and build the index file for runtime use.This is the fastest way possible to do annotated class discovery because you don't need to scan your classpath at runtime, which is usually very slow operation. Also this approach works with any classloader and not only with URLClassLoaders usually supported by runtime scanners.The above mechanism is already implemented in  library.To use it annotate your custom annotation with  meta-annotation. This will create at compile time an index file: META-INF/annotations/com/test/YourCustomAnnotation listing all annotated classes. You can acccess the index at runtime by executing:Use the , or  if you are not in Java 6.Perhaps an annotation processor could produce the necessary files under META-INF/services at compile-time.Try .It can be used to search the classpath or your web application lib directory for specific annotations.You might want to use  Slightly offtopic, but Spring also does something similar, using , which you could perhaps study the source code of?I'm not sure if it will help you or not, but you could look into the apache commons-discovery project.With Spring you can also just write the following using AnnotationUtils class. i.e.:For more details and all different methods check official docs: \nJava does not have \"Discovery\".  The only way I know of is to scan the directory that the .class files should be in, parse the names and use that.  Horribly ugly, maybe there is a better package these days--I haven't looked in a few years.Usually this problem used to be addressed by including a properties file or a .xml file with the classnames in it.I'd be interested in hearing a better answer as well.Google  seems to be much faster than Spring. Found this feature request that adresses this difference: This is a reason to use Reflections as startup time of my application is really important during development. Reflections seems also to be very easy to use for my use case (find all implementers of an interface).The Classloader API doesn't have an \"enumerate\" method, because class loading is an \"on-demand\" activity -- you usually have thousands of classes in your classpath, only a fraction of which will ever be needed (the rt.jar alone is 48MB nowadays!).So, even if you  enumerate all classes, this would be very time- and memory-consuming. The simple approach is to list the concerned classes in a setup file (xml or whatever suits your fancy); if you want to do this automatically, restrict yourself to one JAR or one class directory. If you want a Scala library, use Sclasner:\n"},
{"body": "Date.getTime() returns milliseconds since Jan 1, 1970. Unixtime is seconds since Jan 1, 1970. I don't usually code in java, but I'm working on some bug fixes. I have:Is there a better way to get unixtime in java?Based on John M's suggestion, I ended up with:Avoid the Date object creation w/ .  A divide by 1000 gets you to Unix epoch.As mentioned in a comment, you typically want a primitive long (lower-case-l long) not a boxed object long (capital-L Long) for the unixTime variable's type.Java 8 added a new API for working with dates and times. \nWith Java 8 you can use returns an  that represents the current system time. With  you get the epoch seconds (unix time) from the ."},
{"body": "How do I convert  into  in Java?Of course, I'm interested in any other answer than doing it in a loop, item by item. But if there's no other answer, I'll pick that one as the best to show the fact that this functionality is not part of Java.There is no shortcut for converting from  to  as  does not deal with boxing and will just create a  which is not what you want. You have to make a utility method.Also from ... com.google.common.primitives.Ints:in Java 8 you can do thisI'll add another answer with a different method; no loop but an anonymous class that will utilize the autoboxing features:Arrays.asList will not work as some of the other answers expect.This code will  create a list of 10 integers. It will print , not :This will create a list of integers:If you already have the array of ints, there is not quick way to convert, you're better off with the loop.On the other hand, if your array has Objects, not primitives in it, Arrays.asList will work:The smallest piece of code would be:where ArrayUtils comes from commons-lang :)In Java 8 with stream:or with CollectorsIt's also worth checking out , which was closed with reason \"Not a defect\" and the following text:\"Autoboxing of entire arrays is not specified behavior, for good reason.\nIt can be prohibitively expensive for large arrays.\"give a try to this class:testcase:The best shot:Examples:Here is a generic way to convert array to ArrayListUsageIf you're open to using a third party library, this will work in :Note: I am a committer for ."},
{"body": "I need to determine the current year in Java as an integer. I would like to be able to use this value as a counter that I can, for example, use to run from now until a specified year in the past (i.e. my value starts at 2008, and I have a \"firstYearOfData\" value that is set to 1994. I can now run my process from 2008 back to 1994). I could just use java.util.Date(), but it is deprecated.Not sure if this meets with the criteria of not setting up a new Calendar?  (Why the opposition to doing so?)Using Java 8's time API (assuming you are happy to get the year in your system's default time zone), you could use :This simplest (using Calendar, sorry) is:There is also the new , as well as The easiest way is to get the year from Calendar.If you want the year of any date object, I used the following method:If your application is making heavy use of Date and Calendar objects, you really should use Joda Time, because  is mutable.  has performance problems when its fields get updated, and is clunky for datetime arithmetic. As some people answered above:If you want to use the variable later, better use:If you need the year for just a condition you better use:For example using it in a do while that checks introduced year is not less than the current year-200 or more than the current year (Could be birth year): by  wisely shows how to use the new  in Java 8. But that answer fails to address the critical issue of time zone in determining a date.That code depends on the JVM's current default time zone. The default zone is used in determining what today\u2019s date is. Remember, for example, that in the moment after midnight in Paris the date in Montr\u00e9al is still 'yesterday'. So your results may vary by what machine it runs on, a user/admin changing the host OS time zone, or any Java code  changing the JVM's current default. Better to specify the time zone.By the way, always use . Never use the 3-4 letter codes that are neither standardized nor unique.Example in java.time of Java 8.Some idea as above, but using the  2.7 library.If your goal is to jump a year at a time, no need to extract the year number. Both Joda-Time and java.time have methods for adding/subtracting a year at a time. And those methods are smart, handling Daylight Saving Time and other anomalies.Example in Joda-Time 2.7.You can also use Java 8's :That's how I used, simple and easiest wayYou can also use 2 methods from java.time.YearMonth( Since Java 8 ):I use special functions in my library to work with days/month/year ints -You can do the whole thing using Integer math without needing to instantiate a calendar:May be off for an hour or two at new year but I don't get the impression that is an issue?"},
{"body": "I'm working on my usual projects on Eclipse, it's a J2EE application, made with Spring, Hibernate and so on. I'm using Tomcat 7 for this (no particular reason, I don't exploit any new feature, I just wanted to try that). Every time I debug my application, it happens that Eclipse debugger pops out like it has reached a breakpoint, but it is not the case, in fact it stops on a Java source file that is . There is no stack trace on the console, it just stops. Then if I click on resume it goes on and the app works perfectly. This is what shows in the debugger window:I really can't explain this, because I'm not using  at all. Must be something from Tomcat, Hibernate or Spring. It's very annoying because I always have to resume during debugging.Any clues?The posted stack trace indicates that a RuntimeException was encountered in a Daemon thread. This is typically uncaught at runtime, unless the original developer caught and handled the exception.Typically, the debugger in Eclipse is configured to suspend execution at the location where the exception was thrown, on all uncaught exceptions. Note that the exception might be handled later, lower down in the stack frame and might not lead to the thread being terminated. This would be cause of the behavior observed. is straightforward:\nGo to  >  >  >  and uncheck .There's a more specific solution, which prevents Eclipse breaking on s thrown only from a given class.This behavior is triggered by tomcat when a webapp is reloaded. It's part of tomcat  that (among other things) forces the renewal of its threads.This is now fixed from versions 7.0.54 and 8.0.6 of tomcat :\nI have noticed that this often occurs after modifying server files (jsp or java) and STS has trouble reloading the application.This usually leads to restarting the server in order to get it to get the changes synchronized. After introducing JRebel - it appears to have gone away. So, I would like to think it is a reproducible issue in STS when hotswapping code in debug mode. By removing the native hotswapping, it eliminates the issue with it breaking inside the ThreadPoolExecutor class. "},
{"body": "I need to get a  out of a , but I don't know how to do it. The following fails:How can I fix it so that it works?Use the  method taking a typed array argument of the same size.A different size can also, but that would force the  method to create a new array to return instead of reusing the provided argument, which may end up to be less efficient. See also .Use   method:In Java 8 we can use streams API:We can also make use of the overloaded version of  which takes  as:The purpose of the generator function here is to take an integer (size of desired array) and produce an array of desired size. I personally prefer the former approach using method reference than the later one using lambda expression.Guava style:more info: "},
{"body": "How do I get my project's runtime dependencies copied into the  folder?  As it is right now, after  the  folder contains only my project's jar, but none of the runtime dependencies.This works for me:The best approach depends on what you want to do:Works for me with dependencies directory created in target folder. Like it!Take a look at the , specifically, the .  Take a look at  under the heading .  Set the  configuration property to ${basedir}/target/lib (I believe, you'll have to test).Hope this helps.A simple and elegant solution for the case where one needs to copy the dependencies to a target directory without using any other phases of maven (I found this very useful when working with Vaadin).Complete pom example:Then run The jar file dependencies can be found in Try something like this:If you want to do this on an occasional basis (and thus don't want to change your POM), try this command-line:If you omit the , the dependences are placed in .If you want to deliver a bundle of your application jar, together with all it's dependencies and some scripts to invoke the MainClass, look at the .The following configuration will generate scripts for Window and Linux to launch the application (with a generated path referencing all the dependency jars, download all dependencies (into a lib folder below target/appassembler). The  can then be used to package the whole appassembler directory to a zip which is installed/deployed along with the jar to the repository.The assembly descriptor (in src/main/assembly) to package the direcotry as a zip would be:If you make your project a war or ear type maven will copy the dependencies.You can use the the  to create an uber jar in which you can bundle all your 3rd party dependencies.supposinghere ist what worked for me:Just to spell out what has already been said in brief. I wanted to create an executable JAR file that included my dependencies along with my code. This worked for me:(1) In the pom, under <build><plugins>, I included:(2) Running mvn compile assembly:assembly produced the desired my-project-0.1-SNAPSHOT-jar-with-dependencies.jar in the project's target directory.(3) I ran the JAR with java -jar my-project-0.1-SNAPSHOT-jar-with-dependencies.jarIt's a heavy solution for embedding heavy dependencies, but Maven's  does the trick for me.  @ should work, although for simpler cases you should only need this excerpt from the : If you're having problems related to dependencies not appearing in the WEB-INF/lib file when running on a Tomcat server in Eclipse, take a look at this:You simply had to add the Maven Dependencies in Project Properties > Deployment Assembly."},
{"body": "I upgraded from Java 1.6 to Java 1.7 today.\nSince then an error occur when I try to establish a connection to my webserver over SSL:Here is the code:Its only a test project thats why I allow and use untrusted certificates with the code:I sucessfully tried to connect to .\nwhere is my fault?Thanks.Java 7 introduced SNI support which is enabled by default. I have found out that certain misconfigured servers send an \"Unrecognized Name\" warning in the SSL handshake which is ignored by most clients... except for Java. As  mentioned, the Oracle engineers refuse to \"fix\" this bug/feature.As workaround, they suggest to set the  property. To allow your programs to work without re-compiling, run your app as:The property can also be set in the Java code, but it must be set . Once the SSL library has loaded, you can change the property, but it . To disable SNI on runtime (with the aforementioned limitations), use:The disadvantage of setting this flag is that SNI is disabled everywhere in the application. In order to make use of SNI and still support misconfigured servers:For the Webscarab SSL proxy,  implements the fall-back setup.I had what I believe the same issue is.\nI found that I needed to adjust the Apache configuration to include a ServerName or ServerAlias for the host.This code failed:And this code worked:Wireshark revealed that during the TSL/SSL Hello the warning\nAlert (Level: Warning, Description: Unrecognized Name), Server Hello\nWas being sent from the server to the client.\nIt was only a warning, however, Java 7.1 then responded immediately back with a \"Fatal, Description: Unexpected Message\", which I assume means the Java SSL libraries don't like to see the warning of unrecognized name.From the Wiki on Transport Layer Security (TLS):112 Unrecognized name   warning TLS only; client's Server Name Indicator specified a hostname not supported by the serverThis led me to look at my Apache config files and I found that if I added a ServerName or ServerAlias for the name sent from the client/java side, it worked correctly without any errors.You can disable sending SNI records with the System property jsse.enableSNIExtension=false. If you can change the code it helps to use  (with no host parameter or with a connected socket). In this case it will not send a server_name indication.Instead of relying on the default virtual host mechanism in apache, you can define one last catchall virtualhost that uses an arbitrary ServerName and a wildcard ServerAlias, e.g.In that way you can use SNI and apache will not send back the SSL warning. Of course, this only works if you can describe all of your domains easily using a wildcard syntax.We also ran into this error on a new Apache server build.The fix in our case was to define a  in the  that corresponded to the host name that Java was trying to connect to.  Our  was set to the internal host name. Our SSL cert was using the external host name, but that was not sufficient to avoid the warning.To help debug, you can use this ssl command:If there is a problem with that hostname, then it will print this message near the top of the output:I should also note that we did not get that error when using that command to connect to the internal host name, even though it did not match the SSL cert. Use:It should be useful. To retry on a SNI error in Apache HttpClient 4.4 - the easiest way we came up with (see ):andandYou cannot supply system properties to the jarsigner.exe tool, unfortunately.I have submitted defect , referencing @eckes' defect  and explaining why it was closed in error.My defect is specifically about the impact on the jarsigner tool, but perhaps it will lead them to reopening the other defect and addressing the issue properly. Actually, it turns out that you CAN supply system properties to the Jarsigner tool, it's just not in the help message. Use Ran into this issue with  and jvm 1.7 and 1.8. On AWS, we did not have the option to change the ServerName and ServerAlias to match (they are different) so we did the following:In  we added the following:That allowed us to bypass the issue with the \"Unrecognized Name\".I hit the same problem and it turned out that reverse dns was not setup correct, it pointed to wrong hostname for the IP. After I correct reverse dns and restart httpd, the warning is gone.\n(if I don't correct reverse dns, adding ServerName did the trick for me as well)I have also come across this issue whilst upgrading from Java 1.6_29 to 1.7.Alarmingly, my customer has discovered a setting in the Java control panel which resolves this.In the Advanced Tab you can check 'Use SSL 2.0 compatible ClientHello format'.This seems to resolve the issue.We are using Java applets in an Internet Explorer browser.Hope this helps.I had the same problem with an Ubuntu Linux server running subversion when accessed via Eclipse.It has shown that the problem had to do with a warning when Apache (re)started:This has been due to a new entry in , where another  directive was entered alongside the directive in .After removing the directive in , the problem had vanished (after restarting Apache, naturally)Just to add a solution here. This might help for LAMP usersThe above mentioned line in the virtual host configuration was the culprit.Virtual Host Configuration when errorWorking ConfigurationMy 's  was commented out by default. It worked after uncommenting.There is an  where you can just use your own HostnameVerifier to implicitly trust certain connections. The issue comes with Java 1.7 where SNI extensions have been added and your error is due to a server misconfiguration.You can either use \"-Djsse.enableSNIExtension=false\" to disable SNI across the whole JVM or read my blog where I explain how to implement a custom verifier on top of a URL connection."},
{"body": "? Convert the  to a  and iterate over that? Something else?I use a for loop to iterate the string and use  to get each character to examine it.  Since the String is implemented with an array, the  method is a constant time operation.That's what I would do.  It seems the easiest to me.As far as correctness goes, I don't believe that exists here.  It is all based on your personal style.Two optionsorThe first is probably faster, then 2nd is probably more readable. Note most of the other techniques described here break down if you're dealing with characters outside of the BMP (Unicode ), i.e.  that are outside of the u0000-uFFFF range. This will only happen rarely, since the code points outside this are mostly assigned to dead languages. But there are some useful characters outside this, for example some code points used for mathematical notation, and some used to encode proper names in Chinese.In that case your code will be:The  method requires Java 5+.Source: I agree that StringTokenizer is overkill here. Actually I tried out the suggestions above and took the time. My test was fairly simple: create a StringBuilder with about a million characters, convert it to a String, and traverse each of them with charAt() / after converting to a char array / with a CharacterIterator a thousand times (of course making sure to do something on the string so the compiler can't optimize away the whole loop :-) ).The result on my 2.6 GHz Powerbook (that's a mac :-) ) and JDK 1.5:As the results are significantly different, the most straightforward way also seems to be the fastest one. Interestingly, charAt() of a StringBuilder seems to be slightly slower than the one of String.BTW I suggest not to use CharacterIterator as I consider its abuse of the '\\uFFFF' character as \"end of iteration\" a really awful hack. In big projects there's always two guys that use the same kind of hack for two different purposes and the code crashes really mysteriously. Here's one of the tests:There are some dedicated classes for this:If you have  on your classpath, the following is a pretty readable alternative. Guava even has a fairly sensible custom List implementation for this case, so this shouldn't be inefficient.UPDATE: As @Alex noted, with Java 8 there's also  to use. Even the type is IntStream, so it can be mapped to chars like:If you need to iterate through the code points of a  (see this ) a shorter / more readable way is to use the  method added in Java 8:or using the stream directly instead of a for loop:There is also  if you want a stream of the characters (although it is an , since there is no ).I wouldn't use  as it is one of classes in the JDK that's legacy.The javadoc says:See .Put the length into  and use  loop.StringTokenizer is totally unsuited to the task of breaking a string into its individual characters.  With  you can do that easily by using a regex that matches nothing, e.g.:But StringTokenizer doesn't use regexes, and there's no delimiter string you can specify that will match the nothing between characters.  There  one cute little hack you can use to accomplish the same thing: use the string itself as the delimiter string (making every character in it a delimiter) and have it return the delimiters:However, I only mention these options for the purpose of dismissing them.  Both techniques break the original string into one-character strings instead of char primitives, and both involve a great deal of overhead in the form of object creation and string manipulation.  Compare that to calling charAt() in a for loop, which incurs virtually no overhead. Elaborating on  and .Above answers point out the problem of many of the solutions here which don't iterate by code point value -- they would have trouble with any . The java docs also outline the issue  (see \"Unicode Character Representations\").  Anyhow, here's some code that uses some actual surrogate chars from the supplementary Unicode set, and converts them  to a String.  Note that .toChars() returns an array of chars:  if you're dealing with surrogates, you'll necessarily have two chars.  This code should work for  Unicode character.This Example Code will Help you out!"},
{"body": "How to convert a  value into an  value in Java?or if you don't need to worry about null:And in both situations, you might run into overflows (because a Long can store a wider range than an Integer).Here are three ways to do it:All three versions generate almost identical byte code:If you care to check for overflows and have  handy, there is : is dead simple, and throws  on overflow:You'll need to type cast it.Bear in mind that a long has a bigger range than an int so you might lose data.If you are talking about the boxed types, then read the .The best simple way of doing so is:Assuming not null  longValIt works for example y you get an Object that can be an Integer or a Long. I know that is ugly, but it happens...If you are using Java 8 Do it as belowIn java ,there is a rigorous way to convert a long to intnot only lnog can convert into int,any type of class extends Number can convert to other Number type in general,here I will show you how to convert a long to int,other type vice versa."},
{"body": "Unlike C#'s , where an execution pipeline can be executed as many times as we want, in Java a stream can be 'iterated' only once. Any call to a terminal operation closes the stream, rendering it unusable.\nThis 'feature' takes away a lot of power. I imagine the reason for this is  technical. What were the design considerations behind this strange restriction?Edit: in order to demonstrate what I am talking about, consider the following implementation of Quick-Sort in C#:Now to be sure, I am not advocating that this is a good implementation of quick sort! It is however great example of the expressive power of lambda expression combined with stream operation. And it can't be done in Java!\nI can't even ask a stream whether it is empty without rendering it unusable. I have some recollections from the early design of the Streams API that might shed some light on the design rationale.Back in 2012, we were adding lambdas to the language, and we wanted a collections-oriented or \"bulk data\" set of operations, programmed using lambdas, that would facilitate parallelism. The idea of lazily chaining operations together was well established by this point. We also didn't want the intermediate operations to store results.The main issues we needed to decide were what the objects in the chain looked like in the API and how they hooked up to data sources. The sources were often collections, but we also wanted to support data coming from a file or the network, or data generated on-the-fly, e.g., from a random number generator.There were many influences of existing work on the design. Among the more influential were Google's  library and the Scala collections library. (If anybody is surprised about the influence from Guava, note that , Guava lead developer, was on the  expert group.) On Scala collections, we found this talk by Martin Odersky to be of particular interest: . (Stanford EE380, 2011 June 1.)Our prototype design at the time was based around . The familiar operations , , and so forth were extension (default) methods on . Calling one added an operation to the chain and returned another . A terminal operation like  would call  up the chain to the source, and the operations were implemented within each stage's Iterator.Since these are Iterables, you can call the  method more than once. What should happen then?If the source is a collection, this mostly works fine. Collections are Iterable, and each call to  produces a distinct Iterator instance that is independent of any other active instances, and each traverses the collection independently. Great.Now what if the source is one-shot, like reading lines from a file? Maybe the first Iterator should get all the values but the second and subsequent ones should be empty. Maybe the values should be interleaved among the Iterators. Or maybe each Iterator should get all the same values. Then, what if you have two iterators and one gets farther ahead of the other? Somebody will have to buffer up the values in the second Iterator until they're read. Worse, what if you get one Iterator and read all the values, and only  get a second Iterator. Where do the values come from now? Is there a requirement for them all to be buffered up  somebody wants a second Iterator?Clearly, allowing multiple Iterators over a one-shot source raises a lot of questions. We didn't have good answers for them. We wanted consistent, predictable behavior for what happens if you call  twice. This pushed us toward disallowing multiple traversals, making the pipelines one-shot.We also observed others bumping into these issues. In the JDK, most Iterables are collections or collection-like objects, which allow multiple traversal. It isn't specified anywhere, but there seemed to be an unwritten expectation that Iterables allow multiple traversal. A notable exception is the NIO  interface. Its specification includes this interesting warning:[bold in original]This seemed unusual and unpleasant enough that we didn't want to create a whole bunch of new Iterables that might be once-only. This pushed us away from using Iterable.About this time, an  appeared that described a spot of trouble he'd had with Scala. He'd written this code:It's pretty straightforward. It parses lines of text into  objects and prints them out twice. Except that it actually only prints them out once. It turns out that he thought that  was a collection, when in fact it's an iterator. The second call to  encounters an empty iterator, from which all values have been exhausted, so it prints nothing.This kind of experience convinced us that it was very important to have clearly predictable results if multiple traversal is attempted. It also highlighted the importance of distinguishing between lazy pipeline-like structures from actual collections that store data. This in turn drove the separation of the lazy pipeline operations into the new Stream interface and keeping only eager, mutative operations directly on Collections.  the rationale for that.What about allowing multiple traversal for collection-based pipelines but disallowing it for non-collection-based pipelines? It's inconsistent, but it's sensible. If you're reading values from the network,  you can't traverse them again. If you want to traverse them multiple times, you have to pull them into a collection explicitly.But let's explore allowing multiple traversal from collections-based pipelines. Let's say you did this:(The  operation is now spelled .)If source is a collection, then the first  call will create a chain of Iterators back to the source, execute the pipeline operations, and send the results into the destination. The second call to  will create another chain of Iterators, and execute the pipeline operations . This isn't obviously wrong but it does have the effect of performing all the filter and map operations a second time for each element. I think many programmers would have been surprised by this behavior.As I mentioned above, we had been talking to the Guava developers. One of the cool things they have is an  where they describe features that they decided  to implement along with the reasons. The idea of lazy collections sounds pretty cool, but here's what they have to say about it. Consider a  operation that returns a :To take a specific example, what's the cost of  or  on a List? For commonly used classes like , they're O(1). But if you call one of these on a lazily-filtered list, it has to run the filter over the backing list, and all of a sudden these operations are O(n). Worse, it has to traverse the backing list on  operation.This seemed to us to be  laziness. It's one thing to set up some operations and defer actual execution until you so \"Go\". It's another to set things up in such a way that hides a potentially large amount of recomputation.In proposing to disallow non-linear or \"no-reuse\" streams,  described the  of allowing them as giving rise to \"unexpected or confusing results.\" He also mentioned that parallel execution would make things even trickier. Finally, I'd add that a pipeline operation with side effects would lead to difficult and obscure bugs if the operation were unexpectedly executed multiple times, or at least a different number of times than the programmer expected. (But Java programmers don't write lambda expressions with side effects, do they? DO THEY??)So that's the basic rationale for the Java 8 Streams API design that allows one-shot traversal and that requires a strictly linear (no branching) pipeline. It provides consistent behavior across multiple different stream sources, it clearly separates lazy from eager operations, and it provides a straightforward execution model.With regard to , I am far from an expert on C# and .NET, so I would appreciate being corrected (gently) if I draw any incorrect conclusions. It does appear, however, that  permits multiple traversal to behave differently with different sources; and it permits a branching structure of nested  operations, which may result in some significant recomputation. While I appreciate that different systems make different tradeoffs, these are two characteristics that we sought to avoid in the design of the Java 8 Streams API.The quicksort example given by the OP is interesting, puzzling, and I'm sorry to say, somewhat horrifying. Calling  takes an  and returns an , so no sorting is actually done until the final  is traversed. What the call seems to do, though, is build up a tree structure of  that reflects the partitioning that quicksort would do, without actually doing it. (This is lazy computation, after all.) If the source has N elements, the tree will be N elements wide at its widest, and it will be lg(N) levels deep.It seems to me -- and once again, I'm not a C# or .NET expert -- that this will cause certain innocuous-looking calls, such as pivot selection via , to be more expensive than they look. At the first level, of course, it's O(1). But consider a partition deep in the tree, at the right-hand edge. To compute the first element of this partition, the entire source has to be traversed, an O(N) operation. But since the partitions above are lazy, they must be recomputed, requiring O(lg N) comparisons. So selecting the pivot would be an O(N lg N) operation, which is as expensive as an entire sort.But we don't actually sort until we traverse the returned . In the standard quicksort algorithm, each level of partitioning doubles the number of partitions. Each partition is only half the size, so each level remains at O(N) complexity. The tree of partitions is O(lg N) high, so the total work is O(N lg N).With the tree of lazy IEnumerables, at the bottom of the tree there are N partitions. Computing each partition requires a traversal of N elements, each of which requires lg(N) comparisons up the tree. To compute all the partitions at the bottom of the tree, then, requires O(N^2 lg N) comparisons.(Is this right? I can hardly believe this. Somebody please check this for me.)In any case, it is indeed cool that  can be used this way to build up complicated structures of computation. But if it does increase the computational complexity as much as I think it does, it would seem that programming this way is something that should be avoided unless one is extremely careful.While the question appears simple, the actual answer requires some background to make sense. If you want to skip to the conclusion, scroll down...Using basic concepts, C#'s  concept is more closely related to , which is able to create as many  as you want.  create . Java's  create The history of each concept is similar, in that both  and  have a basic motivation to allow 'for-each' style looping over the members of data collections. That's an oversimplification as they both allow more than just that, and they also arrived at that stage via different progressions, but it is a significant common feature regardless.Let's compare that feature: in both languages, if a class implements the /, then that class must implement at least a single method (for C#, it's  and for Java it's ). In each case, the instance returned from that (/) allows you to access the current and subsequent members of the data. This feature is used in the for-each language syntax. in C# has been extended to allow a number of other language features (). Features added include selections, projections, aggregations, etc. These extensions have a strong motivation from use in set-theory, similar to SQL and Relational Database concepts.Java 8 has also had functionality added to enable a degree of functional programming using Streams and Lambdas. Note that Java 8 streams are not primarily motivated by set theory, but by functional programming. Regardless, there are a lot of parallels.So, this is the second point. The enhancements made to C# were implemented as an enhancement to the  concept. In Java, though, the enhancements made were implemented by creating new base concepts of Lambdas and Streams, and then also creating a relatively trivial way to convert from  and  to Streams, and visa-versa.So, comparing IEnumerable to Java's Stream concept is incomplete. You need to compare it to the combined Streams and Collections API's in Java.Streams are not designed to solve problems the same way that iterators are:With an , you get a data value, process it, and then get another data value.With Streams, you chain a sequence of functions together, then you feed an input value to the stream, and get the output value from the combined sequence. Note, in Java terms, each function is encapsulated in a single  instance. The Streams API allows you to link a sequence of  instances in a way that chains a sequence of transformation expressions.In order to complete the  concept, you need a source of data to feed the stream, and a terminal function that consumes the stream.The way you feed values in to the stream may in fact be from an , but the  sequence itself is not an , it is a compound function.A  is also intended to be lazy, in the sense that it only does work when you request a value from it.Note these significant assumptions and features of Streams:When you consider that a Java Stream is just a part of a supply, stream, and collect system, and that Streams and Iterators are often used together with Collections, then it is no wonder that it is hard to relate to the same concepts which are almost all embedded in to a single  concept in C#.Parts of IEnumerable (and close related concepts) are apparent in all of the Java Iterator, Iterable, Lambda, and Stream concepts.There are small things that the Java concepts can do that are harder in IEnumerable, and visa-versa.Adding Streams gives you more choices when solving problems, which is fair to classify as 'enhancing power', not 'reducing', 'taking away', or 'restricting' it.This question is misguided, because streams are function sequences, not data. Depending on the data source that feeds the stream, you can reset the data source, and feed the same, or different stream.Comparing an  to a  is misguided. The context you are using to say  can be executed as many times as you want, is best compared to Java , which can be iterated as many times as you want. A Java  represents a subset of the  concept, and not the subset that supplies data, and thus cannot be 'rerun'.The first statement is true, in a sense. The 'takes away power' statement is not. You are still comparing Streams it IEnumerables. The terminal operation in the stream is like a 'break' clause in a for loop. You are always free to have another stream, if you want, and if you can re-supply the data you need. Again, if you consider the  to be more like an , for this statement, Java does it just fine.The reason is technical, and for the simple reason that a Stream a subset of what think it is. The stream subset does not control the data supply, so you should reset the supply, not the stream. In that context, it is not so strange.Your quicksort example has the signature:You are treating the input  as a data source:Additionally, return value is  too, which is a supply of data, and since this is a Sort operation, the order of that supply is significant. If you consider the Java  class to be the appropriate match for this, specifically the  specialization of , since List is a supply of data which has a guaranteed order or iteration, then the equivalent Java code to your code would be:Note there is a bug (which I have reproduced), in that the sort does not handle duplicate values gracefully, it is a 'unique value' sort.Also note how the Java code uses data source (), and stream concepts at different point, and that in C# those two 'personalities' can be expressed in just . Also, although I have use  as the base type, I could have used the more general , and with a small iterator-to-Stream conversion, I could have used the even more general s are built around s which are stateful, mutable objects. They don\u2019t have a \u201creset\u201d action and in fact, requiring to support such rewind action would \u201ctake away much power\u201d. How would  be supposed to handle such a request?On the other hand, for s which have a retraceable origin, it is easy to construct an equivalent  to be used again. Just put the steps made to construct the  into a reusable method. Keep in mind that repeating these steps is not an expensive operation as all these steps are lazy operations; the actual work starts with the terminal operation and depending on the actual terminal operation entirely different code might get executed.It would be up to you, the writer of such a method, to specify what calling the method twice implies: does it reproduce exactly the same sequence, as streams created for an unmodified array or collection do, or does it produce a stream with a similar semantics but different elements like a stream of random ints or a stream of console input lines, etc.By the way, to avoid confusion, a terminal operation  the  which is distinct from  the  as calling  on the stream does (which is required for streams having associated resources like, e.g. produced by ).It seems that a lot of confusion stems from misguiding comparison of  with . An  represents the ability to provide an actual , so its like an  in Java. In contrast, a  is a kind of iterator and comparable to an  so it\u2019s wrong to claim that this kind of data type can be used multiple times in .NET, the support for  is optional. The examples discussed here rather use the fact that an  can be used to fetch  s and that works with Java\u2019s s  as well; you can get a new . If the Java developers decided to add the  operations to  directly, with intermediate operations returning another , it was really comparable and it could work the same way.However, the developers decided against it and the decision is discussed in . The biggest point is the confusion about eager Collection operations and lazy Stream operations. By looking at the .NET API, I (yes, personally) find it justified. While it looks reasonable looking at  alone, a particular Collection will have lots of methods manipulating the Collection directly and lots of methods returning a lazy , while the particular nature of a method isn\u2019t always intuitively recognizable. The worst example I found (within the few minutes I looked at it) is  whose name matches  the name of the inherited (is this the right terminus for extension methods?)  while having an entirely contradicting behavior.Of course, these are two distinct decisions. The first one to make  a type distinct from / and the second to make  a kind of one time iterator rather than another kind of iterable. But these decision were made together and it might be the case that separating these two decision never was considered. It wasn\u2019t created with being comparable to .NET\u2019s in mind.The actual API design decision was to add an improved type of iterator, the . s can be provided by the old s (which is the way how these were retrofitted) or entirely new implementations. Then,  was added as a high-level front-end to the rather low level s. That\u2019s it. You may discuss about whether a different design would be better, but that\u2019s not productive, it won\u2019t change, given the way they are designed now.There is another implementation aspect you have to consider. s are  immutable data structures. Each intermediate operation may return a new  instance encapsulating the old one but it may also manipulate its own instance instead and return itself (that doesn\u2019t preclude doing even both for the same operation). Commonly known examples are operations like  or  which do not add another step but manipulate the entire pipeline). Having such a mutable data structure and attempts to reuse (or even worse, using it multiple times at the same time) doesn\u2019t play well\u2026For completeness, here is your quicksort example translated to the Java  API. It shows that it does not really \u201ctake away much power\u201d.It can be used likeYou can write it even more compact asI think there are very few differences between the two when you look closely enough.At it's face, an  does appear to be a reusable construct:However, the compiler is actually doing a little bit of work to help us out; it generates the following code:Each time you would actually iterate over the enumerable, the compiler creates an enumerator.  The enumerator is not reusable; further calls to  will just return false, and there is no way to reset it to the beginning.  If you want to iterate over the numbers again, you will need to create another enumerator instance.To better illustrate that the IEnumerable has (can have) the same 'feature' as a Java Stream, consider a enumerable whose source of the numbers is not a static collection.  For example, we can create an enumerable object which generates a sequence of 5 random numbers:Now we have very similar code to the previous array-based enumerable, but with a second iteration over :The second time we iterate over  we will get a different sequence of numbers, which isn't reusable in the same sense.  Or, we could have written the  to thrown an exception if you try to iterate over it multiple times, making the enumerable actually unusable (like a Java Stream).Also, what does your enumerable-based quick sort mean when applied to a ?So, the biggest difference is that .NET allows you to reuse an  by implicitly creating a new  in the background whenever it would need to access elements in the sequence.This implicit behavior is often useful (and 'powerful' as you state), because we can repeatedly iterate over a collection.But sometimes, this implicit behavior can actually cause problems.  If your data source is not static, or is costly to access (like a database or web site), then a lot of assumptions about  have to be discarded; reuse is not that straight-forwardIt is possible to bypass some of the \"run once\" protections in the Stream API; for example we can avoid  exceptions (with message \"stream has already been operated upon or closed\") by referencing and reusing the  (rather than the  directly).For example, this code will run without throwing an exception:However the output will be limited torather than repeating the output twice. This is because the  used as the  source is stateful and stores its current position. When we replay this  we start again at the end.We have a number of options to solve this challenge:This will print as expected."},
{"body": "I have a update view, where I need to preselect the value stored in database for a Spinner.I was having in mind something like this, but the  has no  method, so I am stuck.Suppose your  is named , and it contains as one of its choices: \"some value\".To find and compare the position of \"some value\" in the Spinner use this:A simple way to set spinner based on value isWay to complex code are already there, this is just much plainer. I keep a separate ArrayList of all the items in my Spinners.  This way I can do indexOf on the ArrayList and then use that value to set the selection in the Spinner.Based on , I came up with this single line solution... it's not very pretty, but you can blame whoever maintains the code for  for neglecting to include a function that does this for that.You'll get a warning about how the cast to a  is unchecked... really, you could just use an  as Merrill did, but that just exchanges one warning for another.Based on Merrill's answer\nhere is how to do with a CursorAdapterIf you need to have an indexOf method on any old Adapter (and you don't know the underlying implementation) then you can use this:if you are using string array this is the best way:    You can use this also,Here is how to do it if you are using a  (where  is the name of the db column that you used to populate your ):(Maybe you will also need to close the cursor, depending on whether you are using a loader.)Also (a refinement of ) this is the corresponding way to do it if you are filling your Spinner from an array:There is actually a way to get this using an index search on the AdapterArray and all this can be done with reflection.  I even went one step further as I had 10 Spinners and wanted to set them dynamically from my database and the database holds the value only not the text as the Spinner actually changes week to week so the value is my id number from the database.Here is the indexed search you can use on almost any list as long as the fields are on top level of object.Cast method which can be create for all primitives  here is one for string and int.here is my solutionand getItemIndexById belowHope this help!I am using a custom adapter, for that this code is enough:So, your code snippet will be like this:This is my simple method to get the index by string.Use following line to select using value:To make the application remember the last selected spinner values, you can use below code:I had the same issue when trying to select the correct item in a spinner populated using a cursorLoader. I retrieved the id of the item I wanted to select first from table 1 and then used a CursorLoader to populate the spinner. In the onLoadFinished I cycled through the cursor populating the spinner's adapter until I found the item that matched the id I already had. Then assigned the row number of the cursor to the spinner's selected position. It would be nice to have a similar function to pass in the id of the value you wish to select in the spinner when populating details on a form containing saved spinner results. As some of the previous answers are very right, I just want to make sure from none of you fall in such this problem.If you set the values to the  using , you MUST get the position of the value using the same string structure .You must get the position of needed value like this:Otherwise, you'll get the , item not found!I used  because of .I hope that will be helpful for you.Here is my hopefully complete solution. I have following enum:used in following classCode to set the spinner by HTTPMethod enum-member:Where  is defined in a layout-file, and  is delivered by android-studio.you have to pass your custom adapter with position like REPEAT[position]. and it works properly."},
{"body": "I want to get a list of files in a directory, but I want to sort it such that the oldest files are first.  My solution was to call File.listFiles and just resort the list based on File.lastModified, but I was wondering if there was a better way.Edit: My current solution, as suggested, is to use an anonymous Comparator:I think your solution is the only sensible way.  The only way to get the list of files is to use  and the documentation states that this makes no guarantees about the order of the files returned.  Therefore you need to write a  that uses  and pass this, along with the array of files, to .This might be faster if you have many files. This uses the decorate-sort-undecorate pattern so that the last-modified date of each file is fetched only  rather than every time the sort algorithm compares two files. This potentially reduces the number of I/O calls from O(n log n) to O(n).It's more code, though, so this should only be used if you're mainly concerned with speed and it is measurably faster in practice (which I haven't checked).You might also look at , it has a built in  and many other nice utilities for working with files.What's about similar approach, but without boxing to the Long objects:In Java 8:Imports :Code :If the files that you are sorting are being modified / updated while the sort is being performed you will be violating the transitivity requirement of the comparator's general contract. To avoid this potential bug, you'll want to build up a static lookup table of last modified values to use in the comparator for each file, something like the following:You can try guava :You can use Apache   libraryI came to this post when i was searching for the same issue but in .\nI don't say this is the best way to get sorted files by last modified date, but its the easiest way I found yet.Below code may be helpful to someone-Thanks"},
{"body": "I don't understand why there is no inheritance in Java annotations, just as Java classes. I think it would be very useful.For example: I want to know if a given annotation is a validator. With inheritance, I could reflexively navigate through superclasses to know if this annotation extends a ValidatorAnnotation. Otherwise, how can I achieve this?So, can anyone give me a reason why this design decision?About the reason why it wasn't designed that way you can find the answer in the  Design FAQ, where it says: So, yes I guess, the reason is it just KISS. Anyway, it seems this issue (along with many others) are being looked into as part of , and you can even find an alternative compiler with this functionality already developed by .Extensible annotations would effectively add the burden of specifying and maintaing another type system.  And this would be a fairly unique type system, so you could not simply apply an OO type paradigm.  Think through all the issues when you introduce polymorphism and inheritance to an annotation (e.g. what happens when sub-annotation changes meta-annotation specs such as retention?)And all this added complexity for what use-case?  You want to know if a given annotation belongs to a category?Try this:As you can see, you can easily group and categorize annotations without undue pain using the provided facilities.  So,  is the reason for not introducing a meta-type type system to the Java language.[p.s. edit]I used the String simply for demonstration and in view of an open ended meta annotation.  For your own given project, you obviously can use an enum of category types and specify multiple categories (\"multiple inheritance\") to a given annotation.  Do note that the values are entirely bogus and for demonstration purposes only:In a sense you already have it with Annotations - meta Annotations. If you annotate an annotation with meta information, that is in many ways equivalent to extending an additional interface. Annotations are interfaces, so polymorphism doesn't really come into play, and since they are static in nature, there can be no runtime dynamic dispatching.In your validator example, you could just on the annotation get the annotated type and see if it has a validator meta-annotation.The only use case I could see that inheritance would help is if you wanted to be able to get the annotation by super type, but that would add a whole bunch of complexity, because a given method or type may have two such annotations on it, meaning that an array would have to be returned instead of just a single object.So I think the ultimate answer is that the use cases are esoteric and complicate more standard use cases making it not worth it.Never thought about that but... seems that you're right, there is no problem with annotations inheritance facility (at least I don't see the problem with it).About your example with  annotation - you can exploit  approach then. I.e. you apply particular meta-annotation to the whole annotation interface.The designers of Java annotation support made a number of \"simplifications\" to the detriment of the Java community. The second one is being remedied in Java 8, but its too late. Many frameworks have been written based on what was possible in Java 5 and now these API warts are here to stay for a good long time.the same problem I have. No, you can't. I did 'disciplined' myself to write properties in annotations to respect some standards, so outside when you get annotation you can 'sniff' what kind od annotation it is by properties it has. One thing I could think of is the possibility to have multiple annotations. So you could add validator and a more specific annotation at the same place. But I could be mistaken :)I might be three years late in responding to this question, but I found it interesting because I found myself in the same spot. Here's my take on it. You can view annotations as Enums. They provide a one-way kind of information - use it or lose it. I had a situation where I wanted to simulate GET, POST, PUT and DELETE in a web-app. I so badly wanted to have a \"super\" annotation that was called \"HTTP_METHOD\". It later on dawned on me that it didn't matter. Well, I had to settle with using a hidden field in the HTML form to identify DELETE and PUT (because POST and GET were available anyway).On the server-side, I looked out for a hidden request parameter with the name, \"_method\". If the value was PUT or DELETE, then it overrode the associated HTTP request method. Having said that, it didn't matter whether or not I needed to extend an annotation to get the work done. All the annotations looked the same, but they were treated differently on the server side.So in your case, drop the itch to extend annotations. Treat them as 'markers'. They \"represent\" some information, and not necessarily \"manipulate\" some information."},
{"body": "How to convert a String to CharSequence in Java?Since   , you can pass a  wherever you need a , or assign a  to a :If you want to convert a  to a , just use the  method that must be implemented by every concrete implementation of .Hope it helps.Straight answer: is an interface, and the  class implements .CharSequence is an interface and String is its one of the implementations other than StringBuilder, StringBuffer and many other.So, just as you use , you can use  or simply You can use "},
{"body": "Just wondering if anyone has tried using new Java 7 language features with Android?\nI know that Android reads the bytecode that Java spits out and turns it to dex. So I guess my question is can it understand the bytecode of Java 7?If you are using , the Java 7  should be enabled automatically without any patches. Try-with-resource requires API Level 19+, and NIO 2.0 stuff are missing. If you can't use Java 7 features, see 's answer on how to edit your .The following is for historical interest only.A small part of Java 7 can certainly be used with Android (note: I have only tested on 4.1). First of all, you could not use Eclipse's ADT because  that only Java compiler 1.5 and 1.6 are compliant. You could recompile ADT but I find there is no simple way to do that aside from recompiling the whole Android together. But you don't need to use Eclipse. For instance, ,  and other javac-based IDEs supports compiling to Android  you could set the compliance even up to Java 8 with:This only allows Java 7 , and you can hardly benefit from anything since a half of improvement also comes from the library. Features you could use are those which do not depend on the library:And these features cannot be used :... \"yet\" :) It turns out that, although Android's library is targeting for 1.6, the Android source does contain interfaces like  and traditional interfaces like  does inherit from AutoCloseable (SafeVarargs is really missing, though). We could confirm its existence via reflection. They are hidden simply because the Javadoc has the  tag, which caused the \"android.jar\" not to include them.There is already as existing questionon how to get those methods back. You just need to  the existing \"android.jar\" reference of the current Platform with our customized one, then many of the Java 7 APIs will become available (the procedure is similar to that in Eclipse. Check Project Structure \u2192 SDKs.)In additional to AutoCloseable, (only) the following Java 7  are also revealed:That's basically all. In particular, NIO 2.0 does not exist, and Arrays.asList is still not @SafeVarargs.Yes, I have tried. But this is not a great test as the compatibility was limited to level 6 with no way (no simple way at least) to really use java 7:So I had  working, and also other apps, more complicated and using , ,  and , but this only proves that the compatibility handling of Java 7 seems to be well done and working with Android.Anyway, the SDK is designed to be used with Java 5 or 6, as explained .We may have something working with Java 7, but it would be working \"by accident\". The building of the DEX may work properly or not, and once the DEX built, it may work or not. This because using a non-qualified JDK gives unpredictable results by definition.Even if someone has succesfully built an Android app under plain Java 7, this does not qualify the JDK. The same process applied to another application may fail, or the resulting application may have bugs tied to the use of that JDK. Not recommended.For those who are involved on webapps development, this exactly the same as deploying a web application built under Java 5 or 6 under an application server qualified for Java 4 only (let's say Weblogic 8 for example). This may work, but this is not something that can be recommended for other purposes than trying.Quote from dalvikvm.com:That means, the .java source file does not matter, it's only the .class bytecode.As far as I know, only  was added to the JVM bytecode in Java 7, the rest is compatible to Java 6. The Java language itself does not use . Other new features, like the  statement using s or the multi- are just syntatic sugar and did not require byte code changes. For example, the multi- just copies the -block for each possible exception.The only problem should be that the new classes introduced in Java 7 are missing in Android, like , so I'm not sure if you can use the -with-resources feature (somebody tried it?).Any comments on that? Am I missing something?As of the Android SDK v15, along with Eclipse 3.7.1, Java 7 is  supported for Android development. Setting the source compatibility to 1.7 mandates setting the generated .class file compatibility to 1.7, which leads to the following error by the Android compiler:To expand on the above answer by @KennyTM, if you are targeting 4.0.3 and above (), you can use the hidden APIs by adding a few classes to your target's SDK android.jar.Once you do this, you can use try-with-resources on any Closeable, as well as implement AutoCloseable in your own classes.I've made a zip containing sources and binaries of all the classes that needed to be modified in android.jar to make these APIs available. You just need to unpack it and add the binaries to your android-sdk/platforms/android-NN/android.jarAlso of note is that, in the past couple of months, Elliott Hughes has made a few commits to the Android tree: , , ,  and . So, there is finally some progress going on.With the release of SDK 19 it is no longer necessary to patch android.jar with the additional APIs.The best method to use try-with-resources in Android Studio for an app that targets 4.0.3 and above () is add the following  to your :Android Studio will complain that try-with-resources can't be used with this API level, but my experience is that it can. The project will build and run without issue on devices with 4.0.3 and above. I've experienced no issues with this, with an app that has been installed into 500k+ devices.To ignore this warning, add the following to your :It seems that getting this to work with pure ant is a bit of a kludge.But it worked for me: In order to use Java 7 features in code build by Android's ant based build system, simply put the following in your  in your projects root directory:Some people might be interested in this git project I've found, that seems to allow to run Java 7 on android. \nHowever too much of a risk if I add this in the current project I work on. So I'll wait until Google to officially support Java 7."},
{"body": "What's the reason Java doesn't allow us to doI could understand .NET didn't allow us to do that, as in .NET you have value types that at run-time can have different sizes, but in Java all kinds of T will be object references, thus having the same size (correct me if I'm wrong).What is the reason?It's because Java's arrays (unlike generics) contain, at runtime, information about its component type. So you must know the component type when you create the array. Since you don't know what  is at runtime, you can't create the array.Quote:(I believe it is , but am not sure)See it in context here: By failing to provide a decent solution, you just end up with something worse IMHO.The common work around is as follows.is replaced with (assuming T extends Object and not another class)I prefer the first example, however more acedemic types seem to prefer the second, or just prefer not to thing about it.  Most of the examples of why you can't just use an Object[] equally apply to List or Collection (which are supported), so I see them as very poor arguments.Note: this is one of the reasons the Collections library itself doesn't compile without  warnings.  If you this usecase cannot be supported without warnings, something is fundermentally broken with the generics model IMHO.The reason this is impossible is that Java implements its Generics purely on the compiler level, and there is only one class file generated for each class.\nThis is called .At runtime, the compiled class needs to handle all of its uses with the same bytecode. So,  would have absolutely no idea what type needs to be instantiated.The answer was already given but if you already have an Instance of T then you can do this:Hope, I could Help,\nFerdi265This last line would compile just fine, but if we run this code, we would get an ArrayStoreException because we\u2019re trying to put a double into an integer array. The fact that we are accessing the array through a Number reference is irrelevant here, what matters is that the array is an array of integers.This means that we can fool the compiler, but we cannot fool the run-time type system. And this is so because arrays are what we call a reifiable type. This means that at run-time Java knows that this array was actually instantiated as an array of integers which simply happens to be accessed through a reference of type Number[].So, as we can see, one thing is the actual type of the object, an another thing is the type of the reference that we use to access it, right?Now, the problem with generic types in Java is that the type information for type parameters is discarded by the compiler after the compilation of code is done; therefore this type information is not available at run time. This process is called type erasure. There are good reasons for implementing generics like this in Java, but that\u2019s a long story, and it has to do with binary compatibility with pre-existing code.Let\u2019s consider now the following unsafe code:If the Java compiler does not stop us from doing this, the run-time type system cannot stop us either, because there is no way, at run time, to determine that this list was supposed to be a list of integers only. The Java run-time would let us put whatever we want into this list, when it should only contain integers, because when it was created, it was declared as a list of integers. That\u2019s why the compiler rejects line number 4 because it is unsafe and if allowed could break the assumptions of the type system.As such, the designers of Java made sure that we cannot fool the compiler. If we cannot fool the compiler (as we can do with arrays) then we cannot fool the run-time type system either.As such, we say that generic types are non-reifiable, since at run time we cannot determine the true nature of the generic type.I skipped some parts of this answers you can read full article here:\n I like the answer indirectly given\nby .  However, I propose it is wrong.  I changed Gafter's code a little.  It compiles and it runs for a while then it bombs where Gafter predicted it wouldThe output isSo it appears to me you can create generic array types in java.  Did I misunderstand the question?The main reason is due to the fact that arrays in Java are covariant.There's a good overview .I know I'm a little late to the party here, but I figured I might be able to help any future googlers since none of these answers fixed my issue.  Ferdi265's answer helped immensely though.I'm trying to create my own Linked list, so the following code is what worked for me:In the toArray() method lies the way to create an array of a generic type for me:In my case, I simply wanted an array of stacks, something like this:Since this was not possible, I used the following as a workaround:Ugly, but Java is happy.Note: as mentioned by BrainSlugs83 in the comment to the question, it is totally possible to have arrays of generics in .NETThere surely must be a good way around it (maybe using reflection), because it seems to me that that's exactly what  does. I quote:So one way around it would be to use this function i.e. create an  of the objects you want in the array, then use  to create the actual array. It wouldn't be speedy, but you didn't mention your requirements.So does anyone know how  is implemented?It is because generics were added on to java after they made it, so its kinda clunky because the original makers of java thought that when making an array the type would be specified in the making of it. So that does not work with generics so you have to do \nE[] array=(E[]) new Object[15];\nThis compiles but it gives a warning. If we cannot instantiate generic arrays, why does the language have generic array types? What's the point of having a type without objects?The only reason I can think of, is varargs - . Otherwise they could have completely scrubbed generic array types. (Well, they didn't really have to use array for varargs, since varargs didn't exist before . That's probably another mistake.)So it is a lie, you  instantiate generic arrays, through varargs!Of course, the problems with generic arrays are still real, e.g.We can use this example to actually demonstrate the danger of  array.On the other hand, we've been using generic varargs for a decade, and the sky is not falling yet. So we can argue that the problems are being exaggerated; it is not a big deal. If explicit generic array creation is allowed, we'll have bugs here and there; but we've been used to the problems of erasure, and we can live with it.And we can point to  to refute the claim that the spec keeps us from the problems that they claim to keep us from. If Sun had more time and resources for , I believe they could have reached a more satisfying resolution.From :To me, it sounds very weak. I think that anybody with a sufficient understanding of generics, would be perfectly fine, and even expect, that the ArrayStoredException is not thrown in such case."},
{"body": "All I am trying to do is to get the current class name, and java appends a useless non-sense  to the end of my class name. How can I get rid of it and only return the actual class name?The \"$1\" is not \"useless non-sense\". If your class is anonymous, a number is appended.If you don't want the class itself, but its declaring class, then you can use . For example:You can move that in some static utility method.But note that this is not the current class name. The anonymous class is different class than its enclosing class. The case is similar for inner classes.Try,This will work as long as you don't use it in a static method.Try using\n or .  If it's an anonymous class, use You can use , like so:this answer is late, but i think there is another way to do this in the context of anonymous handler class.let's say:it will achieve the same result. additionally, it's actually quite convenience since every class is defined at compile time, so no dynamicity is damaged.above that, if the class is really nested, i.e.  actually is enclosed by , the class of B can be easily known as:In your example,  probably refers to an anonymous class instance. Java gives a name to those classes by appending a  to the name of the enclosing class.I'm assuming this is happening for an anonymous class. When you create an anonymous class you actually create a class that extends the class whose name you got.The \"cleaner\" way to get the name you want is:If your class is an anonymous inner class,  should give you the class that it was created from. If you created it from an interface than you're sort of SOL because the best you can do is  which might give you more than one interface.The \"hacky\" way is to just get the name with  and use a regex to drop the .The combination of both answers. Also prints a method name:I've found this to work for my code,, however my code is getting the class out of an array within a for loop."},
{"body": "In Java I'm trying to test for a null value, from a ResultSet, where the column is being cast to a primitive  type. From the code fragment above, is there a better way to do this, and I assume that the second  test is redundant?Educate us, and Thanks The default for  when the field value is  is to return , which is also the default value for your  declaration. In which case your test is completely redundant.If you actually want to do something different if the field value is NULL, I suggest:(Edited as @martin comments below; the OP code as written would not compile because  is not initialised)Another solution:I think, it is redundant.  should return an  object or , if the column value actually was . So it should even be possible to do something like:Just check if the field is  or not using . Substitute  with whatever null-case value you want.Or, if you can guarantee that you use the right DB column type so that  really returns an  (and thus not ,  or ), then you can also just typecast it to an .AFAIK you can simply useeven if it is NULL.With java 8 you can do this:In that case you ensure that the nVal will be null (and not zero) if the SQL value is NULLFor convenience, you can create a wrapper class around ResultSet that returns null values when  ordinarily would not.Another nice way of checking, if you have control the SQL, is to add a default value in the query itself for your int column. Then just check for that value.e.g for an Oracle database, use NVLthen checkOf course this also is under the assumption that there is a value that wouldn't normally be found in the column."},
{"body": "I'm migrating a piece of code to make use of generics. One argument for doing so is that the for loop is much cleaner than keeping track of indexes, or using an explicit iterator.In about half the cases, the list (an ArrayList) is being iterated in reverse order by using an index today.Can someone suggest a cleaner way of doing this (since I dislike the  when working with collections), though it does work? I can't add any new dependencies outside the JDK.Try this: offers  and . As in most cases for Guava, the former delegates to the latter if the argument is an , so you can use the former in all cases.  These do not create new copies of the list but just \"reversed views\" of it.ExampleI don't think it's possible using the for loop syntax.  The only thing I can suggest is to do something like:... but I wouldn't say this is \"cleaner\" given that it's going to be less efficient.Option 1: Have you thought about reversing the List with  and then using foreach?Of course, you may also want to refactor your code such that the list is ordered correctly so you don't have to reverse it, which uses extra space/time.EDIT:Option 2: Alternatively, could you use a  instead of an ArrayList?  It will allow you to iterate forwards and backwardsEDIT:Option 3: As others have suggested, you could write an Iterator that will go through the list in reverse, here is an example:Create a custom reverseIterable You could use the concrete class  instead of the general interface . Then you have a  for iterating with the reverse direction.Don't know why there is no  with ...Here is an (untested) implementation of a .  When  is called it creates and returns a private  implementation, which simply maps calls to  to  and calls to  are mapped to .  It means you could iterate over an  in reverse as follows:Very simple Example:This is an old question, but it's lacking a java8-friendly answer. Here are some ways of reverse-iterating the list, with the help of the Streaming API:If the lists are fairly small so that performance is not a real issue, one can use the -metod of the -class in . Yields pretty -code, and the original list stays the same. Also, the reversed list is backed by the original list, so any change to the original list will be reflected in the reversed one.Yields the following result:Which means that reverse iteration of myList can be written as:Also found google collections  method.To have code which looks like this:Put this code into a file called \"In.java\":You could use  from Apache Commons-Collections:As has been suggested at least twice, you can use  with a , in particular with a . If you want to use the for-each loop (i.e., have an ), you can construct and use a wraper like this:Reason : \"Don't know why there is no descendingIterator with ArrayList...\"Since array list doesnot keep the list in the same order as data has been added to list. So, never use Arraylist .Linked list will keep the data in same order of ADD to list.So , above in my example, i used ArrayList() in order to make user to twist their mind and make them to workout something from their side.Instead of thisUSE:"},
{"body": "How can I detect I am in Release mode or Debug mode in android? The simplest, and best long-term solution, is to use . This is a  value that will be  for a debug build,  otherwise:There have been reports that this value is not 100% reliable from Eclipse-based builds, though I personally have not encountered a problem, so I cannot say how much of an issue it really is.If you are using Android Studio, or if you are using Gradle from the command line, you can add your own stuff to  or otherwise tweak the  and  build types to help distinguish these situations at runtime.The solution from Illegal Argument is based on the value of the  flag in the manifest. If that is how you wish to distinguish a \"debug\" build from a \"release\" build, then by definition, that's the best solution. However, bear in mind that going forward, the  flag is really an independent concept from what Gradle/Android Studio consider a \"debug\" build to be. Any build type can elect to set the  flag to whatever value that makes sense for that developer and for that build type.Try the following:It is taken from bundells post from Yes, you will have no problems using:Unless you are importing the wrong BuildConfig class. Make sure you are referencing your project's BuildConfig class, not from any of your dependency libraries.Due to the mixed comments about , I used the following to disable crashlytics (and analytics) in debug mode :then, in your code you detect the  flag as follows:use the same concept in your app and rename  to anything you want. I like this approach because I can see the flag in the configuration and I can control the flag.Alternatively, you could differentiate using If you're running debug build\n returns true. And for release build  returns true."},
{"body": "What function does the  (caret) operator serve in Java?When I try this:...it gives me:...so I guess it doesn't perform exponentiation. But what is it then? in Java is the exclusive-or (\"xor\") operator.Let's take  as example:This the truth table for bitwise () and logical () xor:More simply, you can also think of xor as \"this  that, but !\".As for integer exponentiation, unfortunately Java does not have such an operator. You can use  (casting the result to  if necessary).You can also use the traditional bit-shifting trick to compute some powers of two. That is,  is two to the -th power for .Addressing your  need, you actually don't need to compute various powers of 10. You can use what is called the , which is not only simple but also efficient.Since you're doing this as a personal exercise, I won't give the Java code, but here's the main idea:It may look complicated at first, but it really isn't. You basically read the digits left to right, and you multiply your result so far by 10 before adding the next digit.In table form:As many people have already pointed out, it's the  operator. Many people have also already pointed out that if you want exponentiation then you need to use .But I think it's also useful to note that  is just one of a family of operators that are collectively known as bitwise operators:From .These operators can come in handy when you need to read and write to integers where the individual bits should be interpreted as flags, or when a specific range of bits in an integer have a special meaning and you want to extract only those. You can do a lot of every day programming without ever needing to use these operators, but if you ever have to work with data at the bit level, a good knowledge of these operators is invaluable.It's bitwise XOR, Java does not have an exponentiation operator, you would have to use  instead.It is the  bitwise operator.As others have said, it's bitwise XOR. If you want to raise a number to a given power, use , where  is a number and  is the power.Lot many people have already explained about what it is and how it can be used but apart from the obvious you can use this operator to do a lot of programming tricks likeLot many such tricks can be done using bit wise operators, interesting topic to explore.use Math.pow instead:That is because you are using the xor operator.In java, or just about any other language, ^ is bitwise xor,\nso of course,10 ^ 1 = 11.\nIt's interesting how Java and C# don't have a power operator.As already stated by the other answer(s), it's the . For more information on bit-operators in Java, see: AraK's link points to the definition of exclusive-or, which explains how this function works for two boolean values.The missing piece of information is how this applies to two integers (or integer-type values). Bitwise exclusive-or is applied to pairs of corresponding binary digits in two numbers, and the results are re-assembled into an integer result.To use your example:A simple way to define bitwise XOR is to say the result has a 1 in every place where the two input numbers differ.With 4 and 5, the only difference is in the last place; so0101 ^ 0100 = 0001 (5 ^ 4 = 1) .It is the Bitwise xor operator in java which results 1 for different value of bit (ie 1 ^ 0 = 1) and 0 for same value of bit (ie 0 ^ 0 = 0) when a number is written in binary form.ex :- To use your example:The binary representation of 5 is 0101.\nThe binary representation of 4 is 0100.A simple way to define Bitwise XOR is to say the result has a 1 in every place where the two input numbers differ.0101 ^ 0100 = 0001 (5 ^ 4 = 1) .It is the bitwise xor operator in java which results 1 for different value (ie 1 ^ 0 = 1) and 0 for same value (ie 0 ^ 0 = 0).^ is binary (as in base-2) xor, not exponentiation (which is not available as a Java operator). For exponentiation, see java.lang.Math.pow().In other languages like Python you can do 10**2=100, try it.Meanwhile, in Groovy:Running the above using for example gives:"},
{"body": "I'm trying to remove some elements from  while iterating it like this:Of course, I get  when trying to remove item from the list at the same time when iterating . Is there some simple solution to do that right?Use an  and call :As an alternative to everyone else's answers I've always done something like this:This will avoid you having to deal with the iterator directly, but requires another list.  I've always preferred this route for whatever reason.Java 8 user can do that: It will remove elements in the list, for which someCondition is satisfiedYou have to use the iterator's remove() method, which means no enhanced for loop:No, no, NO!In single threated tasks you don't need to use Iterator, moreover, CopyOnWriteArrayList (due to performance hit).Solution is much simpler: .According to Java copyright owners (some years ago Sun, now Oracle) , it uses iterator to walk through collection and just hides it to make code looks better. But, unfortunately as we can see, it produced more problems than profits, otherwise this topic would not arise.For example, this code will lead to java.util.ConcurrentModificationException when entering next iteration on modified ArrayList:But following code works just fine:So, try to use indexing approach for iterating over collections and avoid for-each loop, as they are not equivalent!\nFor-each loop uses some internal iterators, which check collection modification and throw ConcurrentModificationException exception. To confirm this, take a closer look at the printed stack trace when using first example that I've posted:For multithreading use corresponding multitask approaches (like synchronized keyword).While other suggested solutions work, If you really want the solution to be made thread safe you should replace ArrayList with If you want to modify your List during traversal, then you need to use the . And then you can use  to remove the elements during traversal.One alternative method is convert your  to , iterate them and remove them directly from the  based on your logic.You can use the iterator remove() function to remove the object from underlying collection object. But in this case you can remove the same object and not any other object from the list.from  Though one answer is accepted and this is an old one, I thought posting this answer as it does not use "},
{"body": "In Java, you can define multiple top level classes in a single file, providing that at most one of these is public (see ).  See below for example.e.g., PublicClass.java:My suggested name for this technique (including multiple top-level classes in a single source file) would be \"mess\". Seriously, I don't think it's a good idea - I'd use a nested type in this situation instead. Then it's still easy to predict which source file it's in. I don't believe there's an official term for this approach though.As for whether this actually changes between implementations - I highly doubt it, but if you avoid doing it in the first place, you'll never need to care :)javac doesn't actively prohibit this, but it does have a limitation that pretty much means that you'd never want to refer to a top-level class from another file unless it has the same name as the file it's in.Suppose you have two files, Foo.java and Bar.java.Foo.java contains:Bar.java contains:Let's also say that all of the classes are in the same package (and the files are in the same directory).What happens if Foo.java refers to Baz but not Bar and we try to compile Foo.java? The compilation fails with an error like this:This makes sense if you think about it. If Foo.java refers to Baz, but there is no Baz.java (or Baz.class), how can javac know what source file to look in?If you instead tell javac to compile Foo.java and Bar.java at the same time, or even if you had previously compiled Bar.java (leaving the Baz.class where javac can find it) then this error goes away. This makes your build process feel very unreliable and flaky, however.Because the actual limitation, which is more like \"don't refer to a top-level class from another file unless it has the same name as the file it's in or you're also referring to a class that's in that same file that's named the same thing as the file\" is kind of hard to follow, people usually go with the much more straightforward (though stricter) convention of just putting one top-level class in each file. This is also better if you ever change your mind about whether a class should be public or not.Sometimes there really is a good reason why everybody does something in a particular way.I believe you simply call  what it is: a . You can also declare  as well.e.g., elsewhere on SO: As for changes in behavior between versions, there was this discussion about something that \"worked perfectly\" in 1.2.2. but stopped working in 1.4 in sun's forum: .Multi-class single-file demo.I'm not aware of any which don't have that restriction - all the file based compilers won't allow you to refer to source code classes in files which are not named the same as the class name. ( if you compile a multi-class file, and put the classes on the class path, then any compiler will find them )You can have as many classes as you wish like thisAccording to Effective Java 2nd edition (Item 13):The nested class may be static or non-static based on whether the member class needs access to the enclosing instance (Item 22)."},
{"body": "I'm putting together a Swing application where I often want to replace the contents of a JPanel. To do this, I'm calling , then adding my new content, then calling .However I'm finding that the old content is still actually visible (though obscured by the the new content). If I add a call to  in addition to , it works as expected.I'm sure on other occasions I've experienced that just calling  is enough.So basically my question is - should I need to call both functions and if not, when should I call each of them?You need to call  and . The former tells Swing that an area of the window is dirty (which is necessary to erase the image of the old children removed by ); the latter tells the layout manager to recalculate the layout (which is necessary when adding components). This should cause  of the panel to repaint, but may not cause the panel itself to do so (see  for the list of repaint triggers).On a more general note: rather than reusing the original panel, I'd recommend building a new panel and swapping them at the parent.Any time you do a remove() or a removeAll(), you should callafter you have completed add()'ing the new components.Calling validate() or revalidate() is mandatory when you do a remove() - see the relevant javadocs.My own testing indicates that repaint() is also necessary. I'm not sure exactly why. is called on a container once new components are added or old ones removed.  this call is an instruction to tell the layout manager to reset based on the new component list.   will trigger a call to repaint what the component thinks are 'dirty regions.'  Obviously not all of the regions on your  are considered dirty by the . is used to tell a component to repaint itself.  It is often the case that you need to call this in order to cleanup conditions such as yours.yes you need to call \n    repaint();\n    revalidate();\nwhen you call removeAll() then you have to call repaint() and revalidate()"},
{"body": "I want to know what actually happens when you annotate a method with @Transactional?\nOf course, I know that Spring will wrap that method in a Transaction.But, I have the following doubts:Source: [Yes, I am a newbie and I don't mind accepting the fact that I don't know this]Cheers !!This is a big topic. The Spring reference doc devotes multiple chapters to it. I recommend reading the ones on  and , as Spring's declarative transaction support uses AOP at its foundation.But at a very high level, Spring creates proxies for classes that declare  on the class itself or on members. The proxy is mostly invisible at runtime. It provides a way for Spring to inject behaviors before, after, or around method calls into the object being proxied. Transaction management is just one example of the behaviors that can be hooked in. Security checks are another. And you can provide your own, too, for things like logging. So when you annotate a method with , Spring dynamically creates a proxy that implements the same interface(s) as the class you're annotating. And when clients make calls into your object, the calls are intercepted and the behaviors injected via the proxy mechanism. Transactions in EJB work similarly, by the way.As you observed, through, the proxy mechanism only works when calls come in from some external object. When you make an internal call within the object, you're really making a call through the \"\" reference, which bypasses the proxy. There are ways of working around that problem, however. I explain one approach in  in which I use a  to inject an instance of the proxy into \"self-referencing\" classes at runtime. I save this reference to a member variable called \"\". Then if I need to make internal calls that require a change in the transaction status of the thread, I direct the call through the proxy (e.g. \"\".) The forum post explains in more detail. Note that the  code would be a little different now, as it was written back in the Spring 1.x timeframe. But hopefully it gives you an idea. I have an updated version that I could probably make available.When Spring loads your bean definitions, and has been configured to look for @Transactional annotations, it will create these proxy objects around your actual bean. These proxy objects are instances of classes that are auto-generated at runtime. The default behaviour of these proxy objects when a method is invoked is just to invoke the same method on the \"target\" bean (i.e. your bean). However, the proxies can also be supplied with interceptors, and when present these interceptors will be invoked by the proxy before it invokes your target bean's method. For target beans annotated with @Transactional, Spring will create a TransactionInterceptor, and pass it to the generated proxy object. So when you call the method from client code, you're calling the method on the proxy object, which first invokes the TransactionInterceptor (which begins a transaction), which in turn invokes the method on your target bean. When the invocation finishes, the TransactionInterceptor commits/rolls back the transaction. It's transparent to the client code.As for the \"external method\" thing, if your bean invokes one of its own methods, then it will not be doing so via the proxy. Remember, Spring wraps your bean in the proxy, your bean has no knowledge of it. Only calls from \"outside\" your bean go through the proxy.Does that help?As a visual person, I like to weigh in with a sequence diagram of the proxy pattern. If you don't know how to read the arrows, I read the first one like this:  executes .\n(I was allowed to post the photo on condition that I mentioned its origins. Author: Noel Vaes, website: www.noelvaes.eu)"},
{"body": "I\u2019m currently monitoring a Java application with jconsole. The memory tab lets you choose between:What is the difference between them ? The heap memory is the runtime data area from which the Java VM allocates memory for all class instances and arrays. The heap may be of a fixed or variable size. The garbage collector is an automatic memory management system that reclaims heap memory for objects.Non-heap memory includes a method area shared among all threads and memory required for the internal processing or optimization for the Java VM. It stores per-class structures such as a runtime constant pool, field and method data, and the code for methods and constructors. The method area is logically part of the heap but, depending on the implementation, a Java VM may not garbage collect or compact it. Like the heap memory, the method area may be of a fixed or variable size. The memory for the method area does not need to be contiguous..With Java8, non heap region no more contains PermGen but Metaspace, which is a major change in Java8, supposed to get rid of out of memory errors with java as metaspace size can be increased depending on the space required by jvm for class data.The new keyword allocates memory on the Java heap. The heap is the main pool of memory,accessible to the whole of the application. If there is not enough memory available to allocate for that object, the JVM attempts to reclaim some memory from the heap with a garbage collection. If it still cannot obtain enough memory, an OutOfMemoryError is thrown, and the JVM exits.The heap is split into several different sections, called generations. As objects survive more garbage collections, they are promoted into different generations. The older generations are not garbage collected as often. Because these objects have already proven to be longer lived, they are less likely to be garbage collected.When objects are first constructed, they are allocated in the Eden Space. If they survive a garbage collection, they are promoted to Survivor Space, and should they live long enough there, they are allocated to the Tenured Generation. This generation is garbage collected much less frequently.There is also a fourth generation, called the Permanent Generation, or PermGen. The objects that reside here are not eligible to be garbage collected, and usually contain an immutable state necessary for the JVM to run, such as class definitions and the String constant pool. Note that the PermGen space is planned to be removed from Java 8, and will be replaced with a new space called Metaspace, which will be held in native memory.\nreference\uff1a\n is part of memory allocated to JVM by Operating System.Objects reside in an area called the heap. The heap is created when the JVM starts up and may increase or decrease in size while the application runs. When the heap becomes full, garbage is collected.You can find more details about  in below SE question:PermGen has been replaced with Metaspace since Java 8 release.Regarding your queries: The Java Virtual Machine (JVM) generates native code and stores it in a memory area called the codecache. The JVM generates native code for a variety of reasons, including for the dynamically generated interpreter loop, Java Native Interface (JNI) stubs, and for Java methods that are compiled into native code by the just-in-time (JIT) compiler. The JIT is by far the biggest user of the codecache."},
{"body": "I'm familiar with ORM as a concept, and I've even used nHibernate several years ago for a .NET project; however, I haven't kept up with the topic of ORM in Java and haven't had a chance to use any of these tools.But, now I may have the chance to begin to use some ORM tools for one of our applications, in an attempt to move away from a series of legacy web services.I'm having a hard time telling the difference betweeen the JPA spec, what you get with the Hibernate library itself, and what JDO has to offer.So, I understand that this question is a bit open-ended, but I was hoping to get some opinions on:Some notes:IMO, I would recommend Hibernate.There have been some comments / questions about what you should do if you  to use Hibernate-specific features.  There are many ways to look at this, but my advice would be:In reality, you will probably need to trade-off  you are worried by vendor tie-in versus  you need those vendor specific extensions.And there are other factors too, like how well you / your staff know the respective technologies, how much the products will cost in licensing, and whose story you believe about what is going to happen in the future for JDO and JPA.Make sure you evaluate the DataNucleus implementation of JDO. We started out with Hibernate because it appeared to be so popular but pretty soon realized that it's not a 100% transparent persistence solution. There are too many caveats and the documentation is full of 'if you have this situation then you must write your code like this' that took away the fun of freely modeling and coding however we want. JDO has  caused me to adjust my code or my model to get it to 'work properly'. I can just design and code simple POJOs as if I was going to use them 'in memory' only, yet I can persist them transparently.The other advantage of JDO/DataNucleus over hibernate is that it doesn't have all the run time reflection overhead and is more memory efficient because it uses build time byte code enhancement (maybe add 1 sec to your build time for a large project) rather than hibernate's run time reflection powered proxy pattern.Another thing you might find annoying with Hibernate is that a reference you have to what you think is the object... it's often a 'proxy' for the object. Without the benefit of byte code enhancement the proxy pattern is required to allow on demand loading (i.e. avoid pulling in your entire object graph when you pull in a top level object). Be prepared to override equals and hashcode because the object you think you're referencing is often just a proxy for that object. Here's an example of frustrations you'll get with Hibernate that you won't get with JDO:\nIf you like coding to 'workarounds' then, sure, Hibernate is for you. If you appreciate clean, pure, object oriented, model driven development where you spend all your time on modeling, design and coding and none of it on ugly workarounds then spend a few hours evaluating . The hours invested will be repaid a thousand fold.For quite some time now DataNucleus' implements the JPA persistence standard in addition to the JDO persistence standard so porting existing JPA projects from Hibernate to DataNucleus should be very straight forward and you can get all of the above mentioned benefits of DataNucleus with very little code change, if any.\nSo in terms of the question, the choice of a particular standard, JPA (RDBMS only) vs JDO (RDBMS + No SQL + ODBMSes + others), DataNucleus supports both, Hibernate is restricted to JPA only.Another issue to consider when choosing an ORM is the efficiency of its dirty checking mechanism - that becomes very important when it needs to construct the SQL to update the objects that have changed in the current transaction - especially when there are a lot of objects.\nThere is a detailed technical description of Hibernate's dirty checking mechanism in this SO answer: \nI have recently evaluated and picked a persistence framework for a java project and my findings are as follows:What I am seeing is that the support in favour of  is primarily:and the support in favour of  is primarily:I am seeing a lot of pro-JPA posts from JPA developers who have clearly not used JDO/Datanucleus offering weak arguments for not using JDO.I am also seeing a lot of posts from JDO users who have migrated to JDO and are much happier as a result.In respect of JPA being more popular, it seems that this is due in part due to RDBMS vendor support rather than it being technically superior. (Sounds like VHS/Betamax to me).JDO and it's reference implementation Datanucleus is clearly not dead, as shown by Google's adoption of it for GAE and active development on the source-code (http://sourceforge.net/projects/datanucleus/).I have seen a number of complaints about JDO due to bytecode enhancement, but no explanation yet for why it is bad. In fact, in a world that is becoming more and more obsessed by NoSQL solutions, JDO (and the datanucleus implementation) seems a much safer bet.I have just started using JDO/Datanucleus and have it set up so that I can switch easily between using db4o and mysql. It's helpful for rapid development to use db4o and not have to worry too much about the DB schema and then, once the schema is stabilised to deploy to a database. I also feel confident that later on, I could deploy all/part of my application to GAE or take advantage of distributed storage/map-reduce a la hbase /hadoop / cassandra without too much refactoring.I found the initial hurdle of getting started with Datanucleus a little tricky - The documentation on the datanucleus website is a little hard to get into - the tutorials are not as easily to follow as I would have liked. Having said that, the more detailed documentation on the API and mapping is very good once you get past the initial learning curve.The answer is, it depends what you want. I would rather have cleaner code, no-vendor-lock-in, more pojo-orientated, nosql options verses more-popular. If you want the warm fussy feeling that you are doing the same as the majority of other developers/sheep, choose JPA/hibernate. If you want to lead in your field, test drive  JDO/Datanucleus and make your own mind up.I would suggest neither! Use Spring DAO's  together with ,  and  instead.My own personal experience with Hibernate is that the time saved up-front is more than offset by the endless days you will spend down the line trying to understand and debug issues like unexpected cascading update behaviour.If you are using a relational DB then the closer your code is to it, the more control you have. Spring's DAO layer allows fine control of the mapping layer, whilst removing the need for boilerplate code. Also, it integrates into Spring's transaction layer which means you can very easily add (via AOP) complicated transactional behaviour without this intruding into your code (of course, you get this with Hibernate too).JDO is not dead actually so please check your facts.\nJDO 2.2 was released in Oct 2008\nJDO 2.3 is under development.This is developed openly, under Apache. More releases than JPA has had, and its ORM specification is still in advance of even the JPA2 proposed featuresJDO is having advanced features than JPA see I am using JPA (OpenJPA implementation from Apache which is based on the KODO JDO codebase which is 5+ years old and extremely fast/reliable). IMHO anyone who tells you to bypass the specs is giving you bad advice. I put the time in and was definitely rewarded. With either JDO or JPA you can change vendors with minimal changes (JPA has orm mapping so we are talking less than a day to possibly change vendors). If you have 100+ tables like I do this is huge. Plus you get built0in caching with cluster-wise cache evictions and its all good. SQL/Jdbc is fine for high performance queries but transparent persistence is far superior for writing your algorithms and data input routines. I only have about 16 SQL queries in my whole system (50k+ lines of code).Anyone who says that JDO is dead is an astroturfing FUD monger and they know it.JDO is alive and well. The specification is still more powerful, mature and advanced than the much younger and constrained JPA.If you want to limit yourself to only what's available in the JPA standard you can write to JPA and use DataNucleus as a high performance, more transparent persistence implementation than the other implementations of JPA. Of course DataNucleus also implements the JDO standard if you want the flexibility and efficiency of modeling that JDO brings.I've been looking into this myself and can't find a strong difference between the two. I think the big choice is in which implementation you use. For myself I've been considering the  platform as it is a data-store agnostic implementation of both.I've used Hibernate (JPA implementation) and JPOX (JDO implementation) in the same project.  JPOX worked ok, but ran into bugs fairly quickly, there where some Java 5 language features it did not support at the time.  It had problems playing nice with XA transactions.  I was generating the database schema from the JDO objects.  It wanted to connect to a database every time which is annoying if your Oracle connection happens not be working.We then switched to Hibernate.  We toyed around with just using pure JPA for awhile, but we needed to use some of the Hibernate specific features to do the mapping.  Running the same code on multiple databases is very easy.  Hibernate seems to cache objects aggressively or just have strange caching behavior at times. There are a few DDL constructs Hibernate can not handle and so they are defined in an additional file that is run to initialize the database.  When I've run into a Hibernate problem there are often many people that have run into the same problem which makes googling for solutions easier.  Finally, Hibernate seems to be well designed and reliable.Some other responders have suggested just using SQL.  The real killer use case for object relational mapping is testing and development.  The databases that are built to handle large volumes of data are typically expensive and or they are difficult to install.  They are difficult to test with.  There are plenty of in-memory Java databases that can be used to test with, but are typically useless for production.  Being able to use a real, but limited database, will increase development productivity and code reliability.I made a sample WebApp in May 2012 that uses JDO 3.0 & DataNucleus 3.0 - take a look how clean it is:\nOkay maybe it's a little bit too clean, because I use the POJOs both for the database and the JSON client, but it's fun :)PS: Contains a few SuppressWarnings annotations (developed in IntelliJ 11)"},
{"body": "If something is not working properly or some plugins are loaded properly in my Eclipse. I often get suggestion to open Eclipse in clean mode. So, how to run in clean mode? and what happens if I do so?What it does:How to use it:(From: )Other eclipse command line options: For clean mode: start the platform likeThat's all. The platform will clear some cached OSGi bundle information, it helps or is recommended if you install new plugins manually or remove unused plugins.It will not affect any workspace related data.You can start Eclipse in clean mode from the command line:Using the  option is the way to go, as mentioned by the other answers.Make sure that you remove it from your  or shortcut after you've fixed the problem.  It causes Eclipse to reevaluate all of the plugins everytime it starts and can dramatically increase startup time, depending on how many Eclipse plugins you have installed.it will take much time then normal start and it will fresh up all resources.For cleaning up in a launch configuration, see this tip:For Windows users:\nYou can do as RTA said or through command line do this:\nNavigate to the locaiton of the eclipse executable then run:First check the name of your executable using the command 'dir' on its pathEasier option is to\nuse For Mac OS X Yosemite I was able to use the open command.This worked for me:"},
{"body": "What does AtomicBoolean do that a volatile boolean cannot achieve?They are just totally different. Consider this example of a  integer:If two threads call the function concurrently,  might be 5 afterwards, since the compiled code will be somewhat similar to this (except you cannot synchronize on ):If a variable is volatile, every atomic access to it is synchronized, but it is not always obvious what actually qualifies as an atomic access. With an  object, it is guaranteed that every method is \"atomic\". Thus, if you use an  and , you can be sure that the result will be . In the same way, if two threads both negate a  variable concurrently, with an  you can be sure it has the original value afterwards, with a , you can't. So whenever you have  modifying a field, you need to make it atomic or use explicit synchronization.The purpose of  is a different one. Consider this exampleIf you have a thread running  and another thread calling , you might run into an infinite loop if you omit , since the first thread might cache the value of stop. Here, the  serves as a hint to the compiler to be a bit more careful with optimizations.I use volatile fields when said field is ONLY UPDATED by its owner thread and the value is only read by other threads, you can think of it as a publish/subscribe scenario where there are many observers but only one publisher. However if those observers must perform some logic based on the value of the field and then push back a new value then I go with Atomic* vars or locks or synchronized blocks, whatever suits me best. In many concurrent scenarios it boils down to get the value, compare it with another one and update if necessary, hence the compareAndSet and getAndSet methods present in the Atomic* classes. Check the JavaDocs of the  package for a list of Atomic classes and an excellent explanation of how they work (just learned that they are lock-free, so they have an advantage over locks or synchronized blocks)You can't do ,  as atomic operation with volatile boolean (unless of course you synchronize it). has methods that perform their compound operations atomically and without having to use a  block. On the other hand,  can only perform compound operations if done so within a  block.The memory effects of reading/writing to  are identical to the  and  methods of  respectively.For example the  method will atomically perform the following (without a  block):Hence, the  method will let you write code that is guaranteed to execute only once, even when called from multiple threads. For example:Is guaranteed to only notify the listener once (assuming no other thread sets the  back to  again after it being set to ). keyword guarantees happens-before relationship among threads sharing that variable. It doesn't guarantee you that 2 or more threads won't interrupt each other while accessing that boolean variable.If there are multiple threads accessing class level variable then\neach thread can keep copy of that variable in its threadlocal cache.Making the variable volatile will prevent threads from keeping the copy of variable in threadlocal cache.Atomic variables are different and they allow atomic modification of their values.Boolean primitive type is atomic for write and read operations, volatile guarantees the happens-before principle. So if you need a simple get() and set() then you don't need the AtomicBoolean.On the other hand if you need to implement some check before setting the value of a variable, e.g. \"if true then set to false\", then you need to do this operation atomically as well, in this case use compareAndSet and other methods provided by AtomicBoolean, since if you try to implement this logic with volatile boolean you'll need some synchronization to be sure that the value has not changed between get and set.Remember the IDIOM -READ - MODIFY- WRITE this you can't achieve with volatile (usually you do this to define a  variable checked in the thread's main loop).However, if you have multiple threads modifying the boolean, you should use an . Else, the following code is not safe:This operation is done in two steps:If an other thread modify the value between  and , you might got a wrong result.  methods avoid this problem by doing steps  and  atomically.The Atomic* classes wrap a volatile primitive of the same type. From the source:So if all you are doing is getting and setting a Atomic* then you might as well just have a volatile field instead.What the Atomic* classes give you however, are methods that provide more advanced functionality such as , , and others that implement multiple operations (get/increment/set, test/set) without locking. That's why the Atomic* classes are so powerful.For example, the following code will work in a multi-threaded environment safely:However, if multiple threads are using the following, there will be race conditions because  is actually: get, increment, and set.It's also important to note that wrapping your volatile field using Atomic* class is a good way to encapsulate the critical shared resource from an object standpoint. This means that developers can't just deal with the field assuming it is not shared possibly injecting problems with a field++; or other code that introducing race conditions."},
{"body": "lets assume this URL...(Here id needs to be sent in a POST request)I want to send the  to the server's , which accepts it in a POST method.How can i do this from within Java?I tried this :But I still can't figure out how to send it via POSTSince some of the classes, in the original answer, are deprecated in the newer version of Apache HTTP Components, I'm posting this update.By the way, you can access the full documentation for more examples .I recommend to use Apache HttpClient. its faster and easier to implement.for more information check this url: Sending a POST request is easy in vanilla Java. Starting with a , we need t convert it to a  using . After that, we need to cast it to a , so we can access its  method to set our method. We finally say that we are going to send data over the connection.We then need to state what we are going to send:A normal POST coming from a http form has a  format. We need to convert our input to this format:We can then attach our form contents to the http request with proper headers and send it.We can also send json using java, this is also easy:Remember that different servers accept different content-types for json, see  question.Sending files can be considered more challenging to handle as the format is more complex. We are also going to add support for sending the files as a string, since we don't want to buffer the file fully into the memory.For this, we define some helper methods:We can then use these methods to create a multipart post request as follows:The first answer was great, but I had to add try/catch to avoid Java compiler errors.\nAlso, I had troubles to figure how to read the  with Java libraries.  Here is the more complete code :A simple way using Apache HTTP Components isTake a look at the Posting code that can send form data in post requests and works even on Java 7simplest way to send parameters with the post request:You have done. now you can use .\nGet response content as string:Call  and  Actually only the latter is needed as POST then becomes the default method."},
{"body": "In Java, static final variables are constants and the convention is that they should be in upper-case. However, I have seen that most people declare loggers in lower-case which comes up as a violation in . e.g:Just search or  for \"static final logger\" and you will see this for yourself.Should we be using LOGGER instead? The logger reference is not a constant, but a final reference, and should NOT be in uppercase. A constant VALUE should be in uppercase.To add more value to crunchdog's answer, The  states this in paragraph 3.3 Field NamingFollowing this convention,  is a  object reference as stated in point 2, but because it  followed by \"\" everytime you use it, it can not be considered as a constant and thus should be lower case.From effective java, 2nd ed.,In summary, constant == static final, plus if it's a reference (vs. a simple type), immutability.Looking at the slf4j logger,\nIt is immutable. On the other hand, the JUL logger is mutable. The log4j logger is also mutable. So to be correct, if you are using log4j or JUL, it should be \"logger\", and if you are using slf4j, it should be LOGGER.Note that the slf4j javadocs page linked above has an example where they user \"logger\", not \"LOGGER\".These are of course only conventions and not rules. If you happen to be using slf4j and you want to use \"logger\" because you are used to that from other frameworks, or if it is easier to type, or for readability, go ahead.I like Google's take on it ()Examples:If you are using an automated tool to check your coding standards and it violates said standards then it or the standards should be fixed. If you're using an external standard, fix the code.The convention in Sun Java is uppercase for public static constants. Obviously a logger is not constant, but represents a mutable thing ( otherwise there would be no point calling methods on it in the hope that something will happen ); there's no specific standard for non-constant final fields.If you google this, you might find that in some cases, the loggers are not defined as static final. Add some quick copy-n-paste to this, and this might explain it. in all our code, and this corresponds to our naming convention (and our CheckStyle is happy with it).We even go further, taking advantage of the strict naming convention in Eclipse.\nWe create a new class with a code template of :The logger is commented out, as initially we don't need it. But should we need it later, we just uncomment it.Then in the code, we use code templates that expect this logger to be present.\nExample with the try-catch template:We have a few more templates that use it. The .I personally think it looks really big in upper-case. Moreover, since it's a class that it's not directly related to the class behaviour, I don't see a major problem in using  instead of . But if you are going to be strictly pedantic, then use .Don't forget that PMD will respect a comment with in it. This will cause PMD to skip the line from its checks, this will allow you to choose whichever style you want. Usually constants are in uppercase.Loggers, however, should not be static but looked up for every \"new\" of the containing class if using the slf4j facade.  This avoids some nasty classloader issues in notably web containers, plus it allows the logger framework to do special stuff depending on the invocation context.Not necessarily. Read this - If your coding standards - if you have any - say that it should be uppercase then yes.I don't see any stringent reason for one way or the other. I think it totally depends on your personal likes resp. your company coding standards.BTW: I prefer \"LOGGER\" ;-)"},
{"body": "With Java:I have a  that represents a file.How do I write this to a file (ie. )I know it's done with InputStream, but I can't seem to work it out.Use Or, if you insist on making work for yourself...Without any libraries:With :With :All of these strategies require that you catch an IOException at some point too. Another solution using :From  onward you can use the  statement to avoid leaking resources and make your code easier to read. More on that .To write your  to a file you would do:Also since Java 7, one line with java.nio.file.Files:Where data is your byte[] and filePath is a String.  You can also add multiple file open options with the StandardOpenOptions class.  Add throws or surround with try/catch.Try an  or more specifically Actually, you'd be  to a ...Basic example:This is a program where we are reading and printing array of bytes offset and length using String Builder and Writing the array of bytes offset length to the new file.`O/P in console : fghij                  O/P in new file :cdefg//////////////////////////  1] File to Byte [] //////////////////////////////////////////   2] Byte [] to File ///////////////////////////"},
{"body": "I am new to Maven. I am trying to package my project. But, it automatically runs the tests. The tests insert some content in the database. This is not what I want, I need to avoid running tests while package the application. Anybody knows how run the package with out test?Run maven with Just provide the command mentioned below which will ignore executing the test cases,you can add this plugin configuration to your pom if you do not want to set command line arg:Note that -Dmaven.test.skip prevents Maven building the test-jar artifact. If you'd like to skip tests but create artifacts as per a normal build use:You can pass the  flag as a JVM argument, to skip running tests when the package phase (and the previous ones in the default lifecycle) is run:You can also pass the  flag alone to the mvn executable. If you want to include this information in your POM, you can create a new profile where you can configure the  to .If you are trying this in Windows Powershell, you will get this error:The reason for this is, in Powershell the \"\" has special meaning and it is causing problem with maven.The solution is to prepend it with a backtick (`), like so..Reference: You only have to provide No longer need the '=true' there.is also a way to add in pom fileTests should always[1] run before package. If you need to turn off the tests, you're doing something wrong. In other words, you're trying to solve the wrong problem. Figure out what your problem really is, and ask that question. It sounds like it's database-related.[1] You might skip tests when you need to quickly generate an artifact for local, development use, but in general, creating an artifact should always follow a successful test run.Answering an old and accepted question here. You can add this in your pom.xml if you want to avoid passing command line argument all the time:You are, obviously, doing it the wrong way. Testing is an important part of pre-packaging. You shouldn't ignore or skip it, but rather do it the right way. Try changing the database to which it inserts the data(like test_db). It may take a while to set it up. And to make sure this database can be used forever, you should delete all the data by the end of tests. JUnit4 has annotations which make it easy for you. Use @Before, @After @Test annotations for the right methods. You need to spend sometime on it, but it will be worth it! worked for me since the  did not work anymore."},
{"body": "In  I used to do to initialize all my array elements to 0.Is there a similar shortcut in Java?\nI want to avoid using the loop, is it possible?A default value of 0 for arrays of integral types is guaranteed by the :If you want to initialize an array to a different value, you can use  (which will of course use a loop internally).While the other answers are correct (int array values are by default initialized to 0), if you wanted to explicitly do so (say for example if you wanted an array filled with the value 42), you can use the fill() method of the  class:Or if you're a fan of 1-liners, you can use the  routine:Would give arr the value:(though it's , and not , if you need the primitive type you could defer to the  routine:In java all elements are initialised to 0 by default. You can save the loop.How it Reduces the Performance of your application....? Read Following.In Java Language Specification the  for any Object can be given as Follows.For type , the  is , that is, the value of (byte) is .For type , the  is , that is, the value of (short) is .For type , the  is , that is, .For type , the  is , that is, .For type , the  is , that is, .For type , the  is , that is, .For type , the  is the  character, that is, ''.For type , the  is .For , the  is .By Considering all this you don't need to initialize with zero values for the array elements because by default all array elements are 0 for int array.Because An  is a container object that holds a fixed number of values of a single type. \nNow the Type of array for you is  so consider the default value for all array elements will be  Because it is .Now  the  for  so that all array elements has  is .you can assign null value by using loop as you suggest in your Question.The more use of machine cycle  More time to Process the data . so that your application data processing can be considered as a low level(Slow up-to some Level).You can save the loop, initialization is already made to 0. Even for a local variable.But please correct the place where you place the brackets, for readability (recognized best-practice):If you are using Float or Integer then you can assign default value like this ...Yes, int values in an array are initialized to zero. But you are not guaranteed this. Oracle documentation states that this is a bad coding practice.You can create a new empty array with your existing array size, and you can assign back them to your array. This may faster than other.\nSnipet: Result :declare the array as instance variable in the class i.e. out of every method and JVM will give it 0 as default value. You need not to worry anymore  result \n    0123456\n    -1012345\n    -2-101234\n    -3-2-10123\n    -4-3-2-1012\n    -5-4-3-2-101\n    -6-5-4-3-2-10"},
{"body": "What is the easy way to concatenate two byte arrays?Say,How do I concatenate two byte arrays and store it in another byte array?Most straightforward:The most elegant way to do this is with a ByteArrayOutputStream.Here's a nice solution using 's :The great thing about this method is that its signature is -which means that you can concatenate an arbitrary number of arrays in a single method call.Another possibility is using .Something likeNote that the array must be appropriately sized to start with, so the allocation line is required (as  simply returns the backing array, without taking the offset, position or limit into account).Another way is to use a utility function (you could make this a static method of a generic utility class if you like):Invoke like so:It will also work for concatenating 3, 4, 5 arrays, etc.Doing it this way gives you the advantage of fast arraycopy code which is also very easy to read and maintain.If you prefer  like @kalefranz, there is always the posibility to concatenate two  (or even more) in one line, like this:You can use third party libraries for Clean Code like Apache Commons Lang and use it like:Two  calls are lean and mean, but not easy on the eyes (harder to understand as a code reviewer, that is).A more readable approach using :For two or multiple arrays, this simple and clean utility method can be used:If you are merging two byte arrays which contain PDF, this logic will not work. We need to use a third-party tool like PDFbox from Apache:This is my way to do it!"},
{"body": "Imagine that I have this class:Now, I have another class that uses the above class:So this is the problem: I have accessed a private field of a class from outside!\nHow can I prevent this? I mean how can I make this array immutable? Does this mean that with every getter method you can work your way up to access the private field? (I don't want any libraries such as Guava. I just need to know the right way to do this).You must return a  of your array.If you can use a List instead of an array, :Modifier  protects only field itself from being accessed from other classes, but not the object references by this field.  If you need to protect referenced object, just do not give it out.  Changeto:or toThe  has already been mentioned - the  strangely not! My solution would also be to use the list from the outside and wrap the array as follows:The problem with copying the array is: if you're doing it every time you access the code and the array is big, you'll create a lot of work for the garbage collector for sure. So the copy is a simple but really bad approach - I'd say \"cheap\", but memory-expensive! Especially when you're having more than just 2 elements.If you look at the source code of  and  there is actually not much created. The first just wraps the array without copying it, the second just wraps the list, making changes to it unavailable.You can also use  which should be better than the standard . The class is part of  libraries that was create by Google.Here is the description:Here is a simple example of how to use it:at this point of view you should use system array copy:You could return a copy of the data. The caller who chooses to change the data will only be changing the copyThe nub of the problem is that you are returning a pointer to a mutable object. Oops.  Either you render the object immutable (the unmodifiable list solution) or you return a copy of the object.  As a general matter, finality of objects does not protect objects from being changed if they are mutable.  These two problems are \"kissing cousins.\"Returning an unmodifiable list is a good idea. But a list that is made unmodifiable during the call to the getter method can still be changed by the class, or classes that are derived from the class.Instead you should make it clear to anybody that extends the class that the list should not be modified.So in your example it could lead to the following code:In the above example I've made the  field public, in principle you could do away with the method call, as the values are already known.You could also assign the strings to a  field made unmodifiable during construction of the class instance. Using a constant or instantiation arguments (of the constructor) depends on the design of the class.Yes, you should return a a copy of the array:"},
{"body": "What's a \"static factory\" method?We avoid providing direct access to database connections because they're resource intensive. So we use a static factory method  that creates a connection if we're below the limit.  Otherwise, it tries to provide a \"spare\" connection, failing with an exception if there are none.The  is a way to encapsulate object creation.  Without a factory method, you would simply call the class's  directly: .  With this pattern, you would instead call the factory method:  .  The constructors are marked private, so they cannot be called except from inside the class, and the factory method is marked as  so that it can be called without first having an object.There are a few advantages to this pattern.  One is that the factory can choose from many subclasses (or implementers of an interface) and return that.  This way the caller can specify the behavior desired via parameters, without having to know or understand a potentially complex class hierarchy.Another advantage is, as Matthew and James have pointed out, controlling access to a limited resource such as connections.  This a way to implement  - instead of building, using, and tearing down an object, if the construction and destruction are expensive processes it might make more sense to build them once and recycle them.  The factory method can return an existing, unused instantiated object if it has one, or construct one if the object count is below some lower threshold, or throw an exception or return  if it's above the upper threshold.As per the article on Wikipedia, multiple factory methods also allow different interpretations of similar argument types.  Normally the constructor has the same name as the class, which means that you can only have one constructor with a given .  Factories are not so constrained, which means you can have two different methods that accept the same argument types: and This can also be used to improve readability, as Rasmus notes.NOTE! \"The  is  the same as the  pattern\" (c) Effective Java, Joshua Bloch.Factory Method: \"Define an interface for creating an object, but let the classes which implement the interface decide which class to instantiate. The Factory method lets a class defer instantiation to subclasses\" (c) GoF.\"Static factory method is simply a static method that returns an instance of a class.\" (c) Effective Java, Joshua Bloch. Usually this method is inside a particular class.The defference:The key idea of static factory method is to gain control over object creation and delegate it from constructor to static method. The decision of object to be created is like in Abstract Factory made ouside the method (in common case, but not allways). While the key (!) idea of Factory Method is to delegate decision of what instance of class to create inside Factory Method. E.g. classic Singleton implementation is a special case of static factory method.  Example of commonly used static factory methods:Readability can be improved by static factory methods:ComparetofromIt all boils down to maintainability.  The best way to put this is whenever you use the  keyword to create an object, you're coupling the code that you're writing to an implementation.The factory pattern lets you separate how you create an object from what you do with the object.  When you create all of your objects using constructors, you are essentially hard-wiring the code that uses the object to that implementation.  The code that uses your object is \"dependent on\" that object.  This may not seem like a big deal on the surface, but when the object changes (think of changing the signature of the constructor, or subclassing the object) you have to go back and rewire things everywhere.Today factories have largely been brushed aside in favor of using Dependency Injection because they require a lot of boiler-plate code that turns out to be a little hard to maintain itself.  Dependency Injection is basically equivalent to factories but allows you to specify how your objects get wired together declaratively (through configuration or annotations).If the constructor of a class is private then you cannot create an object for class from outside of it. We cannot create an object for above class from outside of it. So you cannot access x, y from outside of the class. Then what is the use of this class? \nHere is solution :  method.\nInclude the below method in the above class  So now you can create an object for this class from outside of it. Like the way...A static method which returns the object of the class by executing its private constructor  is called  method.I thought i will add some light to this post on what i know. We used this technique extensively in our . Instead of  you can also use  to instantiate a class. Code listing:: Each time you invoke a constructor an object will get created but you might not want that. suppose you want to check some condition only then you want to create a new object.You would not be creating a new instance of Vinoth each time, unless your condition is satisfied. Another example taken from .This method translates a boolean primitive value into a Boolean object reference. The  method illustrates us, it never creates an object. The ability of  to return the same object from repeated  allows classes to maintain strict control over what instances exist at any time. is that, unlike , they can return an  of any  of their return type. One application of this flexibility is that an API can return objects without making their classes public. Hiding implementation classes in this fashion leads to a very compact API.Calendar.getInstance() is a great example for the above, It creates depending on the locale a ,  or by default one .Another example which i could think is , where you make your constructors private create an own  method where you make sure, that there is always just one instance available. A factory method a method that abstracts away the instantiation of an object.  Generally factories are useful when you know that you need a new instance of a class that implements some interface but you don't know the implementing class.This is useful when working with hierarchies of related classes, a good example of this would be a GUI toolkit.  You could simply hard-code calls to the constructors for concrete implementations of each widget but if you ever wanted to swap one toolkit for another you'd have a lot of places to change.  By using a factory you reduce the amount of code you would need to change.One of the advantages that stems from Static factory is that that API can return objects without making their classes public. This lead to very compact API. In java this is achieved by Collections class which hides around 32 classes which makes it collection API very compact.A static factory method is good when you want to ensure that only one single instance is going to return the concrete class to be used.For example, in a database connection class, you may want to have only one class create the database connection, so that if you decide to switch from Mysql to Oracle you can just change the logic in one class, and the rest of the application will use the new connection.If you want to implement database pooling, then that would also be done without affecting the rest of the application.It protects the rest of the application from changes that you may make to the factory, which is the purpose.The reason for it to be static is if you want to keep track of some limited resource (number of socket connections or file handles) then this class can keep track of how many have been passed out and returned, so you don't exhaust the limited resource.A member declared with the keyword 'static'.Methods that create and return new objects.The programming language is relevant to the meaning of 'static' but not to the definition of 'factory'.Java implementation contains utilities classes  and  both of them contains , examples of it and how to use :Also  class have such :"},
{"body": "There is an issue with the Android appcompat v7 library on Samsung devices running Android 4.2. I keep getting crashes with the following stack trace in my Developer Console:This is line 215 of CustomActivity.java:The crashes come from an array of devices, but always Samsung, and always Android 4.2.A quick web search leads me to believe that many people have the same issue, some of the steps I have tried to solve the issue are:Despite these steps, and despite it working on all other devices and Android versions the crash reports still come through.EDIT:The solution that worked for me was (Using Proguard) to replace this:with this:Credit goes to the .Old answer (Temporary Workaround):\nIt happens in a project where I use an  ActionBar. My solution was to check for those conditions and change the app flow:Then in the activity's onCreate method:As pointed out this is not a definitive solution, it is just a way to allow users to have access to limited functionality while a more permanent solution is found. As  saidThe better solution is add the following lines instead:On which device you are facing this problem ? (Samsung/HTC etc.)If it is Samsung,Various Samsung phones are included older versions of the android support library in the framework or classpath. If you use the new material support library, you'll see this crash on those Samsung devices:To fix this, you must rename that class. Easiest way to do that is by running proguard. If you don't want to obfuscate, here's a 1 liner to rename just the offending classes:There's an issue tracking this problem, but since it's really a Samsung bug, it's never going to get fixed on their end. Only way to fix it on the Google/AOSP side is to rename these internal classes.This issue returned in  where the  package was removed from the library jar. As suggested in the comments above (credits to the people who suggested it there), now also the proguard configuration has to change.To get the answer suggested above working again, try adding these lines to your proguard files:In stead of the old fix:According to the last posts of the bug-report, this should be fixed on the new version of the support library (24.0.0) :\nSomeone  it fixed it.This version is available , so you should update to it.Yes. Samsung already knows about  problem.\nI can suggest you try to using same implementation of Popup from . It is not best way, but will be works.I was having the same problem of this MenuBuilder class not found in USB debugging mode. I solved this problem by simply setting the  to  in both release and debug  block of  . like this:I set the  to true in  type to prevent app from crashing via USB debugging to a live handset.I enabled proguard with the default proguard properties provided with an eclipse project and the problem was fixed for me. Based on some comments here  , some people might have to repackage using:\n-repackageclasses \"android.support.v7\"I got the same error when trying to run a 'Hello World' app on my Samsung Galaxy Tab 3 tablet via Android Studio. The app would appear to launch and then it would crash instantly and that error would show in the console in Android Studio. I did a system update on the tablet and now I am able to run the 'Hello World' app and I'm not getting the error anymore. I hope this helps someone to resolve their issue. Note: The system update I performed on the tablet did not update the Android OS version, because it still says that the version is 4.2.2.Change the Compile Sdk Version of your project to  The default is set to STEPS"},
{"body": "Seeing various locking related question and (almost) always finding the 'loop because of spurious wakeups' terms I wonder, has anyone experienced such kind of a wakeup (assuming a decent hardware/software environment for example)?I know the term 'spurious' means no apparent reason but what can be the reasons for such kind of an event?( Note: I'm not questioning the looping practice.) A helper question (for those who like code samples):If I have the following program, and I run it:What can I do to wake this  up spuriously without waiting forever for a random event?The Wikipedia  has this tidbit:: If a Linux process is signaled its waiting threads will each enjoy a nice, hot .I buy it. That's an easier pill to swallow than the typically vague \"it's for performance\" reason often given.I have a production system that exhibits this behaviour.\nA thread waits on a signal that there is a message in the queue.\nIn busy periods, up to 20% of the wakeups are spurious (ie when it wakes there is nothing in the queue).\nThis thread is the only consumer of the messages.\nIt runs on a Linux SLES-10 8-processor box and is built with GCC 4.1.2.\nThe messages come from an external source and are processed asynchronously because there are problems if my system does not read them fast enough. wrote a  a while back about being hit by the spurious wakeup problem. So yes, it happensI'm guessing it's in the spec (as a possibility) because of limitations of some of the platforms which Java gets deployed on? although I may be wrong!To answer the question in the titile -  it does happen.Though the  mentions a good deal about spurious wakeups a nice explanation for the same that I came across is as follows - I was reading this answer from  and found it reasonable enough. Also read. Just to add this. Yes it happens and I spent three days searching for the cause of a multi-threading problem on a 24 core machine (JDK 6). 4 of 10 executions experienced that without any pattern. This never happened on 2 core or 8 cores.Studied some online material and this is not a Java problem but a general rare but expected behavior."},
{"body": "Consider these two methods:Both report an \"unchecked cast\" warning - I get why. The thing that baffles me is why can I calland it compiles? The compiler should know that  does not implement . The call togives an error (as expected)Can someone explain why would this behaviour be considered valid? How would it be useful?The client does not know that this call is unsafe - the client's code compiles without warning. Why wouldn't the compile warn about that / issue an error?Also, how is it different from this example:Trying to pass  gives an error, as expected:If that is reported as an error, why  isn't? is an . Therefore even if  does not implement  it would be perfectly possible to create a classTherefore you can writebecause the inferred type  is the intersection type .This is a bit odd in the case of  because  is final, but  doesn't play any role in these rules. For example you can writeOn the other hand,  is not an , so it would be impossible to extend  to get a subtype of , because java does not support multiple-inheritance for classes.With the  example, you need to remember that generics are neither covariant nor contravariant. This means that if  is a subtype of ,  is neither a subtype nor a supertype of . Since  does not implement , you cannot use  in your  method.You can, however get this to compileIf you have a method that  a  like this:you can doAgain, this is because the inferred type is  and this is a subtype of .Intersection types occur implicitly when you specify multiple bounds (e.g. ).For further information,  is the part of the JLS where it explains how type bounds work. You can include multiple interfaces, e.g.but only the first bound may be a non-interface.The type that is inferred by your compiler prior to the assignment for  is . This type  weird, because  is final, but it's a perfectly valid type in Java. It is then cast to , which is perfectly OK.There is exactly one possible value for the  type: . With the following implementation:The following assignment will work:Because of this possible value, there's no reason why the assignment should be wrong, even if it is obviously useless. A warning would be useful.In fact, I've recently blogged about this . You should (almost) never design a generic method to return arbitrary types because you can (almost) never guarantee that the inferred type will be delivered. An exception are methods like , in case of which the emptiness of the list (and generic type erasure) is the reason why any inference for  will work:"},
{"body": "As per my understanding I think:Am I correct?Now if am correct, I have the following question:\nThe  internally uses the hashcode of the object. So if two objects can have the same hashcode, then how can the  track which key it uses?Can someone explain how the  internally uses the hashcode of the object?A hashmap works like this (this is a little bit simplified, but it illustrates the basic mechanism):It has a number of \"buckets\" which it uses to store key-value pairs in. Each bucket has a unique number - that's what identifies the bucket. When you put a key-value pair into the map, the hashmap will look at the hash code of the key, and store the pair in the bucket of which the identifier is the hash code of the key. For example: The hash code of the key is 235 -> the pair is stored in bucket number 235. (Note that one bucket can store more then one key-value pair).When you lookup a value in the hashmap, by giving it a key, it will first look at the hash code of the key that you gave. The hashmap will then look into the corresponding bucket, and then it will compare the key that you gave with the keys of all pairs in the bucket, by comparing them with .Now you can see how this is very efficient for looking up key-value pairs in a map: by the hash code of the key the hashmap immediately knows in which bucket to look, so that it only has to test against what's in that bucket.Looking at the above mechanism, you can also see what requirements are necessary on the  and  methods of keys:Your third assertion is incorrect.It's perfectly legal for two unequal objects to have the same hash code. It's used by  as a \"first pass filter\" so that the map can quickly find  entries with the specified key. The keys with the same hash code are then tested for equality with the specified key.You wouldn't want a requirement that two unequal objects couldn't have the same hash code, as otherwise that would limit you to 2 possible objects. (It would also mean that different types couldn't even use an object's fields to generate hash codes, as other classes could generate the same hash.) is an array of  objects.Consider  as just an array of objects.Have a look at what this  is:Each  object represents a key-value pair. The field  refers to another  object if a bucket has more than one .Sometimes it might happen that hash codes for 2 different objects are the same. In this case, two objects will be saved in one bucket and will be presented as a linked list. \nThe entry point is the more recently added object. This object refers to another object with the  field and so on. The last entry refers to .When you create a  with the default constructorThe array is created with size 16 and default 0.75 load balance.If the bucket already has at least one element, a new one gets added and placed in the first position of the bucket. Its  field refers to the old element.You can find excellent information at To Summarize:  HashMap stores both key and value object as Map.Entry. Hashmap applies hashcode(key) to get the bucket. if there is collision ,HashMap uses LinkedList to store object.  HashMap uses Key Object's hashcode to find out bucket location and then call keys.equals() method to identify correct node in LinkedList and return associated value object for that key in Java HashMap.Here is a rough description of  mechanism, for  version, .capacity, means hashtable's bucket count, it could be get from , also could be calculated via  and , thus no need to be defined as a class field.: Get effective capacity.The hashcode determines which bucket for the hashmap to check.  If there is more than one object in the bucket then a linear search is done to find which item in the bucket equals the desired item (using the ) method.In other words, if you have a perfect hashcode then hashmap access is constant, you will never have to iterate through a bucket (technically you would also have to have MAX_INT buckets, the Java implementation may share a few hash codes in the same bucket to cut down on space requirements).  If you have the worst hashcode (always returns the same number) then your hashmap access becomes linear since you have to search through every item in the map (they're all in the same bucket) to get what you want.Most of the time a well written hashcode isn't perfect but is unique enough to give you more or less constant access.You're mistaken on point three.  Two entries can have the same hash code but not be equal.  Take a look at the implementation of .  You can see that it checks that the hashes are equal and the keys are equal.  Were point three true, then it would be unnecessary to check that the keys are equal.  The hash code is compared before the key because the former is a more efficient comparison.  If you're interested in learning a little more about this, take a look at the Wikipedia article on , which I believe is the mechanism that the OpenJdk implementation uses.  That mechanism is subtly different than the \"bucket\" approach one of the other answers mentions.  This is a Most Confusing Question for many of us in Interviews.But its not that complex.We knowTHIS IMAGE WILL HELP YOU UNDERSTAND: So here we see that if both the objects S1 and S2 have different content, then we are pretty sure that our overridden Hashcode method will generate different Hashcode(116232,11601) for both objects. NOW since there are different hash codes, so it won't even bother to call EQUALS method. Because a different Hashcode GUARANTEES DIFFERENT content in an object.Hash map works on the principle of hashing HashMap get(Key k) method calls hashCode method on the key object and applies returned hashValue to its own static hash function to find a bucket location(backing array) where keys and values are stored in form of a nested class called Entry (Map.Entry) . So you have concluded that from the previous line that Both key and value is stored in the bucket as a form of  Entry object . So thinking that Only value is stored  in the bucket is not correct and will not give a good impression on the interviewer .If key is null , then Null keys always map to hash 0, thus index 0.If key is not null then , it will call hashfunction on the key object , see line 4 in above method i.e. key.hashCode()  ,so after key.hashCode() returns hashValue , line 4 looks likeand now ,it applies returned hashValue into its own hashing function .We might wonder why we are calculating the hashvalue again using hash(hashValue). Answer is It defends against poor quality hash functions.Now final  hashvalue is used to find the bucket location at which the Entry object is stored . Entry object stores in the bucket like this (hash,key,value,bucketindex) I will not get into the details of how HashMap works, but will give an example so we can remember how HashMap works by relating it to reality.We have Key, Value ,HashCode and bucket.For sometime, we will relate each of them with the following:Using Map.get(key) :Stevie wants to get to his friend's(Josse) house who lives in a villa in a VIP society, let it be JavaLovers Society. \nJosse's address is his SSN(which is different for everyone).\nThere's an index maintained in which we find out the Society's name based on SSN.\nThis index can be considered to be an algorithm to find out the HashCode.Using Map.put(key,Value)This finds a suitable society for this Value by finding the HashCode and then the value is stored.I hope this helps and this is open for modifications.HashMap works on the principle of hashing, we have put() and get() method for storing and retrieving object from HashMap. When we pass both key and value to put() method to store on HashMap, it uses key object hashcode() method to calculate hashcode and they by applying hashing on that hashcode, it identifies bucket location for storing value object. While retrieving, it uses key object equals method to find out correct key value pair and return value object associated with that key. HashMap  uses linked list in case of collision and object will be stored in next node of linked list.\nAlso HashMap stores both key+value tuple in every node of linked list.As it is said, a picture is worth 1000 words. I say: some code is better than 1000 words. Here's the source code of HashMap. Get method:So it becomes clear that hash is used to find the \"bucket\" and the first element is always checked in that bucket. If not, then  of the key is used to find the actual element in the linked list.Let's see the  method:It's slightly more complicated, but it becomes clear that the new element is put in the tab at the position calculated based on hash: here  is the index where the new element will be put (or it is the \"bucket\").  is the size of the  array (array of \"buckets\").First, it is tried to be put as the first element of in that \"bucket\". If there is already an element, then append a new node to the list.It gonna be a long answer , grab a drink and read on \u2026Hashing is all about storing a key-value pair in memory that can be read and written faster. Lets Say I want to store 4 key value pairs -So to store the keys we need an array of 4 element . Now how do I map one of these 4 keys to 4 array indexes (0,1,2,3)? So java finds the hashCode of individual keys and map them to a particular array index . \nHashcode Formulae is - Hash and girl !! I know what you are thinking. Your fascination about that wild duet might made you miss an important thing .  answer is ,   . So  is mapped to  in our case . which is second element of the array . and the value \u201cahhan\u201d  is stored in a LinkedList associated with array index 1 . -  If you try to find  of the keys  and   using the formulae described above you\u2019ll see both giving us same . Whooaa !! lesson learnt -Now the hash map looks like \u2013Now if some body tries to find the value for the key  , java quickly will find the hashCode of it , module it and start searching for it\u2019s value in the LinkedList corresponding  . So this way we need not search all the 4 array indexes thus making data access faster.But , wait , one sec .   there are 3 values in that linkedList corresponding Array index 1, how it finds out which one was was the value for key \u201chorsemints\u201d ? It stores both key value pair as map entry. So actually Map looks like this . Now you can see While traversing through the linkedList corresponding to ArrayIndex1 it actually compares key of each entry to of that LinkedList to \u201chorsemints\u201d and when it finds one it just returns the value of it .Hope you had fun while reading it :)"},
{"body": "May I know what is the difference between:-Are these technologies/framework complementary to each other? Or they are alternatives to each other (after I use one of them, then I don't need to use the other)?Thanks.So, to summarize:I don't want to make things more confusing but note that Java EE 6 provides modern, standardized and very nice equivalent of the above frameworks: JSF 2.0 and Facelets for the presentation, JPA 2.0 for the persistence, Dependency Injection, etc. For a new development, this is IMO a  option, Java EE 6 is a  stack.Generally...Hibernate is used for handling database operation. There are rich set of database utility functionality, which reduce your number of lines of code. Especially you have to read @Annotation of hibernate. It is ORM framework, persistance layer.Spring provides rich set of Injectioin based working mechanism. Currently Spring become so much famous. You have to also read about Spring AOP. There is bridge between Struts and Hibernate. Mainly Spring provides this kind of utility.Struts2 provides action based programming. There are rich set of Struts tags. You can use it. Struts proves action based programming so you have to maintain all the relavant control of your view.In Addition Tapestry is different framework of JAva. In which you have to handle only .tml (template file). YOu have to create main 2 files for any class. One is JAVA class and another one is its template. Both name's are same. Tapestry automatically called related classes.You can see the overview and ranking for yourself . Hibernate is an ORM, so you can use either struts+Hiberante or spring+hibernate to build a web app. Different web frameworks and many are alternatives to each other.Spring is an application framework which deals with IOC(Inversion of Container).Struts 2 is a web application MVC framework which deals with actions.Hibernate is an ORM(Object Relation Mapping) that deals with persistent data. In hibernate you need not bother about how to create table in SQL and you need not to remember connection ,prepared statement like that data is persisted in a database. So, basically it makes a developer's life easy.  pages and components are simple  consisting of getters and setters for easy access to Java language features."},
{"body": "Hibernate has a handful of methods that, one way or another, takes your object and puts it into the database. What are the differences between them, when to use which, and why isn't there just one intelligent method that knows when to use what?The methods that I have identified thus far are:Here's my understanding of the methods.  Mainly these are based on the  though as I don't use all of these in practice.\nCalls either save or update depending on some checks.  E.g. if no identifier exists, save is called.  Otherwise update is called.\nPersists an entity.  Will assign an identifier if one doesn't exist.  If one does, it's essentially doing an update.  Returns the generated ID of the entity.\nAttempts to persist the entity using an existing identifier.  If no identifier exists, I believe an exception is thrown.\nThis is deprecated and should no longer be used.  Instead there is...\nNow this is where my knowledge starts to falter.  The important thing here is the difference between transient, detached and persistent entities.  For more info on the object states, .  With save & update, you are dealing with persistent objects.  They are linked to a Session so Hibernate knows what has changed.  But when you have a transient object, there is no session involved.  In these cases you need to use merge for updates and persist for saving.\nAs mentioned above, this is used on transient objects.  It does not return the generated ID.This link explains in good manner :We all have those problems that we encounter just infrequently enough that when we see them again, we know we\u2019ve solved this, but can\u2019t remember how.The NonUniqueObjectException thrown when using Session.saveOrUpdate() in Hibernate is one of mine. I\u2019ll be adding new functionality to a complex application. All my unit tests work fine. Then in testing the UI, trying to save an object, I start getting an exception with the message \u201ca different object with the same identifier value was already associated with the session.\u201d Here\u2019s some example code from Java Persistence with Hibernate.To understand the cause of this exception, it\u2019s important to understand detached objects and what happens when you call saveOrUpdate() (or just update()) on a detached object.When we close an individual Hibernate Session, the persistent objects we are working with are detached. This means the data is still in the application\u2019s memory, but Hibernate is no longer responsible for tracking changes to the objects.If we then modify our detached object and want to update it, we have to reattach the object. During that reattachment process, Hibernate will check to see if there are any other copies of the same object. If it finds any, it has to tell us it doesn\u2019t know what the \u201creal\u201d copy is any more. Perhaps other changes were made to those other copies that we expect to be saved, but Hibernate doesn\u2019t know about them, because it wasn\u2019t managing them at the time.Rather than save possibly bad data, Hibernate tells us about the problem via the NonUniqueObjectException.So what are we to do? In Hibernate 3, we have merge() (in Hibernate 2, use saveOrUpdateCopy()). This method will force Hibernate to copy any changes from other detached instances onto the instance you want to save, and thus merges all the changes in memory before the save.It\u2019s important to note that merge returns a reference to the newly updated version of the instance. It isn\u2019t reattaching item to the Session. If you test for instance equality (item == item3), you\u2019ll find it returns false in this case. You will probably want to work with item3 from this point forward.It\u2019s also important to note that the Java Persistence API (JPA) doesn\u2019t have a concept of detached and reattached objects, and uses EntityManager.persist() and EntityManager.merge().I\u2019ve found in general that when using Hibernate, saveOrUpdate() is usually sufficient for my needs. I usually only need to use merge when I have objects that can have references to objects of the same type. Most recently, the cause of the exception was in the code validating that the reference wasn\u2019t recursive. I was loading the same object into my session as part of the validation, causing the error.Where have you encountered this problem? Did merge work for you or did you need another solution? Do you prefer to always use merge, or prefer to use it only as needed for specific casesActually the difference between hibernate  and  methods is depends on generator class we are using.If our generator class is assigned, then there is no difference between  and ) methods. Because generator \u2018assigned\u2019 means, as  a programmer we need to give the primary key value to save in the database right [ Hope you know this generators concept ]\nIn case of other than assigned generator class, suppose if our generator class name is Increment means hibernate it self will assign the primary key id value into the database right [ other than assigned generator, hibernate only used to take care the primary key id value remember  ], so in this case if we call  or  method then it will insert the record into the database normally\nBut hear thing is,   method can return that primary key id value which is generated by hibernate and we can see it byIn this same case,  will never give any value back to the client.Be aware that if you call an update on an detached object, there will always be an update done in the database whether you changed the object or not. If it is not what you want you should use Session.lock() with LockMode.None. You should call update only if the object was changed outside the scope of your current session (when in detached mode).None of the following answers are right.\nAll these methods just seem to be alike, but in practice do absolutely different things.\nIt is hard to give short comments. Better to give a link to full documentation about these methods:\nI found a good example showing the differences between all hibernate save methods:In brief, according to the above link:Also for practical examples of all these, please refer to the link I mentioned above, it shows examples for all these different methods."},
{"body": "I'm trying to test some legacy code, using Mockito.I want to stub a  that is used in production as follows:I can write:But the obvious problem is that  is never called with the same  object that I stubbed the method for. (Curse that  operator!)I would love it if I could stub the method in a way that it returns  regardless of the argument. Failing that, I'll listen to other workaround suggestions, but I'd really like to avoid changing the production code until there is reasonable test coverage.or (to avoid s):Don't forget to import matchers (many others are available):Use like this:Before you need to import anyObject should fit your needs.Also, you can always consider implementing hashCode and equals for the Bazoo class. This would make your code example work the way you want."},
{"body": "How do you make  2.0 wait for the page to load?You can also check pageloaded using following codeUse class Also see You can expect to show some element. something like in C#:If you set the implicit wait of the driver, then call the  method on an element you expect to be on the loaded page, the WebDriver will poll for that element until it finds the element or reaches the time out value.source: In general, with Selenium 2.0 the web driver should only return control to the calling code once it has determined that the page has loaded. If it does not, you can call , which cycles round calling  until it is found or times out (time out can be set).Ruby implementation:You may remove the  line. It is added for debug purposes.You can also use the class:  to explicitly wait for an element to show up on the webpage before you can take any action further actionsYou can use the  class to determine if an element is visible:See  for list of all conditions you are able to check.This seems to be a serious limitation of WebDriver. Obviously waiting for an element will not imply the page being loaded, in particular the DOM can be fully build (onready state) whereby JS is still executing and CSS and images are still loading.I believe the simplest solution is to set a JS variable upon the onload event after everything is initialized and check and wait for this JS variable in Selenium.If you want to wait for a specific element to load, you can use the  method on a  :(Example from )All of these solutions are OK for specific cases, but they suffer from at least one of a couple of possible problems:Here's my attempt at a generic solution that avoids this problem (in Python):First, a generic \"wait\" function (use a WebDriverWait if you like, I find them ugly):Next, the solution relies on the fact that selenium records an (internal) id-number for all elements on a page, including the top-level  element.  When a page refreshes or loads, it gets a new html element with a new ID.So, assuming you want to click on a link with text \"my link\" for example:For more Pythonic, reusable, generic helper, you can make a context manager:And then you can use it on pretty much any selenium interaction:I reckon that's bulletproof!  What do you think?  More info in a Imran's answer rehashed for Java 7:I'm surprised that predicates weren't the first choice as you typically know what element(s) you will next interact with on the page you're waiting to load. My approach has always been to build out predicates/functions like  and , etc. and then use and reuse these wherever I need them, be it for a page load or page content change I'm waiting on.For example,In my test class:In my test class parent:Though this seems like a lot, it takes care of checking repeatedly for you\nand the interval for how often to check can be set along with the ultimate\nwait time before timing out. Also, you will reuse such methods.In this example, the parent class defined and initiated the  and the .I hope this helps.Use implicitly wait for wait of every element on page till given time.this wait for every element on page for 30 sec.Another wait is Explicitly wait or conditional wait in this wait until given condition.In id give static element id which is diffidently display on the page, as soon as page is load.You can change from the document to an element, in the case of where only part of a document is being changed.This technique was inspired by the answer from sincebasic.You can explicitly wait for an element to show up on the webpage before you can take any action (like element.click())This is what I used for a similar scenario and it works fine.My simple way::And to you :The best way to wait for page loads when using the Java bindings for WebDriver is to use the Page Object design pattern with PageFactory. This allows you to utilize the  which to put it simply acts as a global wait for all of your elements. It has limitations on elements such as drop-boxes or complex javascript transitions but it will drastically reduce the amount of code needed and speed up test times. A good example can be found in this blogpost. Basic understanding of Core Java is assumed.You can use this snippet of code for the page to load:Or you can use waiter for any element to be loaded and become visible/clickable on that page, most probably which is going to be load at the end of loading like:In  you can get it via promises...If you write this code, you can be sure that the page is fully loaded when you get to the then...If you write this code, you will navigate, and selenium will wait 3 seconds...From Selenium documentation:this.get( url ) \u2192 ThenableSchedules a command to navigate to the given URL.Returns a promise that will be resolved when the document has .You can use the below existing method to set the time for pageeLoadTimeout \nin below example if the page is taking more than 20 seconds to load , then it will throw an exception of page reload Explicitly wait or conditional wait in this wait until given condition.  This will wait for every web element for 60 seconds.Use implicitly wait for wait of every element on page till given time.This will wait for every web element for 60 seconds.\nThe easiest way is just wait for some element which will appear on loaded page.If you would like to click on some button already after page is loaded you could use await and click: provides the following interesting approach:Sample code:use a if condition and for any of the element present You can try this code to let the page load completely until element is found.The best way I've seen is to utilize the  ExpectedCondition, to wait for the old page to become stale.Example:It'll wait for ten seconds for the old HTML tag to become stale, and then throw an exception if it doesn't happen.use following code it's very easy and simple for page load. i hope this helps you. "},
{"body": "Please  tell with a code example why is SimpleDateFormat not threadsafe. What is the problem in this class?\n? \nPlease give a code which demonstrates this fault in class.FastDateFormat is threadsafe. Why?\nwhat is the difference b/w the SimpleDateFormat and FastDateFormat?Please explain with a code which demonstrates this issue? stores intermediate results in instance fields. So if one instance is used by two threads they can mess each other's results.Looking at the  reveals that there is a  instance field, which is used by operations on  / For example  calls  initially and then . If another thread invokes  before the completion of the first invocation, it will clear the calendar, but the other invocation will expect it to be populated with intermediate results of the calculation.One way to reuse date formats without trading thread-safety is to put them in a  - some libraries do that. That's if you need to use the same format multiple times within one thread. But in case you are using a servlet container (that has a thread pool), remember to clean the thread-local after you finish.To be honest, I don't understand why they need the instance field, but that's the way it is. You can also use   which is threadsafe. is a concrete class for formatting and parsing dates in a locale-sensitive manner.   From the ,  To make the SimpleDateFormat class thread-safe, look at the  :ThreadLocal + SimpleDateFormat =  SimpleDateFormatThreadSafe  in Java 8 is immutable and thread-safe alternative to .Release 3.2 of  will have  class that is a thread-safe substitute of  for Gregorian calendar. See  for more information.Here is a  that proves the fault in the class. I've checked: the problem occurs when using parse and also when you are only using format.Here is the example which results in a strange error. Even Google gives no results:And result :If you want to use the same date format among multiple threads, declare it as a static and synchronize on the instance variable when using it...Here\u2019s an example defines a SimpleDateFormat object as a static field. When two or more threads access \u201csomeMethod\u201d concurrently with different dates, they can mess with each other\u2019s results.You can create a service like below and use jmeter to simulate concurrent users using the same SimpleDateFormat object formatting different dates and their results will be messed up.}The code and jmeter script can be downloaded  ."},
{"body": "I was looking at the Java code for  and noticed that it made use of a static nested class, .What is the reason for using a static nested class, rather than an normal inner class?The only reason I could think of, was that Entry doesn't have access to instance variables, so from an OOP point of view it has better encapsulation. But I thought there might be other reasons, maybe performance. What might it be?Note. I hope I have got my terms correct, I would have called it a static inner class, but I think this is wrong: The Sun page you link to has some key differences between the two:There is no need for  to be  top-level class as it is  used by  (there are some other interfaces that also have static nested classes named , such as  - same concept). And since it does not need access to LinkedList's members, it makes sense for it to be static - it's a much cleaner approach.As , I think it is a better idea if you are using a nested class is to start off with it being static, and then decide if it really needs to be non-static based on your usage.To my mind, the question ought to be the other way round whenever you see an inner class - does it  need to be an inner class, with the extra complexity and the implicit (rather than explicit and clearer, IMO) reference to an instance of the containing class?Mind you, I'm biased as a C# fan - C# doesn't have the equivalent of inner classes, although it does have nested types. I can't say I've missed inner classes yet :)There are non-obvious memory retention issues to take into account here. Since a non-static inner class maintains an implicit reference to it's 'outer' class, if an instance of the inner class is strongly referenced, then the outer instance is strongly referenced too. This can lead to some head-scratching when the outer class is not garbage collected, even though  that nothing references it.Well, for one thing, non-static inner classes have an extra, hidden field that points to the instance of the outer class.  So if the Entry class weren't static, then besides having access that it doesn't need, it would carry around four pointers instead of three.As a rule, I would say, if you define a class that's basically there to act as a collection of data members, like a \"struct\" in C, consider making it static.static nested class is just like any other outer class, as it doesn't have access to outer class members.Just for packaging convenience we can club static nested classes into one outer class for readability purpose. Other than this there is no other use case of static nested class.Example for such kind of usage, you can find in Android R.java (resources) file.\nRes folder of android contains layouts (containing screen designs), drawable folder (containing images used for project), values folder (which contains string constants), etc..Sine all the folders are part of Res folder, android tool generates a R.java (resources) file which internally contains lot of static nested classes for each of their inner folders.\nHere they are using only for packaging convenience. One of the reasons for static vs. normal have to do with classloading. You cannot instantiate an inner class in the constructor of it's parent.PS: I've always understood 'nested' and 'inner' to be interchangeable. There may be subtle nuances in the terms but most Java developers would understand either.Simple example : If non-static the class cannot be instantiated exept in an instance of the upper class (so not in the example where main is a static function)From :Static inner class is used in the builder pattern. Static inner class can instantiate it's outer class which has only private constructor. So you can use static inner class to instantiate the outer class which only has private constructor.  This will output x: 1As per Oracle site below are key benefits using nested class (static or non-static) refer: Why Use Nested Classes?Compelling reasons for using nested classes include the following:It is a way of logically grouping classes that are only used in one \n    place: If a class is useful to only one other class, then it is\n    logical to embed it in that class and keep the two together. Nesting\n    such \"helper classes\" makes their package more streamlined. It increases encapsulation: Consider two top-level classes, A and B,\n    where B needs access to members of A that would otherwise be\n    declared    private. By hiding class B within class A, A's members\n    can be    declared private and B can access them. In addition, B\n    itself can be    hidden from the outside world. It can lead to more readable and    maintainable code: Nesting small classes within\n    top-level classes    places the code closer to where it    is usedNon static inner classes can result in memory leaks while static inner class will protect against them. If the outer class holds considerable data, it can lower the performance of the application.Using a static nested class rather than non-static one may save spaces in some cases. For example: implementing a  inside a class, say Student.Then the  ensures that the Student class has only one Comparator, rather than instantiate a new one every time a new student instance is created. I don't know about performance difference, but as you say, static nested class is not a part of an instance of the enclosing class. Seems just simpler to create a static nested class unless you really need it to be an inner class.It's a bit like why I always make my variables final in Java - if they're not final, I know there's something funny going on with them. If you use an inner class instead of a static nested class, there should be a good reason.Adavantage of inner class--Without existing of outer class inner class will not exist.There are four types of inner class.point --- 10.inner class inside static method then we can access only static  field of outer class."},
{"body": "Is there a way to set my own custom test case names when using parameterized tests in JUnit4?I'd like to change the default \u2014  \u2014 to something meaningful.To use change the name of parameterized tests, you say: is a string, which can have the following special placeholders:The final name of the test will be the name of the test method, followed by the  in brackets, as shown below.For example (adapted from the unit test for the  annotation):will give names like  and .  (The  part of the name is the method name of the ).Looking at JUnit 4.5, its runner clearly doesn't support that, as that logic is buried inside a private class inside the Parameterized class. You could not use the JUnit Parameterized runner, and create your own instead which would understand the concept of names (which leads to the question of how you might set a name ...).From a JUnit perspective, it would be nice if instead of (or in addition to) just passing an increment, they would pass the comma delimited arguments. TestNG does this. If the feature is important to you, you can comment on the yahoo mailing list referenced at www.junit.org.I recently came across the same problem when using JUnit 4.3.1. I implemented a new class  which extends Parameterized called LabelledParameterized. It has been tested using JUnit 4.3.1, 4.4 and 4.5. It reconstructs the Description instance using the String representation of the first argument of each parameter array from the @Parameters method. You can see the code for this at:and an example of its use at:The test description formats nicely in Eclipse which is what I wanted since this makes failed tests a lot easier to find! I will probably further refine and document the classes over the next few days/weeks. Drop the '?' part of the URLs if you want the bleeding edge. :-)To use it, all you have to do is copy that class (GPL v3), and change @RunWith(Parameterized.class) to @RunWith(LabelledParameterized.class) assuming the first element of your parameter list is a sensible label.I don't know if any later releases of JUnit address this issue but even if they did, I can't update JUnit since all my co-developers would have to update too and we have higher priorities than re-tooling. Hence the work in the class to be compilable by multiple versions of JUnit. there is some reflection jiggery-pokery so that it runs across the different JUnit versions as listed above. The version specifically for JUnit 4.3.1 can be found  and, for JUnit 4.4 and 4.5, .With  as a model, I wrote my own custom test runner / suite -- only took about half an hour. It's slightly different from darrenp's  in that it lets you specify a name explicitly rather than relying on the first parameter's .It also doesn't use arrays because I hate arrays. :)And an example:from junit4.8.2, you can create your own MyParameterized class by simply copy Parameterized class. change the getName() and testName() methods in TestClassRunnerForParameters. You may also want to try JUnitParams: You can create a method likeWhile I wouldn't use it all the time it would be useful to figure out exactly which test number 143 is.I make extensive use of static import for Assert and friends, so it is easy for me to redefine assertion:For example, you could add a \"name\" field to your test class, initialized in the constructor, and display that on test failure.  Just pass it in as the first elements of your parameters array for each test.  This also helps label the data:None of it was working for me, so I got the source for Parameterized and modified it create a a new test runner. I didn't have to change much but IT WORKS!!!A workaround would be to catch and nest all Throwables into a new Throwable with a custom message that contains all information about the parameters. The message would appear in the stack trace.\nMy code looks like this:The stack trace of the failed test is:Check out JUnitParams as dsaff mentioned, works using ant to build parameterized test method descriptions in the html report. This was after trying LabelledParameterized and finding that it although it works with eclipse it does not work with ant as far as the html report is concerned.Cheers,Since the parameter accessed (e.g. with  always returns the  representation, one workaround would be to make an anonymous implementation and override  in each case. For example:"},
{"body": "I'm trying to generate Java classes from the FpML (Finanial Products Markup Language) version 4.5. A ton of code is generated, but I cannot use it. Trying to serialize a simple document I get this:In fact  classses have the @XmlRootElement annotation, so what can I be doing wrong?. I'm pointing xjc (JAXB 2.1) to fpml-main-4-5.xsd, which then includes all types.To tie together what others have already stated or hinted at, the rules by which JAXB XJC decides whether or not to put the  annotation on a generated class are non trivial (). exists because the JAXB runtime requires certain information in order to marshal/unmarshal a given object, specifically the XML element name and namespace. You can't just pass any old object to the Marshaller.  provides this information.The annotation is just a convenience, however - JAXB does not require it. The alternative to is to use  wrapper objects, which provide the same information as , but in the form of an object, rather than an annotation. However,  objects are awkward to construct, since you need to know the XML element name and namespace, which business logic usually doesn't. Thankfully, when XJC generates a class model, it also generates a class called . This is partly there for backwards compatibility with JAXB v1, but it's also there as a place for XJC to put generated factory methods which create  wrappers around your own objects. It handles the XML name and namespace for you, so you don't need to worry about it. You just need to look through the  methods (and for large schema, there can be hundreds of them) to find the one you need.This is mentioned at the bottom of the blog post already linked above but this works like a treat for me:As hinted at in one of the above answers, you won't get an XMLRootElement on your root element if in the XSD its type is defined as a named type, since that named type could be used elsewhere in your XSD. Try mking it an anonymous type, i.e. instead of:you would have:@XmlRootElement is not needed for unmarshalling - if one uses the 2 parameter form of Unmarshaller#unmarshall.So, if instead of doing:one should do:The latter code will not require @XmlRootElement annotation at UserType class level.Joe's answer (Joe Jun 26 '09 at 17:26) does it for me. The simple answer is that absence of an @XmlRootElement annotation is no problem if you marshal a JAXBElement. The thing that confused me is the generated ObjectFactory has 2 createMyRootElement methods - the first takes no parameters and gives the unwrapped object, the second takes the unwrapped object and returns it wrapped in a JAXBElement, and marshalling that JAXBElement works fine. Here's the basic code I used (I'm new to this, so apologies if the code's not formatted correctly in this reply), largely cribbed from :You can fix this issue using the binding from .Here is an example with MavenHere is the  file contentIt's not working for us either. But we did find a widely-quoted article that adds SOME background... I'll link to it here for the sake of the next person: With a Maven build, you can add the  annotation with the \"\" plug-in.See more information : see and Did you try to change your xsd like this?As you know the answer is to use the ObjectFactory(). Here is a sample of the code that worked for me :)To soluction it you should configure a xml binding before to compile with wsimport, setting generateElementProperty as false.In case my experience of this problem gives someone a Eureka! moment.. I'll add the following:I was also getting this problem, when using an xsd file that I had generated using IntelliJ's \"Generate xsd from Instance document\" menu option.When I accepted all the defaults of this tool, it generated an xsd file that when used with jaxb, generated java files with no . At runtime when I tried to marshal I got the same exception as discussed in this question.I went back to the IntellJ tool, and saw the default option in the \"Desgin Type\" drop down (which of course I didn't understand.. and still don't if I'm honest) was:Desgin Type:I changed this to , now it generated a (substantially) different xsd, that produced the  when used with jaxb.  Can't say I understand the in's and out's of it, but it worked for me."},
{"body": "I have two sets, A and B, of the same type.I have to find if A contains any element from the set B.What would be the best way to do that without iterating over the sets?\nThe Set library has  and , but not .Wouldn't  work? From the documentation:Thus, the method returns  if the collections contains any common elements.Since Java 8: A good way to implement containsAny for sets is using the Guava . would return a , so the call looks like:This returns true iff the sets are disjoint, otherwise false. The time complexity of this is likely slightly better than retainAll because you dont have to do any cloning to avoid modifying your original set. Apache Commons has a method .Use  in the Set interface. This method provides an intersection of elements common in both sets. See the API docs for more information.You can use  method and get the intersection of your two sets.I would recommend creating a  from set A, and then iterating through set B and checking if any element of B is in A. This would run in  time (as there would be no collisions), whereas  must run in  time.There's a bit rough method to do that. \nIf and only if the A set contains some B's element than the callwill modify the A set. In this situation removeAll will return true (As stated at ). But probably you don't want to modify the A set so you may think to act on a copy, like this way:and the returning value will be true if the sets are not distinct, that is they have non-empty intersection.  Also see I use  \nReturns  if at least one element is in both collections.Simple to use, and the name of the function is more suggestive."},
{"body": "I'm using Ubuntu Gnome 14.04, and I have Java 8 installed (both the JDK and the JRE).When I was installing Android Studio everything worked, but a message appeared saying:How can I install Android Studio correctly, or how do I fix this ?Presuming that you are running the 64bit Ubuntu, the fix suggested for \"Issue \" should solve your problem.Update:\nFor Ubuntu 15.10 & 16.04\n @warsong is right. Installing only  solved the problem.For next uses I rewrite @warsongs comment in answer area. For Ubuntu 15.04,15.10,16.04 LTS & Debian 8For Fedora (tested for Fedora 23/24) runI understand the question is regarding UBUNTU, but I had similar problem in Debian Jessie 64bit and warsongs suggestion worked for it also.\nWhen I ran studio.sh android studio would start, but when I tried to configure the android SDK I got the error\n\nWHen I tried\n\nGot error\n\nSo took warsongs suggestion and only tried to install lib32stdc++6.\n\nAfter this was able to add the Android SDK into Android Studio. The Problem is caused by mksdcard not being installed correctly.if you are running 64 bit, do this to fix the mksdcard problem.and 32 bit:In SDK 6.0, the error message is different but means the same thing.None of these options worked for me on Ubuntu 12.10 (yeah, I need to upgrade).  However, I found an easy solution.  Download the source from here: .  Then simply compile with \"gcc mksdcard.c -o mksdcard\". Backup mksdcard in the SDK tools subfolder and replace with the newly compiled one.  Android Studio will now be happy with your SDK.For Linux Mint runIf you run \nand got a message like: \"\".You can do something like this tut: This issue arises when your 64 bit os tries to install the Android SDK which in turns tries to install some 32 bit binaries and thus is the issue of compatibility. Open an additional terminal and typewould help to install all the required binaries. After this, start the afresh the Android SDK installation process."},
{"body": "In Java, there is a practice of declaring every variable (local or class), parameter final \nif they really are.\nThough this makes the code a lot more verbose, \nthis helps in easy reading/grasping of the code and also prevents mistakes\nas the intention is clearly marked.What are your thoughts on this and what do you follow?I think it all has to do with good coding style. Of course you can write good, robust programs without using a lot of  modifiers anywhere, but when you think about it... Adding  to all things which  change simply narrows down the possibilities that you (or the next programmer, working on your code) will misinterpret or misuse the thought process which resulted in your code. At least it should ring some bells when they now want to change your previously immutable thing.At first, it kind of looks awkward to see a lot of  keywords in your code, but pretty soon you'll stop noticing the word itself and will simply think,  (you can take it from me ;-)I think it's good practice. I am not using it all the time, but when I can and it makes sense to label something  I'll do it.Obsess over:Consider but use judiciously:Ignore unless feeling anal:You really need to understand the full use of the final keyword before using it.  It can apply to and has differing affects on variables, fields, methods and classes I\u2019d recommend checking out the article linked to below for more details.The  modifier, especially for variables, is a means to have the compiler enforce a convention that is generally sensible: make sure a (local or instance) variable is assigned exactly once (no more no less). By making sure a variable is definitely assigned before it is used, you can avoid common cases of a :By preventing a variable from being assigned more than once, you discourage overbroad scoping. Instead of this:You are encouraged to use this:Some links:I'm pretty dogmatic about declaring every possible variable . This includes method parameters, local variables, and rarely, value object fields. I've got three main reasons for declaring final variables everywhere:However, I do think that final classes and methods are not nearly as useful as final variable references. The  keyword, when used with these declarations simply provide roadblocks to automated testing and the use of your code in ways that you could have never anticipated.Effective Java has an item that says \"Favour immutable objects\". Declaring fields as final helps you take some small steps towards this, but there is of course much more to truly immutable objects than that.If you know that objects are immutable they can be shared for reading among many threads/clients without synchronization worries, and it is easier to reason about how the program runs.I have never been in a situation where having a final keyword on a variable has stopped me from making a mistake, so for the moment I think it's a giant waste of time.Unless there is a real reason for doing it (as in you want to make a specific point about that variable being final) I would rather not do it since I find it makes the code less readable.If, however, you don't find it makes the code harder to read or longer to write then by all means go for it. As a clarification (and an attempt to win back down-votes), I'm not saying don't mark constants as final, I'm saying don't do stuff like:It just makes code (in my opinion) harder to read.It's also worth remembering that  final does is prevent you from reassigning a variable, it doesn't make it immutable or anything like that.Final should always be used for constants.  It's even useful for short-lived variables (within a single method) when the rules for defining the variable are complicated.For example:I use  all the time for object attributes.The  keyword has visibility semantics when used on object attributes. Basically, setting the value of a final object attribute happens-before the constructor returns. This means that as long as you don't let the  reference escape the constructor and you use  for  you attributes, your object is (under Java 5 semantics) guarenteed to be properly constructed, and since it is also immutable it can be safely published to other threads.Immutable objects is not just about thread-safety. They also make it a lot easier to reason about the state transitions in your program, because the space of what  change is deliberately and, if used consistently, thoroughly limited to only the things that  change.I sometimes also make methods final, but not as often. I seldomly make classes final. I generally do this because I have little need to. I generally don't use inheritance much. I prefer to use interfaces and object composition instead - this also lends itself to a design that I find is often easier to test. When you code to interfaces instead of concrete classes, then you don't  to use inheritance when you test, as it is, with frameworks such as jMock, much easier to create mock-objects with interfaces than it is with concrete classes.I guess I should make the majority of my classes final, but I just haven't gotten into the habbit yet.I have to read a lot of code for my job. Missing final on instance variables is one of the top things to annoy me and makes understanding the code unnecessarily difficult. For my money, final on local variables causes more clutter than clarity. The language should have been designed to make that the default, but we have to live with the mistake. Sometimes it is useful particularly with loops and definite assignment with an if-else tree, but mostly it tends to indicate your method is too complicated. should obviously be used on constants, and to enforce immutability, but there is another important use on methods. has a whole item on this (Item 15) pointing out the pitfalls of unintended inheritance. Effectively if you didn't design and document your class for inheritance, inheriting from it can give unexpected problems (the item gives a good example). The recommendation therefore is that you use  on any class and/or method that wasn't intended to be inherited from. That may seem draconian, but it makes sense. If you are writing a class library for use by others then you don't want them inheriting from things that weren't designed for it - you will be locking yourself into a particular implementation of the class for back compatibility. If you are coding in a team there is nothing to stop another member of the team from removing the  if they really have to. But the keyword makes them think about what they are doing, and warns them that the class they are inheriting from wasn't designed for it, so they should be extra careful.Sounds like one of the biggest argument  using the final keyword is that \"it's unnecessary\", and it \"wastes space\".If we acknowledge the many benefits of \"final\" as pointed out by many great posts here, while admitting it takes more typing and space, I would argue that Java should have made variables \"final\" by default, and require that things be marked \"mutable\" if the coder wants it to be.Another caveat is that many people confuse final to mean that the contents of the instance variable cannot change, rather than that the reference cannot change. Choosing to type  for each parameter in each method will produce so much irritation both for coders and code readers.Once irritation goes beyond reasonable switch to Scala where arguments are final by default.Or, you can always use code styling tools that will do that automatically for you. All IDEs have them implemented or as plugins.Final when used with  variables in Java provides a substitute for constant in C++. So when final and static is used for a variable it becomes immutable. At the same time makes migrated C++ programmers pretty happy ;-)When used with reference variables it does not allow you to re-reference the object, though the object can be manipulated.When final is used with a method, it does not allow the method to be over-ridden by the subclasses.Once the usage is very clear it should be used with care. It mainly depends on the design as using final on the method would not help polymorphism. One should only use it for variables when you are damn sure that the value of the variable will/should never be changed. Also ensure that you follow the coding convention encouraged by SUN.for eg: final int  COLOR_RED   = 1; (Upper case seperated by underscore)With a reference variable, use it only when we need a an immutable reference to a particular object.Regarding the readability part, ensue that comments play a very important role when using the final modifier.I never use them on local variables, there is little point for the added verbosity.  Even if you don't think the variable should be reassigned, that will make little difference to the next person altering that code that thinks otherwise, and since the code is being changed, any original purpose for making it final may no longer be valid.  If it is just for clarity, I believe it fails due to the negative effects of the verbosity.Pretty much the same applies to member variables as well, as they provide little benefit, except for the case of constants.It also has no bearing on immutability, as the best indicator of something being immutable is that it is documented as such and/or has no methods that can alter the object (this, along with making the class final is the only way to guarantee that it is immutable).But hey, that's just my opinion  :-)I set up Eclipse to add final on all fields and attributes which are not modified. This works great using the Eclipse \"save actions\" which adds these final modifiers (among other things) when saving the file.Highly recommended. Check out  of Eclipse Save Actions.I hardly use final on methods or classes because I like allowing people to override them.Otherwise, I only use finally if it is a Even for local variables, knowing that it is declared final means that I don't need to worry about the reference being changed later on. This means that when debugging and I see that variable later on, I am confident that it is referring to the same object. That is one less thing I need to worry about when looking for a bug.\nA bonus is that if 99% of variables are declared final, then the few variables which really are variable stand out better.\nAlso, the final lets the compiler find some more possible stupid mistakes that might otherwise go unnoticed.For arguments I'm think they're not needed. Mostley they just hurt readabillity. Rreassigning an argument variable is so insanely stupid that I should be pretty confident that they can be treated as constants anyway.The fact that Eclipse colors final red makes it easier to spot variable declarations in the code which I think improves readbillity most of the time.I try to enforce the rule that any and all variables should be final it there isn't an extremley valid reason not to. It's so much easier to answer the \"what is this variable?\" question if you just have to find the initilization and be confident that that is it.I actually get rather nervous around non-final variables now a days. It's like the differnce between having a knife hanging in a thread abouve your head, or just having it you kitchen drawer...A final variable is just a nice way to lable values.A non-final variable is bound to part of some bug-prone algorithm.One nice feature is that when the option to use a variable in out of the question for an algorithm most of the time the sollution is to write a method instead, which usually improves the code significantly.I've been coding for a while now and using final whenever I can. After doing this for a while (for variables, method parameters and class attributes), I can say that 90% (or more) of my variables are actually final. I think the benefit of NOT having variables modified when you don't want to (I saw that before and it's a pain sometimes) pays for the extra typing and the extra \"final\" keywords in your code.That being said, if I would design a language, I would make every variable final unless modified by some other keyword.I don't use final a lot for classes and methods, thought. This is a more or less complicated design choice, unless your class is a utility class (in which case you should have only one private constructor).I also use Collections.unmodifiable... to create unmodifiable lists when I need to.Using anonymous local classes for event listeners and such is a common pattern in Java.\nThe most common use of the final keyword is to make sure that variables in scope are accessible to the even listener.However, if you find yourself being required to put a lot of final statements in your code. That might be a good hint you're doing something wrong.The article posted above gives this example:I use it for constants inside and outside methods.I only sometimes use it for methods because I don't know if a subclass would NOT want to override a given method(for whatever reasons).As far as classes, only for some infrastructure classes, have I used final class.IntelliJ IDEA warns you if a function parameter is written to inside a function. So, I've stopped using final for function arguments. I don't see them inside java Runtime library as well.Using final  is strongly encouraged. However, I wouldn't use it for methods or classes (or at least think about it for a while), because it makes  harder, if not impossible. If you absolutely must make a class or method final, make sure this class implements some interface, so you can have a  implementing the same interface.Marking the class final can also make some method bindings happen at compile time instead of runtime. \nConsider \"v2.foo()\" below - the compiler knows that B cannot have a subclass, so foo() cannot be overridden so the implementation to call is known at compile time.  If class B is NOT marked final, then it's possible that the actual type of v2 is some class that extends B and overrides foo()."},
{"body": "I'm using Spring to define stages in my application. It's configured that the necessary class (here called ) is injected with the stages.\nNow I need the List of Stages in another class, named . The  doesn't offer access to his List of Stages.I cannot change the class .My Idea:\nDefine a new bean called Stages and inject it to  and .\nMy problem with this idea is that I don't know how to transform this property:into a bean.Something like this does not work:Can anybody help me with this?Import the spring util namespace. Then you can define a list bean as follows:The value-type is the generics type to be used, and is optional. You can also specify the list implementation class using the attribute .Here is one method:Another option is to use JavaConfig. Assuming that all stages are already registered as spring beans you just have to:and spring will automatically inject them into this list. If you need to preserve order (upper solution doesn't do that) you can do it in that way:The other solution to preserve order is use a  annotation on beans. Then list will contain beans ordered by ascending annotation value.And in SomeClass:Stacker posed a great answer, I would go one step farther to make it more dynamic and use Spring 3 EL Expression. I was trying to figure out how I could do this with the util:list but couldn't get it work due to conversion errors. I think you may be looking for .You declare a ListFactoryBean instance, providing the list to be instantiated as a property withe a  element as its value, and give the bean an  attribute.  Then, each time you use the declared  as a  or similar in some other bean declaration, a new copy of the list is instantiated.  You can also specify the  class to be used.Use the util namespace, you will be able to register the list as a bean in your application context. You can then reuse the list to inject it in other bean definitions.As an addition to Jakub's answer, if you plan to use JavaConfig, you can also autowire that way:And this is how to inject set in some property in Spring:"},
{"body": "Can anyone tell me how to get the filename without the extension?\nExample:If you, like me, would rather use some library code where they probably have thought of all special cases, such as what happens if you pass in  or dots in the path but not in the filename, you can use the following:The easiest way is to use a regular expression.The above expression will remove the last dot followed by one or more characters.  Here's a basic unit test.See the following test program:which outputs:If your project uses  (14.0 or newer), you can go with .(Essentially the same as  from Apache Commons IO, as the  suggests. Just wanted to point out Guava does this too. Personally I didn't want to add dependency to Commons\u2014which I feel is a bit of a relic\u2014just because of this.)Here is the consolidated list order by my preference.While I am a big believer in reusing libraries, the  is 174KB, which is noticably large for a mobile app.  If you download the source code and take a look at their FilenameUtils class, you can see there are a lot of extra utilities, and it does cope with Windows and Unix paths, which is all lovely.However, if you just want a couple of static utility methods for use with Unix style paths (with a \"/\" separator), you may find the code below useful.  The  method preserves the rest of the path along with the filename.  There is also a similar .Below is reference from If you don't like to import the full apache.commons, I've extracted the same functionality:Try the code below. Using core Java basic functions. It takes care of s with extension, and without extension (without the  character). The case of multiple  is also covered.You can adapt it to work with  strings.?indexOfExtension or indexOfDOT?"},
{"body": "Searching SO and Google, I've found that there are a few Java HTML parsers which are consistently recommended by various parties. Unfortunately it's hard to find any information on the strengths and weaknesses of the various libraries. I'm hoping that some people have spent some comparing these libraries, and can share what they've learned.Here's what I've seen:And if there's a major parser that I've missed, I'd love to hear about its pros and cons as well.Thanks!Almost all known HTML parsers implements the  (part of the JAXP API, Java API for XML processing) and gives you a  back which is ready for direct use by JAXP API. The major differences are usually to be found in the features of the parser in question. Most parsers are to a certain degree forgiving and lenient with non-wellformed HTML (\"tagsoup\"), like , ,  and . You usually use this kind of HTML parsers to \"tidy\" the HTML source (e.g. replacing the HTML-valid  by a XML-valid ), so that you can traverse it \"the usual way\" using the W3C DOM and JAXP API.The only ones which jumps out are  and .  provides a completely own API which gives you the possibility to act like a webbrowser programmatically. I.e. enter form values, click elements, invoke JavaScript, etcetera. It's much more than alone a HTML parser. It's a real \"GUI-less webbrowser\" and HTML unit testing tool. also provides a completely own API. It gives you the possibility to select elements using -like  and provides a slick API to traverse the HTML DOM tree to get the elements of interest. Particularly the traversing of the HTML DOM tree is the major strength of Jsoup. Ones who have worked with  know what a hell of pain it is to traverse the DOM using the verbose  and  APIs. True,  makes the life easier, but still, it's another learning curve and it can end up to be still verbose. Here's an example which uses a \"plain\" W3C DOM parser like JTidy in combination with XPath to extract the first paragraph of your question and the names of all answerers (I am using XPath since without it, the code needed to gather the information of interest would otherwise grow up 10 times as big, without writing utility/helper methods).And here's an example how to do exactly the same with Jsoup:Do you see the difference? It's not only less code, but Jsoup is also relatively easy to grasp if you already have moderate experience with CSS selectors (by e.g. developing websites and/or using jQuery).The pros and cons of each should be clear enough now. If you just want to use the standard JAXP API to traverse it, then go for the first mentioned group of parsers. There are pretty  of them. Which one to choose depends on the features it provides (how is HTML cleaning made easy for you? are there some listeners/interceptors and tag-specific cleaners?) and the robustness of the library (how often is it updated/maintained/fixed?). If you like to unit test the HTML, then HtmlUnit is the way to go. If you like to extract specific data from the HTML (which is more than often the real world requirement), then Jsoup is the way to go. compares certain aspects of the following parsers:It is by no means a complete summary, and it is from 2008.  But you may find it helpful.Add , an implementation of the HTML5 parsing algorithm in Java, to your list. On the plus side, it's specifically designed to match HTML5, and at the heart of the HTML5 validator, so highly likely to match future browser's parsing behaviour to a very high degree of accuracy.On the minus side, no browsers' legacy parsing works exactly like this, and as HTML5 is still in draft, subject to change. In practice, such problems only affect obscure corner cases, and is for all practical purposes, an excellent parser.I found  HTML Parser to be very well written, kept up to date (which many of the parsers are not), no dependencies, and easy to use.I'll just add to @MJB answer after working with most of the HTML parsing libraries in Java, there is a huge pro/con that is omitted: parsers that preserve the formatting and incorrectness of the HTML on input and output.That is most parsers when you change the document will blow away the whitespace, comments, and incorrectness of the DOM particularly if they are an XML like library. is the only parser I know that allows you to manipulate nasty HTML while preserving whitespace formatting and the incorrectness of the HTML (if there is any).Two other options are  and . I have tried most of the parsers here for a crawler / data extraction framework I have been developing. I use HTMLCleaner for the bulk of the data extraction work. This is because it supports a reasonably modern dialect of HTML, XHTML, HTML 5, with namespaces, and it supports DOM, so it is possible to . It's a lot easier to do this with HTMLCleaner than some of the other parsers: JSoup for example supports a DOM like interface, rather than DOM, so . Jericho has a SAX-line interface so again it is requires some work although  but in the end HTMLCleaner just worked better.I also use HTMLParser and Jericho for a table extraction task, which replaced some code written using Perl's . I use HTMLParser to filter the HTML for the table, then use Jericho to parse it. I agree with MJB's and Adam's comments that Jericho is good in some cases because it preserves the underlying HTML. It has a kind of non-standard SAX interface, so for XPath processing HTMLCleaner is better.Parsing HTML in Java is a surprisingly hard problem as all the parsers seem to struggle on certain types of malformed HTML content."},
{"body": "I cannot for the life of me find a definition of what the Java VM flag  actually does, other than some very fuzzy high-level definitions such as \"gets rid of your PermGen problems\" (, btw).I have looked on Sun's/Oracle's site, and even  doesn't actually say what it does.Based upon the name of the flag, I'm guessing that the CMS Garbage Collector doesn't by default unload classes, and this flag turns it on - but I can't be sure.The standard Oracle/Sun VM look on the world is: Classes are forever. So once loaded, they stay in memory even if no one cares anymore. This usually is no problem since you don't have that many purely \"setup\" classes (= used once for setup and then never again). So even if they take up 1MB, who cares.But lately, we have languages like Groovy, that define classes at runtime. Every time you run a script, one (or more) new classes are created and they stay in PermGen forever. If you're running a server, that means you have a memory leak.If you enable  the GC will sweep PermGen, too, and remove classes which are no longer used. You will also have to enable  (thanks to ). See this answer: According to the blog post , it determines if class unloading is enabled under the CMS garbage collector.  The default is .  There is another option called  that is  by default which (presumably) affects the other garbage collectors.The idea is that if the GC detects that a previously loaded class is no longer used anywhere in the JVM, it can reclaim the memory used to hold the classes bytecode and/or native code.Setting CMSClassUnloadingEnabled  help with your permgen problem .  But the chances are that you are not using the CMS, or that you have a genuine classloader related memory leak.  In the latter case, your class will never appear to the GC to be unused ... and will therefore never be unloaded.Aaron Digulla says \"classes are for ever\".  This is not strictly true, even in the purely Java world.  In fact, the lifetime of a class is tied to its classloader.  So if you can arrange that a classloader is garbage collected (and that is not always an easy thing to do) the classes that it loaded will also be garbage collected.In fact, this is what happens when you do a hot redeploy of a webapp.  (Or at least, that's what should happen, if you can avoid the problems that lead to a permgen storage leak.)An example where this is useful:Setting  on our Weblogic 10.3 JVM helped resolving a problem where the JAX-WS implementation created a new proxy class for every web service call, eventually leading to out of memory errors. It wasn't trivial to trace. The following code always returned the same proxy class for Internally, this proxy delegated to an instance of , which again delegated to a new  class where  was incremented at every call. When adding the flags,  was still incremented, but at least those temporary classes were removed from memory.On a more general note, this can be very useful when making heavy use of Java reflection and proxies through "},
{"body": "Continuing from Stack Overflow question :What is the most efficient way to get a Date object without the time? Is there any other way than these two?:Do you absolutely  to use ? I would  recommend that you use  or the  package from Java 8 instead. In particular, while Date and Calendar  represent a particular instant in time, with no such concept as \"just a date\", Joda Time  have a type representing this (). Your code will be much clearer if you're able to use types which represent what you're actually trying to do.There are many, many other reasons to use Joda Time or  instead of the built-in  types - they're generally far better APIs. You can always convert to/from a  at the boundaries of your own code if you need to, e.g. for database interaction.Here is what I used to get today's date with time set to :You can use the  from Apache Commons library.Example: Yes, there is. Java 8 and later comes with the new  built-in. See . Much of the java.time functionality is back-ported to Java 6 & 7 in  and further adapted to Android in .Similar to , java.time offers a  class to represent a date-only value without time-of-day and without time zone.Note that  to determining a particular date. At the stroke of midnight in Paris, for example, the date is still \u201cyesterday\u201d in Montr\u00e9al. By default, java.time uses the  standard in generating a string representation of a date or date-time value. (Another similarity with Joda-Time.) So simply call  to generate text like .The most straightforward way:The standard answer to these questions is to use . The API is better and if you're using the formatters and parsers you can avoid the non-intuitive lack of thread safety of . Using Joda means you can simply do: Using java 8 this can be acheived using It does not make sense to talk about a date without a timestamp with regards to the Date routines in the standard java runtime, as it essentially maps down to a specific millisecond and not a date.  Said millisecond intrinsically has a time of day attached to it which makes it vulnerable to timezone problems like Daylight Savings Time and other calendar adjustments.    See  for an interesting example.If you want to work with dates instead of milliseconds, you need to use something else.  For Java 8 there is a new set of methods providing exactly what you ask for.  For Java 7 and earlier use Well, as far as I know there is no easier way to achieve this if you only use the standard JDK.You can, of course, put that logic in method2 into a static function in a helper class, like done Then you can shorten the second method to:Or, if you really need the current day in this format so often, then you can just wrap it up in another static helper method, thereby making it a one-liner.Definitely not the most correct way, but if you just need a quick solution to get the date without the time and you do not wish to use a third party library this should doI only needed the date for visual purposes and couldn't Joda so I substringed.If you need the date part just for echoing purpose, thenIf all you want is to see the date like so \"YYYY-MM-DD\" without all the other clutter e.g. \"Thu May 21 12:08:18 EDT 2015\" then just use .  This example gets the current date:Also  is a subclass of .If you just need the current date, without time, another option is:This is a simple way of doing it:Check out . It is a simple and efficient alternative to both java.util and Joda-time. It has an intuitive API and classes that represent dates alone, without timestamps.The most straigthforward way that makes full use of the huge TimeZone Database of Java and is correct:Here is a clean solution with no conversion to string and back, and also it doesn't re-calculate time several times as you reset each component of the time to zero. It also uses  (modulus) rather than divide followed by multiply to avoid the double operation.It requires no third-party dependencies, and it RESPECTS THE TIMEZONE OF THE Calender object passed in. This function returns the moment in time at 12 AM in the timezone of the date (Calendar) you pass in.Prefer not to use third-party libraries as much as possible. I know that this way is mentioned before, but here is a nice clean way:Well, not using GregorianCalendar is maybe an option!"},
{"body": "we are in the planning stage of migrating a large website which is built on a custom developed mvc framework to a java based web framework which provides built-in support for ajax, rich media content, mashup, templates based layout, validation, maximum html/java code separation. Grails looked like a good choice, however, we do not want to use a scripting language. We want to continue using java. Template based layout is a primary concern as we intend to use this web application with multiple web sites with similar functionality but radically different look and feel. Is portal based solution a good fit to this problem? Any insights on using \"Spring Roo\" or \"Play\" will be very helpful.I did find similar posts like , but it is more than a year old. Things have surely changed in the mean time! Thanks for the great answers! This site is turning to be the best single source for in-the-trenches programmer info. However, I was expecting more info on using a portal-cms duo. Jahia looks goods. Anything similar?Personally, I would stay away from big fat Portal solutions (they are often productivity killers). I've heard good things about  though but I don't have any real experience with it.About Spring Roo, I've read previous answers like  and other things over the Internet but I'm still not convinced (maybe I don't get it), I'm not sure of its maturity, and, more important, I'm really wondering what SpringSource is doing with Grails and Roo (no,  doesn't convince me that they will both survive).I can't say much about Play. I've seen the demo like everybody but I would like to read real life feedback. Until then, I'll wait.Yes and no :) But let's enter the presentation frameworks hell: there is no single answer to your question (like one year ago), there are dozen of frameworks around there and no clear winner. Just to cite a  few:Actually, I'd suggest to take a look at Matt Raible's , he really did a great job at comparing web frameworks, showing their strengths and weakness, gathering facts and numbers, showing trends... I recommend:Really, have a look at these presentations, they will help you to find an appropriate framework (there is no unique answer but you can restrict the choice by elimination) and might change your point of view.I've been using Spring 3 and Jquery for a while but heard about Play and gave it a shot. I really like it, Play is a great fit between something like PHP and the heavy duty Java frameworks like Spring.The things I like most about play are:Things I don't like about PlayTop choice for me is . Clear separation of markup and java code. Very easy to write and use components. Simple to use Ajax, testability. You can debug right into your pages / components and don't get cryptic error messages from your JSF implementation ;)There is also a good comparison wicket <--> JSF in The top three choices for me are (alphabetically):They:Play is closely similar to ROR, a ROR version in javaIn contrast to other answers, I'd like to highlight the disadvantages (IMHO) of popular web frameworks: - Released and already aged. Still only a few news/articles/blog posts/experiences out. I am skeptical. Still waiting for the next major release of Richfaces/Icefaces which fully supports jsf 2 -  currently only alpha builds can be downloaded. - Seems to be only a good thing if you're still relying on struts and want to refactor most of your code. Otherwise: Don't. - I do not like the single-page and the java->javascript approach. I am not sure if one session - multiple views/windows can be easily achieved. For me, this framework should be used for massive-users single-window rich internet applications. - Nice approach, but a little bit verbose and too less documentation available (except the good wicket in action book, but this covers only 1.3). Also, for me it lacks of big projects which are built on top on it. And I currently cannot see where the road of wicket is traveling or if it has already been driven to a dead end. - Did not tried this yet, but you have to include many jars (spring mess) in your classpath to work with this framework properly. And it relies on JSP (in most projects), which I consider already dead. And you get only a pure MVC framework - all other things (ajax and others) have to be implemented/integrated. - A small and nice designed MVC framework, but too less documentation, too less commits/committers, too few releases, too less industry support, too less mailing list activity.I am also curious if I missed a major framework out there (I left Tapestry out intentionally) which might be an option for you (and also for me, too).I have had great success with . It is the only Java Web Framework that has some sort of JSR spec and multiple implementations other than the servlet and portlet spec (although this can be a bad thing).One thing that is bad and good about Java is that you can pick and match frameworks (python also has this feature/problem). Its nice because you don't have to put all your eggs in one basket.Here is a general Java Web Application Stack Recipe: JQuery, Prototype, Dojo Spring MVC, Stripes, and my favorite JAX-RS (Jersey, Apache CXF) Spring, Guice JPA (Hibernate, Google App storage), Hibernate, JDO and more.I also have had great success in using AspectJ to make Java \"suck less\". By using Spring's @Configurable and AspectJ's ITD mixins you can get Rails like Domain objects (this is infact what Roo does but you don't need Roo to do this).I've found  to be really effective and surprisingly lightweight....it aims to be more lightweight than . I've heard from friends that are fulltime web developers that JSF is not worth bothering with, although I have no firsthand experience, and can't back that up with examples (!).Have a look to , that follow the same principles that Play! but implemented by reusing some enterprise grade frameworks/tools like Maven 3/Spring 3/Jersey/jQuery.RESThub is very disruptive comparing to other frameworks since it is a full stack toolkit, but without any serverside MVC or servlet based framworks. Instead, it use a jQuery UI based GUI that use JAX-RS (REST) webservices and a Javascript templating system based on embeddedJs.Servers are stateless, and we use HTML5 sessionStorage to keep session on client side. This approach is design for RIA and scalability.Some demo applications are provided (even if under construction).I would second the Spring recommendation.  I'm not a huge fan GWT, I don't think the Java -> Javascript crosscompiler is quite there yet.  I am working on an AJAX app that uses spring on the server and jQuery on the client. Although there is technically not \"out-of-the-box\" support for jQuery, implementing a spring-MVC AjaxView is dead simple and took about 25 lines of code.  JSF is a nice framewrok, but JSF 1.2 lacked vision for years to come from its release. JSF 2.0 looks promising and has many new things added fro m JSF 1.2 like ajax support, facelets, Annotation support and default conventions (less XML),easy component building than 1.2.It integrates well with Spring also, if you are concerned for DI support.Maybe a little bit late to the show, but I  to mention . Programming is done in Java exclusively, with a component-based approach. Client-Server communication is more about user interaction than data transport, all business logic resides on server. Ext GWT + SpringI think what you are looking for is something close to Jahia. It supports GWT, Mashups, Media Content etc. \nCouple of years back have used portal software \"\" this was not very matured then.\nBut was good and easy for development.Something that deserves more than just a bullet are player based RIA frameworks. Ex. Adobe Flex + Java (Of course this can hinge somewhat on whether your \"site\" is really a \"site\" or more like an \"application\", you wouldn't do a blog site in Flex.)In the AJAX-as-a-buzzword sense, Flex typically uses AMF (a binary protocol that's  than protocols used by AJAX apps), although you can also do strictly AJAX stuff with Flex too. So Flex supports AJAX, but also supports \"better than AJAX\".Being that Flex runs on the Flash 'virtual machine' platform, I think little needs to be added.Not sure what this is getting at exactly, but it sounds like Flex mxml.Supported of course, although you may decide to do some custom stuff if you want to get fancy. (Not that you have to.) The nice thing is that you can get as sophisticated as you want--or not.You can't get more separated by using a 'virtual machine' development approach like Flex/Silverlight/JavaFX. This doesn't just enable you to keep your presentation code separated from your server-side logic and data access layer--it  that they're separated. 'Virtualizing' your development environment gets you cross-browser compatibility, a consistent target platform, no worries about new browsers or new browser releases breaking your application, top of the line java-like debugging capabilities, and a more professional/impressive looking end product.Take a look to ItsNat is basically a Java W3C browser in server, amazingly simple (DHTML in server), promoting AJAX intensive  applications"},
{"body": "I am trying to split the Value using a separator.\nBut I am finding the surprising resultsI am expecting to get 8 values. \nBut I am getting only 6 values.Any idea and how to fix. No matter EMPTY value comes at anyplace, it should be in array. by default removes trailing empty strings from result array. To turn this mechanism off we need to use overloaded version of  with  set to negative value likeLittle more details:\n internally returns result of  and in  of this method you can find (emphasis mine):It is worth mentioning that removing trailing empty string makes sense . So for  since we can't split  farther we will get as result  array.\nIt happens because split didn't happen here, so  despite being empty and trailing represents  string, not empty string which was  by splitting process.From the documentation of :So you will have to use the two argument version  with a negative value:Doc:This will not leave out any empty elements, including the trailing ones.From :Overloaded  is more appropriate for your case.Another option is to use Guava's Splitter. It not does have the overhead of a regular expression (which you don't need in this case) and by default does not discard empty trailing strings. For example:For further information, see wiki:\n"},
{"body": "I've found the  pretty awesome for keeping hardcoded strings out of my code, and I'd like to keep using it in a utility class that works with models in my application to generate output. For instance, in this case I am generating an email from a model outside of the activity. ? I suppose I could pass in the current activity, but it seems unnecessary. Please correct me if I'm wrong!Edit: Can we access the resources  using ?You can use:... everywhere in your application, even in static constants declarations.\nUnfortunately, it supports .For local resources use . It is not trivial, but it works.Unfortunately, the only way you can access any of the string resources is with a  (i.e. an  or ).  What I've usually done in this case, is to simply require the caller to pass in the context.in MyApplication, which extends :in MyApplication's onCreate:Ta-da!!!! Now you can use this field from anywhere in your application.BTW, one of the reason of  error may be that your IDE imported android.R; class instead of yours one. Just change  to So 2 basic things to get string visible in the different class:If you have a class that you use in an activity and you want to have access the ressource in that class, I recommend you to define a context as a private variable in class and initial it in constructor:Making an instant of class in your activity:I have a utility class Util that wants to call , so I've added a static Context variable with setter:so from each Activity's onCreate, I have to make sure I've initialized the static, i.e.and then from anywhere in my Util I can say reference , such asThis should get you access to  from anywhere allowing you to get  anywhere that can use it; , , , etc.The Singleton:Initialize the Singleton in your  subclass:If I\u00b4m not wrong, this gives you a hook to applicationContext everywhere, call it with \nYou shouldn\u00b4t need to clear this at any point, as when application closes, this goes with it anyway.Remember to update  to use this  subclass:Please let me know if you see anything wrong here, thank you. :)I used \n\nIt works for me."},
{"body": "I'm using Eclipse to generate  and , and there is an option labeled \"Use 'instanceof' to compare types\".  The default is for this option to be unchecked and use  to compare types.  Is there any reason I should prefer  over ?Without using :Using :I usually check the  option, and then go in and remove the \"\" check. (It is redundant since null objects will always fail .)  Is there any reason that's a bad idea?If you use , making your  implementation  will preserve the symmetry contract of the method: . If  seems restrictive, carefully examine your notion of object equivalence to make sure that your overriding implementations fully maintain the contract established by the  class. favors your approach:See also .Effective Java  also covers this.Angelika Langers  gets into that with a long and detailed discussion for a few common and well-known examples, including by Josh Bloch and Barbara Liskov, discovering a couple of problems in most of them. She also gets into the  vs . Some quote from itThe reason to use  is to ensure the symmetric property of the  contract. From equals' JavaDocs:By using instanceof, it's possible to not be symmetric. Consider the example:\nDog extends Animal.\nAnimal's  does an  check of Animal.\nDog's  does an  check of Dog.\nGive Animal  and Dog  (with other fields the same):This violates the symmetric property.To strictly follow equal's contract, symmetry must be ensured, and thus the class needs to be the same.This is something of a religious debate. Both approaches have their problems. has another relevant piece of advice in :Correct me if I am wrong, but getClass() will be useful when you want to make sure your instance is NOT a subclass of the class you are comparing with. If you use instanceof in that situation you can NOT know that because:It depends if you consider if a subclass of a given class is equals to its parent.here I would use 'instanceof', because I want a LastName to be compared to FamilyNamehere I would use 'getClass', because the class already says that the two instances are not equivalent.If you want to ensure only that class will match then use .  If you want to match subclasses then  is needed.Also, instanceof will not match against a null but is safe to compare against a null.  So you don't have to null check it. works for instences of the same class  its subclassesArryaList and RoleList are both  ListWhile  will be  true only if both objects ( this and o ) belongs to exactly the same class.So depending on what you need to compare you could use one or the other. If your logic is: \"One objects is equals to other only if they are both the same class\" you should go for the \"equals\", which I think is most of the cases. Both methods have their problems.  If the subclass changes the identity, then you need to compare their actual classes.  Otherwise, you violate the symmetric property.  For instance, different types of s should not be considered equivalent, even if they have the same name.However, some subclasses don't change identity and these need to use .  For instance, if we have a bunch of immutable  objects, then a  with length and width of 1 should be equal to the unit .In practice, I think the former case is more likely to be true.  Usually, subclassing is a fundamental part of your identity and being exactly like your parent except you can do one little thing does not make you equal.Actually instanceof check where an object belongs to some hierarchy or not. ex: Car object belongs to Vehical class. So \"new Car() instance of Vehical\" returns true. And \"new Car().getClass().equals(Vehical.class)\" return false, though Car object belongs to Vehical class but it's categorized as a separate type."},
{"body": "I want to write a new file with the . I use it like this:Now  and  currently don't exist. I want Java to create them automatically if they aren't already there. Actually Java should set up the whole file path if not already existing.How can I achieve this?Something like:Since Java 1.7 you can use Files.createFile:Use :Use .Use  to handle all these headaches. Edit: For example, use below code to write to a file, this method will 'checking and creating the parent directory if it does not exist'. "},
{"body": "I want to do something like this in Java but I don't know the way:When event \"object 1 say 'hello'\" happens,\nthen object 2 responds to that event by saying \"hello\".Can somebody give me a hint or sample code?You probably want to look into the .Here's some sample code to get yourself started:Related article: What you want is an implementation of the . You can do it yourself completely, or use java classes like  and There are 3 different ways you may wish to set this up: Defaults to Option 3, to try the others simply uncomment the \"\" code block of the class you want to be main, and set that class as the  variable in the  file:"},
{"body": "Is there a good tool that can help to reverse engineer Java classes to UML that will show an overview of how my classes are related to each other? It doesn't need to decompile from JAR file because I have the sources. I know there are quite a few out there but most of those can only generate individual class. I hope there is a tool that can generate class diagram that shows an overview of how all my current classes and packages work together, so that I can analyse my current architecture design. Of course, analysing is one thing. The other is for documentation purposes. I know of a few so far. But they cannot do an overview class diagram. Here's a list of Java UML tool that I have tried and is capable of doing reverse engineer but cannot do an overview class diagram of my whole project:Are there any other recommendations to add to this list? And hopefully, can generate an overview Java class diagram. I am using Eclipse, by the way.I use  plugin from Soyatec, under Eclipse and it works fine for the generation of UML giving the source code. does it.\nIt's free tool which has all the mentioned functionality - I personally use it for the same purposes, as described in this post.\nFor each browsed class it shows 2 instantly generated class diagrams: class relations and class UML view.\nClass relations diagram allows to traverse through the whole structure.\nIt has full support for annotations and generics plus special support for JPA entities.\nWorks very well with big projects (thousands of classes).I\u00b4d say  is by far the most powerful one (though probably not the easiest one to work with).MoDisco is a generic reverse engineering framework (so that you can customize your reverse engineering project, with MoDisco you can even reverse engineer the behaviour of the java methods, not only the structure and signatures) but also includes some predefined features like the generation of class diagrams out of Java code that you need.How about the  Plugin for Eclipse. I have used it and I find it to be quite useful. Although if you are generating diagrams for large sources, you might have to start Eclipse with more memory."},
{"body": "Does somebody know of a tutorial or an example of how to implement the standard  with s? In other words, is it possible to put a standard search with a  in a Fragment?In short, you can't. There are a couple of reasons why creating a search interface within a  is not possible.That being said, it doesn't seem like it would be too difficult to achieve something similar to what you are describing. For instance, you might consider implementing your searchable-Activity so that it will accept the  intent and (instead of immediately displaying the results in a , for example) will pass the search query to your s. For instance, consider the following searchable Activity:When a search-request is made, the system will launch your searchable activity, perform the query, and will pass the results to some container Activity (based on your implementation of ). The container Activity will then pass these results to the contained searchable , in which the results will be displayed. The implementation requires a bit more work than what you were probably hoping for, but I'm sure there are ways that you can make it more modular, and it seems like this might be the best that you can do.p.s. If you use this approach, you might have to pay special attention to which Activitys are added/removed to the backstack. See this  for some more information on how this might be done.p.p.s. You might also forget about the standard search interface completely and just implement a simple search within a  as described in .Here is the example to search something using fragments. Hope it helps and this is what you are looking for:It is quite possible to search in a fragment using the standard ActionBar SearchView ActionView API. This will work back to Android 2.1 (API level 7) too using AppCompat support classes v7. In your fragment:In your menu XMLUsing AppCompat support classes v7. Just adding something to  's solution from  solution to get it work properly in a simple manner, here is my fragment code::I added the , cuz without calling  the system will not know that this fragment needs to interact with the menu.then I removed the line  because it doubled the menu items since Activity inflated a menu, then Fragment inflated another menuThanks to @David and @Rookie When working with  you still need to use an  to control and assign the .\nThis  can have search functionality as before.I've recently switched from a 'normal'  based app, to a  based app and the search functionality worked just the same for me.Have you tried working on it, and didn't succeed? If so give some more detail in your question.EDIT:If you want to have a fragment specific search, have all your  extend an interface  with a  method, and have your 's  method call the current fragment's  method.I think I achieved it : you can actually use fragments and add a search icon to an action bar so that a search is possible inside the fragments. The trick is to use an action bar, an action view, a listener for it, a loader and an adapter of course. This works pretty well although it completely bypasses the android platform search mechanism (but it could be completed with some work to find what @Alex Lockwood describes and pass the search to fragments). It would not react to an intent as expected in the case of an activity, but it works : users can search inside fragments. Here is the code : The xml file for the menu of the search fragments res/menu/menu_search.xml: And the xml layout file res/layout/search_in_fragments.xmlUse the  and . You will be able to handle searches without any connection to Activity. Just set an  to the SearchView.See  post for more details on custom search.A  cannot exist outside an , nor can a  be linked to a  or any other .So without using an  to wrap the the , what you're asking is not possible.In case of Fragments into a ViewPager, I could do it by blocking the search button when I'm not on the fragment where I want to give a search bar. Into the activity: And in case of no physical search button, I added an action item into the fragment, which trigger this code:yes its  possible, please implements Search view on your Activity ,'onQueryTextChange' in  Activity will also listen the  search in  fragment, you can check the fragment    visibility in  'onQueryTextChange' , if it visible you  can call  your search method for fragment, its  working  perfect in  my  codei found a work around :)\nyou can override this method (startActivity(Intent) ) in your BaseActivity and then check if the action is ACTION_SEARCH then do your special job :Dothers solution..... i dont like that.\nThis more easy for me.But its  my idea.Im waiting yours opinion"},
{"body": "How can I use a servlet filter to change an incoming servlet request url fromto?: according to BalusC's steps below, I came up with the following code:The relevant entry in  look like this:I tried both server-side and client-side redirect with the expected results. It worked, thanks BalusC!Don't forget to add a check in the code if the URL  to be changed and if , then just call , else it will call itself in an infinite loop.Alternatively you can also just use an existing 3rd party API to do all the work for you, such as  which can be configured the way as you would do with Apache's .You could use the ready to use  with a rule like this one:Check the  for more... examples.Please note that if your original URL contains parameters, i.e. ? then these parameters will be also forwarded to next servlet/jsp.\nI didn't find a way to get rid of or replace original parameters (only by using HttpServletRequestWrapper). Any ideas?..Update: it seems that  addresses this problem.A simple JSF Url Prettyfier filter based in the steps of . The filter forwards all the requests starting with the /ui path (supposing you've got all your xhtml files stored there) to the same path, but adding the xhtml suffix."},
{"body": "I have a loop that looks something like this:This is the main content of a method whose sole purpose is to return the array of floats. I want this method to return  if there is an error, so I put the loop inside a  block, like this:But then I also thought of putting the  block inside the loop, like this:Is there any reason, performance or otherwise, to prefer one over the other? The consensus seems to be that it is cleaner to put the loop inside the try/catch, possibly inside its own method. However, there is still debate on which is faster. Can someone test this and come back with a unified answer?PERFORMANCE:There is absolutely no performance difference in where the try/catch structures are placed. Internally, they are implemented as a code-range table in a structure that is created when the method is called. While the method is executing, the try/catch structures are completely out of the picture unless a throw occurs, then the location of the error is compared against the table.Here's a reference: The table is described about half-way down.: as  said in his reply, in Java it doesn't make much difference., for readability of the code, your choice of where to catch the exception depends upon whether you want the loop to keep processing or not.  In your example you returned upon catching an exception.  In that case, I'd put the try/catch around the loop.  If you simply want to catch a bad value but carry on processing, put it inside.  : You could always write your own static ParseFloat method and have the exception handling dealt with in that method rather than your loop.  Making the exception handling isolated to the loop itself!All right, after  that there was no performance difference (as of 1997), I went and tested it. I ran this small benchmark:I checked the resulting bytecode using javap to make sure that nothing got inlined.The results showed that, assuming insignificant JIT optimizations, ; there is absolutely  (I did not have access to other versions). The total time difference is on the order of a few milliseconds over the entire test.Therefore, the only consideration is what looks cleanest. I find that the second way is ugly, so I will stick to either the first way or .I agree with all the performance and readability posts.  However, there are cases where it really does matter.  A couple other people mentioned this, but it might be easier to see with examples.Consider this slightly modified example:If you want the parseAll() method to return null if there are any errors (like the original example), you'd put the try/catch on the outside like this:In reality, you should probably return an error here instead of null, and generally I don't like having multiple returns, but you get the idea.On the other hand, if you want it to just ignore the problems, and parse whatever Strings it can, you'd put the try/catch on the inside of the loop like this:As already mentioned, the performance is the same.  However, user experience isn't necessarily identical.  In the first case, you'll fail fast (i.e. after the first error), however if you put the try/catch block inside the loop, you can capture all the errors that would be created for a given call to the method.  When parsing an array of values from strings where you expect some formatting errors, there are definitely cases where you'd like to be able to present all the errors to the user so that they don't need to try and fix them one by one.If its an all-or-nothing fail, then the first format makes sense.  If you want to be able to process/return all the non-failing elements, you need to use the second form.  Those would be my basic criteria for choosing between the methods.  Personally, if it is all-or-nothing, I wouldn't use the second form.As long as you are aware of what you need to accomplish in the loop you could put the try catch outside the loop. But it is important to understand that the loop will then end as soon as the exception occurs and that may not always be what you want. This is actually a very common error in Java based software. People need to process a number of items, such as emptying a queue, and falsely rely on an outer try/catch statement handling all possible exceptions. They could also be handling only a specific exception inside the loop and not expect any other exception to occur.\nThen if an exception occurs that is not handled inside the loop then the loop will be \"preemted\", it ends possibly prematurely and the outer catch statement handles the exception.If the loop had as its role in life to empty a queue then that loop very likely could end before that queue was really emptied.  Very common fault.While performance might be the same and what \"looks\" better is very subjective, there is still a pretty big difference in functionality. Take the following example:The while loop is inside the try catch block, the variable 'j' is incremented until it hits 40, printed out when j mod 4 is zero and an exception is thrown when j hits 20.Before any details, here the other example:Same logic as above, only difference is that the try/catch block is now inside the while loop. Here comes the output (while in try/catch):And the other output (try/catch in while):There you have quite a significant difference: while in try/catch breaks out of the looptry/catch in while keeps the loop activeIn your examples there is no functional difference.  I find your first example more readable.You should prefer the outer version over the inner version. This is just a specific version of the rule, move anything outside the loop that you can move outside the loop. Depending on the IL compiler and JIT compiler your two versions may or may not end up with different performance characteristics.On another note you should probably look at float.TryParse or Convert.ToFloat.If you put the try/catch inside the loop, you'll keep looping after an exception.  If you put it outside the loop you'll stop as soon as an exception is thrown.setting up a special stack frame for the try/catch adds additional overhead, but the JVM may be able to detect the fact that you're returning and optimize this away.depending on the number of iterations, performance difference will likely be negligible.However i agree with the others that having it outside the loop make the loop body look cleaner.If there's a chance that you'll ever want to continue on with the processing rather than exit if there an invalid number, then you would want the code to be inside the loop.If it's inside, then you'll gain the overhead of the try/catch structure N times, as opposed to just the once on the outside.Every time a Try/Catch structure is called it adds overhead to the execution of the method. Just the little bit of memory & processor ticks needed to deal with the structure.  If you're running a loop 100 times, and for hypothetical sake, let's say the cost is 1 tick per try/catch call, then having the Try/Catch inside the loop costs you 100 ticks, as opposed to only 1 tick if it's outside of the loop.The whole point of exceptions is to encourage the first style: letting the error handling be consolidated and handled once, not immediately at every possible error site.put it inside.  You can keep processing (if you want) or you can throw a helpful exception that tells the client the value of myString and the index of the array containing the bad value. I think NumberFormatException will already tell you the bad value but the principle is to place all the helpful data in the exceptions that you throw.  Think about what would be interesting to you in the debugger at this point in the program.  Consider: In the time of need you will really appreciate an exception like this with as much information in it as possible.I's like to add my own  about two competing considerations when looking at the general problem of where to position exception handling:That depends on the failure handling. If you just want to skip the error elements, try inside:In any other case i would prefer the try outside. The code is more readable, it is more clean. Maybe it would be better to throw an IllegalArgumentException in the error case instead if returning null.I'll put my $0.02 in.  Sometimes you wind up needing to add a \"finally\" later on in your code (because who ever writes their code perfectly the first time?).  In those cases, suddenly it makes more sense to have the try/catch outside the loop.  For example:Because if you get an error, or not, you only want to release your database connection (or pick your favorite type of other resource...) once.Another aspect not mentioned in the above is the fact that every try-catch has  impact on the stack, which can have implications for recursive methods.If method \"outer()\" calls method \"inner()\" (which may call itself recursively), try to locate the try-catch in method \"outer()\" if possible.  A simple \"stack crash\" example we use in a performance class fails at about 6,400 frames when the try-catch is in the inner method, and at about 11,600 when it is in the outer method.In the real world, this can be an issue if you're using the Composite pattern and have large, complex nested structures."},
{"body": "Consider the following example.Now, in Java, String objects are immutable. Then how come the object  can be assigned value \"Help!\". Isn't this contradicting the immutability of strings in Java? Can anybody please explain me the exact concept of immutability?Edit:Ok. I am now getting it, but just one follow-up question. What about the following code: Does this mean that two objects are created again (\"Mississippi\" and \"M!ss!ss!pp!\") and the reference  points to a different object after  method?  is not an object, it's a reference to an object.  and  are two distinct  objects. Thus,   a string. You can change what it , but not that which it .Take this code, for example:Now, there is nothing we could do to  that would affect the value of . They refer to the same object - the string  - but that object is immutable and thus cannot be altered. If we do something like this:Here we see the difference between mutating an object, and changing a reference.  still points to the same object as we initially set  to point to. Setting  to  only changes the , while the  object it originally referred to remains unchanged. If strings  mutable, we could do something like this: If you look at the  (also available in src.zip in your JDK installation directory -- a pro tip is to look there whenever you wonder how something really works) you can see that what it does is the following:So yes,  creates a new  object. Again, the following holds:Your homework for now is to see what the above code does if you change  to  :) Actually, it  possible to mutate strings (and other immutable objects). It requires reflection and is very, very dangerous and should never ever be used unless you're actually interested in destroying the program.The object that  references can change, but the actual  objects themselves cannot.The  objects containing the string  and  cannot change their values, hence they are immutable.The immutability of  objects does not mean that the references pointing to the object cannot change.One way that one can prevent the  reference from changing is to declare it as :Now, trying to assign another  to  will cause a compile error.Light_handle I recommend you take a read of  and . This will help a lot when reading the posts above. Have you read them? Yes. Good. This creates a new \"remote control\" called \"\" and sets that to the value  (or ).e.g. in memory this creates:This then changes the remote control \"\" but does not modify the original string .e.g. in memory this creates:This then changes the remote control \"\" but does not modify the original string  or the object that the remote control currently points to.e.g. in memory this creates:The string object that was first referenced by  was not altered, all that you did was make  refer to a new string object.Lets break it into some partsThis Statement creates string containing  and occupy space in memory i.e. in  and and assigned it to reference object This statement assigns the same string  to new reference Both references are pointing to the same string so output the same value as follows.Though  is , assignment can be possible so the  will now refer to new value .But what about  object which is pointing to  it will be as it is.Since String is immutable  by its method. It will create all new String object in pool as follows.Note if String would be mutable then the output would have been Now you might be surprised why String has such methods like  to modify. Following snippet will clear your confusion.    Here we are assigning modified value of string back to  reference.That's why Java decided  Otherwise anyone can modify and change the value of string.\nHope this will help little bit.The String will not change, the reference to it will.  You are confusing immutability with the concept of  fields.  If a field is declared as , once it has been assigned, it cannot be reassigned.Regarding the replace part of your question, try this:Immutability implies that the value of an instantiated object cannot change, you can never turn \"Hello\" into \"Help!\".The variable str is a reference to an object, when you assign a new value to str you aren't changing the value of the object it references, you are referencing a different object.Though java tries to ignore it,  is nothing more than a pointer. This means that when you first write , you create an object that  points to. When you reassign  by writing , a new object is created and the old  object gets garbage collected whenever java feels like it.String class is immutable, and you can not change value of immutable object.\nBut in case of String, if you change the value of string than it will create new string in string pool and than your string reference to that value not the older one. so by this way string is immutable.\nLets take your example,it will create one string  and will add it to String pool\nso now str is pointing to Mississippi.But after above operation,\none another string will be created \nand it will be add to String pool. and \nnow str is pointing to M!ss!ss!pp!, not Mississippi.so by this way when you will alter value of string object it will create one more object and will add it to string pool.Lets have one more example this above three line will add three objects of string to string pool.\n1) Hello\n2) World\n3) HelloWorldUse:If you see here I use the  method to change the original string, that is, \"New String\" with a string \" Added String\", but still I got the output as previous, hence it proves that you can not change the reference of object of String class, but if you do this thing by StringBuilder class it will work. It is listed below.Like Linus Tolvards said:Take a look at this:The output isSo, remember two things:For those wondering how to break String immutability in Java... is . Which means that we can only change the .In Java, objects are generally accessed by references. In your piece of code str is a reference which is first assigned to \"Hello\" (an automatic created object or fetched from ) and then you assigned another object \"Help!\" to same reference. A point to note is the reference is the same and modified, but objects are different. One more thing in your code you accessed three objects,Calling new String() creates a new object even if it exists in string pool, so generally it should not be used. To put a string created from new String () into string pool you can try the  method.I hope this helps.Immutability I can say is that you cannot change the String itself. Suppose you have String x, the value of which is \"abc\". Now you cannot change the String, that is, you cannot change any character/s in \"abc\".If you have to change any character/s in the String, you can use a character array and mutate it or use StringBuilder.Output:Or you can try:This will show how the hashcode changes."},
{"body": "What is the difference between  and  while handling special characters?  was accepted by  as space. In case of ,  was accepted as .If URL  gets the invoices for user 1234 on December 5th, 2013, the controller method would look like:Also, request parameters can be optional, but path variables cannot--if they were, it would change the URL path hierarchy and introduce request mapping conflicts. For example, would  provide the invoices for user  or details about a user with ID \"invoices\"? annotation used for accessing the query parameter values from the request. Look at the following request URL:In the above URL request, the values for param1 and param2 can be accessed as below:The following are the list of parameters supported by the @RequestParam annotation:@ identifies the pattern that is used in the URI for the incoming request. Let\u2019s look at the below request URL:The above URL request can be written in your Spring MVC as below:The @ annotation has only one attribute value for binding the request URI template. It is allowed to use the multiple @ annotation in the single method. But, ensure that no more than one method has the same pattern.Also there is one more interesting annotation:\nAnd the Controller method for itBut you must enable:it may be that the application/x-www-form-urlencoded midia type convert space to , and the reciever will decode the data by converting the  to space.check the url for more info."},
{"body": "How do you define Global variables in Java  ? To define Global Variable you can make use of static Keywordnow you can access a and b from anywhere\nby callingYou don't. That's by design. You shouldn't do it even if you could. That being said you could create a set of public static members in a class named Globals. but you really shouldn't :). Seriously .. don't do it. Another way is to create an interface like this:Any class that needs to use them only has to implement the interface:You are better off using dependency injection:Truly speaking there is not a concept of  in a java OO programNevertheless there is some truth behind your question because there will be some cases where you want to run a method at any part of the program.\nFor example---random() method in Phrase-O-Matic app;it is a method should be callable from anywhere of a program.So in order to satisfy the things like Above \"We need to have Global-like variables and methods\".Because I declared global variables and method as static you can call them anywhere you wish by simply with the help of following codeClassName.X: X can be either method name or variable name as per the requirement and ClassName is the name of the class in which you declared them.Nothing should be global, except for constants.Put this within your main class.  In other .java files, use it through:Make sure when you move your code off the cutting room floor and into release you remove or comment out this functionality.If you have a workhorse method, like a randomizer, I suggest creating a \"Toolbox\" package!  All coders should have one, then whenever you want to use it in a .java, just import it!Lots of good answers, but I want  to give this example as it's considered the more proper way to access variables of a class by another class using getters and setters. The reason why you use getters and setters this way instead of just making the variable public is as follows. Lets say your var is going to be a global parameter that you NEVER want someone to change during the execution of your program(in the case when you are developing code with a team), something like maybe the URL for a website. In theory this could change and may be used many times in your program, so you want to use a global var to be able to update it all at once. But you do not want someone else to go in and change this var(possibly without realizing how important it is). In that case you simply do not include a setter method, and only include the getter method.There is no such thing as a truly global variable in Java.  Every static variable must belong to some class (like System.out), but when you have decided which class it will go in, you can refer to it from everywhere loaded by the same classloader.Note that static variables should always be protected when updating to avoid race conditions.One, There is no global variable in JavaTwo, What we do have is a 'static' keyword and that is all what we need.\nNothing exists outside of class in Java. The static keyword represents a class variable that on the contrary to instance variable only has one copy and that transcends across all the instances of that class created, which means that its value can be changed and accessed across all instances at any point. If you need a global variable which can be accessed beyond scopes, then this is the variable that you need, but its scope exists only where the class is, and that will be all.This way you can access them with  and you can call anywhere you want:As you probably guess from the answer there is no global variables in Java and the only thing you can do is to create a class with static members:You can use it with  elsewhere. However if you use Java 1.5 or better you can use the  magic to make it look even more as a real global variable:And !Now this is far from a best practice so as you can see in the commercials: There are no global variables in Java, but there are global classes with public fields. You can use static import feature of java 5 to make it look almost like global variables.Going by the concept, global variables, also known as instance variable are the class level variables,i.e., they are defined inside a class but outside methods. In order to make them available completely and use them directly provide the static keyword. \nSo if i am writing a program for simple arithmetical operation and it requires a number pair then two instance variables are defined as such:Moreover using static keyword prior to the instance variables enable us not to specify datatypes for same variables again and again. Just write the variable directly.Generally Global variable (I assume you are comparing it with C,Cpp) define as likeENUMs are also useful in such scenario :For Example  )In general,the Java programming doesn't have any global variables .Since other than the local variables all are comes under the scope of any class defined in the program.\nWe can have the static variable to have the scope of global variables.Creating an independent file, eg. Example.java to use the 1st solution, is just fine. You can do that also within the app, if e.g. the global variables are special to your current app, etc.:Create a class at the beginning and declare your variables in there:You can then access these variables -- using them as 'Globals.month_number', etc. -- from averywhere in your app.To define Global Variable you can make use of static Keywordnow you can access a and b from anywhere by callingYoy are right...specially in J2ME...\n  You can avoid NullPointerException by putting inside your MidLet constructor\n(proggy initialization) this line of code:This ensures that Tools will be allocated before any instruction\nthat uses it.That's it!"},
{"body": "In an attempt to fully understand how to solve Java's multiple inheritance problems I have a classic question that I need clarified.Lets say I have class  this has sub classes  and  and I need to make a class  that extends from  and  since  is both a bird and a horse.I think this is the classic diamond problem. From what I can understand the classic way to solve this is to make the ,  and  classes interfaces and implement  from them. I was wondering if there was another way to solve the problem in which I can still create objects for birds and horses. If there was a way to be able to create animals also that would be great but not necessary.You could create interfaces for animal classes (class in the biological meaning), such as  for horses and  for birds (I'm no biologist, so the terms may be wrong).Then you can still create a and and alsoIn order to reduce duplicate code, you could create an abstract class that contains most of the common code of the animals you want to implement.I'd like to add one more detail. As , this is something the OP already knew. However, I want to emphasize, that I suggest to bypass the \"multi-inheritance\" problem with interfaces and that I don't recommend to use interfaces that represent already a concrete type (such as Bird) but more a behavior (others refer to duck-typing, which is good, too, but I mean just: the biological class of birds, Avialae). I also don't recommend to use interface names starting with a capital 'I', such as , which just tells nothing about why you need an interface. That's the difference to the question: construct the inheritance hierarchy using interfaces, use abstract classes when useful, implement concrete classes where needed and use delegation if appropriate.There are two fundamental approaches to combining objects together:The way this works is that you have an Animal object. Within that object you then add further objects that give the properties and behaviors that you require.For example:Now  just looks like this:So  looks like this:Now you have all the advantages of Inheritance. You can re-use code. You can have a collection of IFliers, and can use all the other advantages of polymorphism, etc.However you also have all the flexibility from Composition. You can apply as many different interfaces and composite backing class as you like to each type of  - with as much control as you need over how each bit is set up.An alternative approach depending on what and how you are doing is to have the  base class contain an internal collection to keep the list of different behaviors. In that case you end up using something closer to the Strategy Pattern. That does give advantages in terms of simplifying the code (for example  doesn't need to know anything about  or ) but if you don't also do the interface approach you lose a lot of the advantages of polymorphism, etc.I have a stupid idea:May I suggest the concept of ?Most likely you would tend to make the Pegasus extend a Bird and a Horse interface but duck typing actually suggests that you should rather inherit . As already stated in the comments, a pegasus is not a bird but it can fly. So your Pegasus should rather inherit a -interface and lets say a -interface.This kind of concept is utilized in the . The given example actually shows you how a duck inherits the  and  and still there can be ducks, e.g. the , which can't fly. They could have also made the  extend a -class but then they would have given up some flexibility, because every  would be able to fly, even the poor .Technically speaking, you can only extend one class at a time and implement multiple interfaces, but when laying hands on software engineering, I would rather suggest a problem specific solution not generally answerable. By the way, it is good OO practice,  to extend concrete classes/only extend abstract classes to prevent unwanted inheritance behavior - there is no such thing as an \"animal\" and no use of an animal object but only concrete animals.It is safe to keep a horse in a stable with a half door, as a horse cannot get over a half door.   Therefore I setup a horse housing service that accepts any item of type horse and puts it in a stable with a half door.So is a horse like animal that can fly even a horse?I used to think a lot about multiple inheritance, however now that I have been programming for over 15 years, I no longer care about implementing multiple inheritance.More often than not, when I have tried to cope with a design that pointed toward multiple inheritance, I have later come to release that I had miss understood the problem domain.ORIn Java 8, which is still in the development phase as of February 2014, you could use  to achieve a sort of C++-like multiple inheritance.\nYou could also have a look at  which shows a few examples that should be easier to start working with than the official documentation.Java does not have a Multiple inheritance problem, since it does not have multiple inheritance. This is by design, in order to solve the real multiple inheritance problem (The diamond problem).There are different strategies for mitigating the problem. The most immediately achievable one being the Composite object that Pavel suggests (essentially how C++ handles it). I don't know if multiple inheritence via C3 linearization (or similar) is on the cards for Java's future, but I doubt it.If your question is academic, then the correct solution is that Bird and Horse are more concrete, and it is false to assume that a Pegasus is simply a Bird and a Horse combined. It would be more correct to say that a Pegasus has certain intrinsic properties in common with Birds and Horses (that is they have maybe common ancestors). This can be sufficiently modeled as Moritz' answer points out.I think it depends very much on your needs, and how your animal classes are to be used in your code.If you want to be able to make use of methods and features of your Horse and Bird implementations inside your Pegasus class, then you could implement Pegasus as a  of a Bird and a Horse:Another possibility is to use an  approach instead of inheritance for defining your animals. Of course this means, that you will not have individual Java classes of the animals, but instead they are only defined by their components.Some pseudo code for an Entity-Component-System approach could look like this:you can have an interface hierarchy and then extend your classes from selected interfaces :and then define your classes as needed,  by extending a specific interface :Ehm, your class can be the subclass for only 1 other, but still, you can have as many interfaces implemented, as you wish. A Pegasus is in fact a horse (it is a special case of a horse), which is able to fly (which is the \"skill\" of this special horse). From the other hand, you can say, the Pegasus is a bird, which can walk, and is 4legged - it all depends, how it is easier for you to write the code.Like in your case you can say:Interfaces don't simulate multiple inheritance. Java creators considered multiple inheritance wrong, so there is no such thing in Java.If you want to combine the functionality of two classes into one - use object composition. I.e.And if you want to expose certain methods, define them and let them delegate the call to the corresponding controller.Here interfaces may come handy - if  implements interface  and  implements , you can defineSo that you can use objects interchangeably where the context allows it.So in my point of view, you can't get into diamond problem.As you will already be aware, multiple inheritance of classes in Java is not possible, but it's possible with interfaces. You may also want to consider using the composition design pattern.I wrote a very comprehensive article on composition a few years ago...To reduce the complexity and simplify the language, multiple inheritance is not supported in java.Consider a scenario where A, B and C are three classes. The C class inherits A and B classes. If A and B classes have same method and you call it from child class object, there will be ambiguity to call method of A or B class.Since compile time errors are better than runtime errors, java renders compile time error if you inherit 2 classes. So whether you have same method or different, there will be compile time error now.To solve the problem of mutiple inheritance in Java \u2192 interface is usedHave a look at below example for better understanding"},
{"body": "I want to print something in console, so that I can debug it.  But for some reason, nothing prints in my Android application.  How do I debug then?\nOn the emulator and most devices  gets redirected to LogCat and printed using . This may not be true on very old or custom Android versions. \nThere is no console to send the messages to so the  messages get lost.  In the same way this happens when you run a \"traditional\" Java application with .Instead, you can use the :You can then view the log either in the  view in Eclipse, or by running the following command:It's good to get in to the habit of looking at logcat output as that is also where the Stack Traces of any uncaught Exceptions are displayed.The first Entry to every logging call is the log tag which identifies the source of the log message.  This is helpful as you can filter the output of the log to show just your messages.  To make sure that you're consistent with your log tag it's probably best to define it once as a  somewhere.There are five one-letter methods in  corresponding to the following levels:The :Use the  . Output visible with LogCatYes it does. If you're using the emulator, it will show in the Logcat view under the  tag. Write something and try it in your emulator.Of course, to see the result in logcat, you should set the Log level at least to \"Info\" (); otherwise, as it happened to me, you won't see your output.There is no place on your phone that you can read the Instead, if you want to see the result of something either look at your  window or make a  or a  (if you're on a newer device) appear on the device's screen with the message :) \nThat's what i do when i have to check for example where it goes in a  code! Have fun coding! :)if you really need System.out.println to work(eg. it's called from third party library). you can simply use reflection to change out field in System.class:RedirectLogOutputStream class:"},
{"body": "I have a very big program that is currently using SWT. The program can be run on both Windows, Mac and Linux, and it is a big desktop application with many elements.\nNow SWT being somewhat old I would like to switch to either Swing or JavaFX. And I would like to hear your thoughts on three things.My main concern is what will be better for a desktop GUI application? (I looked online and a lot of people suggest that JavaFX is just as good as Swing, but I didn't see many valid arguments except simple opinion flame wars). It has to work on both Windows, Mac and some popular Linux distributions.I am using MVC methology in my application, if that is of any help.All things being equal, probably JavaFX - the API is much more consistent across components. However, this depends much more on  rather than .Highly dependent on what you're building. Swing has more components around for it (3rd party as well as built in) and not all of them have made their way to the newer JavaFX platform yet, so there may be a certain amount of re-inventing the wheel if you need something a bit custom. On the other hand, if you want to do transitions / animations / video stuff then this is orders of magnitude easier in FX.One other thing to bear in mind is (perhaps) look and feel. If you absolutely must have the default system look and feel, then JavaFX (at present) can't provide this. Not a big must have for me (I prefer the default FX look anyway) but I'm aware some policies mandate a restriction to system styles.Personally, I see JavaFX as the \"up and coming\" UI library that's not  there yet (but more than usable), and Swing as the borderline-legacy UI library that's fully featured and supported for the moment, but probably won't be so much in the years to come (and therefore chances are FX will overtake it at some point.)As stated by Oracle, JavaFX is the next step in their Java based rich client strategy.\nAccordingly, this is what I recommend for your situation:For more info, please take a look these FAQ post by Oracle regarding JavaFX here.I am using javafx for the first time in a non-production recreational app, and there it is fine. It has not production quality IMHO.Example: one needs tricks, work-arounds in some cases, like right-alignment of a column in a TableView may take an extra effort. The usage of callbacks using callbacks is a bit overdone.On the other hand, there are nice effects and extras like HTMLEditor. Switching the application language is easier (simply rebuild the scene). In Java 8 javafx should be more pallatable (callbacks), and ripened.If you cannot wait, go for swing. It is rock-solid.\nYou could opt for the NetBeans Platform RCP, but that takes learning or commercial support. There is effort to port part of the NetBeans Platform to javafx, also in a hybrid version.Last but not least, one may combine both, running javafx inside a swing app.No one has mentioned it, but JavaFX does not compile or run on certain architectures deemed \"servers\" by Oracle (e.g. Solaris), because of the missing \"jfxrt.jar\" support. Stick with SWT, until further notice.I don't think there's any one right answer to this question, but my advice would be to stick with SWT unless you are encountering severe limitations that require such a massive overhaul. Also, SWT is actually newer and more actively maintained than Swing. (It was  as a replacement for Swing using native components).I'd look around to find some (3rd party?) components that do what you want. I've had to create custom Swing components for an agenda view where you can book multiple resources, as well as an Excel-like grid that works well with keyboard navigation and so on. I had a terrible time getting them to work nicely because I needed to delve into many of Swing's many intricacies whenever I came upon a problem. Mouse and focus behaviour and a lot of other things can be very difficult to get right, especially for a casual Swing user. I would hope that JavaFX is a bit more future-orientated and smooth out of the box.On older notebooks with integrated video Swing app starts and works much faster than JavaFX app. As for development, I'd recommend switch to Scala - comparable Scala Swing app contains 2..3 times less code than Java.\nAs for Swing vs SWT: Netbeans GUI considerably faster than Eclipse..."},
{"body": "I have this little crazy method that converts BigDecimal values into nice and readable Strings.It however, also produces a so called grouping separator  that makes all my values come out like this:I do need the separator to be a dot or a point and not a comma. \nDoes anybody have a clue of how to accomplish this little feat?I have read  and in particular  to death now but I cannot find a way to get this done.\nAm I approaching this the wrong way? Is there a much more elegant way of doing this? Maybe even a solution that accounts for different local number representations, since the comma would be perfect by European standards.You can change the separator either by setting a locale or using the .If you want the grouping separator to be a point, you can use an european locale:Alternatively you can use the DecimalFormatSymbols class to change the symbols that appear in the formatted numbers produced by the format method. These symbols include the decimal separator, the grouping separator, the minus sign, and the percent sign, among others:Europe is quite huge. I'm not if they use the same format all over. However  or  answer will be of helpi.e use the correct locale BigDecimal does not seem to respect Locale settings.Slovenian locale should have a decimal comma. Guess I had strange misconceptions regarding numbers.I have edited a part of my message that made no sense since it proved to be due the human error (forgot to commit data and was looking at the wrong thing).Same as BigDecimal can be said for any Java .toString() functions. I guess that is good in some ways. Serialization for example or debugging. There is an unique string representation.Also as others mentioned using formatters works OK. Just use formatters, same for the JSF frontend, formatters do the job properly and are aware of the locale."},
{"body": "Could you explain what  does when invoked? sets the interrupted status/flag of the target thread.  Then code running in that target thread MAY poll the interrupted status and handle it appropriately.  Some methods that block such as  may consume the interrupted status immediately and throw an appropriate exception (usually )Interruption in Java is not pre-emptive.  Put another way both threads have to cooperate in order to process the interrupt properly.  If the target thread does not poll the interrupted status the interrupt is effectively ignored.Polling occurs via the  method which returns the current thread's interrupted status AND clears that interrupt flag.  Usually the thread might then do something such as throw InterruptedException.EDIT (from Thilo comments):  Some API methods have built in interrupt handling.  Of the top of my head this includes.EDIT (from 's answer to  for completeness)Thread interruption is a gentle way to nudge a thread. It is used to give threads a chance to exit , as opposed to  that is more like shooting the thread with an assault rifle.Check this out for complete understanding about same :If the targeted thread has been waiting (by calling , or some other related methods that essentially do the same thing, such as ), it will be interrupted, meaning that it stops waiting for what it was waiting for and receive an InterruptedException instead.It is completely up to the thread itself (the code that called ) to decide what to do in this situation. It does not automatically terminate the thread.It is sometimes used in combination with a termination flag. When interrupted, the thread could check this flag, and then shut itself down. But again, this is just a convention.For completeness, in addition to the other answers, , as the following example shows.Output:Implication: if you loop like the following, and the interrupt occurs at the exact moment when control has left  and is going around the loop, the exception is still going to occur. :Interrupts this thread.Unless the current thread is interrupting itself, which is always permitted, the checkAccess method of this thread is invoked, which may cause a SecurityException to be thrown.If this thread is blocked in an invocation of the wait(), wait(long), or wait(long, int) methods of the Object class, or of the join(), join(long), join(long, int), sleep(long), or sleep(long, int), methods of this class, then its interrupt status will be cleared and it will receive an InterruptedException.If this thread is blocked in an I/O operation upon an interruptible channel then the channel will be closed, the thread's interrupt status will be set, and the thread will receive a ClosedByInterruptException.If this thread is blocked in a Selector then the thread's interrupt status will be set and it will return immediately from the selection operation, possibly with a non-zero value, just as if the selector's wakeup method were invoked.If none of the previous conditions hold then this thread's interrupt status will be set.Interrupting a thread that is not alive need not have any effect.Throws:\n    SecurityException - if the current thread cannot modify this thread sets the interrupted status/flag of the target thread to true which when checked using  can help in stopping the endless thread. Refer An interrupt is an indication to a thread that it should stop what it is doing and do something else. It's up to the programmer to decide exactly how a thread responds to an interrupt, but it is very common for the thread to terminate.\nA very good referance: "},
{"body": "I'm a web developer at day and thinking about building my first real desktop application. The idea is to build a tool that automates a very repetitive task in a web application where no API is available.I know I want to use Java. I used it before for web stuff, know the syntax pretty well  and want the application to be cross plattform as easy as possible. Where I'm not so sure is if I should use SWT or Swing. As my main audience uses Windows, I want to look it as native as possible there. Linux and Mac should work, but the looks are not so important here.So what are the arguments for and against each UI Framework, Swing or SWT?Thanks.PS: I develop on Windows using Eclipse. But was thinking about playing with Netbeans.An important thing to consider is that some users and some resellers (Dell) install a 64 bit VM on their 64 bit Windows, and you can't use the same SWT library on 32 bit and 64 bit VMs.This means you will need to distribute and test different packages depending on whether users have 32-bit or a 64-bit Java VM. See  with Azureus, for instance, but you also have it with Eclipse, where as of today the builds on the front download page do not run on a 64 bit VM. pro swing:But at the bottom line I wouldn't suggest to use 'pure' swing or swt ;-)\nThere are several application frameworks for swing/swt out. .\nThe biggest players are netbeans (swing) and eclipse (swt). Another nice framework could be griffon and a nice 'set of components' is pivot (swing). Griffon is very interesting because it integrates a lot of libraries and ; also pivot, swt, etcI would use Swing for a couple of reasons.If you want to build a very feature-rich application, you might want to check out the  (Rich Client Platform). There's a learning curve, but you can put together nice applications quickly with a little practice. I don't have enough experience with the Eclipse platform to make a valid judgment.If you don't want to use the entire RCP, NetBeans also has many useful components that can be pulled out and used independently.One other word of advice, look into different layout managers. They tripped me up for a long time when I was learning. Some of the best aren't even in the standard library. The  (for both Swing and SWT) and  Forms tools are two of the best in my opinion.I whould choose swing just because it's \"native\" for java.Plus, have a look at .For your requirements it sounds like the bottom line will be to use Swing since it is slightly easier to get started with and not as tightly integrated to the native platform as SWT.Swing usually is a safe bet.Interesting question. I don't know SWT too well to brag about it (unlike Swing and AWT) but here's the comparison done on SWT/Swing/AWT.And here's the site where you can get tutorial on basically anything on SWT ()Hope you make a right decision (if there are right decisions in coding)... :-)If you plan to build a full functional applications with more than a handful of features, I will suggest to jump right to using Eclipse RCP as the framework.If your application won't grow too big or your requirements are just too unique to be handled by a normal business framework, you can safely jump with Swing.At the end of the day, I'd suggest you to try both technologies to find the one suit you better. Like Netbeans vs Eclipse vs IntelliJ, there is no the absolute correct answer here and both frameworks have their own drawbacks.Pro Swing:Pro SWT:One thing to consider: ScreenreadersFor some reasons, some Swing components do not work well when using a screenreader (and the Java AccessBridge for Windows). Know that different screenreaders result in different behaviour. And in my experience the SWT-Tree performs a lot better than the Swing-Tree in combination with a screenreader. Thus our application ended up in using both SWT and Swing components.For distributing and loading the proper SWT-library, you might find this link usefull:\nSWT was created as a response to the sluggishness of Swing around the turn of the century. Now that the differences in performance are becoming negligable, I think Swing is a better option for your standard applications. SWT/Eclipse has a nice framework which helps with a lot of boiler plate code."},
{"body": "Is there a way to compile multiple java source directories in a single maven project? You can add a new source directory with build-helperI naively do it this way :This worked for meto make it work in intelliJ, you can also addto maven-compiler-pluginThis also works with maven by defining the resources tag. You can name your src folder names whatever you like.Used the build-helper-maven-plugin from the post - and update src/main/generated.  And mvn clean compile works on my ../common/src/main/java, or on ../common, so kept the latter.  Then yes, confirming that IntelliJ IDEA (ver 10.5.2) level of the compilation failed as David Phillips mentioned.\nThe issue was that IDEA did not add another source root to the project.  Adding it manually solved the issue.  It's not nice as editing anything in the project should come from maven and not from direct editing of IDEA's project options.  Yet I will be able to live with it until they support build-helper-maven-plugin directly such that it will auto add the sources.Then needed another workaround to make this work though.  Since each time IDEA re-imported maven settings after a pom change me newly added source was kept on module, yet it lost it's Source Folders selections and was useless.  So for IDEA - need to set these once:Now keeping those folders on import is not the best practice in the world either, ..., but giving it a try.This can be done in two steps:If you work with started jetty (jetty:run), then recompilation of any class in any module (with Maven, IDEA or Eclipse) will lead to jetty's restart. The same behavior you'll get for modified resources."},
{"body": "With Mockito, I want to  a method call with  in its argument list, but I didn't find how to write this.I just want something like , how to do that with Mockito ?I would try  Try this:    I would rather use . This worked for me.I agree with Mutanos and Alecio.\nFurther, one can check as many identical method calls as possible (verifying the subsequent calls in the production code, the order of the verify's does not matter).\nHere is the code:Or..You can use Mockito.any()  when arguments are arrays also.\nI used it like this:"},
{"body": "How do I get a  3.0 controller to trigger a 404?I have a controller with  and for some  accessing the controller, I want the container to come up with a 404.Since Spring 3.0 you also can throw an Exception declared with  annotation:Rewrite your method signature so that it accepts  as a parameter, so that you can call  on it.I would like to mention that there's exception (not only) for 404 by default provided by Spring. See  for details. So if you do not need your own exception you can simply do this:you can use the  to handle your Exceptions ,\nThe default behavior the @ControllerAdvice annotated class will assist all known Controllers.so it will be called when any Controller you have throws 404 error .like the following : and map this 404 response error in your web.xml , like the following : Hope that Helps . Since Spring 3.0.2 you can return  as a result of the controller's method:(ResponseEntity<T> is a more flexible than @ResponseBody annotation - see )If your controller method is for something like file handling then  is very handy:I'd recommend throwing , like thisYou must remember that this can be done only before anything is written to servlet output stream.While the marked answer is correct there is a way of achieving this without exceptions. The service is returning  of the searched object and this is mapped to  if found and to  404 if empty. Simply you can use web.xml to add error code and 404 error page. But make sure 404 error page must not locate under WEB-INF.This is the simplest way to do it but this have some limitation. Suppose if you want to add the same style for this page that you added other pages. In this way you can't to that. You have to use the Configure web.xml with settingCreate new controller "},
{"body": "I keep finding both on here and Google people having troubles going from  to  and not the other way around. Yet I'm sure I'm not the only one that has run into this scenario before going from  to .The only other answers I've found were \"Just set it as Long in the first place\" which really doesn't address the question.Can someone help me out here? I initially tried casting but I get a \"\"As you can imagine I'm a little perplexed, I'm stuck using int since some content is coming in as an ArrayList and the entity for which I'm storing this info requires the sequence number as a Long.Thanks!Note that there is a difference between a cast to  and a cast to . If you cast to  (a primitive value) then it should be automatically boxed to a  (the reference type that wraps it).You could alternatively use  to create an instance of , initializing it with the  value.Use the following: .If you already have the int typed as an Integer you can do this:use orI have this little toy, that also deals with non generic interfaces.\nI'm OK with it throwing a ClassCastException if feed wrong (OK and happy)In Java you can do:in your case it would be: We shall get the long value by using  reference.It works for all number types, here is a test:I had a great deal of trouble with this. I just wanted to:Where IntervalCount is a Long, and the JSpinner was set to return a Long.  Eventually I had to write this function:which seems to do the trick.  No amount of simple casting, none of the above solutions worked for me.  Very frustrating.How About// Will not compile// Compiles, and retains the non-NULL spirit of int. The best  is .  Of course, your use case may require Long and possible NULL values.  But if the int, or other longs are your only input, and your method can be modified, I would suggest this approach. // Compiles, is the most efficient way, and makes it clear that the source value, is and will never be NULL. "},
{"body": "I would like to be able to write a Java class in one package which can access non-public methods of a class in another package without having to make it a subclass of the other class. Is this possible?Lets say I have a class  and another class . They are in different packages (family) for hatred reasons. wants to   and  wants to only let   her.In C++,  would declare  as a (lover)  but there are no such things in java.Here are the classes and the trick :Ladies first :So the method  is  but you need a  to call it. It uses this  as a \"signature security\" to ensure that only  can call this method and simply calls  on it so the runtime will throw a  if it is .Now boys :The class  is public, but its constructor is . Therefore anyone can see it, but only  can construct it. I use a static reference so the  that is never used is only constructed once and does not impact optimization.Therefore,  can   and only he can because only he can construct and access a  instance, which is required by  to  her (or else she'll slap you with a ).The designers of Java explicitly rejected the idea of friend as it works in C++. You put your \"friends\" in the same package.  Private, protected, and packaged security is enforced as part of the language design.  James Gosling wanted Java to be C++ without the mistakes. I believe he felt that friend was a mistake because it violates OOP principles. Packages provide a reasonable way to organize components without being too purist about OOP.NR pointed out that you could cheat using reflection, but even that only works if you aren't using the SecurityManager. If you turn on Java standard security, you won't be able to cheat with reflection unless you write security policy to specifically allow it.The 'friend' concept is useful in Java, for example, to separate an API from its implementation. It is common for implementation classes to need access to API class internals but these should not be exposed to API clients. This can be achieved using the 'Friend Accessor' pattern as detailed below:The class exposed through the API:The class providing the 'friend' functionality:Example access from a class in the 'friend' implementation package:There are two solutions to your question that don't involve keeping all classes in the same package.  The first is to use the Friend Accessor/ pattern described in (Practical API Design, Tulach 2008).The second is to use OSGi.  There is an article  explaining how OSGi accomplishes this.  Related Questions: , , and .As far as I know, it is not possible.Maybe, You could give us some more details about Your design. Questions like these are likely the result of design flaws.Just considerI think that friend classes in C++ are like inner-class concept in Java. Using inner-classes\nyou can actually define an enclosing class and an enclosed one. Enclosed class has full access to the public and private members of it's enclosing class.\nsee the following link:\neirikma's answer is easy and excellent.  I might add one more thing:  instead of having a publicly accessible method, getFriend() to get a friend which cannot be used, you could go one step further and disallow getting the friend without a token: getFriend(Service.FriendToken).  This FriendToken would be an inner public class with a private constructor, so that only Service could instantiate one.Using ideas from the other answers, here I detail a clear use case example, ending with the reusable  class. The benefit of this mechanism is that only the friend class itself is allowed to be a friend, and not any sub-classes of it. Potentially making it safer.To begin, here is an example of how to use the  class.Then in another package you can do this:The  class is as follows. (You only need to write this code once, no need to copy it around.)The provided solution was perhaps not the simplest. Another approach is based on the same idea as in C++: private members are not accessible outside the package/private scope, except for a specific class that the owner makes a friend of itself. The class that needs friend access to a member should create a inner public abstract \"friend class\" that the class owning the hidden properties can export access to, by returning a subclass that implement the access-implementing methods. The \"API\" method of the friend class can be private so it is not accessible outside the class that needs friend access. Its only statement is a call to an abstract protected member that the exporting class implements. Here's the code:First the test that verifies that this actually works:Then the Service that needs friend access to a package private member of Entity:Finally: the Entity class that provides friendly access to a package private member only to the class application.service.Service. Okay, I must admit it is a bit longer than \"friend service::Service;\" but it might be possible to shorten it while retaining compile-time checking by using annotations. If you want to access protected methods you could create a subclass of the class you want to use that exposes the methods you want to use as public (or internal to the namespace to be safer), and have an instance of that class in your class (use it as a proxy).As far as private methods are concerned (I think) you are out of luck. I prefer delegation or composition or factory class (depending upon the issue that results in this problem) to avoid making it a public class. If it is a \"interface/implementation classes in different packages\" problem, then I would use a public factory class that would in the same package as the impl package and prevent the exposure of the impl class.If it is a \"I hate to make this class/method public just to provide this functionality for some other class in a different package\" problem, then I would use a public delegate class in the same package and expose only that part of the functionality needed by the \"outsider\" class.Some of these decisions are driven by the target server classloading architecture (OSGi bundle, WAR/EAR, etc.), deployment and package naming conventions. For example, the above proposed solution, 'Friend Accessor' pattern is clever for normal java applications. I wonder if it gets tricky to implement it in OSGi due to the difference in classloading style.See \nfor more info.In Java it is possible to have a \"package-related friendness\". \nThis can be userful for unit testing.\nIf you do not specify private/public/protected in front of a method, it will be \"friend in the package\".\nA class in the same package will be able to access it, but it will be private outside the class.This rule is not always known, and it is a good approximation of a C++ \"friend\" keyword.\nI find it a good replacement.I agree that in most cases the friend keyword is unnecessary.And finally, if it really is necessary, there is the friend accessor pattern mentioned in the other answers.Not using a keyword or so.You could \"cheat\" using reflection etc., but I wouldn't recommend \"cheating\".A method I've found for solving this problem is to create an accessor object, like so:The first code to call  \"claims ownership\" of the accessor. Usually, this is code that creates the object.This also has an advantage over C++'s friend mechanism, because it allows you to limit access on a  level, as opposed to a  level. By controlling the accessor reference, you control access to the object. You can also create multiple accessors, and give different access to each, which allows fine-grained control over what code can access what:Finally, if you'd like things to be a bit more organized, you can create a reference object, which holds everything together. This allows you to claim all accessors with one method call, as well as keep them together with their linked instance. Once you have the reference, you can pass the accessors out to the code that needs it:After much head-banging (not the good kind), this was my final solution, and I very much like it. It is flexible, simple to use, and allows very good control over class access. (The  access is very useful.) If you use protected instead of private for the accessors/references, sub-classes of Foo can even return extended references from . It also doesn't require any reflection, so it can be used in any environment.I think, the approach of using the friend accessor pattern is way too complicated. I had to face the same problem and I solved using the good, old copy constructor, known from C++, in Java:In your application you could write the following code:The advantage of this method is that only your application has access to the protected data. It's not exactly a substitution of the friend keyword. But I think it's quite suitable when you write custom libraries and you need to access protected data.Whenever you have to deal with instances of ProtectedContainer you can wrap your ProtectedAccessor around it and you gain access.It also works with protected methods. You define them protected in your API. Later in your application you write a private wrapper class and expose the protected method as public. That's it.I once saw a reflection based solution that did \"friend checking\" at runtime using reflection and checking the call stack to see if the class calling the method was permitted to do so. Being a runtime check, it has the obvious drawback."},
{"body": "i am trying to integrate google sign in , in my app,i added these libraries:also add this to project build gradle:also add plugin to app build gradle:then add required permissions\nbut when i try to run my app , received this error:Try adding  to your app  file.Try Steve's  first. In case it happens frequently or first step didn't help  might help. For those who love to dig deeper here is couple similar issues (with more answers):  Another thing to watch for, is that you don't use That will import ALL the play services, and it'll only take little more than a hello world to exceed the 65535 method limit of a single dex APK.Always specify only the services you need, for instance: I just had to Clean my project and then it built successfully afterwards.This error began appearing for me when I added some new methods to my project. I knew that I was nowhere near the 65k method limit and did not want to enable multiDex support for my project if I could help it.I resolved it by increasing the memory available to the  task. I did this by specifying  in .I tried this after having had no success with other common solutions to this problem:Note: increasing the memory available to the DEX task can cause performance problems on systems with lower memory - . I also faced similar issue in Android Studio 1.5.1 and gradle 1.5.0.\nI just have to remove unwanted libraries from dependencies which may be automatically added in my app's build.gradle file.\nOne was :  compile 'com.google.android.gms:play-services:8.4.0'.\nSo for best practices try to only include specific play services library like for ads include onlyAlthoughthis will also solve the issue, but provides with a lot of Notes in gradle console, making it confusing to find the other real issues during buildI'm using AS 1.5.1 and encountered the same problem. But just cleaning the project just wont do, so I tried something.This worked with me, so I hope this helps.you can see the documentation of Manifest.xmlAt my case change buildToolsVersion from \"24\" to \"23.0.2\", solve the problem.I had same problem when i rolled back to old version via git, and that version had previous .jar library of one 3rd party api, and for some reason turned out that both jar of the same sdk, just different versions were in /libs folder. First Delete intermediates files\n  YOUR APP FOLDER\\app\\build\\intermediates\nOR\n  Clean your project and then rebuild.Thent add    i.e. It's work for meIn my case the Exception occurred because all google play service extensions are not with same version as followsIt worked when I changed this to  In build.gradle you need to add the next one.  Add the next one in local.properties  After that into Application class you need to add the Multidex too.  Don't forget add the line code into Manifest.xml That's it with this was enough for resolve the bug:\nExecution failed for task ':app:transformClassesWithDexForDebug. \n\nCheck very well into build.gradle with javaMaxHeapSize \"2g\" and the local.properties org.gradle.jvmargs=-Xmx2048m are of 2 gigabyte.If you are using the latest gradle version ie  , then try updating the latest support respository from the SDK manager and rebuild the entire project.If you need add this reference for cordova plugin add next line in your plugin.xml file.If the different dependencies have a same jar also cause this build error.For example:If \"library1\" and \"library2\" has a same jar named , this will make such an error.It happened to me because of Eclipse memory leak. I had to restart my computer.I changed a couple of pngs and the build number in the gradle and now I get this.  No amount of cleaning and restarting helped.  Disabling Instant Run fixed it for me.  YMMVI had the same option and as soon as I turned off Instant run, it worked fine on my API16 device, but on the API24 device it worked fine with Instant run. Hope this helps someone having the same issueSimply go to Build - Edit Build Types - Properties Tab - Build Type Version and downgrade it to ver 23.0.1. Click ok.\nThis works for android studio 1.5.\nIt worked for me.this code solved problemFor easiest way to implement google sign in visit: Also tryAlso keep same version number for different services.the write answer is in  put\ndefaultConfig {\n        multiDexEnabled true\n}\nthen  \nandroid:name=\"android.support.multidex.MultiDexApplication\"\nwish this answer is hellpful to some one"},
{"body": "I'm very new to Java EE and I'm trying to understand the concept of Local interfaces and Remote interfaces. I've been told that one of the big advantages of Java EE is that it is easy to scale (which I believe means you can deploy different components on different servers). Is that where Remote and Local interfaces come in? Are you supposed to use Remote interfaces if you expect your application to have different components on different servers? And use Local interfaces if your application is only going to reside on one server?If my assumptions above are correct, how would you go about choosing whether to use Local or Remote interfaces for a new application, where your unsure of what the volume of traffic would be? Start off by using Local interfaces, and gradually upgrade to Remote interfaces where applicable?Thanks for any clarification and suggestions.In the initial versions of the EJB specification, EJBs were \"assumed\" to be remote components and the only way to invoke them was to make a remote call, using RMI semantics and all the overhead it implies (a network call and object serialization for every method call). EJB clients had to pay this performance penalty even when collocated in the same virtual machine with the EJB container. Later, Sun realized most business applications were actually not distributing EJBs on a different tier and they fixed the spec (in EJB 2.0) by introducing the concept of Local interfaces so that clients collocated in the same virtual machine with the EJB container can call EJBs using direct method invocation, totally bypassing RMI semantics (and the associated overhead).Java EE can scale, but this doesn't necessarily means  components. You can run a Web+EJB application on a cluster without separating the Web tier and the EJB tier. I would phrase it like this: use remote interfaces if the client are not in the same JVM (this doesn't mean using only one server/JVM).I would probably start by using Local interfaces. And as already hinted, switching to remote interfaces is not always mandatory (you can cluster a  structure). I suggest to check the resources mentioned below (the 2 first ones are quite old but still relevant, the 2 others are more recent). While I agree with most of what is written above, I would like to refine the \"how to start\" ideas a bit.My suggestion to you is to never  program directly to EJB interfaces within your code. Always use a regular, business-oriented interface, program to it (meaning, have your code call methods on the business-oriented interface) and provide the EJB \"glue\" code as a pluggable implementation. Your program should be focused on business logic, and not on implementation details such as EJB.That way, you can easily switch between remote and local implementations - and if you use an IoC container such as Spring, you can do it by means of configuration only.A special note about switching from local to remote: note that there are a few semantic differences between the two. For example, calling an EJB method via its \"remote interface\" results in arguments being passed by-value, while calling through the \"local interface\" results in arguments being passed by-reference. This is a  difference; so if you \"start with local\", make sure that you design your system in a way that it takes \"remote\" semantics into consideration as well.If your design relies on EJB methods changing passed-in objects, then it would be tricky for you to \"switch to remote\" later; perhaps even impossible.Good luck.This may answers your concerns :Source: According to EJB Spec 3.2 an EJB can be either be  or . \nA business interface cannot be both local and remote at the same time.  annotated beans can only be accessed if they are in the same application. annotated beans can be accessed across different applications, residing in different jvms or across application servers.So the important things to keep in mind are:"},
{"body": "How do I pick a random element from a set?\nI'm particularly interested in picking a random element from a\nHashSet or a LinkedHashSet, in Java.\nSolutions for other languages are also welcome. A somewhat related Did You Know: There are useful methods in  for shuffling whole collections:  and .Fast solution for Java using an  and a : [element -> index].Motivation: I needed a set of items with  properties, especially to pick a random item from the set (see  method). Random navigation in a binary tree is not accurate: trees are not perfectly balanced, which would not lead to a uniform distribution.If you want to do it in Java, you should consider copying the elements into some kind of random-access collection (such as an ArrayList).  Because, unless your set is small, accessing the selected element will be expensive (O(n) instead of O(1)). [ed: list copy is also O(n)]Alternatively, you could look for another Set implementation that more closely matches your requirements.  The  from Commons Collections looks promising.This is faster than the for-each loop in the accepted answer:The for-each construct calls  on every loop, but since , that check is unnecessary overhead. I saw a 10-20% boost in speed, but YMMV. (Also, this compiles without having to add an extra return statement.)Note that this code (and most other answers) can be applied to any Collection, not just Set. In generic method form:Clojure solution:Can't you just get the size/length of the set/array, generate a random number between 0 and the size/length, then call the element whose index matches that number? HashSet has a .size() method, I'm pretty sure.In psuedocode -Perl 5Here is one way to do it.C++. This should be reasonably quick, as it doesn't require iterating over the whole set, or sorting it. This should work out of the box with most modern compilers, assuming they support . If not, you may need to use Boost.The  are helpful here to explain this, even if you don't use Boost.The trick is to make use of the fact that the data has been divided into buckets, and to quickly identify a randomly chosen bucket (with the appropriate probability).Solution above speak in terms of latency but doesn't guarantee equal probability of each index being selected.\nIf that needs to be considered, try reservoir sampling. . Collections.shuffle() (as suggested by few) uses one such algorithm.PHP, assuming \"set\" is an array:The Mersenne Twister functions are better but there's no MT equivalent of array_rand in PHP. has a set type and a random-element operator, unary \"?\", so the expressionwill produce a random number between 1 and 5.The random seed is initialized to 0 when a program is run, so to produce different results on each run use Javascript solution ;)Or alternatively:In lispIn Mathematica:Or, in recent versions, simply:This received a down-vote, perhaps because it lacks explanation, so here one is: generates a pseudorandom float between 0 and 1.  This is multiplied by the length of the list and then the ceiling function is used to round up to the next integer.  This index is then extracted from .Since hash table functionality is frequently done with rules in Mathematica, and rules are stored in lists, one might use:How about justThis is identical to accepted answer (Khoth), but with the unnecessary  and  variables removed.Though doing away with the two aforementioned variables, the above solution still remains random because we are relying upon random (starting at a randomly selected index) to decrement itself  toward  over each iteration.Unfortunately, this cannot be done efficiently (better than O(n)) in any of the Standard Library set containers.This is odd, since it is very easy to add a randomized pick function to hash sets as well as binary sets. In a not to sparse hash set, you can try random entries, until you get a hit. For a binary tree, you can choose randomly between the left or right subtree, with a maximum of O(log2) steps. I've implemented a demo of the later below:I got [995, 975, 971, 995, 1057, 1004, 966, 1052, 984, 1001] as output, so the distribution seams good.I've struggled with the same problem for myself, and I haven't yet decided weather the performance gain of this more efficient pick is worth the overhead of using a python based collection. I could of course refine it and translate it to C, but that is too much work for me today :)Since you said \"Solutions for other languages are also welcome\", here's the version for Python:PHP, using MT:For fun I wrote a RandomHashSet based on rejection sampling. It's a bit hacky, since HashMap doesn't let us access it's table directly, but it should work just fine.It doesn't use any extra memory, and lookup time is O(1) amortized. (Because java HashTable is dense).you can also  transfer the set to array use array \nit will probably work on small scale i see the for loop in the most voted answer is O(n) anyway If you really just want to pick \"any\" object from the , without any guarantees on the randomness, the easiest is taking the first returned by the iterator.The easiest with Java 8 is:where  is a random integer. Of course it is of less performance than that with the A generic solution using Khoth's answer as a starting point.If set size is not large then by using Arrays this can be done.With  we can do a little better than Khoth's answer:"},
{"body": "I have a Java project in Eclipse with ~10 packages and ~10 class files per package.  Is there a way to determine total lines of code for the whole project from within Eclipse?  I am familiar with other tools (e.g., Code Analyzer, wc, etc.) but I want to know if there is a way to do this within Eclipse (or get confirmation that there is no way to do it).Here's a good metrics plugin that displays number of lines of code and much more:It says it requires Eclipse 3.1, although I imagine they mean 3.1+Here's another metrics plugin that's been tested on Ganymede:  > Check the  box.Use this expression: Select whatever file types (, , etc..) and working sets are appropriate for you.   Under linux, the simpler is:To resume, just do:Are you interested in counting the executable lines rather than the total file line count?\nIf so you could try a code coverage tool such as .\nAs a side effect of the code coverage stats you get stats on the number of executable lines and blocks (and methods and classes). These are rolled up from the method level upwards, so you can see line counts for the packages, source roots and projects as well.For eclipse(Indigo), install ().After installation:\n- Right click on your project\n- Choose  tools --> compute metrics\n- And you will get your answer in a Metrics tab as Number of Lines.You could use a batch file with the following script:I think if you have MyEclipse, it adds a label to the Project Properties page which contains the total number of source code lines. Might not help you as MyEclipse is not free though.Unfortunately, that wasn't enough in my case so I wrote a source analyzer to gather statistics not gathered by other solutions (for example the metrics mentioned by AlbertoPL).You could use former Instantiations product . This eclipse plugin provides you suchlike statistics in code metrics view. This is provided by Google free of charge.A very simple plugin for counting actual lines of source code is  eclipse plugin. Please download and try.Place the downloaded jar file under eclipse\\plugin folder and restart eclipse.\n\n"},
{"body": "I'm essentially looking for a \"@Ignore\" type annotation with which I can stop a particular field from being persisted. How can this be achieved? complies with your needs.To ignore a field, annotate it with  so it will not be mapped by hibernate.\nSource: .To ignore a field, annotate it with  so it will not be mapped by hibernate.but then  the field when converting to JSON.(omit by JPA but still include in Jackson) use  :You can also use  and hide fields in JSON during deserialization when :This answer comes a little late, but it completes the response.In order to avoid a field from an entity to be persisted in DB one can use one of the two mechanisms: - the JPA annotation marking a field as not persistable keyword in java. Beware - using this keyword, will prevent the field to be used with any serialization mechanism from java. So, if the field must be serialized you'd better use just the  annotation.To complete the above answers, I had the case using an XML mapping file where neither the  nor  worked...\nI had to put the transient information in the xml file:"},
{"body": "I'm a beginner in Java.  Please suggest which collection(s) can/should be used for maintaining a sorted list in Java. I have tried  and , but they weren't what I was looking for.This comes very late, but there is a class in the JDK just for the purpose of having a sorted list. It is named (somewhat out of order with the other  interfaces) \"\". It can sort either s or using a .The difference with a  sorted using  is that this will maintain a partial order at all times, with O(log(n)) insertion performance, by using a heap data structure, whereas inserting in a sorted  will be O(n) (i.e., using binary search and move).However, unlike a ,  does not support indexed access (),  (thus the name ).TreeMap and TreeSet will give you an iteration over the contents in sorted order. Or you could use an ArrayList and use Collections.sort() to sort it. All those classes are in java.utilIf you want to maintain a  which you will  (i.e. a structure which, in addition to being sorted, allows duplicates and whose elements can be efficiently referenced by index), then use an ArrayList but when you need to insert an element, always use  at which you add a given element. The latter method tells you the index you need to insert at to keep your list in sorted order.Use Google Guava's TreeMultiset.  Guava is a spectacular collections API.Guava: TreeMultiset: One problem with providing an implementation of List that maintains sorted order is the promise made in the Javadocs of the 'add' method.There are a few options. I'd suggest TreeSet if you don't want duplicates and the objects you're inserting are comparable.You can also use the static methods of the Collections class to do this.See  and  for more info.You want the  implementations, namely .If you just want to sort a list, use any kind of  and use . If you want to make sure elements in the list are unique and always sorted, use a .What I have done is implement List having a internal instance with all the methods delegated.After, I have implemented a new method \"putOrdered\" which insert in the proper position if the element doesn't exist or replace just in case it exist.If you want to allow repeated elements just implement addOrdered instead (or both).If you want to avoid inserts you can also throw and unsupported operation exception on  \"add\" and \"set\" methods. ... and also You have to be careful with ListIterator methods because they could modify your internal list. In this case you can return a copy of the internal list or again throw an exception.TreeSet would not work because they do not allow duplicates plus they do not provide method to fetch element at specific position. PriorityQueue would not work because it does not allow fetching elements at specific position which is a basic requirement for a list.\nI think you need to implement your own algorithm to maintain a sorted list in Java with O(logn) insert time, unless you do not need duplicates.\nMaybe a solution could be using a TreeMap where the key is a subclass of the item overriding the equals method so that duplicates are allowed. You can try solving these tasks with  if you are using prior versions to java 8. You can find it here: Here you have an example:Of course, having this kind of beauty impacts in the performance (an average of 2 times), but can you find a more readable code?The problem with PriorityQueue is that it's backed up by an simple array, and the logic that gets the elements in order is done by the \"queue[2*n+1] and queue[2*(n+1)]\" thingie. It works great if you just pull from head, but makes it useless if you are trying to call the .toArray on it at some point. I go around this problem by using com.google.common.collect.TreeMultimap, but I supply a custom Comparator for the values, wrapped in an Ordering, that never returns 0. ex. for Double:This way I get the values in order when I call .toArray(), and also have duplicates.The most efficient way to implement a sorted list like you want would be to implement indexable skiplist as in here: . \nIt would allow to have inserts/removals in O(log(n)) and would allow to have indexed access at the same time. And it would also allow duplicates.Skiplist is a pretty interesting and, I would say, underrated data structure.\nUnfortunately there is no skiplist implementation in Java base library, but you can use one of open source implementations or implement it yourself.What you want is a binary search tree. It maintains sorted order while offering logarithmic access for searches, removals and insertions (unless you have a degenerated tree - then it's linear). It is quite easy to implement and you even can make it implement the List interface, but then the index-access gets complicated.Second approach is to have an ArrayList and then a bubble sort implementation. Because you are inserting or removing one element at a time, the access times for insertions and removals are linear. Searches are logarithmic and index access constant (times can get different for LinkedList). The only code you need is 5, maybe 6 lines of bubble sort.You can use Arraylist and Treemap, as you said you want repeated values as well then you cant use TreeSet, though it is sorted as well, but you have to define comparator. Use sort() method to sort the list as below:For reference see the link:\nUse  which gives elements in sorted order. OR use  for external sorting with ."},
{"body": "What is the most efficient Java Collections library?A few years ago, I did a lot of Java and had the impression back then that  is the best (most efficient) Java Collections implementation. But when I read the answers to the question \"\" I noticed that  is hardly mentioned. So which Java Collections library is best now?  To clarify, I mostly want to know what library to use when I have to store millions of entries in a hash table etc. (need a small runtime and memory footprint).From inspection, it looks like Trove is just a library of collections for primitive types - it's not like it's meant to be adding a lot of functionality over the normal collections in the JDK.Personally (and I'm biased) I love  (including the former Google Java Collections project). It makes various tasks (including collections) a lot easier, in a way which is at least reasonably efficient. Given that collection operations rarely form a bottleneck in my code (in my experience) this is \"better\" than a collections API which may be more efficient but doesn't make my code as readable.Given that the overlap between Trove and the Guava is pretty much nil, perhaps you could clarify what you're actually looking for from a collections library.The question is (now) about storing lots of data, which can be represented using primitive types like , in a Map. Some of the answers here are very misleading in my opinion. Let's see why.I modified the benchmark from  to measure both runtime and memory consumption. I also added  to this benchmark, which is another collections library for primitive types (I use that one extensively). The 'official' trove benchmark does not compare IntIntMaps to Java Collection's , probably storing  and storing  is not the same from a technical point of view. But a user might not care about this technical detail, he wants to store data representable with  efficiently.First the relevant part of the code:I assume the data comes as primitive , which seems sane. But this implies a runtime penalty for java util, because of the auto-boxing, which is not neccessary for the primitive collections frameworks. The runtime results (without  calls, of course) on WinXP, jdk1.6.0_10:While this might already seem drastic, this is not the reason to use such a framework. The reason is memory performance. The results for a Map containing 100000  entries:Java Collections needs  the memory compared to the primitive collection frameworks. I.e. you can keep three times as much data in memory, without resorting to disk IO which lowers runtime performance by magnitudes. And this matters. Read  to find out why.In my experience high memory consumption is the biggest performance issue with Java, which of course results in worse runtime performance as well. Primitive collection frameworks can really help here.So: No, java.util is not the answer. And \"adding functionality\" to Java collections is not the point when asking about efficiency. Also the modern JDK collections do  \"out-perform even the specialized Trove collections\".Disclaimer: The benchmark here is far from complete, nor is it perfect. It is meant to drive home the point, which I have experienced in many projects. Primitive collections are useful enough to tolerate fishy API -  you work with lots of data.I know this is an old post and there are a ton of answers here. \nBut, The answers above are superficial and over simplified in terms of suggesting a library. There is no one library that does well across the various benchmarks presented here. The only conclusion I derive is if you care about performance and memory and specifically dealing with primitive types, its more than worth looking at the non jdk alternatives.Here is a more sound analysis, in terms of benchmark mechanics and the libraries covered.\n is a thread in the mahout dev list. The libraries covered are:\nUnfortunately, the original benchmarks are no longer available and besides its a bit outdated. \n is a fairly recent (Jan 2015) benchmarks done by someone else. It is not as comprehensive nor does it have the interactive exploratory tools as the original link.As other commentators have noticed, the definition of \"efficient\" casts a wide net. However no one has yet mentioned the . Some of the highlights:The Javolution distribution includes a benchmark suite so you can see how they stack up against other libraries/the built-in collections.Some collection libs to consider:I would first and foremost reach for the JDK collection library.  It covers most common things you need to do and is obviously already available to you.Google Collections is probably the best high-quality library outside the JDK.  It's heavily used and well supported.Apache Commons Collections is older and suffers a bit from the \"too many cooks\" problem but has a lot of useful stuff as well.Trove has very specialized collections for cases like primitive keys/values.  These days we find that on modern JDKs and with the Java 5+ collections and concurrent use cases, the JDK collections out-perform even the specialized Trove collections.If you have really high concurrency use cases, you should definitely check out stuff like the NonBlockingHashMap in the high-scale lib, which is a lock-free implementation and can stomp on ConcurrentHashMap if you have the right use case for it.Sorry for the obvious answer, but for most uses, the default  are more than sufficient.To store millions of  in a map, take a look at I'm developer of happy-collections from Depends on how we define \"efficient\".Every data structure has its own Big-Oh behavior for reading, writing, iterating, memory footprint, etc.  A linked list in one library is likely to be the same as any other.  And a hash map will be faster for reading O(1) than a linked list O(n).This doesn't sound like \"most efficient\".  It sounds like \"most popular\" to me.Just some feedback - I've never heard of it, and I don't know anyone who has used it.  Collections built into the JDK, Google, or Apache Commons are well-known to me.Trove offers a few advantages.That said, a lot has been done to improve jdk collections since trove was written.It's the hashing strategies that make it appealing to me though... Google for trove and read their overview.  as well as the  package should be mentioned, if you plan to use the HashMap in multiple threads. small memory footprint is assued, since this is part of standard java.If you want to store millions of records in a hash table, chances are that you will run into memory problems. This happened to me when I tried creating a map with 2.3 million String objects, for example. I went with , which is very mature and performs well. They have a Java API that wraps the Collections API, so you can easily create arbitrarily large maps with very little memory footprint. Access will be slower though (as it is stored on disk). : is there a decent (and efficient), well maintained, library for immutable collections? Clojure has excellent support for this, and it would be nice to have something similar for Java."},
{"body": "Upcasting is allowed in Java, however downcasting gives a compile error. The compile error can be removed by adding a cast but would anyway break at the runtime. In this case why Java allows downcasting if it cannot be executed at the runtime?\nIs there any practical use for this concept? Downcasting is allowed when there is a possibility that it suceeds at run time:In some cases this will not succeed:In others it will work:Note that some casts will be disallowed at compile time, because they will never succeed at all:Using your example, you could do:I believe this applies to all statically typed languages:The typecast effectively says: assume this is a reference to the cast class and use it as such.  Now, lets say o is  an Integer, assuming this is a String makes no sense and will give unexpected results, thus there needs to be a runtime check and an exception to notify the runtime environment that something is wrong.In practical use, you can write code working on a more general class, but cast it to a subclass if you know what subclass it is and need to treat it as such.  A typical example is overriding Object.equals().  Assume we have a class for Car:We can all see that the code you provided won't work at run time. That's because we know that the expression  can  be an object of type .But that's not how the compiler sees it. By the time the compiler is checking whether the cast is allowed, it just sees this:And as others have demonstrated, that sort of cast is perfectly legal. The expression on the right could very well evaluate to an object of type . The compiler sees that  and  have a subtype relation, so with the \"expression\" view of the code, the cast might work.The compiler does not consider the special case when it knows  what object type  will really have. It just sees the static type as  and considers the dynamic type could be  or any descendant of , including .@ Original Poster - see inline comments.I believe this is because there is no way for the compiler to know at compile-time if the cast will succeed or not. For your example, it's simple to see that the cast will fail, but there are other times where it is not so clear. For instance, imagine that types B, C, and D all extend type A, and then a method  returns an instance of either B, C or D depending on a randomly generated number. The compiler cannot know which exact run-time type will be returned by this method, so if you later cast the results to , there is no way to know if the cast will succeed (or fail). Therefore the compiler has to assume casts will succeed.Downcast works in the case when we are dealing with an upcasted object.\nUpcasting:So now this  variable can always be downcasted to  because the object which was cast is an ,but because  is an Object it cannot be cast to  because  cannot be cast to .Downcasting is very useful in the following code snippet I use this all the time. Thus proving that downcasting is useful. I store String in the Linked List. \nWhen I retrieve the elements of Linked List, Objects are returned. To access the elements as Strings(or any other Class Objects), downcasting helps me. Java allows us to compile downcast code trusting us that we are doing the wrong thing. \nStill if humans make a mistake, it is caught at runtime.Consider the below examplehere we create the object of subclass Bone and assigned it to super class AOne reference and now superclass reference does not know \nabout the method method2 in the subclass i.e Bone  during compile time.therefore we need to downcast this reference of superclass to subclass reference so as the resultant reference can know about the presence of methods in the subclass i.e Bone"},
{"body": "We know that it is expensive to catch exceptions. But, is it also expensive to use a try-catch block in Java even if an exception is never thrown? I found the Stack Overflow question/answer , but it is for . has almost no expense at all. Instead of doing the work of setting up the  at runtime, the code's metadata is structured at compile time such that when an exception is thrown, it now does a relatively expensive operation of walking up the stack and seeing if any  blocks exist that would catch this exception. From a layman's perspective,  may as well be free. It's actually throwing the exception that costs you - but unless you're throwing hundreds or thousands of exceptions, you still won't notice the cost. has some minor costs associated with it. Java cannot do some optimizations on code in a  block that it would otherwise do. For example, Java will often re-arrange instructions in a method to make it run faster - but Java also needs to guarantee that if an exception is thrown, the method's execution is observed as though its statements, as written in the source code, executed in order up to some line.Because in a  block an exception can be thrown (at any line in the try block! Some exceptions are thrown asynchronously, such as by calling  on a Thread (which is deprecated), and even besides that OutOfMemoryError can happen almost anywhere) and yet it can be caught and code continue to execute afterwards in the same method, it is more difficult to reason about optimizations that can be made, so they are less likely to happen. (Someone would have to program the compiler to do them, reason about and guarantee correctness, etc. It'd be a big pain for something meant to be 'exceptional') But again, in practice you won't notice things like this.Let's measure it, shall we?On my computer, this prints something like:At least in this trivial example, the try statement had no measurable impact on performance. Feel free to measure more complex ones.Generally speaking, I recommend not to worry about the performance cost of language constructs until you have evidence of an actual performance problem in your code. Or as Donald Knuth  it: \"premature optimization is the root of all evil\"./ may have some impact on performance. This is because it prevents JVM from doing some optimizations. Joshua Bloch, in \"Effective Java,\" said the following: Yep, as the others have said, a  block inhibits some optimizations across the  characters surrounding it.  In particular, the optimizer must assume that an exception could occur at any point within the block, so there's no assurance that statements get executed.For example:Without the , the value calculated to assign to  could be saved as a \"common subexpression\" and reused to assign to .  But because of the  there is no assurance that the first expression was ever evaluated, so the expression must be recomputed.  This isn't usually a big deal in \"straight-line\" code, but can be significant in a loop.It should be noted, however, that this applies ONLY to JITCed code.  javac does only a piddling amount of optimization, and there is zero cost to the bytecode interpreter to enter/leave a  block.  (There are no bytecodes generated to mark the block boundaries.)And for bestsss:Output:javap output:No \"GOTO\".To understand why the optimizations cannot be performed, It is useful to understand the underlying mechanisms.  The most succinct example I could find was implemented in C macros at:  Compilers often have difficulty determining if a jump can be localized to X, Y and Z so they skip optimizations that they can't guarantee to be safe, but the implementation itself is rather light.Yet another microbenchmark ().I created a test in which I measure try-catch and no-try-catch code version based on an exception percentage. 10% percentage means that 10% of the test cases had division by zero cases. In one situation it is handled by a try-catch block, in the other by a conditional operator. Here is my results table:Which says that there is no significant difference between any of these cases."},
{"body": "How can I create a concurrent List instance, where I can access elements by index? Does the JDK have any classes or factory methods I can use?There is a concurrent list implementation in .  in particular.You can very well use  if all you need is simple invocation synchronization:If you don't care about having index-based access and just want the insertion-order-preserving characteristics of a List, you could consider a . Since it implements Iterable, once you've finished adding all the items, you can loop over the contents using the simplified for-each syntax:Because the act of acquiring the position and getting the element from the given position naturally requires some locking (you can't have the list have structural changes between those two operations).The very idea of a concurrent collection is that each operation on its own is atomic and can be done without explicit locking/synchronization.Therefore getting the element at position  from a given  as an atomic operation doesn't make too much sense in a situation where concurrent access is anticipated."},
{"body": "I just learned about Java's Scanner class and now I'm wondering how it compares/competes with the StringTokenizer and String.Split. I know that the StringTokenizer and String.Split only work on Strings, so why would I want to use the Scanner for a String? Is Scanner just intended to be one-stop-shopping for spliting?They're essentially horses for courses.You'll note from my timings that  can still tokenize  on a typical machine. In addition, it has the advantage over  that it gives you the output as a string array, which is usually what you want. Using an , as provided by , is too \"syntactically fussy\" most of the time. From this point of view,  is a bit of a waste of space nowadays, and you may as well just use .Let's start by eliminating . It is getting old and doesn't even support regular expressions. Its documentation states:So let's throw it out right away. That leaves  and . What's the difference between them?For one thing,  simply returns an array, which makes it easy to use a foreach loop: is built more like a stream:or(It has a rather , so don't think that it's always restricted to such simple things.)This stream-style interface can be useful for parsing simple text files or console input, when you don't have (or can't get) all the input before starting to parse.Personally, the only time I can remember using  is for school projects, when I had to get user input from the command line. It makes that sort of operation easy. But if I have a  that I want to split up, it's almost a no-brainer to go with .StringTokenizer was always there. It is the fastest of all, but the enumeration-like idiom might not look as elegant as the others.split came to existence on JDK 1.4. Slower than tokenizer but easier to use, since it is callable from the String class.Scanner came to be on JDK 1.5. It is the most flexible and fills a long standing gap on the Java API to support an equivalent of the famous Cs scanf function family.Split is slow, but not as slow as Scanner.  StringTokenizer is faster than split. However, I found that I could obtain double the speed, by trading some flexibility, to get a speed-boost, which I did at JFastParser Testing on a string containing one million doubles:If you have a String object you want to tokenize, favor using String's  method over a StringTokenizer.  If you're parsing text data from a source outside your program, like from a file, or from the user, that's where a Scanner comes in handy.I recently did some experiments about the bad performance of String.split() in highly performance sensitive situations. You may find this useful.  The gist is that String.split() compiles a Regular Expression pattern each time and can thus slow down your program, compared to if you use a precompiled Pattern object and use it directly to operate on a String.String.split seems to be much slower than StringTokenizer. The only advantage with split is that you get an array of the tokens. Also you can use any regular expressions in split. \n    org.apache.commons.lang.StringUtils has a split method which works much more faster than any of two viz. StringTokenizer or String.split. \n    But the CPU utilization for all the three is nearly the same. So we also need a method which is less CPU intensive, which I am still not able to find. For the default scenarios I would suggest Pattern.split() as well but if you need maximum performance (especially on Android all solutions I tested are quite slow) and you only need to split by a single char, I now use my own method:Use \"abc\".toCharArray() to get the char array for a String. For example:One important difference is that both String.split() and Scanner can produce empty strings but StringTokenizer never does it.For example:Output:This is because the delimiter for String.split() and Scanner.useDelimiter() is not just a string, but a regular expression. We can replace the delimiter \" \" with \" +\" in the example above to make them behave like StringTokenizer.String.split() works very good but has its own boundaries, like if you wanted to split a string as shown below based on single or double pipe (|) symbol, it doesn't work. In this situation you can use StringTokenizer.ABC|IJK"},
{"body": "I want to start a server which listen to a port. I can specify port explicitly and it works. But I would like to find a port in an automatic way. In this respect I have two questions.If you don't mind the port used, specify a port of 0 to the  and it will listen on any free port.If you want to use a specific set of ports, then the easiest way is probably to iterate through them until one works. Something like this:Could be used like so:If you pass 0 as the port number to the constructor of ServerSocket, It will allocate a port for you.Starting from Java 1.7 you can use try-with-resources like this: If you need to find an open port on a specific interface check  documentation for alternative constructors.  Any code using the port number returned by this method is subject to a race condition - a different process / thread may bind to the same port immediately after we close the ServerSocket instance. According to , you should use ports  to  if you don't need a 'well known' port.AFAIK the only way to determine wheter a port is in use is to try to open it.If you need in  use:The Eclipse SDK contains a class , that does what you want. You may have a look into the git .If you use Spring you may try See This works for me on Java 6If you want to create your own server using a , you can just have it pick a free port for you:Other server implementations typically have similar support.  for example picks a free port unless you explicitly set it:I have recently released a tiny library for doing just that with tests in mind.\nMaven dependency is:Once installed, free port numbers can be obtained via:It may not help you much, but on my (Ubuntu) machine I have a file /etc/services in which at least the ports used/reserved by some of the apps are given. These are the standard ports for those apps. No guarantees that these are running, just the default ports these apps use (so you should not use them if possible).There are slightly more than 500 ports defined, about half UDP and half TCP.The files are made using information by IANA, see .If your server starts up, then that socket was not used. Something like: "},
{"body": "What is lazy loading in Java? I don't understand the process. Can anybody help me to understand the process of lazy loading?Say you have a parent and that parent has a collection of children. Hibernate now can \"lazy-load\" the children, which means that it does not actually load all the children when loading the parent. Instead, it loads them when requested to do so. You can either request this explicitly or, and this is far more common, hibernate will load them automatically when you try to access a child.Lazy-loading can help improve the performance significantly since often you won't need the children and so they will not be loaded.Also beware of the n+1-problem. Hibernate will not actually load all children when you access the collection. Instead, it will load each child individually. When iterating over the collection, this causes a query for every child. In order to avoid this, you can trick hibernate into loading all children simultaneously, e.g. by calling parent.getChildren().size().\"Lazy loading\" means that an entity will be loaded  when you  accesses the entity for the  time.The  is like this:This saves the cost of preloading/prefilling  the entities in a large dataset beforehand while you after all actually don't need  of them.In Hibernate, you can configure to lazily load a collection of child entities. The  lazy loading is then done inside the methods of the  which Hibernate uses \"under the hoods\" to assign the collection of entities as .E.g..Martin Fowler defines the  pattern in  as such:So, when loading a given object, the idea is to not  the related object(s) that you may not use immediately to save the related performance cost. Instead, the related object(s) will be loaded only when used. This is not a pattern specific to data access and Hibernate but it is particularly useful in such fields and Hibernate supports lazy loading of one-to-many associations and single-point associations (one-to-one and many-to-one) also under certain conditions. \nLazy interaction is discussed in more detail in  of the Hibernate 3.0 Reference Documentation. Bydefault lazy loading is true.Lazy loading means when the select query is executed it will not hit the database. It will wait for getter function i.e when we required then ,it will fetch from the datbase.\nfor example:\nYou are a parent who has a kid with a lot of toys. But the current issue is whenever you call him (we assume you have a boy), he comes to you with all his toys as well. Now this is an issue since you do not want him carrying around his toys all the time.\nSo being the rationale parent, you go right ahead and define the toys of the child as LAZY. Now whenever you call him, he just comes to you without his toys.Lazy fetching decides whether to load child objects while loading the Parent Object. \nYou need to do this setting respective hibernate mapping file of the parent class. \n (means not to load child) \nBy default the lazy loading of the child objects is true. This make sure that the child objects are not loaded unless they are explicitly invoked in the application by calling  method on parent.In this case hibernate issues a fresh database call to load the child when  is actully called on the Parent object.But in some cases you do need to load the child objects when parent is loaded. \nJust make the lazy=false and hibernate will load the child when parent is loaded from the database.Example : \nIf you have a TABLE ? EMPLOYEE mapped to Employee object and contains set of Address objects. \nParent Class : Employee class,\nChild class : Address Class In the Employee.hbm.xml file In the above configuration. \nIf  : - when you load the Employee object that time child object Address is also loaded and set to setAddresss() method. \nIf you call employee.getAdress() then loaded data returns.No fresh database call. If  :- This the default configuration. If you don?t mention then hibernate consider lazy=true. \nwhen you load the Employee object that time child object Adress is not loaded. You need extra call to data base to get address objects. \nIf you call  then that time database query fires and return results. Fresh database call.In layman's language it is like you are making a cake and you will need 5-10 ingredients from fridge. You have two options get all ingredients from fridge and put it on your kitchen platform or bring the item you want when you need..\nSimilarly in eager loading you fetch all information about bean and its related classes (not  child or is-a relation but has a relationship, i.e. cake has flour, has milk, has cream etc) and in case of lazy loading first you bring only its identifier and values that are coming from same table (necessary ingredients that first you will need in your bowl in case of cake)..all information that is coming from other tables will be fetched as and when required/used.Hope this helps :)Lazy Loading? Well, it simply means that child records are not fetched immediately, but automatically as soon as you try to access them.WikipediaLink of  from hibernate.orgLazy setting decides whether to load child objects while loading the Parent Object.You need to do this setting respective hibernate mapping file of the parent class.Lazy = true (means not to load child)By default the lazy loading of the child objects is true. This make sure that the child objects are not loaded unless they are explicitly invoked in the application by calling getChild() method on parent.In this case hibernate issues a fresh database call to load the child when getChild() is actully called on the Parent object.But in some cases you do need to load the child objects when parent is loaded. Just make the lazy=false and hibernate will load the child when parent is loaded from the database.Exampleslazy=true (default)Address child of User class can be made lazy if it is not required frequently.lazy=falseBut you may need to load the Author object for Book parent whenever you deal with the book for online bookshop.Lazy initialization is a performance optimization. It's used when data is deemed to be 'expensive' for some reason.\nFor example:\nif the hashCode value for an object might not actually be needed by its caller, always calculating the hashCode for all instances of the object may be felt to be unnecessary.\nsince accessing a file system or network is relatively slow, such operations should be put off until they are absolutely required.Lazy initialization has two objectives :\ndelay an expensive operation until it's absolutely necessary\nstore the result of that expensive operation, such that you won't need to repeat it againHiberante supports the feature of lazy initialization for both entities and collections.\nHibernate engine loads only those objects that we are querying for does not other entites or collections.\n\n\n lazy=\"false\" by default loading initialization mention for the only child is lazy.in case of true that is parent is loading does not support childLazy setting decides whether to load child objects while loading the Parent Object.You need to do this setting respective hibernate mapping file of the parent class.Lazy = true (means not to load child)By default the lazy loading of the child objects is true.Lazy loading allows you to defer the association retrieval or to have a better control over the fetching strategy.When you use EAGER loading, you define a global fetch plan which cannot be overridden at query time, meaning you are limited to a decision you took while designing your entity model. The , because the fetching strategy is a query-time policy and it might differ from a business use case to another.The  is a very important aspect, as too much EAGER fetching can cause serious performance related issues.Well it simply means loading data you need currently instead of loading whole bunch of data at once which you won't use now. Thereby making application load time faster than usual. "},
{"body": "Let's say I have an application that utilizes the  framework as suchWhen I run this application in the debugger, a thread is created with the following (default) name: . As you can see, this isn't terribly useful and as far as I can tell, the  framework does not provide an easy way to name the created threads or thread-pools.So, how does one go about providing names for the threads/thread-pools? For instance, .You could supply a  to . The factory will be responsibe for creating threads, and will be able to name them.To quote the :Guava almost always has what you . and pass it off to your .You can try to provide your own thread factory, which will create thread with appropriate names.  Here's one example:The  from apache commons-lang is also useful to provide the naming behavior. Instead of writing an anonymous inner class, you can use the Builder to name the threads as you want. Here's the example from the javadocs:You can also change the name of your thread afterwards, while the thread is executed:That could be of interest if for instance you're using the same ThreadFactory for different type of tasks.There's an  for this with Oracle. From the comments from the Oracle employee it seems they don't understand the issue and won't fix. It's one of these things that is dead simple to support in the JDK (without breaking backwards compatibility) so it is kind of a shame that the RFE gets misunderstood.As pointed out you need to implement your own . If you don't want to pull in Guava or Apache Commons just for this purpose I provide here a  implementation that you can use. It is exactly similar to what you get from the JDK except for the ability to set the thread name prefix to something else than \"pool\".When you want to use it you simply take advantage of the fact that all  methods allow you to provide your own . Thiswill give an ExecutorService where threads are named  but by using you'll get an ExecutorService where threads are named . Voila!Pass the ThreadFactory to an executorservice and you are good to go A quick and dirty way is to use  in the  method.If you are using Spring, there is  for which you can set a thread name prefix.Extend  Sample code:output:....etc  You can write your own implementation of ThreadFactory, using for example some existing implementation (like defaultThreadFactory) and change the name at the end.Example of implementing ThreadFactory: And usage:"},
{"body": "Is there a way to set the  attribute of a  programmatically? There doesn't appear to be a  method.To be clear, I am not talking about View / Widget styles! I am talking about the following:setTypeface is the Attribute textStyle.As Shankar V added, to preserve the previously set typeface attributes you can use:Let's say you have a style called RedHUGEText on your values/styles.xml:Just create your TextView as usual in the XML layout/your_layout.xml file, let's say:And in the java code of your Activity you do this:It worked for me! And it applied color, size, gravity, etc. I've used it on handsets and tablets with Android API Levels from 8 to 17 with no problems.Remember... this is useful only if the style of the text really depends on a condition on your Java logic or you are building the UI \"on the fly\" with code... if it doesn't, it is better to just do:You can always have it your way!Hope it helps!Search for  or also . There is similar question on stackoverflow: So many way to achieve this task some are below:-This question is asked in a lot of places in a lot of different ways. I originally answered it here but I feel it's relevant in this thread as well (since i ended up  when I was searching for an answer).There is no one line solution to this problem, but this worked for my use case. The problem is, the 'View(context, attrs, defStyle)' constructor does not refer to an actual style, it wants an attribute. So, we will:In 'res/values/attrs.xml', define a new attribute:In res/values/styles.xml' I'm going to create the style I want to use on my custom TextViewIn 'res/values/themes.xml' or 'res/values/styles.xml', modify the theme for your application / activity and add the following style:Finally, in your custom TextView, you can now use the constructor with the attribute and it will receive your styleIt's worth noting that I repeatedly used customTextView in different variants and different places, but it is in no way required that the name of the view match the style or the attribute or anything. Also, this technique should work with any custom view, not just TextViews.This worked for meor I\u00b4ve resolved it with two simple methods.Follow the explanation.My existing style declaration:My Android Java code:Regards.Take a look at this.This feature is not currently supported."},
{"body": "I am trying to build an application, but it gives some error. My JDK version is given below:Here is my Error Log: happens because of a higher JDK during compile time and lower JDK during runtime.These guys gave you the reason why is failing but not how to solve it. This problem may appear even if you have a jdk which matches JVM which you are trying it into.Project -> Properties -> Java CompilerEnable project specific settings.Then select Compiler Compliance Level to 1.6 or 1.5, build and test your app.Now, it should be fine.Version 51 is Java 7, you probably use the wrong JDK. Check JAVA_HOME.I encountered the same issue, when jdk 1.7 was used to compile then jre 1.4 was used for execution. My solution was to set environment variable PATH by adding pathname C:\\glassfish3\\jdk7\\bin in front of the existing PATH setting. The updated value is \"C:\\glassfish3\\jdk7\\bin;C:\\Sun\\SDK\\bin\". After the update, the problem was gone. It means that you compiled your classes under a , but then try to run them under  of JDK.Make sure you're using the correct SDK when compiling/running and also, make sure you use source/target 1.7.Use Maven and use the  to explicitly call the actual correct version JDK javac.exe command, because Maven could be running any version; this also catches !  This later part could have easily been fixed in Java 1.5+ by adding versioning attributes to new classes, methods, and properties, or separate compiler versioning data, so is a quite stupid oversight by Sun and Oracle."},
{"body": "According to the JLS, an  array should be filled by zeros just after initialization. However, I am faced with a situation where it is not. Such a behavior occurs first in JDK 7u4 and also occurs in all later updates (I use 64-bit implementation). The following code throws exception:The exception occurs after the JVM performs compilation of the code block and does not arise with  flag. Additionally, the  statement (as all other statements in this code) is necessary, and the exception does not occurs if it is absent. It is clear that this possible bug is bounded with some JVM optimization. Any ideas for the reason of such a behavior?\nI see this behavior on HotSpot 64-bit server VM, Java version from 1.7.0_04 to 1.7.0_10 on Gentoo Linux, Debian Linux (both kernel 3.0 version) and MacOS Lion. This error can always be reproduced with the code above. I did not test this problem with a 32-bit JDK or on Windows. I already sent a bug report to the Oracle (bug id 7196857) and it will appear in public Oracle bug database in few days.\nOracle published this bug at their public bug database:  Here we are faced with a bug in the JIT-compiler. Compiler determines that the allocated array is filled after allocation in , but the check for uses between the allocation and the fill is faulty. So, compiler performs an illegal optimization - it skips zeroing of allocated array.This bug is placed in Oracle bug tracker (). Unfortunately, I did not wait for any clarifications from Oracle about the following points. As I see, this bug is OS-specific: it absolutely reproducible on 64-bit Linux and Mac, but, as I see from comments, it reproduces not regularly on Windows (for similar versions of JDK). Additionally it would be nice to know when this bug will be fixed.There is only advice at the moment: do not use JDK1.7.0_04 or later if you depend on JLS for newly declared arrays.In the new  of the JDK 7u10 (early access) released at October 04, 2012, this bug was fixed at least for Linux OS (I did not test for other). Thanks to @Makoto, who found that this bug is no longer available for public access in Oracle bug database. Unfortunately, I do not know for the reasons Oracle removed it from public access, but it is available in Google . Also, this bug has caught the attention of Redhat: the CVE identifiers   () and  () were assigned to this flaw.I made some change in your code.\nIt's not a problem of Integer overflow. See the code, it throws an exception at runtime "},
{"body": "I declare an enum as : And then, iterate enum as shown below :I checked the Java API but can't find the values() method? I'm curious as to where this method comes from? API link : \nYou can't see this method in javadoc because it's added by the compiler.Documented in three places : The  function simply list all values of the enumeration.The method is implicitly defined (i.e. generated by the compiler).From the :Run this you will see These are all public methods that \"sex\" class has. They are not in the source code, javac.exe added themNotes: "},
{"body": " API provides a class called as , which would basically serialize the control in order to access the critical resource. It gives method such as  and .  We can do similar things if we can use  keyword and using  and  methods.  I am wondering which one of these is better in practice and why?If you're simply locking an object, I'd prefer to use Example:You have to explicitly do  everywhere.Whereas with synchronized, it's super clear and impossible to get wrong:That said, s may be more useful for more complicated things where you can't acquire and release in such a clean manner.  I would honestly prefer to avoid using bare s in the first place, and just go with a more sophisticated concurrency control such as a  or a , if they meet your needs.I've never had a reason to use  or  but there may be some good ones.I've found that  and  (and other new  classes) are just more tools for the toolbox. I could do most everything I needed with my old claw hammer (the  keyword), but it was awkward to use in some situations. Several of those awkward situations became much simpler once I added more tools to my toolbox: a rubber mallet, a ball-peen hammer, a prybar, and some nail punches. , my old claw hammer still sees its share of use.I don't think one is really \"better\" than the other, but rather each is a better fit for different problems.  In a nutshell, the simple model and scope-oriented nature of  helps protect me from bugs in my code, but those same advantages are sometimes hindrances in more complex scenarios. Its these more complex scenarios that the concurrent package was created to help address. But using this higher level constructs requires more explicit and careful management in the code.===I think the  does a good job of describing the distinction between  and  (the emphasis is mine):You can achieve everything the utilities in   do with the low-level primitives like , , or  / However, concurrency is tricky, and most people get at least some parts of it wrong, making their code either incorrect or inefficient (or both).The concurrent API provides a higher-level approach, which is easier (and as such safer) to use. In a nutshell, you should not need to use  directly anymore. The   class itself is on the lower-level side of this toolbox, you may not even need to use that directly either (you can use  and  and stuff, etc, most of the time).There are 4 main factors into why you would want to use  or .Note: Synchronized locking is what I mean when I say intrinsic locking. Brian Goetz's \"Java Concurrency In Practice\" book, section 13.3:\n\"...Like the default ReentrantLock, intrinsic locking offers no deterministic fairness guarantees, but the\nstatistical fairness guarantees of most locking implementations are good enough for almost all situations...\"The main difference is fairness, in other words are requests handled FIFO or can there be barging?  Method level synchronization ensures fair or FIFO allocation of the lock.  Using ordoes not assure fairness.If you have lots of contention for the lock you can easily encounter barging where newer requests get the lock and older requests get stuck.  I've seen cases where 200 threads arrive in short order for a lock and the 2nd one to arrive got processed last.  This is ok for some applications but for others its deadly.See Brian Goetz's \"Java Concurrency In Practice\" book, section 13.3 for a full discussion of this topic.I would like to add some more things on top of   answer. support various methods for finer grained lock control, which are more expressive than implicit monitors ( locks)Advantages of  from documentation : In simple terms as per my understanding,  allows an object to re-enter from one critical section to other critical section . Since you already have lock to enter one critical section, you can other critical section on same object by using current lock.  key features as per this You can use   to further acquire control on granular locking on read and write operations.Apart from these three ReentrantLocks, java 8 provides one more LockYou can use these stamps to either release a lock or to check if the lock is still valid. Additionally stamped locks support another lock mode called optimistic locking.Have a look at this  on usage of different type of  and  locks.Lock makes programmers life easier. Here are few situations that can be achieved easier with lock.While, the lock, and conditions are build on the synchronized. So certainly you can achiever the same goal with that. However, that might make your life difficult and can deviate you from solving the actual problem. "},
{"body": "I write a little command-line-application in Java. This application should work with a mix of parameters and commands, similar to .I'm a fan of .You can set it to understand commands, flags (with short and long names), whether or not certain commands/switches are required, or if they have default values. It even has functionality to print out a useful  type  message.The  page has some good examples of how it can be used. I prefer  to Commons CLI. (And I\u2019ve used both.)With , you don\u2019t need to call any functions. Everything\u2019s done for you!  (Parameters are set to object fields via reflection.)Here's a relatively up to date (As of Oct 2013) list of libraries that answer your question.If you're looking for a recommendation, I recommend JOpt Simple or JewelCli.JewelCLI is a .  It uses Proxied Interfaces Configured with Annotations to dynamically build a type-safe API for your command-line parameters.An example parameter interface :An example usage of the parameter interface :Save copies of the files above to a single directory and download the  to that directory as well.Compile and run the example in Bash on Linux/Mac OS X/etc.:Compile and run the example in the Windows Command Prompt:Running the example should yield the following output:For completeness sake let's add JCommander and an example usageIt's also worth looking at . It 'attempts to honor the command line option syntaxes of POSIX getopt() and GNU getopt_long().' \nIt seems to have some community traction, notably being the command line parsing lib of choice for the  (and Minecraft!). is annotation based, allows complex rules for combining arguments (sequences,nesting,arguments,types,...) and is reasonably well documented.To use it, add to your pom, and declare the available options as follows:and then to actually parse the command line, donote that it does not (yet) contain an auto generated help text. This was prototyped, but aborted. It is easy to generate a basic help text for simple cases, but for more complex configurations (a.e. the available options for an application like \"find\" or \"gcc\"), the result will not be pretty, and you will likely rather want to control the layout yourself.JSAP looks pretty good to me.I'm using airlift for a project I'm working on, seems to work quite nicely:Simple Maven dependency that you need to add:And after that it's annotation based and has a pretty neat way of displaying help text as well.Can see an example here if it's helpful:There is also a java getopt "},
{"body": "What is a JavaBean and why do I need it? Since I can create all apps with the class and interface structure? Why do I need beans? And can you give me some examples where beans are essential instead of classes and interfaces?Please explain the essentiality of a bean in the below context:They often just represents real world data. Here's a simple example of a Javabean:Implementing  is not per se mandatory, but very useful if you'd like to be able to persist or transfer Javabeans outside Java's memory, e.g. in harddisk or over network. In for example a DAO class you can use it to create a list of users wherein you  the data of the  table in the database:In for example a Servlet class you can use it to  data from the database to the UI:In for example a JSP page you can  it by , which follows the Javabean conventions, to display the data:Does it make sense? You see, it's kind of a  which you can use everywhere to ,  and  data. are everywhere, they're a convention and just about every single slightly larger library out there uses those conventions to automate things. Just a few reasons why JavaBeans should be used:Also there's of course  which are a whole another matter and shouldn't be mixed with plain JavaBeans. I just wanted to mention EJB:s because the names are similar and it's easy to get those two confused.If you consider \"normal\" JavaBeans in web app context, they make more sense than wearing shoes in your legs. Since the Servlet specification requires for sessions to be serializable, it means you should store your data in session as something that's serializable - why not make it a bean then! Just throw your SomeBusinessDataBean into the session and you're good to go, laughably easy, specification-compliant and convenient.Also transferring that data around the application is easy too since JavaBeans help you to decouple parts of your application completely. Think JavaBeans as a letter and various subsystems of the application as departments within a very large corporation: Dept.A mails a bunch of data to Dept.B, Dept.B doesn't know -- where the data came from just as it should be and can just open the letter, read stuff from it and do its thing based on that data.Actually what's above applies to standalone apps too, the only difference is that you can mess up with the UI a bit more since standalone applications have stateful UI:s while web applications have statelss UI:s which in some cases only simulate stateful UI:s. Because of this difference, it's easier to make a mess with standalone application but that's worth a whole another topic and isn't directly related to JavaBeans at all.A bean is nothing much, really. For a class to be a \"bean\", all it requires is:To that, you can add getters and setters for properties of the class that conform to a specific naming convention if you want the fields to be discoverable in certain circumstances (e.g. making that class some object you can drag and drop from a visual editor in your IDE, for example).You can find more directly from Sun .A Java Bean is a software component that has been designed to be reusable in a variety of different environments. There is no restriction on the capability of a Bean. It may perform a simple function, such as checking the spelling of a document, or a complex function, such as forecasting the performance of a stock portfolio. A Bean may be visible to an end user. One example of this is a button on a graphical user interface. A Bean may also be invisible to a user. Software to decode a stream of multimedia information in real time is an example of this type of building block. Finally, a Bean may be designed to work autonomously on a user's workstation or to work in cooperation with a set of other distributed components. Software to generate a pie chart from a set of data points is an example of a Bean that can execute locally. However, a Bean that provides real-time price information from a stock or commodities exchange would need to work in cooperation with other distributed software to obtain its data.We will see shortly what specific changes a software developer must make to a class so that it is usable as a Java Bean. However, one of the goals of the Java designers was to make it easy to use this technology. Therefore, the code changes are minimal.A software component architecture provides standard mechanisms to deal with software building blocks. The following list enumerates some of the specific benefits that Java technology provides for a component developer:This is a real Bean named MyBean that has state (the variable theValue) that will automatically be saved and restored by the JavaBeans persistence mechanism, and it has a property named MyValue that is usable by a visual programming environment. This Bean doesn't have any visual representation, but that isn't a requirement for a JavaBean component. "},
{"body": "What is this \"Execute Around\" idiom (or similar) I've been hearing about? \nWhy might I use it, and why might I not want to use it?Basically it's the pattern where you write a method to do things which are always required, e.g. resource allocation and clean-up, and make the caller pass in \"what we want to do with the resource\". For example:The calling code doesn't need to worry about the open/clean-up side - it will be taken care of by .This was frankly painful in Java because closures were so wordy, starting with Java 8 lambda expressions can be implemented like in many other languages (e.g. C# lambda expressions, or Groovy), and this special case is handled since Java 7 with  and  streams.Although \"allocate and clean-up\" is the typical example given, there are plenty of other possible examples - transaction handling, logging, executing some code with more privileges etc. It's basically a bit like the  but without inheritance.The Execute Around idiom is used when you find yourself having to do something like this:In order to avoid repeating all of this redundant code that is always executed \"around\" your actual tasks, you would create a class that takes care of it automatically:This idiom moves all of the complicated redundant code into one place, and leaves your main program much more readable (and maintainable!)Take a look at  for a C# example, and  for a C++ example.See also , which surveys this construct across many programming languages and offers some interesting research\u2019y ideas.  Concerning the specific question of why one might use it, the above paper offers some concrete examples:And later:The paper does not explore why  to use this idiom, but it does describe why the idiom is easy to get wrong without language-level help:I see you have a Java tag here so I'll use Java as an example even though the pattern isn't platform-specific.The idea is that sometimes you have code that always involves the same boilerplate before you run the code and after you run the code.  A good example is JDBC.  You always grab a connection and create a statement (or prepared statement) before running the actual query and processing the result set, and then you always do the same boilerplate cleanup at the end--closing the statement and connection.The idea with execute-around is that it's better if you can factor out the boilerplate code. That saves you some typing, but the reason is deeper. It's the don't-repeat-yourself (DRY) principle here--you isolate the code to one location so if there's a bug or you need to change it, or you just want to understand it, it's all in one place.The thing that's a little tricky with this kind of factoring-out though is that you have references that both the \"before\" and \"after\" parts need to see. In the JDBC example this would include the Connection and (Prepared)Statement.  So to handle that you essentially \"wrap\" your target code with the boilerplate code.You may be familiar with some common cases in Java. One is servlet filters. Another is AOP around advice. A third is the various xxxTemplate classes in Spring.  In each case you have some wrapper object into which your \"interesting\" code (say the JDBC query and result set processing) is injected. The wrapper object does the \"before\" part, invokes the interesting code and then does the \"after\" part.An  is where you pass arbitrary code to a method, which may perform setup and/or teardown code and execute your code in between.Java isn't the language I'd choose to do this in.  It's more stylish to pass a closure (or lambda expression) as the argument.  Though objects are arguably .It seems to me that the Execute Around Method is sort of like  (Dependency Injection) that you can vary ad hoc, every time you call the method.But it could also be interpreted as an example of Control Coupling (telling a method what to do by its argument, literally in this case).This reminds me of the .  Notice that the link I pointed to includes Java code for the pattern.Obviously one could perform \"Execute Around\" by making initialization and cleanup code and just passing in a strategy, which will then always be wrapped in initialization and cleanup code.As with any technique used to reduce code repetition, you should not use it until you have at least 2 cases where you need it, perhaps even 3 (a la the YAGNI principle).  Keep in mind that the removing code repetition reduces maintenance (fewer copies of code means less time spent copying fixes across each copy), but also increases maintenance (more total code).  Thus, the cost of this trick is that you are adding more code.This type of technique is useful for more than just initialization and cleanup.  It's also good for when you want to make it easier to call your functions (e.g. you could use it in a wizard so that the \"next\" and \"previous\" buttons don't need giant case statements to decide what to do to go to the next/previous page.I'll try to explain, as I would to a four year old:Santa's coming to town. His elves code whatever they want behind his back, and unless they change things get a little repetitive:Or this:....ad nauseam a million times with a million different presents: notice that the only thing different is step 2. If step two is the only thing that is different, then why is Santa duplicating the code, i.e. why is he duplicating steps 1 and 3 one million times? A million presents means that he is needlessly repeating steps 1 and 3 a million times. Execute around helps to solve that problem. and helps eliminate code. Steps 1 and 3 are basically constant, allowing for step 2 to be the only part that changes.If you still don't get it, here is another example: think of a sandwhich: the bread on the outside is always the same, but what's on the inside changes depending on the type of sandwhich you choose (.e.g ham, cheese, jam, peanut butter etc). Bread is always on the outside and you don't need to repeat that a billion times for every type of sandwhich you are creating.Now if you read the above explanations, perhaps you will find it easier to understand. I hope this explanation helped you.If you want groovy idioms, here it is:"},
{"body": "I want to invoke the  method which is static. I got the object of type , but I am not able to create an instance of that class and also not able to invoke the  method .In case the method is private use  instead of . And call  on the method object.Fromthe Javadoc of Method.invoke():What happens when you "},
{"body": "I have this piece of code, which is not working:The sum variable is always 0. What am I doing wrong? is immutable.  The javadocs stat that  \"[r]eturns a BigInteger whose value is (this + val).\" Therefore, you can't change , you need to reassign the result of the  method to .The  class is immutable, hence you can't change its state. So calling \"add\" creates a new , rather than modifying the current.Other replies have nailed it; BigInteger is immutable.  Here's the minor change to make that code work. is an  class so we can not assign new object in the location of already assigned object. But you can create new object to assign new value like:BigInteger is an immutable class. So whenever you do any arithmetic, you have to reassign the output to a variable. Yes it's Immutable    so the method add() of BigInteger class does not add new BigIntger value to its own value ,but  without changing the current BigInteger and   is an immutable class. \nYou need to explicitly assign value of your output to sum like this:Actually you can use,for creating object for BigInteger class.But the problem here is,you cannot give a variable in the double quotes.So we have to use the  method and we have to store the answer in that sum again.So we will write,Since you are summing up some int values together, there is no need to use BigInteger.  is enough for that.  is 32 bits, while  is 64 bits, that can contain the sum of all int values."},
{"body": "What's the difference between and in Java? When should I use them?The first form is called .  You use this when you're writing formal APIs for your code, which are generated by the  tool.  For an example,  uses Javadoc and was generated by that tool.Some common elements you'd see in Javadoc include:As an example, here's Javadoc for the  method of :The second form is a block (multi-line) comment.  You use this if you want to have multiple lines in a comment.I will say that you'd only want to use the latter form ; that is, you don't want to overburden your code with block comments that don't describe what behaviors the method/complex function is supposed to have.Since Javadoc is the more descriptive of the two, and you can generate actual documentation as a result of using it, using Javadoc would be more preferable to simple block comments.For the Java , there is  between the two. Java has two types of comments: traditional comments () and end-of-line comments (). See the . So, for the Java programming language, both  and  are instances of traditional comments, and they are both treated exactly the same by the Java compiler, i.e., they are ignored (or more correctly: they are treated as white space).However, as a Java programmer, you do not only use a Java compiler. You use a an entire tool chain, which includes e.g. the compiler, an IDE, a build system, etc. And some of these tools interpret things differently than the Java compiler. In particular,  comments are interpreted by the Javadoc tool, which is included in the Java  and generates documentation. The Javadoc tool will scan the Java source file and interpret the parts between  as documentation.This is similar to tags like  and : if you include a comment like  or , most IDEs will highlight such comments so that you don't forget about them. But for Java, they are just comments.  The first is Javadoc comments. They can be processed by the  tool to generate the API documentation for your classes. The second is a normal block comment.Reading the section  well explain all you need to know about comments in Java.The first oneis used to declare .For more information on  refer to the .The second one, as explained clearly in JLS, will ignore all the text between  and  thus is used to create multiline comments.Thus, the following text is a single complete comment:I don't think the existing answers adequately addressed this part of the question:If you're writing an API that will be published or reused within your organization, you should write comprehensive Javadoc comments for every  class, method, and field, as well as  methods and fields of non- classes.  Javadoc should cover everything that  be conveyed by the method signature, such as preconditions, postconditions, valid arguments, runtime exceptions, internal calls, etc.If you're writing an internal API (one that's used by different parts of the same program), Javadoc is arguably less important.  But for the benefit of maintenance programmers, you should still write Javadoc for any method or field where the correct usage or meaning is not immediately obvious.The \"killer feature\" of Javadoc is that it's closely integrated with Eclipse and other IDEs.  A developer only needs to hover their mouse pointer over an identifier to learn everything they need to know about it.  Constantly referring to the documentation becomes second nature for experienced Java developers, which improves the quality of their own code.  If your API isn't documented with Javadoc, experienced developers will not want to use it.First one is for Javadoc you define on the top of classes, interfaces, methods etc. You can use Javadoc as the name suggest to document your code on what the class does or what method does etc and generate report on it.Second one is code block comment.\nSay for example you have some code block which you do not want compiler to interpret then you use code block comment.another one is //\nthis you use on statement level to specify what the proceeding lines of codes are supposed to do.There are some other also like //TODO, this will mark that you want to do something later on that place//FIXME you can use when you have some temporary solution but you want to visit later and make it better.Hope this helpsComments in the following listing of Java Code are the greyed out characters:The Java language supports three kinds of comments:The compiler ignores everything from  to .This indicates a documentation comment (doc comment, for short). The compiler ignores this kind of comment, just like it ignores comments that use  and . The JDK javadoc tool uses doc comments when preparing automatically generated documentation.The compiler ignores everything from  to the end of the line.Now regarding when you should be using them:Use  when you want to comment a single line of code.Use  when you want to comment multiple lines of code.Use   when you would want to add some info about the program that can be used for automatic generation of program documentation. Java supports two types of comments:Some tool such as  use a special multiline comment for their purpose. For example  is a documentation comment used by javadoc when preparing the automatically generated documentation, but for Java it's a simple multiline comment."},
{"body": "In my app I want to save a copy of a certain file with a different name (which I get from user)Do I really need to open the contents of the file and write it to another file?What is the best way to do so?To copy a file and save it to your destination path you can use the method below.Alternatively, you can use  to copy a file. It  be faster than the byte copy method when copying a large file. These worked nice for meIt might be too late for an answer but the most convenient way is using 'se.g. this is what I did``Here is a solution that actually closes the input/output streams if an error occurs while copying. This solution utilizes apache Commons IO IOUtils methods for both copying and handling the closing of streams.If you have root permission you can copy using below code:OR"},
{"body": "I have a vertical LinearLayout where one of the items is an  loaded using Picasso. I need to rise the image's width to the full device width, and to display the center part of the image cropped by a fixed height (150dp). I currently have the following code:Which values should I put into  and  (=150dp)?You are looking for:What these mean:Image Resizing with resize(x, y)\nGenerally it's optimal if your server or API deliver the image in the exact dimensions you need, which are a perfect trade-off between bandwidth, memory consumption and image quality.Unfortunately, it's not always in your control to request images in the perfect dimensions. If the images are in a weird size you can use the resize(horizontalSize, verticalSize) call to change the dimensions of your image into a more suitable size. This will resize the image before displaying it in the ImageView.Use of scaleDown()\nWhen using the resize() option Picasso will also upscale your image. Since making a small image bigger without improving the quality of the image can be wasted computing time, call scaleDown(true) to only apply the resize() when the original image has larger dimensions than the target size.Avoiding Stretched Images with Scaling\nNow, as with any image manipulation, resizing images can really distort the aspect ratio and uglify the image display. In most of your use cases, you want to prevent this from happening. Picasso gives you two mitigation choices here, either call centerCrop() or centerInside().CenterCrop() is a cropping technique that scales the image so that it fills the requested bounds of the ImageView and then crops the extra. The ImageView will be filled completely, but the entire image might not be displayed.CenterInside() is a cropping technique that scales the image so that both dimensions are equal to or less than the requested bounds of the ImageView. The image will be displayed completely, but might not fill the entire ImageView.Last, but not least: Picasso's fit()\nThe discussed options should cover your needs for functionality regarding image resizing and scaling. There is one last helper functionality of Picasso, which can be very useful: fit().fit() is measuring the dimensions of the target ImageView and internally uses resize() to reduce the image size to the dimensions of the ImageView. There are two things to know about fit(). First, calling fit() can delay the image request since Picasso will need to wait until the size of the ImageView can be measured. Second, you only can use fit() with an ImageView as the target (we'll look at other targets later).The advantage is that the image is at the lowest possible resolution, without affecting its quality. A lower resolution means less data to be hold in the cache. This can significantly reduce the impact of images in the memory footprint of your app. In summary, if you prefer a lower memory impact over a little faster loading times, fit() is a great tool."},
{"body": "Trying to remove all letters and characters that are not 0-9 and a period.  Im using Character.isDigit() but it also removes decimal, how can I also keep the decimal.Try this code:Now  will contain .I would use a regex.printsYou might like to keep  as well for negative numbers.With guava:see result: 0097-557890-999if you also do not need \"-\" in String you can do like this:result: 0097557890999Adding an extra character check for dot  will solve the requirement:A way to replace it with a java 8 stream:"},
{"body": "I was trying to look how my app looks in material design and I would like to use the new cards lib.\nMy Problem is, that it's giving me this error within my gradle file and I need to fix that.I downloaded and installed it. in Terminal is showing me that 1.7 is installed:wellis giving me: doesn't have a . I found the  here:And set the path to the \"SDK location\" Preferences in Android Studio under \"JDK location\". But it's not working -- it seems that it still can't find JDK 7.I'm using Mac OSX 10.9.3 and Android Studio (Beta) 0.8.1.Setting the directory to:\n\nin JDK settings solved my issue. I had the same problem getting started up. Hope this helps!@megapoff answer is correct . But I face little difficulty to fix it . So here is the detail solution step-by-step  The other answers are very correct but I want to be more concise and clear. To prevent others from visiting this page multiple times unnecessarily.Important* Old Path is /System/Library/Java... and New Path is /Library/Java... (Not under the System directory)Replace old path: /System/Library/Java/JavaVirtualMachines/jdk1.6.0_0.jdk/Contents/HomeSet your new path: /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/HomeI haven't moved over to Android Studio, yet. I've used it for a few tests and really like it. Just haven't been able to switch over yet. I've had this sort of issue in Eclipse and that's obviously a different solution, but looking through one of my test projects, this appears to be how you go about it:Open your project and go to File->Settings.Under the Project Settings, expand Compiler and go to the Java Compiler option. You want to use javac and set the project bytecode version to 1.7.Hopefully that'll do it.For jdk-7u79-macosx-x64.dmg just Setting the directory to\n/Library/Java/JavaVirtualMachines/jdk1.7.0_60.jdk/Contents/HomeNot in \n/System/Library/Java/JavaVirtualMachines/jdk1.7.0_60.jdk/Contents/HomeBoth are differentInstead of looking for the folder inside :\nWe have to look into :"},
{"body": "My keystore is corrupt, therefore the Android Market is requiring me to rename the app and resubmit it. However, whenever I go to edit the package names in Manifest and throughout the files, it gives me tons of errors.What's the proper way to change the application name?If you're using Eclipse, you could try  from Android's developer site. They're specifically for the GestureBuilder sample but should apply to any application as far as I can tell:Also, be sure you remembered to rename the package itself along with the references to it in the files. In Eclipse you can see the name of the package in the file explorer window/tree view on the left hand side. In my experience, Eclipse can sometimes be a little finnicky and unreliable with this (leaving behind stray references to the old package name, for example).There is a way to change the package name easily in Eclipse. Right click on your project, scroll down to Android Tools, and then click on Rename Application Package.Here's how you could do this in Eclipse:\nsuper easy way\nright click on your project...\nIn , which, quite honestly, you should be using, change the package name by  on the package name in the It then gives the option of renaming the directory or the package. Select the package. The directory should follow suit. Type in your new package name, and click Refactor. It will change all the imports and remove redundant imports for you. You can even have it fix it for you in comments and strings, etc., change the package name accordingly in your AndroidManifest.xml towards the top. Otherwise you will get errors everywhere complaining about R.whatever.First create a new package with the desired namejava folder -> new -> package.`Then, select and drag all your classes to the new package. AndroidStudio will re-factor the package name everywhere.After that: in your app's  add/edit applicationId with the new one. i.e. ( in my case):  Original post and more comments Without Eclipse:The above 6 steps are what I did to get my package name changed and get a successful* build. There may be a better way to handle steps 5 and 6 via dex commands to update paths, or perhaps by editing classes.dex.d in the root directory of the project. I'm not familiar with dex or if it's ok to delete/edit classes.dex.d so I went with the method of deleting .class files that I know will be regenerated in the build. I then checked classes.dex.d to see what still needed to be updated.*No errors or warnings left in my build EXCEPT dex and apkbuilder both state \"Found Deleted Target File\" with no specifics about what that file is. Not sure if this shows up in every build, if it was there before I messed with my package name, or if it's a result of my deletions and I'm missing a step.Follow these steps:-Changing package name is a pain in the ass. It looks like different methods work for different people. My solution is quick and error free. Looks like no cleaning or resetting eclipse is needed.:P.S. If you will not follow this order you can end up changing all the java files one by one with new imports and a bunch of compile time errors, so the order is very important.Bernstein has the method, use the Eclipse tool, \"Rename Application Package\", you may have to do some clean-up even after the fact. \nAlso, Eclipse sometimes loses track of things when you make changes to a project. You may have to use the \"Clean Project\" tool (under the \"Project\" menu.) If that doesn't work, you may have to close and restart Eclipse. Voo-doo solutions, but Eclipse can be that way. I found the easiest solution was to use  to replace \"com.package.name\" with \"com.newpackage.name\", then rename the directories properly. Super easy, super fast.There is also another solution for users without Eclipse, simply change the package attribute in  <manifest> tag in AndroidManifest.xml, by replacing the the old package name used with a new one.  You have to adjust the all the related import statements and related folders manually in your project than, too.Alternative: I just lost few hours trying all solutions. I was sure, problem is in my code - apk starting but some errors when working with different classes and activities.Only way working with my project:For me it works, only solution.In Android Studio 1.2.2\nSay if you want to change  to \nYou can follow the steps in each of the directories as displayed in the below screen shot. It will give you the preview option so that you can preview before making any changes. Go to  and give your new name. You have to do it for each of the folders, say for com, example and myapp. It will automatically update the imports so that you don't have to worry about it.\nAlso update the file  which is not updated automatically.After that it will ask for  do it. Then everything will be fine. I'm able to upload my APK to google store after this. Make sure you have signed your app to upload it to the store.So, using IntelliJ with Android (Studio) plugin was: I went to  on top and changed package name by right-clicking -> Refactor -> rename.\nOur then package name had four parts , the new one only .\nSo I renamed the first three. Then I went to the directory of generated sources (), right-clicked  class and Refactor->Move[d] it to one package higher. Same with  in .By using Refactor->Move, IntelliJ updates all references to  and . Finally I updated all applicationId[s] I found in gradle.build I found. I hit Clean Project, Make and Rebuild Project. Deleted the app from my phone and hit \"Play\". It all worked out so refactoring was easy and quite fast."},
{"body": "For new applications written in Java 7, is there any reason to use a  object any more or can we consider it deprecated? I believe a  can do everything a  can do and more.  will most likely  be deprecated / unsupported. That said,  is part of the more modern  lib, and does everything  can, but generally in a better way, and then some. For new projects, use .And if you ever need a  object for legacy, just call Not unless and until it is so marked in the Javadoc.Check this article about more info - Basically file.Path will be the way to go from now on but as is widely known Java people tend to keep back-compatibility so I guess that's why they have left it. Yes, but many existing APIs, including Java7's own standard APIs, still work only with  type.Am I missing something? Problem for me is that Path doesn't give you attributes as easily as File. For example, you want to use Java 8 streams to get the last modified file in a directory, where it's tempting to do the following:To do this with Path would require a lot of messy stuff retrieving .This is a bit like saying: \"should Napoleon invade Russia,  are these Brussels sprouts really tasty?\"As to the second part of the question, you can indeed consider it deprecated. As of March 2017, it isn't deprecated.  But there's nothing to stop you  it so.  Whether that will procure you any advantage in this life or the next is impossible to say."},
{"body": "I'm trying to hold a list of items in a collection with a key of my choice. In Java, I would simply use Map as follows:Is there an equivalent way of doing this in C#?\n doesn't uses hash and I cannot define a custom type key\n isn't a generic class\n doesn't have a  methodYou can index Dictionary, you didn't need 'get'.An efficient way to test/get values is  (thanx to  Earwicker):With this method you can fast and exception-less get values (if present).Resources:Dictionary<,> is the equivalent.  While it doesn't have a Get(...) method, it does have an indexed property called Item which you can access in C# directly using index notation:If you want to use a custom key type then you should consider implementing IEquatable<> and overriding Equals(object) and GetHashCode() unless the default (reference or struct) equality is sufficient for determining equality of keys.  You should also make your key type immutable to prevent weird things happening if a key is mutated after it has been inserted into a dictionary (e.g. because the mutation caused its hash code to change)."},
{"body": "My question is very basic, but I didn't find an answer on a Google search.In , what is the maximum size a  object may have, referring to the  method call?I know that  return the size of a  as a ;Considering the  class'  method returns an , the maximum length that would be returned by the method would be , which is  (or approximately 2 billion.)In terms of lengths and indexing of arrays, (such as , which is probably the way the internal data representation is implemented for s),  of  says the following:Furthermore, the indexing must be by  values, as mentioned in :Therefore, it appears that the limit is indeed , as that is the maximum value for a nonnegative  value.However, there probably are going to be other limitations, such as the maximum allocatable size for an array.Since arrays must be indexed with integers, the maximum length of an array is  (2-1, or 2\u00a0147\u00a0483\u00a0647). This is assuming you have enough memory to hold an array of that size, of course. and  say that a  object is represented by  of length information and the  representation of every character in the string. This concludes that the length of String is limited by the number of bytes of the modified UTF-8 representation of the string when used with  and .In addition,  found in the Java virtual machine specification defines the structure as follows.You can find that the size of 'length' is .That the return type of a certain method (e.g. ) is  does not always mean that its allowed maximum value is . Instead, in most cases,  is chosen just for performance reasons. The Java language specification says that integers whose size is smaller than that of  are converted to  before calculation (if my memory serves me correctly) and it is one reason to choose  when there is no special reason.The maximum length at compilation time is at most 65536. Note again that the length is the number of bytes of the  representation, not the number of characters in a  object. objects may be able to have much more characters at runtime. However, if you want to use  objects with  and  interfaces, it is better to avoid using too long  objects. I found this limitation when I implemented Objective-C equivalents of  and .apparently it's bound to an int, which is 0x7FFFFFFF (2147483647).The Return type of the length() method of the String class is .Refer So the maximum value of int is .String is considered as char array internally,So indexing is done within the maximum range.\nThis means we cannot index the 2147483648th member.So the maximum length of String in java is 2147483647.Primitive data type int is 4 bytes(32 bits) in java.As 1 bit (MSB) is used as a ,The range is constrained within  (-2147483648 to 2147483647).\nWe cannot use negative values for indexing.So obviously the range we can use is from 0 to 2147483647.I have a 2010 iMac with 8GB of RAM, running Eclipse Neon.2 Release (4.6.2) with Java 1.8.0_25. With the VM argument -Xmx6g, I ran the following code:This prints:So, it seems that the max array size is ~1,207,959,549. Then I realized that we don't actually care if Java runs out of memory: we're just looking for the maximum array size (which seems to be a constant defined somewhere). So:Which prints:So, it seems the max is Integer.MAX_VALUE - 2, or (2^31) - 3P.S. I'm not sure why my  maxed out at  while my  maxed out at (2^31)-3. It seems that  doubles the size of its internal  to grow it, so that probably causes the issue."},
{"body": "i am executing simple Dependency Injection program of spring & getting this exception. \nI have already included common-logging1.1.1.jar and spring.jar file. Could you please help to out?I have also faced the same issues, to fix, download the jar files from the below urland copy to your lib folder, will resolve your issue.If you're using maven for managing dependencies, add the following line in your pom.xml:You just download  and then copy this file in to libsfinally, it works.I had the same problem, and solved it by just adding the  to the class path.commons-logging-1.1.1.jar or jcl-over-slf4j-1.7.6.jar alIf you are using maven, use the below code.Setting the scope to compile did it for meAre you sure you spelled the name of the JAR file exactly right? I think it should probably be  (note the extra  in the name). Also check if the directory name is correct. always means that a class cannot be found, so most likely your class path is not correct.Issue solved by adding commons-logging.jarImp files are ,Two options (at least):Note: linking the jar can lead to problems with the server and maybe the reason why it's added to the build path but not solving the server startup problem.So don't point the jar to an external folder.OR...If you're using a tc server instance, then you need to add the jar as an external jar to the server instance run configurations.go to run as, run configurations..., {your tc server instance}, and then the Class Path tab.Then add the commons-logging jar.Adding commons-logging.jar or commons-logging-1.1.jar will solve this...Try doing a complete clean of the target/deployment directory for the app to get rid of any stale library jars. Make a fresh build and check that commons-logging.jar is actually being placed in the correct lib folder. It might not be included when you are building the library for the application. use this url to download jar files and include them in your class path, issue will be solvedI got the same trouble than you.\nFinally I checked the version of apache possessing the class. \nI found that the version 1.0.4 has the class.Try to use the version 1.0.4 instead of 1.1.X or 1.2.XMy dependencies : My Java Code My Result : Double check also that your maven dependencies are well imported.I generally assign the classpath to a variable and then verify it.  I've written a small ruby script which I include in a my startup scripts which .  Validating the classpath before the JVM starts has saved me lots of time troubleshooting these types of problems.Hey I was following the tutorial on tutorialpoint.com. Add after you complete  You must  libraries to the project from the files downloaded at this step. For me the file name was \"\".  If you're running this on Android then note that apparently  package is not complete on Android. To attempt to fix it on Android try the following:, I apologise as I realise this is not exactly answering the question, though this SO page comes up a lot when searching for android-generated  errors.Just check whether the commons-logging.jar has been added to your libs and the classpath.. I had the same issue and that was because of this. \ndhammikas-try to include:into your WEB-INF/lib folder.I tried, it works.Check whether the jars are imported properly. I imported them using build path. But it didn't recognise the jar in WAR/lib folder. Later, I . It works fine now. You can refresh / clean your project.try adding this dependency\n    \n        org.apache.commons\n        commons-exec\n        1.3\n    Hello friends if your getting any not class found exception in hibernate code it is the problem of jar files.here mainly two problems\n1.I mean to say your working old version of hibernate may be 3.2 bellow.So if u try above 3.6 it will works fine2.first checkes database connection.if it database working properly their was a mistake in ur program or jar file.  please check these two prioblems if it also not working you tried to IDE . I am using netbeanside 6.9 version.here hibernate working fine.you dont get any error from class not founnd exception..I hope this one helps moreSolution is to Add  jar fileIf all else fails, as it had for me, try putting the commons-logging-x.y.z.jar in your Tomcat lib directory.  It solved the problem!  BTW, I am using Tomcat 6."},
{"body": "How can I change the current working directory from within a Java program? Everything I've been able to find about the issue claims that you simply can't do it, but I can't believe that that's really the case.I have a piece of code that opens a file using a hard-coded relative file path from the directory it's normally started in, and I just want to be able to use that code from within a different Java program without having to start it from within a particular directory. It seems like you should just be able to call , but as far as I can figure out, calling that line just silently fails and does nothing.I would understand if Java didn't allow you to do this, if it weren't for the fact that it allows you to  the current working directory, and even allows you to open files using relative file paths....There is no reliable way to do this in pure Java. Setting the  property via  or  does seem to affect subsequent creations of , but not e.g. .The  constructor can help if you build up your directory path separately from your file path, allowing easier swapping.An alternative is to set up a script to run Java from a different directory, or use JNI native code . was closed in 2008 as \"will not fix\".If you run your legacy program with , you will be able to specify its working .There  a way to do this using the system property \"user.dir\".  The key part to understand is that getAbsoluteFile() must be called (as shown below) or else relative paths will be resolved against the  \"user.dir\" value.It is possible to change the PWD, using JNA/JNI to make calls to libc. The JRuby guys have a handy java library for making POSIX calls called  Here's You can see an example of its use  (Clojure code, sorry). Look at the function chdirToRootIf I understand correctly, a Java program starts with a  of the current environment variables. Any changes via  are modifying the copy, not the original environment variables. Not that this provides a thorough reason as to why Sun chose this behavior, but perhaps it sheds a little light...As mentioned you can't change the CWD of the JVM but if you were to launch another process using Runtime.exec() you can use the overloaded method that lets you specify the working directory. This is not really for running your Java program in another directory but for many cases when one needs to launch another program like a Perl script for example, you can specify the working directory of that script while leaving the working dir of the JVM unchanged.See  javadocsSpecifically,where  is the working directory to run the subprocess inThe working directory is a operating system feature (set when the process starts). \nWhy don't you just pass your own System property () and use that in your code as the parent of your File:The smarter/easier thing to do here is to just change your code so that instead of opening the file assuming that it exists in the current working directory (I assume you are doing something like , just build the path to the file yourself.Let the user pass in the base directory, read it from a config file, fall back to  if the other properties can't be found, etc. But it's a whole lot easier to improve the logic in your program than it is to change how environment variables work.I have tried to invokeIt seems to work. But throws a  thoughshows the correct path. \nI have . I think the problem is:The solution may be: It creates a file Object as absolute one with the current directory which is known by the JVM. But that code should be existing in a used class, it needs changing of reused codes.~~~~JcHartmutThe other possible answer to this question may depend on the reason you are opening the file.  Is this a property file or a file that has some configuration related to your application?If this is the case you may consider trying to load the file through the classpath loader, this way you can load any file Java has access to.If you run your commands in a shell you can write something like \"java -cp\" and add any directories you want separated by \":\" if java doesnt find something in one directory it will go try and find them in the other directories, that is what I do.You can use after Will printUse FileSystemView "},
{"body": "So, normally  would return a type of ....but supposed it's an \n of object , how do I make  to return a type of  rather than ?Like this:It's tempting to do it like:but the internal implementation will realloc a properly sized array anyway so you are better doing it upfront.If your list is not properly typed you need to do a cast before calling toArray. Like this:It doesn't really need to return , for example:-Here's my  class:-I got the answer...this seems to be working perfectly fineSamples:"},
{"body": "In eclipse, when your cursor is placed on a method (or other things), other places the method exists are highlighted. I'd like to change the color of this highlight, but after scouring the eclipse preferences many times in all 3 places, I have yet to find it.Any of you Eclipse gurus know where to find this option?Thank you!After running around in the Preferences dialog, the following is the location at which the highlight color for \"occurrences\" can be changed:Look for  from the  list.Then, be sure that  is selected, then choose the desired color.And, a picture is worth a thousand words...For those working in Titanium Studio, the item is a little different:  It's under the \"Titanium Studio\" Themes tab.The color to change is the \"Selection\" one in the top right.1 - right click the highlight whose color you want to change2 - select \"Properties\" in the popup menu3 - choose the new color (as  suggested)This solution is easy because you dont have to search for the highlight by its name (\"Ocurrence\" or \"Write Ocurrence\" etc), just right click and the appropriate window is shown.If you're using eclipse with PHP package and want to change highlighted colour then there is slight difference to above answer."},
{"body": "Does creating an object using reflection rather than calling the class constructor result in any significant performance differences? Looking up a class via reflection is, , more expensive.Quoting :Here's a simple test I hacked up in 5 minutes on my machine, running Sun JRE 6u10:With these results:Bear in mind the lookup and the instantiation are done together, and in some cases the lookup can be refactored away, but this is just a basic example.Even if you just instantiate, you still get a performance hit:Again, YMMV.Yes, it's slower.But remember the damn #1 rule--PREMATURE OPTIMIZATION IS THE ROOT OF ALL EVIL(Well, may be tied with #1 for DRY)I swear, if someone came up to me at work and asked me this I'd be very watchful over their code for the next few months.You must never optimize until you are sure you need it, until then, just write good, readable code.Oh, and I don't mean write stupid code either.  Just be thinking about the cleanest way you can possibly do it--no copy and paste, etc.  (Still be wary of stuff like inner loops and using the collection that best fits your need--Ignoring these isn't \"unoptimized\" programming, it's \"bad\" programming)It freaks me out when I hear questions like this, but then I forget that everyone has to go through learning all the rules themselves before they really get it.  You'll get it after you've spent a man-month debugging something someone \"Optimized\".EDIT:An interesting thing happened in this thread.  Check the #1 answer, it's an example of how powerful the compiler is at optimizing things.  The test is completely invalid because the non-reflective instantiation can be completely factored out.Lesson?  Don't EVER optimize until you've written a clean, neatly coded solution and proven it to be too slow.You may find that A a = new A() is being optimised out by the JVM.\nIf you put the objects into an array, they don't perform so well. ;)\nThe following prints...This suggest the difference is about 150 ns on my machine.There is some overhead with reflection, but it's a lot smaller on modern VMs than it used to be.If you're using reflection to create every simple object in your program then something is wrong. Using it occasionally, when you have good reason, shouldn't be a problem at all.\"Significant\" is entirely dependent on context.If you're using reflection to create a single handler object based on some configuration file, and then spending the rest of your time running database queries, then it's insignificant. If you're creating large numbers of objects via reflection in a tight loop, then yes, it's significant.In general, design flexibility (where needed!) should drive your use of reflection, not performance. However, to determine whether performance is an issue, you need to profile rather than get arbitrary responses from a discussion forum.If there  is need for something faster than reflection, and it's not just a premature optimization, then bytecode generation with  or a higher level library is an option. Generating the bytecode the first time is slower than just using reflection, but once the bytecode has been generated, it is as fast as normal Java code and will be optimized by the JIT compiler.Some examples of applications which use code generation:Reflection is slow, though object allocation is not as hopeless as other aspects of reflection.  Achieving equivalent performance with reflection-based instantiation requires you to write your code so the jit can tell which class is being instantiated.  If the identity of the class can't be determined, then the allocation code can't be inlined.  Worse, escape analysis fails, and the object can't be stack-allocated.  If you're lucky, the JVM's run-time profiling may come to the rescue if this code gets hot, and may determine dynamically which class predominates and may optimize for that one.Be aware the microbenchmarks in this thread are deeply flawed, so take them with a grain of salt.  The least flawed by far is Peter Lawrey's: it does warmup runs to get the methods jitted, and it (consciously) defeats escape analysis to ensure the allocations are actually occurring.  Even that one has its problems, though: for example, the tremendous number of array stores can be expected to defeat caches and store buffers, so this will wind up being mostly a memory benchmark if your allocations are very fast.  (Kudos to Peter on getting the conclusion right though: that the difference is \"150ns\" rather than \"2.5x\".  I suspect he does this kind of thing for a living.)Yes there is a performance hit when using Reflection but a possible workaround for optimization is caching the method:will result in:Yes, it is significantly slower. We were running some code that did that, and while I don't have the metrics available at the moment, the end result was that we had to refactor that code to not use reflection. If you know what the class is, just call the constructor directly.Interestingly enough, settting setAccessible(true), which skips the security checks, has a 20% reduction in cost.Without setAccessible(true)With setAccessible(true)In the doReflection() is the overhead because of Class.forName(\"misc.A\") (that would require a class lookup, potentially scanning the class path on the filsystem), rather than the newInstance() called on the class. I am wondering what the stats would look like if the Class.forName(\"misc.A\") is done only once outside the for-loop, it doesn't really have to be done for every invocation of the loop.Yes, always will be slower create an object by reflection because the JVM cannot optimize the code on compilation time. See the Sun/Java  for more details.See this simple test:Often you can use Apache commons BeanUtils or PropertyUtils which introspection (basically they cache the meta data about the classes so they don't always need to use reflection).I think it depends on how light/heavy the target method is. if the target method is very light(e.g. getter/setter), It could be 1 ~ 3 times slower. if the target method takes about 1 millisecond or above,  then the performance will be very close. here is the test I did with Java 8 and  :The complete test code is available at GitHub:"},
{"body": "What is the maximum number of parameters that a method in Java can have and why?I am using Java 1.8 on a 64-bit Windows system.All the answers on StackOverflow about this say that the technical limit is 255 parameters without specifying why.To be precise, 255 for static and 254 for non-static ( will be the 255th in this case) methods.I thought this could be described in some sort of specification and that there is simply a statically defined maximum number of parameters allowed. But this was only valid for .\nI did some tests with  parameters, and I was only able to declare 127 parameters in that case.With  parameters, the allowed number I deduced from testing is 255 (it may be because the reference size is 4 bytes in Java?).But since I am using a 64-bit system, references size should be 8 bytes wide and so with  parameters the maximum allowed number should be 127, similar to  types.How does this limit is exactly applied? Does the limit have anything to do with the  of the method?Note: I am not really going to use these many parameters in any method, but this question is only to clarify the exact behavior.That limit is defined in the :Section  gives some additional information:Your observations were spot on, double word primitives (/) need twice the size of usual 4 bytes variables .Regarding the last part of your question related to 64bit systems, the specification defines how many ,  that part of the specification  even on a 64bit platform,  the 64bit JVM will accomodate 255 instance parameters (like your 255 ) regardless of the internal object's pointer size. of the JVM specification has the information you are looking for:Therefore it appears that whether the host-machine is 32-bit or 64-bit has no effect on the number of parameters. If you notice, the documentation speaks in terms of \"units\", where the length of one \"unit\" is a function of the word-size. If the number of parameters directly proportional to word-size, there would be portability issues; you wouldn't be able to compile the same Java program on different architectures (assuming that at least one method used the maximum-number of parameters on the architecture with the larger word-size). I found an interesting issue from a newsletter about this, "},
{"body": "What are the pros and cons of each  (BDD) framework for Java?I've found some of them , for example.Does it make sense to use a BDD framework if I already use a mocking library (e.g. )?I've just finished comparing three BDD frameworks for Java. Obviously my findings have a fairly short use-by date.I didn't have the chance to try out Cuke4Duke of JDave as I would have liked, but will probably push for JBehave at this time.\"pros and cons\" might be different things for different people. I usually have a look atAnd from some frameworks I had a look atConcerning the mocks: You definitely need a mocking framework as well. The BDD frameworks just help you in writing the specs, but some tests will need mocks or stubs, esp. when you design top down (from overview to detail).Here is an interesting link about Really, look at the one mentioned above.Short answer: yes, definitely. Actually, acceptance testing using a BDD framework and unit testing in isolation using mock objects are so different that I don't really get the question. Acceptance testing is black box testing, tests are used to verify that a business feature is working and are ideally written by business analyst. Unit tests in isolation using mocks is white box testing, tests are used to verify that a unit is working and are written by developers. Both are useful buty they have totally different purposes. In other words, using Mockito doesn't replace a BDD framework at all and the inverse is also true.I originally did my BDD with plain jUnit but I've been looking at  lately because it's almost 1:1 to what I was doing with jUnit. It also runs on top of jUnit so it already works on Eclipse and is also easy to configure to work on continuous integration systems such as Hudson. Can't really compare it with others but my experiences with JDave have been good so far.Oh and it's never a stupid idea to use mocks! They're not tied to TDD/BDD specifically, their purpose is to ease the burden of testing in general.Wow, I see the topic is hot, lot of good answers...Irony aside, I recently discovered BDD and found the concept interesting. Hey, it forces to write both tests... and specifications! As surprising as it might seem, the latter can be also missing in some projects... Or just lacking the precision that BDD forces to introduce.The  article summarizes the concept and links to some good articles (like the one written by Andrew Glover). Moreover, to the topic of this thread, it gives a rather comprehensive (I suppose) listing of BDD frameworks, a good number of them being for Java.\nIt doesn't solve the problem of choosing the framework but at least it will ease the search...Since BDD relies heavily on readability of test code, I suppose a good criterion of choice is to look at the quick tours/tutorial and see which one seems the more fitting your style.\nOther criteria could be the fact a framework leverage tools you are familiar with (unit test, mocking), usage with IDE, and so on.My team have been using  for some time. It uses plain text files to store specifications. Every step (Given, When, Then) is then executed by a certain method which can extract parameters from the step. Scenarios can be indented and well formatted which helps a lot if clients want to verify them.There are some problems, too. We have switched to Java 6. Sometimes some scenario steps are ignored during execution. It may cause a lot of trouble figuring out where's the bug.My team have used JBehave with success - we moved to it after using EasyB and found the plain text scenario files easier to deal with.I tried  (previously developed as Cuke4Duke).\nIt uses Gherkin DSL for specification, stored as plain text.It can be run as JUnit test. So the only problem to start using is to make business people or Product Manager to read/write .features in Sources.Results"},
{"body": "I've seen some interesting claims on SO re Java hashmaps and their  lookup time. Can someone explain why this is so? Unless these hashmaps are vastly different from any of the hashing algorithms I was bought up on, there must always exist a dataset that contains collisions.In which case, the lookup would be  rather than . Can someone explain whether they  O(1) and, if so, how they achieve this?A particular feature of a HashMap is that unlike, say, balanced trees, its behavior is probabilistic.  In these cases its usually most helpful to talk about complexity in terms of the probability of a worst-case event occurring would be.  For a hash map, that of course is the case of a collision with respect to how full the map happens to be.  A collision is pretty easy to estimate.  So a hash map with even a modest number of elements is pretty likely to experience at least one collision.  Big O notation allows us to do something more compelling. Observe that for any arbitrary, fixed constant k.We can use this feature to improve the performance of the hash map.  We could instead think about the probability of at most 2 collisions.This is much lower.  Since the cost of handling one extra collision is irrelevant to Big O performance, we've found a way to improve performance without actually changing the algorithm!  We can generalzie this to And now we can disregard some arbitrary number of collisions and end up with vanishingly tiny likelihood of more collisions than we are accounting for.  You could get the probability to an arbitrarily tiny level by choosing the correct k, all without altering the actual implementation of the algorithm.We talk about this by saying that the hash-map has O(1) access You seem to mix up worst-case behaviour with average-case (expected) runtime. The former is indeed O(n) for hash tables in general (i.e. not using a perfect hashing) but this is rarely relevant in practice.Any dependable hash table implementation, coupled with a half decent hash, has a retrieval performance of O(1) with a very small factor (2, in fact) in the expected case, within a very narrow margin of variance.In Java, HashMap works by using hashCode to locate a bucket.  Each bucket is a list of items residing in that bucket.  The items are scanned, using equals for comparison.  When adding items, the HashMap is resized once a certain load percentage is reached.So, sometimes it will have to compare against a few items, but generally it's much closer to O(1) than O(n).  For practical purposes, that's all you should need to know.Remember that o(1) does not mean that each lookup only examines a single item - it means that the average number of items checked remains constant w.r.t. the number of items in the container. So if it takes on average 4 comparisons to find an item in a container with 100 items, it should also take an average of 4 comparisons to find an item in a container with 10000 items, and for any other number of items (there's always a bit of variance, especially around the points at which the hash table rehashes, and when there's a very small number of items).So collisions don't prevent the container from having o(1) operations, as long as the average number of keys per bucket remains within a fixed bound.O(1+n/k) where k is the number of buckets. If implementation sets k = n/alpha then it is O(1+alpha) = O(1) since alpha is a constant.I know this is an old question, but there's actually a new answer to it.  You're right that a hash map isn't really O(1), strictly speaking, because as the number of elements gets arbitrarily large, eventually you will not be able to search in constant time (and O-notation is defined in terms of numbers that can get arbitrarily large).  But it doesn't follow that the real time complexity is O(n)--because there's no rule that says that the buckets have to be implemented as a linear list.  In fact, Java 8 implements the buckets as  once they exceed a threshold, which makes the actual time O(log n).If the number of buckets (call it b) is held constant (the usual case), then lookup is actually O(n).\n As n gets large, the number of elements in each bucket averages n/b. If collision resolution is done in one of the usual ways (linked list for example), then lookup is O(n/b) = O(n).The O notation is about what happens when n gets larger and larger. It can be misleading when applied to certain algorithms, and hash tables are a case in point. We choose the number of buckets based on how many elements we're expecting to deal with. When n is about the same size as b, then lookup is roughly constant-time, but we can't call it O(1) because O is defined in terms of a limit as n \u2192 \u221e.We've established that the standard description of hash table lookups being O(1) refers to the average-case expected time, not the strict worst-case performance. For a hash table resolving collisions with chaining (like Java's hashmap) this is technically O(1+\u03b1) with , where \u03b1 is the table's load factor. Still constant as long as the number of objects you're storing is no more than a constant factor larger than the table size.It's also been explained that strictly speaking it's possible to construct input that requires O() lookups for any deterministic hash function. But it's also interesting to consider the worst-case  time, which is different than average search time. Using chaining this is O(1 + the length of the longest chain), for example \u0398(log  / log log ) when \u03b1=1.If you're interested in theoretical ways to achieve constant time expected worst-case lookups, you can read about  which resolves collisions recursively with another hash table!It is O(1) only if your hashing function is very good. The Java hash table implementation does not protect against bad hash functions.Whether you need to grow the table when you add items or not is not relevant to the question because it is about lookup time.This basically goes for most hash table implementations in most programming languages, as the algorithm itself doesn't really change. If there are no collisions present in the table, you only have to do a single look-up, therefore the running time is O(1). If there are collisions present, you have to do more than one look-up, which drives down the performance towards O(n).It depends on the algorithm you choose to avoid collisions. If your implementation uses separate chaining then the worst case scenario happens where every data element is hashed to the same value (poor choice of the hash function for example). In that case, data lookup is no different from a linear search on a linked list i.e. O(n). However, the probability of that happening is negligible and lookups best and average cases remain constant i.e. O(1).Academics aside, from a practical perspective, HashMaps should be accepted as having an inconsequential performance impact (unless your profiler tells you otherwise.)Elements inside the HashMap are stored as an array of linked list (node), each linked list in the array represent a bucket for unique hash value of one or more keys.\nWhile adding an entry in the HashMap, the hashcode of the key is used to determine the location of the bucket in the array, something like:Here the & represents bitwise AND operator.For example: During get operation it uses same way to determine the location of bucket for the key. Under the best case each hashcode is unique and results in a unique bucket for each key, in this case the get method spends time only to determine the bucket location and retrieving the value which is constant O(1). Under the worst case, all the keys have same hashcode and stored in same bucket, this results in traversing through the entire list which leads to O(n).In the case of java 8, the Linked List bucket is replaced with a TreeMap if the size grows to more than 8, this reduces the worst case search efficiency to O(log n).Only in theoretical case, when hashcodes are always different and bucket for every hash code is also different, the O(1) will exist. Otherwise, it is of constant order i.e. on increment of hashmap, its order of search remains constant.Of course the performance of the hashmap will depend based on the quality of the hashCode() function for the given object. However, if the function is implemented such that the possibility of collisions is very low, it will have a very good performance (this is not strictly O(1) in  possible case but it is in  cases).For example the default implementation in the Oracle JRE is to use a random number (which is stored in the object instance so that it doesn't change - but it also disables biased locking, but that's an other discussion) so the chance of collisions is very low."},
{"body": "What is a synthetic class in Java? Why should it be used? How can I use it?For example, When you have a switch statement, java creates a variable that starts with a $.  If you want to see an example of this, peek into the java reflection of a class that has a switch statement in it.  You will see these variables when you have at least one switch statement anywhere in the class. To answer your question, I don't believe you are able to access(other than reflection) the synthetic classes.If you are analyzing a class that you don't know anything about (via reflection) and need to know very specific and low-level things about that class, you may end up using Java reflection methods that have to do with synthetic classes. The only \"use\" here is get more information about the class in order to use it appropriately in your code. (If you're doing this, you're probably building a framework of some sorts that other developers could use. )Otherwise, if you are not using reflection, there are no practical uses of synthetic classes that I know of. Java has the ability to create classes at runtime. These classes are known as Synthetic Classes or Dynamic Proxies.See  for more information.Other open-source libraries, such as  and  also allow you to generate synthetic classes, and are more powerful than the libraries provided with the JRE.Synthetic classes are used by AOP (Aspect Oriented Programming) libraries such as Spring AOP and AspectJ, as well as ORM libraries such as Hibernate. Well I found the answer to the first question on google:This is just a basic definition but I found it in a forum thread and there was no explanation. Still looking for a better one...synthetic classes / methods / fields:These things are important for the VM. Have a look at following code snippet:According to , though the language specification describes an \"isSynthetic\" proprty for classes, this is pretty much ignored by implementations and not used for either dynamic proxies or anonymous classes. Synthetic fields and constructors are used to implement nested classes (there is not concept of nested classes in byte code, only in source code).I think that the concept of synthetic classes has simply proven to be not useful, i.e. nobody cares whether a class is synthetic. With fields and methods, it's probably used in exactly one place: to determine what to show in an IDE class structure view - you want normal methods and fields to show up there, but not the synthetic ones used to simulate nested classes. OTOH, you DO want anonymous classes to show up there.They are created by JVM at run time when they invoke private members of inner class for  debugging purposeThe methods,fields,class created by JVM during run time for its execution purpose are called SyntheticAlso Synthetic Classes or Dynamic Proxies are used by EasyMock to create implementations of interfaces or abstract classes at runtime.If I get it right, a synthetic class is one generated on the fly, without having to give it an explicit name. For example:This creates a synthetic subclass of Thread and overrides its run() method, then instantiates it and starts it.When the Java compiler compiles certain constructs, such as inner classes, it creates ; these are classes, methods, fields, and other constructs that do not have a corresponding construct in the source code. \n\nSynthetic constructs enable Java compilers to implement new Java language features without changes to the JVM. However, synthetic constructs can vary among different Java compiler implementations, which means that .class files can vary among different implementations as well.reference:Synthetic constructs are classes, methods, fields etc that do not have a corresponding construct in the source code. Synthetic constructs enable Java compilers to implement new Java language features without changes to the JVM. However, synthetic constructs can vary among different Java compiler implementations, which means that .class files can vary among different implementations as well.I saw a synthetic class in a disassembled java 5+ project. Turns out it was a compiler hack to implement switching on enums.Synthetic class does not appear in your code, but made up by compiler. \nE.g. Bridge method made up by compiler in java is typically synthetic.Using  instruction, u can see a bridge method it is made up by compiler, however does not appear in your code."},
{"body": "I was surprised recently to find that it's possible to have a return statement in a finally block in Java.It seems like lots of people think it's a bad thing to do as described in ''. Scratching a little deeper, I also found '' which shows some pretty horrible examples of other types of flow control in finally blocks.So, my question is, can anyone give me an example where a return statement (or other flow control) in a finally block produces better / more readable code?The examples you provided are reason enough to  use flow-control from finally.Even if there's a contrived example where it's \"better,\" consider the developer who has to maintain your code later and who might not be aware of the subtleties.  That poor developer might even be you....I had a REALLY hard time to track down a bug years ago that was caused by this. The code was something like:What happened is that the exception was thrown down in some other code. It was being caught and logged and rethrown within the  method. But the exception wasn't being propagated up past . After a LONG time of looking at this we finally tracked it down to the return method. The return method in the finally block was basically stopping the exception that happened in the try block from propagating up even though it wasn't caught.Like others have said, while it is legal to return from a finally block according to the Java spec, it is a BAD thing and shouldn't be done.javac will warn of return in finally if you use the -Xlint:finally. Originally javac emitted no warnings - if something is wrong with the code, it should fail to compile. Unfortunately backwards compatibility means that unanticipated ingenious foolishness cannot be prohibited.Exceptions can be thrown from finally blocks, but in that case the exhibited behaviour is almost certainly what you want.Adding control structures and returns to finally{} blocks are just another example of \"just because you can\" abuses which are scattered throughout virtually all development languages.  Jason was right in suggesting it could easily become a maintenance nightmare - the arguments against early returns from functions apply more-so to this case of \"late returns\".Finally blocks exist for one purpose, to allow you to completely tidy up after yourself, no matter what happened in all the preceeding code. Principally this is closing / releasing file pointers, database connections etc., though I could see it being stretched to say adding in bespoke auditing.Anything that affects the return of the function should lie in the try{} block.  Even if you had a method whereby you checked an external state, did a time consuming operation, then checked that state again in case it became invalid, you would still want the second check inside the try{} - if it sat inside finally{} and the long operation failed, you would then be checking that state a second time needlessly.One interesting point for me was to see how Groovy deals with implicit returns. In Groovy it is possible to \"return\" from a method simply leaving a value at the end (without return). What do you think happens, if you uncomment the  line in the finally statement - will this overwrite the regular return value (\"OK\") and cover the exception?!"},
{"body": "Is there any difference betweenand?If there is no difference, what is the benefit of using ?The difference is that, for example, ais abut not aSo:You would think a  of s should be a  of s, but there's a good reason why it isn't:Suppose you could do:So this is why a  of s shouldn't be a  of s.You cannot assign expressions with types such as  to the first.(If you want to know why you can't assign  to  see a  other questions on SO.)What I'm missing in the other answers is a reference to how this relates to co- and contravariance and sub- and supertypes (that is, polymorphism) in general and to Java in particular. This may be well understood by the OP, but just in case, here it goes:If you have a class , then  and  are their subtypes. Any Car can be assigned to a variable of type Automobile, this is well-known in OO and is called polymorphism. Covariance refers to using this same principle in scenarios with generics or delegates. Java doesn't have delegates (yet), so the term applies only to generics.I tend to think of covariance as standard polymorphism what you would expect to work without thinking, because:The reason of the error is, however, correct:   inherit from  and thus cannot be assigned to each other. Only the generic type parameters have an inherit relationship. One might think that the Java compiler simply isn't smart enough to properly understand your scenario there. However, you can help the compiler by giving him a hint:The reverse of co-variance is contravariance. Where in covariance the parameter types must have a subtype relationship, in contravariance they must have a supertype relationship. This can be considered as an inheritance upper-bound: any supertype is allowed up and including the specified type:This can be used with :You could even call it with a comparer that compares objects and use it with any type.A bit OT perhaps, you didn't ask, but it helps understanding answering your question. In general, when you  something, use covariance and when you  something, use contravariance. This is best explained in .You use , so the rules for  applies. Here you have a list of maps and each item you store in the list must be a  or derive from it. The statement  cannot derive from , but must be  .Hence, the following will work, because  inherits from :but this will not:and this will not work either, because it does not satisfy the covariance constraint:This is probably obvious, but you may have already noted that using the  keyword only applies to that parameter and not to the rest. I.e., the following will not compile:Suppose you want to allow any type in the map, with a key as string, you can use  on each type parameter. I.e., suppose you process XML and you want to store AttrNode, Element etc in a map, you can do something like:Today, I have used this feature, so here's my very fresh real-life example. (I have changed class and method names to generic ones so they won't distract from the actual point.)I have a method that's meant to accept a  of  objects that I originally wrote with this signature:But it want to actually call it with s of subclasses of . But this is not allowed! (The reason for that is,  could add objects to  that are of type , but not of the subtype that 's objects are declared to be at the caller's site. So this could break the type system if it were possible.)Now here come generics to the rescue, because it works as intended if I use this method signature instead:or shorter, if you don't need to use the actual type in the method body:This way, 's type becomes a collection of objects of the actual subtype of , so it becomes possible to use this with subclasses without endangering the type system.As you mentioned, there could be two below versions of defining a List:2 is very open. It can hold any object type. This may not be useful in case you want to have a map of a given type. In case someone accidentally puts a different type of map, for example, . Your consumer method might break.In order to ensure that  can hold objects of a given type, Java generics introduced . So in #1, the  can hold any object which is derived from  type. Adding any other type of data would throw an exception."},
{"body": "From my understanding, garbage collection in Java cleans up some object if nothing else is 'pointing' to that object.My question is, what happens if we have something like this:, , and  should be garbage collected, but they are all being referenced by other objects.How does the Java garbage collection deal with this? (or is it simply a memory drain?)Java's GC considers objects \"garbage\" if they aren't reachable through a chain starting at a garbage collection root, so these objects will be collected.  Even though objects may point to each other to form a cycle, they're still garbage if they're cut off from the root.See the section on unreachable objects in Appendix A: The Truth About Garbage Collection in  (free ebook, also available on ) for the gory details.yes Java Garbage collector handles circular-reference!There are special objects called called garbage-collection roots (GC roots). These are always reachable and so is any object that has them at its own root.A simple Java application has the following GC roots:To determine which objects are no longer in use, the JVM intermittently runs what is very aptly called a . It works as followsSo if any object is not reachable from the GC roots(even if it is self-referenced or cyclic-referenced) it will be subjected to garbage collection.Ofcourse sometimes this may led to memory leak if programmer forgets to dereference an object.Source : A garbage collector starts from some \"root\" set of places that are always considered \"reachable\", such as the CPU registers, stack, and global variables. It works by finding any pointers in those areas, and recursively finding everything they point at. Once it's found all that,  else is garbage.There are, of course, quite a few variations, mostly for the sake of speed. For example, most modern garbage collectors are \"generational\", meaning that they divide objects into generations, and as an object gets older, the garbage collector goes longer and longer between times that it tries to figure out whether that object is still valid or not -- it just starts to assume that if it has lived a long time, chances are pretty good that it'll continue to live even longer.Nonetheless, the basic idea remains the same: it's all based on starting from some root set of things that it takes for granted could still be used, and then chasing all the pointers to find what else could be in use.Interesting aside: may people are often surprised by the degree of similarity between this part of a garbage collector and code for marshaling objects for things like remote procedure calls. In each case, you're starting from some root set of objects, and chasing pointers to find all the other objects those refer to...You are correct. The specific form of garbage collection you describe is called \"\". The way it works (conceptually, at least, most modern implementations of reference counting are actually implemented quite differently) in the simplest case, looks like this:And this simple strategy has exactly the problem you decribe: if A references B and B references A, then both of their reference counts can  be less than 1, which means they will never get collected.There are four ways to deal with this problem:By the way, the  major way to implement a garbage collector (and I have already hinted at that a couple of times above), is . A tracing collector is based on the concept of . You start out with some  that you know is  reachable (global constants, for example, or the  class, the current lexical scope, the current stack frame) and from there you  all objects that are reachable from the root set, then all objects that are reachable from the objects reachable from the root set and so on, until you have the transitive closure. Everything that is  in that closure is garbage.Since a cycle is only reachable within itself, but not reachable from the root set, it will be collected.The Java GCs don't actually behave as you describe.  It's more accurate to say that they start from a base set of objects, frequently called \"GC roots\", and will collect any object that can not be reached from a root.\nGC roots include things like:So, in your case, once the local variables a, b, and c go out of scope at the end of your method, there are no more GC roots that contain, directly or indirectly, a reference to any of your three nodes, and they'll be eligible for garbage collection.TofuBeer's link has more detail if you want it. goes into depth about the garbage collector (conceptually... there are several implementations).  The relevant part to your post is \"A.3.4 Unreachable\".Garbage collection doesn't usually mean \"clean some object iff nothing else is 'pointing' to that object\" (that's reference counting). Garbage collection roughly means finding objects that can't be reached from the program.So in your example, after a,b, and c go out of scope, they can be collected by the GC, since you can't access these objects anymore.Bill answered your question directly. As Amnon said, your definition of garbage collection is just reference counting. I just wanted to add that even very simple algorithms like mark and sweep and copy collection easily handle circular references. So, nothing magic about it!"},
{"body": "What is the difference between  and ?I do not understand the significant difference (I have read something about them!). Could you please help me?Maybe an example demonstrating how both methods are used will help you to understand things better. So, consider the following class:As explained in its javadoc, calling   i.e. it returns  which is affected to the  variable of type .Then, calling   In other words, this is here actually equivalent to a  and returns a new instance of .And running this  class thus prints the following output:The big difference with the traditional  is that  allows to instantiate a class that you don't know until runtime, making your code more dynamic. A typical example is the JDBC API which loads, at runtime, the exact driver required to perform the work. EJBs containers, Servlet containers are other good examples: they use dynamic runtime loading to load and create components they don't know anything before the runtime.Actually, if you want to go further, have a look at Ted Neward paper  that I was paraphrasing in the paragraph just above. (answering a question from the OP posted as comment): The case of JDBC drivers is a bit special. As explained in the  chapter of :To register themselves during initialization, JDBC driver typically use a static initialization block like this:Calling  causes the initialization of the  class and thus the execution of the static initialization block. And   will indeed \"create\" an instance but this is just a consequence of how (good) JDBC Driver are implemented.As a side note, I'd mention that all this is not required anymore with JDBC 4.0(added as a default package since Java 7) and the new auto-loading feature of JDBC 4.0 drivers. See .Class.forName() gives you the class object, which is useful for reflection. The methods that this object has are defined by Java, not by the programmer writing the class. They are the same for every class. Calling newInstance() on that gives you an instance of that class (i.e. calling  it is equivalent to calling ), on which you can call the methods that the class defines, access the visible fields etc.  In JDBC world, the  practice (according the JDBC API) is that you use  to load a JDBC driver. The JDBC driver should namely register itself in  inside a static block:Invoking  will execute all . This way the  can find the associated driver among the registered drivers by connection URL during  which roughly look like follows:But there were also  JDBC drivers, starting with the  as well known example, which incorrectly registers itself inside the  instead of a static block:The only way to get it to work dynamically is to call  afterwards! Otherwise you will face at first sight unexplainable \"SQLException: no suitable driver\". Once again, this is a  in the JDBC driver, not in your own code. Nowadays, no one JDBC driver should contain this bug. So you can (and should) leave the  away.1 : if you are interested only in the static block of the class , the loading the class only would do , and would execute static blocks then all you need is:2 : if you are interested in loading the class , execute its static blocks and also want to access its its non static part , then you need an instance and then you need:Class.forName() gets a reference to a Class, Class.forName().newInstance() tries to use the no-arg constructor for the Class to return a new instance.\"Class.forName()\" returns the Class-Type for the given name. \"newInstance()\" does return an instance of this class.On the type you can't call directly any instance methods but can only use reflection for the class. If you want to work with an object of the class you have to create an instance of it (same as calling \"new MyClass()\").Example for \"Class.forName()\"Example for \"Class.forName().newInstance()\"just adding to above answers, when we have a static code (ie code block is instance independent) that needs to be present in memory, we can have the class returned so we'll use Class.forname(\"someName\") else if we dont have static code we can go for Class.forname().newInstance(\"someName\") as it will load object level code blocks(non static) to memoryClass.forName()-->forName() is the static method of Class class it returns Class class object used for reflection not user class object so you can only call Class class methods on it like getMethods(),getConstructors() etc. If you care about only running static block of your(Runtime given) class and only getting information of methods,constructors,Modifier etc of your class you can do with this object which you get using Class.forName()But if you want to access or call your class method (class which you have given at runtime) then you need to have its object so newInstance method of Class class do it for you.It create new instance of the class and return it to you .You just need to type-cast it to your class.ex-:  suppose Employee is your class thenClass a=Class.forName(args[0]); //args[0]=cmd line argument to give class at  runtime. Employee ob1=a.newInstance();a.newInstance() is similar to creating object using new Employee().now you can access all your class visible fields and methods."},
{"body": "Where can I view Tomcat log files in Eclipse?For some reason my Tomcat installation/log folder is always empty.BTW, does Tomcat dump to the log file after a while or is it immediate?Go to the \"Server\" view, then double-click the Tomcat server you're running. The  log files are stored relative to the path in the \"Server path\" field, which itself is relative to the workspace path.I'm not sure if you were after catalina.out or one of the other logs produced by Tomcat.But, if you're after the catalina.out log file then follow the directions below:Another forum provided this answer:Looks like the logs are scattered? I found access logs under\nDouble click and open the server.\nGo to 'Arguments'.\n-Dcatalina.base= .. something.\nGo to that something.\nYour logs are there.:Since the path field is uneditable, you can also \"Open Launch Configuration\", click Arguments tab, copy the VM argument for catalina.base (within quotes). This is the full path of your WTP webapp directory. Copying the value to the clipboard can save you the laborious task of browsing the file system to the path.Also note you should be seeing the output to the log file in your Console view as you run or debug.If you want logs in a separate file other than the console: \nDouble click on the server--> Open Launch Configuration--> Arguments --> add \n-Dlog.dir = \"Path where you want to store this file\" and restart the server. Tip: Make sure that the server is not running when you are trying to add the argument.\nYou should have log4j or similar logging framework in place. "},
{"body": "How do you return a JSON object form a Java servlet.Previously when doing AJAX with a servlet I have returned a string. Is there a JSON object type that needs to be used, or do you just return a String that looks like a JSON object e.g. I do exactly what you suggest (return a ).You might consider setting the MIME type to indicate you're returning JSON, though (according to  it's \"application/json\").Write the JSON object to the response object's output stream.You should also set the content type  as follows, which will specify what you are returning:          First convert the JSON object to . Then just write it out to the response writer along with content type of  and character encoding of UTF-8.Here's an example assuming you're using  to convert a Java object to a JSON string:That's all.Just write a string to the output stream. You might set the MIME-type to  (:  is apparently officialer) if you're feeling helpful. (There's a small but nonzero chance that it'll keep something from messing it up someday, and it's a good practice.)There might be a JSON object for Java coding convenience. But at last the data structure will be serialized to string. Setting a proper MIME type would be nice.I'd suggest  from .Gson is very  usefull for this. easier even.\nhere is my example:}Have to say people if yours vars are empty when using gson it wont build the json for you.Just theI used  to convert Java Object to JSON string and send as follows.response.setContentType(\"text/json\");//create the JSON string, I suggest using some framework.String your_string;out.write(your_string.getBytes(\"UTF-8\"));Close to BalusC answer in 3 simple lines using Google Gson lib. Add this lines in the servlet method:`Good luck!"},
{"body": "I am using Java to get a  input from the user. I am trying to make the first letter of this input capitalized. I tried this:which led to these compiler errors:With your example:  from the value of  is What you want to do is probably this:(converts first char to uppercase and adds the remainder of the original string)Also, you create an input stream reader, but never read any line. Thus  will always be .This should work: from .Use .Set the string to lower case, then set the first Letter to upper like this:then to capitalise the first letter:substring is just getting a piece of a larger string, then we are combining them  back together.Shortest too:Worked for me.This is just to show you, that you were not that wrong. Add this dependency to your Now you can useYou can also try this:This is better(optimized) than with using substring. (but not to worry on small string)You can use  to do this.  But there are two different cases:If the  you are capitalizing is meant to be human-readable, you should also specify the default locale:If the  you are capitalizing is meant to be machine-readable, avoid using  because the string that is returned will be inconsistent across different regions, and in this case always specify the same locale (for example, ).  This will ensure that the strings you are using for internal processing are consistent, which will help you avoid difficult-to-find bugs.Note: You do not have to specify  for , as this is done automatically.What about ?try this oneWhat this method does is that consider the work \"hello world\" this method turn it into \"Hello World\" capitalize the beginning of each word .This will workHave a look at ACL WordUtils.WordUtils.capitalize(\"your string\") == \"Your String\"Many of the answers are very helpful so I used them to create a method to turn any string to a title (first character capitalized):You can use the following code:example test with JUnit: Following example also capitalizes words after special characters such as [/-]thanks I have read some of the comments and I came with the following I hope its helps \ngood luck You can use the following code:The answer from Ameen Mahheen is good but if we have some string with double space, like \"hello  world\" then sb.append gets IndexOutOfBounds Exception. Right thing to do is teste before this line, doing:You may try thisYou can use Class WordUtils.Suppose your String is \"current address\" then use ****strong text\noutput : Current AddressRefer: Try this, it worked for me."},
{"body": "I installed Android Studio, but when I edit my layout files, I can't find live preview! I just see an XML file. How can I see my layout in graphical view?Update:\nThis is how it looks like in my case:You should have a  button next to the  button under the xml text editor:Or you can use the  button in the upper right corner to add a preview window next to the XML code:If you dont have it, then do this:  ->  -> Several people seem to have the same problem. The issue is that the IDE only displays the preview if editing a layout file in the  directory of an Android project.In particular, it won't show if editing a file in  since those are not  directory but  directory. In your case, you are editing a file in the  directory...The Resource folder is set automatically, and can be viewed (and changed) in Project Structure > Modules > [Module name] > Android > Resources directory.In case that helps anyone, I had the same issue today where the 'design / text' tabs were missing. I had switched to the dark theme and thought maybe that was the issue, so went back to Preferences / Appearance (under IDE settings) switched back to Default Theme, and that reset everything correctly for me. I could also then switch again to Darcula theme and the tabs were still there, so seems like switching themes is a way to reset the IDE windows/tabs.The following worked for me:-> file -> settings -> plugins -> disable the android support plugin -> you will be prompted to restart -> once restarted re-enable the plugin and other dependency plugins that might have been disabled in the process-> you will be prompted to restart once again. Hopefully when android studio restarts the second time the preview should render. Got the same problem after importing my Eclipse ADT project to Android Studio. Text and Desing tabs where missing. Found my Event Log windows reads \n\"Frameworks detected: Android framework is detected in the project Configure\"I click the hyperlink provided and everything was fixed, Text and Desing tabs became visible and functionalNavigate to file -> Project structure -> modules -> click on green plus button to add a module.Select new module -> select Application Module in Android option -> give a module name -> next -> next -> finishSelect project that to be include in module -> click apply -> okayNow you will be able to see the full project structure; then open the module form project window (the left panel), select res then select layout -> your layout name(.xml).Now you will be able to see the design view and text view both...Guys everything is very simple... \n1. Just input in search \"Preview\" and it will show you a single result. Just click on it and preview appears again :)\n2. Pull the right-side line and window will appear. It's kinda resize.Happy coding!Go to File->Invalidate Caches / Restart.This will solve the issue.As etienne said be sure that the XML file you are looking at is in I had the same issue. If you're in a layout file in  directory, you won't see a preview, nor will you have it as an option to enable. I wish Google had a slight warning for it.If you want to see the , in the right part of the screen you should have a button call  that show/hide the live preview. If what you want is to use the WYSISYG editor mode, in the bottom of the editor there is a tab that switch between  mode and  mode.This works in the same way both in IntelliJ and Android Studio.I had the same issue and resolved by editing the t file in src>main>res>layout. You can choose between Test and Design mode at the bottom of editor. Quite simple if we know where to look for !!! spend few hours figuring it out!!!  File>>setting>>Compiler>>JavaCompiler At \"Project bytecode version(leave blank for jdk default):\" choose your jdk.I had this problem a couple hours ago when I exported my projects from Eclipse to Android Studio. Unfortunately, the top answers here didn't work for me. Anyway, creating a new project instead of opening an old one did the trick for me as what Thomas Kaliakos mentioned on his comment In case you want docked mode, (it still visible while editing the xml file), and you, by mistake, clicked and unmarked docked mode. In order to get it back you have focus on preview and click .If you see a message at the bottom saying something like, \"Android Framework detected. Click to configure\", DO IT.After doing this, my Text and Design bottom-tabs appeared."},
{"body": "I'm trying to compile my android project and I'm getting this errorI've been reading in other post that try to compile with java 8 might cause that error but not my case, I have the following Java version:OS: Linux Mint\n(I'm not have Java 8 installed.)\nBuild: MAVENCan anyone help me with this?\nThanks in advance!I face this problem too when making new project from android studio.I've been able to resolve this by downgrading buildToolsVersion in app gradle  setting:\nchange {module-name}/build.gradle lineto \n@Edit: \nIn Android Studio 2.1 Go to File-> Project Structure->App -> Build Tool Version. Change it to 23.0.3Do the method above, only when you are using java version 7 and for some reason do not want to upgrade to java 8 yet. Hope this helps >> Change  to source : experienceInitially I had downgraded  from  to , as specified in Rudy Kurniawan's answer. Then I have noticed that I have jdk 7 specified in my project settings. I have changed it to jdk 8 and now build tools  work.It's also important to have compile options set to :I installed Android Studio alongside to Xamarin Visual Studio (was already installed). After the installation (excluded SDK, because they were already installed) I started Android Studio and it downloaded, installed and added missing SDKs (after giving the path to the SDK location). As a result I got the error message on buildAs a solution I installed  without JRE (because it was already installed). Before I tried the x64 version, but it disappeared ... Then you have to change the .This is done in Visual Studio by clicking Tools > Options > Xamarin > Android Settings. Here you can navigate to the correct location. In my case it was .Finally, clean your project and make a new build :-)The problem specified:. To solve this problem we have to change from  from 24 to maximum 23:Java 8 must be required in the future for , so we have to start using Java 8.I had the same problem with my IntelliJ Maven build. My \"solution\" was to go into the build tools and remove the build tools 24.0.0 folder. I found it in the  directory. This is not a long term fix, but this should at least get your project building again. Upgrading to Java 8 as many have suggested will be better long term.What no one here is saying is that with Build Tools 24.0.0, Java 8 is required and most people have either 1.6 or 1.7. So yeah, setting the build tool to 23.x.x would 'solve' the problem but the root cause is the Java version on your system. On the long term, you might want to upgrade your dev environment to use JDK8 to make use the new language enhancements and the jack compiler.I am on Android Studio 2.0 and facing the same problem. \nThe solution provided by Rudy Kurniawan sorted out this issue. The affected file can be located by:The  \"\" pane is default on the left. To find it, inspect the name of the side tabs, click it, then use the top pull down box to get to \"\". Expand the tree in the pane to find the target file. Double-click it to edit. Sorry for the late reply.Hope it helps someone elseThis problem is related with your SDK, not with your JDK.\nYou can check your version information from You will get something like If you are using preview tools for building ,then you will get similar errors all over.gotoBack to your code   and \n(In rare cases, you have to select build-tools from project settings page)I also faced this problem when making a new project in eclipse.Hope this helps is the code for JDK 8.  You can see that here: .  So Gradle is expecting you to have JDK 8 as the default Java version on your machine.  Newest versions of Gradle for Android won't work with Java 7.The solution is simple: make Java 8 the default jdk version on your machine.SOLUTION FOUND TO ALL USERS HAVE THIS PROBLEM.THE SOLUTION TO THE PROBLEM WITH ECLIPSE IS WRITE THIS IN YOUR project.properties FILE:THE SOLUTION TO THE PROBLEM WITH ANDROID IS STUDIO VERSION 2.1 FILE write this in BUESTRO project.properties:Thanks everyone for solution.I could solve my same problem using below solution.In my project, I added jar which were created in Java8. And my project was referring to JRE 7. When i changed project JRE to 8. My problem solved.Steps: In eclipse, right click on project name in project explorer > build path > Libraries > click on jre version > click edit > installed JRE > add > standerd VM > select JRE home click-path (path should be localePath\\java\\jdk1.8.0_25\\jre) > provide name > save > select same JRE for project > finish > ok Refresh/build project once > try to run your java file. it should work.Get this error message on the travis build server?I fixed my  build with \nbuildToolsVersion  using this In my case the default jdk was 1.7 then I changed it to 1.8 by browsing to the exact folder where the updated jdk is found in.I had the same problem and tried to change the version, sometimes is for the version of Android Studio in Project> Gradle Scripts> build.gradle(Module:app) you can change the version. For example:From  question.You can try to change your compiler level back to 1.7 in the IDE you're using.If this doesn't help, try checking other's answer in the link mentioned above and let us know what helped you.Your Android build tools are not properly installed. Try installing some other version of build tools and give that version in the gradle file.\nor you can go to this directoryC:\\Users\\\\AppData\\Local\\Android\\sdk\\build-tools and see which build tools is installed. Try changing the build tool version in the gradle file and compile the app to see if it is working.i had 22.0.1,23.0.02 and 24.0.0 versions of build tools and only the old 22.0.1 version worked.source: i tried it myself and it worked for me.This problem stems from the fact that your build tool version and JDK won't work together. I was using JDK version 7 with build tool 24.0.1. Of course lowering build tool version may fix the problem but it is not a real fix, as upgrading your build tools in future will break it again.You should make sure build tool version and JDK work together. I upgraded my build tool to latest (24.0.1) and installed jdk8. Make sure to set your JAVA_HOME to latest and then try clean build. Got the same issue outside of Android Studio, when trying to build for Cordova using the sdk from command line (cordova build android). The solution provided by Rudy works in this case too. You just don't downgrade the version of Build Tools from Android Studio but you do it using the android sdk manager ui.I just encountered this problem.Reverting from the \"Preview Channel\" versions of the SDK tools and build tools to the latest stable version fixed it.I had two versions of java jdk installed. Once I pointed to right version of java jdk in File->Project Structure -> SDK Location to the latest version which I had in JAVA_HOME environment variable, the issue went away.Changing  to  fixed it for me.My Android Studio version is 2.1.2, perhaps that's whyThe Simplest  solution is you have to update your JDK to latest, version . Because  Cordova supports only latest JDK .  First of all you have to update your Android SDK. Then, If you are not  able to update through your terminal ,  Got to your  of Linux destro and  search the Latest (which one you want to install) and install  that one .Then again run  .  It will  solve the problem .In ,my case it worked.You need to go into your SDK installation directory, and make sure that the  sub-directory matches the  in your app's build.gradle file:\nCheck that you have the latest version of the SDK installed in either  or Then go to VS2015 and follow the path tools - options - Xamarin - Android settings and in the section JDK location select change and go to look for the version you have either x64 or x32.I am on cordova, here's what I've done:-\u00a0rename your android project, so that there's space for new one\n-\u00a0update JAVA Development Kit to 1.8 (latest one in time of writing this)\n-\u00a0run    Should work without problems now. Your app hash will change, so if you are using it f.e. for facbeook login, you will need to update itI'd had this issue for too long (SO etc hadn't helped) and only just solved it (using sdk 25).-The local.properties file proguard.dir var was not applying with ant; I'd specified 5.3.2, but a command line call and signed export build (eclipse) was using 4.7, from the sdk dir(only 5+ supports java 8)My solution was to replace the proguard jars (android-sdk/tools/proguard/libs directory) in the sdk with a current (5+) version of proguard.unsupported-major-minor-version error can be because of unsupported JDK version. Update JDK, Go to Module Settings and change the JDK path to the new one. In most of the cases, it fixes the error."},
{"body": "I am building an android app that needs to download and synchronise with an online database, I am sending my query from the app to a php page which returns the relevant rows from a database in JSON format. can someone please tell me the best way to iterate through a JSON array?I receive an array of objects:What is the simplest piece of code I could use to access the JSONObjects in the array?EDIT: now that I think of it the method I used to iterate the loop was:So I guess I had was somehow able to turn the returned Json into and iterable array. Any Ideas how I could achieve this?I apologise for my vaguness but I had this working from an example I found on the web and have since been unable to find it.I have done it two different ways,I think this code is short and clear:Is that what you were looking for?This article helped me when I got started with JSON and Android:On Arrays, look for:Use the , it's also available for Android.There are several ways to parse JSON with it:Take org.json classes, there are  the android API.If you're using the , which is open source, you can just make JSONArray implement the  interface and add the following method to the class:This will make all instances of JSONArray iterable, meaning that the  syntax will now work with it (note that foo has to be an Object, because JSONArrays do not have a declared type). All this works because the JSONArray class is backed by a simple ArrayList, which is already iterable. I imagine that other open source implementations would be just as easy to change.unfortunately , JSONArray doesn't support for each statement, like:You are using the same Cast object for every entry.\nOn each iteration you just changed the same object instead creating a new one.This code should fix it:While iterating over a JSON array (org.json.JSONArray, built into Android), watch out for  objects; for example, you may get  instead of a  string.A check may look like:When I tried @vipw's suggestion, I was faced with this exception:\nThis worked for me instead:"},
{"body": "In my code I need to find all my things that happened today.  So I need to compare against dates from today at 00:00am (midnight early this morning) to 12:00pm (midnight tonight).I know ...... gets me right now.  And ...... gets me zero time on Jan 1, 1970.  But what's an easy way to get zero time today and zero time tomorrow?Any help is greatly appreciated!UPDATE; I did this, but surely there's an easier way??If you're using a JDK < 8, I recommend , because the API is really nice:\nSince version 2.3 of Joda Time  is , so use this:Pass a time zone if you don't want the JVM\u2019s current default time zone.Remember,  is not used to represent  (!). To represent date you need a calendar. This:will create a  instance representing present date in your current time zone. Now what you need is to truncate every field below day (hour, minute, second and millisecond) by setting it to . You now have a midnight today.Now to get midnight next day, you need to add one day:Note that adding  seconds or 24 hours is incorrect due to summer time that might occur in the meantime.UPDATE: However my favourite way to deal with this problem is to use  class from :It uses  behind the scenes...The easiest way to find a midnight:Next day:As of JodaTime 2.3, the  is deprecated.From Here is a sample code without  method. ()For sake of completeness, if you are using  you can also use the  method of the  class to get midnight in .As written in the JavadocHope it helps.This appears to be an option:to add a day to it, eitherorI have a hunch the latter is preferred in case of something weird like daylight savings causing adding 24 hours to not be enough (see  and its other answers).If you are using Java 8 and later, you can try the  ():these methods will help you-and Other answers are correct, especially the . As some mentioned, you should avoid the old java.util.Date/.Calendar classes as they are poorly designed, confusing, and troublesome. They have been supplanted by the java.time classes.Let me add notes about strategy around  and .In date-time work, spans of time are often defined using the \u201cHalf-Open\u201d approach. In this approach the beginning is  while the ending is . This solves problems and if used consistently makes reasoning about your date-time handling much easier. One problem solved is defining the end of the day. Is the last moment of the day  ()? Perhaps, in the java.util.Date class (from earliest Java; troublesome \u2013 avoid this class!) and in the highly successful  library. But in other software, such as database like Postgres, the last moment will be  (). But in other software such as the  framework (built into Java 8 and later, successor to Joda-Time) and in some database such the , the last moment might be  (). Rather than splitting hairs, think in terms of first moment only, not last moment.In Half-Open, a day runs from the first moment of one day and goes up to but  the first moment of the following day. So rather than think like this:\u2026think like this\u2026In database work, this approach means  using the  in SQL.Furthermore, the first moment of the day is  always the time-of-day .  in some time zones, and possibly other anomalies, can mean a different time starts the day. So let the  classes do the work of determining the start of a day with a call to . So we have to detour through  and back to  as you can see in this example code.Note the passing of the optional . If omitted your JVM\u2019s current default time zone is applied implicitly. Better to be explicit.Time zone is crucial to date-time work. The Question and some other Answers are potentially flawed because the do not consciously handle time zone.If you  use a java.util.Date or .Calendar, look for new conversion methods added to those old classes.By the way, if you are doing much work with spans of time take a look at:I did this differently than everyone else here did.  I'm new to Java, so maybe my solution is poor.  I'm not sure this works yet, but either way, I'd appreciate any feedback on this solution.  I'm confused by the statement above that you can calculate tomorrow by calling:If you add 1 to the day of the month and it's the 31st day, don't you get the 32nd day of the month?Why are times/dates not all based on UTC in Java?  I would think Timezones should only be needed when used with i/o, but internally should always be used in UTC.  However, the classes seem to include Timezone info which seems not only wasteful, but prone to coding errors.   Apache Commons Lang, java.util.Date)The simplest way with JodaTime  Because of one day is  ms, \nthe midnight of this day can be calculate as...I know this is very old post. I thought to share my knowledge here ! For the date Mid night today with exact Time zone you can use following Where    is being subtracted i.e. actually related to time zone for example Indian time zone i.e. kolkata differs +5:30hrs from actual . So subtracting  that with converting into milliseconds. So change last substracted number according  to you. I m creating a product i.e. only based in India So just used specific timestamp. "},
{"body": "I have an  and I want to copy it exactly. I use utility classes when possible on the assumption that someone spent some time making it correct. So naturally, I end up with the  class which contains a copy method.Suppose I have the following:This fails because basically it thinks  isn't big enough to hold . Yes I know  has size 0, but it should be big enough now shouldn't it? If I have to fill  first, then  becomes a completely useless function in my mind. So, except for programming a copy function (which I'm going to do now) is there a proper way to do this?Callingcreates a shallow copy of  within . All elements will exist within  in the exact same order that they were within  (assuming it had an order).Similarly, callingalso creates a shallow copy of  within . If the first parameter, , does not have enough  (not size) to contain all of 's elements, then it will throw an . The expectation is that no allocations will be required by  to work, and if any are, then it throws that exception. It's an optimization to require the copied collection to be preallocated (), but I generally do not think that the feature is worth it due to the required checks given the constructor-based alternatives like the one shown above that have no weird side effects.To create a deep copy, the , via either mechanism, would have to have intricate knowledge of the underlying type. In the case of s, which are immutable in Java (and .NET for that matter), you don't even need a deep copy. In the case of , you need to know how to make a deep copy of it and that is not a generic operation.Note: The originally accepted answer was the top result for  in Google, and it was flat out wrong as pointed out in the comments. has a  of 3, but a  of 0. The fact that  has some sort of buffer capacity is an implementation detail - it's not part of the  interface, so  doesn't use it. It would be ugly for it to special-case .As MrWiggles has indicated, using the ArrayList constructor which takes a collection is the way to in the example provided.For more complicated scenarios (which may well include your real code), you may find the  useful.Just do:ArrayList has a constructor that will accept another Collection to copy the elements fromThe answer by Stephen Katulka (accepted answer) is wrong (the second part).\nIt explains that  does a deep copy, which it does not. Both,  and  only do a shallow copy. The difference is, that the constructor allocates new memory, and  does not, which makes it suitable in cases where you can reuse arrays, as it has a performance advantage there.The Java standard API tries to discourage the use of deep copies, as it would be bad if new coders would use this on a regular basis, which may also be one of the reason why  is not public by default.The source code for  can be seen on line 552 at:\nIf you need a deep copy, you have to iterate over the items manually, using a for loop and clone() on each object.the simplest way to copy a List is to pass it to the constructor of the new list: will be a shallow copy of Looking at the source of  (I'd never seen it before) it seems to be for coping the elements index by index. using  thus element 0 will over write element 0 in the target list etc etc. Not particularly clear from the javadocs I'd have to admit.doesn't set the size. It sets the initial capacity (being how many elements it can fit in before it needs to resize).  A simpler way of copying in this case is:As hoijui mentions. The selected answer from Stephen Katulka contains a comment about Collections.copy that is incorrect. The author probably accepted it because the first line of code was doing the copy that he wanted. The additional call to Collections.copy just copies again. (Resulting in the copy happening twice).Here is code to prove it.Most answers here do not realize the problem, the user wants to have a COPY of the elements from first list to the second list, destination list elements are new objects and not reference to the elements of original list.\n(means changing an element of second list should not change values for corresponding element of source list.)\nFor the mutable objects we cannot use ArrayList(Collection) constructor because it will simple refer to the original list element and will not copy.\nYou need to have a list cloner for each object when copying.Why dont you just use  method:even if you have existing items in b or you want to pend some elements after it, such as:If you want to copy an ArrayList, copy it by using:Strings can be deep copied withbecause they are immutable. Every other Object not --> you need to iterate and do a copy by yourself.Every other Object not --> you need to iterate and do a copy by yourself.To avoid this implement Cloneable.....The following output illustrates results of using copy constructor and Collections.copy():The source of full program is here: . But the output is enough to see how java.util.Collections.copy() behaves.And if you are using google guava, the one line solution would be This creates a mutable array list instance.Copy isn't useless if you imagine the use case to copy some values into an existing collection. I.e. you want to overwrite existing elements instead of inserting.An example: a = [1,2,3,4,5] b = [2,2,2,2,3,3,3,3,3,4,4,4,] a.copy(b) = [1,2,3,4,5,3,3,3,3,4,4,4]However I'd expect a copy method that would take additional parameters for the start index of the source and target collection, as well as a parameter for count.See Java BUG To understand why Collections.copy() throws an IndexOutOfBoundsException although you've made the backing array of the destination list large enough (via the size() call on the sourceList), see the answer by Abhay Yadav in this related question:\n"},
{"body": "So I installed the beta of JDK 8 a while ago to look at some of the examples. I thought for sure by now, it's easy to change between versions. Doing some Play development with IntelliJ. For some reason, IntelliJ is compiling with 8 even though:If I go to the Java Preferences page, it does show 8 installed, but there is no option to uninstall it and it doesn't see any of the other versions.When I do , it tells me  and I do  and it returns 1.6.Note: with a  little fiddling, you can use IntelliJ and JDK7, see .I was able to unistall jdk 8 in mavericks successfully doing the following steps:Make it really simple...Managing Java versions on Mac OSX is a nightmare.  I recently switched over to using JDK 1.7, deleting JDK 6 from my MacBook entirely (I also had traces of JDK 5 - this laptop has been updated a few times).Here's what I did to move to JDK 7.1) download the latest from Oracle () and install it.2) Remove (using rm - if you've got backups, you can revert if you make a mistake) all the JDK6 and JRE6 files.At this stage, you should see:(and nothing else)3) In the folder /Library/Java/Extensions/, you'll need to remove all the old jar files, the ones that correspond to other releases of Java.  If you don't, you'll get the infamous message about the wrong version of tools.jar (see ).  It is not enough to rename the jar files, because Java will open every jar in that folder - I moved mine into a sub-directory.  It's safe to remove them once you know everything else works.I haven't found I need to set JAVA_HOME for simple things.: I just tried running IntelliJ and it  start unless you have Apple's JDK 6 installed (see ).  Same is true for Eclipse. Netbeans works fine.Use  ; I found these alias and function to be pretty useful in my :Here is the official document about uninstalling the JDK.I nuked everything Java, JDK, and oracle. I was running Java 8 on OSX El CapitanOther answers were missing tons of stuff. This answer covers a lot more bases.Good bye, shovelware.If you have installed jdk8 on your Mac but now you want to remove it, just run below command \"sudo rm -rf /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk\"If you uninstall all the files but it still fails, use this line:For yosomite imac OS x:This worked perfectly for me:"},
{"body": "I have an  that I'd like to return a copy of.   has a clone method has the following signature:After I call this method, how do I cast the returned Object back to ?Why would you want to clone? Creating a new list usually makes more sense.Job done.This is the code I use for that:Hope is usefull for youBe advised that Object.clone() has some major problems, and its use is discouraged in most cases. Please see Item 11, from \"\" by Joshua Bloch for a complete answer. I believe you can safely use Object.clone() on primitive type arrays, but apart from that you need to be judicious about properly using and overriding clone. You are probably better off defining a copy constructor or a static factory method that explicitly clones the object according to your semantics.I think this should do the trick using the Collections API:: the copy method runs in linear time.    With Java 8 it can be cloned with a stream....I find using addAll works fine.parentheses are used rather than the generics syntaxBe very careful when cloning ArrayLists. Cloning in java is shallow. This means that it will  only clone the Arraylist itself and not its members. So if you have an ArrayList X1 and clone it into X2 any change in X2 will also manifest in X1 and vice-versa. When you clone you will only generate a new ArrayList with pointers to the same elements in the original. My function to clone a List with type:This should also work:If you want this in order to be able to return the List in a getter it would be better to do:To clone a generic interface like  you will just need to cast it. here you are an example:It is a bit tricky, but it works, if you are limited to return a  interface, so anyone after you can implement your list whenever he wants.I know this answer is close to the final answer, but my answer answers how to do all of that while you are working with  -the generic parent- not I am not a java professional, but I have the same problem and I tried to solve by this method. (It suppose that T has a copy constructor)."},
{"body": "Is there any Utils help reader a textfile in resource into a String. I suppose this is a popular requirement, but I couldn't found any Utils after Googling.ThanksYes,  provides this in the  class. For example:You can use the old  oneliner to do that without any additional dependency like guava:Guys, don't use 3rd party stuff unless you really need that. There is a lot of functionality in the JDK already. has a \"toString\" method for reading a file into a String:This method does not require the file to be in the classpath (as in  previous answer).For java 7: has a utility name : has found a :I often had this problem myself. To avoid dependencies on small projects, I often\nwrite a small utility function when I don't need commons io or such. Here is\nthe code to load the content of the file in a string buffer :Specifying the encoding  important in that case, because you might have\nedited your file in UTF-8, and then put it in a jar, and the computer that opens\nthe file may have CP-1251 as its native file encoding (for example); so in\nthis case you never know the target encoding, therefore the explicit\nencoding information is crucial.\nAlso the loop to read the file char by char seems inefficient, but it is used on a\nBufferedReader, and so actually quite fast.You can use the following code  form Java If you want to get your String from a project resource like the file\ntestcase/foo.json in src/main/resources in your project, do this:Note that the getClassLoader() method is missing on some of the other examples.Use Apache commons's FileUtils. It has a method Here is my approach worked fine Guava also has  if you want a return value as  line-by-line:Please refer to  to compare 3 ways ( vs. Guava's  vs. Guava's ) to get  from a text file.With set of static imports, Guava solution can be very compact one-liner:The following imports are required:I'm using the following for reading resource files from the :No third party dependencies required."},
{"body": " Sun's JVM source doesn't contain this exact message, but I think the text  is from the native implementation of :My guess is that it is caused when the client has terminated the connection, before getting the full response (e.g. sent a request, but before getting the full response, it got closed / terminated / offline)I need to have a proof that this stack trace is the socket client's \"fault\", and there is nothing that the server could have done to avoid it. (except catching the exception, or using a non Sun JVM SocketOutputStream, though both don't really avoid the fact the client has terminated)\"This error can occur when the local network system aborts a connection, such as when WinSock closes an established connection after data retransmission fails (receiver never acknowledges data sent on a datastream socket).\". See . See also .I have seen this most often when a corporate firewall on a workstation/laptop gets in the way, it kills the connection.eg. I have a server process and a client process on the same machine. The server is listening on all interfaces (0.0.0.0) and the client attempts a connection to the public/home interface (note not the loopback interface 127.0.0.1).If the machine is has its network disconnected (eg wifi turned off) then the connection is formed. If the machine is connected to the corporate network (directly or vpn) then the connection is formed.However, if the machine is connected to a public wifi (or home network) then the firewall kicks in an kills the connection. In this situation connecting the client to the loopback interface works fine, just not to the home/public interface.Hope this helps.I was facing the same issue.\nCommonly This kind of error occurs due to client has closed its connection and server still trying to write on that client.\nSo make sure that your client has its connection open until server done with its outputstream.\nAnd one more thing, Don`t forgot to Hope this helps. \nAnd if still facing issue than brief your problem here in details.To prove which component fails I would monitor the TCP/IP communication using  and look who is actaully closing the port, also timeouts could be relevant.Have you checked the Tomcat source code  the JVM source ? That may give you more help.I think your general thinking is good. I would expect a  in the scenario that you couldn't connect. The above looks very like it's client-driven.For anyone using simple Client Server programms and getting this error, it is a problem of unclosed (or closed to early) Input or Output Streams.The  is thrown when there is an error creating or accessing  (such as ). This usually can be caused when the server has terminated the connection (without properly closing it), so before getting the full response. In most cases this can be caused either by the timeout issue (e.g. the response takes too much time or server is overloaded with the requests), or the client sent the SYN, but it didn't receive ACK (acknowledgment of the connection termination). For timeout issues, you can consider increasing the timeout value.The Socket Exception usually comes with the specified detail message about the issue.Example of detailed messages:This error happened to me while testing my soap service with SoapUI client, basically I was trying to get a very big message (>500kb) and SoapUI closed the connection by timeout....and put a large value, such as 180000 (3 minutes), this won't be the perfect fix for your issue because the file is in fact to large, but at least you will have a response.I was facing the same problem with wireMock while mocking the rest API calls.\nEarlier I was defining the server like this:But it should be defined like as shown below:In my case, the error was:It was received in eclipse while debugging a java application accessing a H2 database. The source of the error was that I had initially opened the database with SQuirreL to check manually for integrity. I did use the flag to enable multiple connections to the same DB (i.e. ), so there was no problem connecting to the DB from java.The error appeared when, after a while --it is a long java process-- I decided to close SQuirreL to free resources. It appears as if SQuirreL were the one \"owning\" the DB server instance and that it was shut down with the SQuirreL connection.Restarting the Java application did not yield the error again.My server was throwing this exception in the pass 2 days and I solved it by moving the disconnecting function with: To the end of the  listing thread.\nif it will helped anyone."},
{"body": "Is there an open-source Java library for parsing SQL statements?If possible, it should be customizable or flexible enough to also be able to parse (or at least ignore) vendor-specific syntax (such as Oracle tablespace definitions or MySQL's LIMIT clause).If not, strict adherence to the SQL standard is also fine. I need this for two things:  has an ANSI SQL grammar available.  You can use that to create your own parser.ANTLR4 has a .If you need a parser there should be a parser in the code base of .You may want to look at the  method on the jdbc Connection object which you can pass it vendor neutral queries that will get postprocessed into vendor specific queries. is not open source, but is exactly what you are looking after.Try Hibernate uses ANTLR for sql and hql parsing.JSqlParser is also a good option.although it has some bugs(or some features not implemented) while parsing oracle pl/sql.\nsee its forum for detail.so if you're parsing oracle pl/sql, ANTLR is recommended.What you want to do with the parsed SQL? I can recommend a few Java implementation of Lex/Yacc (, ) that you can use an existing SQL grammar with. If you want to actually do something with the resulting parsed grammar, I might suggest looking at , an open source SQL database written in Java. "},
{"body": "Having been using  now for 6+ months or so, I'm pretty happy with the new API changes. One area I'm still not confident in is when to use . I seem to swing between wanting to use it everywhere something may be , and nowhere at all.There seem to be a lot of situations when I could use it, and I'm never sure if it adds benefit (IE readability / null safety) or just causes additional overhead. So, I have a few examples, and I'd be interested in the community's thoughts on whether  adds benefit. 1 - As a public method return type when the method could return :2 - As a method parameter when the param may be :3 - As an optional member of a bean:4 - In : In general I don't think:adds anything - especially since one can use  to remove  values etc, but are there any good uses for  in collections?Any cases I've missed?The main point of  is to provide a means for a function returning a value to indicate the absence of a return value. See . This allows the caller to continue a chain of fluent method calls.This most closely matches use case  in the OP's question. Although,  is a more precise formulation than  since something like  could never return null.For use case , passing an optional argument to a method, this could be made to work, but it's rather clumsy. Suppose you have a method that takes a string followed by an optional second string. Accepting an  as the second arg would result in code like this:Even accepting null is nicer:Probably the best is to have an overloaded method that accepts a single string argument and provides a default for the second:This does have limitations, but it's much nicer than either of the above.Use cases  and , having an  in a class field or in a data structure, is considered a misuse of the API. First, it goes against the main design goal of  as stated at the top. Second, it doesn't add any value.There are three ways to deal with the absence of a value in an : to provide a substitute value, to call a function to provide a substitute value, or to throw an exception. If you're storing into a field, you'd do this at initialization or assignment time. If you're adding values into a list, as the OP mentioned, you have the additional choice of simply not adding the value, thereby \"flattening\" out absent values.I'm sure somebody could come up with some contrived cases where they really want to store an  in a field or a collection, but in general, it is best to avoid doing this.I'm late to the game but for what it's worth, I want to add my 2 Cents. They go against the , which is well summarized by , but I'm still convinced of their validity (obviously).I wrote an entire  but it basically comes down to this:The first two exceptions can reduce the perceived overhead of wrapping and unwrapping references in . They are chosen such that a null can never legally pass a boundary from one instance into another.Note that this will almost never allow s in collections which is almost as bad as s. Just don't do it. ;)Doing this reduces the presence of s in your code base, although it does not eradicate them. But that is not even the main point. There are other important advantages:Using  clearly expresses that the variable is, well, optional. Any reader of your code or consumer of your API will be beaten over the head with the fact that there might be nothing there and that a check is necessary before accessing the value.Without  the meaning of a  occurrence is unclear. It could be a legal representation of a state (see ) or an implementation error like a missing or failed initialization.This changes dramatically with the persistent use of . Here, already the occurrence of  signifies the presence of a bug. (Because if the value were allowed to be missing, an  would have been used.) This makes debugging a null pointer exception much easier as the question of the meaning of this  is already answered.Now that nothing can be  anymore, this can be enforced everywhere. Whether with annotations, assertions or plain checks, you never have to think about whether this argument or that return type can be null. It can't!Of course, there is no silver bullet...Wrapping values (especially primitives) into an extra instance can degrade performance. In tight loops this might become noticeable or even worse.Note that the compiler might be able to circumvent the extra reference for short lived lifetimes of s. In Java 10  might further reduce or remove the penalty. but a  is not overly complicated.Due to the invariance of generic types in Java, certain operations become cumbersome when the actual value type is pushed into a generic type argument. An example is given .Personally, I prefer to use  to use  and  checks as these are largely compile time (can have some runtime checks) This has lower overhead in terms of code readability and runtime performance.  It is not as rigorous as using Optional, however this lack of rigour should be backed by decent unit tests.This works with Java 5 and no need to wrap and unwrap values. (or create wrapper objects)I think the Guava Optional and their wiki page puts it quite well: adds some overhead, but I think its clear advantage is to make it  \nthat an object might be absent and it enforces that programmers handle the situation. It prevents that someone forgets the beloved  check.Taking the example of , I think it is far more explicit code to write:than For me, the  better captures the fact that there is no soundcard present.My 2\u00a2 about your points:In general, I would try to minimize passing around s. (Once burnt...) \nI think it is worth to find the appropriate abstractions and indicate to the fellow programmers what a certain return value actually represents.From :There are already several resources about this feature:Here is an interesting usage (I believe) for... Tests.I intend to heavily test one of my projects and I therefore build assertions; only there are things I have to verify and others I don't.I therefore build things to assert and use an assert to verify them, like this:In the NodeAssert class, I do this:Which means the assert really only triggers if I want to check the label!Seems  is only useful if the type T in Optional is a primitive type like , , , etc. For \"real\" classes, it does not make sense to me as you can use a  value anyway.I think it was taken from here (or from another similar language concept).In C# this  was introduced long ago to wrap value types.I do not think that Optional is a general substitute for methods that potentially return null values.The basic idea is: The absence of a value does not mean that it potentially is available in the future. It's a difference between findById(-1) and findById(67).The main information of Optionals for the caller is that he may not count on the value given but it may be available at some time. Maybe it will disappear again and comes back later one more time. It's like an on/off switch. You have the \"option\" to switch the light on or off. But you have no option if you do not have a light to switch on.So I find it too messy to introduce Optionals everywhere where previously null was potentially returned. I will still use null, but only in restricted areas like the root of a tree, lazy initialization and explicit find-methods.Java SE 8 introduces a new class called java.util.Optional,You can create an empty Optional or Optional with null value.And here is an Optional with a non-null value:Now that you have an Optional object, you can access the methods available to explicitly deal with the presence or absence of values. Instead of having to remember to do a null check, as follows:You can use the ifPresent() method, as follows:"},
{"body": "What are good reasons to prohibit inheritance in Java, for example by using final classes or classes using a single, private parameterless constructor? What are good reasons of making a method final?Your best reference here is Item 17 (15 in the first edition) of Joshua Bloch's excellent book \"Effective Java\", called \"Design and document for inheritance or else prohibit it\". You should really read it, but I'll summarize.The interaction of inherited classes with their parents can be surprising and unpredicatable if the ancestor wasn't designed to be inherited from. Classes should therefore come in two kinds :If you are writing purely internal code this may be a bit of overkill. However the extra effort involved in adding five characters to a class file is very small. If you are writing only for internal comsumption then a future coder can always remove the 'final' - you can think of it as a warning saying \"this class was not designed with inheritance in mind\".You might want to make a method final so that overriding classes can't change behavior that is counted on in other methods.  Methods called in constructors are often declared final so you don't get any unpleasant surprises when creating objects.One reason to make a class final would be if you wanted to force composition over inheritance. This is generally desirable in avoiding tight coupling between classes.you might want to make immutable objects (), you might want to create a singleton (), or you might want to prevent someone from overriding the method for reasons of efficiency, safety, or security.So that no body can extend those classes and change their behavior.Eg: Wrapper class Integer is a final class. If that class is not final, then any one can extend Integer into his own class and change the basic behavior of integer class. To avoid this, java made all wrapper classes as final classes.Inheritance is like a chainsaw - very powerful, but awful in the wrong hands. Either you design a class to be inherited from (which can limit flexibility and take a lot longer) or you should prohibit it.See Effective Java 2nd edition items 16 and 17, or my blog post .Hmmm... I can think of two things:You might have a class that deals with certain security issues. By subclassing it and feeding your system the subclassed version of it, an attacker can circumvent security restrictions. E.g. your application might support plugins and if a plugin can just subclass your security relevant classes, it can use this trick to somehow smuggle a subclassed version of it into place. However, this is rather something Sun has to deal with regarding applets and the like, maybe not such a realistic case.A much more realistic one is to avoid an object becomes mutable. E.g. since Strings are immutable, your code can safely keep references to itinstead of copying the string first. However, if you can subclass String, you can add methods to it that allow the string value to be modified, now no code can rely anymore that the string will stay the same if it just copies the string as above, instead it must duplicate the string.To stop people from doing things that could confuse themselves and others. Imagine a physics library where you have some defined constants or calculations. Without using the final keyword, someone could come along and redefine basic calculations or constants that should NEVER change.Also, if you are writing a commercial closed source class, you might not want people to be able to change the functionality down the line, especially if u need to give support for it and people have overridden your method and are complaining that calling it gives unexpected results.If you mark classes and methods as final, you may notice a small performance gain, since the runtime doesn't have to look up the right class method to invoke for a given object. Non-final methods are marked as virtual so that they can be properly extended if needed, final methods can be directly linked or compiled inline in the class.You want to make a method final so that overriding classes does not change its behavior. When you want to be able to change the behavior make the method public. When you override a public method it can be changed. "},
{"body": "If you have a jar file called  located in  and you want to use the class called  from it, how do you go about doing it from the command line?I thought it would be to go into the directory and say  but that isn't working. Any help would be appreciated.Use .You want:The  gives the following example:Their are two types of JAR file available in javaAssuming you are in the directory where  file is and that  has a  method on it:You use the following command line:Where:"},
{"body": "Say you catch an exception and get the following on the standard output (like, say, the console) if you do a  :Now I want to send this instead to a logger like, say, log4j to get the following:How can I do this?You pass the exception directly to the logger, e.g.It's up to log4j to render the stack trace.If you want to log a stacktrace without involving an exception just do this: You can also get stack trace as string via ExceptionUtils.getStackTrace.\nI use it only for log.debug, to keep log.error simple.This answer may be not related to the question asked but related to title of the question. ORORJust because it happened to me and can be useful.\nIf you do thisyou will get the header of the exception and not the whole stacktrace. Because the logger will think that you are passing a String.\nDo it without  as skaffman saidCreate this : Call this in your code"},
{"body": "I would like to know if there is such a method in Java. Take this snippet as example :To quote a :If you want it back as a string later, you can call getPath(). Indeed, if you really wanted to mimic Path.Combine, you could just write something like:You can just do One way is to get system properties that give you the path separator for the operating system,  explains how.  You can then use a standard string join using the .This is a start, I don't think it works exactly as you intend, but it at least produces a consistent result."},
{"body": "I am working with a rather large app written in .\nJSF 1.2 is around 6 years old now. I need to upgrade to JSF 2.0. How painful will this be? I noticed that some attributes in custom tags have been changed etc. Painfulness of upgrading JSF 1.2 to 2.0 depends on the view technology which you are currently using and which you want to use.Regardless of the view technology switch,  the following steps should be done:If you're using  and want to  using it, then you basically don't need to change anything else. If you're already using a suffix  for the , like , then it's good to know that the  will first scan for  file and if it is not present, then scan for  file. This provides you room to gradually convert from JSP to Facelets behind the scenes without changing the URL's. But if you're using a prefix , like  and you want to gradually upgrade from JSP to Facelets, then you really have to change it to  and possibly also all links in the existing JSP pages.You only need to keep in mind that the new JSF 2.0 provided implicit navigation doesn't scan for the presence of the file, it will go to  anyway. So if you want to come from or go to , then you still need to include it in the viewid the JSF 1.x way.If you're using  as view technology and want to use the JSF 2.0 supplied , then you need to do the following additional steps:That should basically be it.If you're using  as view technology and you want to upgrade to  immediately, then you need to do a lot of changes before the site can go live. You're basically changing the view technology here. On every master page, you need to change the following basic JSP template....to the following basic Facelets template:If your existing JSP pages are well designed, you should not have any line of  code and you should also have only the  as the sole JSP-specific tag. Any of those needs to be changed from:toThe basic JSP include page template of....should be changed to the following basic Facelets include page template:You need to change the JSP TLD files to Facelets TLD files as described in this .Regardless of the migration approach, you can gradually  the  by the new JSF 2.0 annotations. Any  can be annotated by :Next to , there are also ,  and  available. If you omit the  attribute of the , then it will default to classname with the 1st char lowercased. In this particular example, it will be .Any  can be annotated using :Any  can be annotated using :Any  can be annotated using Any  can be annotated using Any  which uses the filename of the XHTML page as both  and  can be removed since this will be  done. This can be gradually done by changing all outcome values to match the filename of the target view.Finally, any session scoped bean which was been put in the session with the sole reason to retain the bean data in subsequent requests in the same tab/window can better be marked , because this way the bean won't be affected when the enduser opens the same page in different tabs/windows.Note that I don't take any 3rd party componant libraries like PrimeFaces/RichFaces/IceFaces into account in this answer, it would then be impossible to write a reliable answer since it basically boils down to \"it depends\". In general it's sufficient to just upgrade the component library to a -by themselves verified- JSF 2.0 compatible version as per their instructions. Best is to just write unit tests, run them before and after the upgrade and fix any issues individually. Here are at least some useful links with regard to migration of the specific component library:PrimeFaces has no migration guide for PrimeFaces 1.x to 2.x as PrimeFaces 1.x requires Facelets 1.x already, so you just have to follow Facelets 1.x to 2.x migration steps. However, there's a PrimeFaces  which might apply as well on migrating from PrimeFaces 1.x to 3.x. Tomahawk has also no migration guide. Basically the only which you need to change are the JARs and if necessary get rid of all  references on a request scoped bean by making the bean view scoped.One thing to mention is that if anyone is using JSTL with JSF 1.2 then when upgrading to JSF2 you should change the namespace from:to:JSF 2.0 have many new features and components and I don't feel migration will be painful.  Only area you will find difficult is in using thrid party libraries.  If your application is heavily dependant upon libraries like Richfaces then you will face problem.  Not all the components from Richfaces 3 is ported to Richfaces 4.This also might help\nAlso check this Web.xmlStep 1: Change web.xmlStep 2: webmvc-config.xmlStep3:facess-config.xmlIf you are using Apache Trinidad you'll also have to upgrade it to version 2.0 so that it will support JSF 2.0.  There's more info at ."},
{"body": "I know how to work out the index of a certain character or number in a string, but is there any predefined method I can use to give me the character at the  position? So in the string \"foo\", if I asked for the character with index 0 it would return \"f\".Note - in the above question, by \"character\" I don't mean the char data type, but a letter or number in a string. The important thing here is that I don't receive a char when the method is invoked, but a string (of length 1). And I know about the substring() method, but I was wondering if there was a neater way.The method you're looking for is . Here's an example:For more information, see the . If you want another simple tutorial,  or .If you don't want the result as a  data type, but rather as a string, you would use the  method:If you want more information on the  class and the  method, I pulled my info from .You want returns If you're hellbent on having a string there are a couple of ways to convert a char to a string:Or Or evenFor example.You're pretty stuck with , given your requirements.  The standard way would be , but you said you won't accept a char data type.You could use  method result as parameter for . A hybrid approach combining  with your requirement of not getting  char could beBut that's not really \"neater\" than  to be honest.simple as,None of the proposed answers works for surrogate pairs used to encode characters outside of the .Here is an example using 3 different techniques to iterate over the \"characters\" of a string (incl. using Java 8 stream API). Please notice this example includes characters of the Unicode Supplementary Multilingual Plane (SMP). You need a proper font to display this example and the result correctly.The First solution is a simple loop over all  of the string:The Second solution uses an explicit loop too, but accessing individual \ncode points with  and incrementing the loop index accordingly to :The third solution is basically the same as the second, but using the :When you run that test program, you obtain:As you can see (if you're able to display hieroglyphs properly), the first solution does not handle properly characters outside of the Unicode BMP. On the other hand, the other two solutions deal well with surrogate pairs.Here's the correct code. if you're using zybooks this will answer all the problems.Like this:"},
{"body": "I'm trying to read a text file line by line using InputStream from the assets directory in Android.I want to convert the InputStream to a BufferedReader to be able to use the readLine().I have the following code:The third line drops the following error:What I'm trying to do in C would be something like:What am I doing wrong or how should I do that? Thanks! can't wrap an  directly. It wraps another . In this case you'd want to do something like:A BufferedReader constructor takes a  as argument, not an InputStream. You should first create a Reader from your stream, like so:Preferrably, you also provide a Charset or character encoding name to the StreamReader constructor. Since a stream just provides bytes, converting these to text means the encoding must be known. If you don't specify it, the system default is assumed."},
{"body": "In a few large projects i have been working on lately it seems to become increasingly important to choose one or the other (XML or Annotation). As projects grow, consistency is very important for maintainability. My question is, what do people prefer.  Do you prefer XML based or Annotation based? or Both? Everybody talks about XML configuration hell and how annotations are the answer, what about Annotation configuration hell?Annotations have their use, but they are not the one silver bullet to kill XML configuration.  I recommend mixing the two!For instance, if using Spring, it is entirely intuitive to use XML for the dependency injection portion of your application.  This gets the code's dependencies away from the code which will be using it, by contrast, using some sort of annotation in the code that needs the dependencies makes the code aware of this automatic configuration.However, instead of using XML for transactional management, marking a method as transactional with an annotation makes perfect sense, since this is information a programmer would probably wish to know.  But that an interface is going to be injected as a SubtypeY instead of a SubtypeX should not be included in the class, because if now you wish to inject SubtypeX, you have to change your code, whereas you had an interface contract before anyways, so with XML, you would just need to change the XML mappings and it is fairly quick and painless to do so.I haven't used JPA annotations, so I don't know how good they are, but I would argue that leaving the mapping of beans to the database in XML is also good, as the object shouldn't care where its information came from, it should just care what it can do with its information.  But if you like JPA (I don't have any expirience with it), by all means, go for it.In general:\nIf an annotation provides functionality and acts as a comment in and of itself, and doesn't tie the code down to some specific process in order to function normally without this annotation, then go for annotations.  For example, a transactional method marked as being transactional does not kill its operating logic, and serves as a good code-level comment as well.  Otherwise, this information is probably best expressed as XML, because although it will eventually affect how the code operates, it won't change the main functionality of the code, and hence doesn't belong in the source files.There is a wider issue here, that of externalised vs inlined meta-data. If your object model is only ever going to persisted in one way, then inlined meta-data (i.e. annotations) are more compact and readable.If, however, your object model was reused in different applications in such a way that each application wanted to persist the model in different ways, then externalising the meta-data (i.e. XML descriptors) becomes more appropriate.Neither one is better, and so both are supported, although annotations are more fashionable. As a result, new hair-on-fire frameworks like JPA tend to put more emphasis on them. More mature APIs like native Hibernate offer both, because it's known that neither one is enough.I always think about annotations as some kind of indicator of  a class is capable of, or  it interacts with others.Spring XML configuration on the other hand to me is just that, For instance, information about the ip and port of a proxy, is definetly going into an XML file, it is the runtime configuration.Using , to indicate the framework what to do with the class is good use of annotations.Putting the URL into the  annotation is bad style.But this is just my opinion.\nThe line between interaction and configuration is not always clear.I've been using Spring for a few years now and the amount of XML that was required was definitely getting tedious.  Between the new XML schemas and annotation support in Spring 2.5 I usually do these things:I think that visibility is a big win with an XML based approach.  I find that the XML isn't really that bad, given the various tools out there for navigating XML documents (i.e. Visual Studio + ReSharper's File Structure window).You can certainly take a mixed approach, but that seems dangerous to me if only because, potentially, it would make it difficult for new developers on a project to figure out where different objects are configured or mapped.I don't know; in the end XML Hell doesn't seem all that bad to me.It depends on what everything you want to configure, because there are some options that cannot be configured with anotations. If we see it from the side of annotations:It's up to you what is more important...In general I would recommend to choose one way and use it all over some closed part of product...(with some exceptions: eg if you choose XML based configurations, it's ok to use @Autowire annotation. It's mixing, but this one helps both readability and maintainability)An important part in using an annotation-only approach is that the concept of a \"bean name\" more or less goes away (becomes insignificant).The \"bean names\" in Spring form an additional level of abstraction over the implementing classes. With XML beans are defined and referenced relative to their bean name. With annotations they are referenced by their class/interface. (Although the bean name exists, you do not need to know it) I strongly believe that getting rid of superfluous abstractions simplifies systems and improves productivity. For  projects I think the gains by getting rid of XML can be substantial.I also think a mix is the best thing, but it also depends on the type of configuration parameters.\nI'm working on a Seam project which also uses Spring and I usually deploy it to different development and test servers. So I have split:The key difference is that you don't have to recompile the code for all changing server-specific configurations, just edit the xml file.\nThere's also the advantage that some configuration changes can be done by team members who don't understand all the code involved.There are other aspect to compare like refactoring and other code changes. when using XML it takes serous effort to make refactoring because you have to take care of all the XML content. But it is easy when using Annotations.My preferred way is the Java based configuration without (or minimal) annotations. I might be wrong, but I thought Annotations (as in Java's @Tag and C#'s [Attribute]) were a compile-time option, and XML was a run-time option. That to me says the are not equivalent and have different pros and cons.In the scope of DI container, I consider annotation based DI is abusing the use of Java annotation. By saying that, I don't recommend to use it widely in your project. If your project does really needs the power of DI container, I would recommend to use Spring IoC with Xml based configuration option.If it is just for a sake of Unit-test, developers should apply Dependency Inject pattern in their coding and take advantages from mocking tools such as EasyMock or JMock to circumvent dependencies.You should try to avoid using DI container in its wrong context.Configuration information that is always going to be linked to a specific Java component (class, method, or field) is a good candidate to be represented by annotations. Annotations work especially well in this case when the configuration is core to the purpose of the code. Because of the limitations on annotations, it's also best when each component can only ever have one configuration. If you need to deal with multiple configurations, especially ones that are conditional on anything outside the Java class containing an annotation, annotations may create more problems than they solve. Finally, annotations cannot be modified without recompiling the Java source code, so anything that needs to be reconfigurable at run time can't use annotations.Please refer following links. They might be useful too.This is the classic 'Configuration versus Convention' question.  Personal taste dictates the answer in most cases.  However, personally I prefer Configuration (i.e. XML based) over Convention.  IMO IDE's are sufficiently robust enough to overcome some of the XML hell people often associate w/ the building and maintaining an XML based approach.  In the end, I find the benefits of Configuration (such as building utilities to build, maintain and deploy the XML config file) outweighs Convention in the long run.  I use both. Mostly XML, but when I have a bunch of beans that inherit from a common class and have common properties, I use annotations for those, in the superclass, so I don't have to set the same properties for each bean. Because I'm a bit of a control freak, I use @Resource(name=\"referredBean\") instead of just autowiring stuff (and save myself a lot of trouble if I ever need another bean of the same class as the original referredBean).There are some pros and cons of annotation configuration from my experience:I prefer combining both approaches - java annotations and essential xml minimum that minimize configuration hell.For Spring Framework I like the idea of being able to use the @Component annotation and setting the \"component-scan\" option so that Spring can find my java beans so that I do not have to define all of my beans in XML, nor in JavaConfig.  For example, for stateless singleton java beans that simply need to be wired up to other classes (via an interface ideally) this approach works very well.  In general, for Spring beans I have for the most part moved away from Spring XML DSL for defining beans, and now favor the use of JavaConfig and Spring Annotations because you get some compile time checking of your configuration and some refactoring support that you don't get with Spring XML configuration.  I do mix the two in certain rare cases where I've found that JavaConfig/Annotations can't do what is available using XML configuration. For Hibernate ORM (haven't used JPA yet) I still prefer the XML mapping files because annotations in domain model classes to some degree violates  which is a layering architectural style I have adopted over the past few years.  The violation occurs because it requires the Core Layer to depend on persistence related things such as Hibernate or JPA libraries and it makes the domain model POJOs a bit less persistence ignorant.  In fact the Core Layer is not supposed to depend on any other infrastructure at all.However, if The Clean Architecture is not your \"cup of tea\" then I can see there are definitely advantages (such as convenience and maintainability) of using Hibernate/JPA annotations in domain model classes over separate XML mapping files."},
{"body": "I have an INTELIJ(v12) android project successfully imported to AndroidStudio(v0.4.0). It works perfectly if I don't change anything in manifest. When I want to change the launcher activity and run, it outputs with the following error:When I click  it outputs:Anyone has faced this problem? Any ideas?Run settings:\nI faced a similar problem after refactoring.\nThis is what i did to resolve this issue:And everything worked fine!\nI think the key is to .  Hope this helps you or anyone else!\nIf above steps doesn't work for you, then  seems be a solution, as pointed out by @Yasitha.  When running Android Studio 2.1 and up you can also encounter this issue when you have the instant run option enabled in your preferences (is enabled by default). To disable this option go to  option in the  top menu and look for  so you can uncheck the first checkbox on that screen.Anyway that fixed it for me. Originally pointed out by user @yusufonder. I discovered this was the issue since gradle install still worked.This happens when you do the followingAS thinks you still have the app in your device.tl;dr - To resolve this, you can simply disconnect your device after uninstalling the app and reconnect it.Right now it says:Try either  to the beginning of the Activity's name:Or  to the beginning of the Activity's name:May be helpful for someone:--Sometimes when testing on a device, . To verify and fix this:For me, the problem was that   that the app was still on the device.To fix it:make sure the  of the  is added to your !I had the same error after renaming/refactoring. What I did was add the  property attribute to my build.gradle file, and set its value to the application package. I would face this problem when uninstalling the app via the device (i.e. dragging the app to the \"Uninstall\" option). But here is the proper way to uninstall:Use the  command. This will prevent the  error.I had the same issue and I solved it refactoring my activity launcher, just change the class name and it works.Even I had the same problem but none of the above solutions worked for me.\nThe problem was that, I had froze the particular app which I was trying to run via Titanium Backup due to which I got the above error. I tried both in Eclipse and Android Studio.After the realization I just unistalled the app and then ran it again.Problem Solved :-)I also faced the same problem somewhere in the past.  Renaming and Moving files require changes in the gradle file so whenever you rename or move some file just clean the project:Cleaning the project just removes the  files and recompiles the project. Basically, it forces a project rebuild. Sometimes such types of errors did not cleaned on cleaning project then try to uninstall the app from the device (either it is emulator or physical one) and run the app again. Hope this will help you, it helps me 50% times. I face the similar Problem please follow the below steps.\nit will help you:1- Clean your Project\n2- Delete your build directory\n3- Restart your Android Studio\n4- Rebuild the project\n5- it will run successfully.  Thanksfor me, on android 6 when i uninstalled the app it actually went to disabled instead of being removed from device.Settings > Apps > click on your app and uninstallthis fixed it for mei just go to Build > Rebuild Project and my problem is solvedNone of the above worked for me.  I had a version of the app on the device that could not be uninstalled as it was corrupt somehow.  I had to factory reset the device.  Not too bothered cause it was a just a dev deviceI'd like to share the trick that helped in my case. I uninstalled the application from the device and nothing of  operations didn't help. Since Android Studio thinks that the application is still installed on the device and doesn't deploy it, you can force the installation using the ADB:where  means reinstall the app, keeping its data.As others have noted, this problem can be caused by an attached device/emulator while uninstalling the app and AS connection still exists.  On my end, I just delete all the  folders (under app and project dirs) in the project, and relaunch the application on the device/emulator.I took reference from @jayeffkay's comment.It works for me after I deleted the gradle cache files located in 2.10 is the gradle version used in my case.I had same issue. My problem fixed when I disabled instant run for Android Studio 2.1.1I had Error type 3. I managed to fix it by adding the following code below in AndroidMainfest.xml.I faced this problem lately, and tried all suggestions above, and problem was not saved. Finally I changed a NDK, and problem was solved...For me it was a very specific problem, I've got a  to test my application on, and to reset my apps data I uninstalled it on the phone, but the phone has a \"nice\" feature to don't uninstall apps immediatly so you might can reinstall them within one day.\nSo the app was installed but not usable() after removing the app from the phone completely it worked.I think another reason that issue happen is that it is not fully deleted for all users on the device.Go to Settings -> Apps - > Your Apps -> Click to the 3 dots on the top right -> Uninstall for all usersIt works for me. It happen especially you change the icons of the app or messing around with the AndroidManifest.xml file.If you're not careful and you're trying to disable something in your app manifest make sure you don't disable the app...I accidentally set  to \"false\" instead of . Wasted 2 hours searching for a solution. \"instant run\" can be found with the following steps:\nPreferences -> Build,Execution,Deployment -> Instant Run and then uncheck the checkbox \"Enable Instant Run to hot swap....\" Check if you are building hidden version. That\u2019s intended behavior for hidden app.If you want to build regular version, you need to change Build Variant in Android Studio , change it to regular.I have LG Stylus and in my test phone, application isn't remove permanently. In Settings -> Application I found debug app (which I try install and debug by AS) with adnotation turn-off. When I remove app from my phone, error disappeard."},
{"body": "I'd like to know if I can get the first element of a list or set.  Which method to use?(This is the closest you'll get to having the \"first\" element of a .  You should realize that it has absolutely no meaning for most implementations of .  This may have meaning for LinkedHashSet and TreeSet, but not for HashSet.)See the javadoc of or and check the size before using the above methods by invoking In Java >=8 you could also use the Streaming API:(Useful if the Set/List may be empty.)SortedSet has a first() method:The sorted objects must implement the Comparable interface (like String does)SetListYou can use the get(index) method to access an element from a List. Sets, by definition, simply contain elements and have no particular order. Therefore, there is no \"first\" element you can get, but it is possible to iterate through it using iterator (using the for each loop) or convert it to an array using the toArray() method. I'm surprised that nobody suggested guava solution yet:or if you expect single element:A less polished solution can even be"},
{"body": "I want to return an age in years as an int in a Java method.\nWhat I have now is the following where getBirthDate() returns a Date object (with the birth date ;-)):But since getYear() is deprecated I'm wondering if there is a better way to do this? I'm not even sure this works correctly, since I have no unit tests in place (yet).Check out , which simplifies date/time calculations (Joda is also the basis of the new standard Java date/time apis, so you'll be learning a soon-to-be-standard API). EDIT: Java 8 has  and is worth checking out.e.g. which is as simple as you could want. The pre-Java 8 stuff is (as you've identified) somewhat unintuitive.JDK 8 makes this easy and elegant:A JUnit test to demonstrate its use: Everyone should be using JDK 8 by now. All earlier versions have passed the end of their support lives.Note that the expression  is implicitly related to the system timezone (which is often overlooked by users). For clarity it is generally better to use the overloaded method  specifying an explicit timezone (here \"Europe/Paris\" as example). If the system timezone is requested then my personal preference is to write  to make the relation to the system timezone clearer. This is more writing effort but makes reading easier.Please note that the proposed and accepted Joda-Time-solution yields a different computation result for the dates shown above (a rare case), namely:I consider this as a small bug but the Joda-team has a different view on this weird behaviour and does not want to fix it (weird because the day-of-month of end date is smaller than of start date so the year should be one less). See also this closed .For comparison see the various other answers. I would not recommend using these outdated classes at all because the resulting code is still errorprone in some exotic cases and/or way too complex considering the fact that the original question sounds so simple. In year 2015 we have really better libraries.The proposed solution is simple but will sometimes fail in case of leap years. Just evaluating the day of year is not reliable.:This works similar to Java-8-solution. Just replace  by  and  by . However, getting \"today\" requires an explicit timezone reference.If you are using GWT you will be limited to using java.util.Date, here is a method that takes the date as integers, but still uses java.util.Date:I simply use the milliseconds in a year constant value to my advantage:The correct answer using  is:You could even shorten it into one line if you like. I copied the idea from , but I believe this is more correct as you see from the comments there (and it answers the question exactly).The fields birth and effect are both date fields:    This basically a modification of John O's solution without using depreciated methods. I spent a fair amount of time trying to get his code to work in in my code. Maybe this will save others that time.This is an improved version of the one above... considering that you want age to be an 'int'. because sometimes you don't want to fill your program with a bunch of libraries.Try to copy this one in your code, then use the method to get the age.With the  library :  has the date of birth. and format is whatever (defined in the following line):Here is how to format:Variable  will have the years.Elegant, , timestamp difference based  variant of Yaron Ronen solution.I am including a . It is impossible due (to possibly) different number of leap days (and seconds) in any timestamp difference. The discrepancy should be max +-1 day (and one second) for this algorithm, see test2(), whereas Yaron Ronen solution based on completely constant assumption of  can differ 10 days for a 40ty year old, nevertheless this variant is incorrect too.It is tricky, because this improved variant, using formula , returns correct results most of the time, as number of leap years in on average same between two dates.It's perhaps surprising to note that you don't need to know how many days or months there are in a year or how many days are in those months, likewise, you don't need to know about leap years, leap seconds, or any of that stuff using this simple, 100% accurate method:What about this one?Here is the java code to calculate age in year, month and days. I use this piece of code for age calculation ,Hope this helps ..no libraries used"},
{"body": "I have a situation where the return statement nested in two for loops will always be reached, theoretically. The compiler disagrees and requires a return statement outside of the for loop. I'd like to know an elegant way to optimize this method that's beyond my current understanding, none of my attempted implementations of break seem to work. Attached is a method from an assignment that generates random integers and returns the iterations cycled through until a second random integer is found, generated within a range passed into the method as an int parameter.The compiler's heuristics will never let you omit the last . If you're sure it'll never be reached, I'd replace it with a  to make the situation clear.As  you can make sure the second  statement is semantically unreachable:Compiles & runs fine. And if you ever get an  you'll know the implementation was semantically wrong, without having to explicitly throw anything.Since you asked about breaking out of two  loops, you can use a label to do that (see the example below):While an assert is a good fast solution. In general this kind of problems means that your code is too complicated. When I am looking at your code, it's obvious that you don't really want an array to hold previous numbers. You want a :Now note that what we are returning is actually the size of the set. The code complexity has decreased from quadratic to linear and it is immediately more readable.Now we can realize that we don't even need that  index:As your return value is based on the outer loop's variable you could simply alter the outer loop's condition to  and then return this last value (which you've just omitted) at the end of the function:This way you don't need to introduce code that will never be reached.Use a temp variable, for instance \"result\" , and remove the inner return. \nChange the for loop for a while loop with the proper condition. \nTo me it's always more elegant to have only one return as the last statement of the function.Maybe this is an indication that you should rewrite your code.  For example:Methods that have a return statement and have a loop/loops inside them always require a return statement outside the loop(s). Even if this statement outside the loop is never reached. In such cases, in order to avoid unnecessary return statements, you could define a variable of the respective type, an integer in your case, at the beginning of the method i.e. before and outside the respective loop(s). When the desired result inside the loop is reached, you can ascribe the respective value to this pre-defined variable and use it for the return statement outside the loop. Since you want your method to return the first result when rInt[i] equals rInt[count], implementing only the above-mentioned variable is not enough because the method will return the last result when rInt[i] equals rInt[count]. One options is to implement two \"break statements\" that are called when the we have the desired result. So, the method will look something like this:I agree that one should throw an exception where unreachable statement occurs. Just wanted to show how the same method can do this in more readable way (java 8 streams required)."},
{"body": "What is the difference between them? I know that But in sourcecode of LinkedHashSet there are only calling constructors of HashSet. So where is double-linked List and insertion order?The answer lies in  the  uses to construct the base class:And (one example of) a  constructor that takes a boolean argument is described, and looks like this:'s constructors invoke the following base class constructor:As you can see, the internal map is a . If you look inside , you'll discover the following field:This is the linked list in question.You should look at the source of the  constructor it calls... it's a special constructor that makes the backing  a  instead of just a .A HashSet is unordered and unsorted Set. LinkedHashSet is the ordered version of HashSet.The only difference between HashSet and LinkedHashSet is that LinkedHashSet maintains the insertion order. When we iterate through a HashSet, the order is unpredictable while it is predictable in case of LinkedHashSet.\nThe reason why LinkedHashSet maintains insertion order is because the underlying data structure is a doubly-linked list.HashSet:\nUnordered actually.\nif u passing the parameter meansOut Put:\nMay be  not predictable. next time another order. which produce FIFO Order.If you take a look at the constructors called from the LinkedHashSet class you will see that internally it's a LinkedHashMap that is used for backing purpose.I suggest you to use  most of the time, because it has ):You can see source test page here: All Methods and constructors are same but only one difference is LinkedHashset will maintain insertion order but it will not allow duplicates.Hashset will not maintain any insertion order.\nIt is combination of List and Set simple :)"},
{"body": "I was wondering what happens when you try to catch an StackOverflowError and came up with the following method:Now my question:Why does this method print '4'?I thought maybe it was because  needs 3 segments on the call stack, but I don't know where the number 3 comes from. When you look at the source code (and bytecode) of , it normally would lead to far more method invocations than 3 (so 3 segments on the call stack would not be sufficient). If it's because of optimizations the Hotspot VM applies (method inlining), I wonder if the result would be different on another VM.:As the output seems to be highly JVM specific, I get the result 4 using\nJava(TM) SE Runtime Environment (build 1.6.0_41-b02)\nJava HotSpot(TM) 64-Bit Server VM (build 20.14-b01, mixed mode)My question is not about why there is a cnt > 0 (obviously because  requires stack size and throws another  before something gets printed), but why it has the particular value of 4, respectively 0,3,8,55 or something else on other systems.I think the others have done a good job at explaining why cnt > 0, but there's not enough details regarding why cnt = 4, and why cnt varies so widely among different settings. I will attempt to fill that void here.Let When we first get into main, the space left over is X-M. Each recursive call takes up R more memory. So for 1 recursive call (1 more than original), the memory use is M + R. Suppose that StackOverflowError is thrown after C successful recursive calls, that is, M + C * R <= X and M + C * (R + 1) > X. At the time of the first StackOverflowError, there's X - M - C * R memory left.To be able to run , we need P amount of space left on the stack. If it so happens that X - M - C * R >= P, then 0 will be printed. If P requires more space, then we remove frames from the stack, gaining R memory at the cost of cnt++. When  is finally able to run, X - M - (C - cnt) * R >= P. So if P is large for a particular system, then cnt will be large. Let's look at this with some examples.  Suppose Then C = floor((X-M)/R) = 49, and cnt = ceiling((P - (X - M - C*R))/R) = 0. Suppose thatThen C = 19, and cnt = 2. Suppose that Then C = 20, and cnt = 3. Suppose that Then C = 19, and cnt = 2.Thus, we see that both the system (M, R, and P) and the stack size (X) affects cnt.As a side note, it does not matter how much space  requires to start. As long as there is not enough space for , then cnt will not increase, so there are no external effects.I take back what I said about . It does play a role. Suppose it requires T amount of space to start. cnt starts to increment when the leftover space is greater than T, and  runs when the leftover space is greater than T + P. This adds an extra step to the calculations and further muddies up the already muddy analysis.I finally found time to run some experiments to back up my theory. Unfortunately, the theory doesn't seem to match up with the experiments. What actually happens is very different.Experiment setup:\nUbuntu 12.04 server with default java and default-jdk. Xss starting at 70,000 at 1 byte increments to 460,000.The results are available at: \nI've created another version where every repeated data point is removed. In other words, only points that are different from the previous are shown. This makes it easier to see anomalies. This is the victim of bad recursive call. As you are wondering why the value of  varies, it is because the stack size depends on the platform. Java SE 6 on Windows has a default stack size of 320k in the 32-bit VM and 1024k in the 64-bit VM. You can read more .You can run using different stack sizes and you will see different values of  before the stack overflows-You don't see the value of  being printed multiple times even though the value is greater than 1 sometimes because your print statement is also throwing error which you can debug to be sure through Eclipse or other IDEs.You can change the code to the following to debug per statement execution if you'd prefer-As this getting a lot more attention, let's have another example to make things clearer-We created another method named  to do a bad recursion and removed the  statement from the catch block so it doesn't start throwing another set of errors while trying to print. This works as expected. You can try putting  statement after  above and compile. Then run multiple times. Depending on your platform, you may get different values of .This is why generally we do not catch errors because mystery in code is not fantasy.The behavior is dependent upon the stack size (which can be manually set using . The stack size is architecture specific. From JDK 7 :So when the  is thrown, the error is caught in catch block. Here  is another stack call which throws exception again. This gets repeated.  - Well it depends on when JVM thinks it is no longer stackoverflow. And that depends on the stack size of each function call (difficult to find) and the . As mentioned above default total size and size of each function call (depends on memory page size etc) is platform specific. Hence different behavior.Calling the  call with  gives me . Hence the correlataion.I think the number displayed is the number of time the  call throws the  exception.It probably depend on the implementation of the  and the number of stacking call it is made in it.As an illustration:The  call trigger the  exception at call i.\nThe i-1 call of main catch the exception and call  which trigger a second .   get increment to 1.\nThe i-2 call of main catch now the exception and call .  In  a method is called triggering a 3rd exception.   get increment to 2.\n  this continue until  can make all its needed call and finally display the value of .This is then dependent of the actual implementation of .For the JDK7 either it detect cycling call and throws the exception earlier either it keep some stack resource and throw the exception before reaching the limit to give some room for remediation logic either the  implementation doesn't make calls either the ++ operation is done after the  call thus is by pass by the exception. After digging around for a while, I can't say that I find the answer, but I think it's quite close now.First, we need to know when a  will be thrown. In fact, the stack for a java thread stores frames, which containing all the data needed for invoking a method and resume. According to , when invoking a method,Second, we should make it clear what is \"\". According to ,So, when a frame is created, there should be enough heap space to create a stack frame and enough stack space to store the new reference which point to the new stack frame if the frame is heap allocated.Now let's go back to the question. From the above, we can know that when a method is execute, it may just costs the same amount of stack space. And invoking  (may) needs 5 level of method invocation, so 5 frames need to be created. Then when  is thrown out, it has to go back 5 times to get enough stack space to store 5 frames' references. Hence 4 is print out. Why not 5? Because you use . Change it to , and then you will get 5.And you will notice that when the size of stack go to a high level, you will get 50 sometimes. That is because the amount of available heap space need to be taken into consideration then. When the stack's size is too large, maybe heap space will run out before stack. And (maybe) the actual size of stack frames of  is about 51 times of , therefore it goes back 51 times and print 50.This is not exactly an answer to the question but I just wanted to add something to the original question that I came across and how I understood the problem:In the original problem the exception is caught where it was possible:For example with jdk 1.7 it is caught at first place of occurence.but in earlier versions of jdk it looks like the exception is not being caught at the first place of occurence hence 4, 50 etc..Now if you remove the try catch block as followingThen you will see all the values of  ant the thrown exceptions (on jdk 1.7).I used netbeans to see the output, as the cmd will not show all the output and exception thrown."},
{"body": "Is there any performance reason to declare method parameters final in Java?As in:Versus:Assuming that  is only read and never modified in .The final keyword does not appear in the class file for local variables and parameters, thus it cannot impact the runtime performance.  It's only use is to clarify the coders intent that the variable not be changed (which many consider dubious reason for its usage), and dealing with anonymous inner classes.There is a lot of argument over whether the final modifier on the method itself has any performance gain since the methods will be inlined by the optimizing compiler at runtime anyway, regardless of the modifier.  In this case it should also only be used to restrict the overriding of the method.The only benefit to a final parameter is that it can be used in anonymous nested classes.  If a parameter is never changed, the compiler will already detect that as part of it's normal operation even without the final modifier.  It's pretty rare that bugs are caused by a parameter being unexpectedly assigned - if your methods are big enough to need this level of engineering, make them smaller - methods you call can't change your parameters.I can't think of a reason why the compiler would care if you declared a method parameter final or not.But the real answer to this question is - write two functions, one with final parameters and one with regular parameters. Run them a million times each and see if there's any noticeable runtime difference. If you're worried about performance, it's very important to do some profiling work on your code and find out exactly what is slowing you down. It's almost certainly not what you would expect it to be :)Compilers that operate after class loading, such as JIT compilers, can take advantage of final methods. Consequently, methods declared final could have some performance benefit. Oh and another good resourceI would suggest you never write micro benchmarks. You do not know which optimization the JIT can do and when, and you would likely get a wrong idea of how it behave just doing a \"simple test case\"I assume the compiler could possibly remove all private static final variables that has a primitive type, such as int, and inline them directly in the code just like with a C++ macro.However, i have no clue if this is done in practice, but it could be done in order to save some memory. Just one more point that to above that using non-final local variables declared within the method\u2014the inner class instance may outlive the stack frame, so the local variable might vanish while the inner object is still aliveparameters (means the object's identity, not its state)."},
{"body": "Do interfaces inherit from  class in Java?If no then how we are able to call the method of object class on interface instanceNo, they don't. And there is no common \"root\" interface implicitly inherited by all interfaces either (as in the case with classes) for that matter.An interface implicitly declared one method for each public method in . Thus the  method is implicitly declared as a member in an interface (unless it already inherits it from a superinterface).This is explained in detail in the Java Language Specification, .This post has been rewritten as an article .There is actually a superclass field in every  file, including those that represent interfaces.For an interface it always points to .  But that isn't used for anything.Another way to look at it is:Here the cast  is always valid, which implies that every interface type is a subtype of . is a supertype of any interface [1] However, an interface does not , , or,  .JLS has a special clause to add  methods into interfaces [2][1] [2] \nNo Interface does not inherits Object class,but it provide accessibility to all methods of Object class. \nThe members of an interface are:, . It is a compile-time error if the interface explicitly declares such a method m in the case where m is declared to be final in Object.Now it is clear that all superinterface have abstract member method corresponding to each public instance method declared in Object .\nsource:\n\". Classes, enums, arrays, and \"Quoted from: \nSecond sentence to be clear.You are calling the equals method on the Object which implements the Interface.Any class implementing any interface is also derived from  as well by definition.That's because  reads that there is a class that  , and is assigned to variable . Every class that implements an interface extends Object implicitly, hence when you do , the language knows that you have a class that is a subtype of . The JVM will do runtime checking for your code (i.e. throw )."},
{"body": "Is it possible to do something similar to the following code in JavaSadly - no.  The closest you can do is:Of course, you can wrap this up in library methods if you feel the need to (it's unlikely to cut down on length much), but at the syntax level there isn't anything more succinct available. has a method that does something similar called .This is more helpful when you have something likesince it saves you from either calling the potentially expensive method twice or declaring a local variable in your code to reference twice.Short answer: The best you can do is to create a static utility method (so that it can be imported using  syntax)The above is equivalent to Guava's method  by @ColinD, but that can be extended more in generalNo, and be aware that workaround functions are not exactly the same, a true null coalescing operator short circuits like && and || do, meaning it will only attempt to evaluate the second expression if the first is null., from Apache Commons Lang 3 is another option. I prefer this becuase unlike Guava, this method does not throw an . It will simply return ;Primitives in Java can never be null, so that statement does not make sense conceptually. However, the wrapper classes (Integer, Character, etc.), as well as any other instantiable class can be null.Besides that fact, there isn't any short-hand syntax for a null coalescing operator. You must use the expanded form."},
{"body": "Is it still worth to add the log4j library to a Java 5 project just to log\nlet's say some exceptions to a file with some nice rollover settings.\nOr will the standard util.logging facility do the job as well?What do you think?I'd say you're probably fine with util.logging for the needs you describe.For a good decision tree, have a look at That said, pretty much every project these days seems to wind up including log4j, if only because some other library uses it.I recommend that you use the  (SLF4J). It supports different providers that include Log4J and can be used as a replacement for Apache Commons Logging.Log4j has been around for a long time, and it works very well.  I have no scientific study to back it, but based on what I've seen at a large number of clients, it is easily the logging framework that I see used more than any other.  It has been around for a long time, and not been replaced by the Next Big Logging Framework, which says something.  It is dead simple to set up, and easy to learn the basic appenders (outputs).  There are a whole host appenders that are available, including:Plus others.  It isn't difficult to write your own appender either.  Additionally there is a great deal of flexibility in each of the appenders that allow you to control specifically what is output in your log.One note, I had a series of classloader problems when I used apache commons logging in addition to log4j.  It was only for one specific application, but I found it simpler to use log4j alone, rather than to have the flexibility offered when using an abstraction layer like commons logging.    See this article for\n:Good luck!java.util.logging offers a comprehensive logging package without the excess baggage some of the others provide..log4j is a much nicer package overall, and doesn't have some of the hiccups that java.util.logging contains.  I'd second that using log4j directly is easier than using the commons logging.I recommend using  as your logging interface. That way you have the flexibility to switch logging implementations anytime you want without requiring any code changes on your end.I would go with log4j. The possibilites with log4j is not obsolete at all!"},
{"body": "How do you remove a cookie in a Java servlet?I tried this:\nEDIT: The following now works successfully it appears to be the combination of:andBefore I was doing:Which expires the cookie when the browser is closed as per .The full working snippet to expire a cookie is:The MaxAge of -1 signals that you want the cookie to persist for the duration of the session. You want to set MaxAge to 0 instead.From the :In my environment, following code works. Although looks redundant at first glance,  and  are necessary to clear the cookie properly.    Keep in mind that a cookie is actually defined by the tuple of it's name, path, and domain.  If any one of those three is different, or there is more than one cookie of the same name, but defined with paths/domains that may still be visible for the URL in question, you'll still see that cookie passed on the request.  E.g. if the url is \"\", you'll see any cookies defined on bar.com or foo.bar.com, or with a path of \"/\" or \"/baz\".Thus, what you have looks like it should work, as long as there's only one cookie defined in the client, with the name \"SSO_COOKIE_NAME\", domain \"SSO_DOMAIN\", and path \"/\".  If there are any cookies with different path or domain, you'll still see the cookie sent to the client.To debug this, go into Firefox's preferences -> Security tab, and search for all cookies with the SSO_COOKIE_NAME.  Click on each to see the domain and path.  I'm betting you'll find one in there that's not quite what you're expecting.This is code that I have effectively used before, passing  as the strPath parameter.did that not worked? This removes all cookies if response is send back."},
{"body": "I tried searching using Google Search and Stack\u00a0Overflow, but it didn't show up any results. I have seen this in opensource library code:What does \"|=\" (  ) mean? reads the same way as .is the same aswhere  is the bit-wise OR operator.All operators are referenced .A bit-wise operator is used because, as is frequent, those constants enable an int to carry flags.If you  at those constants, you'll see that they're in powers of two :So you can use bit-wise OR to add flagssosimply means we add a flag.And symmetrically, we test a flag is set using  :You have already got sufficient answer for your question. But may be my answer help you more about  kind of binary operators.    I am writing table for :\nFollowing are valid:  note all operators are binary operators.    Also     It's a shortening for this:And  is a bit-wise OR. is the  operator, and it is being applied like . I was looking for an answer on what  does in Groovy and although answers above are right on they did not help me understand a particular piece of code I was looking at.In particular, when applied to a boolean variable \"|=\" will set it to TRUE the first time it encounters a truthy expression on the right side and will HOLD its TRUE value for all |= subsequent calls. Like a latch.Here a simplified example of this:Output::\nWhy is this useful?Consider a situation where you want to know if anything has changed on a variety of objects and if so notify some one of the changes. So, you would setup a  boolean and set it to   and then  etc.\nHere is a brief example:Note: ||= does not exist. (logical or)\nYou can use or"},
{"body": "i got a tricky one:I can't set valid breakpoints. Not in Tests, neither in my Java Classes. I searched Stackoverflow and google, but I couldn't find anybody with the same problem.I'm using STS(x86) and Maven. It may seem confusing but I solved it by myself.\nI have to go Run-> Skip all Breakpoints (it was set, and I wonder how it was set, because I didn't do it)There is a menu entry you have discovered for yourself that toggles the skipping of all breakpoints. There is also an icon for this in the \"Breakpoints\" View, and there may be a hot-key defined as well, all of which you may have triggered by accident.Take a look at the .Screenshot of the 'skip all breakpoints' in eclipse.When you click on 'skip all breakpoints'(which is selected), everything will become normal    The shortcut key for placing a breakpoint in Eclipse (Ctrl + Shift + B) is quite similar to the one that skips all the breakpoint (Ctrl + Alt + B). Hence, if a \"skip all breakpoints\" condition is to be cancelled, it can be achieved by pressing \"Ctrl + Alt + B\" again.1) Run => Skip all breakpoints.\n2) Run => remove all break points.and then your debugger wont show cross sign and will keep debugging your app.I followed these steps below to fix this"},
{"body": "For example why can you do:But not:And you can do:But not: is a primitive type. Variables of type  store the actual binary value for the integer you want to represent.  doesn't make sense because  is  a class and therefore doesn't have any methods. is a class, no different from any other in the Java language. Variables of type  store  to  objects, just as with any other reference (object) type.  is a call to the static method  from class  (note that this method actually returns an  and not an ).To be more specific,  is a class with a single field of type . This class is used where you need an  to be treated like any other object, such as in generic types or situations where you need nullability.Note that every primitive type in Java has an equivalent  class: Wrapper classes inherit from Object class, and primitive don't. So it can be used in collections with Object reference or with Generics.Since java 5 we have autoboxing, and the conversion between primitive and wrapper class is done automatically.  Beware, however, as this can introduce subtle bugs and performance problems; being explicit about conversions never hurts.Integer is a class and int is a primitive type.Read up on at these links: An Integer is pretty much just a wrapper for the primitive type int. It allows you to use all the functions of the Integer class to make life a bit easier for you.If you're new to Java, something you should learn to appreciate is the Java documentation. For example, anything you want to know about the  is documented in detail.This is straight out of the documentation for the Integer class:  refers to wrapper type in Java whereas  is a primitive type. Everything except primitive data types in Java is implemented just as objects that implies Java is a highly qualified pure object-oriented progamming language. If you need, all primitives types are also available as wrapper types in Java. You can have some performance benefit with primitive types and hence wrapper types should be used only when there is absolutely necessary.In your example as below.the constant  is being  ( and  occurs automatically from  onwards) to  and therefore you can use the statement like that and also . This is actually achieved through the statement Integer is an wrapper class/Object and int is primitive type. This difference plays huge role when you want to store int values in a collection, because they accept only objects as values (until jdk1.4). JDK5 onwards because of autoboxing it is whole different story. is a primitive type that represent an integer. whereas  is an Object that wraps . The  object gives you more functionality, such as converting to hex, string, etc.You can also use OOP concepts with . For example, you can use Integer for generics (i.e. ).int is a primitive type and not an object. That means that there are no methods associated with it. Integer is an object with methods (such as parseInt).With newer java there is functionality for auto boxing (and unboxing). That means that the compiler will insert Integer.valueOf(int) or integer.intValue() where needed. That means that it is actually possible to writewhich is interpreted asAn int variable holds a 32 bit signed integer value. An Integer (with capital I) holds a reference to an object of (class) type Integer, or to null.Java automatically casts between the two; from Integer to int whenever the Integer object occurs as an argument to an int operator or is assigned to an int variable, or an int value is assigned to an Integer variable. This casting is called boxing/unboxing.If an Integer variable referencing null is unboxed, explicitly or implicitly, a NullPointerException is thrown.To optimize the Java code runtime,   has been added including ,  etc. but they come along with there  so that if needed you can convert and use them as standard Java object along with many utility that comes as their member functions (such as ).In Java int is a primitive data type while Integer is a Helper class, it is use to convert for one data type to other.For example:Primitive data types are store the fastest available memory where the Helper class is complex and store in heap memory.reference from \"David Gassner\" Java Essential Training. is a primitive data type while  is a Reference or Wrapper Type (Class) in Java.after  which introduce the concept of  and  you can initialize both  or  like this. is a Class defined in  library and  is a static method belongs to  ClassSo,  is possible in java. but  is primitive type (assume like a keyword) in java. So, you can't call  with ."},
{"body": "I am wanting to create an array of arraylist like below:But it's not compiling. How can I do this?As per :Instead, you could do:As suggested by Tom Hawting - tackline, it is even better to do:As the others have mentioned it's probably better to use another list to store the ArrayList in but if you have to use an array:This works:You can create a class extending ArrayListand then create the arrayI totally do not get it, why everyone is suggesting the genric type over the array particularly for this question.What if my need is to index  different arraylists.With declaring  I need to create   objects manually or put a for loop to create  lists or some other way, in any way it will always be my duty to create  lists.Isn't it great if we declare it through casting as . I see it as a good design where one do not have to create all the indexing object (arraylists) by himselfCan anyone enlighten me why this (arrayform) will be a bad design and what are its disadvantages?The problem with this situation is by using a arraylist you get a time complexity of o(n) for adding at a specific position. If you use an array you create a memory location by declaring your array therefore it is constantYou can create Array of ArrayListThis will be help full in scenarios like. You know the size of the outer one . But the size of inner ones varies. Here you can create array of fixed length. which contain size varying Array lists. Hope this will be helpful for youYou can't create array of generic type. Create List of ArrayLists :or if you REALLY need array (WARNING: bad design!):This works, array of ArrayList. Give it a try to understand how.Credits to Kelvincer for some of codes.To declare an array of ArrayLists statically for, say, sprite positions as Points:dynamically:Despite the cautions and some complex suggestions here, I have found an array of ArrayLists to be an elegant solution to represent related ArrayLists of the same type.I find this easier to use...ArrayList[] lists = (ArrayList[])new ArrayList[10]; You can do this ://Create an Array of type ArrayList//For each element in array make an ArrayListyou can create a List[] and initialize them by for loop. it compiles without errors:it works with arrayList[] l as well."},
{"body": "My code here detects if the  is equals to some  type, if it is, it will do a certain conversionI have shortened my code, because it has a lot of  statements, What design pattern is suitable for removing many  and  or  statements?You could have a  interface. Then you could create a class for each Mimetype like:You would need a class like this for each converter. Then you could set up a map like this:Then your  method becomes like this:Using this approach you could easily add different converters in the future.All untested, probably doesn't compile, but you get the ideaIf you use pre-JDK7, you may add an enum for all  types:And have a look at the Stack Overflow question  on how to convert Strings to enums.Consider using the Strategy design pattern and a  to dispatch to the appropriate strategy. Particularly useful if you you will need additional functionality, in addition to a conversion for a particular , or the convertors are large and complicated code and you would want to place each convertor in its own  file.If you run the  you should check If you are using , you can use  construct:See: For prior versions,  is the only choice.It's definitely a Strategy design pattern. But you have a big problem in your general design. It's not a good programming habit to use String to identify a type. Simply because it's easily editable and you can make a grammar mistake and spend all the afternoon looking for a programming mistake. You can avoid using map<>.I suggest the following:This design is scalable and you can add as much as you need FileType and converters.\nThe answer you vote for is misleading!!!!\nThere is a big difference between coding and hacking.If you are not using Java 7 you could create an  and use that value with a  case. You then only need to pass the enum value (rather than a file, I don't why you are doing that). It would look neater too.These should help with what you want to do:"},
{"body": "What does  mean in Java?  I'm in the process of learning. In all the examples in the book I'm working from  comes before any method that is being used or created. What does this mean? It's three completely different things: means that the method is visible and can be called from other objects of other types. Other alternatives are private, protected, package and . See  for more details. means that the method is associated with the class, not a specific instance (object) of that class. This means that you can call a static method without creating an object of the class. means that the method has no return value. If the method returned an  you would write  instead of .The combination of all three of these is most commonly seen on the  method which most tutorials will include.The three words have orthogonal meanings. means that the method will be visible from classes in other packages. means that the method is not attached to a specific instance, and it has no \"\". It is more or less a function. is the return type. It means \"this method returns nothing\".The  keyword is an access specifier, which allows the programmer to control the visibility of class members. When a class member is preceded by public, then that member may be accessed by code outside the class in which it is declared. (The opposite of public is private, which prevents a member from being used by code defined outside of its class.) In this case,  must be declared as public, since it must be called by code outside of its class when the program is started. The keyword  allows  to be called without having to instantiate a particular instance of the class. This is necessary since  is called by the Java interpreter before any objects are made. The keyword  simply tells the compiler that  does not return a value. As you will see, methods may also return values.It means that:You'd think that the lack of a return means it isn't doing much, but it might be saving things in the database, for example.It means three things.First  means that any other object can access it. means that the class in which it resides doesn't have to be instantiated first before the function can be called. means that the function does not return a value.Since you are just learning, don't worry about the first two too much until you learn about classes, and the third won't matter much until you start writing functions (other than main that is).Best piece of advice I got when learning to program, and which I pass along to you, is don't worry about the little details you don't understand right away.  Get a broad overview of the fundamentals, then go back and worry about the details.  The reason is that you have to use some things (like ) in your first programs which can't really be explained well without teaching you about a bunch of other stuff first.  So, for the moment, just accept that that's the way it's done, and move on.  You will understand them shortly.Considering the typical top-level class. Only public and no modifier access modifiers may be used at the top level so you'll either see public or you won't see any access modifier at all.  `static`` is used because you may not have a need to create an actual object at the top level \n(but sometimes you will want to so you may not always see/use static. There are other reasons why you wouldn't include static too but this is the typical one at the top level.) is used because usually you're not going to be returning a value from the top level (class). (sometimes you'll want to return a value other than  so void may not always be used either especially in the case when you have declared, initialized an object at the top level that you are assigning some value to).\nI'm a newbie myself so if this answer is wrong in any way please don't hang me. By day I'm a tech recruiter not a developer; coding is my hobby. Also, I'm always open to constructive criticism and love to learn so please feel free to point out any errors. - means that the class (program) is available for use by any other class. - creates a class. Can also be applied to variables and methods,making them class methods/variables instead of just local to a particular instance of the class. - this means that no product is returned when the class completes processing. Compare this with helper classes that provide a return value to the main class,these operate like functions; these do not have void in the declaration. means that the method is associated with the class, not a specific instance (object) of that class. This means that you can call a static method without creating an object of the class.\nBecause of use of a  keyword  is your first method to be invoked..\n doesn't need to any object to instance...\nso, is called by the Java interpreter before any objects are made."},
{"body": "Imagine I'm in a Service that already has a background thread. Can I do a request using volley in that same thread, so that callbacks happen synchronously?There are 2 reasons for this: \n- First, I do not need another thread and it would be a waste to create it.\n- Second, if I'm in a ServiceIntent, the execution of the thread will finish before the callback, and therefor I will have no response from Volley. I know I can create my own Service that has some thread with a runloop I can control, but it would be desirable having this functionality in volley.Thank you!It looks like it is possible with Volley's  class. For example, to create a synchronous JSON HTTP GET request, you can do the following:Note @Matthews answer is correct BUT if you are on another thread and you do a volley call when you have no internet,  (Therefore if that thread is an IntentService, you will never be able to send another message to it and your service will be basically dead).Use the version of  that has a timeout  and catch the error to exit your thread.To match @Mathews answer:Below I wrapped it in a method & use a different request:It is probably recommended to use the Futures, but if for whatever reason you don't want to, instead of cooking your own synchronized blocking thing you should use a . So that would work like this..As a complementary observation to both @Blundells and @Mathews answers, I'm not sure  call is delivered to anything  the main thread by Volley.Having a look at the  it seems the  is using a  to execute the request and a  to deliver the result (the  is injected into the ). The  is in turn created with a  spawn from the main thread (somewhere around line 112 in the  implementation).Somewhere about line 135 in the  it seems like also successful results are delivered through the same  as any errors. Again; a  based on a  spawn from the main thread.For the use-case where a request is to be made from an  it's fair to assume that the thread of the service should block until we have a response from Volley (to guarantee a living runtime scope to handle the result in).One approach would be to override the default way a , where an alternative constructor is used instead, injecting a  which spawns from the  thread rather than the main thread. I haven't investigated the implications of this, however.I use a lock to achieve that effect now im wondering if its correct my way\nanyone want to comment ?I want to add something to Matthew's accepted answer. While  might seem to make a synchronous call from the thread you created it, it does not. Instead, the call is executed on a background thread.\nFrom what I understand after going through the library, requests in the  are dispatched in its  method:Now both  and  classes extend thread. So effectively a new worker thread is spawned for dequeuing the request queue and the response is returned to the success and error listeners implemented internally by .\nAlthough your second purpose is attained but you first purpose is not since a new thread is always spawned, no matter from which thread you execute .\nIn short,  Correct me if I am wrong."},
{"body": "Difference between UTF-8 and UTF-16?\nWhy do we need these?I believe there are a lot of good articles about this around the Web, but here is a short summary.Both UTF-8 and UTF-16 are variable length encodings. However, in UTF-8 a character may occupy a minimum of 8 bits, while in UTF-16 character length starts with 16 bits.Main UTF-8 pros:Main UTF-8 cons:Main UTF-16 pros:Main UTF-16 cons:In general, UTF-16 is usually better for in-memory representation because BE/LE is irrelevant there (just use native order) and indexing is faster (just don't forget to handle surrogate pairs properly). UTF-8, on the other hand, is extremely good for text files and network protocols because there is no BE/LE issue and null-termination often comes in handy, as well as ASCII-compatibility.They're simply different schemes for representing Unicode characters.Both are variable-length - UTF-16 uses 2 bytes for all characters in the basic multilingual plane (BMP) which contains most characters in common use.UTF-8 uses between 1 and 3 bytes for characters in the BMP, up to 4 for characters in the current Unicode range of U+0000 to U+1FFFFF, and is extensible up to U+7FFFFFFF if that ever becomes necessary... but notably all ASCII characters are represented in a single byte each.For the purposes of a message digest it won't matter which of these you pick, so long as everyone who tries to recreate the digest uses the same option.See  for more about UTF-8 and Unicode.(Note that all Java characters are UTF-16 code points within the BMP; to represent characters above U+FFFF you need to use surrogate pairs in Java.)This is unrelated to UTF-8/16 (in general, although it does convert to UTF16 and the BE/LE part can be set w/ a single line), yet below is the fastest way to convert String to byte[]. For instance: good exactly for the case provided (hash code). String.getBytes(enc) is relatively slow. Simple way to differentiate UTF-8 and UTF-16 is to identify commonalities between them.Other than sharing same unicode number for given character, each one is their own format."},
{"body": "I am trying to return 2 values from a Java method but I get these errors. Here is my code:Error:Java Result: 1Instead of returning an array that contains the two values or using a generic  class, consider creating a class that represents the result that you want to return, and return an instance of that class. Give the class a meaningful name. The benefits of this approach over using an array are type safety and it will make your program much easier to understand.Note: A generic  class, as proposed in some of the other answers here, also gives you type safety, but doesn't convey what the result represents.Example (which doesn't use really meaningful names):Java does not support multi-value returns. Return an array of values.You could implement a generic  if you are sure that you just need to return two values:and then have the method return that :You can only return one value in Java, so the neatest way is like this:Here's an updated version of your code:Try this :you have to use collections to return more then one return valuesin your case you write your code asYou don't need to create your own class to return two different values. Just use a HashMap like this:You even have the benefit of type safety.In my opinion the best is to create a new class which constructor is the function you need, e.g.:Then simply use the constructor as you would use the function:and you can use pR.sth1, pR.sth2 as \"2 results of the function\"You also can send in mutable objects as parameters, if you use methods to modify them then they will be modified when you return from the function. It won't work on stuff like Float, since it is immutable.The result is:\nRutgerUse a Pair/Tuple type object , you don't even need to create one if u depend on Apache commons-lang. Just use the  class."},
{"body": "I'm making a Java application with an application-logic-thread and a database-access-thread.\nBoth of them persist for the entire lifetime of the application and both need to be running at the same time (one talks to the server, one talks to the user; when the app is fully started, I need  of them to work).However, on startup, I need to make sure that initially the app thread waits until the db thread is ready (currently determined by polling a custom method ).\nI wouldn't mind if app thread blocks until the db thread was ready. doesn't look like a solution - the db thread only exits at app shutdown. kind of works, but the empty loop consumes a lot of processor cycles.Any other ideas? Thanks.I would really recommend that you go through a tutorial like  before you commence in the magical world of multithreading.There are also a number of good books out (google for \"Concurrent Programming in Java\", \"Java Concurrency in Practice\".In your code that must wait for the , you must have something like this:In your 's method, you would need to do something like this:The  I'm using in these examples is preferably the object that you need to manipulate concurrently from  each thread, or you could create a separate  for that purpose (I would not recommend making the methods themselves synchronized):\nThere are other (sometimes better) ways to do the above, e.g. with , etc. Since Java 5 there are a lot of nifty concurrency classes in the  package and sub-packages. You really need to find material online to get to know concurrency, or get a good book. Use a  with a counter of 1.Now in the app thread do-In the db thread, after you are done, do - Requirement ::  Answer :: Job Done!! See example belowOutput of this program ::You can see that  takes 6sec before finishing its task which is greater than other thread. So Future.get() waits until the task is done.If you don't use future.get() it doesn't wait to finish and executes based time consumption.Good Luck with Java concurrency.Try  class out of the  package, which provides higher level synchronization mechanisms, that are far less error prone than any of the low level stuff.You could do it using an  object shared between the two threads:And in the second thread:As others have said, do not take this light-hearted and just copy-paste code. Do some reading first.Use this class like this then: Create a ThreadEvent:In the method this is waiting for results:And in the method that is creating the results after all the results have been created:(Sorry for editing this post, but this code has a very bad race condition and I don't have enough reputation to comment)You can only use this if you are 100% sure that signal() is called after await(). This is the one big reason why you cannot use Java object like e.g. Windows Events.The if the code runs in this order:then . This is because Object.notify() only wakes up one of the currently running threads. A thread waiting later is not awoken. This is very different from how I expect events to work, where an event is signalled until a) waited for or b) explicitly reset.Note: Most of the time, you should use notifyAll(), but this is not relevant to the \"wait forever\" problem above.The  interface from the  package is designed to provide access to results calculated in another thread.Take a look at  and  for a ready-made way of doing this kind of thing.I'd strongly recommend reading  to anyone interested in concurrency and multithreading. It obviously concentrates on Java, but there is plenty of meat for anybody working in other languages too.This applies to all languages:You want to have an event/listener model.  You create a listener to wait for a particular event.  The event would be created (or signaled) in your worker thread.  This will block the thread until the signal is received instead of constantly polling to see if a condition is met, like the solution you currently have.Your situation is one of the most common causes for deadlocks- make sure you signal the other thread regardless of errors that may have occurred.  Example- if your application throws an exception- and never calls the method to signal the other that things have completed.  This will make it so the other thread never 'wakes up'.I suggest that you look into the concepts of using events and event handlers to better understand this paradigm before implementing your case.Alternatively you can use a blocking function call using a mutex- which will cause the thread to wait for the resource to be free.  To do this you need good thread synchronization- such as: If you want something quick and dirty, you can just add a Thread.sleep() call within your while loop.  If the database library is something you can't change, then there is really no other easy solution.  Polling the database until is ready with a wait period won't kill the performance.Hardly something that you could call elegant code, but gets the work done.In case you can modify the database code, then using a mutex as proposed in other answers is better.You could read from a blocking queue in one thread and write to it in another thread.Since You can consider other alternatives:A lot of correct answers but without a simple example.. Here is an easy and simple way of to use :This idea can apply?. If you use CountdownLatches or Semaphores works perfect but if u are looking for the easiest answer for an interview i think this can apply."},
{"body": "I installed JDK using apt-get install. I dont know where my jdk folder is. I need to set the path for that. Does any one has a clue on the location?This depends a bit from your package system ... if the  command works, you can type  to find the location of the java command. On the OpenSUSE system I'm on now it returns  (but this is not a system which uses ).On Ubuntu, it   for OpenJDK, and in some other subdirectory of  for Suns JDK (and other implementations as well, I think).For any given package you can determine what files it installs and where it installs them by querying dpkg.  For example for the package 'openjdk-6-jdk': will tell you which java implementation is the default for your system and where in the filesystem it is installed. Check the manual for more options.should give you something likeThis question will get moved but you can do the followingorUse find to located it.  It should be under  somewhere:Another best way to find Java folder path is to use  command in Fedora Linux (I know its for Ubuntu but I hit this post from google just by its headline). Just want to share incase people like me looking for answers for fedora flavour.To display all information regarding javaon OpenSUSE 13.1/13.2 its: \nversion-number can be 1.7.x 1.8.x etc. check software manager witch version you have installed...  Andr\u00e9 Simple, try it:It's /"},
{"body": "Is there an easy way (aka: not using a proxy) to get access to the raw request/response XML for a webservice published with JAX-WS reference implementation (the one included in JDK 1.5 and better) ?\nBeing able to do that via code is what I need to do.\nJust having it logged to a file by clever logging configurations would be nice but enough.I know that other more complex and complete frameworks exist that might do that, but I would like to keep it as simple as possible and axis, cxf, etc all add considerable overhead that I want to avoid.Thanks!Following options enable logging of all communication to the console (technically, you only need one of these, but that depends on the libraries you use, so setting all four is safer option). You can set it in the code like in example, or as command line parameter using -D or as environment variable as Upendra wrote.See question  for details.Here is the solution in raw code (put together thanks to stjohnroe and Shamik):Where SOAPLoggingHandler is (ripped from linked examples):Before starting tomcat, set  as below in Linux envs. Then start Tomcat. You will see the request and response in the  file.There are various ways of doing this programmatically, as described in the other answers, but they're quite invasive mechanisms. However, if you know that you're using the JAX-WS RI (aka \"Metro\"), then you can do this at the configuration level.  on how to do this. No need to mess about with your application.// This solution provides a way programatically add a handler to the web service clien w/o the XML config// See full doc here: // Create new class that implements SOAPHandler// Programatically add your LogMessageHandlerYou need to implement a javax.xml.ws.handler.LogicalHandler, this handler then needs to be referenced in a handler configuration file, which in turn is referenced by an @HandlerChain annotation in your service endpoint (interface or implementation).\nYou can then either output the message via system.out or a logger in your processMessage implementation. See I am posting a new answer, as I do not have enough reputation to comment on the one provided by  (see: ).In case you want the SOAP message to be printed in a file (e.g. via Log4j), you may use:Please note that under certain circumstances, the method call writeTo() may not behave as expected (see:  or ), therefore the following code will do the trick:You could try to put a  in front of the webservice and inspect request and response going to / returned from the service.Although you specifically did not ask for a proxy, sometimes I find  is enough to see what goes on on a connection. It's a simple tool, no install, it does show the data streams and can write to file too.In  you could simply executeas  is a public var defined in the class as followsam I correct in understanding that you want to change/access the raw XML message?If so, you (or since this is five years old, the next guy) might want to have a look at the Provider interface that is part of the JAXWS. The client counterpart is done using the \"Dispatch\" class. Anyway, you don't have to add handlers or interceptors. You still CAN, of course. The downside is this way, you are COMPLETELY responsible for building the SOAPMessage, but its easy, and if that's what you want(like I did) this is perfect.Here is an example for the server side(bit clumsy, it was just for experimenting)-You publish it like you would an SEI,Or you can use an Endpoint class for it.\nHope that has been helpful.And oh, if you want you needn't deal with headers and stuff, if you change the service mode to PAYLOAD(You'll only get the Soap Body).Inject  to endpoint interface. we can trace the SOAP request and responseImplementing SOAPHandler with    by adding  annotation to your endpoint interface.handlers.xmlSOAPLoggingHandler.java  Set the following system properties, this will enabled xml logging. You can set it in java or configuration file.console logs:One way to do is not using your code but use network packet sniffers like Etheral or WireShark which can capture the HTTP packet with the XML message as payload to it and you can keep logging them to a file or so.But more sophisticated approach is to write your own message handlers. You can have a look at it . Actually. If you look into sources of HttpClientTransport you will notice that it is also writing messages into java.util.logging.Logger. Which means you can see those messages in your logs too.For example if you are using Log4J2 all you need to do is the following:After these steps you start seeing SOAP messages in your logs."},
{"body": "I have a gigantic QuickBooks SDK .XSD schema file which defines XML requests/responses that I can send/receive from QuickBooks.I'd like to be able to easily generate Java classes from these .XSD files, which I could then use to marshal XML to Java objects, and Java objects to XML. Is there an easy way to do this...? Ideally, it would not require any libraries external to the basic Java distro at run-time. But I'm flexible...  does EXACTLY what you want. It's built into the JRE/JDK starting at 1.6To expand on the \"use JAXB\" comments above, In Windows\n    e.g., \n    Wait a bit, and if you had a well-formed XSD file, you will get some well-formed Java classesIf you want to start coding Java to XML and XML to Java in less than 5 minutes, try  Simple XML Serialization.  Don't spend hours learning the JAXB API\nHowever, if you are really keen on learning JAXB, here's an excellent tutorial\nContents of tutorial:There're a number of way to do XML serialization in Java. If you want fine-grained control over parsing and serialization you can go for SAX, DOM, or Stax for better performance. Yet, what I often want to do is a simple mapping between POJOs and XML. However, creating Java classes to do XML event parsing manually is not trivial. I recently found JAXB to be a quick and convenient Java-XML mapping or serialization.JAXB contains a lot of useful features, you can check out the reference implementation here.  is also a good resource to learn more about JAXB. For this blog entry, I'll show you how to do a simple Java-XML serialization with JAXB.Let's say I have an Item Java object. I want to serialize an Item object to XML format. What I have to do first is to annotate this POJO with a few XML annotation from javax.xml.bind.annotation.* package. See code listing 1 for Item.javaFrom the codeMy  is ready. I can then go ahead and create JAXB script for marshaling Item.For complete code Listing please see Code Listing 2 . The output Code Listing 3  file is created. It looks like this:Easy right? You can alternatively channel the output XML as text String, Stream, Writer, ContentHandler, etc by simply change the parameter of the marshal(...) method likeLet's reverse the process. Assume that I now have a piece of XML string data and I want to turn it into Item.java object. XML data (Code listing 3) looks likeI can then unmarshal this xml code to Item object byFor complete code Listing please see Code Listing 2 (main.java). The XML source can come in many forms both from Stream and file. The only difference, again, is the method parameter:Last thing I want to mention here is validating input XML with schema before unmarshalling to Java object. I create an XML schema file called item.xsd. For complete code Listing please see Code Listing 4 (Item.xsd). Now what I have to do is register this schema for validation.When I try to unmarshal XML data to POJO, if the input XML is not conformed to the schema, exception will be caught. For complete code Listing please see Code Listing 5 (invalid_item.xml).Here I change the 'id' attribute to string instead of integer.If XML input is valid against the schema, the XML data will be unmarshalled to Item.java object successfully.Using Eclipse IDE:- will do it.  Specifically the \"scomp\" command.EDIT: XMLBeans has been , check  for more info.Maven can be used for the purpose, you need to add some dependencies and just clean your application. You will get all classes created automatically in your target folder.Just copy them from target to desired place, here is pom.xml that i have used to create classed from xsd files :Just place your xsd files under \"src/main/webapp/schemas/\" and maven will find them at compile time.Hope this will help you, more information can be found at Hope it will help :)If you don't mind using an external library, I've used  to do this in the past.the easiest way is using command line. Just type in directory of your .xsd file: So, the java will generate all Pojos.JAXB Limitation.I worked on JAXB, as per my opinion its a nice way of dealing with data between XML and Java objects. The Positive sides are its proven and better in performance and control over the data during runtime. With a good usage of built tools or scripts it will takes away lot of coding efforts.I found the configuration part is not a straight away task, and spent hours in getting the development environment setup.However I dropped this solution due to a silly limitation I faced. My XML Schema Definition ( XSD ) has a attribute/element with name \"value\" and that I have to use XSD as it is. This very little constraint forced the  my binding step XJC failed with a Error \"Property 'Value' already used.\"This is due to the JAXB implementation, the binding process tries to create Java objects out of XSD by adding few attributes to each class and one of them being a value attribute. When it processed my XSD it complained that there is already a property with that name. Well best option is .I also have a question if we have an option to do reverse engineering here. if yes can we generate xsd from pojo class?Isn't JAXB's XJC is a possible answer to this? I'm trying to achieve the same thing. Still in the \"trying\" phase though. Came across XJC, so thought of sharing.The well-known There is a  that could do this for you at any build phase you want.You could do this stuff in both ways: xsd <-> JavaTalking about JAXB limitation, a solution when having the same name for different attributes is adding inline jaxb customizations to the xsd:  +\n   \n      .\n      .\n      binding declarations\n      .\n      .\n   \nor external customizations...You can see further informations on :\n"},
{"body": "I have the following code in Java;What is the best way to write the if condition?Use  instead of :Comparing with the  constant  avoids having to construct a  every execution.FYI,  also has constants  and  for your convenience.The reason you can't use  is that it takes  into consideration:so it's unsuitable for a purely numeric comparison. However,  doesn't consider scale when comparing:Alternatively,  can be used:There is a constant that you can check against:I usually use the following:You would want to use equals() since they are objects, and utilize the built in ZERO instance:Note that  takes scale into account, so unless selectPrice is the same scale (0) as  then this will return false.To take scale out of the equation as it were:I should note that for certain mathematical situations, , which is why I imagine  takes the scale into account.  gives precision to the hundredths place, whereas  is not that precise. Depending on the situation you may want to stick with .Alternatively, I think it is worth mentioning that the behavior of equals and compareTo methods in the class BigDecimal .This basically means that:Therefore, you have to be very careful with the scale in your  variable, otherwise you would get unexpected result.There is a static constant that :You should do this instead of:in order to avoid the case where  is ."},
{"body": "Is there a standard idiom for comparing version numbers?  I can't just use a straight String compareTo because I don't know yet what the maximum number of point releases there will be.  I need to compare the versions and have the following hold true:Tokenize the strings with the dot as delimiter and then compare the integer translation side by side, beginning from the left.Another solution for this old post (for those that it might help) :Edit:@daiscog: Thank you for your remark, this piece of code has been developed for the Android platform and as recommended by Google, the method \"matches\" check the entire string unlike Java that uses a regulatory pattern. ( - )It's really easy using Maven:You can get the right dependency string for Maven Artifact from :You need to normalise the version strings so they can be compared. Something likePrintsThe best to reuse existing code,\ntake advantages:Don't include dependency to maven-artifact as that will pull various transitive dependenciesWondering why everybody assumes that the versions is only made up of integers - in my case it was not.Why reinventing the wheel (assuming the version follows the Semver standard)First install  via MavenThen use this libraryfor my projects I use my commons-version library \nit contains two auxiliary classes - to parse version (parsed version can be compared with another version object because it is comparable one) and VersionValidator which allows to check version for some expression like Wrote a little function myself.Simpler Using ListsI created simple  on  using  convention. So it works only for strings in format X.Y.Z (Major.Minor.Patch) where X, Y, and Z are non-negative integers. You can find it on my .Method  compares two version strings. It returns 0 if the versions are equal, 1 if version v1 is before version v2, -1 if version v1 is after version v2, -2 if version format is invalid.Here's an optimized implementation:Result:For Scala you can use a library that I made: This code try to resolve this type of comparison versions.I liked the idea from @Peter Lawrey, And i extended it to further limits : Hope it helps someone. It passed all test cases in interviewbit and leetcode (need to uncomment two lines in compareVersion function). Easily tested !My java Solution"},
{"body": "I am trying to add a text field onto my Android app in Eclipse, but then I drag the  option on to the graphical layout, a message at the bottom comes up. It reads\n\nEven when I go to  there is no error log option. The whole designer is useless now, because I can not use it anymore until I delete the  directly from the xml. What is causing this error, and how do I fix it? I am running the latest version (as of today, 6-30-14), and Windows 8 Pro x64.Here is my full layout code:Check the \"Android version to use when rendering layouts\" and make sure you're not using a version that ends in \"W\" for Android Wear ( API 20: Android 4.4W). I don't believe Wear supports .In both Android Studio and Eclipse, it's the dropdown with the green android in the layout preview's toolbar. You may want to set it explicitly and not allow the IDE to choose the Android version automatically.From the Eclipse IDE, just change the API version to use for previewing, as shown in below screenshot.\nInstead of \"Automatically Pick Best\", manually select the one which works for you (API 17 worked for me).I changed my Android version for Android 4.2, but it still not work for me. I tried different solutions found that it only work by deleting Android 4.4W package.Window > Android SDK Manager > check Android 4.4W(API 20) if it was installed > Delete packageIf you are facing this on Android Studio, follow along1) Uninstall Android 4.4W(API 20) from the SDK Manager2) Make sure you have Android SDK Build Tools 19.1 installed from the SDK Manager.3) Edit build.gradle within your app folder. Set the following two values as below4) The IDE will prompt you to sync the Gradle file with your project, click Yes.5) Open your activity file and then change the 'Android version to use when rendering layouts in IDE' to 'API 19'. This is the green colored Android Bot towards the right on the preview windowI deleted 4.4w from my sdk install pile, which must have slipped past me last time I installed an sdk. Once I removed it it was no longer and option, and eclipse picked an sdk I did have that wasn't W and it worked.The W in Android 4.4W suggest wearable devices.\nAndroid Wear is a wrist watch and you cannot type anything in it so you cannot use EditText on 4.4W. Change the API to 19 or less or change it to 4.4LCheck it out @ You can change your previewing API version as Jim suggested if u don't want to develop apps for wearable devices. "},
{"body": "I've just started playing with Guice, and a use-case I can think of is that in a test I just want to override a single binding.  I think I'd like to use the rest of the production level bindings to ensure everything is setup correctly and to avoid duplication.So imagine I have the following ModuleAnd in my test I only want to override InterfaceC, while keeping InterfaceA and InterfaceB in tact, so I'd want something like:I've also tried the following, with no luck:Does anyone know if it's possible to do what I want or am I completely barking up the wrong tree??--- Follow up:\nIt would seem I can achieve what I want if I make use of the @ImplementedBy tag on the interface and then just provide a binding in the test case, which works nicely when there is a 1-1 mapping between the interface and implementation.Also, after discussing this with a colleague it would seem we'd head down the road of overriding an entire module and ensuring we have our modules defined correctly.  This seems like it might cause a problem though where a binding is misplaced in a module and needs to be moved, thus possibly breaking a load of tests as bindings may no longer be available to be overriden.This might not be the answer you're looking for, but if you're writing unit tests, you probably shouldn't be using an injector and rather be injecting mock or fake objects by hand.On the other hand, if you really want to replace a single binding, you could use :See details .But as the javadoc for  recommends, you should design your modules in such a way that you don't need to override bindings. In the example you gave, you could accomplish that by moving the binding of  to a separate module.Why not to use inheritance? You can override your specific bindings in  method, leaving shared implementations in  method.And finally create your injector this way:If you don't want to change your production module and if you have a default maven-like project structure likeYou can just create a new class  in your test directory using the same package as for your original class. Guice will then bind  to  from your test directory whereas all other interfaces will be bound to your production classes. You want to use  where you can declare your custom configuration for each test class.In a different setup, we have more than one activity defined in separate modules.  The activity that's being injected into is in an Android Library Module, with its own RoboGuice module definition in the AndroidManifest.xml file.  The setup looks like this.  In the Library Module there are these definitions:AndroidManifest.xml:Then we have a type being injected:Some default implementation of Foo:MainModule configures the FooThing implementation for Foo:And finally, an Activity that consumes Foo:In the consuming Android Application Module, we would like to use  but, for testing purposes, inject our own .One might argue to expose the module handling to the client application, however, we need to mostly hide the components being injected because the Library Module is an SDK, and exposing pieces has larger implications.(Remember, this is for testing, so we know the internals of SomeActivity, and know it consumes a (package visible) Foo).The way I found that works makes sense; use the the suggested override for :Now, when  is started, it will get  for its injected  instance.It's a very specific situation where, in our case, OtherFooThing was used internally to record test situations, while FooThing was used, by default, for all other uses.Keep in mind, we  using  in our unit tests, and it works flawlessly."},
{"body": "How can I configure  to log different levels for a logger to different destinations?For example, given the following Logback configuration, will Logback record  messages to  and  messages to ?(Note that this example is a variation of example  shown in ).Update: For an all configuration based approach using Groovy see .--You can do some interesting things with . The below configuration will only print warn and error messages to stderr, and everything else to stdout.I believe this would be the simplest solution:okay, here is my favorite xml way of doing it.  I do this for the eclipse version so I can and for some reason SO is not showing this all properly but most seems to be there...Using ThresoldFilter & multiple LevelFilters : This is the configuration that I use, which works fine, it is based on XML + JaninoEventEvaluator (requires the  library to be added to Classpath)I use logback.groovy to configure my logback but you can do it with xml config as well:I think to use GEventEvaluator is simplier because there is no need to create filter classes.\nI apologize for my English!The simplest solution is to use  on the appenders:Full example:Update: As Mike pointed out in the comment, messages with ERROR level are printed here both to STDOUT and STDERR. Not sure what was the OP's intent, though. You can try Mike's answer if this is not what you wanted.I take no credit for this answer, as it's merely a combination of the best two answers above: that of X. Wo Satuk and that of S\u00e9bastien Helbert:  is lovely but you can't configure it to have an upper level as well as a lower level*, but combining it with two  set to \"DENY\"  and  works a treat.: do not forget the  tag in the STDERR appender: my omission of it had me frustrated for a few minutes.* it does however have a method  in the  but I haven't a clue how you'd use it in this context.Example of how to output colored messages of level \"INFO\" or higher to  and messages of level \"WARN\" or higher to .Your  file:Try this. You can just use built-in  and . No need to create your own filters programmically. In this example WARN and ERROR levels are logged to System.err and rest to System.out:\n\n    "},
{"body": "What's the equivalent of Java's  in JavaScript?The simple answer is that there is no such function.The closest thing you have is:Note that you  don't want to busy-wait (e.g. in a spin loop), since your browser is almost certainly executing your JavaScript in a single-threaded environment.Here are a couple of other SO questions that deal with threads in JavaScript:And this question may also be helpful:Try with this code. I hope it's useful for you.There's no direct equivalent, as it'd pause a webpage.  However there is a , e.g.:Closure example (thanks Daniel):The second argument is milliseconds before firing, you can use this for time events or waiting before performing an operation.  Updated based on comments for a cleaner result.You can either write a spin loop (a loop that just loops for a long period of time performing some sort of computation to delay the function) or use:This will call 'Func1()' after 3 seconds.Edit:Credit goes to the commenters, but you can pass anonymous functions to setTimeout.This is much more efficient and does not invoke javascript's eval function.This eventually helped me:Or maybe you can use the setInterval function, to call a particular function, after the specified number of milliseconds. Just do a google for the setInterval prototype.I don't quite recollect it.setTimeout would not hold and resume on your own thread however Thread.sleep does. There is no actual equal in Javascript"},
{"body": "I am having  called  which contains .When iterating the map, if  is match with specified string, I need to remove the key from map.i.e. contains  but I am unable to remove the key from . Instead getting error :Try:Use To remove specific key and element from hashmap use full source code is likeSource : "},
{"body": "I've met these articles:And that lead me to this Google I/O 2010 video about REST client applicationsSince now, I've been creating REST component as static component in my Application controller class.   From now, I think, I should change the pattern.  pointed out that  application is great sample of how to write REST clients on Android.  told that this ways is too overcomplicated.  So, can anybody please show us what is the best practice? In short and simple way.\nThe IOSched application is too complex for sample use-case.The original answer is more than a year and a half old at the time of this edit. Although the concepts presented in original answer still hold, as other answers point out, there are now libraries out there that make this task easier for you. More importantly, some of these libraries handle device configuration changes for you.The original answer is retained below for reference. But please also take the time to examine some of the Rest client libraries for Android to see if they fit your use cases. The following is a list of some of the libraries I've evaluated. It is by no means intended to be an exhaustive list.Presenting my approach to having REST clients on Android. I do not claim it is the best though :) Also, note that this is what I came up with in response to my requirement. You might need to have more layers/add more complexity if your use case demands it. For example, I do not have local storage at all; because my app can tolerate loss of a few REST responses.My approach uses just s under the covers. In my case, I \"call\" these Tasks from my  instance; but to fully account for cases like screen rotation, you might choose to call them from a  or such.I consciously chose my REST client itself to be an API. This means, that the app which uses my REST client need not even be aware of the actual REST URL's and the data format used. The client would have 2 layers:In addition, I chose to use a Callback mechanism to communicate the result of the s back to the app.Enough of text. Let's see some code now. Lets take a hypothetical REST API URL - The top layer might look like this:Note that the app doesn't use the JSON or XML (or whatever other format) returned by the REST API directly. Instead, the app only sees the bean .Then, the lower layer (AsyncTask layer) might look like this:Here's how an app might use the API (in an  or ):I hope the comments are sufficient to explain the design; but I'd be glad to provide more info.\"Developing Android REST client applications\" by Virgil Dobjanschi led to much discussion, since no source code was presented during the session or was provided afterwards.The only reference implementation I know (please comment if you know more) is available at  (the Google IO session is mentioned under /presentation). It is a library which you can use in your own application.The second link asks for the \"best\" REST framework, which is discussed heavily on stackoverflow. For me the application size is important, followed by the performance of the implementation.Therefore I stick to org.json or GSON for complexer scenarios. For the architecture of an org.json implementation, I am using a static class which represents the server use cases (e.g. findPerson, getPerson). I call this functionality from a service and use utility classes which are doing the mapping (project specific) and the network IO (my own REST template for plain GET or POST). I try to avoid the usage of reflection.Never use AsynTask to perform network request or whatever that need to be persisted. Async Task are strongly tied to your activity and if the user change the orientation of the screen since the App is re created the AsyncTask will be stopped.I suggest you to use Service pattern with Intent Service and ResultReceiver. Take a look to . It's a library that allows you to perform any kind of REST request asynchronously and notify your UI with Request Listeners implementing the Virgil Dobjanschi's service pattern.There is another library with much cleaner API and type-safe data.\nHere is a simple usage exampleOr more complex with callbacksIt is fresh new, but looks very promising.There is plenty of libraries out there and I'm using this one: . This was created by me, and, as you can see in the documentation, it's way cleaner and simpler than the other ones. It's not focused on Android, but I'm using in it and it's working pretty well.It supports HTTP Basic Auth. It does the dirty job of serializing and deserializing JSON objects. You will like it, specially if your API is Rails like.Disclaimer: I am involved in the rest2mobile open source projectAnother alternative as a REST client is to use .The approach is slightly different as it uses concrete  to generate the client code for the REST service. The code replaces the REST URL and JSON payloads with native java methods and POJOs. It also automatically handles server connections, asynchronous invocations and POJO to/from JSON conversions. Note that this tool comes in different flavors (cli, plugins, android/ios/js support) and you can use the  to generate the API directly into your app. All the code can be found on ."},
{"body": "In Java, I have just found out that the following code is legal:FYI, receiver is just a helper class with the following signature:I've never seen the  notation before. How does that work?  Is there any way to code that more conventionally?It's the way to instantiate a non-static inner class from outside the containing class body, as described in the . Every inner class instance is associated with an instance of its containing class. When you  an inner class from  its containing class it uses the  instance of the container by default:But if you want to create an instance of Bar outside Foo, or associate a new instance with a containing instance other than  then you have to use the prefix notation.Have a look at this example:Using javap we can view instructions generated for this codeMain method:Inner class constructor:Everything is simple - when invoking TestInner constructor, java passes Test instance as a first argument . Not looking at that TestInner should have a no argument constructor. TestInner in its turn just saves reference to parent object, . When you are invoking inner class constructor from an instance method, reference to parent object  is passes automatically, so you do not have to specify it. Actually its passes every time, but when invoking from outside it should be passed explicitly. - is just a way to specify the first hidden argument to TestInner constructor, not a type is equal to: is equal to:When inner classes were added to Java in version 1.1 of the language they were originally defined as a transformation to 1.0 compatible code. If you look at an example of this transformation, I think it will make it a lot clearer how an inner class actually works.Consider the code from Ian Roberts' answer:When transformed to 1.0 compatible code, that inner class  would become something like this:The inner class name is prefixed with the outer class name so as to make it unique. A hidden private  member is added that holds a copy of the outer . And a hidden constructor is created to initialise that member.And if you look at the  method, it would be transformed into something like this:So let's see what happens when you execute the following code.First we instantiate an instance of  and intialise the  member to 5 (i.e. ).Next we call , which instantiates an instance of  and initialises the  member to the value of  passed in from  (i.e. ).Finally we call  which tries to print  which is  which is 5.Now that was a regular instantiation of an inner class. Let's look at what happens when instantiating  from outside .Applying our 1.0 transformation again, that second line would become something like this:This is almost identical to the  call. Again we're instantiating an instance of  and initialising the  member to f. So again, .And again when you call , you are printing  which is  which is 5.The key thing to remember is that the inner class has a hidden member holding a copy of  from the outer class. When you instantiate an inner class from within the outer class, it it implicitly initialised with the current value of . When you instantiate the inner class from outside the outer class, you explicitly specify which instance of the outer class to use, via the prefix on the  keyword.Think of  as a single token. Kind of like a function name with a space in it.Of course, the class  does not literally have a function named , but I'm guessing the syntax is meant to suggest that. It's meant to look like you're calling a function that creates a new instance of  using a particular instance of  for any accesses to the enclosing class.If a declaration of a type (such as a member variable or a parameter name) in a particular scope (such as an inner class or a method definition) has the same name as another declaration in the enclosing scope, then the declaration shadows the declaration of the enclosing scope. You cannot refer to a shadowed declaration by its name alone. The following example, ShadowTest, demonstrates this:This example defines three variables named x: The member variable of the class ShadowTest, the member variable of the inner class FirstLevel, and the parameter in the method methodInFirstLevel. The variable x defined as a parameter of the method methodInFirstLevel shadows the variable of the inner class FirstLevel. Consequently, when you use the variable x in the method methodInFirstLevel, it refers to the method parameter. To refer to the member variable of the inner class FirstLevel, use the keyword this to represent the enclosing scope:Refer to member variables that enclose larger scopes by the class name to which they belong. For example, the following statement accesses the member variable of the class ShadowTest from the method methodInFirstLevel:"},
{"body": "How do you find a memory leak in Java (using, for example, JHat)? I have tried to load the heap dump up in JHat to take a basic look. However, I do not understand how I am supposed to be able to find the root reference () or whatever it is called. Basically, I can tell that there are several hundred megabytes of hash table entries ([java.util.HashMap$Entry or something like that), but maps are used all over the place... Is there some way to search for large maps, or perhaps find general roots of large object trees?[Edit]\nOk, I've read the answers so far but let's just say I am a cheap bastard (meaning I am more interested in learning how to use JHat than to pay for JProfiler). Also, JHat is always available since it is part of the JDK. Unless of course there is no way with JHat but brute force, but I can't believe that can be the case.Also, I do not think I will be able to actually modify (adding logging of  map sizes) and run it for long enough for me to notice the leak.I use following approach to finding memory leaks in Java. I've used jProfiler with great success, but I believe that any specialized tool with graphing capabilities (diffs are easier to analyze in graphical form) will work.Basically analysis should start from greatest positive diff by, say, object types and find what causes those extra objects to stick in memory.For web applications that process requests in several threads analysis gets more complicated, but nevertheless general approach still applies.I did quite a number of projects specifically aimed at reducing memory footprint of the applications and this general approach with some application specific tweaks and trick always worked well.Questioner here, I have got to say getting a tool that does not take 5 minutes to answer any click makes it a lot easier to find potential memory leaks.Since people are suggesting several tools ( I only tried visual wm since I got that in the JDK and JProbe trial ) I though I should suggest a free / open source tool built on the Eclipse platform, the Memory Analyzer (sometimes referenced as the SAP memory analyzer) available on  . What is really cool about this tool is that it indexed the heap dump when I first opened it which allowed it to show data like retained heap without waiting 5 minutes for each object (pretty much all operations were tons faster than the other tools I tried).When you open the dump, the first screen shows you a pie chart with the biggest objects (counting retained heap) and one can quickly navigate down to the objects that are to big for comfort. It also has a Find likely leak suspects which I reccon can come in handy, but since the navigation was enough for me I did not really get into it.A tool is a big help.However, there are times when you can't use a tool: the heap dump is so huge it crashes the tool, you are trying to troubleshoot a machine in some production environment to which you only have shell access, etc.In that case, it helps to know your way around the hprof dump file.Look for SITES BEGIN. This shows you what objects are using the most memory. But the objects aren't lumped together solely by type: each entry also includes a \"trace\" ID. You can then search for that \"TRACE nnnn\" to see the top few frames of the stack where the object was allocated. Often, once I see where the object is allocated, I find a bug and I'm done. Also, note that you can control how many frames are recorded in the stack with the options to -Xrunhprof.If you check out the allocation site, and don't see anything wrong, you have to start backward chaining from some of those live objects to root objects, to find the unexpected reference chain. This is where a tool really helps, but you can do the same thing by hand (well, with grep). There is not just one root object (i.e., object not subject to garbage collection). Threads, classes, and stack frames act as root objects, and anything they reference strongly is not collectible.To do the chaining, look in the HEAP DUMP section for entries with the bad trace id. This will take you to an OBJ or ARR entry, which shows a unique object identifier in hexadecimal. Search for all occurrences of that id to find who's got a strong reference to the object. Follow each of those paths backward as they branch until you figure out where the leak is. See why a tool is so handy?Static members are a repeat offender for memory leaks. In fact, even without a tool, it'd be worth spending a few minutes looking through your code for static Map members. Can a map grow large? Does anything ever clean up its entries?There are tools that should help you find your leak, like JProbe, YourKit, AD4J or JRockit Mission Control. The last is the one that I personally know best. Any good tool should let you drill down to a level where you can easily identify what leaks, and where the leaking objects are allocated. Using HashTables, Hashmaps or similar is one of the few ways that you can acually leak memory in Java at all. If I had to find the leak by hand I would peridically print the size of my HashMaps, and from there find the one where I add items and forget to delete them.Well, there's always the low tech solution of adding logging of the size of your maps when you modify them, then search the logs for which maps are growing beyond a reasonable size.Most of the time, in enterprise applications the Java heap given is larger than the ideal size of max 12 to 16 GB. I have found it hard to make the NetBeans profiler work directly on these big java apps.But usually this is not needed. You can use the jmap utility that comes with the jdk to take a \"live\" heap dump , that is jmap will dump the heap after running GC.  Do some operation on the application, wait till the operation is completed, then take another \"live\" heap dump. Use tools like Eclipse MAT to load the heapdumps, sort on the histogram, see which objects have increased, or which are the highest, This would give a clue.There is only one problem with this approach; Huge heap dumps, even with the live option, may be too big to transfer out to development lap, and may need a machine with enough memory/RAM to open.That is where the class histogram comes into picture. You can dump a live class histogram with the jmap tool. This will give only the class histogram of memory usage.Basically it won't have the information to chain the reference. For example it may put char array at the top. And String class somewhere below. You have to draw the connection yourself. Instead of taking two heap dumps, take two class histograms, like as described above; Then compare the class histograms and see the classes that are increasing. See if you can relate the Java classes to your application classes. This will give a pretty good hint. Here is a pythons script that can help you compare two  jmap histogram dumps. Finally tools like JConolse and VisualVm are essential to see the memory growth over time, and see if there is a memory leak. Finally sometimes your problem may not be a memory leak , but high memory usage.For this enable GC logging;use a more advanced and new compacting GC like G1GC; and you can use jdk tools like jstat to see the GC behaviour liveOther referecences to google for -jhat, jmap, Full GC, Humongous allocation, G1GCYou really need to use a memory profiler that tracks allocations. Take a look at  - their \"heap walker\" feature is great, and they have integration with all of the major Java IDEs. It's not free, but it isn't that expensive either ($499 for a single license) - you will burn $500 worth of time pretty quickly struggling to find a leak with less sophisticated tools.NetBeans has a built-in profiler. you may want to check out .  It's also part of the JDK and I have found it helpful to find memory/reference leaks in conjunction with jhat.  Also take a look at  blog entry."},
{"body": "I'm trying  problem from Sphere Online Judge (SPOJ) where I need to find a palindrome for a integer of up to a million digits. I thought about using Java's functions for reversing Strings, but would they allow for a String to be this long?   You should be able to get a String of length  (always 2147483647 (2 - 1) by the Java specification, the maximum size of an array, which the String class uses for internal storage) or half your maximum heap size (since each character is two bytes), whichever is smaller.I believe they can be up to 2^31-1 characters, as they are held by an internal array, and arrays are indexed by integers in Java.While you can in theory Integer.MAX_VALUE characters, the JVM is limited in the size of the array it can use.on Oracle Java 8 update 92 printsNote: in Java 9, Strings will use byte[] which will mean that multi-byte characters will use more than one byte and reduce the maximum further.  If you have all four byte code-points e.g. emojis, you will only get around 500 million charactersHave you considered using  instead of  to hold your numbers?Integer.MAX_VALUE is max size of string + depends of your memory size but the Problem on sphere's online judge you don't have to use those functions The heap part gets worse, my friends. UTF-16 isn't guaranteed to be limited to 16 bits and can expand to 32Java9 uses byte[] to store String.value, so you can only get about 1GB Strings in Java9. Java8 on the other hand can have 2GB Strings.By character I mean \"char\"s, some character is not representable in BMP(like some of the emojis), so it will take more(currently 2) chars.If you use google's app engine, com.google.appengine.api.datastore.Text can help. It allows a single string to store upto1 megabyte."},
{"body": "How can I elegantly serialize a lambda?For example, the code below throws a . How can I fix it without creating a  \"dummy\" interface?Java 8 introduces the possibility to . In the case of serialization, it is therefore possible to write:And the lambda automagically becomes serializable.The same construction can be used for method references. For example this code:defines a lambda expression and a method reference with a serializable target type.If you are willing to switch to another serialization framework like , you can get rid of the multiple bounds or the requirement that the implemented interface must implement . The approach is to For details and code see this "},
{"body": "Is there a nicer way to write in jUnitIf you add in Hamcrest and JUnit4, you could do:With some static imports, it looks a lot better:The static imports needed would be:use  whenever possible EDIT:  may have more assertions (a fork)Use hamcrest Matcher You can optional add an even more detail error message.Use the new  syntax together with .It is available starting with .Another variant isMoreover in  there are some other interesting matchers, like ,  etc.I've tried out many answers on this page, none really worked:So I stopped trying to make nicely readable code, but used the simple and workable approach mentioned in the question instead."},
{"body": "I'm finally making the voyage back to IntelliJ via Eclipse.  Currently my Eclipse is set up so that if I currently have a statement such as this (where ^ denotes where my cursor currently sits):and I hit the semi-colon (;) key, it will automatically put the semi-colon at the end of the statement:Currently IntelliJ does this:Meaning I will have to explicitly type the closing bracket before typing the semi-colon.Not a huge problem obviously but I have found myself putting the semi-colon in the wrong place a few times today as I make the transition back to IntelliJ and thought that it may be more efficient (for both my fingers and brain) not to have to type the closing bracket.Try ++. That finishes the statement you're currently writing. Try it in a few different situations, like in if statements, for loops etc, and you'll see that it'll complete the line and open some curly braces for you if necessary.You can  a keymap of your own. I added + to my Keymaps for the \"Complete Current Statement\" action. This saved me an extra key stroke and made it a little bit more intuitive.You can opt to remove or keep the existing mapping.  Should look something like this when you're done:"},
{"body": "I have the following  condition.What value of  will return  for this condition in Java?I am unable to think of any such value of  considering  notation in Java.I would also love to have algebraic proof of whatever answer this condition has (in context with Java)?The only  value for which it works is  .It's because integers are negated using the .Usingyou see that  isTaking the negative value is done by first swapping  and , which givesand by adding , which givesAs you can see in the link I gave, Wikipedia mentions the problem with the most negative numbers and specifies it's the sole exception :Of course you have the same phenomenon for  if you store it in a  variable.Note that . Another (bad) solution could for example have been to negate by simply changing the most significant bit and letting the other bits unchanged, this would have avoided this problem with MIN_VALUE but would have made 2 different  values and complicated binary arithmetic (how would you have incremented for example ?).The value you are looking for is .That's off-topic for Stack Exchange.  But you could do it starting from the definition of Java integers ()andand the definition of the Java unary '-' operator ():In additional to the answers given so far...There is four values in totalThe wrapped values get unwrapped so they are also true for this expression.  Note: Math.abs documents.andIt is surprising that Math.abs might return a negative number.  This happens either because a) there is no positive values for -MIN_VALUE in these cases b) performing the  calculation results in an overflow.What is also interest is why doesn't Byte.MIN_VALUE, Short.MIN_VALUE do not do this.  This is because the  changes the type to  for these and thus no overflow.Character.MIN_VALUE doesn't have a problem because it is 0.Float.MIN_VALUE and Double.MIN_VALUE have a different meaning.  These are the smallest representable value greater than zero. Thus they have valid negative values which are not themselves.Like the others have mentioned, this is only fulfilled by . As for proof, let me offer an easier to understand explanation other than in binary (although it is still rooted in that).Note that  is equal to  or  and  is equal to  or .  is , which is now too large for an Integer (since it is past ) thus causing an Integer overflow, making it  again. It's the only Integer that does this since  is the only number with no negative equivalent aside from 0.Tentative algebraic proof, using  arithmetic: can be rewritten as  (adding  on both sides), or .This equation has two solutions of the form , namely  and  obtained by shifting in either  or  on the left.The solution  being excluded, there remains the solution .Maybe it's not too educative, but instead of thinking you could run this code:to see that it prints infinitely :)"},
{"body": "What does  do?\nFor example in the function:If you launch your program with  (or  for short) then this statementis equivalent toIf you launch your program without this option, the assert statement will have no effect.For example, , as posted in your question, is equivalent to(If you launched with  that is.)Formally, the  says the following:Where  is controlled with the  switch and  means that an  is thrown.You can append  like this:to specify what the error message of the thrown AssertionError should be.This post has been rewritten as an article .If the condition isn't satisfied, an  will be thrown.Assertions have to be enabled, though; otherwise the  expression does nothing. See: is a debugging tool that will cause the program to throw an  exception if the condition is not true.  In this case, the program will throw an exception if either of the two conditions following it evaluate to false.  Although I have read a lot documentation about this one, I'm still confusing on how, when, and where to use it. Make it very simple to understand:When you have a similar situation like this:You might receive warning (displaying yellow line on strB = strA.toLowerCase(); ) that strA might produce a NULL value to strB. Although you know that strB is absolutely won't be null in the end, just in case, you use assert toSometime, when you compile your code, you don't get your result and it's a bug. But the application won't crash, and you spend a very hard time to find where is causing this bug.So, if you put assert, like this:you tell the compiler that strA is absolutely not a null value, it can 'peacefully' turn off the warning. IF it is NULL (worst case happens), it will stop the application and throw a bug to you to locate it.Assertions are generally used primarily as a means of checking the program's expected behavior. It should lead to a crash in most cases, since the programmer's assumptions about the state of the program are false. This is where the debugging aspect of assertions come in. They create a checkpoint that we simply can't ignore if we would like to have correct behavior. In your case it does data validation on the incoming parameters, though it does not prevent clients from misusing the function in the future. Especially if they are not, (and should not) be included in release builds.    It ensures that the expression returns true.  Otherwise, it throws a .Assert does throw an AssertionError if you run your app with assertions turned on.If you run this with, say: It shall throw an "},
{"body": "How do I build a URL or a URI in Java? Is there an idiomatic way, or libraries that easily do this?I need to allow starting from a request string, parse/change various URL parts (scheme, host, path, query string) and support adding and automatically encoding query parameters.As of Apache HTTP Component HttpClient 4.1.3, from the official :Edit: as of v4.2  has been deprecated in favor of :?As the author, I'm probably not the best person to judge if my URL/URI builder is , but here it nevertheless is: I wanted the simplest possible complete solution with zero dependencies outside the JDK, so I had to roll my own.Using HTTPClient worked well.Bug (RFE) 6306820 in the java bug database adresses this.In one of the comments, a  is provided.After being lambasted for suggesting the URL class.  I will take the commenter's advice and suggest the  instead.  I suggest you look closely at the constructors for a URI as the class is very immutable once created.\nI think this constructor allows you to set everything in the URI that you could need.There are plenty of libraries that can help you with URI building (don't reinvent the wheel). Here are three to get you started: It's  and there is a very popular library named  which has been starred  times on GitHub. With this library, you can build an url like below:The  has pretty good methods for constructing a URL."},
{"body": "I can't seem to find the answer I'm looking for regarding a simple question: how do I round up any number to the nearest ?For example, whenever the number is 0.2, 0.7, 0.2222, 0.4324, 0.99999 I would want the outcome to be 1.So far I haveIt doesn't seem to be doing the job, though. is the correct function to call. I'm guessing  is an , which would make  perform integer arithmetic. Try  instead.Outputs:See I don't know why you are dividing by 100 but here my assumption or This seemed to do the perfect job. Worked everytime.Assuming a as double and we need a rounded number with no decimal place . Use Math.round() function.\nThis goes as my solution . "},
{"body": "I wrote a web service project using netbeans 6.7.1 with glassfish v2.1, put log4j.properties to the root dir of project and use:in Constructor:and in functions:but, it is error info(actually, I have tried to put it almost every dir that I could realize):the example project could be get from I know it's a bit late to answer this question, and maybe you already found the solution, but I'm posting the solution I found (after I googled a lot) so it may help a little:Hope this will help.rgdsAs already stated, log4j.properties should be in a directory included in the classpath, I want to add that in a mavenized project a good place can be You have to put it in the root directory, that corresponds to your execution context.Example:If you start executing from a different project, you need to have that file in the project used for starting the execution. For example, if a different project holds some JUnit tests, it needs to have also its log4j.properties file.I suggest using log4j.xml instead of the log4j.properties. You have more options, get assistance from your IDE and so on...You can specify config file location with VM argument -Dlog4j.configuration=\"file:/C:/workspace3/local/log4j.properties\"If you put log4j.properties inside src, you don't need to use the statement - It will be taken automatically as the properties file is in the classpath.For a Maven Based Project keep your log4j.properties in src/main/resources. Nothing else to do!The file should be located in the WEB-INF/classes directory.\nThis directory structure should be packaged within the war file. Try:My IDE is NetBeans. I put log4j.property file as shown in the picturesRootWebWEB-INFTo use this property file you should to write this code:You can define  from another JSP file.\nExample:Now you can use log4j.property file in your projects.A few technically correct specific answers already provided but in general, it can be anywhere on the runtime classpath, i.e. wherever classes are sought by the JVM.This could be the /src dir in Eclipse or the WEB-INF/classes directory in your deployed app, but it's best to be aware of the classpath concept and why the file is placed in it, don't just treat WEB-INF/classes as a \"magic\" directory.I've spent a great deal of time to figure out why the  file is not seen. \nThen I noticed it was visible for the project only when it was in both  and  folders. \nHope it'll be useful to somebody. \nPS: The project was maven-based.I found that Glassfish by default is looking at [Glassfish install location]\\glassfish\\domains[your domain]\\ as the default working directory...  you can drop the log4j.properties file in this location and initialize it in your code using PropertyConfigurator as previously mentioned...I don't know this is correct way.But it solved my problem.\nput log4j.properties file in \"project folder\"/config and use PropertyConfigurator.configure(\"config//log4j.properties\");it will works with IDE but not when run the jar file yourself.\nwhen you run the jar file by yourself just copy the log4j.properties file in to the folder that jar file is in.when the jar and property file in same directory it runs well."},
{"body": "im using Android Studio\nwhy every time I create a new project always comes up when I remove        \napplications in dependencies no problem anymore...I had the same problem. Solved by adding url for missing repository in the  file:That's it.Just remove the \"testCompile 'junit:junit:4.12'\" from build.gradle file:worked for me and I am Happy! :) Go to File -> Project Structure. Following window will open:From there:Hope it works for you too :D It's not able to get junit library.After adding above line inside android block in build.gradle file, it resolved problem.\nThis can be because your Android studio doesn't have junit library.Probably your gradle is incomplete, I recommend you add the following   but in some cases won't work , you can completely delete it from you dependencies in your gradle.add repository in your build.gradle fileHere is what I did to solve the same problem. I am behind a firewall, which is same issue as yours I suppose.\nSo I had tried removing the but that didnt work for me.\nI tried adding below lines of code:Even that did not work for me.I tried removing (-) and readding (+) Junit4.12 from the library dependencies under Module Settings.\nStill that did not work for me.Tried syncing and rebuilding project several times. Still did not work for me.Finally what I did was to manually download the Junit4.12.jar file from mvnrepository website. I put this jar file in the Androids Workspace under the Project folder inside libs folder.\nThen go to Module Settings > Dependencies Tab > (+) > File Dependency >\nunder Sleect path window, expand the 'libs' folder and you will find the Jar file you copied inside there.\nSelect the File and click 'OK'\nNow remove the previous version of junit4.12 from the list of dependencies.You should have one entry  in the Dependencies list.\nNow click 'OK'.Now Gradle will rebuild the project and you should be good to go.Hope this helps!I'll tryed everithing, but the only thing that helps me resolve the problem was delete the line from the app gradel.I received this error after creating a new project. In the build.gradle file, I had this:  I change it to the following and the error went away:  I think this is because I am behind a firewall and specifying the url like so changes it from https to httpProbably you are behind proxy. Happened to me, used my mobile tethering (no proxy) rebuild project and error disappeared. Returned to original connection (with proxy) and rebuild with no errors.It happens HTTPS is blocked by Proxy.\nTry to change from default jcenter (which uses HTTPS) into HTTP. BeforeAfterRepeat the above step for allprojects.? If so, the problem can be in missing network configuration for  in your  file. AndroidStudio puts automatically your default proxy settings to  file in your project, but only for http and forgets https.So basically your  file needs to contain both http and https config:CHANGE your build.gradle like with this, work fine for me:added to Go to File -> Project Structure -> dependency\nThere you will find ->  junit:unit:4.12On the right hand side ..select compile from the drop down.\nSimple.. its done.Reference Image: Reds'\nVVMostly this issue will come when ever you update your SDK, at the time of project creation Gradle build fails. If you add the  and  repositories to your  your problem will solved.These are the two line you have to add after The error is caused by missing jar files. My simple solution is just by copying all the files that does not resolve to the C:\\Program Files\\Android\\Android Studio\\gradle\\m2repository... (your file path may be different). I got around 6 dependencies that cannot be resolved, junit is one of them and the others are com and org and javax. Since I am behind a firewall, even if I added the code for the repository, the Android Studio doesn't seem to access it. I went to the maven repository and downloaded all the files that will not resolve. Problem solved and the Gradle sync without error. But I am a certified newbie with only 1 day experience so I do not not if this is the proper way to do it. Example error: \nCannot resolve com:squareup:javawriter:2.1.1Step 1: I created a path C:\\Program Files\\Android\\Android Studio\\gradle\\m2repository\\com\\squareup\\javawriter\\2.1.1\\ Step 2: I downloaded all the jar files from the maven repository: \nStep 3: I manually downloaded all the .jar files from this directoryStep 4: I copied them to C:\\Program Files\\Android\\Android Studio\\gradle\\m2repository\\com\\squareup\\javawriter\\2.1.1\\ I repeated this to all the files that did not resolve including the junit.For junit, here is the directory I created: \nC:\\Program Files\\Android\\Android Studio\\gradle\\m2repository\\junit\\junit\\4.12\nand then I copied the junit-4.12.jar inside this directory and the junit error disappeared.After that sync the project again.Try this:If you are behind a proxy. Android Studio will add proxy for http to Gradle, but will not for https.\nAdd proxy settings for https to gradle.propertiesMy installation of Android Studio is completely offline. To resolve these kind of problems I have used the Process Monitor. It showed that a few files are missing within \"Android Studio\\gradle\\m2repository\".\nI have downloaded all files fromand copied these files in \"Android Studio\\gradle\\m2repository\". You have to create the structure below \"m2repository\" as it is below \"maven2\".\nMaybe there are more missing files, but at this time at least Gradle build is finished without errors.build.gradle(project: ...)I had the same problem, but with another problem.My other problem was that the Gradle build was too slow!I resolved my problem by doing thisLIf you do like mdew you need to this any time you're creating your project to do thisSo if you want to set default option to maven Do this: Go to the folder:Then open the  file with notepad++ or notepad\nand replace all  with .EDIT: Why its going down voted? you don't like it?I was having same problem.I couldn't work out why Android Studio was not syncing with gradle. It turned out that it didn't like my VPN, so watch for that!Go to Go to \"File\" -> \"Project Structure\" -> \"App\"\nIn the tab \"properties\". In \"Library Repository\"  put '' then press Ok.\nIt was fixed like that for me. Now the project is compiling.Just connect to Internet and start Android Studio and open your project.\nWhile Gradle Sync it will download the dependencies from Internet(All JAR Files). This solved it for me.\nNo Editing in Gradle file ,all was done by Android Studio Automatically.\nUsing Android Studio 2.2 :)Also don't forget to install Java JDK 1.x(7 or 8 all works fine).I would love to suggest the solution, which perfects suitable for my situation:Simply try to compile and run you project while having active internet connection. it worked for me in Android studio 1.5 Ubuntu 15.04"},
{"body": " has questioned and answered how to declare an empty  but how do I declare an arraylist with values?I've tried the following but it returns a syntax error:You can create a new object using the constructor that accepts a :When you have question like this, you should visit the  and see what constructors available there:Java 8 solution using :You can do like this :Use:If you don't want to add new elements to the list later, you can also use ( returns a fixed-size list):Note: you can also use a static import if you like, then it looks like this:...orThe  contains convenience methods for creating lists and other collections which makes this much prettier than using the standard library classes.Example:(This assumes )Try this!It's a good practice to declare the  with interface  if you don't have to invoke the specific methods.Use this one: "},
{"body": "How does a Java  work when it has an assignment and an equality check -d together??Why is this printing FALSE?The expression is not parsed the way you think. It's notin which case the result would have been , butThe value of  expression is computed first, and it is , because  is set to  going into the computation.The reason it is parsed this way is that the  of the  is lower than that of the  operator, but higher than the precedence of the assignment operator .This is a precedence issue, basically. You're assuming that your code is equivalent to:... but it's not. It's actually equivalent to:... which is equivalent to:(because  is  to start with)... which is equivalent to:which assigns the value  to , with the result of the expression being .See the  for a useful table of operator precedence.Expression  will evaluate in following step.  //precedence of  is highest // Operator  have higher precedence  Since boolean value of expression becomes false.So else statement is being executed. returns false, because both of them are false. this is true because one of them is true"},
{"body": "Is it possible in JUnit to assert an object is an instance of a class? For various reasons I have an object in my test that I want to check the type of. Is it a type of Object1 or a type of Object2?Currently I have:This works but I was wondering if there is a more expressive way of doing this.For example something like:I could do this:Is there a specific assert method that allows me to test a type of an object in a more elegant, fluid manner?You can use the  method and the Matchers that comes with JUnit.Take a look at  that describes a little bit about the JUnit Matchers.Example:Test:"},
{"body": "Some time ago, I came across a piece of code, that used some piece of standard Java functionality to locate the classes that implemented a given interface. I know the functions were hidden in some non-logical place, but they could be used for other classes as the package name implied. Back then I did not need it, so I forgot about it, but now I do, and I can't seem to find the functions again. Where can these functions be found?Edit: I'm not looking for any IDE functions or anything, but rather something that can be executed within the Java application.Awhile ago, I put together a package for doing what you want, and more. (I needed it for a utility I was writing). It uses the  library. You can use reflection, but ASM turned out to perform better.I put my package in an open source library I have on my web site. The library is here: . You want to start with the with  class.The utility I wrote it for is an RSS reader that I still use every day, so the code does tend to get exercised. I use ClassFinder to support a plug-in API in the RSS reader; on startup, it looks in a couple directory trees for jars and class files containing classes that implement a certain interface. It's a lot faster than you might expect.The library is BSD-licensed, so you can safely bundle it with your code. Source is available.If that's useful to you, help yourself.Update: If you're using Scala, you might find  to be more Scala-friendly.Spring can do this for you...N.B. The TypeFilter is important if you want the correct results!\nYou can also use exclusion filters here instead.The Scanner can be found in the spring-context jar, the registry in spring-beans, the type filter is in spring-core.I really like the  for doing this.It provides a lot of different types of scanners (, , etc), and it is dead simple to write or extend your own.The code you are talking about sounds like  which was introduced in Java 6 to support a feature that has been defined since  or earlier. For performance reasons, this is the recommended approach to find interface implementations at runtime; if you need support for this in an older version of Java, I hope that you'll find  helpful.There are a couple of implementations of this in earlier versions of Java, but in the Sun packages, not in the core API (I think there are some classes internal to ImageIO that do this). As the code is simple, I'd recommend providing your own implementation rather than relying on non-standard Sun code which is subject to change.I know this question has already been answered a long time ago but another solution to this problem is to use Package Level Annotations.While its pretty hard to go find all the classes in the JVM its actually pretty easy to browse the package hierarchy. Then just make your annotation have an argument of an array of Class.\nThen in your package-info.java for a particular package put the MyAno.I'll add more details (code) if people are interested but most probably get the idea.To add to @erickson answer you can also use the service loader approach. Kohsuke has an awesome way of generating the the required META-INF stuff you need for the service loader approach:You could also use the Extensible Component Scanner (extcos: ) and search all classes implementing an interface like so:This works for classes on the file system, within jars and even for those on the JBoss virtual file system. It's further designed to work within standalone applications as well as within any web or application container.In full generality, this functionality is impossible. The Java ClassLoader mechanism guarantees only the ability to ask for a class with a specific name (including pacakge), and the ClassLoader can supply a class, or it can state that it does not know that class.Classes can be (and frequently are) loaded from remote servers, and they can even be constructed on the fly; it is not difficult at all to write a ClassLoader that returns a valid class that implements a given interface for  name you ask from it; a List of the classes that implement that interface would then be infinite in length.In practice, the most common case is an  that looks for classes in a list of filesystem directories and JAR files. So what you need is to get the , then iterate through those directories and archives, and for each class file you find in them, request the corresponding  object and look through the return of its  method.Obviously, Class.isAssignableFrom() tells you whether an  class implements the given interface. So then the problem is getting the list of classes to test.As far as I'm aware, there's no direct way from Java to ask the class loader for \"the list of classes that you could  load\". So you'll have to do this yourself by iterating through the visible jars, calling Class.forName() to load the class, then testing it.However, it's a little easier if you just want to know classes implementing the given interface from those that have  been loaded:If you use the instrumentation technique, then (as explained in the link) what happens is that your \"agent\" class is called essentially when the JVM starts up, and passed an Instrumentation object. At that point, you probably want to \"save it for later\" in a static field, and then have your main application code call it later on to get the list of loaded classes.If you were asking from the perspective of working this out with a running program then you need to look to the java.lang.* package. If you get a Class object, you can use the isAssignableFrom method to check if it is an interface of another Class.There isn't a simple built in way of searching for these, tools like Eclipse build an index of this information.If you don't have a specific list of Class objects to test you can look to the ClassLoader object, use the getPackages() method and build your own package hierarchy iterator.Just a warning though that these methods and classes can be quite slow. "},
{"body": "A GUI with no white space appears 'crowded'.  How can I provide white space without resorting to explicitly setting the position or size of components?\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adUsing various  one can provide spacing between various components. There are a number of ways in a Swing GUI to provide a separation between components, and white space around components:But more generally, look to:Here is an example of using the layout separator  &  values & borders (specifically an ) to provide 'white' (actually shown as 'red' to make it very obvious) space.  Adjust the spinners to see the result.When you use ,  method can help you to make some white space.Another method is . It can help you to make some white space around component.Thanks for Andrew Thompson's remind.I've revised BoxLayout in recent days and I     find that  can add some white space depend on the panel's size and you can not set the explicit pixel value of the length of white space.But  can do that.  Here is a MCTaRE and show the    effect of those two methods. and  can be used too. Besides,  has the ability too create white space too. has multiple ways of creating space. (A space is called a gap in this layout.)\nGaps can be created at the highest level with layout constraints, it is possible to\ncreate gaps between rows and column and gaps can be also set between individual \ncomponents with component constraints. There are also specific gaps around the borders\nof a container called insets which have their own specific keyword to be set.The following example creates all these kinds of gaps:We have four panels in the layout. Each of this panels has a  manager.This line creates container insets and vertical gaps between panels.Here we apply gaps for the whole grid structure and also set container gaps.This line creates gaps between columns.Row gaps are defined with this code.Finally, it is possible to create gaps between individual components.  Author Karsten Lentzsch has a collection of  on UI design.   In particular  speaks to the need for aesthetic whitespace.  Adding meaningful space while also paying attention to clutter separates the wheat from the chaff."},
{"body": "OK, this should really be asked to someone from Google, but I just want other opinions.Even Android supports Native code applications, the main development tool is Java. But why? I mean, isn't it too slow to interpret code on a mobile device? When introducing Froyo, Google said that new JIT compiler can achieve 2-5 times faster applications. This means, that using Java over native code is 2-x times slower.Yes, I know that using managed code applications is safer in terms of system stability, since virtual machine has better control of program, but still, this performance drop is huge, and I don't see any point why to use it.Some points:On the byte-code level, Android doesn't use Java.  The source is Java, but it doesn't use a JVM.The improvement to system stability is  on a device like a cell phone.  is even more important. The Android environment lets users run semi-trusted apps which could exploit the phone in truly unpleasant ways without excellent security. By running all apps in a virtual machine, you guarantee that no app can exploit the OS kernel unless there is a flaw in the VM implementation. The VM implementation, in turn, is presumably small and has a small, well-defined security surface. Perhaps most important, when programs are compiled to code for a virtual machine, they do not have to be recompiled for new hardware. The market for phone chips is diverse and rapidly-changing, so that's a big deal.Also, using Java makes it less likely that the apps people write will be exploitable themselves. No buffer-overruns, mistakes with pointers, etc...Native code is not necessarily any faster than Java code. Where is your profile data showing that native code could run faster?Why Java?Java has a pretty compelling argument for Google using it in Android: it has a huge base of developers. All these developers are (kind of) ready to develop for their mobile platform.Keep in mind that, technically speaking, Android does not use  Java.First of all, according to Google, Android doesn't use Java. That's why Oracle is suing Google. Oracle claims that Android infringes on some Java technology, but Google says it's Dalvik.Secondly, I haven't seen a Java byte code interpreter since 1995.Can you back up your performance conjecture with some actual benchmarks? The scope of your presumptions don't seem justified given the inaccurate background information you provide.As touched on elsewhere, the main issue is that Android is designed as a portable OS, to run on a wide variety of hardware.\nIt's also building on a framework and language familiar to many existing mobile developers.Finally, I would say it is a bet against the future - whatever performance issues exist will become irrelevant as hardware improves - equally by getting developers to code against an abstraction, Google can rip-out and change the underlying OS far more easily, than if developers were coding to the POSIX/Unix APIs.For most applications the overhead of using a VM-based language over native is not significant (the bottleneck for apps consuming web services, like Twitter, is mostly networking). The Palm WebOS also demonstrates this - and that uses JavaScript rather than Java as the main language.  Given that almost all VMs JIT compile down to native code, raw code speed is often comparable with native speed. A lot of delays attributed to higher-level languages are less to do with the VM overhead than other factors (a complex object runtime, 'safety' checking memory access by doing bounds checking, etc).Also remember that regardless of the language used to write an application, a lot of the actual work is done in lower level APIs. The top level language is often just chaining API calls together.There are, of course, many exceptions to this rule - games, audio and graphics apps that push the limits of phone hardware. Even on the iOS, developers often drop down to C/C++ to get speed in these areas.The new JIT is running the applications 2 - 5 times faster than the old dalvikVM (both JAVA). So comparison is not C over JAVA, but JIT over dalvikVM.First of all it's about the same thing will windows mobile or the iPhone, the .net framework needs its own VM as well as cocoa.And even if the performance is not at the best, because it's an interpretation of byte code, android brings the entire java community as potential developers. More applications, more clients, etc.To finish, no performance is not that bad, that's why java is used even on smaller devices (see JavaMe)."},
{"body": "I'm attempting to override the default  appearance. Here's the XML that defines the :Now, we have two 30 x 30 icons we want to use for the clicked/non-clicked states. Right now we have code that programmatically changes the background icon depending on the state:Obviously I'm looking for a better way to do this. I've tried to make a selector for the background image, which would automatically switch between the states:But this does not work; reading the  API (), it appears that the only inherited xml attributes areThere does not seem to be the android:state_checked attribute, despite the class having the method  and .So, is there a way to do what I want in XML, or am I stuck with my messy workaround?Your code is fine. However, the toggle button will display the first item in your selector that it matches, so the default should come last. Arrange the items in the following manner to ensure they will all be utilized:"},
{"body": "In javadoc for  is the following:What does it mean? What happens if I try to iterate the map with two threads at the same time? What happens if I put or remove a value from the map while iterating it?That means that each iterator you obtain from a  is designed to be used by a single thread and should not be passed around. This includes the syntactic sugar that the for-each loop provides.It will work as expected if each of the threads uses it's own iterator. It is guaranteed that things will not break if you do this (that's part of what the \"concurrent\" in  means). However, there is no guarantee that one thread will see the changes to the map that the other thread performs (without obtaining a new iterator from the map). The iterator is guaranteed to reflect the state of the map at the time of it's creation. Futher changes may be reflected in the iterator, but they do not have to be.In conclusion, a statement likewill be fine (or at least safe) almost every time you see it. You may use this class to test two accessing threads and one mutating the shared instance of :No exception will be thrown.Sharing the same iterator between accessor threads can lead to deadlock:As soon as you start sharing the same  among accessor and mutator threads s will start popping up.It means that you should not share an iterator object among multiple threads. Creating multiple iterators and using them concurrently in separate threads is fine.It means that you should not try to use the same iterator in two threads.  If you have two threads that need to iterate over the keys, values or entries, then they each should create and use their own iterators.It is not entirely clear what would happen if you broke this rule.  You could just get confusing behavior, in the same way that you do if (for example) two threads try to read from standard input without synchronizing.  You could also get non-thread-safe behavior.But if the two threads used different iterators, you should be fine.That's a separate issue, but the javadoc section that you quoted adequately answers it.  Basically, the iterators are thread-safe, but  whether you will see the effects of any concurrent insertions, updates or deletions reflected in the sequence of objects returned by the iterator.  In practice, it probably depends on where in the map the updates occur. might give you a good insight Regarding this:It means, while using iterators produced by ConcurrentHashMap in two threads are safe, it may cause an unexpected result in the application."},
{"body": "At the moment a default entry looks something like this:How do I get it to do this?Clarification I'm using java.util.loggingAs of Java 7,  supports getting its  from a system property, so adding something like this to the JVM command line will cause it to print on one line:Alternatively, you can also add this to your :Java 7 supports a property with the  format string syntax.See .My favorite is:which makes output like:IDEs typically let you set system properties for a project.\nE.g. in NetBeans, instead of adding -D...=... somewhere, add the property in the action dialog, in a form of  - without any quotes. The IDE should figure out.For your convenience, Here is how to put it to Surefire:I have a library with . Amongst them, it's .\n Downloadable jar .Like Obediah Stane said, it's necessary to create your own  method. But I would change a few things:The following class can be  in a , which in turn can be  to the . Note that it ignores all class and method information available in the .Similar to Tervor, But I like to change the property  on runtime. Note that this need to be set before the first SimpleFormatter is created - as was  written in the comments.Per screenshot, in Eclipse select \"run as\" then \"Run Configurations...\" and add the answer from Trevor Robinson with double quotes instead of quotes. If you miss the double quotes you'll get \"could not find or load main class\" errors.I've figured out a way that works. You can subclass SimpleFormatter and override the format methodA bit surprised at this API I would have thought that more functionality/flexibility would have been provided out of the boxThis is what I'm using.You'll get something like...This logging is specific to your application and not a general Java feature. What application(s) are you running?It might be that this is coming from a specific logging library that you are using within your own code. If so, please post the details of which one you are using.If you log in a web application using tomcat add:On VM argumentsif you're using java.util.logging, then there is a configuration file that is doing this to log contents (unless you're using programmatic configuration).  So, your options are \n1) run post -processor that removes the line breaks\n2) change the log configuration AND remove the line breaks from it. Restart your application (server) and you should be good."},
{"body": "Following is resulting in an :Is there a better way to parse  to get  than: ?Use :You can use this (the French locale has  for decimal separator)Or you can use  and set the appropriate symbols:As E-Riz points out, NumberFormat.parse(String) parse \"1,23abc\" as 1.23. To take the entire input we can use:If you don't know the correct Locale and the string can have a thousand separator this could be a last resort:Be aware: this will happily parse strings like \"R 1 52.43,2\" to \"15243.2\".This is the static method I use in my own code:...is very quick as it searches the underlying character array on a char-by-char basis. The string replace versions compile a RegEx to evaluate.Basically replace(char,char) is about 10 times quicker and since you'll be doing these kind of things in low-level code it makes sense to think about this. The Hot Spot optimiser will not figure it out... Certainly doesn't on my system.You of course need to use the correct locale.  question will help.This would do the job:"},
{"body": "When running any java application, or just 'java', the jvm fails:Here is a list of  answers:Any ideas?The problem comes from an improper java installation (e.g. an installation done without admin rights or by simply unzipping tools.zip).You can either uninstall, then reinstall Java with an installer and/or more privileges or try the following:Check in your JDK folder for  files in  and \nsuch as  (the default location is  for Microsoft Windows and   for Unix/GNU Linux) Those  files need to be unpacked to  files using this command:and repeat that step with all of the *.pack files and relaunch your program.  For java 8 @ *NIX OS:From directory  (For me it: /usr/java/jdk1.8.0_05/jre/lib)Run:(May You can't use the system's unpack200 cause version problems.)\nThis unpack200 is in java 8 directory (for me: /usr/java/jdk1.8.0_05/bin)BenedekIt seems that for a 64 bit architecture you have to install both the 32-bit version and the 64-bit version of jre (architecture independent files as rt.jar are distributed only in the 32-bit version).Remember then to pay attention to include the correct java executable on the global PATH environment variable. for impatient people ;) On  machines, try this:\nGo to  directory and delete  (or rename it to something like ).Since at least 1.6, there should not be a  in the Windows directory. If there is, it's a leftover from something. I'm really suprised that a question from 2012 doesn't have an approved answer yet and I've actually encountered the same issue in 2015 on my Win 7 32-Bit OS!So what did happen?Basically, everything was working fine, I downloaded H2 database and when I tried to start  I got:I found this question and I was able to confirm the same symptoms:JAVA_HOME is set correctly: fails, while  works fine:\nGo to  directory and delete (I actually renamed)  file!!!!Now, I get:and  works fine as well!Credits go to the last post in this forum:\nYou are most probably missing a file called rt.jar in your installation which has the class file for java.lang.Object. Check your install files etc.In particular, note that a 64-bit intsaller overlays (or installs \"next to\") an existing 32-bit installation. In other words, to get a fully working 64-bit installation, you must first run the 32-bit installation, and follow that up with a 64-bit installation if you have a 64bit capable machine...If instead you do just a 64-bit installation you will be missing certain files in the installation and will get errors such as the one above.I downloaded new JDK today (1.8.0.73) started  and got the infamous:I just wanted to share my working solution on here.When I cd'ied into the  folder, Java would run fine so I knew it was the . I set  to just  at CMD to prove it and it worked.So, one of the folders in the  must have had  that was causing the conflict, I thought. As it turned out, it was  that holds  to the executables.  was pointing to . The file was corrupt, when I started --the exact same error. Bingo. I re-installed JRE and the problem went away. Happy coding...This problem happens when you install the JDK by  it instead of  it. In the first scenario, the runtime libraries, as rt.jar, don't get automatically uncompresessed (thus, you can find the rt.pack files, etc. instead of the .jar ones).You cannot install just the 64bit, you must first install the 32bit and then add the 64bit components.From java.com:I had the same problem recently. In my case my windows 7 machine automatically downloaded java and added  to the beginning of my path environment variable, which messed up my java. Once I got rid of that from the path, it worked.if you do \"chmod u+rx\" on the java binary and run it, it will the unpack the jar files and you can do a java -version without runtime errors If you install a 64-bit version without first installing 32-bit, this error will occur despite fixing all of the other issues.  I have a brand new Dell i7 64-bit Windows 10 Pro machine running Java 8u71.  After having added my %path% and %classpath% to environment variables and trying several other fixes, uninstalling 64-bit, installing 32-bit then reinstalling 64-bit fixed it.Some of the issues, like not having your files unpacked, etc. that have been mentioned as possible causes may still be causing issues, but if you don't do this, as well, the other fixes won't work.In my case, I use a windows 8.1 (installed jdk1.8.0_77), I did three things:and voila got it fixed!I have faced the similar issue and found that the symlink in program data(C:\\ProgramData\\Oracle\\Java\\javapath) was wrong. I have given the correct path and it worked.Another answer could be to use the tar.gz file instead in the Linux case. There seem to be something like that also for the solaris platform. This way all files will already be in the expected format and there won't be any unpacking issues.I have the some problem on x86_64 Linux installations with JDK 1.7.0_40 i586.\nI figured out that the problem is that rpm can't unpack jar files, as mentioned by Rigg802 (though rpm completes marking success):File /lib/ld-linux.so.2 is provided by glibc-2.12-1.107.el6_4.4. which is not among rpm deps of jdk rpm.Oracle JDK rpm also requires 32 bit versions of libgcc-4.4.7-3.el6. to be installedSo, workaround is to install glibc-2.12-1.107.el6_4.4.i686 and libgcc-4.4.7-3.el6.i686 first.Quick fix that worked for me:I found that this error occurred when I extracted the .rpm file.I then removed that folder and downloaded jdk-7u79-linux-x64.tar.gz for Linux 64 and extracted the contents of this file instead.\nAlso:\n    export JAVA_HOME=/opt/java/jdk1.7.0_79\n    export JDK_HOME=/opt/java/jdk1.7.0_79\n    export PATH=${JAVA_HOME}/binJust install the jre . It simply solved my problem. (SonarQube startup batch started to give this error after I installed jdk)Go to control panel, uninstall the java related stuff(close eclipse if opened), then re-install java and open eclipse, clean projects.Just did this on Solaris and ran into this identical problem where even \"java -version\" does not work.  There is a reason that the 64 bit versions of the distro are WAY smaller than the 32-bit.  It is indeed as stated above: In other words, to get a fully working 64-bit installation, you must first run the 32-bit installation, and follow that up with a 64-bit installation if you have a 64bit capable machine...So I ran the installer for the 32-bit:Then I ran the installer for the 64-bit:This gives me several java executables to choose from:The sparcv9 java's are the 64bit versions and they work with \"-version\" when installed alongside the 32bit JDK.-DanOn Windows 10, I was facing the same issue with JRE 1.8 (8u121).\nTyping     the cmd prompt returnsAll the other commands, , , ,  worked fine.Going to environment variables on system administration panel, remove from PATH the link , and be sure to have set in PATH the link to .After that, check if in  exists a  file; if true, delete that file.Typing now  it works fine.I was facing same issue: Error occurred during initialization of VM\njava/lang/NoClassDefFoundError: java/lang/ObjectFollow below steps to resolve issue :Step 1. Goto C:\\Program Files\\ and search for Java folder.Step 2. Delete C:\\Program Files\\Java folder.Step 3. Download new Jdk for your version 32 bit/64 bit from Step 4. Install JDKStep 5: Now Set JAVA_HOME to \"C:\\Program Files\\Java\\jdk1.8.0_91\"Step 6: Open command prompt and enter java -version.It works.I faced same issue, I have installed two java version hence it caused this issue. to confirm this go and click java icon in control panel if doesnt open then issue is same, just go and uninstall one version. piece of cake. thanks."},
{"body": "Is there some one-liner bridge method to dump a given Enumeration to java.util.List or java.util.Set?Something built-in like  or  should exist somewhere, but I'm unable to find that in my IntelliJ debugger's evaluator window (and Google/SO results, too).Thanks in advance,\nAntonYou can use  to convert an  to a  in one line:There's no similar method to get a , however you can still do it one line:How about this: There is a simple example of convert enumeration to list. for this i used    method. Reference :  If you need  rather than , you can use .: JakeRobb is right. My answer is about java.lang.Enum instead of java.util.Enumeration. Sorry for unrelated answer.I needed same thing and this solution work fine, hope it can help someone alsothen you can get the .name() of your enumeration.When using guava (See ) there is . Given an  you can do the following:to get a immutable Set:to get a immutable List:to get a hashSet:"},
{"body": "I've always been able to allocate 1400 megabytes for Java SE running on 32-bit Windows XP (Java 1.4, 1.5 and 1.6).Today I tried the same option on a new Windows XP machine using Java 1.5_16 and 1.6.0_07 and got the error:Through trial and error it seems 1200 megabytes is the most I can allocate on this machine.Any ideas why one machine would allow 1400 and another only 1200?Edit: The machine has 4GB of RAM with about 3.5GB that Windows can recognize.Keep in mind that Windows has virtual memory management and the JVM only needs memory that is contiguous . So, other programs running on the system shouldn't necessarily impact your heap size. What will get in your way are DLL's that get loaded in to your address space. Unfortunately optimizations in Windows that minimize the relocation of DLL's during linking make it more likely you'll have a fragmented address space. Things that are likely to cut in to your address space aside from the usual stuff include security software, CBT software, spyware and other forms of malware. Likely causes of the variances are different security patches, C runtime versions, etc. Device drivers and other kernel bits have their own address space (the other 2GB of the 4GB 32-bit space).You  try going through your DLL bindings in your JVM process and look at trying to rebase your DLL's in to a more compact address space. Not fun, but if you are desperate...Alternatively, you can just switch to 64-bit Windows and a 64-bit JVM. Despite what others have suggested, while it will chew up more RAM, you will have  more contiguous virtual address space, and allocating 2GB contiguously would be trivial.This has to do with contiguous memory. for somebody asking that before, supposedly from a \"VM god\":The Java heap size limits for Windows are:This doesn't help you getting a bigger Java heap, but now you know you can't go beyond these values., which can handle a non-contiguous heap, can have a Java heap size of 2.85 GB on Windows 2003/XP with the /3GB switch. It seems that fragmentation can have quite an impact on how large a Java heap can be.The JVM needs contiguous memory and depending on what else is running, what was running before, and how windows has managed memory you may be able to get up to 1.4GB of contiguous memory.  I think 64bit Windows will allow larger heaps.Sun's JVM needs contiguous memory. So the maximal amount of available memory is dictated by memory fragmentation. Especially driver's dlls tend to fragment the memory, when loading into some predefined base address. So your hardware and its drivers determine how much memory you can get. Two sources for this with statements from Sun engineers:  Maybe another JVM? Have you tried ? I think they planned to allow non-continuous memory.I think it has more to do with how Windows is configured as hinted by this response:\nSome more testing: I was able to allocate 1300MB on an old Windows XP machine with only 768MB physical RAM (plus virtual memory). On my 2GB RAM machine I can only get 1220MB. On various other corporate machines (with older Windows XP) I was able to get 1400MB. The machine with a 1220MB limit is pretty new (just purchased from Dell), so maybe it has newer (and more bloated) Windows and DLLs (it's running Window XP Pro Version 2002 SP2).I got this error message when running a java program from a (limited memory) virtuozzo VPS. I had not specified any memory arguments, and found I had to explicitly set a  amount as the default must have been too high. E.g. -Xmx32m (obviously needs to be tuned depending on the program you run).Just putting this here in case anyone else gets the above error message without specifying a large amount of memory like the questioner did.sun's JDK/JRE needs a contiguous amount of memory if you allocate a huge block.The OS and initial apps tend to allocate bits and pieces during loading which fragments the available RAM. If a contiguous block is NOT available, the SUN JDK cannot use it. JRockit from Bea(acquired by Oracle) can allocate memory from pieces.Here is how to increase the Paging sizeEveryone seems to be answering about contiguous memory, but have neglected to acknowledge a more pressing issue.Even with 100% contiguous memory allocation, you can't have a 2 GiB heap size on a 32-bit Windows OS (*by default). This is because 32-bit Windows processes cannot address more than 2 GiB of space.The Java process will contain perm gen (pre Java 8), stack size per thread, JVM / library overhead (which pretty much increases with each build) .Furthermore, JVM flags and their default values change between versions. Just run the following and you'll get some idea:Lots of the options affect memory division in and out of the heap. Leaving you with more or less of that 2 GiB to play with...To reuse portions of  answer of mine (about Tomcat, but applies to any Java process):First, using a page-file when you have 4 GB of RAM is useless. Windows can't access more than 4GB (actually, less because of memory holes) so the page file is not used.Second, the address space is split in 2, half for kernel, half for user mode. If you need more RAM for your applications use the /3GB option in boot.ini (make sure java.exe is marked as \"large address aware\" (google for more info).Third, I think you can't allocate the full 2 GB of address space because java wastes some memory internally (for threads, JIT compiler, VM initialization, etc). Use the /3GB switch for more."},
{"body": "What is the concept of erasure in generics in Java?It's basically the way that generics are implemented in Java via compiler trickery. The compiled generic code  just uses  wherever you talk about  (or some other type parameter) - and there's some metadata to tell the compiler that it really is a generic type.When you compile some code against a generic type or method, the compiler works out what you really mean (i.e. what the type argument for  is) and verifies at  time that you're doing the right thing, but the emitted code again just talks in terms of  - the compiler generates extra casts where necessary. At execution time, a   and a  are exactly the same; the extra type information has been  by the compiler.Compare this with, say, C#, where the information is retained at execution time, allowing code to contain expressions such as  which is the equivalent to  - except that the latter is invalid. (There are further differences between .NET generics and Java generics, mind you.) Type erasure is the source of many of the \"odd\" warning/error messages when dealing with Java generics.Other resources:Just as a side-note, it is an interesting exercise to actually see what the compiler is doing when it performs erasure -- makes the whole concept a little easier to grasp.  There is a special flag you can pass the compiler to output java files that have had the generics erased and casts inserted.  An example:The  is the flag that gets handed off to the compiler that generates the files.  (The  part is what tells  to hand it to the executable jar that actually does the compiling rather than just , but I digress...)  The  is necessary because the compiler needs some place to put the new .java files.This, of course, does more than just erasure; all of the automatic stuff the compiler does gets done here.  For example, default constructors are also inserted, the new foreach-style  loops are expanded to regular  loops, etc.  It is nice to see the little things that are happening automagically.To complete the already very complete Jon Skeet's answer, you have to realize the concept of  derives from a need of .Initially presented at EclipseCon 2007 (no longer available), the compatibility included those points:Original answer:Hence:There are propositions for a greater . Reify being \"Regard an abstract concept as real\", where language constructs should be concepts, not just syntactic sugar.I should also mention the  method of Java\u00a06, which returns a dynamically typesafe view of the specified collection. Any attempt to insert an element of the wrong type will result in an immediate .The generics mechanism in the language .Usually this is not a problem, as the compiler issues warnings on all such unchecked operations.There are, however, times when static type checking alone is not sufficient, like:Update July 2012, almost four years later:It is now (2012) detailed in \"\"Erasure, literally means that the type information which is present in the source code is erased from the compiled bytecode. Let us understand this with some code.If you compile this code and then decompile it with a Java decompiler, you will get something like this. Complementing the already-complemented Jon Skeet answer...It has been mentioned that implementing generics through erasure leads to some annoying limitations (e.g. no ).  It has also been mentioned that the primary reason for doing things this way was backwards compatibility in the bytecode.  This is also (mostly) true.  The bytecode generated -target 1.5 is somewhat different from just de-sugared casting -target 1.4.  Technically, it's even possible (through immense trickery) to gain access to generic type instantiations , proving that there really is something in the bytecode.The more interesting point (which has not been raised) is that implementing generics using erasure offers quite a bit more flexibility in what the high-level type system can accomplish.  A good example of this would be Scala's JVM implementation vs CLR.  On the JVM, it is possible to implement higher-kinds directly due to the fact that the JVM itself imposes no restrictions on generic types (since these \"types\" are effectively absent).  This contrasts with the CLR, which has runtime knowledge of parameter instantiations.  Because of this, the CLR itself must have some concept of how generics should be used, nullifying attempts to extend the system with unanticipated rules.  As a result, Scala's higher-kinds on the CLR are implemented using a weird form of erasure emulated within the compiler itself, making them not-entirely-compatible with plain-old .NET generics.Erasure may be inconvenient when you want to do naughty things at runtime, but it does offer the most flexibility to the compiler writers.  I'm guessing that's part of why it's not going away any time soon.As I understand it (being a  guy) the  has no concept of generics, so the compiler replaces type parameters with Object and performs all the casting for you.This means that Java generics are nothing but syntax sugar and don't offer any performance improvement for value types that require boxing/unboxing when passed by reference.The  is defined as follows: For example:1.The  of , , and  is .2.The  of  is .3.The  of  is .4.The  of  or  is .Now consider a class ,This will  because Now consider  This will show up a  becauseGenerics were introduced to the Java language to provide tighter type checks at compile time and to support generic programming. To implement generics, the Java compiler applies type erasure to:Replace all type parameters in generic types with their bounds or Object if the type parameters are unbounded. The produced bytecode, therefore, contains only ordinary classes, interfaces, and methods.\nInsert type casts if necessary to preserve type safety.\nGenerate bridge methods to preserve polymorphism in extended generic types.\nType erasure ensures that no new classes are created for parameterized types; consequently, generics incur no runtime overhead.Erasure of Generic TypesDuring the type erasure process, the Java compiler erases all type parameters and replaces each with its first bound if the type parameter is bounded, or Object if the type parameter is unbounded.Consider the following generic class that represents a node in a singly linked list:public class Node {}\nBecause the type parameter T is unbounded, the Java compiler replaces it with Object:public class Node {}\nIn the following example, the generic Node class uses a bounded type parameter:public class Node> {}\nThe Java compiler replaces the bounded type parameter T with the first bound class, Comparable:public class Node {Java docs for Generics  : Generic programming is introduce in java 1.5 version\n\nGeneric programming is a type safe object,Before generic in collection we can store any type of object. and after generic we must to store the data of specific type of object.  \nThe main advantages of generic is Type casting is not required and also type-sage and Generic will check the compile time. and the general syntax of Generic is ClassOrInterface here type is the signal that this class can have set the class when it instantiated  .\nGenericClassDemo\n\n"},
{"body": "can anyone help. I keep getting an error message in eclipse when creating a new project and i don't understand why.I have created a workspace at the levelInside Counter there are no files but there is a directory called counter_src which contains source files for the project CounterSo in eclipse I do, new java project, and then uncheck default location and choose the directory counter_src  (which is one level down from Counter)but it now displaysNow if i create my workspace at which means my counter_src is actually 2 levels down then it allows me, but the problem is that the directory JAVA contains lots of projects so i wanted to create the workspace in Counter (which has no files) which has subdirectory of counter_src where my source files are.Also tested creating directory off of C:\\Users\\Martin\\Java\\ and it appears to work also but I didn't want to create another subdirectory off of \"C:\\Users\\Martin\\Java\\\" just to store my workspace for 1 project.I would really appreciate any help on this, i am a little list.Thnaks in advanceEclipse is erroring because if you try and create a project on a directory that exists, Eclipse doesn't know if it's an actual project or not - so it errors, saving you from losing work!So you have two solutions:So, I was having the same issue, but trying to  via the \"Import...\" menu. When neither of the above two solutions worked on Eclipse Juno:Once the project rebuilds, everything should be back in order.(This was written when Eclipse Indigo was in vogue, and there may be changes as Google updates their tools to cover corner cases.)This has  More your project folder outside your workspace in some other location and then try. Go to Assume D:\\MyDirectory\\MyWorkSpace        - Path of your WorkSpace  in In my case checking the check-box did the trick.simply \"CUT\" project folder and move it out of workspace directory and do the followingand you done !This too took me sometime to figure out.To create a new  under the existing workspace, just have the \"\" ticked ().The name of the project will be determined by you  in step 2 of the creation wizard.It was so confusing because in my case, because when I selected to create a new Maven Project: the default workspace loaction is ticked and directly proceeding it is the grayed out \"Location\" text input had the workspace location + the existing project I was looking at before choose to create a new Maven Project. (ie: Location = '[workspace path]/last looked at project')So I unticked the default workspace location box and entered in '[workspace path]/new project', which didn't work because eclipse expects the [workspace path] to be different compared to the default path. (Otherwise we would of selected the default workspace check box). In my case clicking the checkbox for 'import project into workspace' fixed the error, even though the project was already in the workspace folder and didn't actually get moved their by eclipse.FWIW:Neither of the other suggestions worked for me. I had previously created a project with the same name which I then deleted. I recreated the base source-files (using PhoneGap) - which doesn't create the \"eclipse\"-project. I then tried to create an Android project using existing source files, but it failed with the same error message as the original question implies. The solution for me was to move the source-folder and files out of the workspace, and use the same option, but this time check the option for copying the files into the workspace in the wizard.I know this is older, but wanted to contribute another possibly solution.If you want to keep the project location, as I did, I found that copying the .project file from another project into the project's directory, then editing the .project file to name it properly, then choosing the Import Existing Projects into Workspace option worked for me.In Windows, I used a file monitor to see what Eclipse was doing, and it was simply erroring out for some unknown reason when trying to create the .project file. So, I did that manually and it worked for me.If the project type isn't recognized, preventing one of these import methods from working, then try this.  Once you add the generic project, you can then add support for whatever language you require."},
{"body": "There are discussions around  vs  in Java. The default value of the former is  while in the latter it's . How about  vs ? A variable in my application can have / values. I would like to use / and prefer not to use . Can I use / instead? you can use / instead.First one is Object and second one is primitive type.Now choose your way.  the boolean primitive type. In JDK 5 and upwards, Oracle (or Sun before Oracle bought them) introduced , which essentially allows you to do thisorWhich essentially the compiler does, So, for your answer, it's YES.I am a bit extending provided answers (since so far they concentrate on their \"own\"/artificial terminology focusing on programming a particular language instead of taking care of the bigger picture behind the scene of , in general, i.e. when things like type-safety vs. memory considerations make the difference):Consider with outputJava code on 3rd line  illustrates that  () cannot be implicitly converted (casted) into an . I am bringing this up not to illustrate the details of implementation behind JVM, but to point out that in terms of low level considerations (as memory size) one does have to prefer values over type safety. Especially if that type safety is not truly/fully used as in boolean types where checks are done in form of All just to state that {0,1} < {-2^31, .. , 2^31 -1}. Seems like an overkill, right? Type safety is truly important in user defined types, not in implicit casting of primitives (although last are included in the first).Note that in memory your variable from range of {0,1} will still occupy at least a byte or a word (xbits depending on the size of the register) unless specially taken care of (e.g. packed nicely in memory - 8 \"boolean\" bits into 1 byte - back and forth).By preferring type safety (as in putting/wrapping value into a box of a particular type) over extra value packing (e.g. using bit shifts or arithmetic), one does effectively chooses writing less code over gaining more memory. (On the other hand one can always define a custom user type which will facilitate all the conversion not worth than Boolean).Finally, your question is about comparing  vs. . I believe it is important to explain why or how exactly you will get performance by using/preferring keywords (\"marked\" as ) over types (normal composite user-definable classes using another keyword )\nor in other wordsvs.The first \"thing\" (type) can not be extended (subclassed) and not without a reason. Effectively Java terminology of  and   classes can be simply translated into  value (a LITERAL or a constant that gets directly substituted by compiler whenever it is possible to infer the substitution or  if not - still fallback into wrapping the value). Optimization is achieved due to trivial:That is why when the actual type inference is done it may (still) end up in instantiating of wrapping class with all the type information if necessary (or converting/casting into such).So, the difference between  and  is exactly in  and  (a bit far going but almost as  vs. ). Note the fact that Java can do  is just a \"syntactic sugar\". It does not speed up anything, just allows you to write less code. That's it. Casting and wrapping into type information container is still performed. For performance reasons choose arithmetics which will always skip extra housekeeping of creating class instances with type information to implement type safety. Lack of  is the price you pay to gain performance. For code with boolean-valued expressions type safety (when you write less and hence  code) would be critical e.g. for if-then-else flow controls.You can use the  -  and  instead of  and . You can create your variable as of type  if primitive is what you are after. This way you won't have to create new  objects.  Basically boolean represent a primitive data type where Boolean represent a reference data type. this story is started when Java want to become purely object oriented it's provided wrapper class concept to over come to use of primitive data type. and  are not same.The java.lang.Boolean class wraps a value of the primitive type boolean in an object. An object of type Boolean contains a single field whose type is booleanFollowing is the declaration,\npublic final class Boolean\n   extends Object\n      implements Serializable, Comparable"},
{"body": "In the context of security frameworks, a few terms commonly occur ,  and , of which I have not been able to find a clear definition and the difference between them. So, what exactly do these terms mean, and why are these distinctions of  and  needed?These are hierarchical in the way that genus, species and individual are hierarchical.Subject/Object inherits from the same terms as used in grammar.  In a sentence the subject is the actor and the object is the thing acted on.  In this sense the use has been around since before computers were invented.  In a security context, a subject is anything that can make a request.  As noted above, this need not be limited to IT security and so is a very broad classification.  The interesting thing is that subject implies object.  Without an object, there is no subject.Principals are what subjects resolve to.  When you present your credit card you are the subject and the account number is the principal.  In other contexts your user ID or state-issued identification is your principal.  But principals can be associated with many types of subject that are not people.  When applications make requests for system-level functions the principal may the signer of a signed executable code module but even in that case the user driving the request is still the subject.User is more specific than subject or principal in that it usually refers to an interactive operator.  That is why we have a graphical User Interface and not a Graphical Principal Interface.  A user is an instance of  that resolves to a .  A single user may resolve to any number of principals but any principal is expected to resolve to a single user (assuming people observe the requirement not to share IDs).  In the example above, the signer of an executable code module is definitely  the user, but it  a valid principal.  The interactive operator trying to get the module loaded is the user.As noted in the comments, even the authoritative sources do not agree on these terms.  I searched NIST, SANS, IEEE, MITRE and several \"quasi-authoritative\" sources such as security exam guides while preparing this response. No single source that I found which was at least quasi-authoritative covered all three terms and all differed significantly in their usage.  This is my take on how the terms  be used but from a practical standpoint, when you are poring over a manual in the middle of the night, the definitions tend to be whatever the vendor or writer say they are.  Hopefully though responses here will provide enough insight to navigate the waters and parse any security document using these terms.Have a look at my :I think the terminology is taken from . is the entity that requests a service. It can be a user or a process. Probably that is why the name Subject was chosen instead of user. When a subject tries to access a service, the subject has to be authenticated first. Successful authentication ends with loading the  for that Subject. For example, in a Role Based Access Control system, an authenticated (logged-in) user will usually have two principals - userId and roleId. In such systems, the privileges(i.e who can access what) are specified for both roles and for users. During authorization(i.e checking whether the requested service should be permitted), the security system will check for accessibility against both the principals. Therefore, from the perspective of authorization, principals are the actual entities for which access is allowed or disallowed. Subject is just a user/thread/process that holds some principals. As T.Rob explained, Subject is any entity that requests access to an object. Starting from that point I've found a comment on javax.security.auth.Subject code that i've found VERY useful and easy to understand:\"Subjects may potentially have multiple identities. Each identity is represented as a Principal within the Subject. Principals simply bind names to a Subject. For example, a Subject that happens to be a person, Alice, might have two Principals: one which binds \"Alice Bar\", the name on her driver license, to the Subject, and another which binds, \"999-99-9999\", the number on her student identification card, to the Subject. Both Principals refer to the same Subject even though each has a different name.\"Hope it helps."},
{"body": "It's been a while from those school years. Got a job as IT specialist at a hospital.  Trying to move to do some actual programming now.  I'm working on binary trees now, and I was wondering what would be the best way to determine if the tree is height-balanced.  I was thinking of something along this:Is this a good implementation? or am I missing something?Stumbled across this old question while searching for something else. I notice that you never did get a complete answer.The way to solve this problem is to start by writing a specification for the function you are trying to write.Specification: A well-formed binary tree is said to be \"height-balanced\" if (1) it is empty, or (2) its left and right children are height-balanced and the height of the left tree is within 1 of the height of the right tree.Now that you have the specification, the code is trivial to write. Just follow the specification:Translating that into the programming language of your choice should be trivial.Bonus exercise: this naive code sketch traverses the tree far too many times when computing the heights. Can you make it more efficient?Super bonus exercise: suppose the tree is  unbalanced. Like, a million nodes deep on one side and three deep on the other. Is there a scenario in which this algorithm blows the stack? Can you fix the implementation so that it never blows the stack, even when given a massively unbalanced tree?UPDATE: Donal Fellows points out in his answer that there are different definitions of 'balanced' that one could choose. For example, one could take a stricter definition of \"height balanced\", and require that the path length to the  empty child is within one of the path to the  empty child. My definition is less strict than that, and therefore admits more trees. One can also be less strict than my definition; one could say that a balanced tree is one in which the maximum path length to an empty tree on each branch differs by no more than two, or three, or some other constant. Or that the maximum path length is some fraction of the minimum path length, like a half or a quarter.It really doesn't matter usually. The point of any tree-balancing algorithm is to ensure that you do not wind up in the situation where you have a million nodes on one side and three on the other. Donal's definition is fine in theory, but in practice it is a pain coming up with a tree-balancing algorithm that meets that level of strictness. The performance savings usually does not justify the implementation cost. You spend a lot of time doing unnecessary tree rearrangements in order to attain a level of balance that in practice makes little difference. Who cares if sometimes it takes forty branches to get to the farthest leaf in a million-node imperfectly-balanced tree when it could in theory take only twenty in a perfectly balanced tree? The point is that it doesn't ever take a million. Getting from a worst case of a million down to a worst case of forty is usually good enough; you don't have to go all the way to the optimal case. Balance is a truly subtle property; you think you know what it is, but it's so easy to get wrong. In particular, even Eric Lippert's (good) answer is off. That's because the notion of  is not enough. You need to have the concept of minimum and maximum heights of a tree (where the minimum height is the least number of steps from the root to a leaf, and the maximum is... well, you get the picture). Given that, we can define balance to be:(This actually implies that the branches are themselves balanced; you can pick the same branch for both maximum and minimum.)All you need to do to verify this property is a simple tree traversal keeping track of the current depth. The first time you backtrack, that gives you a baseline depth. Each time after that when you backtrack, you compare the new depth against the baselineIn code:I suppose you could do this without using the Observer pattern, but I find it easier to reason this way.[EDIT]: Why you can't just take the height of each side. Consider this tree:OK, a bit messy, but each side of the root is balanced:  is depth 2, , , ,  are depth 3, and , , ,  are depth 4. The height of the left branch is 2 (remember the height decreases as you traverse the branch), the height of the right branch is 3. Yet the overall tree is  balanced as there is a difference in height of 2 between  and . You need a minimax specification (though the actual algorithm can be less complex as there should be only two permitted heights).This only determines if the top level of the tree is balanced. That is, you could have a tree with two long branches off the far left and far right, with nothing in the middle, and this would return true. You need to recursively check the  and  to see if they are internally balanced as well before returning true.Bonus exercise response.  The simple solution.  Obviously in a real implementation one might wrap this or something to avoid requiring the user to include height in their response.Post order solution, traverse the tree only once. Time complexity is O(n), space is O(1), it's better than top-down solution. I give you a java version implementation.The definition of a height-balanced binary tree is:So,\nAn empty binary tree is always height-balanced. \nA non-empty binary tree is height-balanced if:Consider the tree:As seen the left subtree of  is height-balanced (as it is empty) and so is its right subtree. But still the tree is not height-balanced as condition 3 is not met as height of left-subtree is  and height of right sub-tree is .Also the following tree is not height balanced even though the height of left and right sub-tree are equal. Your existing code will return true for it.So the word  in the def is very important.This will work:This is being made way more complicated than it actually is.The algorithm is as follows:What balanced means depends a bit on the structure at hand.  For instance, A B-Tree cannot have nodes more than a certain depth from the root, or less for that matter, all data lives at a fixed depth from the root, but it can be out of balance if the distribution of leaves to leaves-but-one nodes is uneven.  Skip-lists Have no notion at all of balance, relying instead on probability to achieve decent performance.  Fibonacci trees purposefully fall out of balance, postponing the rebalance to achieve superior asymptotic performance in exchange for occasionally longer updates.  AVL and Red-Black trees attach metadata to each node to attain a depth-balance invariant. All of these structures and more are present in the standard libraries of most common programming systems (except python, RAGE!).  Implementing one or two is good programming practice, but its probably not a good use of time to roll your own for production, unless your problem has some peculiar performance need not satisfied by any off-the-shelf collections.Note 1: The height of any sub-tree is computed only once.Note 2: If the left sub-tree is unbalanced then the computation of the right sub-tree, potentially containing million elements, is skipped.Balancing usually depends on the length of the longest path on each direction. The above algorithm is not going to do that for you.What are you trying to implement? There are self-balancing trees around (AVL/Red-black).\nIn fact, Java trees are balanced. If this is for your , I suggest:If binary tree is balanced or not can be checked by Level order traversal:Here is a complete worked out tested solution in C# (sorry I'm no java dev) (just copy paste in console app).\nI know that definition of balanced varies so not everyone may like my test results but please just look at the slightly different approach of checking depth/height in a recursive loop and exiting on the first mismatch without saving node height/level/depth on each node (only maintaining it in a function call).Well, you need a way to determine the heights of left and right, and if left and right are balanced.And I'd just As to writing a  function, read:\nWhat kind of tree are you talking about? There are  trees out there. Check their algorithms where they determine if they need to reorder the tree in order to maintain balance.Here is a version based on a generic depth-first traversal. Should be faster than the other correct answer and handle all the mentioned \"challenges.\" Apologies for the style, I don't really know Java.You can still make it much faster by returning early if max and min are both set and have a difference >1.Here's what i have tried for Eric's bonus exercise.\nI try to unwind of my recursive loops and return as soon as I find a subtree to be not balanced.An empty tree is height-balanced. A non-empty binary tree T is balanced if:1) Left subtree of T is balanced2) Right subtree of T is balanced3) The difference between heights of left subtree and right subtree is not more than 1.Time Complexity: O(n)To have a better performance specially on huge trees you can save the height in each node so it is a trade off space Vs performance:Example of implementing the addition and same for deletion Wouldn't this work?Any unbalanced tree would always fail this."},
{"body": "AssumingI was wondering if doing:is equivalent toor on the other hand it meansFrom the Java Language Specification - .So  is equivalent to .(In some usages, the type-casting makes a difference to the result, but in this one  has to be  and the type-cast does nothing.)In practice, there is little difference between  and .  If  is a variable or a constant, the result is going to be the same for both versions.  There is only a semantic difference when the evaluation of  can have side-effects; i.e. when it is a non-trivial subexpression.On the performance side, the trade-off is between the cost of evaluating , and the cost of a test and branch of the value of , and the potential saving of avoiding an unnecessary assignment to .  The analysis is not straight-forward, but unless the cost of calculating  is non-trivial, the potential performance difference between the two versions is likely to be too small to be worth considering.see .  For boolean operands, the  operator is boolean, not bitwise.  The only difference between  and  for boolean operands is that for  it is short circuited (meaning that the second operand isn't evaluated if the first operand evaluates to false).So in your case, if  is a primitive, , , and  all do the same thing.It's the last one:i came across a similar situation using booleans where I wanted to avoid calling b() if a was already false.This worked for me:"},
{"body": "I marked a method with jUnit's @BeforeClass annotation, and got this exception saying it must be static. What's the rationale? This forces all my init to be on static fields, for no good reason as far as I see.In .Net (NUnit), this is not the case. - the fact that a method annotated with @BeforeClass runs only once has nothing to do with it being a static method - one can have a non-static method run only once (as in NUnit).JUnit  creates one instance of the test class for each @Test method.  to make it easier to write tests without side-effects. Good tests do not have any order-of-run dependencies (see ) and creating fresh instances of the test class and its instance variables for each test is crucial in achieving this. Some testing frameworks reuse the same test class instance for all tests, which leads to more possibilities of accidentally creating side-effects between tests.And because each test method has its own instance, it makes no sense for the @BeforeClass/@AfterClass methods to be instance methods. Otherwise, on which of the test class instances should the methods be called? If it would be possible for the @BeforeClass/@AfterClass methods to reference instance variables,  - the rest would have the instance variables at their default values - and the @Test method would be randomly selected, because the order of methods in the .class file is unspecified/compiler-dependent (IIRC, Java's reflection API returns the methods in the same order as they are declared in the .class file, although also that behaviour is unspecified - I have written  for actually sorting them by their line numbers).So enforcing those methods to be static is the only reasonable solution.Here is an example:Which prints:As you can see, each of the tests is executed with its own instance. What JUnit does is basically the same as this:The short answer is this:  In fact, making it static causes all sorts of problems if you use Junit to execute DBUnit based DAO integration tests.  The static requirement interferes with dependency injection, application context access, resource handling, logging, and anything that depends on \"getClass\".JUnit documentation seems scarce, but I'll guess: perhaps JUnit creates a new instance of your test class before running each test case, so the only way for your \"fixture\" state to persist across runs is to have it be static, which can be enforced by making sure your fixtureSetup (@BeforeClass method) is static.there are two types of annotations:so @BeforeClass must be declared static because it is called once. You should also consider that being static is the only way to ensure proper \"state\" propagation between tests (JUnit model imposes one test instance per @Test) and, since in Java only static methods can access static data... @BeforeClass and @AfterClass can be applied only to static methods. This example test should clarify @BeforeClass vs @Before usage:output:I've created a bug tracker entry for this:Seems like nobody had reported this design flaw before ...found a nice workaround called class initializer:it works just like the static{} initializer which runs when the class gets initialized. It seems that JUnit creates a new instance of the test class for each test method. Try this code out The output is \n0\n0\n0This means that if the @BeforeClass method is not static then it will have to be executed before each test method and there would be no way to differentiate between the semantics of @Before and @BeforeClass Though this won't answer the original question. It will answers the obvious follow up. How to create a rule that works before and after a class and before and after a test.To achieve that you can use this pattern:On before(Class) the JPAConnection creates the connection once on after(Class) it closes it. returns an inner class of  that implements jpa's EntityManager and can access the connection inside the . On before (test) it begins a transaction on after (test) it rolls it back again.This isn't thread-safe but can be made to be so.Selected code of To resolve this issue just change the method to and all that are defined in this method to ."},
{"body": "I'm surprised at how it is possible to continue execution even after a  has occurred in Java.I know that  is a sublass of the class Error.\nThe class Error is decumented as \"a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch.\"This sounds more like a recommendation than a rule, subtending that catching a Error like a StackOverflowError is in fact permitted and it's up to the programmer's reasonability not to do so. And see, I tested this code and it terminates normally.How can this be? I think by the time the StackOverflowError is thrown, the stack should be so full that there is no room for calling another function. Is the error handling block running in a different stack, or what is going on here?When the stack overflows and  is thrown, the usual exception handling unwinds the stack. Unwinding the stack means:... until the exception is caught. This is normal (in fact, necessary) and independent of which exception is thrown and why. Since you catch the exception outside of the first call to , the thousands of  stack frames that filled the stack have all been unwound and most of the stack is free to be used again.When the StackOverflowError is thrown, the stack is full. However, when it's , all those  calls have been popped from the stack.  can run normally because the stack is no longer overflowing with s. (Note that I don't think the JLS guarantees you can recover from a stack overflow like this.)When the StackOverFlow occurs, the JVM will pop down to the catch, freeing the stack.\nIn you example, it get rids of all the stacked foo.Because the stack doesn't actually overflow.  A better name might be AttemptToOverflowStack.  Basically what it means is that the last attempt to adjust the stack frame errs because there isn't enough free space left on the stack. The stack could actually have lots of space left, just not enough space.  So, whatever operation would have depended upon the call succeeding (typically a method invocation), never gets exectued and all that is left is for the program to deal with that fact.  Which means that it is really no different from any other exception.  In fact, you could catch the exception in the function that is making the call."},
{"body": "Basically I would like to decode a given Html document, and replace all special chars, such as  -> ,  -> .In .NET we can make use of . What's the equivalent function in Java?I have used the Apache Commons  for this:I tried Apache Commons StringEscapeUtils.unescapeHtml3() in my project, but wasn't satisfied with its performance. Turns out, it does a lot of unnecessary operations. For one, it allocates a StringWriter for every call, even if there's nothing to unescape in the string.  I've rewritten that code differently, now it works much faster. Whoever finds this in google is welcome to use it.Following code unescapes all HTML 3 symbols and numeric escapes (equivalent to Apache unescapeHtml3). You can just add more entries to the map if you need HTML 4.The libraries mentioned in other answers would be fine solutions, but if you already happen to be digging through real-world html in your project, the  project has a lot more to offer than just managing  things.And you also get the convenient API for extracting and manipulating data, using the best of DOM, CSS, and jquery-like methods.  It's open source and MIT licence.The following library can also be used for HTML escaping in Java: .HTML can be unescaped this way:A very simple but inefficient solution without any external library is:This should be use only if you have only small count of string to decode.Consider using the  Java class. You may need to add some items (not all entities are in the list). The Apache Commons StringEscapeUtils as suggested by Kevin Hakanson did not work 100% for me; several entities like &#145 (left single quote) were translated into '222' somehow. I also tried org.jsoup, and had the same problem.This did the job for me,Hope this helps :)In my case i use the replace method by testing every entity in every variable, my code looks like this:In my case this worked very well.Incase you want to mimic what php function htmlspecialchars_decode does use php function get_html_translation_table() to dump the table and then use the java code like,"},
{"body": "I have a blob column in my database table, for which I have to use  in my Java program as a mapping and to use this data I have to convert it to  or . But I don't know what happens internally when I do so. Can anyone briefly explain me what's happening when I do this conversion?You create and use byte array I/O streams as follows:Assuming that you are using a JDBC driver that implements the standard  (not all do), you can connect a InputStream or OutputStream to a blob using the getBinaryStream and setBinaryStream methods, and you can also get and set the bytes directly.(In general, you should take appropriate steps to handle any exceptions, and close streams.  However, closing  and  in the example above is unnecessary, since they aren't associated with any external resources; e.g. file descriptors, sockets, database connections.)I'm assuming you mean that 'use' means read, but what i'll explain for the read case can be basically reversed for the write case.so you end up with a byte[]. this could represent any kind of data which may need special types of conversions (character, encrypted, etc). let's pretend you want to write this data as is to a file.firstly you could create a  which is basically a mechanism to supply the bytes to something in sequence.then you could create a  for the file you want to create. there are many types of InputStreams and OutputStreams for different data sources and destinations.lastly you would write the InputStream to the OutputStream. in this case, the array of bytes would be sent in sequence to the FileOutputStream for writing. For this i recommend using and in reverseif you use the above code snippets you'll need to handle exceptions and i recommend you do the 'closes' in a finally block.There is no conversion between InputStream/OutputStream and the bytes they are working with. They are made for binary data, and just read (or write) the bytes one by one as is.A conversion needs to happen when you want to go from byte to char. Then you need to convert using a character set. This happens when you make String or Reader from bytes, which are made for character data.we can convert byte[] array into input stream by using ByteArrayInputStreamFor full example please check here I do realize that my answer is way late for this question but I think the community would like . I think this is better since you already have an existing OutputStream in the response object.\nno need to create a new OutputStream."},
{"body": "I doubt if there is a way to make compile-time conditions in Java like #ifdef #ifndef in C++.My problem is that have an algorithm written in Java, and I have different running time improves to that algorithm. So I want to measure how much time I save when each improve is used.Right now I have a set of boolean variables that are used to decide during the running time which improve should be used and which not. But even testing those variables influences the total running time.  So I want to find out a way to decide during the compilation time which parts of the program should be compiled and used.  Does someone knows a way to do it in Java. Or maybe someone knows that there is no such way (it also would be useful).Conditionals like that shown above are evaluated at compile time. If instead you use thisThen any conditions dependent on enableFast will be evaluated by the JIT compiler. The overhead for this is negligible.javac will not output compiled code that is unreachable. Use a final variable set to a constant value for your  and a normal  statement for the .You can use javap to prove that the unreachable code isn't included in the output class file. For example, consider the following code: gives the following output, indicating that only one of the two paths was compiled in (and the if statement wasn't):I think that I've found the solution, It's much simpler.\nIf I define the boolean variables with \"final\" modifier Java compiler itself solves the problem. Because it knows in advance what would be the result of testing this condition.\nFor example this code:runs about 3 seconds on my computer.\nAnd this oneruns about 1 second. The same time this code takesNever used it, but this existsIf you really need conditional compilation and you use , you might be able to filter your code and do a search-and-replace in it.For example: In the same manner you can, for example, write a filter to replace  with . This would still execute faster than  stuff, not to mention being more concise at the same time.If you use , there is a similar feature described .Use the Factory Pattern to switch between implementations of a class?  The object creation time can't be a concern now could it? When averaged over a long running time period, the biggest component of time spent should be in the main algorithm now wouldn't it?Strictly speaking, you don't really need a preprocessor to do what you seek to achieve.  There are most probably other ways of meeting your requirement than the one I have proposed of course."},
{"body": "I am doing a https post and I'm getting an exception of ssl exception Not trusted server certificate. If i do normal http it is working perfectly fine. Do I have to accept the server certificate somehow?I'm making a guess, but if you want an actual handshake to occur, you have to let android know of your certificate.  If you want to just accept no matter what, then use this pseudo-code to get what you need with the Apache HTTP Client:CustomSSLSocketFactory:FullX509TrustManager is a class that implements javax.net.ssl.X509TrustManager, yet none of the methods actually perform any work, get a sample .Good Luck!This is what I am doing. It simply doesn't check the certificate anymore.andWhile trying to answer this question I found a better tutorial.  With it you don't have to compromise the certificate check.*I did not write this but thanks to Bob Lee for the workYou can also look at my blog article, very similar to crazybobs.This solution also doesn't compromise certificate checking and explains how to add the trusted certs in your own keystore.Courtesy Maduranga When developing an application that uses https, your test server doesn't have a valid SSL certificate. Or sometimes the web site is using a self-signed certificate or the web site is using free SSL certificate. So if you try to connect to the server using Apache , you will get a exception telling that the \"peer not authenticated\". Though it is not a good practice to trust all the certificates in a production software, you may have to do so according to the situation.\nThis solution resolves the exception caused by \"peer not authenticated\".But before we go to the solution, I must warn you that this is not a good idea for a production application. This will violate the purpose of using a security certificate. So unless you have a good reason or if you are sure that this will not cause any problem, don't use this solution.Normally you create a  like this.But you have to change the way you create the HttpClient.First you have to create a class extending .Then create a method like this.Then you can create the .If you are trying to send a post request to a login page the rest of the code would be like this.You get the html page to the InputStream. Then you can do whatever you want with the returned html page.But here you will face a problem. If you want to manage a session using cookies, you will not be able to do it with this method. If you want to get the cookies, you will have to do it via a browser. Then only you will receive cookies.If you are using a StartSSL or Thawte certificate, it will fail for Froyo and older versions. You can use a  instead of trusting every certificate.None of these worked for me (aggravated by the  as well). Eventually I got it fixed with  and Any of this answers didn't work for me so here is code which trust any certificates.I don't know about the Android specifics for ssl certificates, but it would make sense that Android won't accept a self signed ssl certificate off the bat. I found this post from android forums which seems to be addressing the same issue:\nThis is a known problem with Android 2.x. I was struggling with this problem for a week until I came across the following question, which not only gives a good background of the problem but also provides a working and effective solution devoid of any security holes.For some reason the solution mentioned for httpClient above didn't worked for me. At the end I was able to make it work by correctly overriding the method when implementing the custom SSLSocketFactory class.This is how it worked perfectly for me. You can see the full custom class and implementing on the following thread:\nI make this class and foundin you code white thisSources that helped me get to work with my self signed certificate on my AWS Apache server and connect with HttpsURLConnection from android device:\n - amazon tutorial on ssl\n - creating your own trust manager on client for accepting your certificate\n - easy script for creating your certificatesThen I did the following:Just use this method as your HTTPClient:"},
{"body": "I want to use leiningen to build and develop my clojure project. Is there a way to modify project.clj to tell it to pick some jars from local directories?I have some proprietary jars that cannot be uploaded to public repos.Also, can leiningen be used to maintain a \"lib\" directory for clojure projects? If a bunch of my clojure projects share the same jars, I don't want to maintain a separate copy for each of them.ThanksYou could put your private jars in  and they'd be on the classpath for the purposes of  and the like; this does seem to defeat the point of using a dependency management tool, though if you don't actually  those dependencies managed, you could treat Leiningen as an \"open source dependencies management tool\" and maybe be careful with .As the situation becomes more complex -- there's a larger number of private jars involved, they evolve and you need to take some versioning info on them into account -- Arthur's idea of creating a private Maven repo may be more appropriate.Also, as of yet, there is no universal agreement on the question of which is the best build tool for Clojure, and Leiningen, while gaining in mindshare, is also constantly gaining in the areas features and polish -- meaning, in particular, that it's not yet complete. Here's a quote from Stuart Halloway, the author of Pragmatic Bookshelf's \"Programming Clojure\": \"My 2c: Leiningen is an important step, but there is still plenty to do.\" For the full posting and a very interesting discussion re: build tools and the like in Clojure space, see the  thread on the Clojure Google group. Many participants specifically mention the need to have local dependencies not contained in any repositories, local or otherwise, and elaborate on the solutions they've come up with for such scenarios. Perhaps you could see if there's anything over there which can solve your problem now / might solve it in the future, when feature sets mature?Anyway, it is possible that Leiningen may not in fact have a good story ready yet for some complex scenarios. If you feel this may be true of your case (and I mean after you consider the private repo idea), here's some links to maven-based alternatives taken from the above mentioned thread: , ;  aims to be useful to people trying to use maven with Clojure. As I recall, Meikel Brandmeyer (also on SO under his online handle of kotarak) uses Gradle (a Groovy build system) with a plugin to accomodate Clojure called Clojuresque; I never tried it myself, as don't know the first thing about Groovy, but he claims to run a very nice building act with it and I believe it's got nothing to do with maven -- something which is a plus in and of itself for some of us. :-)Just use  in your project.clj file. I use it, e.g. to connect to Siebel servers. Just created a  directory in my project directory and copied the jar files in there. But of course you could use a more generic directory:Then from the  I can create Siebel Data Bean instances, e.g.If you have a newer Java version you can of course use wildcards in your path specification like this for a more general directory: The warning can be ignored, since the jar will be checked into the project and not downloaded from the internet.Original source:  (changed since copying)I find  works well when developing libraries. Do this in the library being developed and your application requiring it will use it without any  foo required.Alternatively,  is slightly more concise.This allows calling the library like any other I believe the \"correct\" approach is to  so that you can store the jars in a single location and all your branches etc will pick up the changes. This may be overkill for what your doing. I'm curious if these is an easier way.You may like to use the plugin : A recent development is Phil's  plugin for Leiningen: This should allow you to publish artifacts to a private remote repo.Maybe have a look at this , I provide step by step instructions to setup a repository local to the project (accessed through ) in which you could install your jars.Try my solution how to build jar file with dependencies \nNone of these solutions worked me. Instead I have installed a local repository, and used maven to install the jar file in the local repo, and added the local repo to my project.cljIn command line:And I write my project.clj like this:Hope it helps.[REFERENCE:  ]"},
{"body": "Is there a way to extract the source code from an executable .jar file (Java ME)? Use . Open the application, drag and drop your JAR file into it.You can extract a jar file with the command :References : I believe this can be done very easily. You can always extract the source files (Java files) of a jar file into a zip.Hope this helps.The link is dead due to some reason so adding the link from where you can download the Your JAR may contain source and javadoc, in which case you can simply use  to extract them.Otherwise you can use a decompiler as mentioned in adarshr's answer:I know it's an old question Still thought it would help someone1) Go to your jar file's folder.2) change it's extension to .zip.3) You are good to go and can easily extract it by just double clicking it.  I tested this in MAC, it works. Hopefully it will work on windows too.AndroChef Java Decompiler produces very good code that you can use directly in your projects...-Covert .jar file to .zip (In windows just change the extension)\n-Unzip the .zip folder \n-You will get complete .java files is a Java decompiler website.Just upload your  and Bingo!!! Get your source code.P.S : This saved my entire week's efforts..suppose your JAR file is in C:\\Documents and Settings\\mmeher\\Desktop\\jar and the JAR file name is xx.jar, then write the below two commands in command prompt:1> cd C:\\Documents and Settings\\mmeher\\Desktop\\jar 2> jar xf xx.jarAbove tools extract the jar. Also there are certain other tools and commands to extract the jar.\nBut AFAIK you cant get the java code in case code has been obfuscated."},
{"body": "Is it possible to iterate through  object using Iterator?Not with an iterator.For , you can do:For , you can do:You can use the  method and use a classical  loop."},
{"body": "Currently whenever I need to create stream from an array, I doIs there some direct way to create stream from an array?You can use Arrays.stream E.g.You can also use  as mentioned by @fge , which looks likeBut note  will return  whereas  will return  providing you pass an array of type . So in a nutshell for primitives type you can observe the difference between 2 methods E.g.When you pass primitive array to , the following code is invokedand when you pass primitive array to  the following code is invokedHence you get different results.: As mentioned by  comment\nThe subrange overload of  is preferable to using  because the former results in a SIZED stream whereas the latter does not. The reason is that  doesn't know whether the size is m or less than m, whereas  does range checks and knows the exact size of the stream\nYou can read the source code for stream implementation returned by   , whereas for stream implementation returned by  is within .Alternative to @sol4me's solution:Of the difference between this and : it  make a difference if your array is of a primitive type. For instance, if you do:where  is a , it will return a . , on the other hand, will return a  with a single element.Or, if you are already have an array, you can also do For primitive types use  or  etc.You can make it also by low level method which has parallel option:"},
{"body": "I have some big (more than 3 fields) Objects which can and should be immutable. Every time I run into that case i tend to create constructor abominations with long parameter lists. It doesn't feel right, is hard to use and readability suffers.It is even worse if the fields are some sort of collection type like lists. A simple  would ease the object creation so much but renders the object mutable.What do you guys use in such cases? I'm on Scala and Java, but i think the problem is language agnostic as long as the language is object oriented.Solutions I can think of:Thanks for your input!Well, you want both an easier to read and immutable object once created?I think a fluent interface  would help you.It would look like this (purely made up example):I wrote  in bold because most Java programmers get fluent interfaces wrong and pollute their object with the method necessary to build the object, which is of course completely wrong.The trick is that  (hence you Foo can be immutable).,  and  all create \"something else\".That something else may be a FooFactory, here's one way to do it....You FooFactory would look like this:In Scala 2.8, you could use named and default parameters as well as the  method on a case class. Here's some example code:Well, consider this on Scala 2.8:This does have its share of problems, of course. For instance, try making  and , and then getting two persons married to each other. I can't think of a way to solve that without resorting to either a  and/or a  constructor plus a factory.Here are a couple of more options:Make the implementation itself mutable, but separate the interfaces that it exposes to mutable and immutable. This is taken from the Swing library design.If your application contains a large but pre-defined set of immutable objects (e.g., configuration objects), you might consider using the  framework.You could also make the immutable objects expose methods that look like mutators (like addSibling) but let them return a new instance. That's what the immutable Scala collections do.The downside is that you might create more instances than necessary. It's also only applicable when there exist intermediate valid configurations (like some node without siblings which is ok in most cases) unless you don't want to deal with partially built objects.For example a graph edge which has no destination yet isn't a valid graph edge.Consider four possibilities:To me, each of 2, 3, and 4 is adapted to a difference situation. The first one is hard to love, for the reasons cited by the OP, and is generally a symptom of a design that has suffered some creep and needs some refactoring.What I'm listing as (2) is good when there is no state behind the 'factory', whereas (3) is the design of choice when there is state. I find myself using (2) rather than (3) when I don't want to worry about threads and synchronization, and I don't need to worry about amortizing some expensive setup over the production of many objects. (3), on the other hand, is called forth when real work goes into the construction of the factory (setting up from an SPI, reading configuration files, etc).Finally, someone else's answer mentioned option (4), where you have lots of little immutable objects and the preferable pattern is to get news ones from old ones.Note that I'm not a member of the 'pattern fan club' -- sure, some things are worth emulating, but it seems to me that they take on an unhelpful life of their own once people give them names and funny hats.Another potential option is to refactor to have fewer configurable fields.  If groups of fields only work (mostly) with each other, gather them up into their own small immutable object.  That \"small\" object's constructors/builders should be more manageable, as will the constructor/builder for this \"big\" object.It helps to remember there are . For your case, I think \"popsicle\" immutability will work really well:So you initialize your object, then set a \"freeze\" flag of some sort indicating that its no longer writable. Preferably, you'd hide the mutation behind a function so the function is still pure to clients consuming your API.I use C#, and these are my approaches. Consider: Constructor with optional parametersUsed as e.g. . Not for Java or C# versions before 4.0. but still worth showing, as it's an example how not all solutions are language agnostic. Constructor taking a single parameter objectUsage example: C# from 3.0 on makes this more elegant with object initializer syntax (semantically equivalent to the previous example):\nRedesign your class not to need such a huge number of parameters. You could split its repsonsibilities into multiple classes. Or pass parameters not to the constructor but only to specific methods, on demand. Not always viable, but when it is, it's worth doing."},
{"body": "I have a standalone enum type defined, something like this:Now, I want to inject a value of that type into a bean property:...and that didn't work :(How should I Inject an Enum into a spring bean? Have you tried just \"TYPE1\" ? I suppose spring uses reflection to determine the type of \"type\" anyway, so the fully qualified name seems redundant. I must admit I'm guessing, but spring generally doesn't subscribe to redundancy ;)Use the value child element instead of the value attribute and specify the Enum class name:The advantage of this approach over just writing  is that it also works if Spring can't infer the actual type of the enum from the property (e.g. the property's declared type is an interface).I know this is a really old question, but in case someone is looking for the newer way to do this, use the spring util namespace:As described in the .You can just do \"TYPE1\".This is what did it for me MessageDeliveryMode is the enum the bean will have the value PERSISTENT:Using SPEL and P-NAMESPACE:You can write Bean Editors (details are in the Spring Docs) if you want to add further value and write to custom types.Spring-integration example, routing based on a an Enum field:config:To be specific, set the value to be the name of a constant of the enum type, e.g., \"TYPE1\" or \"TYPE2\" in your case, as shown below. And it will work:"},
{"body": "I've got a large-ish class (40 or so methods) that is part of a package I will be submitting as course-work. Currently, the methods are pretty jumbled up in terms of utility public/private etc. and I want to order them in a sensible way. Is there a standard way of doing this? E.g. normally fields are listed before methods, the constructor(s) are listed before other methods, and getters/setters last; what about the remaining methods?Some conventions list all the public methods first, and then all the private ones - that means it's easy to separate the API from the implementation, even when there's no interface involved, if you see what I mean.Another idea is to group related methods together - this makes it easier to spot seams where you could split your existing large class into several smaller, more targeted ones.Source: The more precise link to \u00abCode Conventions\u00bb: Not sure if there is universally accepted standard but my own preferences are;40 methods in a single class is a bit much.Would it make sense to move some of the functionality into other - suitably named - classes.  Then it is much easier to make sense of.When you have fewer, it is much easier to list them in a natural reading order.  A frequent paradigm is to list things either  or  you need them , in the order you need them.This usually means that main() goes on top or on bottom.My \"convention\": static before instance, public before private, constructor before methods, but main method at the bottom (if present). Also, eclipse offers the possibility to sort class members for you, if you for some reason mixed them up:Open your class file, the go to \"Source\" in the main menu and select \"Sort Members\".taken from here: Are you using Eclipse? If so I would stick with the default member sort order, because that is likely to be most familiar to whoever reads your code (although it is not my favourite sort order.)"},
{"body": "I am doing Android programming and was learning about Intents, when I saw a constructor that, to my C# trained mind, seemed funky.  The call was: Both of the parameters are new to me.  How is there a static \".this\" off of a Class Name?  Is this a Java thing or an Android thing?  I am assuming that it is the same as just saying \"this\", since I am in the context of , but I don't get how the \"this\" can be called off of the Class name itself.  Also.  The \".class\" looks like it is used for reflection, which I am familiar with in C#, but any insight into this would be welcomed as well.Thanks.Usually, you can use only . But, sometimes  makes reference to an inner class... so, for example:One at a time:The first construct is called a . The purpose of the syntax is in the case where you are in an inner class (typically an anonymous inner class) and you want to reference the  of the outer class rather than the  of the (anonymous) inner class. The \"qualified this\" can only be used in a context where  would be ambiguous. The quote the JLS \"It is a compile-time error if the expression occurs in a class or interface which is not an inner class of class T or T itself\".The second construct is called a  is the way to reference the Class object that represents that type. It can be used in any context.The syntax \"Classname.this\" is for inner classes. If you want to refer to the enclosing instance of type \"Outerclass\" then you do it as \"Outerclass.this\".NextActivity.class is simply the Class object that describes class \"NextActivity\". is used to reference the current instance of an outerclass from an inner class. in java means  in C#is used in nested classes to refer to the current instance of the enclosing class, since the `this' keyword refers to the nest class instance."},
{"body": "I'm working on a fairly big Maven project.  We have probably around 70 or so individual artifacts, which are roughly split into two libraries of shared code and maybe ten applications which use them.  All of these items live in the namespace .Most of the time we're running against snapshot builds.  So to do a full build of an application, I might first build the library projects so that they are installed to my local repository (as, say, ).The problem is that when I then go build the applications.  For some reason, Maven wants to check the main two public repositories (maven-net-repo and java-net-repo) for updates for all of the  artifacts.  Of course, they aren't found there, and everything eventually resolves back to the versions I just built to my local repository, but I'd like Maven to stop doing this because (a) it makes me feel like a bad net.citizen for constantly checking these repositories for things that will never be there, and (b) it adds some unnecessary and annoying network latency into my build process.I've taken to running maven in offline mode most of the time to work around this, but that's not ideal since occasionally a dependency on a public library will be updated.  So what I'm looking for is a solution which will cause Maven not to check for updates from given repositories for artifacts which meet certain criteria - in this case, I'd be happy if Maven would ignore either SNAPSHOT versions or artifacts which were in the  namespace.The updatePolicy tag didn't work for me. However Rich Seller mentioned that snapshots should be disabled anyways so I looked further and noticed that the extra repository that I added to my settings.xml was causing the problem actually. Adding the snapshots section to this repository in my settings.xml did the trick!Also, you can use  or  in the mvn command line which will put maven in \"offline mode\" so it won't check for updates. You'll get some warning about not being able to get dependencies not already in your local repo, but no big deal.Something that is now available in maven as well isor in shortUpdate: I should have probably started with this as your projects are SNAPSHOTs. It is part of the SNAPSHOT semantics that Maven will check for updates on each build. Being a SNAPSHOT means that it is volatile and subject to change so updates should be checked for. However it's worth pointing out that the   configures central to have snapshots disabled, so Maven shouldn't ever check for updates for SNAPSHOTs on central unless you've overridden that in your own pom/settings.You can configure Maven to use a  for the central repository, this will redirect all requests that would normally go to central to your internal repository.In your settings.xml you would add something like this to set your internal repository as as mirror for central:If you are using a repository manager like  for your internal repository. You can set up a  for proxy central, so any requests that would normally go to Central are instead sent to your proxy repository (or a  containing the proxy), and subsequent requests are cached in the internal repository manager. You can even set the proxy cache timeout to -1, so it will never request for contents from central that are already on the proxy repository.A more basic solution if you are only working with local repositories is to set the  for the central repository to \"never\", this means Maven will only ever check for artifacts that aren't already in the local repository. This can then be overridden at the command line when needed by using the -U switch to force Maven to check for updates.You would configure the repository (in your pom or a profile in the settings.xml) as follows:Very simple :In your Super POM parent or setting.xml, useIt's my tipsI had some trouble similar to this,Setting the updatePolicy to \"never\" did not work. Removing these repo was the way I solved it.\nps: I was following this  about web services (btw, probably the best tutorial for ws for java)"},
{"body": "How does my java program know where my keystore containing the certificate is? Or alternatively how do I tell my java program where to look for the keystore?After specifying the keystore in some way, how to specify the certificate to use for authenticating the server to client? SSL properties are set at the JVM level via system properties. Meaning you can either set them when you run the program (java -D....) Or you can set them in code by doing System.setProperty. The specific keys you have to set are below: First of all, there're two kinds of keystores. and The application will use the one indicated in the startup or the default of the system.It will be a different folder if JRE or JDK is running, or if you check the personal or the \"global\" one.In short, the path will be like:$JAVA_HOME/lib/security/cacerts for the \"general one\", who has all the CA for the Authorities and is quite important."},
{"body": "This came up as a question I asked in an interview recently as something the candidate wished to see added to the Java language. It's commonly-identified as a pain that Java doesn't have  but, when pushed, the candidate couldn't actually tell me the sort of things that he could have achieved were they there.Obviously because raw types are allowable in Java (and unsafe checks), it is possible to subvert generics and end up with a  that (for example) actually contains s. This clearly could be rendered impossible were type information reified; !Could people post examples of things that , were reified generics available? I mean, obviously you could get the type of a  at runtime - but what would you do with it?: A quick update to this as the answers seem mainly to be concerned about the need to pass in a  as a parameter (for example ). I was looking more for something along the lines of . For example:From the few times that I came across this \"need\", it ultimately boils down to this construct:This does work in C# assuming that  has a  constructor. You can even get the runtime type by  and get the constructors by .The common Java solution would be to pass the  as argument.For all other generic type constructs, the actual type can easily be resolved with a bit help of reflection. The below Q&A illustrate the use cases and possibilities:The thing that most commonly bites me is the inability to take advantage of multiple dispatch across multiple generic types. The following isn't possible and there are many cases where it would be the best solution: comes to mind. Downcasting to a parametrized type will always be unsafe without reified generics:Also,  - at least the ones which may be interested in runtime information about their type parameters. Today, if you need any kind of runtime information about the type of one of the generic parameters you have to pass its  along as well. That way, your external interface depends on your implementation (whether you use RTTI about your parameters or not).You'd be able to create generic arrays in your code.This is an old question, there are a ton of answers, but I think that the existing answers are off the mark.\"reified\" just means real and usually just means the opposite of type erasure.The big problem related to Java Generics:My exposure to Java Geneircs is quite limited, and apart from the points other answers have already mentioned there is a scenario explained in the book , by Maurice Naftalin and Philip Walder, where the reified generics are useful.Since the types are not reifiable, it is not possible to have Parameterized exceptions. For example the declaration of below form is not valid.This is because the  clause checks whether the thrown exception matches a given type. This check is same as the check performed by instance test and since the type is not reifiable the above form of statement is invalid.If the above code was valid then exception handling in the below manner would have been possible:The book also mentions that if Java generics are defined similar to the way C++ templates are \ndefined (expansion) it may lead to more efficient implementation as this offers more \nopportunities for optimization. But doesn't offer any explanation more than this, so any explanation (pointers) from the knowledgeable folks would be helpful.Serialization would be more straightforward with reification.  What we would want isWhat we have to do islooks ugly and works funkily.There are also cases where it would be really helpful to say something likeThese things don't bite often, but they do bite when they happen.Arrays would probably play much nicer with generics if they were reified.I have a wrapper that presents a jdbc resultset as an iterator, (it means I can unit test database-originated operations a lot easier through dependency injection).  The API looks like  where T is some type that can be constructed using only strings in the constructor.  The Iterator then looks at the strings being returned from the sql query and then tries to match it to a constructor of type T.In the current way that generics are implemented, I have to also pass in the class of the objects that I will be creating from my resultset.  If I understand correctly, if generics were reified, I could just call T.getClass() get its constructors, and then not have to cast the result of Class.newInstance(), which would be far neater.Basically, I think it makes writing APIs (as opposed to just writing an application) easier, because you can infer a lot more from objects, and thereby less configuration will be necessary...I didn't appreciate the implications of annotations until I saw them being used in things like spring or xstream instead of reams of config.One nice thing would be avoiding boxing for primitive (value) types.  This is somewhat related to the array complaint that others have raised, and in cases where memory use is constrained it could actually make a significant difference.There are also several types of problems when writing a framework where being able to reflect over the parameterized type is important.  Of course this can be worked around by passing a class object around at runtime, but this obscures the API and places an additional burden on the user of the framework.It's not that you will achieve anything extraordinary. It will just be simpler to understand. Type erasure seems like a hard time for beginners, and it ultimately requires one's understanding on the way the compiler works.My opinion is, that generics are simply  that saves a lot of redundant casting.Here's one that's caught me today: without reification, if you write a method that accepts a varargs list of generic items ... callers can THINK they're typesafe, but accidentally pass in any-old crud, and blow up your method.Seems unlikely that would happen? ... Sure, until ... you use Class as your datatype. At this point, your caller will happily send you lots of Class objects, but a simple typo will send you Class objects that don't adhere to T, and disaster strikes.(NB: I may have made a mistake here, but googling around \"generics varargs\", the above appears to be just what you'd expect. The thing that makes this a practical problem is the use of Class, I think - callers seem to be less careful :( )For instance, I'm using a paradigm that uses Class objects as a key in maps (it's more complex than a simple map - but conceptually that's what's going on).e.g. this works great in Java Generics (trivial example) :e.g. without reification in Java Generics, this one accepts ANY \"Class\" object. And it's only a tiny extension of the previous code :The above methods have to be written out thousands of times in an individual project - so the possibility for human error becomes high. Debugging mistakes is proving \"not fun\". I'm currently trying to find an alternative, but don't hold much hope."},
{"body": "I tried to migrate a project from Eclipse to Android studio. Finally I am able to run it, but at a certain point I got this exception, and I found nothing in google about this:Please advice me if you can.alternative to @sbaar's answer,keep  to  and add as well and set it to .ieRemove from your theme, then make sure you are inheriting from a .NoActionBar Theme, then set your toolbar like normal.Make sure that your theme is child from , then in :Btw, it's a new issue for Support Library 22.1.Check if you call setContentView() after super.onCreate(), and not before. This helped in my case.Use this parent in Style.xml\nparent=\"Theme.AppCompat.Light.NoActionBar\"in my case i didnt change to .NoActionBar Theme. i just remove android prefix from this item.and the error goes away.Make sure thatare at the top of everything this works for me....good luckadd dependency to gradle like thisI solved the issue by my main Activity extending AppCompatActivity :)I had the same problem when I upgraded the library version from 22.0.0 to 22.1.1 and fixed it by dropping back to the previous version: com.android.support:appcompat-v7:22.0.0 and go back to using ActionBarActivity, not AppCompatActivity in my Activity classes as required by the newer version of the compatibility library. I'll try again later.just Use this in your style.xml no other editing is neededdon't add anything in to activity file please leave itIn Java class change  to . It worked for me.In my case, I look for @rewrihitesh answer, and I notice that I . Changing from to Fix my problem.Hope it helps !!if you have added ,\nthen ,you need to addto solve the problem."},
{"body": "If I do this...it printsThe problem is, I am behind a proxy. Where does the JVM get its proxy information from on Windows? How do I set this up? All my other apps seem perfectly happy with my proxy.Since java 1.5 you can also pass a  instance to the  method:If your proxy requires authentication it will give you response 407.In this case you'll need the following code:This is fairly easy to answer from the internet. Set system properties  and . You can do this with , or from the command line with the  syntax.Proxies are supported through two system properties: http.proxyHost and http.proxyPort. They must be set to the proxy server and port respectively. The following basic example illustrates it:Set following before you openConnection,If proxy requires authentication,You can also setOn Windows and Linux this will use the system settings so you don't need to repeat yourself (DRY)The approved answer will work ... if you know your proxy host and port =) . But in case you are looking for the proxy host and port the steps below should helpkudos to bekur from Once you have the host and port just pop in into this and your good to goFor Java 1.8 and higher you must set  to make proxies with Basic Authorization working with https."},
{"body": "For Example I have the date: \"23/2/2010\" (23th Feb 2010). I want to pass it to a function which would return the . How can I do this?In this example, the function should return  \"Tue\".Additionally, if just the day ordinal is desired, how can that be retrieved?Yes.  Depending on your exact case:Use this code for find the Day name from a input date.Simple and well tested.Simply use SimpleDateFormat stufs :)The result is:  . If you want diferent positions just replace it at applyPattern method.But if you want only the day of the week leave it like that:UPDATE: The Joda-Time project is now in maintenance mode. The team advises migrating to the java.time classes. The java.time framework is built into Java 8 (as well as  and ). See the .Here is example code using the  library version 2.4, as mentioned in the . Joda-Time is far superior to the java.util.Date/.Calendar classes bundled with Java.Joda-Time offers the  class to represent a date-only without any time-of-day or time zone. Just what this Question calls for. The old java.util.Date/.Calendar classes bundled with Java lack this concept.Parse the string into a date value.Extract from the date value the day of week number and name. Dump to console.When run.Using  framework built into Java 8 and later.The   can generate a String of the day\u2019s name automatically localized to the human language and cultural norms of a . Specify a  to indicate you want long form or abbreviated name.Another \"fun\" way is to use . It's a way longer method but it's also faster if you don't need to create a Calendar object with a given date.Get the day value by providing the current time stamp.You can try the following code:"},
{"body": "How do I add n hours to a Date object?  I found another example using days on StackOverflow, but still don't understand how to do it with hours.Check Calendar class. It has  method (and some others) to allow time manipulation. Something like this should work.Check  for more.If you use , you can do it in one step using :(The original object is unchanged)With To simplify @Christopher's example.Say you have a constantYou can write.If you use  to store date/time instead of the Date object you can doSince Java 8:See .Something like:The java.time framework built into Java 8 and later supplants the old Java.util.Date/.Calendar classes. Those old classes are notoriously troublesome. Avoid them.Use the  method newly added to java.util.Date to convert from the old type to the new java.time type. An  is a moment on the time line in  with a resolution of .You can add hours to that  by passing a  such as . To read that date-time, generate a String in standard ISO 8601 format by calling .You may want to see that moment through the lens of some region\u2019s . Adjust the  into your desired/expected time zone by creating a .Alternatively, you can call  to add your count of hours. Being zoned means Daylight Saving Time (DST) and other anomalies will be handled on your behalf.You should avoid using the old date-time classes including  and . But if you truly need a  for interoperability with classes not yet updated for java.time types, convert from  via . New methods added to the old classes facilitate conversion to/from java.time types.For more discussion on converting, see  to the Question, .The  framework is built into Java 8 and later. These classes supplant the troublesome old  date-time classes such as , , & .The  project, now in , advises migration to java.time.To learn more, see the . And search Stack Overflow for many examples and explanations. Specification is .Where to obtain the java.time classes? The  project extends java.time with additional classes. This project is a proving ground for possible future additions to java.time. You may find some useful classes here such as , , , and .Using the newish  class you can do it like thisThis is another piece of code when your  object is in Datetime format. The beauty of this code is, If you give more number of hours the date will also update accordingly.Here is the Output:You can do it with Joda DateTime APIIf you're willing to use , here's a method to add ISO 8601 formatted durations:You can use this method, It is easy to understand and implement :"},
{"body": "Why can't you switch on an enum in Java? It seems simple enough to do and would make for some convenient code. Also this question could apply to 's. You can switch on a , but not a  ...?You definitely can switch on enums. An example posted from the java .You actually can  on s, but you can't  on s until Java 7. You might consider using polymorphic method dispatch with Java s rather than an explicit . Note that s are objects in Java, not just symbols for s like they are in C/C++. You can have a method on an  type, then instead of writing a , just call the method - one line of code: done!First, you can switch on an  in Java. I'm guessing you intended to say you can\u2019t, but you can. s have a set range of values, so it's easy to compare. Strings can be anything.A  statement is usually implemented as a  in the underlying compilation, which is only possible with a finite set of values. C#  switch on strings, but it causes a performance decrease because a jump table cannot be used.Java 7 and later supports  with the same characteristics.You might be using the enums incorrectly in the switch cases. In comparison with the above example by CoolBeans.. you might be doing the following:Make sure that you use the actual enum values instead of EnumType.EnumValueEclipse points out this mistake though..Actually you can use a switch statement with Strings in java...unfortunetly this is a new feature of Java 7 and most people are not using Java 7 yet because it's so new."},
{"body": "According to  the String '\u0967\u0968\u0969' is numeric. Since I believed this might be a mistake in the documentation, I ran tests to verify the statement. I found that according to Apache Commons it is numeric.Why is this String numeric? What are those characters representing?Because that \"CharSequence contains only Unicode digits\" (quoting your ).All of the characters return true for : are Devanagari digits:The symbol  is the same as 123 for the Nepali language or any other language using the  like Hindi, Gujarati...\ntherefore is a number for Apache Commons. :)You can use  to check the character's general category:This will print , which is an \"evidence\" that '\u0967' is a .Now let's examine the unicode value of the '\u0967' character:This number is on the range of  - which is:  through .Also try: is:\"\u0967\u0968\u0969\" is a \"123\" (Basic Latin unicode).Reading:If you ever want to know what properties a particular \"character\" has (and there are quite a few), go directly to the source: . They have research tools that can show you most anything you would care to know. The Unicode Consortium produces a specification, not software. This means that it is up to each software vendor to implement the specification . So just like HTML, JavaScript, CSS, SQL, etc, there is variation between different platforms, languages, and so on. For example, I found a bug in Microsoft's .NET Framework whereby circled Latin letters  and   -- Code Points 0x24B6 through 0x24E9 -- do not properly register as being  (). And that leads to unexpected behavior in related functionality, such as when calling the  method ().Symbols '\u0967\u0968\u0969' are actually derived from Hindi language(Basically from Sanskrit language i.e Devanagiri) which represent numeric values just like:\u0967 represent 1\u0968 represent 2and like wise If you want to know whether a character is a digit or not simply call the utility method  and if you want to know its corresponding name use .So in your case, you could write this simple code to get more information about those specific characters that you don't know:"},
{"body": "Apart from the fact that  does not allow duplicate values, what is the difference between  and ?I mean implementation wise? It's a little bit vague because both use  to store values.They are entirely different constructs.  A  is an implementation of .  A  maps keys to values.  The key look up occurs using the hash.On the other hand, a  is an implementation of .  A  is designed to match the mathematical model of a set.  A  does use a  to back its implementation, as you noted.  However, it implements an entirely different interface.When you are looking for what will be the best  for your purposes, this  is a good starting place.  If you truly want to know what's going on, , too.HashSet is a , e.g. HashMap is a  (key to value) map, e.g. Notice in my example above that in the HashMap there must not be duplicate keys, but it may have duplicate values.In the HashSet, there must be no duplicate elements.It's really a shame that both their names start with .  That's the least important part of them.  The important parts come after the  - the  and , as others have pointed out.  What they are, respectively, are a  - an unordered collection - and a  - a collection with keyed access.  They happen to be implemented with hashes - that's where the names come from - but their essence is hidden behind that part of their names.Don't be confused by their names; they are deeply different things.Please refer  to find more information.HashSet allows us to store objects in the set where as HashMap allows us to store objects on the basis of key and value. Every object or stored object will be having key.As the names imply, a   is an associative  (mapping from a key to a value), a  is just a .A  is to add, get, remove, ... objects indexed by a custom key of any type.\nA  is to add elements, remove elements and check if elements are present by comparing their hashes.So a HashMap contains the elements and a HashSet remembers their hashes.Differences:\nwith respect to heirarchy: \nHashSet implements Set.\nHashMap implements Map and stores a mapping of keys and values.A use of HashSet and HashMap with respect to database would help you understand the significance of each.\n\n is generally used for storing unique collection objects.\nE.g: It might be used as implementation class for storing many-to-one relation ship between \n\n is used to map a key to value.the value may be null or any Object /list of Object (which is object in itself).HashSet internally uses HashMap to store objects.when add(String) method called it calls HahsMap put(key,value) method where key=String object & value=new Object(Dummy).so it maintain no duplicates because keys are nothing but Value Object.the Objects which are stored as key in Hashset/HashMap should override hashcode & equals contract. Keys which are used to access/store value objects in HashMap should declared as Final because when it is modified Value object can't be located & returns null.A  is implemented in terms of a .  It's a mapping between the key and a PRESENT object.you pretty much answered your own question - hashset doesn't allow duplicate values. it would be trivial to build a hashset using a backing hashmap (and just a check to see if the value already exists). i guess the various java implementations either do that, or implement some custom code to do it more efficiently.A HashSet uses a HashMap internally to store its entries.  Each entry in the internal HashMap is keyed by a single Object, so all entries hash into the same bucket.  I don't recall what the internal HashMap uses to store its values, but it doesn't really matter since that internal container will never contain duplicate values.:  To address Matthew's comment, he's right; I had it backwards.  The internal HashMap is keyed .  The values of the HashMap are an Object that's just simply stored in the HashMap buckets.   First and most significant difference between HashMap and HashSet is that HashMap is an implementation of Map interface while HashSet is an implementation of Set interface, which means HashMap is a key value based data-structure and HashSet guarantees uniqueness by not allowing duplicates.In reality HashSet is a wrapper around HashMap in Java, if you look at the code of add(E e) method of HashSet.java you will see following code :where its putting  Object into map as key and value is an final object PRESENT which is dummy. Second difference between HashMap and HashSet is that , we use add() method to put elements into Set but we use put() method to insert key and value into HashMap in Java. HashSet allows only one null key, but HashMap can allow one null key + multiple null values.That's all on difference between HashSet and HashMap in Java. In summary HashSet and HashMap are two different type of Collection one being Set and other being Map. HashSet  is implementation of Set Interface which does not allow duplicate value all the methods which are in Collection Framework are also in Set Interface by default but when we are talking about Hash set the main thing is objects which are going to be stored in HashSet must override equals() and hashCode() method so that we can check for equality and no duplicate value are stored in our set.if we have created our own objects we need to implement hashCode() and equal() in such a manner that will be able to compare objects correctly when storing in a set so that duplicate objects are not stored,if we have not override this method objects will take default implementation of this method.\npublic boolean add(Object o)  Method is used to add element in a set which returns false if it\u2019s a duplicate value in case of  HashSet otherwise returns true if added successfully.HashMap is a implementation of Map Interface, which maps a key to value.Duplicate keys are not allowed in a map.Basically map Interface has two implementation classes HashMap and TreeMap the main difference is TreeMap maintains order of the objects but HashMap will not.HashMap allows null values and null keys.HashMap is not synchronized,but collection framework provide methods so that we can make them synchronized if multiple threads are going to access our hashmap and one thread is structurally change our map.\npublic Object put(Object Key,Object value) method is used to add element in map. is a  implementation, allowing  but . For adding an object a Key/Value pair is required. Null Keys and Null values are allowed. eg: is a  implementation,which does .If you tried to add a duplicate object, a call to  method, then the set remains unchanged and returns . eg:1) First and most significant difference between HashMap and HashSet is that HashMap is an implementation of Map interface while HashSet is an implementation of Set interface, which means HashMap is a key value based data-structure and HashSet guarantees uniqueness by not allowing duplicates.In reality HashSet is a wrapper around HashMap in Java, if you look at the code of add(E e) method of HashSet.java you will see following code :where its putting  Object into map as key and value is an final object PRESENT which is dummy.2) Second difference between HashMap and HashSet is that , we use add() method to put elements into Set but we use put() method to insert key and value into HashMap in Java.3) HashSet allows only one null key, but HashMap can allow one null key + multiple null values.That's all on difference between HashSet and HashMap in Java. In summary HashSet and HashMap are two different type of Collection one being Set and other being Map.Basically in HashMap, user has to provide both Key and Value, whereas in HashSet you provide only Value, the Key is derived automatically from Value by using hash function. So after having both Key and Value, HashSet can be stored as HashMap internally. HashSet and HashMap both store  pairs , the difference lies that in HashMap you can specify a key while in HashSet the key comes from object's hash code allow one null key and null values. They are not synchronized, which increases efficiency. If it is required, you can make them synchronized using  don't allow null keys and are synchronized.HashMap  is a implementation of Map interface\nHashSet is an implementation of Set InterfaceHashMap Stores data in form of  key value pair\nHashSet Store only objectsPut method is used to add element in map\nAdd method is used to add element is SetIn hash map hashcode value is calculated using key object\nHere member object is used for calculating hashcode value which can be same for two objects so equal () method is used to check for equality if it returns false that means two objects are different.HashMap is faster than hashset because unique key is used to access object\nHashSet is slower than HashmapThe Hashset Internally implements HashMap. If you see the internal implementation\n on  the values inserted in HashSet are stored as keys in the HashMap and the value is a Dummy object of Object class.\nDifference between HashMap vs HashSet is:-\n1. HashMap contains key value pairs and each value can be accessed by key where as HashSet needs to be iterated everytime as there is no get method.\n2. HashSet implements Map interface and allows one null value as a key and multiple null values as values.Where as HashSet implements Set interface, allows only one null value and no duplicated values.(Remeber one null key is allowed in HashMap key hence one null value in HashSet as HashSet implemements HashMap internally).\n3.HashSet and HashMap does not maintain the order of insertion while iterating."},
{"body": "I have read a lot of stackoverflow questions but none seems to be working for me. i am using  to round off.\nthis is the code:the output i get is:  but i want it to be . i read that adding  will help but as you can see i didn't manage to get it to work.it is absolutely essential for both input and output to be a double.it would be great great help if you change the line 4 of the code above and post it.Output isOr as @Rufein said this will do it for you as well.Go back to your code, and replace  by  and let me know if it works.\nHowever, if you want to be formal, try this:should be Adding 'D' to 100 makes it Double literal, thus result produced will have precisionTry :seems like you are hit by integer arithmetic: in some languages (int)/(int) will always be evaluated as integer arithmetic.\nin order to force floating-point arithmetic, make sure that at least one of the operands is non-integer:Just pass your number to this function as a double, it will return you rounding the decimal value up to the nearest value of 5;if 4.25, Output 4.25if 4.20, Output 4.20if 4.24, Output 4.20if 4.26, Output 4.30if you want to round upto 2 decimal places,then useif up to 3 places, new DecimalFormat(\"#.###\") if up to n places, new DecimalFormat(\"#.\")I know this is 2 year old question but as every body faces a problem to round off the values at some point of time.I would like to share a different way which can give us rounded values to any scale by using  class .Here we can avoid extra steps which are required to get the final value if we use     or using  .This program would give us below outputI just modified your code. It works fine in my system. See if this helpsShould be ok for most cases. You can still changes types if you want to be compliant with doubles for instance."},
{"body": "I'm trying to make sure my Java application takes reasonable steps to be robust, and part of that involves shutting down gracefully. I am reading about  and I don't actually get how to make use of them in practice.Is there a practical example out there?Let's say I had a really simple application like this one below, which writes numbers to a file, 10 to a line, in batches of 100, and I want to make sure a given batch finishes if the program is interrupted. I get how to register a shutdown hook but I have no idea how to integrate that into my application. Any suggestions?You could do the following:Some sketchy code:That's roughly how I do a graceful \"reject all clients upon hitting Control-C\" in terminal.From :That is, a shutdown hook keeps the JVM running until the hook has terminated (returned from the -method.Shutdown Hooks are unstarted threads that are registered with Runtime.addShutdownHook().JVM does not give any guarantee on the order in which shutdown hooks are started.For more info refer "},
{"body": "My question is a variation of .Since my Java Web-app project requires a lot of read filters/queries and interfaces with tools like GridFS, I'm struggling to think of a sensible way to employ MongoDB in the way the above solution suggests.Therefore, I'm considering running an embedded instance of MongoDB alongside my integration tests. I'd like it to  (either for each test or the whole suite),  for every test, and  at the end. These tests might be run on development machines as well as the CI server, so my solution will also need to be .Can anyone with more knowledge on MongoDB help me get idea of the feasibility of this approach, and/or perhaps suggest any reading material that might help me get started?I'm also open to other suggestions people might have on how I could approach this problem...I have found  library which looks quite promising and does what you have asked for. Currently supports MongoDB versions:  to , provided the binaries are still available from the configured mirror.Here is short example of use, which I have just tried and it works perfectly:There is Foursquare product .\nFongo is an in-memory java implementation of mongo. It intercepts calls to the standard mongo-java-driver for finds, updates, inserts, removes and other methods. The primary use is for lightweight unit testing where you don't want to spin up a mongo process.If you are using sbt and specs2, I wrote the same kind of wrapper for embedmongoIf you're using Maven you may be interested in a plugin I've created that wraps the :It provides a  goal that you can use to start any version of MongoDB you want (e.g. during ), and a  goal that will stop MongoDB (e.g. during ).The real benefit of using this plugin over others is that there is no requirement for MongoDB to be installed beforehand. MongoDB binaries are downloaded and stored in  for future builds.with spring-boot 1.3 you can use If you are using maven, you can use ours You can also check this project which simulate a MongoDB inside JVM memory.\n\nBut it is still in development.You can run MongoDB in memory as of version 3.2.6. From the :Not [just for] for unit testings, but read this blog post if you like to run MongoDB (even a cluster) as in-memory deployment if you're using Linux.  Would be great to have it out of the box like RavenDB though.Similar to the embedmongo-maven-plugin mentioned here, there is also a  available. Like the Maven plugin it also wraps the  and allows you to run a managed instance of Mongo from your Gradle builds.In production, you will be using a real database.If you want your tests to reflect how your product behaves in production, use a real instance of Mongo.A fake implementation may not behave exactly the same as a real one. When testing, you should strive for correctness. Speed of execution comes second.Check this code example here: . No installation, no dependency. It's simply a platform independent ant script that do download and setup for you. It also cleans up everything after your tests."},
{"body": "I'm looking for a Java in-memory object caching API. Any recommendations? What solutions have you used in the past?Right now, I'm just using a Map:I need to extend the cache to include basic features like:However, I don't need more sophisticated features like:In-Memory caching:Enterprise caching: is very nice.  You can create an in memory cache. Check out their  for an example of creating an in memory cache.  You can specify a max size, and a time to live.EHCache does offer some advanced features, but if your not interested in using them - don't.  But it's nice to know they are there if your requirements ever change.Here is an in memory cache.  Created in code, with no configuration files.Creates a cache that will hold 200 elements, and has a ttl of 24 hours.I really like the  that comes with  ()The JavaDoc has a pretty neat example that demonstrates both its ease of use and its power:Furthermore,  introduced the much more extensive .You can also check out my little cache library called KittyCache at: There are some performance benchmarks vs ehcache.It's used in the  project as a second level cache.Guava's  has been replaced by their  class.You can check out LinkedHashMap to implement a simple cache without third party jars:then you can get from the cache likerest left as exercise for reader :) is tried and true.  Even though it is light as far as caching mechanisms go, you might dig into the actual code and mimic what they do with HashMap under the covers to exactly what you need and no more.  You seem to have a pretty good idea of what you are looking for.  memcached has client for Java.  Requires separate process to be a caching server, but powerful thing."},
{"body": "I saw this quote on the question: Is this true?  If so, what is it about the JVM that creates this fundamental limitation?This post:  might help.In short, tail call optimization is hard to do in the JVM because of the security model and the need to always have a stack trace available. These requirements could in theory be supported, but it would probably require a new bytecode (see ).There is also more discussion in , where the evaluation (from 2002) ends:Currently, there is some work going on in the  project. The tail call subproject's status is listed as \"proto 80%\"; it is unlikely to make it into Java 7, but I think it has a very good chance at Java 8.The fundamental limitation is simply that the JVM does not provide tail calls in its byte code and, consequently, there is no direct way for a language built upon the JVM to provide tail calls itself. There are workarounds that can achieve a similar effect (e.g. trampolining) but they come at the grave cost of awful performance and obfuscating the generated intermediate code which makes a debugger useless.So the JVM cannot support any production-quality functional programming languages until Sun implement tail calls in the JVM itself. They have been discussing it for years but I doubt they will ever implement tail calls: it will be very difficult because they have prematurely optimized their VM before implementing such basic functionality, and Sun's effort is strongly focused on dynamic languages rather than functional languages.Hence there is a very strong argument that Scala is not a real functional programming language: these languages have regarded tail calls as an essential feature since Scheme was first introduced over 30 years ago.Scala 2.7.x supports tail-call optimization for self-recursion (a function calling itself) of final methods and local functions.Scala 2.8 might come with library support for trampoline too, which is a technique to optimize mutually recursive functions.A good deal of information about the state of Scala recursion can be found in .In addition to the paper linked in Lambda The Ultimate (from the link mmyers posted above), John Rose from Sun has some more to say about tail call optimization.I have heard that it might be implemented on the JVM someday. Tail call support amongst other things are being looked at on the Da Vinci Machine.All sources point to the JVM being unable to optimize in the case of tail recursion, but upon reading  (2003, O'reilly) I found the author claiming he can achieve greater recursion performance by implementing tail recursion.You can find his claim on page 212 (search for 'tail recursion' it should be the second result). What gives?"},
{"body": "Will Java code built and compiled against a 32-bit JDK into 32-bit byte code work in a 64-bit JVM?  Or does a 64-bit JVM require 64-bit byte code?To give a little more detail, I have code that was working in a Solaris environment running a 32-bit JVM, but now I'm getting issues after upgrading the JDK and Weblogic Server to 64-bit.Yes, Java bytecode (and source code) is platform independent, assuming you use platform independent libraries. 32 vs. 64 bit shouldn't matter.I accidentally ran our (largeish) application on a 64bit VM rather than a 32bit VM and didn't notice until some external libraries (called by JNI) started failing.Data serialized on a 32bit platform was read in on the 64bit platform with no issues at all.What sort of issues are you getting? Do some things work and not others? Have you tried attaching JConsole etc and have a peak around?If you have a very big VM you may find that GC issues in 64 bit can affect you. Yes to the first question and no to the second question; it's a virtual machine. Your problems are probably related to unspecified changes in library implementation between versions. Although it could be, say, a race condition.There are some hoops the VM has to go through. Notably references are treated in class files as if they took the same space as s on the stack.  and  take up two reference slots. For instance fields, there's some rearrangement the VM usually goes through anyway. This is all done (relatively) transparently.Also some 64-bit JVMs use \"compressed oops\". Because data is aligned to around every 8 or 16 bytes, three or four bits of the address are useless (although a \"mark\" bit may be stolen for some algorithms). This allows 32-bit address data (therefore using half as much bandwidth, and therefore faster) to use heap sizes of 35- or 36-bits on a 64-bit platform.All byte code is 8-bit based. (That's why its called BYTE code) All the instructions are a multiple of 8-bits in size. \nWe develop on 32-bit machines and run our servers with 64-bit JVM.Could you give some detail of the problem you are facing?  Then we might have a chance of helping you. Otherwise we would just be guessing what the problem is you are having.Unless you have native code (machine code compiled for a specific arcitechture) your code will run equally well in a 32-bit and 64-bit JVM.Note, however, that due to the larger adresses (32-bit is 4 bytes, 64-bit is 8 bytes) a 64-bit JVM will require more memory than a 32-bit JVM for the same task.The 32-bit vs 64-bit difference does become more important when you are interfacing with native libraries. 64-bit Java will not be able to interface with a 32-bit non-Java dll (via JNI)Add a paramter as below in you in configuration while creating the exeI hope it helps.thanks.../javThe Java JNI requires OS libraries of the same \"bittiness\" as the JVM. If you attempt to build something that depends, for example, on IESHIMS.DLL (lives in %ProgramFiles%\\Internet Explorer) you need to take the 32bit version when your JVM is 32bit, the 64bit version when your JVM is 64bit. Likewise for other platforms.Apart from that, you should be all set. The generated Java bytecode s/b the same.Note that you should use 64bit Java compiler for larger projects because it can address more memory. yo where wrong! To this theme i wrote an question to oracle. The answer was. \"If you compile your code on an 32 Bit Machine, your code should only run on an 32 Bit Processor. If you want to run your code on an 64 Bit JVM you have to compile your class Files on an 64 Bit Machine using an 64-Bit JDK.\""},
{"body": "I'm acquainted with the fact that , and in particular you need a \"lexer hack\" in C. On the other hand, I'm under the impression that you can parse Java with only 2 tokens of look-ahead, despite considerable similarity between the two languages.I ask because all of the examples I've seen of C's context-sensitivity are technically allowable but awfully weird. For example,could be calling the void function  with argument . Or, it could be declaring  to be an object of type , but you could just as easily get rid of the parantheses. In part, this weirdness occurs because the \"direct declarator\" production rule for the  fulfills the dual purpose of declaring both functions and variables.On the other hand, the  has separate production rules for variable declaration and function declaration. If you writethen you know it's a variable declaration and  can unambiguously be parsed as a typename. This might not be valid code if the class  hasn't been defined somewhere in the current scope, but that's a job for semantic analysis that can be performed in a later compiler pass.I've seen it said that C is hard to parse because of typedef, but you can declare your own types in Java too. Which C grammar rules, besides , are at fault?See this .  The short summary is that C and C++  are inherently ambiguous; they will give you multiple parses and you  use context to resolve the ambiguities. People then make the mistake of assuming you have to resolve ambiguities as you  parse; not so, see below.  If you insist on resolving ambiguities as you parse, your parser gets more complicated and that much harder to build; but that complexity is a self-inflicted wound.IIRC,  Java 1.4's \"obvious\" LALR(1) grammar was not ambiguous, so it was \"easy\" to parse.  I'm not so sure that modern Java hasn't got at least long distance local ambiguities; there's always the problem of deciding whether \"...>>\" closes off two templates or is a \"right shift operator\".  I suspect . But one can get past the parsing problem by using strong parsers (or weak parsers and context collection hacks as C and C++ front ends mostly do now), for both languages.\nC and C++ have the additional complication of having a preprocessor; these are more complicated in practice than they look.  One claim is that the C and C++ parsers are so hard they have to be be written by hand.    Once you parse, you will want to do something with the AST/parse tree.  In practice, you need to know, for every identifier, what its definition is and where it is used  (\"name and type resolution\", sloppily, building symbol tables).   This turns out to be a LOT more work than getting the parser right, compounded  by inheritance, interfaces, overloading and templates, and the confounded by the fact that the semantics for all this is written in informal natural language spread across tens to hundreds of pages of the language standard.  C++ is really bad here.  Java 7 and 8 are getting to be pretty awful from this point of view. (And symbol tables aren't all you need; see my bio for a longer essay on \"Life After Parsing\").Most folks struggle with the pure parsing part (often never finishing; check SO itself for the many, many questions about to how to build working parsers for real langauges), so they don't ever see life after parsing.  And then we get folk theorems about what is hard to parse and no signal about what happens after that stage.Regarding changing the C++ syntax: you'll find you need to patch a lot of places to take care of the variety of local and real ambiguities in any C++ grammar.  If you insist, the .   I contend there is no point in doing this if you are not the C++ standards committee; if you did so, and built a compiler using that, nobody sane would use it.   There's too much invested in existing C++ applications to switch for convenience of the guys building parsers; besides, their pain is over and existing parsers work fine.You may want to write your own parser.  OK, that's fine; just don't expect the rest of the community to let you change the language they must use to make it easier for you.  They all want it easier for them, and that's to use the language as documented and implemented."},
{"body": "Is it possible to see the return value of a method after the line has been run and before the instruction pointer returns to the calling function?I am debugging code I can't modify , and sometimes it jumps to code I don't have source to or the return expression has side effects that stop me being able to just run the expression in the  tab.Often the return value is used in a compound statement, and so the  view will never show me the value (hence wanting to see the result before control returns to the calling function). I can't use the expression viewer as there are side-effects in the statement.This feature was added to Eclipse version 4.7 M2 under .Found a really good shortcut for this.\nSelect the expression which returns the value and press This will display the value of the return statement. This is really helpful in cases where you can't or don't want to change just for debugging purpose.Hope this helps.Note: Have not tested this with third party libraries, but it is working fine for my code.\nTested this on That's why I always stick with the following pattern for methods:My rules:Naturally, the most trivial getters are exempt.This is actually a long standing bug in Eclipse, dating back from the very first days of the IDE: I am curious about to learn the answer to this question also. In the past, when dealing with 3rd party library like that, what I did is to create a wrapper class or child class that delegate to the parent class and do my debugging in the wrapper/child class. It takes extra work though.Depending on the return statement, you can highlight the expression that is being returned and from the right-click menu, there should be something like \"evaluate expression\" (I don't have eclipse in front of me now, but it's something like that).  It will show you what is going to be returned. Tough one.  My experience, outside of Eclipse, is that if you might need to see the return value, it is best to assign it to a local variable in the function so that the return statement is a simple  and not .  However, that's not dreadfully helpful to you since you say you can't (or don't want to) modify or even recompile the code.  So, I don't have a good answer for you - perhaps you need to reconsider your requirement.This is a bit far-fetched, but as there doesn't seem to be a simple way:You could use AspectJ to instrument the JAR with aspects that get hold of the return value of the methods you're interested in. According to Eclipse's documentation, AspectJ programs can be  like other programs.There are two options to weave your classes without recompiling the library :See the eclipse documentation (link above) and also the ."},
{"body": "I'm following a tutorial. I've created a new activity using a wizard. I get  when attempting to call a method on s obtained with  in my activity .Activity :Layout XML ():The tutorial is probably outdated, attempting to create an activity-based UI instead of the fragment-based UI preferred by wizard-generated code.The view is in the fragment layout ()  and not in the activity layout ().  is too early in the lifecycle to find it in the activity view hierarchy, and a  is returned. Invoking a method on  causes the NPE.The preferred solution is to move the code to the fragment , calling  on the inflated fragment layout :As a side note, the fragment layout will eventually be a part of the activity view hierarchy and discoverable with activity  but only after the fragment transaction has been run. Pending fragment transactions get executed in  after .Try  method and just use or Declare any View using  method in  Declare click listener on view by Agreed, this is a typical error because people often don't really understand how Fragments work when they begin working on Android development. To alleviate confusion, I created a simple example code that I originally posted on  , but I posted it here as well.An example is the following:activity_container.xml:ExampleFragment:fragment_example.xml:And that should be a valid example, it shows how you can use an Activity to display a Fragment, and handle events in that Fragment. And also how to communicate with the containing Activity.You are trying to access UI elements in the onCreate() but , it is too early to access them , since in fragment views can be created in onCreateView() method. \nAnd onActivityCreated() method is reliable to handle any actions on them, since activity is fully loaded in this state.Try to shift your accessing views to the onViewCreated method of fragment because sometimes when you try to access the views in onCreate method they are not rendered at the time resulting null pointer exception.The view \"something\" is in fragment and not in activity, so instead of accessing it in activity you must access it in the fragment class like Since you have declared your View in the ,move that piece of code where you get the NPE in the  method of the fragment.\nThis should solve the issue.Add the following in your in the posted code above in the question there is a problem :\nyou are using R.layout.activity_main in oncreate method, but the xml files name is \"fragment_main.xml\" , means you are trying to get the view of fragment_main.xml file which is not being shown so it gives null pointer exception. change the code like :I've got the same NullPointerException initializing a listener after calling findViewById onCreate and onCreateView methods.But when I've used the (Bundle savedInstanceState) {...} it works. So, I could access the GroupView and set my listener.I hope it be helpful."},
{"body": "Two years after , there seems to be a   and  has listed the feature as \"proto 80%\" for some time now.Is there no active interest from Sun's/Oracle's side in supporting tail calls or is it just that tail calls are \"[...]  [...]\" as mentioned at the ?I would be really interested if someone has tested a MLVM build and could share some impressions of how well it works (if at all).  () explains why the JVM does not support tail-call optimization.It then gives an example of Java code that won't transform.Then it gives a test you can use to figure out if your JIT does this.Naturally, since this is an IBM paper, it includes a plug:One reason I've seen in the past for not implementing TCO (and it being seen as difficult) in Java is that the permission model in the JVM is stack-sensitive and thus tail-calls must handle the security aspects.  I believe this was shown to not be an obstacle by Clements and Felleisen [1] [2] and I'm pretty sure the MLVM patch mentioned in the question deals with it as well.I realize this does not answer your question; just adding interesting information.Perhaps you know this already, but the feature is not as trivial as it may sound since the Java language actually exposes the stack trace to the programmer.Consider the following program:Even though this has a \"tail-call\" it may not be optimized. (If it  optimized, it still requires book-keeping of the entire call-stack since the semantics of the program relies on it.)Basically, this means that it's hard to support this while still being backward compatible.Java is the least functional language you could possibly imagine (well, OK, !) but this would be a great advantage for JVM languages, like , which are. My observations are that making the JVM a platform for other languages has never seemed to be at the top of the priority list for Sun and I guess, now for Oracle."},
{"body": "And what kind of alternative strategies do you use for avoiding LazyLoadExceptions?I do understand that open session in view has issues with:But, if you know that your application is running on a single vm, why not ease your pain by using an open session in view strategy?Because sending possibly uninitialised Proxies, especially collections, in the view layer and triggering hibernate loading from there can be troubling from both a performance and understanding point of view.:Using OSIV 'pollutes' the view layer with concerns related to the data access layer.The view layer is not prepare to handle a  which may happen when lazy loading, but presumably the data access layer is.:OSIV tends to tug proper entity loading under the carpet - you tend not to notice that your collections or entities are lazily initialised ( perhaps N+1 ). More convenience, less control. see  for a larger discussion regarding this subject. The author lists three important points:For a longer description, you can read my  article. Otherwise, here's a summary for why you shouldn't use Open Session In View.Open Session In View takes a bad approach to fetching data. Instead of letting the business layer decide how it\u2019s best to fetch all the associations that are needed by the View layer, it forces the Persistence Context to stay open so that the View layer can trigger the Proxy initialization.At a first glance, this might not look like a terrible thing to do, but, once you view it from a database perspective, a series of flaws start to become more obvious.The service layer opens and closes a database transaction, but afterward, there is no explicit transaction going on. For this reason, every additional statement issued from the UI rendering phase is executed in auto-commit mode. Auto-commit puts pressure on the database server because each statement must flush the transaction log to disk, therefore causing a lot of I/O traffic on the database side. One optimization would be to mark the  as read-only which would allow the database server to avoid writing to the transaction log.There is no separation of concerns anymore because statements are generated both by the service layer and by the UI rendering process. Writing integration tests that  requires going through all layers (web, service, DAO), while having the application deployed on a web container. Even when using an in-memory database (e.g. HSQLDB) and a lightweight web server (e.g. Jetty), these integration tests are going to be slower to execute than if layers were separated and the back-end integration tests used the database, while the front-end integration tests were mocking the service layer altogether.The UI layer is limited to navigating associations which can, in turn, trigger N+1 query problems. Although Hibernate offers  for fetching associations in batches, and  to cope with this scenario, the annotations are affecting the default fetch plan, so they get applied to every business use case. For this reason, a data access layer query is much more suitable because it can be tailored for the current use case data fetch requirements.Last but not least, the database connection could be held throughout the UI rendering phase(depending on your connection release mode) which increases connection lease time and limits the overall transaction throughput due to congestion on the database connection pool. The more the connection is held, the more other concurrent requests are going to wait to get a connection from the pool.So, either you get the connection held for too long, either you acquire/release multiple connections for a single HTTP request, therefore putting pressure on the underlying connection pool and limiting scalability.I wouldn't say that Open Session In View is considered a bad practice; what gives you that impression?Open-Session-In-View is a simple approach to handling sessions with Hibernate.  Because it's simple, it's sometimes simplistic.  If you need fine-grained control over your transactions, such as having multiple transactions in a request, Open-Session-In-View is not always a good approach.As others have pointed out, there are some trade-offs to OSIV -- you're much more prone to the N+1 problem because you're less likely to realize what transactions you're kicking off.  At the same time, it means you don't need to change your service layer to adapt to minor changes in your view.If you're using an Inversion of Control (IoC) container such as Spring, you may want to read up on . Essentially, I'm telling Spring to give me a Hibernate  object whose life cycle spans the entire request (i.e., it gets created and destroyed at the start and end of the HTTP request). I don't have to worry about s nor closing the session since the IoC container manages that for me.As mentioned, you will have to think about N+1 SELECT performance issues. You can always configure your Hibernate entity afterwards to do eager join loading in places where performance is an issue.The bean scoping solution is not a Spring-specific. I know PicoContainer offers the same capability and I'm sure other mature IoC containers offer something similar.I just did a post on some guidelines as to when to use open session in view in my blog. Check it out if your interested.In my own experience, OSIV is not so bad.\nThe only arrangement I made is using two different transactions:\n- the first, opened in \"service layer\", where I have the \"business logic\"\n- the second opened just before the view renderingI am v. rusty on Hibernate.. but I think its possible to have multiple transactions in one Hibernate session. So your transaction boundaries do not have to be the same as session start/stop events.OSIV, imo, primarily is useful because we can avoid writing code for starting a 'persistence context' (a.k.a. session) every time the request needs to make a DB access.In your service layer, you will probably need to make calls to methods which have different transaction needs, such as 'Required, New Required, etc.' The only thing these methods need is that somebody (i.e the OSIV filter) has started up the persistence context, so that only thing they have to worry about is - \"hey give me the hibernate session for this thread.. I need to do some DB stuff\".This won't help too much but you can check my topic here:\n* I have some OutOfMemory issues because of OpenSessionInView and a lot of entities loaded, because they stay in Hibernate cache level1 and are not garbage collected (i load a lot of entities with 500 items per page, but all entities stay in cache)"},
{"body": "I came across this question in a quiz,The output of this program is \"String Version\". But I was not able to understand why passing a null to an overloaded method chose the string version. Is null a String variable pointing to nothing ?However when the code is changed to,it gives a compile error saying \"The method method(StringBuffer) is ambiguous for the type MoneyCalc\"A null reference can be converted to an expression of any class type. So in the case of , this is fine:The  overload here is chosen because the Java compiler picks the  overload, as per . In particular:In your second case, both methods are still applicable, but neither  nor  is more specific than the other, therefore neither method is more specific than the other, hence the compiler error.Additionally, the  also declares that \"null\" is a literal value of the \"null type\". Therefore there exists a type called \"null\".Later, the  states that there exists a null type of which is impossible to declare variables, but you can use it through the null literal only. Later it says:Why the compiler chooses to widen it to String might well be explained in .You can assign a  to a  value so it is valid and the order for java and most programming languages is fit to the closest type and then to object. To answer the question in the title:  is neither a  nor an , but a reference to either can be assigned to .I'm actually surprised this code even compiles.  I tried something similar previously and I got a compiler error saying that the call was ambiguous.However, in this case, it seems like the compiler is choosing the method which is lowest on the food chain.  It's assuming that you want the least generic version of the method in order to help you out.I'll have to see if I can dig up the example where I got a compiler error in this (seemingly) exact same scenario, though...]  I see.  In the version I made, I had two overloaded methods accepting a  and an .  In this scenario, there is no \"most specific\" parameter (as in  and ), so it can't choose between them, unlike in your code.Very cool question!As String type is more specific than Object type. Let's say you add one more method that takes an Integer type.Then you will get a compiler error saying that the call is ambiguous. As now we two equally specific methods with same precedence.Java compiler gives most derived class type to assign null.Here is the example to understand it : B Class.on the other hand: The method fun(C) is ambiguous for the type MyTestHope it will help to understand this case better.I would say neither.  NULL is a state not a value.  Check out this  for more info on this (the article applies to SQL, but I think it helps with your question as well)."},
{"body": " when we split on empty string like split mechanism would split in places marked with because empty space  exists before and after each character. So as result it would generate at first this arrayand later will  (because we didn't explicitly provide negative value to  argument) so it will finally return  split mechanism seems to have changed. Now when we use we will get  array instead of  so it looks like empty strings at start are also removed. But this theory fails because for instanceis returning array with empty string at start . Can someone explain what is going on here and how rules of split for this cases have changed in Java\u00a08?The behavior of  (which calls ) changes between Java 7 and Java 8.Comparing between the documentation of  in  and , we observe the following clause being added:The same clause is also added to  in , compared to .Let us compare the code of  of the reference implemetation in Java 7 and Java 8. The code is retrieved from grepcode, for version 7u40-b43 and 8-b132.The addition of the following code in Java 8 excludes the zero-length match at the beginning of the input string, which explains the behavior above.To make  behaves consistently across versions and compatible with the behavior in Java 8: checks that the string does not end at the beginning of the string, which implies that the match is an empty match at the beginning of the string.There is no general solution to make  backward-compatible with Java 7 and prior, short of replacing all instance of  to point to your own custom implementation.This has been specified in the documentation of .In  you  got a zero-width match at the beginning so the leading empty substring is not included in the resulting array. However in your second snippet when you split on  you got a positive width match (1 in this case), so the empty leading substring is included as expected.(Removed irrelevant source code)There was a slight change in the docs for  from Java 7 to Java 8. Specifically, the following statement was added:The empty string split generates a zero-width match at the beginning, so an empty string is not included at the start of the resulting array in accordance with what is specified above. By contrast, your second example which splits on  generates a -width match at the start of the string, so an empty string is in fact included at the start of the resulting array."},
{"body": "Swing components have multiple methods related to updates of screen layout, in particular:The Java documentation defines these somewhat from a technical perspective, but it's not particularly clear how they are meant to be used.What is the difference between these, and in what circumstances should you use one rather than the others?Just IMHO. Not sure it's 100% correct. marks the container as invalid. Means the content is somehow wrong and must be relayed out. But it's just a kind of mark/flag. It's possible that multiple invalid containers must be refreshed later. performs relayout. It means invalid content is asked for all the sizes and all the subcomponents' sizes are set to proper values by . is just sum of both. It marks the container as invalid and performs layout of the container. : In Swing when you create a Component, it is not  i.e. its valid property is . A component is said to be valid, when its width, height, location and stuff has been determined. This is usually done by calling their  method, directly or indirectly. When we call  on containers, it will validate the container (if it is invalid) by calling its  method, which typically will invoke the . Now each child placed on this container will be validated recursively, so that the entire tree will be laid out and will become valid. :  is to be called when you change an attribute that would affect their width/height and call repaint() when you change an attribute that would affect their appearance.\nFor example, if your  contains a , now at a certain point of time you removed that  and inserted a new one in its place, depending on the contents of the newly placed , the size of the components inside the  as well as  itself (by virtue of the layout manager used by it), changes. Which pushes it to the invalid state. So in order to validate this change, you have to explicitly call . : This thing is something, I have never used, so might not be much of info I can give. But seems like the scenario presented above, can give a bit of a hint, as to what happens in . "},
{"body": "I have the following Java code with several big arrays which never change their size. It runs in 1100 ms on my computer.I implemented the same code in C++ and used .The time of the C++ implementation which runs the exact same code is 8800 ms on my computer. What did I do wrong, so that it runs this slowly?Basically the code does the following:It iterates through different arrays with a size of around 20000.You can find both implementations under the following links:(On ideone I could only run the loop 400 times instead of 2000 times because of the time limitation. But even here there is a difference of three times)Here is the C++ version with the per-node data gathered into a structure, and a single vector of that structure used:The time is now 2x the speed of the Java version.  (846 vs 1631).Odds are the JIT noticed the cache burning of accessing data all over the place, and transformed your code into a logically similar but more efficient order.I also turned off stdio synchronization, as that is only needed if you mix / with C++  and .  As it happens, you only print out a few values, but C++'s default behavior for printing is overly paranoid and inefficient.If  is not an actual constant value, then the 3 \"array\" values will have to be stripped out of the .  That shouldn't cause a huge performance hit.You might be able to get another performance boost by sorting the values in that  by decreasing size, thus reducing memory footprint (and sorting access as well when it doesn't matter).  But I am unsure.A rule of thumb is that a single cache miss is 100x more expensive than an instruction.  Arranging your data to have cache coherency has lots of value.If rearranging the data into a  is infeasible, you can change your iteration to be over each container in turn.As an aside, note that the Java and C++ versions had some subtle differences in them.  The one I spotted was that the Java version has 3 variables in the \"for each edge\" loop, while the C++ one only had 2.  I made mine match the Java.  I don't know if there are others.Yep, the cache in the c++ version takes a hammering. It seems the JIT is better equipped to handle this. If you change the outer  in isUpdateNeeded() to shorter snippets. The difference goes away. The sample below produces a 4x speedup. This shows to a reasonable degree that cache misses are the reason for the slowdown. It is also important to note that the variables are not dependent so a threaded solution is easily created. As per stefans comment I tried grouping them in a struct using the original sizes. This removes the immediate cache pressure in a similar fashion. The result is that the c++ (CCFLAG -O3) version is about 15% faster than the java version. My result differs slightly from Jerry Coffins for the original sizes. For me the differences remains.  It might well be my java version, 1.7.0_75. As @Stefan guessed in a comment on @CaptainGiraffe's answer, you gain quite a bit by using a vector of structs instead of a struct of vectors. Corrected code looks like this:Compiled with the compiler from VC++ 2015 CTP, using , I get results like:Compiling with g++ produces a result that's slightly slower:On the same hardware, using the compiler/JVM from Java 8u45, I get results like:This is around 35% slower than the version from VC++, and about 16% slower than the version from g++.If we increase the number of iterations to the desired 2000, the difference drops to only 3%, suggesting that part of the advantage of C++ in this case is simply faster loading (a perennial problem with Java), not really in execution itself. This doesn't strike me as surprising in this case--the computation being measured (in the posted code) is so trivial that I doubt most compilers can do a whole lot to optimize it.I suspect this is about allocation of memory.I am thinking that  grabs a large contiguous block at program startup whereas  asks the OS for bits and pieces as it goes along.To put that theory to the test I made one modification to the  version and it suddenly started running slightly faster than the  version:Runtime  the preallocating vector:Runtime  the preallocating vector:Runtime for  version:"},
{"body": "I'm using JUnit 4.4 and Maven and I have a large number of long-running integration tests.When it comes to parallelizing test suites there are a few solutions that allow me to run each test method in a single test-class in parallel. But all of these require that I change the tests in one way or another.I really think it would be a much cleaner solution to run X different test classes in X threads in parallel. I have hundreds of tests so I don't really care about threading individual test-classes.Is there any way to do this?Use maven plugin:From junit 4.7 it's now possible to run tests in parallel without using TestNG. Actually it has been possible since 4.6, but there are a number of fixes being made in 4.7 that will make it a viable option. You may also run parallel tests with spring, which you can read about Inspired by JUnit's experimental  runner I've built my own  and  runners. Using these runners one can easily parallelize test suites and parameterized tests.Usage is simple. Just change  annotations value to one of these  classes. offers something similar, check the docs for details. It relies on JUnit 4.7 and you just mark your test to .Cheers (this was my first reflex - then I saw you're already having a lot of testcases). For JUnit, look at . You can check out the open source library - . It does exactly what you ask for - run different test classes in parallel. This integrates at the ant-junit level so that you do not have to change your tests in anyway. I am one of the authors of the library.Also, think about not running them in threads as you may need a process level sandbox. For example, if you are hitting a DB in your integration tests, you do not want one test to fail because another test added some data in a different thread. Most of the times, tests are not written with this in mind.Finally, how have solved this problem till now?You can run the tests in parallel using ParallelComputer provided by Junit itself. Here's a small snippet to get you started.This will help when you need to run tests from code as it has no dependencies on Maven or any other build management tools.Please note that, this will run all test cases in parallel, if you have any dependencies between different test cases it might result in false positives. You SHOULD NOT have interdependent tests anyway.You can change your test to be TestNg test in a minute (you just need to change imports), TestNG is the best in parallel testing.You could try  that lets you run distribute your tests across a compute grid. "},
{"body": "Having a chain of \"instanceof\" operations is considered a \"code smell\".  The standard answer is \"use polymorphism\".  How would I do it in this case?There are a number of subclasses of a base class; none of them are under my control.  An analogous situation would be with the Java classes Integer, Double, BigDecimal etc.I do have control over NumberStuff and so on.I don't want to use many lines of code where a few lines would do.  (Sometimes I make a HashMap mapping Integer.class to an instance of IntegerStuff, BigDecimal.class to an instance of BigDecimalStuff etc.  But today I want something simpler.)I'd like something as simple as this:But Java just doesn't work that way.I'd like to use static methods when formatting.  The things I'm formatting are composite, where a Thing1 can contain an array Thing2s and a Thing2 can contain an array of Thing1s.  I had a problem when I implemented my formatters like this:Yes, I know the HashMap and a bit more code can fix that too.  But the \"instanceof\" seems so readable and maintainable by comparison.  Is there anything simple but not smelly?Note added 5/10/2010:It turns out that new subclasses will probably be added in the future, and my existing code will have to handle them gracefully.  The HashMap on Class won't work in that case because the Class won't be found.  A chain of if statements, starting with the most specific and ending with the most general, is probably the best after all:You might be interested in this entry from Steve Yegge's Amazon blog: . Essentially he's addressing cases like this, when polymorphism causes more trouble than it solves. The issue is that to use polymorphism you have to make the logic of \"handle\" part of each 'switching' class - i.e. Integer etc. in this case. Clearly this is not practical. Sometimes it isn't even logically the right place to put the code. He recommends the 'instanceof' approach as being the lesser of several evils.As with all cases where you are forced to write smelly code, keep it buttoned up in one method (or at most one class) so that the smell doesn't leak out.As highlighted in the comments, the visitor pattern would be a good choice. But without direct control over the target/acceptor/visitee you can't implement that pattern.  Here's one way the visitor pattern could possibly still be used here even though you have no direct control over the subclasses by using wrappers (taking Integer as an example):Of course, wrapping a final class might be considered a smell of its own but maybe it's a good fit with your subclasses.  Personally, I don't think  is that bad a smell here, especially if it is confined to one method and I would happily use it (probably over my own suggestion above).  As you say, its quite readable, typesafe and maintainable. As always, keep it simple.Instead of a huge , you can put the instances you handle in a map (key: class, value: handler).If the lookup by key returns , call a special handler method which tries to find a matching handler (for example by calling  on every key in the map). When a handler is found, register it under the new key.This makes the general case fast and simple and allows you to handle inheritance.You can use reflection:You can expand on the idea to generically handle subclasses and classes that implement certain interfaces.I think that the best solution is HashMap with Class as key and Handler as value. Note that HashMap based solution runs in constant algorithmic complexity \u03b8(1), while the smelling chain of if-instanceof-else runs in linear algorithmic complexity O(N), where N is the number of links in the if-instanceof-else chain (i.e. the number of different classes to be handled). So the performance of HashMap based solution is asymptotically higher N times than the performance of if-instanceof-else chain solution.\nConsider that you need to handle different descendants of Message class differently: Message1, Message2, etc. . Below is the code snippet for HashMap based handling.More info on usage of variables of type Class in Java: You could consider . For your first example, something like:and then similarly for your other handlers. Then it's a case of stringing together the StuffHandlers in order (most specific to least specific, with a final 'fallback' handler), and your despatcher code is just .(An alternative is to, rather than using a chain, just have a  in your dispatcher class, and have it loop through the list until  returns true).Just go with the instanceof.  All the workarounds seem more complicated.  Here is a blog post that talks about it:  I have solved this problem using  (around 15 years back in pre Generics era).I have defined one Generic Class ( abstract Base class). I have defined many concrete implementations of base class. Each concrete class will be loaded with className  as parameter. This class name is defined as part of configuration. Base class defines common state across all concrete classes and concrete classes will modify the state by overriding abstract rules defined in base class. At that time, I don't know the name of this mechanism, which has been known as  . Few more alternatives are listed in this  :  and  apart from reflection. "},
{"body": "Is there an elegant way to handle exceptions that are thrown in  block? For example:How do you avoid the / in the  block?I usually do it like this:Elsewhere:I typically use one of the  methods in :If you're using Java 7, and  implements , you can do this (using InputStream as an example):Arguably a bit over the top, but maybe useful if you're letting exceptions bubble up and you can't log anything from within your method (e.g. because it's a library and you'd rather let the calling code handle exceptions and logging):UPDATE: I looked into this a bit more and found a great blog post from someone who has clearly thought about this more than me:   He goes one step further and combines the two exceptions into one, which I could see being useful in some cases.As of Java 7 you no longer need to explicitly close resources in a  block instead you can use -with-resources syntax. The try-with-resources statement is a try statement that declares one or more resources. A resource is an object that must be closed after the program is finished with it. The try-with-resources statement ensures that each resource is closed at the end of the statement. Any object that implements java.lang.AutoCloseable, which includes all objects which implement java.io.Closeable, can be used as a resource.Assume the following code:If any exception happens the  method will be called on each of these three resources in opposite order in which they were created. It means the close method would be called first for ResultSetm then the Statement and at the end for the Connection object.It's also important to know that any exceptions that occur when the close methods is automatically called are suppressed. These suppressed exceptions can be retrieved by  method defined in the  class.Source: One solution, if the two Exceptions are two different classesBut sometimes you cannot avoid this second try-catch. e.g. for closing a streamIgnoring exceptions which occur in a 'finally' block is generally a  unless one knows what those exceptions will be and what conditions they will represent.  In the normal  usage pattern, the  block places things into a state the outside code won't be expecting, and the  block restores those things' state to what the outside code expects.  Outside code which catches an exception will generally expect that, despite the exception, everything has been restored to a  state.  For example, suppose some code starts a transaction and then tries to add two records; the \"finally\" block performs a \"rollback if not committed\" operation.  A caller might be prepared for an exception to occur during the execution of the second \"add\" operation, and may expect that if it catches such an exception, the database will be in the state it was before either operation was attempted.  If, however, a second exception occurs during the rollback, bad things could happen if the caller makes any assumptions about the database state.  The rollback failure represents a  crisis--one which should not be caught by code expecting a mere \"Failed to add record\" exception.My personal inclination would be to have a finally method catch exceptions that occur and wrap them in a \"CleanupFailedException\", recognizing that such failure represents a major problem and such an exception should not be caught lightly.Why do you want to avoid the additional block? Since the finally block contains \"normal\" operations which may throw an exception AND you want the finally block to run completely you HAVE to catch exceptions.If you don't expect the finally block to throw an exception and you don't know how to handle the exception anyway (you would just dump stack trace) let the exception bubble up the call stack (remove the try-catch from the finally block).If you want to reduce typing you could implement a \"global\" outer try-catch block, which will catch all exceptions thrown in finally blocks:After lots of consideration, I find the following code best:That code guarantees following:If you can you should test to avoid the error condition to begin with.Also you should probably only be catching exceptions that you can recover from, if you can't recover then let it propagate to the top level of your program.  If you can't test for an error condition that you will have to surround your code with a try catch block like you already have done (although I would recommend still catching specific, expected errors).You could refactor this into another method ... I usually do this:Rationale: If I'm done with the resource and the only problem I have is closing it, there  is not much I can do about it. It doesn't make sense either to kill the whole thread if I'm done with the resource anyway.This is one of the cases when at least for me, it is safe to ignore that checked exception.To this day I haven't had any problem using this idiom. Job done. No null tests. Single catch, include acquire and release exceptions. Of course you can use the Execute Around idiom and only have to write it once for each resource type."},
{"body": "We recently had an issue with an Eclipse project for one of our team members. Tomcat was not deploying JARs of the application. We eventually noticed the  Eclipse file was not the same as for the team members where the project was OK. We replaced the  file with one from a project that was OK and the Tomcat deploy was complete.Just out of curiosity and to know at what to look in the future if something is wrong, Eclipse is a runtime environment for plugins. Virtually everything you see in Eclipse is the result of plugins installed on Eclipse, rather than Eclipse itself.The  file is maintained by the core Eclipse platform, and its goal is to describe the project from a generic, plugin-independent Eclipse view. What's the project's name? what other projects in the workspace does it refer to? What are the builders that are used in order to build the project? (remember, the concept of \"build\" doesn't pertain specifically to Java projects, but also to other types of projects)The  file is maintained by Eclipse's JDT feature ( = set of plugins). JDT holds multiple such \"meta\" files in the project (see the  directory inside the project); the  file is just one of them. Specifically, the  file contains information that the JDT feature needs in order to properly compile the project: the project's source folders (that is,  to compile); the output folders (where to compile ); and classpath entries (such as other projects in the workspace, arbitrary JAR files on the file system, and so forth).Blindly copying such files from one machine to another may be risky. For example, if arbitrary JAR files are placed on the classpath (that is, JAR files that are located outside the workspace and are referred-to by absolute path naming), the  file is rendered non-portable and must be modified in order to be portable. There are certain best practices that can be followed to guarantee  file portability.When a project is created in the workspace, a project description file is automatically generated that describes the project. The sole purpose of this file is to make the project self-describing, so that a project that is zipped up or released to a server can be correctly recreated in another workspace.Classpath specifies which Java source files and resource files in a project are considered by the Java builder and specifies how to find types outside of the project. The Java builder compiles the Java source files into the output folder and also copies the resources into it.Complete reference is not available for the mentioned files, as they are extensible by various plug-ins.Basically, .project files store project-settings, such as builder and project nature settings, while .classpath files define the classpath to use during running. The classpath files contains src and target entries that correspond with folders in the project; the con entries are used to describe some kind of \"virtual\" entries, such as the JVM libs or in case of eclipse plug-ins dependencies (normal Java project dependencies are displayed differently, using a special src entry)."},
{"body": "What is the best data type to use for money in java application?Java has  class that represents the ISO 4217 currency codes.\n is the best type for representing currency decimal values.  has provided a library to represent money.You can use . This API is expected to be part of Java 9. You can use this API in Java 7 and Java 8, provided you add appropriate dependencies to your project.For Java 8, add the following reference implementation as a dependency to your :This dependency will transitively add  as a dependency.You can then use the API:An integral type representing the smallest value possible. In other words your program should think in cents not in dollars/euros.This should not stop you from having the gui translate it back to dollars/euros. can be used, good explanation of why to not use Float or Double can be seen here: I would use It's still at version 0.6 but looks very promisingJSR 354 provides an API for representing, transporting, and performing comprehensive calculations with Money and Currency. You can download it from this link: An example of creating a MonetaryAmount and printing it to the console looks like this::When using the reference implementation API, the necessary code is much simpler:The API also supports calculations with MonetaryAmounts:CurrencyUnit and MonetaryAmountMonetaryAmount has various methods that allow accessing the assigned currency, the numeric amount, its precision and more:MonetaryAmounts can be rounded using a rounding operator:When working with collections of MonetaryAmounts, some nice utility methods for filtering, sorting and grouping are available.Custom MonetaryAmount operationsResources: See Also: You should use   to represent monetary values .It allows you to use a variety of , and in\nfinancial applications, the rounding mode is often a hard requirement\nthat may even be mandated by law.BigDecimal is the best data type to use for currency.There are a whole lot of containers for currency, but they all use BigDecimal as the underlying data type. You won't go wrong with BigDecimal, probably using BigDecimal.ROUND_HALF_EVEN rounding.I like using  which would wrap either a double, BigDecimal, or int as previous answers have suggested.  (I would use a double unless precision problems crop up).A Tiny Type gives you type safety so you don't confused a double money with other doubles.I have done a microbenchmark (JMH) to compare Moneta (java currency JSR 354  implementation) against BigDecimal in terms of performance.Surprisingly, BigDecimal performance seems to be better than moneta's. \nI have used following moneta config: org.javamoney.moneta.Money.defaults.precision=19\norg.javamoney.moneta.Money.defaults.roundingMode=HALF_UPResulting in Please feel free to correct me if i'm missing somethingFor simple case (one currency) it'is enough /. \nKeep money in cents (...) or hundredth / thousandth of cents (any precision you need with fixed divider)"},
{"body": "An existing web application is running on Tomcat 4.1.  There is an XSS issue with a page, but I can't modify the source.  I've decided to write a servlet filter to sanitize the parameter before it is seen by the page.I would like to write a Filter class like this:But  doesn't exist.How can I change the value of the request parameter before passing the request down the chain?As you've noted  does not have a setParameter method. This is deliberate, since the class represents the request as it came from the client, and modifying the parameter would not represent that.One solution is to use the  class, which allows you to wrap one request with another. You can subclass that, and override the  method to return your sanitized value. You can then pass that wrapped request to  instead of the original request.It's a bit ugly, but that's what the servlet API says you should do.  If you try to pass anything else to , some servlet containers will complain that you have violated the spec, and will refuse to handle it.A more elegant solution is more work - modify the original servlet/JSP that processes the parameter, so that it expects a request  instead of a parameter. The filter examines the parameter, sanitizes it, and sets the attribute (using ) with the sanitized value. No subclassing, no spoofing, but does require you to modify other parts of your application.For the record, here is the class I ended up writing:Write a simple class that subcalsses  with a getParameter() method that returns the sanitized version of the input. Then pass an instance of your  to  instead of the request object directly.Try . It worked fine for me.Please find this code sample:You can use  for Sanitization. Inside filter before calling  method, call this code.\nHere is Sample Code:"},
{"body": "I want to copy text from a 's cell to the clipboard, making it available to be pasted into other programs such as Microsoft Word. I have the text from the , but I am unsure how to copy it to the clipboard.This works for me and is quite simple:Import these:And then put this snippet of code wherever you'd like to alter the clipboard:I've just tried it and it works. Not sure if there are some 'good practice' flaws in though, but it will solve your problem!LHThe following class allows you to copy/paste a String to/from the clipboard."},
{"body": "Is there an easy way to get the ID (ObjectID) of the last inserted document of a mongoDB instance using the Java driver?Hate to answer my own question, but I just realized you can do this:It's safe to do if you look at driver code I do not know about the Java driver but for posterity, the getLastError command can be run to get the _id of a write, even an upsert (as of 1.5.4)To avoid casting from  to , given a  and a , you can do the following:After a document is inserted into the MongoDB collection, the successful insertion should update required fields (viz. _id). You may query the inserted object for the _id.In MongoTemplate.class has a methodand the method will set id for uswe can see if the entity is a sub-class of BasicDBObject,it will set a id for us.This is insert operation:After insert u get last inserted id:after getting value convert to inter type."},
{"body": "I have data that is organized in kind of a \"key-key\" format, rather than \"key-value\".  It's like a HashMap, but I will need O(1) lookup in both directions.  Is there a name for this type of data structure, and is anything like this included in Java's standard libraries? (or maybe Apache Commons?)I could write my own class that basically uses two mirrored Maps, but I'd rather not reinvent the wheel (if this already exists but I'm just not searching for the right term).There is no such class in the Java API. The Apache Commons class you want is going to be one of the implementations of .As a mathematician, I would call this kind of structure a bijection.In addition to Apache Commons,  also has a .Here is a simple class I used to get this done (I did not want to have yet another third party dependency). It does not offer all features available in Maps but it is a good start.  If no collisions occur, you can always add both directions to the same HashMap :-)Here my 2 cents.Or you can use a simple method with generics. Piece of cake.Of course you must have a map with unique values. Otherwise, one of them will be replaced.Quite an old question here, but if someone else has brain block like I just did and stumbles on this, hopefully this will help.I too was looking for a bi-directional HashMap, sometimes it is the simplest of answers that are the most useful.If you do not wish to re-invent the wheel and prefer not to add other libraries or projects to your project, how about a simple implementation of parallel arrays (or ArrayLists if your design demands it).As soon as you know the index of 1 of the two keys you can easily request the other. So your lookup methods could looks something like:This is assuming you are using proper object oriented structures, where only methods are modifying these arrays/ArrayLists, it would be very simple to keep them parallel. Even easier for an ArrayList since you would not have to rebuild if the size of the arrays change, so long as you add/remove in tandem.Inspired by  I decided to write something similar by myself with some improvements:Usage is just like a normal map, to get a reverse view on the mapping call . The content is not copied, only a view is returned.I'm not sure this is totally fool-proof (actually, it's probably not), so feel free to comment if you notice any flaws and I'll update the answer."},
{"body": "How would I  something is ?for example But I get an error saying that I cannot have  in .You can use  method:why not use  /  ?If you want to , you can do In  you can do Use the following (from Hamcrest):"},
{"body": "I'm currently working on a Java project that is emitting the following warning when I compile:I'm not sure how SO will render the character before the date, but it should be a copyright symbol, and is displayed in the warning as a question mark in a diamond.It's worth noting that the character appears in the output artifact correctly, but the warnings are a nuisance and the file containing this class may one day be touched by a text editor that saves the encoding incorrectly...How can I inject this character into the \"copyright\" string so that the compiler is happy, and the symbol is preserved in the file without potential re-encoding issues?Use the \"\\uxxxx\" escape format.According to , the copyright symbol is unicode U+00A9 so your line should read:Try with:\njavac -encoding ISO-8859-1 file_name.java If you're using Maven, set the  explicitly in the compiler plugin's configuration, e.g.This helped for me: Source: put this line in yor file .gradle  above the Java conf.Most of the time this compile error comes when unicode(UTF-8 encoded) file compiling and also You can add this compile option to your IDE \nex:  Intellij idea\n(File>settings>Java Compiler) add as additional command line parameterI had the same problem, where the character index reported in the java error message was incorrect. I narrowed it down to the double quote characters just prior to the reported position being hex 094 (cancel instead of quote, but represented as a quote) instead of hex 022.  As soon as I swapped for the hex 022 variant all was fine.If one is using Maven Build from the command prompt one can use the following command as well:This worked for me - If you use eclipse (Eclipse can put utf8 code for you even you write utf8 character. You will see normal utf8 character when you programming but background will be utf8 code) ; this will ok if you static value in code. For Example String test = \"\u0130\u0130\u0130\u0130\u0130\u0131\u0131\u0131\u0131\u0131\u0131\u00e7\u00e7\u00e7\u00e7\u00e7\";"},
{"body": "In this question  is a handy flow chart to use when choosing C++ collections.I thought that this was a useful resource for people who are not sure which collection they should be using so I tried to find a similar flow chart for Java and was not able to do so.What resources and \"cheat sheets\" are available to help people choose the right Collection to use when programming in Java? How do people know what List, Set and Map implementations they should use?Since I couldn't find a similar flowchart I decided to make one myself.This flow chart does not try and cover things like synchronized access, thread safety etc or the legacy collections, but it does cover the 3 standard s, 3 standard s and 2 standard s.Probably the most useful other reference is the following page from the oracle documentation which describes each .There is a detailed discussion of when to use  or  here:\nDetailed discussion: : An interface representing an unordered \"bag\" of items, called \"elements\". The \"next\" element is undefined (random).Basic collection diagrams:Comparing the insertion of an element with an  and :Even simpler picture is here. Intentionally simplified!It is simple: if you need to store values with keys mapped to them go for the Map interface, otherwise use List for values which may be duplicated and finally use the Set interface if you don\u2019t want duplicated values in your collection. Here is the complete explanation  , including flowchart etc"},
{"body": "I have configured java to dump garbage collection information into the logs (). I am unsure of what the garbage collection entries in the logs mean. A sample of these entries are posted below. I've searched around on  and have not found solid explanations. I have some reasonable guesses, but I'm looking for answers which provide strict definitions of what the numbers in the entries mean, backed up by credible sources. An automatic +1 to all answers which cite sun documentation. My questions are:Most of it is explained in the  (which you would do well to read anyway).I'm not certain why there's a PSYoungGen in yours; did you change the garbage collector?An example of an associated full GC also shows the collectors used for the old and permanent generations:Finally, breaking down one line of your example log output:I just wanted to mention that one can get the detailed GC log with the parameter. Then you see the PSYoungGen or PSPermGen output like in the answer.Also  seems to generate the same output like  but you can specify an output file in the first.Example usage:To visualize the data better you can try  (a more recent version can be found on ).Take care to write the parameters correctly, I forgot the \"+\" and my JBoss would not start up, without any error message!"},
{"body": "When should I create a checked exception, and when should I make a runtime exception?For example, suppose I created the following class:How should I create my ? Should it extend  or ? Or should I just use  instead?There's a LOT of disagreement on this topic.  At my last job, we ran into some real issues with Runtime exceptions being forgotten until they showed up in production (on agedwards.com), so we resolved to use checked exceptions exclusively.At my current job, I find that there are many who are for Runtime exceptions in many or all cases.Here's what I think:  Using CheckedExceptions, I am forced at compile time to at least acknowledge the exception in the caller.  With Runtime exceptions, I am not forced to by the compiler, but can write a unit test that makes me deal with it.  Since I still believe that the earlier a bug is caught the cheaper it is to fix it, I prefer CheckedExceptions for this reason.From a philosophical point of view, a method call is a contract to some degree between the caller and the called.  Since the compiler enforces the types of parameters that are passed in, it seems symmetrical to let it enforce the types on the way out.  That is, return values or exceptions.My experience tells me that I get higher quality, that is, code that JUST WORKS, when I'm using checked exceptions.  Checked exceptions may clutter code, but there are techniques to deal with this.  I like to translate exceptions when passing a layer boundary.  For example, if I'm passing up from my persistence layer, I would like to convert an SQL exception to a persistence exception, since the next layer up shouldn't care that I'm persisting to a SQL database, but will want to know if something could not be persisted.  Another technique I use is to create a simple hierarchy of exceptions.  This lets me write cleaner code one layer up, since I can catch the superclass, and only deal with the individual subclasses when it really matters.In general, I think the advice by Joshua Bloch in  best summarises the answer to your question:  (Item 58 in 2nd edition). So in this case, if you really want to use exceptions, it should be a checked one. (Unless the documentation of  made it very clear that the method  be called without checking for sufficient balance first by using some other  method - but this would seem a bit awkward.)But also note Items 59:  and 57: . As others have pointed out, this case may not warrant an exception at all. Consider returning  (or perhaps a status object with details about what happened) if there is not enough credit.When to use checked exceptions?  Honestly?  In my humble opinion... never.  I think it's been about 6 years since I last created a checked exception.You can't force someone to deal with an error.  Arguably it makes code worse not better.  I can't tell you the number of times I've come across code like this:Whereas I have countless times written code like this:Why?  Because a condition (not necessarily IOException; that's just an example) wasn't recoverable but was forced down my throat anyway and I am often forced to make the choice between doing the above and polluting my API just to propagate a checked exception all the way to the top where it's (rightlfully) fatal and will be logged.There's a reason Spring's DAO helper classes translate the checked SQLException into the unchecked DataAccessException.If you have things like lack of write permissions to a disk, lack of disk space or other fatal conditions you want to be making as much noise as possible and the way to do this is with... unchecked exceptions (or even Errors).Additionally, .This idea that checked exceptions should be used for \"recoverable\" errors is really pie-in-the-sky wishful thinking.Checked exceptions in Java were an experiment... a failed experiment.  We should just cut our losses, admit we made a mistake and move on.  IMHO .Net got it right by only having unchecked exceptions.  Then again it had the second-adopter advantage of learning from Java's mistakes.IMHO, it shouldn't be an exception at all. An exception, in my mind, should be used when exceptional things happen, and not as flow controls.In your case, it isn't at all an exceptional status that someone tries to transfer more money than the balance allows. I figure these things happen very often in the real world. So you should program against these situations. An exception might be that your if-statement evaluates the balance good, but when the money is actually being subtracted from the account, the balance isn't good anymore, for some strange reason.An exception might be that, just before calling , you checked that the line was open to the bank. But inside the , the code notices that the line isn't open any more, although, by all logic, it should be.  is an exception. If the line can't be opened, that's not an exception, that's a plausible situation.IMHO recap: Exceptions == weird black magic.So, not to be all too contradictive, the method itself might very well throw an exception. But the use of the method should be controlled: You first check the balance (outside of the  method), and if the balance is good, only then call . If  notices that the balance, for some odd reason, isn't good anymore, you throw the exception, which you diligently catch. In that case, you have all your ducks in a row, and know that there's nothing more you can do (because what was  became , as if by itself), other than log the exception, send a notification to someone, and tell the customer politely that someone didn't sacrifice their virgins properly during the last full moon, and the problem will be fixed at the first possible moment.If you are doing this for your own pleasure (and the case seems to be this, see comments), I'd suggest returning a boolean instead. The usage would be something like this:I recently had a problem with exceptions, code threw NullPointerException and I had no idea why, after some investigation it turned out that real exception was swallowed(it was in new code, so its still being done) and method just returned null. If you do checked exceptions you must understand that bad programmers will just try catch it and ignore exception.My feeling is that the checked exception is a useful contract that should be used sparingly.  The classic example of where I think a checked exception is a good idea is an .  My feeling is that I do want to be able to stop a thread / process when I want it to stop, regardless of how long someone has specified to Thread.sleep().So, trying to answer your specific question, is this something that you absolutely want to make sure that everyone deals with?  To my mind, a situation where an  doesn't have enough money is a serious enough problem that you have to deal with it. In response to 's comment: here's an example using InterruptedException as concrete case of an exception that should be handled and you need to have a useful default handler.  Here is what I strongly recommend, certainly at my real job.  You should at least do this:That handler will ensure that the code catches the checked exception and does exactly what you want: get this thread to stop.  Admittedly, if there's another exception handler / eater upstream, it's not impossible that it will handle the exception less well.  Even so,  can help you find those.Now, reality sets in: you can't necessarily force everyone who writes an exception handler for your checked exception to handle it well.  That said, at least you'll be able to \"Find Usages\" and know where it is used and give some advice.Short form: you're inflicting a load the users of your method if you use a checked exception.  Make sure that there's a good reason for it, recommend a correct handling method and document all this extensively.My rule isThere is much documentation on the subject. You can find a lot by browsing the Hibernate\nweb pages since they changed all exceptions of Hibernate 2.x from checked to unchecked in version 3.xFrom :Note that an unchecked exception is one derived from  and a checked exception is one derived from .Why throw a  if a client cannot do anything to recover from the exception?  The article explains:A checked exception means that clients of your class are forced to deal with it by the compiler.  Their code cannot compile unless they add a try/catch block.The designers of C# have decided that unchecked exceptions are preferred.Or you can follow the C-style and check return values and not throw exceptions.Exceptions do have a cost, so they shouldn't be used for control flow, as noted earlier.  But the one thing they have going for them is that they can't be ignored.  If you decide that in this case to eschew exceptions, you run the risk that a client of your class will ignore the return value or fail to check the balance before trying to transfer.  I'd recommend an unchecked exception, and I'd give it a descriptive name like InsufficientFundsException to make it quite clear what was going on.Line isn't always clear, but for me usually runtime exceptions = programming errors, checked exceptions = external errors. This is very rough categorization though. Like others say, checked exceptions force you to handle, or at least think for a very tiny fraction of time, about it.Simply put, use checked exception only as part of external contract for a library, and only if the client wants/needs to catch it. Remember, when using checked exception you are forcing yourself on the caller. With runtime exception, if they are well-documented, you are giving the caller a choice.It is a known problem that checked exceptions are over-used in Java, but it doesn't mean that they are all bad. That's why it is such in integral part of the Spring philosophy, for example ()The advantage of checked exceptions is that the compiler forces the developer to deal with them earlier.  The disadvantage, in my mind anyway, is that developers tend to be lazy and impatient, and stub out the exception-handling code with the intention of coming back and fixing it later.  Which, of course, rarely happens.Bruce Eckel, author of , has a nice  on this topic.I don't think the scenario (insufficient funds) warrants throwing an  --- it's simply  exceptional enough, and should be handled by the normal control flow of the program. However, if I really had to throw an exception, I would choose a , by extending , not  which is unchecked. This forces me to handle the exception explicitly (I need to declare it to be thrown, or catch it somewhere). is a subclass of , which makes it an unchecked exception. I would only consider throwing this if the caller has some convenient way of determining whether or not the method arguments are legal. In your particular code, it's not clear if the caller has access to , or whether the whole \"check balance and transfer funds\" is an atomic operation (if it isn't then the caller really has no convenient way of validating the arguments).EDIT: Clarified my position on throwing .Myself, I prefer using checked exceptions as I can.If you are an API Developer (back-end developer), use checked exceptions, otherwise, use Runtime exceptions.Also note that, using Runtime exceptions in some situations is to be considered a big mistake, for example if you are to throw runtime exceptions from your session beans (see :  for more info about the problem from using Runtime excpetions in session beans)."},
{"body": "In this code, what does the two joins and break mean?  causes  to stop until  terminates?To quote from the :There is a thread that is running your example code which is probably the .It is important to understand that the  and  threads have been running  but the main thread that started them needs to wait for them to finish before it can continue.  That's a common pattern.  Also,  and/or  could have finished  the main thread calls  on them.  If so then  will not wait but will return immediately.No.  The  thread that is calling  will stop running and wait for the  thread to finish.  The  thread is running in parallel and is not affected by  or the  call at all.In terms of the try/catch, the  throws  meaning that the main thread that is calling  may itself be interrupted by another thread.This is a  question. means, t1 says something like \"\". Same is the case with . No matter who started  or  thread (in this case the  method), main will wait until  and  finish their task.However, an important point to note down,  and  themselves   on  and . It is the  thread that has to . means waiting for a thread to complete. This is a blocker method. Your main thread (the one that does the ) will wait on the  line until  finishes its work, and then will do the same for .When thread tA call tB.join() its causes not only waits for tB to die or tA be interrupted itself but create happens-before relation between last statement in tB and next statement after tB.join() in tA thread.It means programAlways printBut programCan print not only But Always only '0'. Because Java Memory Model don't require 'transfering' new value of 'sharedVar' from threadB to main thread without heppens-before relation (thread start, thread join, usage of 'synchonized' keyword, usage of AtomicXXX variables, etc).From oracle documentation If t1 is a  object whose thread is currently executing,If t2 is a  object whose thread is currently executing, API is low level API, which has been introduced in earlier versions of java. Lot of things have been changed over a period of time (especially with jdk 1.5 release) on concurrency front. You can achieve the same with java.util.concurrent API. Some of the examples are Refer to related SE questions:"},
{"body": "Ok so I have a been making an addressbook application and have pretty much finished all the key features but I am looking to implement a sort feature in the program.I want to sort an Arraylist which is of a type called Contact (contactArray) which is a separate class which contains four fields; name, home number, mobile number and address.\nSo I was looking into using the collection sort yet am not sure how i'd implement this.Is this the right sort I should be using / is it possible to use or should I look into making a custom sort?Here's a tutorial about ordering objects:Although I will give some examples, I would recommend to read it anyway.There are various way to sort an . If you want to define a  (default) , then you need to let  implement . Assuming that you want to sort by default on , then do (nullchecks omitted for simplicity):so that you can just doIf you want to define an  (which overrides the natural ordering), then you need to create a :You can even define the s in the  itself so that you can reuse them instead of recreating them everytime:which can be used as follows:And to cream the top off, you could consider to use a :which you can use as follows:In addition to what was already posted you should know that since Java 8 we can shorten our code and write it like:or since List now have  method Since Java 8, functional interfaces (interfaces with only one abstract method - they can have more default or static methods) can be easily implemented using:Since  has only one abstract method  it is functional interface.So instead of (example from  )we can reduce this code to:We can simplify this (or any) lambda by skipping So instead of  we can writeAlso now  has static methods like  or  which we could use to easily create Comparators which should compare some specific values from objects. In other words we can rewrite above code as tells you all you need to know about sorting collections, such as ArrayList.Basically you need toThere's another way as well, involving creating a Comparator class, and you can read about that from the linked page as well.Example:BalusC and bguiz have already given very complete answers on how to use Java's built-in Comparators.I just want to add that google-collections has an  class which is more \"powerful\" than the standard Comparators.\nIt might be worth checking out. You can do cool things such as compounding Orderings, reversing them, ordering depending on a function's result for your objects... is a blog post that mentions some of its benefits.You need make your Contact classes implement , and then implement the  method.  That way, the Collections.sort will be able to sort them for you.  Per the page I linked to, compareTo 'returns a negative integer, zero, or a positive integer as this object is less than, equal to, or greater than the specified object.'For example, if you wanted to sort by name (A to Z), your class would look like this:By using  you can sort a collection of your contacts (for example by their name) as it followsor by their address:and so on. More in general, it offers a DSL to access and manipulate your collections in many ways, like filtering or grouping your contacts based on some conditions, aggregate some of their property values, etc.The Collections.sort is a good sort implementation. If you don't have The comparable implemented for Contact, you will need to pass in a Of note:The merge sort is probably better than most search algorithm you can do.I did it by the following way.\nnumber and name are two arraylist. I have to sort name .If any change happen to name arralist order then the number arraylist also change its order.You shoud use the Arrays.sort function. The containing classes should implement Comparable."},
{"body": "In my application, I have 2 's right above each other. Via a menu option, I want to be able to make the bottom one disappear, and have the top one drop down over the disappeared .The problem is, I have no idea on how to do this in Java.It doesn't have to be animated, I want to hide the  on return of another activity (the menu), in . The menu  sets a  on which I check in , and according to it's value I determine if I need to hide or show the bottom :Can anybody give me a hint or a link on how I should do this?You can call  if you want to remove it from the layout.Or  if you just want to hide it.From :Try this: "},
{"body": "I want to write an comparator that will let me sort TreeMap by value instead of the default natural sorting. i tried something like this, but can't find out what went wrong:I guess what am i asking is what controls what gets passed to comparator function, can i get an Map.Entry passed to comparator?You can't have the  itself sort on the values, since that defies the  specification:However, using an external collection, you can always sort  however you wish, either by keys, values, or even a combination(!!) of the two.Here's a generic method that returns a  of , given a  whose values are :Now you can do the following:Note that funky stuff will happen if you try to modify either the  itself, or the  within, because this is no longer a \"view\" of the original map like  is.Generally speaking, the need to sort a map's entries by its values is atypical.Your original comparator compares  using . This is almost always wrong, since  with  operands is a reference equality, not value equality.polygenelubricants answer is  perfect. It has one important bug though. It will not handle map entries where the values are the same.This code:...Would output:Note how our cow dissapeared  as it shared the value \"1\" with our ape :O!This modification of the code solves that issue:In Java 8:A  is  sorted by the keys, anything else is impossible. A  merely allows you to control   the keys are sorted.If you want the sorted values, you have to extract them into a  and sort that.This can't be done by using a , as it will always get the  of the map to compare.  can only sort by the key.Olof's answer is good, but it needs  more thing before it's perfect. In the comments below his answer, dacwe (correctly) points out that his implementation violates the Compare/Equals contract for Sets. If you try to call contains or remove on an entry that's clearly in the set, the set won't recognize it because of the code that allows entries with equal values to be placed in the set. So, in order to fix this, we need to test for equality between the keys:\"Note that the ordering maintained by a sorted set (whether or not an explicit comparator is provided) must be consistent with equals if the sorted set is to correctly implement the Set interface... the Set interface is defined in terms of the equals operation, but .\"\n()Since we originally overlooked equality in order to force the set to add equal valued entries, now we have to test for equality in the keys in order for the set to actually return the entry you're looking for. This is kinda messy and definitely not how sets were intended to be used - but it works.A lot of people hear adviced to use List and i prefer to use it as wellhere are two methods you need to sort the entries of the Map according to their values.I know this post specifically asks for sorting a TreeMap by values, but for those of us that don't really care about implementation but do want a solution that keeps the collection sorted as elements are added, I would appreciate feedback on this TreeSet-based solution. For one, elements are not easily retrieved by key, but for the use case I had at hand (finding the n keys with the lowest values), this was not a requirement."},
{"body": "I need to find my MySQL username. When I open the MySQL command line client, it only asks me for my password. I don't remember my username. And for connectivity with JDBC, I need the URL, host and port number. Where do I find all of these?If you're already logged into the command line client try this:It will output something similar to this:In my example above, I was logged in as  from .To find port number and other interesting settings use this command:If you want to know the  is running you can use this query on MySQL Command line client --It will give you the port number on which MySQL is running.If you want to know the  you can use this query on MySQL Command line client --It will give you the hostname for mysql.If you want to know the  you can use this query on MySQL Command line client --It will give you the username for mysql.For example, you can try:If you don't know the exact variable name use , as the result may contain more than 500 rows:For Example in my case :  is the host name of the box where my mysql is running. And it my local PC host name.  If it is romote box than you can ping that host directly if, If you are in network with that box you should be able to ping that host.If it  in terminal to check the host name.\nif it is windows you can see same value in   you can see ( i.e System Properties) Hope it will answer your Q. If you use phpMyAdmin, click on , then  on the top menu. Look for the  setting on the page. The value it is set to is the port your MySQL server is running on.Here are the default settings"},
{"body": "My POST method looks like this:When I create a Jersey Client in Netbeans the method who calls the post method looks like this:When running this test:It gives the following output in the server:What do I need to change so that the parameters are giving the correct value?Your  method should be accepting a JSON object instead of a string.  Jersey uses JAXB to support marshaling and unmarshaling JSON objects (see ).  Create a class like:Then your  method would look like the following:This method expects to receive JSON object as the body of the HTTP POST.  JAX-RS passes the content body of the HTTP message as an unannotated parameter --  in this case.  The actual message would look something like:Using JSON in this way is quite common for obvious reasons.  However, if you are generating or consuming it in something other than JavaScript, then you do have to be careful to properly escape the data.  In JAX-RS, you would use a  and  to implement this.  I believe that Jersey already has implementations for the required types (e.g., Java primitives and JAXB wrapped classes) as well as for JSON.  JAX-RS supports a number of other methods for passing data.  These don't require the creation of a new class since the data is passed using simple argument passing.The parameters would be annotated using :The browser will encode the form using .  The JAX-RS runtime will take care of decoding the body and passing it to the method.  Here's what you should see on the wire:The content is  in this case.If you do not know the names of the FormParam's you can do the following:You can using the  annotation if you want to pass parameters via HTTP headers:Here's what the HTTP message would look like.  Note that this POST does not have a body.I wouldn't use this method for generalized parameter passing.  It is really handy if you need to access the value of a particular HTTP header though.This method is primarily used with HTTP GETs but it is equally applicable to POSTs.  It uses the  annotation.Like the previous technique, passing parameters via the query string does not require a message body.  Here's the HTTP message:You do have to be particularly careful to properly  on the client side.  Using query parameters can be problematic due to URL length restrictions enforced by some proxies as well as problems associated with encoding them.Path parameters are similar to query parameters except that they are embedded in the HTTP resource path.  This method seems to be in favor today.  There are impacts with respect to HTTP caching since the path is what really defines the HTTP resource.  The code looks a little different than the others since the  annotation is modified and it uses :The message is similar to the query parameter version except that the names of the parameters are not included anywhere in the message.This method shares the same encoding woes that the query parameter version.   so you do have to be careful there as well.As you can see, there are pros and cons to each method.  The choice is usually decided by your clients.  If you are serving -based HTML pages, then use .  If your clients are JavaScript+HTML5-based, then you will probably want to use JAXB-based serialization and JSON objects.  The  implementations should take care of the necessary escaping for you so that is one fewer thing that can go wrong.  If your client is Java based but does not have a good XML processor (e.g., Android), then I would probably use  encoding since a content body is easier to generate and encode properly than URLs are.  Hopefully this mini-wiki entry sheds some light on the various methods that JAX-RS supports. in the interest of full disclosure, I haven't actually used this feature of Jersey yet.  We were tinkering with it since we have a number of JAXB+JAX-RS applications deployed and are moving into the mobile client space.  JSON is a much better fit that XML on HTML5 or jQuery-based solutions."},
{"body": "Is it good/bad/acceptable practice to pass the current object in a method call.  As in:Specifically, is the line  acceptable?There's no reason not to use it,  is the current instance and it's perfectly legitimate to use. In fact there's often no clean way to omit it.So use it.As it's hard to convince it's acceptable without example (a negative answer to such a question is always easier to argument), I just opened one of the most common java.lang classes, the  one, and of course I found instances of this use, for exampleLook for  in big \"accepted\" projects, you won't fail to find it.There's nothing wrong with that. What is  is to do the same inside constructors, because you would give a reference to a not-yet-completely-initialized object.There is a sort of similar post here: \n where they give an explanation of why the latter is a bad practice., but you should be careful about two things  It's perfectly normal and perfectly acceptable.this stands for the current object. What you are doing is sytatically correct but i don't see a need of this if you are calling the method in the same class.  you can use it.Its just common in programming to pass .But there are pros and cons about using that.Still it is not hazardous  to do so. to pass the current object in a method call if there less complex alternatives to achieve the same behaviour.By definition, a bidirectional association is created as soon as  is passed from one object to another.To quote Refactoring, by Martin Fowler:So, theoretically, we should be hearing alarm bells when we find we need to pass  and try really hard to think of other ways to solve the problem at hand. There are, of course, times when, at last resort, it makes sense to do it. Also it is often necessary to corrupt your design temporarily, doing 'bad practice things', during a longer term refactoring of your code for an overall improvement. (One step back, two steps forward).In practice I have found my code has improved  by avoiding bidirectional links like the plague.Just to add one more example where passing  is correct and follows good design: . In Visitor design pattern, method  is typically implemented in a way it just calls .AcceptableSnippet from Oracle JAVA docs:Everything in java is passed by value. But objects are NEVER passed to the method!\nWhen java passes an object to a method, it first makes a copy of a reference to the object, not a copy of the object itself. Hence this is pefectly used method in java. And most commonly followed usage. "},
{"body": "Is it possible to use a DB sequence for some column that ? I'm using hibernate as jpa provider, and I have a table that has some columns that are generated values (using a sequence), although they are not part of the identifier.What I want is to use a sequence to create a new value for an entity, where the column for the sequence is  (part of) the primary key:Then when I do this:the id will be generated, but the  property will be also generated by my JPA provider.Just to make things clear: I want  to generate the value for the  property. I know Hibernate can handle database-generated values, but I don't want to use a trigger or any other thing other than Hibernate itself to generate the value for my property. If Hibernate can generate values for primary keys, why can't it generate for a simple property?Looking for answers to this problem, I stumbled upon It seems that Hibernate/JPA isn't able to automatically create a value for your non-id-properties. The  annotation is only used in conjunction with  to create auto-numbers.The  annotation just tells Hibernate that the database is generating this value itself.The solution (or work-around) suggested in that forum is to create a separate entity with a generated Id, something like this:I found that  works perfect but only for PostgreSQL. For me this was perfect solution, because second entity is \"ugly\" option.Hibernate definitely supports this. From the docs:\"Generated properties are properties which have their values generated by the database. Typically, Hibernate applications needed to refresh  objects which contain any properties for which the database was generating values. Marking properties as generated, however, lets the application delegate this responsibility to Hibernate. Essentially, whenever Hibernate issues an SQL INSERT or UPDATE for an entity which has defined generated properties, it immediately issues a select afterwards to retrieve the generated values.\"For properties generated on insert only, your property mapping (.hbm.xml) would look like:For properties generated on insert and update your property mapping (.hbm.xml) would look like:Unfortunately, I don't know JPA, so I don't know if this feature is exposed via JPA (I suspect possibly not)Alternatively, you should be able to exclude the property from inserts and updates, and then \"manually\" call session.refresh( obj ); after you have inserted/updated it to load the generated value from the database.This is how you would exclude the property from being used in insert and update statements:Again, I don't know if JPA exposes these Hibernate features, but Hibernate does support them.I know this is a very old question, but it's showed firstly upon the results and jpa has changed a lot since the question.The right way to do it now is with the  annotation. You can define the sequence, set the default in the column to that sequence and then map the column as:As a followup here's how I got it to work:Although this is an old thread I want to share my solution and hopefully get some feedback on this. Be warned that I only tested this solution with my local database in some JUnit testcase. So this is not a productive feature so far.I solved that issue for my by introducing a custom annotation called Sequence with no property. It's just a marker for fields that should be assigned a value from an incremented sequence.Using this annotation i marked my entities.To keep things database independent I introduced an entity called SequenceNumber which holds the sequence current value and the increment size. I chose the className as unique key so each entity class wil get its own sequence.The last step and the most difficult is a PreInsertListener that handles the sequence number assignment. Note that I used spring as bean container.As you can see from the above code the listener used one SequenceNumber instance per entity class and reserves a couple of sequence numbers defined by the incrementValue of the SequenceNumber entity. If it runs out of sequence numbers it loads the SequenceNumber entity for the target class and reserves incrementValue values for the next calls. This way I do not need to query the database each time a sequence value is needed.\nNote the StatelessSession that is being opened for reserving the next set of sequence numbers. You cannot use the same session the target entity is currently persisted since this would lead to a ConcurrentModificationException in the EntityPersister.Hope this helps someone.I run in the same situation like you and I also didn't find any serious answers if it is basically possible to generate non-id propertys with JPA or not.My solution is to call the sequence with a native JPA query to set the property by hand before persisiting it.This is not satisfying but it works as a workaround for the moment.MarioI've found this specific note in session 9.1.9 GeneratedValue Annotation from JPA specification:\n\"[43] Portable applications should not use the GeneratedValue annotation on other persistent fields or properties.\"\nSo, I presume that it is not possible to auto generate value for non primary key values at least using simply JPA.I've been in a situation like you (JPA/Hibernate sequence for non @Id field) and I ended up creating a trigger in my db schema that add a unique sequence number on insert. I just never got it to work with JPA/Hibernate\"I don't want to use a trigger or any other thing other than Hibernate itself to generate the value for my property\"In that case, how about creating an implementation of UserType which generates the required value, and configuring the metadata to use that UserType for persistence of the mySequenceVal property?This is not the same as using a sequence.  When using a sequence, you are not inserting or updating anything.  You are simply retrieving the next sequence value.  It looks like hibernate does not support it.I fixed the generation of UUID (or sequences) with Hibernate using  annotation:"},
{"body": "From :The second criteria confuses me a bit. Given the first collection is unmodifiable, and assuming that the original collection reference has been disposed away, what are the changes that are referred to in the second line? Is it referring to the changes in the elements held in the collection ie the state of the elements? Second question:\nFor a collection to be immutable, how does one go about providing the additional guarentees specified? If the state of an element in the collection is updated by a thread, is it sufficient for immutability that those updates in the state are not visible on the thread holding the immutable collection?Edit : (highlighting the focus of second question) :Unmodifiable collections are usually read-only views (wrappers) of other collections. You can't add, remove or clear them, but the underlying collection can change.Immutable collections can't be changed at all - they don't wrap another collection - they have their own elements.Here's a quote from guava's So, basically, in order to get an immutable collection out of a mutable one, you have to copy its elements to the new collection, and disallow all operations.The difference is that you can't have a reference to an immutable collection which allows changes. Unmodifiable collections are unmodifiable , but some other object may point to the same data through which it can be changed.e.g. is  (i.e. neither  nor ).\n is : it can't be changed itself, but if later on I change  then  change will be visible in .This is because  is simply a wrapper around  and not really an independent copy. Guava provides the  and some implementations. Those work by actually creating a copy of the input (unless the input is an immutable collection on its own).Regarding your second question:The mutability/immutability of a collection does  depend on the mutability/immutability of the objects contained therein. Modifying an object contained in a collection does  count as a \"modification of the collection\" for this description. Of course if you need a immutable collection, you  also want it to contain immutable objects.I believe the point here is that even if a collection is Unmodifiable, that does not ensure that it cannot change. Take for example a collection that evicts elements if they are too old. Unmodifiable just means that the object holding the reference cannot change it, not that it cannot change. A true example of this is  method. It returns an unmodifiable view of a List. The the List reference that was passed into this method is still modifiable and so the list can be modified by any holder of the reference that was passed. This can result in ConcurrentModificationExceptions and other bad things.Immutable, mean that in no way can the collection be changed.Second question: An Immutable collection does not mean that the objects contained in the collection will not change, just that collection will not change in the number and composition of objects that it holds. In other words, the collection's list of references will not change. That does not mean that the internals of the object being referenced cannot change. supports what you are after, in two ways.First, it provides an  annotation, so that you can annotate a class to say that it is immutable.  There is a maven plugin to allow you to check that your code  immutable (use of  etc.).  Second, it provides the persistent collections from Clojure, (with added generics) and ensures that elements added to the collections are immutable.  Performance of these is apparently pretty good.  Collections are all immutable, but implement java collections interfaces (and generics) for inspection.  Mutation returns new collections.Now  has factory Methods for Immutable List, Set, Map and Map.Entry .In Java SE 8 and earlier versions, We can use Collections class utility methods like unmodifiableXXX to create Immutable Collection objects. However these Collections.unmodifiableXXX methods are very tedious and verbose approach. To overcome those shortcomings, Oracle corp has added couple of utility methods to List, Set and Map interfaces. \nList and Set interfaces have \u201cof()\u201d methods to create an empty or no-empty Immutable List or Set objects as shown below:I have written the documentation for  collections that are introduced in Java 9 which can be found ."},
{"body": "Guava offers a nice shortcut for initializing a map.  However I get the following compiler error (Eclipse Indigo) when my map initializes to nine entries. The method  in the type  is not applicable for the arguments \nThe message appears to say that Obviously, this cannot be the case but I can't figure out what to do to increase the size of my initializer.Can someone tell me what is missing?Notice that your error message only contains five  pairs, 10 arguments total. This is by design; the ImmutableMap class provides six different  methods, accepting between zero and six key-value pairings. There is not an  overload accepting a varags parameter because  and  can be different types.You want an :if the map is short you can do:If it is longer then:"},
{"body": "I'm currently using jackson 2.1.4 and I'm having some trouble ignoring fields when I'm converting an object to a JSON string.Here's my class which acts as the object to be converted:And here's how I convert it:Here's the output:How can I avoid those null values? I only want to take required information for the \"subscription\" purpose!Here's exactly the output that I'm looking for:I also tried @JsonInclude(Include.NON_NULL) and put all my variables to null, but it didn't work either! Thanks for your help guys!You have the annotation in the wrong place - it needs to be on the class, not the field. i.e: As noted in comments, in version 2.x+ the syntax for this annotation is: The other option is to configure the  directly, simply by calling \n(for the record, I think the popularity of this answer is an indication that this annotation  be applicable on a field-by-field basis *ahem @fasterxml*)You can also set the global option:Also you can try to use if you are dealing with jackson with version below 2+ (1.9.5) i tested it, you can easily use this annotation above the class. Not for specified for the attributes, just for class decleration.Or you can use GSON [], where these null fields will be automatically removed.OUTPUT:I used For jackson 2.x@JsonInclude(JsonInclude.Include.NON_NULL) just before the field.You need to add import com.fasterxml.jackson.annotation.JsonInclude;Add  on top of POJO If you have nested POJO then need to add on every values.NOTE:\nJAXRS (Jersey ) automatically handle this scenario 2.6 and above.I was having similar problem recently with version 2.6.6. Using above annotation either on filed or class level was not working as expected. The POJO was mutable where I was applying the annotation. When I changed the behaviour of the POJO to be immutable the annotation worked its magic. I am not sure if its down to new version or previous versions of this lib had similar behaviour but for 2.6.6 certainly you need to have Immutable POJO for the annotation to work. Above option mentioned in various answers of setting serialisation inclusion in ObjectMapper directly at global level works as well but, I prefer controlling it at class or filed level. So if you wanted all the null fields to be ignored while JSON serialisation then use the annotation at class level but if you want only few fields to ignored in a class then use it over those specific fields. This way its more readable & easy for maintenance if you wanted to change behaviour for specific response."},
{"body": "The Eclipse IDE is showing red underline and when I focus it the tag is : can not find the library descriptor for I also use this but I don't get any error.Did you include the  in your library? If not maybe this causing the problem. And also the 'tld' folder do you have it? And how about your  did you map it?Have a look on the info about  for other information.I know this thread is a year old now but having experienced the same problem I managed to solve the problem by setting a target server for my project.i.e. right-click on your project and select 'Properties' -> 'Targeted Runtimes' and select the server you going to run your web app on (Tomcat 6 or 7).As @ace mentioned you will need the jstl.jar in your project, so if you are using maven, you could add this dependency:Source: Hope it helps. Most of servers already have this dependency, if you add it using maven it may cause version conflicts (like Method/ClassNotFoundException) if you don't configure the server well, so it's better set a target server for your project, as @willix mentioned.Try to add like this:instead of having After a couple of hit and trial I use this. This works for me.WARNING: As BalusC correctly mentioned, this works for JSTL 1.0.Add both javax.servlet.jsp.jstl-api-1.2.1.jar and standard-1.1.2.jarYou are probably targeting a server without built-in JSTL support (e.g. some version of Tomcat.) You will need to provision your own JSTL tag library.I tried \"validating\" de *.jsp and *.xml files in eclipse with the validate tool.\"right click on directory/file ->- validate\" and it worked!Using eclipse juno.Hope it helps!Resolves the problem.paste below two jar in your /WEB-INF/lib folder and then go to project properties and go to add jar and select these two jars  then click Ok, Okstandard.jar, \njstl-1.0.2.jarIt has nothing to do about .Just go to project and right click then  project menu -> Clean the project error will definitely remove and update maven .It will work perfectly when you will place the two required jar files under /WEB-INF/lib folder i.e. \njstl-1.2.jar\nand javax.servlet.jsp under /WEB-INF/lib folder.Hope it helps. :) This should work     and moreover please let us know why are you importing all these classWe don't need to include java.lang as it is the default package.I will throw one more solution into the mix. I downloaded a sample app and it was crimping only on this taglib. Turns out it didn't care for the single quotes around the attributes.Once I changed those and made sure jstl.jar was in the web app, i was good to go.I added jstl jar in a library and added it to build path and deployment assembly but it dint worked.\nthen i simply copied my jstl jar into lib folder inside webcontent, it worked.\nin eclipse lib folder in included to deployment assembly by defaultYou have to write asMake sure you have  jstl-1.0 & standard.jar  files are placed in a classpathI solved this issue.\nuse below taglib and add jstl-1.2.jar"},
{"body": "I want to use the count from the JSTL forEach loop, but my code doesnt seem to work.produces The variable set by varStatus is a  object, not an int. Use:To clarify:You can try this. similar resultIts really helped me to dynamically generate ids of  for the below code.if you execute this line  prints the below:you'd use any of these:JSTL c:forEach varStatus propertiesProperty    Getter  Description "},
{"body": "I am seeking to run a common Java program in both Windows and Linux.The program needs to do some things differently on each platform.So how can / should my Java program detect it is running under Linux vs. Windows? has a class \nyou can use :Try:Useful simple class are forked by me on: \nI think It's a best approach to use Apache lang dependency to decide which OS you're running programmatically through JavaYou can use \"system.properties.os\", for example:Here are more details:"},
{"body": "I've a Java object 'ChildObj' which is extended from 'ParentObj'. Now, if it is possible to retrieve all the attribute names and values of ChildObj, including the inherited attributes too, using Java reflection mechanism? gives me the array of public attributes, and  gives me the array of all fields, but none of them includes the inherited fields list.Is there any way to retrieve the inherited attributes also?no, you need to write it yourself. It is a simple recursive method called on :If instead you wanted to rely upon a library to accomplish this,  version 3.2+ provides :You need to call:Recursing up the inheritance hierarchy as necessary.Use Reflections library:Working version of \"DidYouMeanThatTomHa...\" solution aboveThe recursive solutions are OK, the only small issue is that they return a superset of declared and inherited members. Note that getDeclaredFields() method returns also private methods. So given that you navigate the whole superclass hierarchy you will include all private fields declared in the superclasses, and those don't get inherited.A simple filter with a Modifier.isPublic || Modifier.isProtected predicate would do:You can try:Shorter and with less object instantiated ? ^^"},
{"body": "I'm starting a new project now. I have to choose technologies. I need something light, so no EJB or Seam. On the other hand I need JPA (Hibernate or alternative) and JSF with IceFaces.Do you think that such a stack on Spring 3 deployed on Tomcat is a good choice? Or a Java EE 6 web application could be better? I'm afraid that Java EE 6 is a new technology, not well documented yet. Tomcat seems to be easier to maintain than Glassfish 3. What's your opinion? Do you have any experiences?Would you care to explain what makes EJBs heavy since EJB3? Do you realize that we are not in 2004 anymore? I'd really like to read  definition of light and your arguments (and I will update my answer with pleasure because I'm pretty sure I would have a few solid things to say).Java EE 6 Web Profile which includes JSF 2.0, JPA 2.0, Bean Validation, EJB 3.1 Lite, CDI,... would be perfect for this and you can use  to run an application built with the Java EE 6 Web Profile.Well,  like the idea to run my code on a  (Java EE) rather than on a  (Spring). And I think that Java EE 6 is good enough (and this is an euphemism, EJB 3.1 (Lite), JPA 2.0, JSF 2.0, CDI kick ass). Note that I was a JSF skeptic but I took a second look and JSF 2.0 with CDI is so different that I can't even compare. And if you didn't look at CDI, let me tell you that it rocks. Java EE looks pretty well documented to me. This sounds like free claim. And, believe me or not,  start to find Spring getting complicated while Java EE getting easier.Did you try something? Did you face any particular problem? Again, this sounds like free claim.I have not used JavaEE6.However, I have been beaten up badly enough by all the previous versions of JavaEE and EJB's that I won't trust it until it establishes itself as the de facto standard, not just the de jure standard.  Right now, Spring is still the de facto standard.Fool me once, shame on you.  Fool me twice, shame on me.   Fool me three times, EJB.Some will claim that Spring is proprietary.  I would argue that the vendor implementations of the JavaEE specs have been just as proprietary, if not more so.I went through a major conversion recently of moving a bunch of Java Applications from JBoss to Weblogic.  All of the Spring/Hibernate apps ported with zero modifications, because they had all the libraries they needed built in.  All the apps that used JPA and EJB and JSF were a disaster to port.  Subtle differences in interpretations of JPA, EJB, and JSF between appservers caused all kinds of nasty bugs that took forever to fix.  Even something as simple as JNDI naming was completely different between AppServers.Spring is an implementation.  JavaEE is a spec.  That is a HUGE difference.  I would prefer to use a spec IF the spec was 100% air-tight and gave absolutely no wiggle room in the way vendors implement that spec.  But the JavaEE spec has never been that.  Maybe JavaEE6 is more air-tight?  I don't know.  The more you can package in your WAR, and the less you depend on AppServer libraries, the more portable your application will be, and that, after all, is the reason I use Java and not Dot-NET.Even IF the spec was air-tight, it would be nice to be able to upgrade the appserver without having to upgrade all my technology stacks in all my applications along with it.  If I want to upgrade from JBoss 4.2 to JBoss 7.0, I have to consider the impact of the newer version of JSF on all of my applications.  I don't have to consider the impact on my Spring-MVC (or Struts) applications.   It doesn't matter. Java EE 6 is good enough and because of the profiles there, it is not \"heavy\" - you'll just be using the web profile.Personally, I prefer Spring. But I'm running out of rational arguments against Java EE 6 :)(As I was reminded by a comment - you might want to try , as well as  and/or  - depending on what components you need).Recently, one of my client assignments involved evaluating Spring Stack Vs Custom framework stack Vs a Java EE Standards. After a month of evaluation and prototyping, I was not just happy but blown away by the Java EE 6 feature set. For any new \"enterprise\" project architecture in 2011 and going forward, I would go with Java EE 6 and potential extensions like Seam 3 or the upcoming Apache JSR299 extensions project. Java EE 6 Architecture is streamlined and incorporates best of many open source ideas that have evolved in the last several years. Consider the following features out of the box: Event Management, Contexts and DI, Interceptors, Decorators, RESTful webservices, integrated testing with embeddable container, Security, and many more.Most of my results are  explaining the key concepts of Java EE 6 that you might find useful.Of course, there is no hard and fast rule for choosing a framework. Java EE 6 could be well bloated for simpler \"web sites\" that don't require a rich conversational session state. You might as well pick Grails or Play! Framework. But for conversational web applications, I can't see a better argument why Java EE 6 is not a good fit.Now, after some time, I have experience with stacks : My colclusions are:Read Adam Bien's , including comments to get both sides of coin. I will choose Spring for several reasons and following is one of them (reproducing one of the comments from post)'I am not sure which Java EE 6 server you are talking about. There is Glassfish certified and TMAX JEUS. It will take quite a while (read: years) until Java EE 6 compliant versions of WebSphere, WebLogic, JBoss etc are in production and can be used for real application. Spring 3 just needs Java 1.5 and J2EE 1.4 so can readily be used in almost all environments' My opinion is based on something not mentioned by others, namely that code at my work tend to live for decades (literaly), and hence that maintenance is very important to us.  Maintenance of our own code, and the libraries we use.  Our own code we control, but it is in our interest that the libraries we use, are maintained by  in the above mentioned decades or more.To make a long story short, I have concluded that the best way to achieve this is by using open source implementations of Sun specifications all the way down to the raw JVM.Of the open source implementations Apache Jakarta has proven to maintain their libraries, and recently Sun has done a lot of work in producing high quality implementations for Glassfish v3.  In any case, we also have the source for all modules, so if all else fails, we can maintain them ourselves.Sun specifications are usually very strict meaning that implementations conforming to the spec can be interchanged easily.  Just have a look at servlet containers.In this particular case, I would suggest having a look at JavaServer Faces simply because it is part of Java EE 6 meaning it will be available and maintained for a very, very long time.  Then we have chosen to augment with MyFaces Tomahawk as it gives some useful additions, and it is a jakarta project.There is nothing wrong with JBoss Seam or others.  It is just that their focus is less towards the maintenance issue that is so important to us.I can see using Spring if you already have it, but for the new project, what's the point? I would go directly with Java EE 6 (ejb3, jsf2.0, etc.)If the client is fine with Flex, go for it. Use BlazeDS or similar - no mvc. You might spend more time on that part (exchanging data between server and client) but you have full control on both sides.Don't use Vaadin, unless you want to kill your browser. Plus, you spend more time on getting around the code once your pages become more complex. Also, your mindset will need to be completely changed and anything you know about standard front end development will be waste. The argument that you don't have to use HTML or JS doesn't make much sense. You still have to know it even if you don't use it. It renders to HTML and JS eventually. Then try to debug it - make sure you got few days for simple stuff. Plus, I cannot imagine web developer who doesn't know html/js.I just don't understand why people are trying all those abstractions instead of using Java EE directly.Why is there still rumblings about EJB being heavyweight in 2010? It seems people are not being updated in Java EE technologies. Just try it out , you will be pleasantly surprised how things are simplified in Java EE 6. The answer to your questions depends on your project requirements. If you don't require the Java EE features like message queues, container managed global transactions etc then go with tomcat+spring.Also from experience I have found that projects that require a lot of web service integration, scheduling, message queues are best best done using some of the Java EE stack.\nThe good thing is using spring you can still integrate with Java EE modules running in an application server. Java EE 6 is very different from the previous releases, and it really makes everything lot easier. Java EE 6 combines the best ideas from the diverse Java community - for instance Rod Johnson from Spring framework was actively involved in the making of the Dependency Injection JSR in Java EE 6. A benefit of using Java EE 6 is that you are coding according to a standard, which could be important in some organizations for vendor support etc. GlassFish v3 supports Java EE 6 and it is quite light-weight and starts up really fast. I have been using glassfish v3 for my developments, and it is really easy to configure. It comes with a very user-friendly admin console that lets you graphically administer your server.If you are using GlassfishV3 and JSF 2, then you can take advantage of the CDI features of Java EE 6, that lets you easily create conversations (e.g. wizard like pages) in JSF.Having said that, using Java EE 6 also requires you to learn a new API. Depending on the timeframe available it might not be the best choice for you. Tomcat has been around for ages, and the tomcat+spring combination has been adopted by many web projects, which means lots of documentation/forums are around.I have worked in both Spring and Java EE 6. What I can say from my experience is that If you are going for the age old JSP or proprietary Flex then you are safe if you stay with Spring.But if you are to move ahead with JSF then it's time to shift to Java EE 6. With Java EE 6 you are moving to Facelets and standardized script libraries and component libraries. No more script incompatibilities and component library matrices.Regarding Spring MVC, it's good as long as your project doesn't grow too big. If it's a huge enterprise application stick on to Java EE 6. Because that's the only way you could maintain your own component libraries and resource bundles in an orderly manner.If you need the Java EE full stack I recommend you GlassFish 3.1. It starts very quickly compared to other Java EE containers which implements some part or all Java EE 6 (JBoss 6, WebLogic 10.3.4), redeployment take seconds and almost all can be done by convention over configuration, it is very friendly.I you want something \"Light\" you can customize an Apache Tomcat 7.x with the desired features. I used a lot with the following libraries:\nWeld 1.1.0 (CDI)\nJPA 2.0 (Hibernate 3.6.x) - only resource local transactions\nJSF 2.x (Mojarra)\nRichFaces 4.0\nBIRT runtimeBeen a Java EE developer for the past 10 years (I suffer early EJB, JSF and web technologies), Java EE 6 is very easy, well coupled and current hardware runs smooth so original reasons that motivated Spring are no longer valid.I'd still prefer Spring.And I'd pass on JSF.  I think it's a dead technology.  Spring MVC would be a better alternative.  So would Flex.  Think in terms of contract first XML services and you can decouple the back end from the UI completely.  I'd recommend Spring + Tomcat unless you can wait the time for glassfish v3 and Weld to become more mature.  There are currently a few issues with memory consumption/cpu load when running glassfish with CDI enabled applications.Didn't read everything but just to tell that you can now use EJB3 inside a war on Java EE 6 so you can use EJB3 on Tomcat (I think).I recommended to you Tomcat with Spring because:It is good choice to choose Tomcat because you don't need any heavyweight processing"},
{"body": "I have enums like:When formatting the file, the output becomes:The answer by @wjans worked fine for normal enums, but not for enums with arguments. To expand on his answer a bit, here's the settings that provided the most sensible formatting for me in Eclipse Juno:This sets the 3 subnodes for the enum treenode to the same wrapping policy, and the same force split policy except for the  treenode, so your enums with arguments will be formatted each on their own line. The arguments will only wrap if they exceed maximum line width.You can specify this in your formatter preferences:It's slightly ugly too, but if your company policy prevents you from changing the formatter, you can just put comments at the end of lines you don't want to be wrapped.It's not nice but you can turn the Eclipse formatter off for some sections of code...the option is in the Windows->Preferences->Java->Code Style->Formatter->Edit->Off/On Tags panelYou need to set the line wrapping policy under enum declaration for \"Constants.\"Set the wrapping policy to"},
{"body": "I have several output listeners that are implementing .\nThey can be either a  writing to stdout or to a , or they can be writing to memory or any other output destination; therefore, I specified  as an argument in the method.Now, I have received the String. What is the best way to write to streams here?Should I just use ? I can give it bytes, but if the destination stream is a character stream then will it convert automatically?Do I need to use some bridge streams here instead?Thank you.Streams ( and ) transfer  data. If you want to write a string to a stream, you must first convert it to bytes, or in other words  it. You can do that manually (as you suggest) using the  method, but you should avoid the  method, because that uses the default encoding of the JVM, which can't be reliably predicted in a portable way.The usual way to write character data to a stream, though, is to wrap the stream in a , (often a ), that does the conversion for you when you call its  (or ) method. The corresponding wrapper for InputStreams is a . is a special  implementation in the sense that it also contain methods that automatically encode strings (it uses a writer internally). But it is still a stream. You can safely wrap your stream with a writer no matter if it is a  or some other stream implementation. There is no danger of double encoding.OutputStream writes bytes, String provides chars. You need to define Charset to encode string to byte[]:Change  to a charset of your choice.You can create a PrintStream wrapping around your OutputStream and then just call it's print(String):Wrap your OutputStream with a  and use the print methods on that class.  They take in a String and do the work for you. it is to be done this way:You may use :"},
{"body": "I'm trying to write an app that helps you manage your finances.  I'm using an  Field where the user can specify an amount of money.I set the  to  which works fine, except that this allows people to enter numbers such as  which is not perfect for money.Is there a way to limit the number of characters after the decimal point to two?More elegant way would be using a regular expression ( regex ) as follows:To use it do: Simpler solution without using regex:To use: This implementation of  solves the problem.Here is a sample  which only allows max 4 digits before the decimal point and max 1 digit after that.Values that edittext allows: , , Values that edittext blocks: , , I achieved this with the help of  by the following wayThis solution will not allow the user to enter more than two digit after decimal point. Also you can enter any number of digits before decimal point. See this blog  to set filter for multiple EditText. I hope this will help. Thank you.I made some fixes for @Pinhassi solution. It handles some cases:1.you can move cursor anywhere2.minus sign handling3.digitsbefore = 2  and digitsafter = 4 and you enter 12.4545. Then if you want to remove \".\", it will not allow.My solution is simple and works perfect!Usage:I don't like the other solution and I created my own.\nWith this solution you can't enter more than MAX_BEFORE_POINT digit before the point and the decimals can't be more than MAX_DECIMAL.You just can't type the digit in excess, no other effects!\nIn additional if you write \".\" it types \"0.\"And it's done!Try using  to format your string before you put it into a TextView.Something like: - There is no inputType for currency that I could find in the docs. I imagine this is because there are some currencies that don't follow the same rule for decimal places, such as the Japanese Yen.As LeffelMania mentioned, you can correct user input by using the above code with a  that is set on your .Slightly improved @Pinhassi solution.Works very well. It validates concatenated strings.The requirement is  There should be  for digits before decimal point. So, solution should be,And use it as,Thanks to @Pinhassi for the inspiration.All answers here are pretty complex I tried to make it much simpler.Look at my code and decide for yourself - What this does is when you exit editing phase it formats the field to the right format. At them moment it has only 2 decimal charachters. I think this is pretty easy way to do this.I have modified the above solutions and created following one. You can set number of digits before and after decimal point.}Simple Helper class is here to prevent the user entering more than 2 digits after decimal :The InputFilter I came up with allows you to configure the number of digits before and after the decimal place.  Additionally, it disallows leading zeroes.Here is my solution:If the user enters a number with more than two numbers after the decimal point, it will be automatically corrected.I hope I have helped!I've also came across this problem. I wanted to be able to reuse the code in many EditTexts. This is my solution:Usage :Class:I really liked Pinhassi's answer, but noticed that after the user had entered the specified number digits after the decimal point you could no longer enter text to the left side of the decimal point.  The problem was that the solution only tested the previous text that had been entered, not the current text being entered.  So here is my solution that inserts the new character into the original text for validation.And the call to set the editText filterI improved on the solution that uses a regex by Pinhassi so it also handles the edge cases correctly. Before checking if the input is correct, first the final string is constructed as described by the android docs.Usage:@Meh for u..A very late response:\nWe can do it simply like this:Like others said, I added this class in my project and set the filter to the  I want. The filter is copied from @Pixel's answer. I'm just putting it all together. Now set the filter in your  like this.Here one important thing is it does solves my problem of not allowing showing more than two digits after the decimal point in that  but the problem is when I  from that , it returns the whole input I typed. For example, after applying the filter over the , I tried to set input 1.5699856987. So in the screen it shows 1.56 which is perfect.Then I wanted to use this input for some other calculations so I wanted to get the text from that input field (). When I called  it returns 1.5699856987 which was not acceptable in my case.So I had to parse the value again after getting it from the .  does the trick here after getting the full text from the . et = (EditText) vw.findViewById(R.id.tx_edittext);This works fine for me. It allows value to be entered even after focus changed and retrieved back. For example: ,  , , etc..1.\nSpecifies the length of the input  accessed from  file.It is quiet easy to change values.\n2., this is for decimal places max limit.Array of  values that allows to perform action.I just used array of values that contain multiple edittext\nNext  file.Here is the  that allow only  number of digits after decimal point.ThanksThis is to build on pinhassi's answer - the issue that I came across was that you couldn't add values before the decimal once the decimal limit has been reached.  To fix the issue, we need to construct the final string before doing the pattern match.The simplest way to achieve that is:I have changed answer \u21166 (by Favas Kv)  because there You can put just point in the first position.  This is the simplest solution to limit the number of digits after decimal point to two.Hope this helps!"},
{"body": "Two questions about using a question mark \"?\" and colon \":\" operator within the parentheses of a print function:  What do they do? Also, does anyone know the standard term for them or where I can find more information on their use?  I've read that they are similar to an 'if' 'else' statement.This is the , which can be used anywhere, not just the print statement. It's sometimes just called \"the ternary operator\", but , just the most common one.Here's a good example from Wikipedia demonstrating how it works:Basically it takes the form:So if the boolean statement is true, you get the first part, and if it's false you get the second one.Try these if that still doesn't make sense:Thats an if/else statement equilavent toMaybe It can be perfect example for Android,\n since the condition is false it takes y value.A question mark (?)\n. The value to use if the condition is trueA colon (:)\n. The value to use if the condition is falseit is a ternary operator and in simple english it states Also just though I'd post the answer to another related question I had,Is equivalent to:If x is false or null then the value of y is taken.They are called  since they are the only one in Java. The difference to the if...else construct is, that they return something, and this something can be anything: "},
{"body": "I was testing out some new features of Java 8 and copied the example into my IDE (Eclipse originally, then IntelliJ) as shown here:\nEclipse offered no support whatsoever for lambda expressions, and IntelliJ kept reporting an error \"Lambda expressions not supported at this language level\".  I would like to know if this is a problem with my install, the code, or support.In IntelliJ IDEA:In  \u2192  \u2192 , change  to You should change source code Language Level also on the Source tab (Modules part). For intellij 13, \nSimply change the  itself to  with following navigation. I also had to update  when there was no maven plugin for .But this  would automatically be fixed if there's already a  for it, Just add  in build.gradle yours app:Actually, Eclipse support for Java 8 is available: see  and .To compile with Java 8 (lambdas etc) in IntelliJ IDEA 15;As Stephen C pointed out, Eclipse Kepler (4.3) has Java 8 support when the patch is installed (installation instructions )Once installed, you\u2019ll need to tell your projects to use java 8. First add the JDK to eclipse:Then tell the project to use JDK 1.8:In intellij 14, following settings worked for me.\nEven after applying above defined project specific settings on IntelliJ as well as Eclipse, it was still failing for me !Possible Cause #1 (same as the first 3 answers for this question): Project Structure SettingsIf the above does not work, check the  of your compiler and move on to Possible Cause #2.Possible Cause #2: CompilerBest wishes :)Adding following block to pom file worked for me :Ctrl + Alt + Shift + S and then from project select the language level 1.8, read more about Lambda Expressions "},
{"body": "I'm trying to mess with the new RecyclerView and whenever I try to run it, my app immediately crashes. It gives me NullPointerException for trying to access methods from . I've looked at other posts and saw that most people didn't have  but I tried that and it hasn't helped at all. Not really sure what to do at this point, any help would be appreciated. Here the error log: (I would post a picture but I don't have 10 rep yet)This issue usually occurs when no  was provided for the . You can do it like so:  In my case it was not connected to 'final', but to the issue mentioned in @NemanjaKova\u010devi\u0107 comment to @aga answer.\nI was setting a layoutManager on data load and that was the cause of the same crash. \nAfter moving the layoutManager setup to onCreateView of my fragment the issue was fixed.Something like this:For me, I was having the same issue, the issue was that there was an unused RecyclerView in xml with view gone but I am not binding it to any adapter in Activity, hence the issue. It was solved as soon as I removed such unused recycler views in xmli.e - I removed this view as this was not called in code or any adapter has been setI experienced this crash even though I had the  properly set. I had to move the   initialization code into the  callback to fix this issue.You need to use  in the  method. Before adding  to a view, it must have the  set.Since LinearLayoutManager is vertical by default, an easier way to do this is:If you want to change the orientation you could use this constructor:I got this issue due to wrong reference recycler view id.recyclerView = (RecyclerView) findViewById(R.id.rv_followers_list);torecyclerView = (RecyclerView) findViewById(R.id.rv_search_list);Check with you recycler view ID, pointing to actual recycler view solved my issueI think the problem in your Adapter.\nMake sure you have returned ViewHolder in onCreateViewHolder().\nLike below"},
{"body": "I do not understand this process at all. I have been able to navigate to the folder containing the keytool in the Java sdk. Although I keep getting the error openssl not recognised as an internal or external command. The problem is even if I can get this to work, what would I do and with what afterwards?Any help would be much appreciated.Here is what you need to do -Download openSSl from \nExtract it. create a folder- OpenSSL in C:/ and copy the extracted code here.detect debug.keystore file path. If u didn't find, then do a search in C:/ and use the Path in the command in next step.detect your keytool.exe path and go to that dir/ in command prompt and run this command in 1 line-it will ask for password, put android\nthat's all. u will get a key-hashOpen Terminal : You will find  in the \".android\" folder. Copy it and paste onto the desktop and run the above command. Make sure that in both cases it asks for a password. If it does not ask for a password, it means that something is wrong in the command. Password for  is  and for release you have to enter password that you .OpenSSL: You have to install that if it doesn't come preinstalled with your operating system . How to install that depends on your OS (for Windows check the  provided by coder_For_Life22). The easiest way without fiddling around is copying that openssl.exe binary to your keytool path if you are on Windows. If you don't want to do that, you have to add it to your  environment variable. Then execute the command provided in the docs.Note that the argument after  points to your debug keystore. This location also depends on your operating system. Should be in one of the following locations:If you did everything right, you should be prompted for a password. That is  for the debug certificate. If the password is correct the console prints a hash (somewhat random chars and numbers). Take that and copy it into the  field inside the preferences of your app on facebook. To get there, go to , select your app, go to  and scroll down. After that, wait a few minutes until the changes take effect.Please try this:to generate your key hash on your local computer, run Java's keytool utility (which should be on your console's path) against the Android debug keystore. This is, by default, in your home .android directory). On OS X, run:On Windows, use:-hope this will help youRef - developer facebook siteThat's how I obtained my: So when you re trying to enter without the key, an exception will occur. Facebook put the RIGHT key into this exception. All you need to do is to copy it. :My computer -> properties -> Advanced configurations -> Advanced -> System variables -> under system variables find path, and  add this to its endings:\n;yourFullOpenSSLDir\\binNow open a command line on your jdk\\bin folder C:\\Program Files\\Java\\jdk1.8.0_40\\bin (on windows hold shift and right click -> open command line here) and use:And copy the 28 lenght number it generates after giving the password.For easy vedio tutorial link for the generate KeyHash Download openssl from I was having the same exact problem, I wasnt being asked for a password, and it seems that I had the wrong path for the keystore file.In fact, if the keytool doesn't find the keystore you have set, it will create one and give you the wrong key since it isn't using the correct one.The general rule is that if you aren't being asked for a password then you have the wrong key being generated."},
{"body": "I intend to develop a small (Java) application for managing my finances. I believe I need to use an embedded database, but I have no experience regarding this issue. I tried to look at , but I can't decide which one would be more suitable for me. , ,  and  seem to be good candidates, but I still don't see how they compare to each other. I appreciate your help comparing them and helping me decide which one to use.I intend to use Hibernate for my application (unless you would recommend using DBMS-provided API), but I also want to have the ability to edit the database easily using a SQL browsing tool (modifying schema and changing data).Thank you.EitherorWhich one you use is up to you, depending how much performance and how much stability you need.The developer of H2 has put up a nice performance evaluation:\nI use  for pretty much all of my embedded database needs. You can also use Sun's Java DB that is based on Derby but the latest version of Derby is much newer. It supports a lot of options that commercial, native databases support but is much smaller and easier to embed. I've had some database tables with more than a million records with no issues.I used to use HSQLDB and Hypersonic about 3 years ago. It has some major performance issues at the time and I switch to Derby from it because of those issues. Derby has been solid even when it was in incubator at Apache.I needed to use Java embedded database in one of my projects and I did lot of research understanding pros and cons of each database. I wrote a blog listing pros and cons of popular embedded java databases (H2, HSQLDB, Derby, ObjectDB, Neo4j, OrientDB), you can have a look at it. I chose H2 as I thought it best suited my requirements.\nLink for the blog: \nHope it helps!I'd go with H2, the performance is meant to much better than Derby. Read  for more info. is a good candidate (the fact that it is used in OpenOffice may convinced some of you), but for such a small personnal application, why not using an object database (instead of a classic relationnal database) ?I used  in one of my projects, and I'm very satisfied with it. Being object-oriented, you don't need the whole Hibernate layer, and can directly insert/update/delete/query objects ! Moreover, you don't need to worry about the schema, you directly work with the objects and DB4O does the rest !I agree that it may take some time to get used to this new type of database, but check the  to see how easy it makes working with the DB !EDIT: As said in the comments, DB4O handles automatically the newer versions of the classes. Moreover, a tool for browsing and updating the database outside of the application is available here :  (Sun's distribution of Apache Derby) now ships  JDK 6!  I've been wanted to do something like Jason Cohen and have been thinking this looks like the easiest way being in the JDK distro (which of last week is now a requirement for my app).  Or maybe I am just lazy that way.We use HSQLDB in production as a \"no-configuration\" option for our application.  It allows people to trial without the hassle of setting up a real database.However we do  support it for normal use.  The reasons are several:For at least (2) and (3), there are ways around it but it's difficult; it's much easier to e.g. install MySQL. is: I haven't had a chance to try it yet - but it looks very promising.  Note this is not an SQL database - your object graph is persisted for you - so it might not be appropriate for your existing app.Good comparison tool can be found here: Notice also the Head to Head DBMS/JPA ComparisonsI am a big fan of .Performance has become much better since the early releases. The licensing model isnt too bad, either. I particularly like the options available for querying your objects. Query by example is very powerful and easy to get used to.What criteria will you use to evaluate these ? If you don't know yet, then you don't need to decide right now. Try to make your application as database-implementation-agnostic as you can - providing the appropriate wrappers, data access objects etc., and make this decision when you have all the facts to hand and you have to decide.If you're using relational databases and SQL then the above shouldn't be too hard (using JDBC etc). Make sure you have plenty of surrounding tests so that when you want to switch between databases, you can determine that your application's functionality remains the same.I ran into the same issue some time ago. I didn't know which database to go for, so my first solution used Derby (or HSQLDB?), and I was later able to switch to HSQLDB (or Derby ? Can't remember which solution worked) once I'd determined where I had issues (relating to performance) and which solution would really work for me.HSQLDB may cause problems for large applications, its not quite that stable. The best I've heard (not first hand experience however) is berkleyDB. But unless you opensource it, it will cost you an arm and a leg to use due to licensing...see this  for details. ps. berkleyDB is not a relational database in case you didnt know.I have used Derby and i really hate it's data type conversion functions, especially date/time functions. (Number Type)<--> Varchar conversion it's a pain.So that if you plan use data type conversions in your DB statements consider the use of othe embedded DB, i learn it too late.Most things have been said already, but I can just add that I've used HSQL, Derby and Berkely DB in a few of my pet projects and they all worked just fine. So I don't think it really matters much to be honest. One thing worth mentioning is that HSQL saves itself as a text file with SQL statements which is quite good. Makes it really easy for when you are developing to do tests and setup data quickly. Can also do quick edits if needed. Guess you could easily transfer all that to any database if you ever need to change as well :)If I am correct H2 is from the same guys who wrote HSQLDB. Its a lot better if you trust the benchmarks on their site. Also, there is some notion that sun community jumped too quickly into Derby.I personally favor HSQLDB, but mostly because it was the first I tried.H2 is said to be faster and provides a nicer GUI frontend (which is generic and works with any JDBC driver, by the way).At least HSQLDB, H2 and Derby provide server modes which is great for development, because you can access the DB with your application and some tool at the same time (which embedded mode usually doesn't allow).I realize you mentioned SQL browsing, but everything else in your question makes me want to suggest you also consider , which is .I guess I'm a little late (a lot late;-)) to this post, but I'd like to add Perst, an open source, object-oriented embedded database for Java &.NET. for your consideration. Perst is an open source / dual license embedded database for Java. The distribution is compatible with Google's Android platform, and also includes Perst Lite for Java ME. We've even built an Android benchmark and produced a whitepaper on the subject...you can take a look here: All the best,\nChris"},
{"body": "Since the method  is deprecated, which method are we supposed to use now? The following code:Gives the following warnings:You're using  instead of .If you are using org.junit.Assert.assertEquals(float expected,float actual) but still encounter this deprecate warning, it is because currently junit prefer a third parameter rather than just two float variables input.The third parameter is delta:\npublic static void assertEquals(double expected,\n                                double actual,\n                                double delta)\nfor more information, please refer this problem: "},
{"body": "I'm trying to use javac with the windows command prompt, but its not working.After adding the directory \"C:\\Program Files\\Java\\jdk1.6.0_16\\bin\\\" to the end of the environment path variable, the java command works fine, but using javac gives me the error:Any ideas? Thanks.If you added it in the control panel while your command prompt was open, that won't affect your current command prompt. You'll need to exit and re-open or simply do:By way of checking, execute:from your command prompt and let us know what it is.Otherwise, make sure there  a javac in that directory by trying:from the command prompt. You can also tell  executable (if any) is being used with the command:This is a neat trick similar to the  and/or  commands in some UNIX-type operating systems.Windows OS searches the current directory and the directories listed in the PATH environment variable for executable programs. JDK's programs (such as Java compiler javac.exe and Java runtime java.exe) reside in directory \"\\bin\" (where  denotes the JDK installed directory, e.g., C:\\Program Files\\Java\\jdk1.8.0_xx). You need to include the \"\\bin\" directory in the PATH.To edit the PATH environment variable in Windows XP/Vista/7/8:(( now read the following 3 times before proceeding,  ))In \"Variable value\" field, INSERT \"c:\\Program Files\\Java\\jdk1.8.0_xx\\bin\" (Replace xx with the upgrade number and VERIFY that this is your JDK's binary directory!!!) IN FRONT of all the existing directories, followed by a semi-colon (;) which separates the JDK's binary directory from the rest of the existing directories.\nDO NOT DELETE any existing entries; otherwise, some existing applications may not run.After long Google, I came to know that javac.exe must be inside (C:\\Program Files\\Java\\jdk(version number)\\bin) not inside  (C:\\Program Files (x86)\\Java\\jre7\\bin)   in order to use  compiler javacjavac will not work if you are pointing bin inside jreIn order to use javac in cmd , JDK must be installed in your system...  this is wrong   this is correctMake sure that \"javac.exe\" is inside your Dont confuse with JRE and JDK  both are totally different if you dont have JDK pls download from this link reference thread for JDK VS JRE  I know this may not be your specific error, but I once had a leading space in my path and java would work but javac would not. For what it's worth, I offer the sage advice: \"Examine your Path closely\".Try the solutions here: These are much more robust to change -- like when you upgrade the JDK or JRE, since there is no hard coded path.The quick solution (if you don't want to read the blog) isYou can then add these lines to a startup/login script.I just had to do this to get this to work on windows 7 64.Open up a command prompt (cmd.exe) and type:Make sure you reopen all running command prompt Windows to get the environment variable updated as well.Okay this can not be the case always but many of us have done this mistake in the past and few out of those are still not aware of it, which is, every time you append a path (any path) of any environment variable, you're likely to hit the space bar right after the \"semicolon\" (as you normally would, after the \"period\" while typing in an editor).  This will create a leading space in the path e.g \" C:\\Program Files\\Java\\jdk1.6.0\\bin\" and therefore \"javac.exe\" won't be found by the system.Change the folder \"jdk1.7.0_45\" \"jdk1_7_0_60\" and update the path in Windows environment. Otherwise, the path ignores the dot at the front which stands for hidden file and so the folder is not displayed in PATH strings.I faced the exact same problem that java would work but javac would not on a cmd prompt in Windows 8.The problem occured because I forgot to remove  at the end of the path name, i.e., it was like this:where it was suppose to be like this:The path will only be set for the administrator account. Therefore it is important to launch command prompt as administrator, if you are not already.Ensure you don't allow spaces (white space) in between paths in the Path variable. My problem was I had white space in and I believe Windows treated it as a NULL and didn't read my path in for Java.I was having the same problem posted in this title. Java would work, but  would not in the Windows command prompt ().For me, it was simply that I had placed a space when adding  to the end of my  environment variable.\nRemove the space between the  and the next file path.I appreciate this is an old question now but my solution wasn't an answer on here so posting it in case anyone else tries all the rest.In my case, a previous install of the Java JRE (in ProgramData/Oracle/Java) had a path variable at the top of my list of path variables. The contents of that \"Oracle\" path had a java.exe but not a javac.exe.\nI added my full JDK path to the top of the list of path variables, ahead of the \"Oracle\" one, and it then picked up javac.exe as well as java.\";C:\\Program Files\\Java\\jdk1.6.0\\bin\" sometime you may forget to put semicolon on last existing path.When i tried to make the .java to .class the command Javac didnt work. I got it working by going to C:\\Program Files (x86)\\Java\\jdk1.7.0_04\\bin and when i was on that directory I typed Javac.exe C\\Test\\test.java and it made the class with that tactic. Try that out.Give it as \"C:\\Program Files\\Java\\jdk1.6.0_16\\bin\". Remove the backslash it will work"},
{"body": "I am looking into Spring Data JPA. Consider the below example where I will get all the crud and finder functionality working by default and if I want to customize a finder then that can be also done easily in the interface itself.I would like to know how can I add a complete custom method with its implementation for the above AccountRepository? Since its an Interface I cannot implement the method there.You need to create a separate interface for your custom methods:and provide an implementation class for that interface:In addition to axtavt's , don't forget you can inject Entity Manager in your custom implementation if you need it to build your queries:Im using the following code in order to access generated find methods from my custom implementation. Getting the implementation through the bean factory prevents circular bean creation problems.If you want to be able to do more sophisticated operations you might need access to Spring Data's internals, in which case the following works (as my interim solution to ):This is limited in usage, but for simple custom methods you can use  interface methods like:EDIT: In  tutorial it is written:So it is even possible to just declare method like:and if object  is a property of Customer then Spring will automatically define method for you.Considering your code snippet, please note that you can only pass Native objects to the  findBy### method, lets say you want to load a list of accounts that belongs  certain costumers, one solution is to do this, Make sure the name of the table  to be queried is thesame as the Entity class. that is all you need spring-data-jpa does the rest of the magic for you, just inject  this bean in your service class and use it.\nFor further implementations please take a look at  There is another issue to be considered here. Some people expect that adding custom method to your repository will automatically expose them as REST services under '/search' link. This is unfortunately not the case. Spring doesn't support that currently. This is 'by design' feature, spring data rest explicitly checks if method is a custom method and doesn't expose it as a REST search link:This is a qoute of Oliver Gierke:For more details see this issue: "},
{"body": "How to make a  non-editable? I don't want my users to be able to edit the values in cells by double-clicking them.Any help would be greatly appreciated.Thanks.You can use a .Define a class like this:actually  is  by default so you may ommit it. (see: )Then use  method of your .You can override the method isCellEditable and implement as you want\nfor example:orIf your  is disappearing when you use this it is most likely because you need to use the  constructor instead.just add it works fine for me.If you are creating the TableModel automatically from a set of values (with \"new JTable(Vector, Vector)\"), perhaps it is easier to remove editors from columns:Without editors, data will be not editable.create new DefaultCellEditor class :and use setCellEditor : it is very simple and works fine."},
{"body": "I'm generating a CSV file (delimited by commas rather than tabs). My users will most likely open the CSV file in Excel by double clicking it. My data may contain commas and speech marks, so I'm escaping those as follows.As far as I know that's always been the way to do it. Here's my boggle: when I open this file in Excel 2010 my escaping is not respected. Speech marks appear on the sheet, and the comma causes new columns.We eventually found the answer to this.Excel will only respect the escaping of commas and speech marks if the column value is NOT preceded by a space. So generating the file without spaces like this...... fixed the problem. Hope this helps someone!Below are the rules if you believe it's random. A utility function can be created on the basis of these rules.According to Yashu's instructions, I wrote the following function (it's PL/SQL code, but it should be easily adaptable to any other language).Even after double quotes, I had this problem for a few days.Replaced Pipe Delimiter with Comma, then things worked fine."},
{"body": "I need a small code snippet which unzips a few files from a given .zip file and gives the separate files according to the format they were in the zipped file. Please post your knowledge and help me out. Had peno's version optimised a bit. The increase in performance is perceptible.Based on Vasily Sochinsky's answer a bit tweaked & with a small fix:Notable differencesSoshould do the equivalent of the originalThis is my unzip method, which I use:Android has build-in Java API. Check out  package.The class  is what you should look into. Read ZipEntry from the ZipInputStream and dump it into filesystem/folder. Check  file.While the answers that are already here work well, I found that they were slightly slower than I had hoped for. Instead I used , which I think is the best solution because of its speed. It also allowed for different options for the amount of compression, which I found useful.->Helper Class(Unzipper.java)->xml layout(activity_main.xml):->permission in Menifest file:According to @zapl answer,Unzip with progress report:UPDATE 2016 \n  use the following classHow to usePermissionsHere is a ZipFileIterator (like a java Iterator, but for zip files):Minimal example I used to unzip a specific file from my zipfile into my applications cache folder. I then read the manifest file using a different method.Use this library.add this jar file in lib folder of app. "},
{"body": "I have just made a clean installation of , and I have downloaded  , but if I execute it, gives me this message:Asking me to install ; I have already installed , and if I press  in that dialog, download and install it, and open Eclipse again, the dialog appears again. How I can fix it?This is in part due to Oracle's missing definitions of the JRE8 VM capabilities.In case you don't want to install JRE6 at all and simply use JRE8 without symlinking it to the JRE6 either you can do the following:Copy the Info.plist located at the path named below to e.g. ~/Downloads/:and then replacewith the following:Afterwards copy the file back to its original location (you need administrator rights). For this change to take effect you need to log out of your account (and back in) or restart your computer. The dialog for Java 6 should shouldn't appear anymore and Eclipse should launch just fine using JRE8 (or JRE7). The same holds true for any other application that initially asks for Java, e.g. Adobe's Creative Suite.On a related note it appears that this plist change sticks even after updates done through the Java Preference Panel in the System Preferences.If it still doesn't work. You might need to add some folders and a symlink ():I had this problem after a Mavericks install.  I was able to solve it by installing Java from the Apple download at I hope this helps.To be able to run Eclipse with Java 7 (Oracle), I launch Eclipse using this file: eclipse/Eclipse.app/Contents/MacOS/eclipse. \"eclipse\" folder contains alias for this file by default. So all that you need to do is to double-click the alias named \"eclipse\".Also Oracle warns that Oracle's Java version 7u25 and below have been disabled by Apple on OS X (see ). I had upgraded to the latest JDK version before I found out the way of launching Eclipse with Java 7. So I don't know if the upgrade is necessary or not. You need to download and install the JAVA for MAC manually.  That is what worked for me.Download here: I happened to get it running without a procedure like the suggestions above. I erased the eclipse folder and then copied it back from the trashcan. Please verify if it works for you.On MAC OS X, after installing JRE 7 from Oracle using the .dmg download, on opening Eclipse, it still pointed back to my old JRE 6. After numerous google searches for the problem, and getting here, in desperation I clicked on \"Search\" in Eclipse --> Preferences --> Installed JREs and voila - it picked up JRE 7.  In my case, with  (installed from the OS X installer, downloaded from eclipse.org) and :"},
{"body": "I have a ArrayList made up of different elements imported from a db, made up of strings, numbers, doubles and ints. Is there a way to use a reflection type technique to find out what each type of data each element holds?  FYI: The reason that there is so many types of data is that this is a piece of java code being written to be implemented with different DB's.In C#:Fixed with recommendation from In Java:You can use the  method, or you can use instanceof. For exampleorNote that instanceof will match subclasses. For instance, of  is a subclass of , then the following will be true:However, the following will be false:You almost never want you use something like:because you aren't accounting for possible subclasses.  You really want to use Class#isAssignableFrom:In Java just use the instanceof operator. This will also take care of subclasses.Just call  on each  in a loop.Unfortunately, Java doesn't have . :)Instanceof works if you don't depend on specific classes, but also keep in mind that you can have nulls in the list, so obj.getClass() will fail, but instanceof always returns false on null.Since Java 8instead of using  you can use , because it returns a simple class name without a package name included.for instance,gives,You say \"this is a piece of java code being written\", from which I infer that there is still a chance that you could design it a different way.  Having an ArrayList is like having a collection of stuff.  Rather than force the instanceof or getClass every time you take an object from the list, why not design the system so that you get the type of the object when you retrieve it from the DB, and store it into a collection of the appropriate type of object?Or, you could use one of the many data access libraries that exist to do this for you.If you expect the data to be numeric in some form, and all you are interested in doing is converting the result to a numeric value, I would suggest:"},
{"body": "I am using persisting objects using JPA. The Main object has an owning One-Many relationship with another object. The other object is stored in a HashMap.  What sort of synchronisation would fix this problem?  It seems to happen at completely random times and is very unpredictable.  Here is the exception I get:This is not a synchronization problem.  This will occur if the underlying collection that is being iterated over is modified by anything other than the Iterator itself.This will throw a ConcurrentModificationException when the it.hasNext() is called the second time.The correct approach would be Assuming this iterator supports the remove() operation.Try using a ConcurrentHashMap instead of a plain HashMapIt sounds less like a Java synchronization issue and more like a database locking problem.I don't know if adding a version to all your persistent classes will sort it out, but that's one way that Hibernate can provide exclusive access to rows in a table.  Could be that isolation level needs to be higher.  If you allow \"dirty reads\", maybe you need to bump up to serializable.Try either CopyOnWriteArrayList or CopyOnWriteArraySet depending on what you are trying to do."},
{"body": "I am trying to convert a long value (The number of milliseconds elapsed from 1/1/1970) to a time of format \nThe long value I use as timestamp, I get from the field  of logging event from log4j.\nHow do I do the conversion?\nFor example to get the minutes I tried the following and all fail:\n   and\n \nbut I get garbage:\nI get   How can I convert this?  ThanksTry this:List of other I'll show you three ways to (a) get the minute field from a long value, and (b) print it using the Date format you want. One uses , another uses , and the last uses the java.time framework built into Java 8 and later. The java.time framework supplants the old bundled date-time classes, and is inspired by Joda-Time, defined by JSR 310, and extended by the ThreeTen-Extra project.The java.time framework is the way to go when using Java 8 and later. Otherwise, such as Android, use Joda-Time. The java.util.Date/.Calendar classes are notoriously troublesome and should be avoided.It is possible to use apache commons (commons-lang3) and its DurationFormatUtils class.For example:Hope it can help ...Doingwill give you hours, not minutes. Try:and you will end up with the same answer asTry this:"},
{"body": "My Java test worked well from Eclipse. But now, when I relaunch test from the run menu, I get the following message: In the  file I have all  files, and at the end have: How can I resolve this error and get tests running again?this just happened to me. Rebuilding or restarting Eclipse didn't help.I solved it by renaming one of the test methods to start with \"test...\" (JUnit3 style) and then  tests are found. I renamed it back to what it was previously, and it still works.When we get these errors it seems like Eclipse is just confused.  Restart Eclipse, refresh the project, clean it, let Eclipse rebuild it, and try again.  Most times that works like a charm.In context menu of your 'test' directory choose 'Build path' -> 'Use as a source folder'.\nEclipse should see your unitTests.java files as a source files.\nWarning 'No JUnit tests found' occures because there is no unitTests.class files in your 'build' directoryCheck if your test class extends \"TestCase\". if so, remove that clause. Your class does not need to extend from \"TestCase\" class. It's most of the cases I've met. Following TestCase should be fine.I was facing the same problem and I debugged it to bad examples on the web and internals of junit. Basically don't make your class extend TestCase as some examples show for Junit 4.x. Use some naming convention  or if you want to have an annotation you can use @RunWith(JUnit4.class).If you need access to assert methods extend Assert or use static imports.If your class extends TestCase then even if you use Junit 4 Runner it will be run as 3. This is because in the initialization code there is detection:See JUnit3Builder and the lines:This returns true and the test for junit4 compatibility won't be tried.Try Adding @Test above the method for the test like thisI have found out the answer:I got this error when I executed the test standalone from eclipse (right click on the method and choose to run as junit test), When I executed the complete class as junit test the test executed correctly with the parameters.No testsuits in JUnit4. Use annotations instead or use old JUnit3 name conventions.Example:When I face this problem I just edit the file and save it... works like charmMy problem was that declaration  has disappeared (or wasn't added?). After adding it, I had to remove another  declaration (Eclipse'll hint you which one) and everything began to work again.Very late but what solved the problem for me was that my test method names all started with captial letters: \"public void Test\". Making the t lower case worked.I tried the solution from Germ\u00e1n.\nIt worked for all the method from my class but i have a lot of classes in my project.So I tried removing from build path and then re-adding it.\nIt worked perfectly.Hope it helps.This happened to me as well. I tried restarting Eclipse and also prefixed my test-methods with tests. Neither worked.The following step worked:\nChange all your test methods present in @BeforeClass and @AfterClass to static methods.i.e. if you have your test method in the below format:then change it to:This worked for me.Yet another possible solution I'll throw into the ring: I wasn't able to run the test class either from the editor window, nor the Package Explorer, but right-clicking on the class name in the Outline view and selecting Run As JUnit Test did work... Go figure!May be your JUnit launch configuration was for a individual test class, and you somehow changed that config to \"run all tests in a source folder, package or project\"But that could trigger the \"No tests found with test runner 'JUnit 4'\" error message.Or you did a modification in your test class, removing the  annotation.\nSee this .I also faced the same issue while running JUnit test. I resolved this by putting the annotation @Test just above the main test function.What fixed my case was similar to @JamesG's answer:  I restarted Eclipse, rebuilt the project, and refreshed it; BUT before I did any of that, I 1st closed the project (right-click project in package explorer -> Close Project) and then re-opened it.  Then it worked.A workaround solution I found before finding that ultimate solution I just described:  Copy the test class, and run the test class as JUnit.Check if the folder your tests are in is a source folder. If not - right click and use as source folder.Close and open the project worked for me.Six years later ... and there are still problems with Eclipse and occasionally not finding JUnits.In my Eclipse Mars 2 I discovered that it won't recognise test classes pulled in from git if there are more than 9 or 10  annotations in the file. I need to comment out any extra tests, run the test class, then uncomment them and re-run the class. Go figure...Is your Eclipse project maven based? If so, you may need to update the m2eclipse version. From here: This happened to me too. I found that in Eclipse I didn't make a new Java Class file and so that's why it wasn't compiling. Try copying your code into a java class file if it's not already there and then compile.I found out that Eclipse seems to only perform JUnit 3 style tests if your test-class extends from . If you remove the inheritance, the annotations worked for me.Beware that you need to statically import all the required  methods like .I'm also running Eclipse with Maven (m2e 1.4). The tests were running with Maven, but not with Eclipse... even after several application of .My solution was to add some lines in the .classpath generated by m2e. The lines are now sticking.I have this problem from time to time. The thing that resolves the issue most for me is to run the JUnit test from Run configurations... ensuring that JUnit 4 is set as the test runner.Generally, I see this issue when attempting to Run As... Junit test from the context menu on the Package Explorer. If you right click the code for the test you are trying to run and instead of selecting Run As... Junit Test you select Run configurations... ensure the Project, Test Class and test runner are set correctly, clicking apply, then run works all the time for me.I started to work with Selenium and Eclipse in my job and I was doing my first automated test and I deleted from the code @Before, @Test, and @After notes and I was having this issue \"No tests found with test runner junit4\".My solution it was simply to add again the @Before, @Test and @After notes and with that my script worked. Is important to not delete this from the code.This is a simple test that uses Google to search something:Using ScalaIDE (3.0.4-2.11-20140723-2253-Typesafe) I was having a similar problem with the  context menu.I tried editting the class(but not for a compile failure), cleaning, closing the project, closing Eclipse.  None of those worked to restore the context menu for classes that had previously worked well.  The test classes don't use the  annotation and instead use the  annotation at the top of the class using ScalaTest code.When I tried choosing  from the Run Configuration launch editor directly, I received the dialog from the question.  Footix29's answer was the key for me.I noticed that even though I had cleaned my project a few times, my classes in the /bin directory hadn't actually been rebuilt in a while.Here's how I got back the context menu, and was able to once again run s:I suspect that a class edit in general is able to clean some saved state of Eclipse and get it going again.  In my case all of the previously working classes I tried had failed so the  clean step was just the hammer I needed.  However, other tricks that affect Eclipse's concept of the class path/build state should also work.Further, I think that this behaviour was triggered in part by attempting to refactor a Scala class by renaming it( which the Scala Eclipse IDE sucks at ), where all the cleanup after the initial file change is manual.  There were no build errors, but there were also no warnings that I was expecting meaning something was definitely stuck in Eclipse's build state info.There is another chance, you might have changed Junit Test from lower version(e.g. Junit 3) to Junit 4 .\nIs so follow below steps:-Right Click the Project -> Build Dependencies -> remove the ones which have been excluded from the build path -> Click OKRight Click the Project -> Maven -> Update Project.You should be good to go..You can fix this issue by do as following:This issue happened because of junit cannot recognize your source code :D"},
{"body": "I have a Java bean. Now, I want to be sure that the field should be unique.\nI am using following code:But am getting some error:Whats the proper way to use unique constraints? I am using play framework.To ensure a field value is unique you can writeThe @UniqueConstraint annotation is for annotating multiple unique keys at the table level, which is why you get an error when applying it to a field.References (JPA TopLink):You can use at class level with following syntaxI'm currently using play framework too with hibernate and JPA 2.0 annotation and this model works without problems        Hope it helped. In Kotlin the syntax for declaring the arrays in annotations uses  instead of Unique constraints used only for creating composite key ,which will be unique.It will represent the table as primary key combined as unique. you can use  @UniqueConstraint   on class level, for combined primary key in a table. for example:public class ProductAttribute{}"},
{"body": "I want to change the automatic author that appears when I create a file in AndroidStudio.The author takes 'a556520' but I want that appears my name, and not the number of employee. Is that possible?\nI didnt found in the settings.You can overwrite the  variable in the template file with the  function. Go to Settings -> File and Code Templates -> Includes -> File Header prepend the  function call, for example:The above answers are correct. But you can go even further and define your own variables - such as User, Company, Email etc.:1)Open Android Studio  dialog.2)In the search box, write \"File and Code Templates\".3)Select the left menu item \"File and Code Templates\".4)From the middle tabular navigation section, select .5)Select  item that applies to the Java files.6)You will find an editor section that allow you to edit it for the required pattern. Use the description section below to understand the different parameters that can be used.Note: For the  attribute, you can simply write it directly without using attributes. Also you can add your company name or project name in the same way also such as:Press ++ then go to . Here you can set up what you want. E.g. replace  to your name.You can change template for file header by going to  Preferences -> Editor -> File and Code Templates. Then change  in File Header under Includes tab. However this is hardcoding solution it would be better to change actual value of  variable.Actually the correct way to change the username is to change the name\nof the current user logged in into Windows. (if you're using windows)Android Studio uses the name saved in %USERNAME% variable.\nThis is the name you get if you type  into a command console\nor batch file. And it is the name that is stored under C(orWhatEver):\\User.To change the name you can  just change the name of the profile \nyou are logged in. \nYou need to create a new user and give it the correct name.\nThis way, even if you reinstall AndroidStudio some day, you will end with\nthe correct  again.The easier way surely is to just hard code your name into the template.\nBut that is just treating the symptoms and you should use the way to fix the root cause."},
{"body": "During my work with databases I noticed that I write query strings and in this strings I have to put several restrictions in the where-clause from a list/array/collection. Should look like this:You can simplify this by reducing this to the question that you have collection of strings and want to create a comma-separated list of this strings in just one string.My approach I have used so far is something like that:But this is as you can see very ugly. You cannot see what happens there on the first look, especially when the constructed strings (like every SQL query) is getting complicated.What is your (more) elegant way?Since strings are immutable, you may want to use the StringBuilder class if you're going to alter the String in the code.The StringBuilder class can be seen as a mutable String object which allocates more memory when its content is altered.The original suggestion in the question can be written even more clearly and efficiently, by taking care of the :Use the 's  method:I just looked at code that did this today.  This is a variation on AviewAnew's answer.The  ( <-- commons.lang 2.x, or ) we used is from .The way I write that loop is:Don't worry about the performance of sep. An assignment is  fast. Hotspot tends to peel off the first iteration of a loop anyway (as it often has to deal with oddities such as null and mono/bimorphic inlining checks).If you use it lots (more than once), put it in a shared method.There is another question on stackoverflow dealing with how to insert a list of ids into an SQL statement.Since Java 8, you can use:I found the iterator idiom elegant, because it has a test for more elements (ommited null/empty test for brevity):There's a lot of manual solutions to this, but I wanted to reiterate and update Julie's answer above. Use .It handles var args, iterables and arrays and properly handles separators of more than one char (unlike gimmel's answer). It will also handle null values in your list if you need it to.Here's an incredibly generic version that I've built from a combination of the previous suggestions:available in the Java8 api.alternative to (without the need to add a google guava dependency):I think it's not a good idea contruct the sql concatenating the where clause values like you are doing :Where valueX comes from a list of Strings. First, if you are comparing Strings they must be quoted, an this it isn't trivial if the Strings could have a quote inside. Second, if the values comes from the user,or other system, then a SQL injection atack is posible.It's a lot more verbose but what you should do is create a String like this:and then bind the variables with Statement.setString (nParameter,parameterValue)You could tryThis will be the shortest solution so far, except of using Guava or Apache CommonsGood with 0,1 and n element list. But you'll need to check for null list.\nI use this in GWT, so I'm good without StringBuilder there. And for short lists with just couple of elements its ok too elsewhere ;)In case someone stumbled over this in more recent times, I have added a simple variation using Java 8 . It also includes some of the already mentioned solutions by others:Just another method to deal with this problem. Not the most short, but it is efficient and gets the job done.There are some third-party Java libraries that provide string join method, but you probably don't want to start using a library just for something simple like that. I would just create a helper method like this, which I think is a bit better than your version, It uses StringBuffer, which will be more efficient if you need to join many strings, and it works on a collection of any type.Another suggestion with using Collection.toString() is shorter, but that relies on Collection.toString() returning a string in a very specific format, which I would personally not want to rely on.If you use Spring, you can do:(package org.springframework.util)In Android you should use this:I'm not sure how \"sophisticated\" this is, but it's certainly a bit shorter. It will work with various different types of collection e.g. Set<Integer>, List<String>, etc.: modify this method so that it correctly handles a null/empty collection :)What makes the code ugly is the special-handling for the first case.  Most of the lines in this small snippet are devoted, not to doing the code's routine job, but to handling that special case.  And that's what alternatives like gimel's solve, by moving the special handling outside the loop.  There is one special case (well, you could see both start and end as special cases - but only one of them needs to be treated specially), so handling it inside the loop is unnecessarily complicated.Join 'methods' are available in Arrays and the classes that extend AbstractCollections but doesn't override toString() method (like virtually all collections in java.util)for instance:\nString s= java.util.Arrays.toString(collectionOfStrings.toArray());s = s.substing(1, s.length()-1);// [] are guaranteed to be therethat's quite weird way since it works only for numbers alike data sql wise.I've just checked-in a test for my library :it create a fluent wrapper around lists/arrays/strings/etc using : .:using ranges the previous list can be re-writed as The nice thing about the IN expression is that if you have repeated values, it does not change the result.  So, just duplicate the first item and process the entire list.  This assumes that there is at least one item in the list.  If there are no items, I'd suggest checking for that first and then not executing the SQL at all.This will do the trick, is obvious in what it is doing and does not rely on any external libraries:While I think your best bet is to use Joiner from Guava, if I were to code it by hand I find this approach more elegant that the 'first' flag or chopping the last comma off.  if you have an array you can do:You may be able to use LINQ (to SQL), and you may be able to make use of the Dynamic Query LINQ sample from MS. List token=new ArrayList(result);\nfinal StringBuilder builder = new StringBuilder();builder.toString();Another option, based on what I see here (with slight modifications).There is an easy way. You can get your result in a single line. To get complete idea check the code below"},
{"body": "I thought about this awhile ago and it recently resurfaced as my shop is doing its first real Java web app.As an intro, I see two main package naming strategies.  (To be clear, I'm not referring to the whole 'domain.company.project' part of this, I'm talking about the package convention beneath that.)  Anyway, the package naming conventions that I see are as follows:So I guess the question then would go out to you, how do you name your packages and why?  Please understand that I don't necessarily think that I've stumbled onto the golden goose or something here.  I'm pretty new to all this with mostly academic experience.  However, I can't spot the holes in my reasoning so I'm hoping you all can so that I can move on.For package design, I first divide by layer, then by some other functionality.There are some additional rules:So, for a web application for example, you could have the following layers in your application tier (from top to bottom):For the resulting package layout, these are some additional rules:Here is an example layout.The presentation layer is divided by view technology, and optionally by (groups of) applications.The application layer is divided into use cases.The service layer is divided into business domains, influenced by the domain logic in a backend tier.The integration layer is divided into 'technologies' and access objects.Advantages of separating packages like this is that it is easier to manage complexity, and it increases testability and reusability. While it seems like a lot of overhead, in my experience it actually comes very natural and everyone working on this structure (or similar) picks it up in a matter of days.Why do I think the vertical approach is not so good?In the layered model, several different high-level modules can use the same lower-level module. For example: you can build multiple views for the same application, multiple applications can use the same service, multiple services can use the same gateway. The trick here is that when moving through the layers, the level of functionality changes. Modules in more specific layers don't map 1-1 on modules from the more general layer, because the levels of functionality they express don't map 1-1.When you use the vertical approach for package design, i.e. you divide by functionality first, then you force all building blocks with different  of functionality into the same 'functionality jacket'. You might design your general modules for the more specific one. But this violates the important principle that the more general layer should not know about more specific layers. The service layer for example shouldn't be modeled after concepts from the application layer.I find myself sticking with Uncle Bob's .  In short, classes which are to be reused together and changed together (for the same reason, e.g. a dependency change or a framework change) should be put in the same package.  IMO, the functional breakdown would have better chance of achieving these goals than the vertical/business-specific break-down in most applications.  For example, a horizontal slice of domain objects can be reused by different kinds of front-ends or even applications and a horizontal slice of the web front-end is likely to change together when the underlying web framework needs to be changed.  On the other hand, it's easy to imagine the ripple effect of these changes across many packages if classes across different functional areas are grouped in those packages.  Obviously, not all kinds of software are the same and the vertical breakdown may make sense (in terms of achieving the goals of reusability and closeability-to-change) in certain projects.  There are usually both levels of division present. From the top, there are deployment units. These are named 'logically' (in your terms, think Eclipse features). Inside deployment unit, you have functional division of packages (think Eclipse plugins).For example, feature is , and it consists of ,  and  plugins. Inside plugins, I have very little division to other packages, although that's not unusual too. Btw, there is great talk by Juergen Hoeller about code organization at InfoQ: . Juergen is one of architects of Spring, and knows a lot about this stuff.Most java projects I've worked on slice the java packages functionally first, then logically.Usually parts are sufficiently large that they're broken up into separate build artifacts, where you might put core functionality into one jar, apis into another, web frontend stuff into a warfile, etc. I personally prefer grouping classes logically then within that include a subpackage for each functional participation. Packages are after all about grouping things together - the idea being related classes live close to each other. If they live in the same package they can take advantage of package private to limit visibility. The problem is lumping all your view and persitance stuff into one package can lead to a lot of classes being mixed up into a single package. The next sensible thing to do is thus create view, persistance, util sub packages and refactor classes accordingly. Underfortunately protected and package private scoping does not support the concept of the current package and sub package as this would aide in enforcing such visibility rules.I see now value in separation via functionality becase what value is there to group all the view related stuff. Things in this naming strategy become disconnected with some classes in the view whilst others are in persistance and so on.For purposes of illustration lets name two modules - ill use the name module as a concept that groups classes under a particular branch of a pacckage tree.A client using the Banana.store.BananaStore is only exposed to the functionality we wish to make available. The hibernate version is an implementation detail which they do not need to be aware nor should they see these classes as they add clutter to storage operations.The further up towards the root the broader the scope becomes and things belonging to one package start to exhibit more and more dependencies on things belonging to toher modules. If one were to examine for example the \"banana\" module most of the dependencies would be limited to within that module. In fact most helpers under \"banana\" would not be referenced at all outside this package scope. What value does one achieve by lumping things based on functionality. Most classes in such a case are independent of each other with little or no need to take advantage of  package private methods or classes. Refactoring them so into their own subpackages gains little but does help reduce the clutter.When developers are tasked to make changes that are a bit more than trivial it seems silly that potentially they have changes that include files from all areas of the package tree. With the logical structured approach their changes are more local within the same part of the package tree which just seems right.Both  (architectural) and  (feature) approaches to packaging have a place. Many example applications (those found in text books etc.) follow the functional approach of placing presentation, business services, data mapping, and other architectural layers into separate packages. In example applications, each package often has only a few or just one class. This initial approach is fine since a contrived example often serves to: 1) conceptually map out the architecture of the framework being presented, 2) is done so with a single logical purpose (e.g. add/remove/update/delete pets from a clinic).  The problem is that many readers take this as a standard that has no bounds.As a \"business\" application expands to include more and more features, following the  approach becomes a burden. Although I know where to look for types based on architecture layer (e.g. web controllers under a \"web\" or \"ui\" package, etc.), developing a single  feature begins to require jumping back and forth between many packages. This is cumbersome, at the very least, but its worse than that. Since logically related types are not packaged together, the API is overly publicized; the interaction between logically related types is forced to be 'public' so that types can import and interact with each other (the ability to minimize to default/package visibility is lost).If I am building a framework library, by all means my packages will follow a functional/architectural packaging approach. My API consumers might even appreciate that their import statements contain intuitive package named after the architecture.Conversely, when building a business application I will package by feature. I have no problem placing Widget, WidgetService, and WidgetController all in the same \"\" package and then takomg advantage of default visibility (and having fewer import statements as well as inter-package dependencies).There are, however, cross-over cases. If my WidgetService is used by many logical domains (features), I might create a \"\" package. There is also a good chance that I create classes with intention to be re-usable across features and end up with packages such as \"\" and \"\". I may even end up moving all these later \"common\" classes in a separate project and include them in my business application as a myorg-commons.jar dependency.It depends on the granularity of your logical processes?If they're standalone, you often have a new project for them in source control, rather than a new package.The project I'm on at the moment is erring towards logical splitting, there's a package for the jython aspect, a package for a rule engine, packages for foo, bar, binglewozzle, etc. I'm looking at having the XML specific parsers/writers for each module within that package, rather than having an XML package (which I have done previously), although there will still be a core XML package where shared logic goes. One reason for this however is that it may be extensible (plugins) and thus each plugin will need to also define its XML (or database, etc) code, so centralising this could introduce problems later on.In the end it seems to be how it seems most sensible for the particular project. I think it's easy to package along the lines of the typical project layered diagram however. You'll end up with a mix of logical and functional packaging.What's needed is tagged namespaces. An XML parser for some Jython functionality could be tagged both Jython and XML, rather than having to choose one or the other.Or maybe I'm wibbling.Packages are to be compiled and distributed as a unit. When considering what classes belong in a package, one of the key criteria is its dependencies. What other packages (including third-party libraries) does this class depend on. A well-organized system will cluster classes with similar dependencies in a package. This limits the impact of a change in one library, since only a few well-defined packages will depend on it.It sounds like your logical, vertical system might tend to \"smear\" dependencies across most packages. That is, if every feature is packaged as a vertical slice, every package will depend on every third party library that you use. Any change to a library is likely to ripple through your whole system.I would personally go for functional naming. The short reason: it avoids code duplication or dependency nightmare.Let me elaborate a bit. What happens when you are using an external jar file, with its own package tree? You are effectively importing the (compiled) code into your project, and with it a (functionally separated) package tree. Would it make sense to use the two naming conventions at the same time? No, unless that was hidden from you. And it is, if your project is small enough and has a single component. But if you have several logical units, you probably don't want to re-implement, let's say, the data file loading module. You want to share it between logical units, not have artificial dependencies between logically unrelated units, and not have to choose which unit you are going to put that particular shared tool into.I guess this is why functional naming is the most used in projects that reach, or are meant to reach, a certain size, and logical naming is used in class naming conventions to keep track of the specific role, if any of each class in a package.I will try to respond more precisely to each of your points on logical naming.I try to design package structures in such a way that if I were to draw a dependency graph, it would be easy to follow and use a consistent pattern, with as few circular references as possible.For me, this is much easier to maintain and visualize in a vertical naming system rather than horizontal. if component1.display has a reference to component2.dataaccess, that throws off more warning bells than if display.component1 has a reference to dataaccess. component2.Of course, components shared by both go in their own package.I totally follow and propose the logical (\"by-feature\") organization! A package should follow the concept of a \"module\" as closely as possible. The functional organization may spread a module over a project, resulting in less encapsulation, and prone to changes in implementation details.Let's take an Eclipse plugin for example: putting all the views or actions in one package would be a mess. Instead, each component of a feature should go to the feature's package, or if there are many, into subpackages (featureA.handlers, featureA.preferences etc.)Of course, the problem lies in the hierarchical package system (which among others Java has), which makes the handling of orthogonal concerns impossible or at least very difficult - although they occur everywhere!From a purely practical standpoint, java's visibility constructs allow classes in the same package to access methods and properties with  and  visibility, as well as the  ones. Using non-public methods from a completely different layer of the code would definitely be a big code smell. So I tend to put classes from the same layer into the same package.I don't often use these protected or default methods elsewhere - except possibly in the unit tests for the class - but when I do, it is  from a class at the same layerIt depends. In my line of work, we sometimes split packages by functions (data access, analytics) or by asset class (credit, equities, interest rates). Just select the structure which is most convenient for your team.It is an interesting experiment not to use packages at all (except for the root package.)The question that arises then, is, when and why it makes sense to introduce packages. Presumably, the answer will be different from what you would have answered at the beginning of the project.I presume that your question arises at all, because packages are like categories and it's sometimes hard to decide for one or the other. Sometimes tags would be more appreciate to communicate that a class is usable in many contexts.From my experience, re-usability creates more problems than solving. With the latest & cheap processors and memory, I would prefer duplication of code rather than tightly integrating in order to reuse."},
{"body": "In Java, I want to convert a double to an integer, I know if you do this:you get y=1. If you do this:You'll likely get 2. However, I am wondering: since double representations of integers sometimes look like 1.9999999998 or something, is there a possibility that casting a double created via Math.round() will still result in a truncated down number, rather than the rounded number we are looking for (i.e.: 1 instead of 2 in the code as represented) ?(and yes, I do mean it as such: Is there  value for x, where y will show a result that is a truncated rather than a rounded representation of x?)If so: Is there a better way to make a double into a rounded int without running the risk of truncation?Figured something: Math.round(x) returns a long, not a double. Hence: it is impossible for Math.round() to return a number looking like 3.9999998. Therefore, int(Math.round()) will never need to truncate anything and will always work.No,  will always round your double to the correct value, and then, it will be cast to an  which will truncate any decimal places.  But after rounding, there will not be any fractional parts remaining.Here are the docs from :For the datatype  to , you can use the following:"},
{"body": "I understand the difference between runtime and compile-time and how to differentiate between the two, but I just don't see the need to make a distinction between compile-time and runtime .What I'm choking on is this: how can a program  on something at runtime that it depended on during compilation? If my Java app uses log4j, then it needs the log4j.jar file in order to compile (my code integrating with and invoking member methods from inside log4j) as well as runtime (my code has absolutely no control over what happens once code inside log4j.jar is ran).I'm reading up on dependency resolution tools such as Ivy and Maven, and these tools clearly make the distinction between these two types of dependencies. I just don't understand the need for it.Can anyone give a simple, \"King's English\"-type explanation, preferably with an actual example that even a poor sap like me could understand?A compile-time dependency is generally required at runtime. In maven, a  scoped dependency will be added to the classpath on runtime (e.g. in wars they will be copied to WEB-INF/lib).It is not, however, strictly required; for instance, we may compile against a certain API, making it a compile-time dependency, but then at runtime include an implementation that also includes the API.There may be fringe cases where the project requires a certain dependency to compile but then the corresponding code is not actually needed, but these will be rare.On the other hand, including runtime dependencies that are not needed at compile-time is very common. For instance, if you're writing a Java EE 6 application, you compile against the Java EE 6 API, but at runtime, any Java EE container can be used; it's this container that provides the implementation.Compile-time dependencies can be avoided by using reflection. For instance, a JDBC driver can be loaded with a  and the actual class loaded be configurable through a configuration file.Each Maven dependency has a scope that defines which classpath that dependency is available on. When you create a JAR for a project, dependencies are not bundled with the generated artifact; they are used only for compilation. (However, you can still make maven include the dependencies in the built jar, see: )When you use Maven to create a WAR or an EAR file, you can configure Maven to bundle dependencies with the generated artifact, and you can also configure it to exclude certain dependencies from the WAR file using the provided scope.The most common scope \u2014  \u2014 indicates that the dependency is available to your project on the compile classpath, the unit test compile and execution classpaths, and the eventual runtime classpath when you execute your application. In a Java EE web application, this means the dependency is copied into your deployed application. In a .jar file however, dependencies will not be included with compile scope..  indicates that the dependency is available to your project on the unit test execution and runtime execution classpaths,\nbut unlike compile scope it  or its unit tests.  This is good for making sure you do not mistakenly depend on a specific library. (See for example: ) Finally,  indicates that the container in which your application executes provides the dependency on your behalf. In a Java EE application, this means the dependency is already on the Servlet container\u2019s or application server\u2019s classpath and  It also means that you need this dependency for compiling your project.You need at compile time dependencies which you might need at runtime.  However many libraries run without all its possible dependencies. i.e. a libraries which can use four different XML libraries, but only needs one to work.Many libraries, need other libraries in turn.  These libraries are not needed at compile time but are needed at runtime. i.e. when the code is actually run.Generally you are right and probasbly it is the ideal situation if runtime and compile time dependencies are identical. I will give you 2 example when this rule is incorrect.If class A depends on class B that depends on class C that depends on class D where A is your class and B, C and D are classes from different third party libraries you need only B and C at compile time and you need also D at runtime.\nOften programs use dynamic class loading. In this case you do not need classes dynamically loaded by library you are using at compile time. Moreover often the library chooses which implementation to use at runtime. For example SLF4J or Commons Logging can change the target log implementation at runtime. You need only SSL4J itself at compile time. Opposite example when you need more dependencies at compile time than at runtime.\nThink that you are developing application that has to work at different environments or operating systems. You need all platform specific libraries at compile time and only libraries needed for current environment at runtime.I hope my explanations help.Usually, the static dependencies graph is a sub-graph of the dynamic one, see e.g. . That said, there are some exceptions, mainly dependencies that add compiler-support, which becomes invisible at runtime. For instance for code generation as via  or additional checks as via the .Just ran into an issue that answers your question.  is a transient dependency in my web project and is needed both at compile time and runtime. But  is also included in my Tomcat library.The solution here is to make  in maven available only at compile time and not packaged in my war file so that it would not clash with the  contained in my Tomcat library. I hope this explains Compile time and Runtime dependency.At compile time you enables contracts/api that you are expected from your dependencies.\n(eg: here you just sign for a contract with broadband internet provider)\nAt run-time actually you are using the dependencies. \n(eg: here you actually are using the broadband internet) "},
{"body": "The  has the following concepts:I'm trying to understand the relationship, , the  between them.Thanks in advance for any help here!I found this article which explains all aspects of the AMQP model, of which, channel is one. I found it very helpful in rounding out my understanding"},
{"body": " This question and most of its answers date to before the release of Java 7. Java 7 provides  functionality for doing this easilly. If you are using Java 7 or later you should advance to .What is considered the best, most comprehensive way to close nested streams in Java? For example, consider the setup:I understand the close operation needs to be insured (probably by using a finally clause). What I wonder about is, is it necessary to explicitly make sure the nested streams are closed, or is it enough to just make sure to close the outer stream (oos)?One thing I notice, at least dealing with this specific example, is that the inner streams only seem to throw FileNotFoundExceptions. Which would seem to imply that there's not technically a need to worry about closing them if they fail.Here's what a colleague wrote:Technically, if it were implemented right, closing the outermost\nstream (oos) should be enough. But the implementation seems flawed.Example:\nBufferedOutputStream inherits close() from FilterOutputStream, which defines it as:However, if flush() throws a runtime exception for some reason, then\nout.close() will never be called. So it seems \"safest\" (but ugly) to\nmostly worry about closing FOS, which is keeping the file open.What is considered to be the hands-down best, when-you-absolutely-need-to-be-sure, approach to closing nested streams?And are there any official Java/Sun docs that deal with this in fine detail?I usually do the following. First, define a template-method based class to deal with the try/catch messNote the \"pending\" exception -- this takes care of the case where an exception thrown during close would mask an exception we might really care about.The finally tries to close from the outside of any decorated stream first, so if you had a BufferedWriter wrapping a FileWriter, we try to close the BuffereredWriter first, and if that fails, still try to close the FileWriter itself. (Note that the definition of Closeable calls for close() to ignore the call if the stream is already closed)You can use the above class as follows:Using this approach you never have to worry about the try/catch/finally to deal with closing files again.If this is too heavy for your use, at least think about following the try/catch and the \"pending\" variable approach it uses.When closing chained streams, you only need to close the outermost stream.  Any errors will be propagated up the chain and be caught.Refer to  for details.This isn't right.  After you catch and ignore that exception, execution will pick back up after the catch block and the  statement will be executed.Your colleague makes a good point about the Exception.  If you absolutely need the stream to be closed, you can always try to close each one individually, from the outside in, stopping at the first exception.In the Java 7 era,  is certainly the way to go. As mentioned in several previous answers, the close request propagates from the outermost stream to the innermost stream. So a single close is all that is required.There is however a problem with this pattern. The try-with-resources is not aware of the inner FileInputStream, so if the ObjectInputStream constructor throws an exception, the FileInputStream is never closed (until the garbage collector gets to it). The solution is...This is not as elegant, but is more robust. Whether this is actually a problem will depend on what exceptions can be thrown during construction of the outer object(s). ObjectInputStream can throw IOException which may well get handled by an application without terminating. Many stream classes only throw unchecked exceptions, which may well result in termination of the application.It is a good practice to use Apache Commons to handle IO related objects.In the  clause use  Code snippet below.This is a surprisingly awkward question. (Even assuming the  code is correct.)If the construction of the decorator fails, then you wont be closing the underlying stream. Therefore you do need to close the underlying stream explicitly, whether in the finally after use or, more diifcult after successfully handing over the resource to the decorator).If an exception causes execution to fail, do you really want to flush?Some decorators actually have resources themselves. The current Sun implementation of  for instance has non-Java heap memory allocated.It has been claimed that (IIRC) two thirds of the resources uses in the Java library are implemented in a clearly incorrect manner.Whilst  closes even on an  from ,  closes correctly.My advice: Close resources as directly as possible and don't let them taint other code. OTOH, you can spend too much time on this issue - if  is thrown it's nice to behave nicely, but other aspects of your program are probably a higher priority and library code is probably broken in this situation anyway. But I'd always write:(Look: No catch!)And perhaps use the Execute Around idiom.The colleague raises an interesting point, and there are grounds for arguing either way.Personally, I would ignore the , because an unchecked exception signifies a bug in the program. If the program is incorrect, fix it. You can't \"handle\" a bad program at runtime.Also you dont have to close all nested streamscheck this\nThe Java SE 7  doesn't seem to be mentioned. It eliminates needing to explicitly do a close completely, and I quite like the idea.Unfortunately, for Android development this sweet only becomes available by using Android Studio (I think) and .I use to close streams like this,  blocksSun's JavaDocs include s in their documentation, as shown by InputStream's  method; documented as throwing NullPointerException and IndexOutOfBoundsException.FilterOutputStream's  is only documented as throwing IOException, thus it doesn't actually throw any s.  Any that could be thrown would most likely be wrapped in an .It could still throw an , but there's not much you can do about those; Sun recommends that you don't try to catch them."},
{"body": "What is the use of Collections.singletonList() in Java? (I understand that it returns a list with one element. Why would I want to have a separate method to do that? How does immutability play a role here?)Are there any special useful use-cases for this method, rather than just being a convenience method?The  says this:You ask:As a convenience ... to save you having to write a sequence of statements to:Clearly, there are use-cases where it is convenient to use the  method. But I don't know how you would (objectively) distinguish between an ordinary use-case and a \"specially useful\" one ... Here's one  on the singleton methods:If an Immutable/Singleton collections refers to the one which having only one object and which is not further gets modified, then the same functionality can be achieved by making a collection \"UnmodifiableCollection\" having only one object. Since the same functionality can be achieved by Unmodifiable Collection with one object, then what special purpose the Singleton Collection serves for?"},
{"body": "Was there any reason why the designers of Java felt that local variables should not be given a default value? Seriously, if instance variables can be given a default value, then why can't we do the same for local variables?And it also leads to problems as explained in :Local variables are declared mostly to do some calculation. So its the programmer's decision to set the value of the variable and it should not take a default value. If the programmer, by mistake, did not initialize a local variable and it take default value, then the output could be some unexpected value. So in case of local variables, the compiler will ask the programmer to initialize with some value before they access the variable to avoid the usage of undefined values. seems to be describing this situation:The commenter's complaint is that the compiler balks at the line in the  section, claiming that  might be uninitialized. The comment then mentions another way of writing the code, probably something like this:The commenter is unhappy with that solution because the compiler then says that the code \"must be within a try.\" I guess that means some of the code may raise an exception that isn't handled anymore. I'm not sure. Neither version of my code handles any exceptions, so anything exception-related in the first version should work the same in the second.Anyway, this second version of code is the  way to write it. In the first version, the compiler's error message was correct. The  variable might be uninitialized. In particular, if the  constructor fails,  will not be initialized, and so it will be an error to attempt to call . Always enter the  section  you have acquired the resource that the  section finalizes.The - block after the  initialization is there  to protect the  instance, to make sure it gets cleaned up no matter what else happens. If there are  things that need to run, but they aren't related to whether the  instance was property allocated, then they should go in  - block, probably one that wraps the one I've shown.Requiring variables to be assigned manually before use does not lead to real problems. It only leads to minor hassles, but your code will be better for it. You'll have variables with more limited scope, and - blocks that don't try to protect too much.If local variables had default values, then  in the first example would have been . That wouldn't really have solved anything. Instead of getting a compile-time error in the  block, you'd have a  lurking there that might  whatever other exception could occur in the \"Do some work here\" section of the code. (Or do exceptions in  sections automatically chain to the previous exception? I don't remember. Even so, you'd have an extra exception in the way of the real one.)Moreover, in the example below, an exception may have been thrown inside the SomeObject construction, in which case the 'so' variable would be null and the call to CleanUp will throw a NullPointerExceptionWhat I tend to do is this:Notice that the final instance/member variables don't get initialized by default. Because those are final and can't be changed in the program afterwards. That's the reason that Java doesn't give any default value for them and force the programmer to initialize it. On the other hand, non-final member variables can be changed later. Hence the compiler doesn't let them remain uninitialised, precisely, because those can be changed later. Regarding local variables, the scope of local variables is much narrower. Compiler knows when its getting used. Hence, forcing programmer to initialize the variable makes sense.The actual answer to your question is because method variables are instantiated by simply adding a number to the stack pointer.  To zero them would be an extra step.  For class variables they are put into initialized memory on the heap.Why not take the extra step?  Take a step back--Nobody mentioned that the \"warning\" in this case is a Very Good Thing.You should never initialize your variable to zero or null on the first pass (when you are first coding it).  Either assign it to the actual value or don't assign it at all because if you don't then java can tell you when you really screw up.  Take Electric Monk's answer as a great example.  In the first case, it's actually amazingly useful that it's telling you that if the try() fails because SomeObject's constructor threw an exception, then you would end up with an NPE in the finally.  If the constructor can't throw an exception, it shouldn't be in the try.This warning is an awesome multi-path bad programmer checker that has saved me from doing stupid stuff since it checks every path and makes sure that if you used the variable in some path then you had to initialize it in every path that lead up to it.  I now never explicitly initialize variables until I determine that it is the correct thing to do.On top of that, isn't it better to explicitly say \"int size=0\" rather than \"int size\" and make the next programmer go figure out that you intend it to be zero?On the flip side I can't come up with a single valid reason to have the compiler initialize all uninitialized variables to 0.I think the primary purpose was to maintain similarity with C/C++. However the compiler detects and warns you about using uninitialized variables which will reduce the problem to a minimal point. From a performance perspective, it's a little faster to let you declare uninitialized variables since the compiler will not have to write an assignment statement, even if you overwrite the value of the variable in the next statement.It is more efficient not to initialize variables, and in the case of local variables it is safe to do so, because initialization can be tracked by the compiler.In cases where you need a variable to be initialized you can always do it yourself, so it is not a problem.(It may seem strange to post a new answer so long after the question, but a  came up.)For me, the  comes down to this this: The purpose of local variables is different than the purpose of instance variables. Local variables are there to be used as part of a calculation; instance variables are there to contain state. If you use a local variable without assigning it a value, that's almost certainly a logic error.That said, I could totally get behind requiring that instance variables were always explicitly initialized; the error would occur on any constructor where the result allows an uninitialized instance variable (e.g., not initialized at declaration and not in the constructor). But that's not the decision Gosling, et. al., took in the early 90's, so here we are. (And I'm not saying they made the wrong call.)I could  get behind defaulting local variables, though. Yes, we shouldn't rely on compilers to double-check our logic, and one doesn't, but it's still handy when the compiler catches one out. :-)Eclipse even gives you warnings of uninitialized variables, so it becomes quite obvious anyway.  Personally I think it's a good thing that this is the default behaviour, otherwise your application may use unexpected values, and instead of the compiler throwing an error it won't do anything (but perhaps give a warning) and then you'll be scratching your head as to why certain things don't quite behave the way they should.The local variables are stored on a stack, but instance variables are stored on the heap, so there are some chances that a previous value on the stack will be read instead of a default value as happens in the heap. For that reason the jvm doesn't allow to use a local variable without initialize it.The answer is instance variables can be initialized in class constructor or any class method, But in case of local variables, once you defined whatever in the method that remains forever in the class.I could think of following 2 reasons"},
{"body": "Quite a stupid question. Given the code:Could you tell if it's good Java or not? What I'm talking about is,  is an unchecked exception. You  to specify it as part of  signature. Moreover, as far as I understand, the idea of unchecked exceptions is just to signal that program's implementation is incorrect, and even more, catching unchecked exceptions is a bad idea, since it's like .Would somebody please clarify whether::Imagine, it's not an open-source framework, that you should use for some reason. You look at method's signature and think - \"OK, it never throws\". Then, some day, you got an exception. Is it normal?:There are some comments saying my  is a bad design. I do absolutely agree, but for those who believe that original problem would just never appear if we had good design, here's an extra question:The problem definition is like this: you have a data source where numbers are stored as s. This source may be XML file, web page, desktop window with 2 edit boxes, whatever. Your goal is to implement the logic that takes these 2 s, converts them to s and displays message box saying \"the sum is xxx\".No matter what's the approach you use to design/implement this, you'll :The primary question of my original post is:This is a good question. I wish more people would think about such things.IMHO, throwing unchecked exceptions is acceptable if you've been passed rubbish parameters.Generally speaking, you shouldn't throw  because you shouldn't use Exceptions to control program flow. Exceptions are for the exceptional. Callers to your method can know  they call it if their strings are numbers or not, so passing rubbish in is avoidable and therefore can be considered a , which means it's OK to throw unchecked exceptions.Regarding declaring  - this is not that useful, because few will notice due to NumberFormatException being unchecked. However, IDE's can make use of it and offer to wrap in  correctly. A good option is to use javadoc as well, eg::\nThe commenters have made valid points. You need to consider how this will be used and the overall design of your app.  If the method will be used all over the place, and it's important that all callers handle problems, the declare the method as throwing a checked exception (forcing callers to deal with problems), but cluttering the code with  blocks.If on the other hand we are using this method with data we trust, then declare it as above, because it is not expected to ever explode and you avoid the code clutter of essentially unnecessary  blocks.In my opinion it would be preferable to handle exception logic as far up as possible. Hence I would prefer the signatureWith your method signature I would  change anything. Either you areHence, exception handling in this case becomes a  issue. Number 4.  As given, this method should not take strings as parameters it should take integers.  In which case (since java wraps instead of overflowing) there's no possibility of an exception.is a lot clearer as to what is meant than \n     You want the exception to happen as close to the source (input) as possible.  As to options 1-3, you don't define an exception because you expect your callers to assume that otherwise your code can't fail, you define an exception to define what happens under known failure conditions WHICH ARE UNIQUE TO YOUR METHOD. I.e. if you have a method that is a wrapper around another object, and it throws an exception then pass it along.  Only if the exception is unique to your method should you throw a custom exception (frex, in your example, if sum was supposed to only return positive results, then checking for that and throwing an exception would be appropriate, if on the other hand java threw an overflow exception instead of wrapping, then you would pass that along, not define it in your signature, rename it, or eat it).Update in response to update of the question:The solution to this is to to wrap the MUST library, and return a SHOULD value.  In this case, a function that returns an Integer.  Write a function that takes a string and returns an Integer object -- either it works, or it returns null (like guava's Ints.tryParse).  Do your validation seperate from your operation, your operation should take ints.  Whether your operation gets called with default values when you have invalid input, or you do something else, will depend upon your specs -- most I can say about that, is that it's really unlikely that the place to make that decision is in the operation method.I think so. It's a nice documentation.Sometimes yes. The checked exceptions are consider to be better in some cases, but working with them is quite a PITA. That's why many frameworks (e.g., Hibernate) use runtime exceptions only.Never. More work, less speed (unless you expect throwing the exception to be a rule), and no gain at all.None at all.Nr 4.I think I wouldn't change the method at all.\nI would put a try catch around the calling method or higher in the stack-trace where I'm in a context where I can gracefully recover with business logic from the exception.I wouldn't certainty do #3 as I deem it overkill.Assuming that what you are writing is going to be consumed (like as an API) by someone else, then you should go with 1, NumberFormatException is specifically for the purpose of communicating such exceptions and should be used.Depends a lot on the scenario you are in.Case 1. Its always you who debug the code and no one else and exception wont cause a bad user experienceThrow the default NumberFormatExceptionCase2: Code should be extremely maintainable and understandableDefine your own exception and add lot more data for debugging while throwing it.You dont need regex checks as, its gonna go to exception on bad input anyway.If it was a production level code, my idea would be to define more than one custom exceptions, likeand deal with all these seperatelyOveral, a NumberFormaException is unchecked because it is expected that correctly parseable input is provided. Input validation is something you should handle. However, actually parsing the input is the easiest way to do this. You could simply leave your method as it is and warn in the documentation that correct input is expected and anyone calling your function should validate both inputs before using it.Any exceptional behaviour should be clarified in the documentation. Either it should state that this method returns a special value in case the of failure (like , by changing the return type to ) or case 1 should be used. Having it explicit in the method's signature lets the user ignore it if he ensures correct strings by other means, but it still is obvious that the method doesn't handle this kind of failure by itself. Answer to your updated question.Yes it's perfectly normal to get \"surprise\" exceptions.\nThink about all the run time errors one got when new to programming.Also a common surprise exception from the for each loop.While I agree with the answer that the runtime exception should be allowed to be percolated, from a design and usability perspective, it would be a good idea to wrap it into a IllegalArgumentException rather than throw it as NumberFormatException. This then makes the contract of your method more clear whereby it declares an illegal argument was passed to it due to which it threw an exception.Regarding the update to the question \"Imagine, it's not an open-source framework, that you should use for some reason. You look at method's signature and think - \"OK, it never throws\". Then, some day, you got an exception. Is it normal?\" the javadoc of your method should always spill out the behavior of your method (pre and post constraints). Think on the lines of say collection interfaces where in if a null is not allowed the javadoc says that a null pointer exception will be thrown although it is never part of the method signature. As you are talking about good java practice ,in my opinion it is always better I think it depends on your purpose, but I would document it at a minimum:Or, take a page from the Java source code for the java.lang.Integer class:How about the input validation pattern implemented by  or  ()?In my experience, it is considered good practice to validate a function's parameters at the beginning of the function and throw Exceptions where appropriate.Also, I would consider this question to be largely language independent. The 'good practice' here would apply to all languages that have functions which can take parameters which may or may not be valid.I think your very first sentence of \"Quite a stupid question\" is very relevant. Why would you ever write a method with that signature in the first place? Does it even make sense to sum two strings? If the calling method wants to sum two strings, it is the calling method's responsibility to make sure they are valid ints and to convert them before calling the method.In this example, if the calling method cannot convert the two Strings into an int, it could do several things. It really depends at what layer this summation occurs at. I am assuming the String conversion would be very close to front-end code (if it was done properly), such that case 1. would be the most likely:There are lots of interesting answers to this question. But I still want to add this :For string parsing, I always prefer to use \"regular expressions\". The java.util.regex package is there to help us. So I will end up with something like this, that never throws any exception. It's up to me to return a special value if I want to catch some error :As one can see, the code is just a bit longer, but we can handle what we want (and set default values for x and y, control what happens with else clauses, etc...) \nWe could even write a more general transformation routine, to which we can pass strings, defaut return values, REGEX code to compile, error messages to throw, ...Hope It was usefull.Warning : I was not able to test this code, so please excuse eventual syntax problems.You face this issue because you let user errors propagate too deep into the core of the application and partly also because you abuse Java data types.You should have a clearer separation between user input validation and business logic, use proper data typing, and this problem will disappear by itself.The fact is the semantics of  are known - it's primary purpose it to parse  integers. You're missing an explicit user input validation/parsing step."},
{"body": "I have created a JAR file in this way . Now, I'm trying to run it. Running it does not work (jre command is not found):This does not work either:(Failed to load Main-Class manifest attribute from main.jar).I also found out thatWhat is the \"Main-Class manifest header\"? How do I create it and where do I put it?I'm not sure I believe your symptoms:I'd expect you to see this error if you run:The Main-Class header needs to be in the manifest for the JAR file - this is metadata about things like other required libraries. See the  for how to create an appropriate manifest. Basically you need to create a text file which includes a line like this:Then runYou can run with:It works for me if there is no manifest in the JAR file.I got this error, and it was because I had the arguments in the wrong order:CORRECTWRONGTake a look at the tutorial .The easiest way to be sure that you have created the runnable JAR file correctly, with the appropriate manifest file, is to use  to build it for you. In your Eclipse project, you basically just select File/Export from the menu, and follow the prompts. That way, you can be sure that your JAR file is correct and will know to look elsewhere if there is still an issue. The process is described in full in .I discovered that I was also having this error in NetBeans. \nI hope the following is helpful.This was the problem I was getting because I had other \"test\" programs I was using in NetBeans and I had to make sure the Main Class under the Run portion of the Project configuration was set correctly.many blessings,\nJohn PI was getting the same error when i ran:\nWhat resolved it was this:\nMy manifest has the entry point as given in oracle docs (make sure there is a new line character at the end of the file):\nTryno need to have  file.I faced the same problem. This unix command is not able to find the main class. This is because the runtime and compile time JDK versions are different. Make the jar through eclipse after changing the java compiler version. The following link helped me.Try running the jar created after this step and then execute itIf your class path is fully specified in manifest,\nmaybe you need the  of java runtime environment.\nMy problem fixed when i reinstalled the jre 8.  If you using eclipse, try below:\n1. Right click on the project -> select Export\n2. Select Runnable Jar file in the select an export destination\n3. Enter jar's name and Select \"Package required ... \" (second radio button) -> FinishHope this helps...!"},
{"body": "I've been using Guice's AOP to intercept some method calls. My class implements an interface and I would like to annotate the interface methods so Guice could select the right methods. Even if the annotation type is annotated with  annotation implementing class doesn't inherit the annotation as stated in Inherited's java doc:What could be the reason for this? Getting to know all interfaces that an object's class does implement in runtime is not that hard thing to do so there must be a good reason behind this decision.I'd say the reason is that otherwise a multiple-inheritance problem would occur.If I do this:what's the result going to be? 'baz', 'phleem' or 'flopp'?For this reason, annotations on interfaces are rarely useful.From the  for @Inherited:On the other hand, JSR 305 validators do some sort of inheritance lookup. If you have a hierarchy of classes:Then the effective validations on  are .  has no  meta-annotation."},
{"body": "I was reading through some JMockit examples and found this code:What does the tilde in the generic identifier mean? I know it's the unary bitwise NOT operator, but I don't see an operand here.Also, I tried compiling it and got an error. Am I just missing something?It is just a shorthand for \"same as in declaration\". Some IDEs, e.g. Intellij use this too.The files on disk do not have this notation, which is only a compaction in the IDE GUI.If there wasn't a tilde, I'd say, the code was already Java 7.  so this is/will be legal Java code:(but - no tilde with this syntax)In IntelliJ IDEA, the  here:means , which is the same as in the declaration on the left side.I think that is shorthand to mean whatever the type is, in this case ."},
{"body": "In our project I have several  tests that e.g. take every file from a directory and run a test on it. If I implement a  method in the  this shows up as only one test that may fail or succeed. But I am interested in the results on each individual file. How can I write a  /  such that each file shows up as a separate test e.g. in the graphical TestRunner of Eclipse? (Coding an explicit test method for each file is not an option.)Compare also the question .Take a look at  in JUnit 4.Actually I did this a few days ago. I'll try to explain ...First build your test class normally, as you where just testing with one input file.\nDecorate your class with:Build one constructor that takes the input that will change in every test call (in this case it may be the file itself)Then, build a static method that will return a  of arrays. Each array in the collection will contain the input arguments for your class constructor e.g. the file. Decorate this method with:Here's a sample class.Also check this Should be possible in JUnit 3 by inheriting from  and overriding the  method to list the files and for each return an instance of a subclass of  that takes the filename as constructor parameter and has a test method that tests the file given in the constructor.In JUnit 4 it might be even easier.If TestNG is an option, you could use .Each individual file's test will have its result shown in the text-based report or Eclipse's TestNG plugin UI. The number of total tests run will count each of your files individually.This behavior differs from JUnit , in which all results are lumped under one \"theory\" entry and only count as 1 test. If you want separate result reporting in JUnit, you can try .You could consider using , so you would have a few more (cleaner) options:You can see more .In addition : supports this through the notion of a , which is to be generated in a , by means of the static method .The tests run in your IDE (IntelliJ here) will be displayed like this:I had a similar problem and ended up writing a simple JUnit 4 runner that allows med to dynamically generate tests. "},
{"body": "Ok, I read the Java Documentation and I just can't figure out what is the main difference between those two methods. Sometimes I used , sometimes , sometimes one does what I want, sometimes the other.So, what is the main difference between the two? Which one should I use for  and ?ThanksThe short answer is: it's complicated.The slightly longer answer is: use  if your component's parent has no layout manager, and  and its related  and  if it does. probably won't do anything if the component's parent is using a layout manager; the places this will typically have an effect would be on top-level components ( and ) and things that are inside of .  You also must call  if you've got components inside a parent without a layout manager.As a general rule,  should do the \"right thing\" if you've got a layout manager; most layout managers work by getting the preferred (as well as minimum and maximum) sizes of their components, and then using  and  to position those components according to the layout's rules.  So (as an example) a  will try to make the bounds of its \"north\" region equal to the  of its north component - they may end up larger or smaller than that, depending on the size of the , the size of the other components in the layout, and so on. or  can be used when no layout manager is being used.However, if you are using a layout manager you can provide hints to the layout manager using the  methods like  and  etc. And be sure that the component's container uses a layout manager that respects the requested size. The , , and  managers use the component's preferred size (the latter two depending on the constraints you set), but  and  usually don't.If you specify new size hints for a component that's already visible, you need to invoke the revalidate method on it to make sure that its containment hierarchy is laid out again. Then invoke the repaint method. will resize the component to the specified size. sets the preferred size.  The component may not actually be this size depending on the size of the container it's in, or if the user re-sized the component manually.IIRC ... sets the size of the component. sets the preferred size. \nThe Layoutmanager will try to arrange that much space for your component.It depends on whether you're using a layout manager or not ..."},
{"body": "I want to manipulate a Microsoft Access database (.accdb or .mdb file) from my Java project. I don't want to use the JDBC-ODBC Bridge and the Access ODBC driver from Microsoft because:I have seen other answers mentioning a JDBC driver for Access databases named . How can I set up my Java project to use this approach?(Answers suggesting better ways of working with Access databases from Java would also be most welcome.) is a pure Java JDBC driver that allows us to read from and write to Access databases without using ODBC. It uses two other packages,  and , to perform these tasks. The following is a brief overview of how to get it set up.\u00a0If your project uses  you can simply include UCanAccess via the following coordinates: net.sf.ucanaccess\n ucanaccess\u00a0As mentioned above, UCanAccess requires Jackcess and HSQLDB. Jackcess in turn has its own . So to use UCanAccess you will need to include the following components: (ucanaccess-x.x.x.jar)\n (hsqldb.jar, version 2.2.5 or newer)\n (jackcess-2.x.x.jar)\n (commons-lang-2.6.jar, or newer )\n (commons-logging-1.1.1.jar, or newer )Fortunately, UCanAccess includes all of the required JAR files in its distribution file. When you unzip it you will see something likeAll you need to do is add all  JARs to your project. Right-click the project in Package Explorer and choose . Click the \"Add External JARs...\" button to add each of the five (5) JARs. When you are finished your Java Build Path should look something like this Expand the tree view for your project, right-click the \"Libraries\" folder and choose \"Add JAR/Folder...\", then browse to the JAR file. After adding all five (5) JAR files the \"Libraries\" folder should look something like this: Choose  from the main menu. In the \"Libraries\" pane click the \"Add\" () button and add the five (5) JAR files. Once that is done the project should look something like this:\u00a0Now \"U Can Access\" data in .accdb and .mdb files using code like this\u00a0At the time of writing this Q&A I had no involvement in or affiliation with the UCanAccess project; I just used it. I have since become a contributor to the project."},
{"body": "Is there a reason there'sbut no?How do I filter a list correctly? I could useof course, but this way it's not guaranteed that my ordering stays the same, if I understand correctly.It wasn't implemented because it would expose a perilous large number of slow methods, such as #get(index) on the returned List view (inviting performance bugs). And ListIterator would be a pain to implement as well (though I submitted a  years ago to cover that).Since indexed methods can't be efficient in the filtered List view, it's better to just go with a filtered Iterable, which doesn't have them.You can use , which will definitely maintain ordering.Note that by constructing a new list, you'll be  the elements (just references, of course) - so it won't be a live view onto the original list. Creating a view would be pretty tricky - consider this situation:That would have to iterate over the whole original list, applying the filter to everything. I suppose it could require that the predicate matching didn't change over the lifetime of the view, but that would be not-entirely-satisfactory.(This is just guessing, mind you. Maybe one of the Guava maintainers will chip in with the  reason :)This isn't true.   is a lazily-evaluated function - it doesn't actually filter your collection until you start accessing the filtered version. For example, if you iterate over the filtered version, then the filtered elements will pop out of the iterator in the same order as your original collection (minus the ones filtered out, obviously). Perhaps you were thinking that it does the filtering up front, then dumps the results into an arbitrary, unordered Collection of some form - it doesn't.So if you use the output of  as the input to a new list, then your original order  be retained.Using static imports (and the  function), it becomes fairly succinct:Note that while  will not eagerly iterate over the underlying collection,   - it will extract all elements of the filtered collection and copy them into a new .As mentioned by Jon, you can use  or  and if you don't need a live view you can use  or  and yes ordering will be maintained.\n\nIf you are really interested in  part, you can visit  for more details.Summing up what the others said, you can easily create a generic wrapper to filter lists:"},
{"body": "I am just trying to understand why all fields defined in an Interface are implicitly  and . The idea of keeping fields  makes sense to me as you can't have objects of an interface but why they are  (implicitly)?Any one knows why Java designers went with making the fields in an interface  and ?An interface can't have behavior or state because it is intended to specify only an interaction contract, no implementation details. No behavior is enforced by not allowing method/constructor bodies or static/instance initializing blocks. No state is enforced by only allowing constants. A constant in Java is defined by a static final field (and by convention the name uses UPPER_CASE_AND_UNDERSCORES).There are a couple of points glossed over here:Just because fields in an interface are implicitly static final does not mean they must be compile-time constants, or even immutable. You can define e.g.(Beware that doing this inside an annotation definition can , relating to the fact that the above actually compiles to a static initializer.)Also, the reason for this restriction is more stylistic than technical, and a lot of people would .REASON FOR BEING FINAL--Any implementations can change value of fields if they are not defined as final. Then they would become a part of the implementation.An interface is a pure specification without any implementation.REASON FOR BEING STATIC--If they are static, then they belong to the interface, and not the object, nor the run-time type of the object.The fields must be static because they can't be abstract (like methods can). Because they can't be abstract, the implementers will not be able to logically provide the different implementation of the fields.The fields must be final, I think, because the fields may be accessed by many different implementers allows they to be changeable might be problematic (as synchronization). Also to avoid it to be re-implemented (hidden).Just my thought.I consider the requirement that the fields be final as unduly restrictive and a mistake by the Java language designers. There are times, e.g. tree handling, when you need to set constants in the implementation which are required to perform operations on an object of the interface type. Selecting a code path on the implementing class is a kludge. The workaround which I use is to define an interface function and implement it by returning a literal:However, it would be simpler, clearer and less prone to aberrant implementation to use this syntax:Specification, contracts... The machine instruction for field access uses object address plus field offset. Since classes can implement many interfaces, there is no way to make non-final interface field to have the same offset in all classes that extend this interface. Therefore different mechanism for field access must be implemented: two memory accesses (get field offset, get field value) instead of one plus maintaining kind of virtual field table (analog of virtual method table). Guess they just didn't want to complicate jvm for functionality that can be easily simulated via existing stuff (methods).In scala we can have fields in interfaces, though internally they are implemented as I explained above (as methods).:Anything (variable or method) that is  in Java can be invoked as  or  or directly. It is not compulsory to invoke it only by using object name.In interface, objects cannot be declared and  makes it possible to invoke variables just through class name without the need of object name.:It helps to maintain a constant value for a variable as it can't be overridden in its subclasses."},
{"body": "I am working with tomcat 6.0, and while I am indexing (not while i am starting tomcat), I have a permgen space error.\nHow could I increase that space??ThanksYou can use :to increase the space. But this usually only postpones the inevitable.You can also enable the PermGen to be garbage collectedUsually this occurs when doing lots of redeploys. I am surprised you have it using something like indexing. Use virtualvm or jconsole to monitor the Perm gen space and check it levels off after warming up the indexing.Maybe you should consider changing to another JVM like the IBM JVM. It does not have a Permanent Generation and is immune to this issue.For tomcat you can increase the permGem space by using For this you need to create (if not already exists) a file named setenv.sh in tomcat/bin folder and include following line in it Reference : You can also increase it via the VM arguments in your IDE. In my case, I am using Tomcat v7.0 which is running on Eclipse. To do this, double click on your server (Tomcat v7.0). Click the 'Open launch configuration' link. Go to the 'Arguments' tab. Add -XX:MaxPermSize=512m to the VM arguments list. Click 'Apply' and then 'OK'. Restart your server.if you found out that the memory settings were not being used and in order to change the memory settings, I used the tomcat7w or tomcat8w in the \\bin folder.Then the following should pop up:Click the Java tab and add the arguments.restart tomcatOn Debian-like distributions you set that in "},
{"body": "I'm trying to send an email using Java:I am getting the error :Will this code work to send email?The following code works very well with Google SMTP server. You need to supply your Google username and password.Username + password is no longer a recommended solution. This is due toGoogle had released Gmail API - . We should use oAuth2 method, instead of username + password.Here's the code snippet to work with Gmail API.To construct an authorized Gmail service through oAuth2, here's the code snippet.To provide a user friendly way of oAuth2 authentication, I made use of JavaFX, to display the following input dialogThe key to display user friendly oAuth2 dialog can be found in  and Following code worked for me.Required jar filesThe short answer - No.The long answer - no, since the code relies on the presence of a SMTP server running on the local machine, and listening on port 25. The SMTP server (technically the MTA or Mail Transfer Agent) is responsible for communicating with the Mail User Agent (MUA, which in this case is the Java process) to receive outgoing emails.Now, MTAs are typically responsible for receiving mails from users for a particular domain. So, for the domain gmail.com, it would be the Google mail servers that are responsible for authenticating mail user agents and hence transferring of mails to inboxes on the GMail servers. I'm not sure if GMail trusts open mail relay servers, but it is certainly not an easy task to perform authentication on behalf on Google, and then relay mail to the GMail servers.If you read the , you'll notice that the hostname and the port happen to be pointing to the GMail servers, and certainly not to localhost. If you intend to use your local machine, you'll need to perform either relaying or forwarding.You'll probably need to understand the SMTP protocol in depth if you intend to get anywhere when it comes to SMTP. You can start with the , but any further progress will actually necessitate programming against a SMTP server.It has been quite a while since this has been posted. But as of Nov 13,2012 I can verify that port 465 still works.Refer to GaryM's answer on .\nI hope this helps few more people.You need a SMTP server for sending mails. There are servers you can install locally on your own pc, or you can use one of the many online servers. One of the more known servers is Google's:I just successfully tested the allowed  using the first example from :Notice the various ports and transport strategies (which handle all the necessary properties for you).Curiously, Google require TLS on port 25 as well, even though Google's instructions .The following code works very well.Try this as a java application with javamail-1.4.5.jarTry this out. it works well for me. Make sure that before send email u need to give the access for less secure app in your gmail account. So go to the following link and try out with this java code.\nYou need to import javax.mail.jar file and activation.jar file to your project.Well, no, not without changing some parts since you're getting an error. You are currently trying to send mail via a SMTP server running on localhost but you aren't running any  hence the . Assuming the code is OK (I didn't really check), you'll have to either run a local SMTP server, or to use a (remote) one (from your ISP).Regarding the code, you can find samples in the JavaMail download package as mentioned in the :I have put my working gmail java class up on pastebin for your review, pay special attention to the \"startSessionWithTLS\" method and you may be able adjust JavaMail to provide the same functionality. Your code works, apart from setting up the connection with the SMTP server. You need a running mail (SMTP) server to send you email for you.Here is your modified code. I commented out the parts that are not needed and changed the Session creation so it takes an Authenticator. Now just find out the SMPT_HOSTNAME, USERNAME and PASSWORD you want to use (your Internet provider usually provides them).I always do it like this (using a remote SMTP server I know) because running a local mailserver is not that trivial under Windows (it's apparently quite easy under Linux).Indeed 465 works and the exception that you're getting is may be due to the un open SMTP port 25. By default the port number is 25. Yet you can configure it using the mail agent that is available as open source - For simplicity, just use the following configuration and you'll be fine. For even more: check out the complete working example from scratch Here is the working solution bro. it's guranteed1) First of all open your gmail account from which you wanted to send mail, like in you case \"\"xyz@gmail.com\"2) open this link below 3) click on \"Go to the \"Less secure apps\" section in My Account.\" option4) Then turn on it5) that's it (:here is my codeI got the same exception as you got.\nReason for this is not having up and running smpt server in your machine(since your host is localhost). If you use windows 7 it does not have SMTP server . so you will have to download, install and configure with domain and creating accounts.I used hmailserver as smtp server installed and configure in my local machine. \nYou can find a complete and very simple java class for sending emails using Google(gmail) account here,It uses following  properties"},
{"body": "Someone explain to me the differences between the following two statements?A  variable initialized by a  code block:A  variable initialized by an assignment:In this example, there's one  difference - in your first example,  isn't determined to be a compile-time constant, so it can't be used as a case in  blocks (and wouldn't be inlined into other code); in your second example it, is. So for example:That's valid when  is deemed to be a constant expression, but not when it's \"just\" a static final variable.However, static initializer blocks are  used when you have more complicated initialization code - such as populating a collection.The  for initialization is described in ; any static final fields which are considered as compile-time constants are initialized first (step 6) and initializers are run later (step 9); all initializers (whether they're field initializers or static initializers) are run in textual order.The value of  is  when the class is  and .Here, the value of  will be a  constant. So, in reality  will be available as part of th  itself. In IInd case- value of  ie compiler identifies and assign value foo to variable , which cant be changed,and this will be .and In Ist case-value of foo initialize  as a very first assignment before instance variable assigned,also here you  or static field can be  in static block.So whenever there is a condition arrive  of variable foo, condition II will work,for ex-.The JLS describes a few special behaviors of what it calls , which are  variables (whether  or not) which are initialized with constant expressions of  or primitive type.Constant variables have a major difference with respect to binary compatibility: the  of constant variables become part of the class's API, as far as the compiler is concerned.An example:Here,  is a \"constant variable\" and  is not, but they are otherwise equivalent. Class  prints out each of them. Compile those classes, then disassemble them with , and here is the output:Class X:Class Y:Class Z:Things to notice in the disassembly, which tell you the differences between  and  run deeper than syntactic sugar:Other differences you will find:The JLS describes the above effects constant variables have on compiled class files in :And in :The upshot is that if your public library exposes any constant variables, you  change their values if your new library version is otherwise supposed to be compatible with code compiled against old versions of the library. It won't necessarily cause an error, but the existing code will probably malfunction since it will have outdated ideas about the values of constants. (If your new library version needs for classes which use it to be recompiled anyway, then changing constants doesn't cause this problem.)Thus, initializing a constant with a block gives you more freedom to change its value, because it prevents the compiler embedding the value into other classes.The only difference is the initialization time.Java first initializes the members and then the static blocks.An additional aspect: Consider the case when you have multiple static fields, and yes this is a corner case...As stated in Jon Skeet's answer, the JLS defines the exact order of initialization.\nHowever, if for some reason you have to initialize multiple static attributes in a specific order, you may want to make the initialization sequence clearly visible in the code.\nWhen using direct field initialization: Some code formatters (and developers) may decide at some point to sort fields differently, this will directly impact how the fields get initialized and introduce unwanted effects.By the way, if you want to follow common java coding conventions, you should use capital letters when defining 'constants' (final static fields).--- edited reflecting Jon Skeet's comments ---Static block give you more than simple statement. In this particular case is the same thing.\nStatic section will be executed at class load time, before any instances constructed. You can call methods here and assign their results to static fields. And you can catch exceptions in static blocks."},
{"body": "My company has been evaluating Spring MVC to determine if we should use it in one of our next projects. So far I love what I've seen, and right now I'm taking a look at the Spring Security module to determine if it's something we can/should use. Our security requirements are pretty basic; a user just needs to be able to provide a username and password to be able to access certain parts of the site (such as to get info about their account); and there are a handful of pages on the site (FAQs, Support, etc) where an anonymous user should be given access.In the prototype I've been creating, I have been storing a \"LoginCredentials\" object (which just contains username and password) in Session for an authenticated user; some of the controllers check to see if this object is in session to get a reference to the logged-in username, for example. I'm looking to replace this home-grown logic with Spring Security instead, which would have the nice benefit of removing any sort of \"how do we track logged in users?\" and \"how do we authenticate users?\" from my controller/business code. It seems like Spring Security provides a (per-thread) \"context\" object to be able to access the username/principal info from anywhere in your app...... which seems very un-Spring like as this object is a (global) singleton, in a way.My question is this: if this is the standard way to access information about the authenticated user in Spring Security, what is the accepted way to inject an Authentication object into the SecurityContext so that it is available for my unit tests when the unit tests require an authenticated user?Do I need to wire this up in the initialization method of each test case?This seems overly verbose. Is there an easier way? The  object itself seems very un-Spring-like...The problem is that Spring Security does not make the Authentication object available as a bean in the container, so there is no way to easily inject or autowire it out of the box.Before we started to use Spring Security, we would create a session-scoped bean in the container to store the Principal, inject this into an \"AuthenticationService\" (singleton) and then inject this bean into other services that needed knowledge of the current Principal.If you are implementing your own authentication service, you could basically do the same thing: create a session-scoped bean with a \"principal\" property, inject this into your authentication service, have the auth service set the property on successful auth, and then make the auth service available to other beans as you need it.I wouldn't feel too bad about using SecurityContextHolder. though.  I know that it's a static / Singleton and that Spring discourages using such things but their implementation takes care to behave appropriately depending on the environment: session-scoped in a Servlet container, thread-scoped in a JUnit test, etc.  The real limiting factor of a Singleton is when it provides an implementation that is inflexible to different environments.Just do it the usual way and then insert it using  in your test class, for example:Controller:Test:You are quite right to be concerned - static method calls are particularly problematic for unit testing as you cannot easily mock your dependencies. What I am going to show you is how to let the Spring IoC container do the dirty work for you, leaving you with neat, testable code. SecurityContextHolder is a framework class and while it may be ok for your low-level security code to be tied to it, you probably want to expose a neater interface to your UI components (i.e. controllers).cliff.meyers mentioned one way around it - create your own \"principal\" type and inject an instance into consumers. The Spring </> tag introduced in 2.x combined with a request scope bean definition, and the factory-method support may be the ticket to the most readable code.It could work like following:Nothing complicated so far, right? In fact you probably had to do most of this already. Next, in your bean context define a request-scoped bean to hold the principal:Thanks to the magic of the aop:scoped-proxy tag, the static method getUserDetails will be called every time a new HTTP request comes in and any references to the currentUser property will be resolved correctly. Now unit testing becomes trivial:Hope this helps!Personally I would just use Powermock along with Mockito or Easymock to mock the static SecurityContextHolder.getSecurityContext() in your unit/integration test e.g.Admittedly there is quite a bit of boiler plate code here i.e. mock an Authentication object, mock a SecurityContext to return the Authentication and finally mock the SecurityContextHolder to get the SecurityContext, however its very flexible and allows you to unit test for scenarios like null Authentication objects etc. without having to change your (non test) codeWithout answering the question about how to create and inject Authentication objects, Spring Security 4.0 provides some welcome alternatives when it comes to testing. The  annotation enables the developer to specify a mock user (with optional authorities, username, password and roles) in a neat way:There is also the option to use  to emulate a  returned from the , e.g.More details can be found in the  and the  chapters in the Spring Security reference docs (from which the above examples where copied)Using a static in this case is the best way to write secure code.Yes, statics are generally bad - generally, but in this case, the static is what you want.  Since the security context associates a Principal with the currently running thread, the most secure code would access the static from the thread as directly as possible.  Hiding the access behind a wrapper class that is injected provides an attacker with more points to attack.  They wouldn't need access to the code (which they would have a hard time changing if the jar was signed), they just need a way to override the configuration, which can be done at runtime or slipping some XML onto the classpath.  Even using annotation injection would be overridable with external XML.  Such XML could inject the running system with a rogue principal.I asked the same question myself over , and just posted an answer that I recently found.  Short answer is: inject a , and refer to  only in your Spring config to obtain the I would take a look at Spring's abstract test classes and mock objects which are talked about . They provide a powerful way of auto-wiring your Spring managed objects making unit and integration testing easier.Authentication is a property of a thread in server environment in the same way as it is a property of a process in OS. Having a bean instance for accessing authentication information would be inconvenient configuration and wiring overhead without any benefit. Regarding test authentication there are several ways how you can make your life easier. My favourite is to make a custom annotation  and test execution listener, which manages it. Check  for inspiration.In the meantime (since version 3.2, in the year 2013, thanks to ) the authentication can be injected into MVC methods using the annotation :In your unit test you can obviously call this Method directly. In integration tests using  you can use  to inject the user like this:This will however just directly fill the SecurityContext. If you want to make sure that the user is loaded from a session in your test, you can use this:After quite a lot of work I was able to reproduce the desired behavior. I had emulated the login through  MockMvc. It is too heavy for most unit tests but helpful for integration tests. Of course I am willing to see those new features in Spring Security 4.0 that will make our testing easier."},
{"body": "So I know about [](, but it's indexed by the  offset, not by the codepoint offset.  I'm thinking about trying something like:But my concerns areYes, Java uses a UTF-16-esque encoding for internal representations of Strings, and, yes, it encodes characters outside the Basic Multilingual Plane () using the surrogacy scheme.If you know you'll be dealing with characters outside the BMP, then here is the canonical way to iterate over the characters of a Java String:Java 8 added  which returns an  containing the code points.\nYou can use the stream directly to iterate over them:or with a for loop by collecting the stream into an array:These ways are probably more expensive than , but they are faster to read/write and the performance difference will usually be insignificant.Iterating over code points is filed as a feature request at Sun. See There is also an example on how to iterate over String CodePoints there.Thought I'd add a workaround method that works with foreach loops (), plus you can convert it to java 8's new String#codePoints method easily when you move to java 8:Then you can use it with foreach like this:Or alternately if you just want to convert a string to an array of int (which might use more RAM than the above approach):"},
{"body": "I know we can use the  method in Java get an individual character in a string by specifying its position. Is there an equivalent method in C#?You can index into a string in C# like an array, and you get the character at that index.Example:In Java, you would say In C#, you would say AndThe above is same as using indexers in c#.you can use LINQ Console.WriteLine allows the user to specify a position in a string.See sample:string str = \"Tigger\";\nConsole.WriteLine( str[0] ); //returns \"T\";\nConsole.WriteLine( str[2] ); //returns \"g\";There you go!please try to make it as a character "},
{"body": "I've recently read about this and seen people using this class, but in pretty much all cases, using  would've worked as well - if not more intuitively. Can someone provide a concrete example where  would achieve something that  couldn't or in a much cleaner way? The only thing I can think of is to use it with  that don't accept  keys, but even that could be done with a side \"mapping\" of null's value. Can anyone provide me with a more convincing argument? Thank you.Guava team member here.Probably the single biggest disadvantage of  is that it's not obvious what it should mean in any given context: it doesn't have an illustrative name. It's not always obvious that  means \"no value for this parameter\" -- heck, as a return value, sometimes it means \"error\", or even \"success\" (!!), or simply \"the correct answer is nothing\".  is frequently the concept you actually mean when you make a variable nullable, but not always. When it isn't, we recommend that you write your own class, similar to  but with a different naming scheme, to make clear what you actually mean.But I would say the biggest advantage of  isn't in readability: the advantage is its idiot-proof-ness. It forces you to actively think about the absent case if you want your program to compile at all, since you have to actively unwrap the  and address that case. Null makes it disturbingly easy to simply forget things, and though FindBugs helps, I don't think it addresses the issue nearly as well. This is especially relevant when you're returning values that may or may not be \"present.\" You (and others) are far more likely to forget that  could return a  value than you're likely to forget that  could be  when you're implementing . Returning  makes it impossible for callers to forget that case, since they have to unwrap the object themselves.For these reasons, we recommend that you use  as a return type for your methods, but not necessarily in your method arguments.(This is totally cribbed, by the way, from the discussion .)It really looks like the  Monad pattern from Haskell.You should read the following, Wikipedia :And read  on   which discusses about the Optional of Guava used as a Monad:\nWith Java8, there's a built-in Optional that has monadic operators like . This has been a controversial subject but finally has been implemented.See The  operator is essential to allow monadic operations, and permits to easily chain calls that all return Optional results.Think about it, if you used the  operator 5 times you would end up with an , while using  would give you Since Java8 I would rather not use Guava's Optional which is less powerful.One good reason to use it is that it makes your nulls very meaningful.  Instead of returning a null that could mean many things (like error, or failure, or empty,etc) you can put a 'name' to your null. Look at this example:lets define a basic POJO:}Now lets make use of this simple POJO:Now lets avoid using null and do our checks with Optional so its meaningfulthus in the end its a way to make nulls meaningful, & less ambiguity. The most important advantage of Optional is that it adds more details to the contract between the implementer and caller of a function. For this reason is both useful for parameters and return type.If you make the convention to always have  for possible null objects you add more clarifications to cases like:So the good part of using Optional is that the contract became both descriptive (similar with  annotation) but also formal since you must write code  to cope with ."},
{"body": "I get this when I call  on an object I received from a function call. I know the type of the object is encoded in this string, but I don't know how to read it. What is this type of encoding called? is the name for , the  representing the class of array of .The naming scheme is documented in :Here are some examples:The reason why the  method on arrays returns  in this format is because arrays do not  the method inherited from , which is specified as follows:: you can not rely on the  of any arbitrary object to follow the above specification, since they can (and usually do)  it to return something else. The more reliable way of inspecting the type of an arbitrary object is to invoke  on it (a  method inherited from ) and then  on the returned  object. Ideally, though, the API should've been designed such that reflection is not necessary (see ). provides  overloads for primitive arrays and . There is also  that you may want to use for nested arrays.Here are some examples:There are also  and  that perform array equality comparison by their elements, among many other array-related utility methods."},
{"body": "So, if I try to remove elements from a Java  while iterating, I get a .  What is the best way to remove a subset of the elements from a  as in the following example?Here is a solution, but I don't think it's very elegant:Thanks!You can manually iterate over the elements of the set:You will often see this pattern using a  loop rather than a  loop:As people have pointed out, using a  loop is preferred because it keeps the iterator variable ( in this case) confined to a smaller scope.The reason you get a  is because an entry is removed via  as opposed to .  If an entry is removed via  while an iteration is being done, you will get a ConcurrentModificationException.  On the other hand, removal of entries via  while iteration is supported in this case.The new for loop is nice, but unfortunately it does not work in this case, because you can't use the Iterator reference.If you need to remove an entry while iteration, you need to use the long form that uses the Iterator directly.you can also refactor your solution removing the first loop:Does it need to be whilst iterating?  If all you're doing is filtering or selecting I would suggest using Apache Commons .  There are some powerful tools there and it makes your code \"cooler.\"Here's an implementation that should provide what you need:If you find yourself using the same kind of predicate frequently you can pull that out into a static variable for reuse... name it something like .  Some may see that code and declare it \"hard to read\" but it looks cleaner when you pull out the Predicate into a static.  Then it's easy to see that we're doing a  and that seems more readable (to me) than a bunch of loops all over creation.Java 8 Collection has a nice method called removeIf that makes things easier and safer. From the API docs:Interesting note:From:\nAn other possible solution:Or:Like timber said - \"Java 8 Collection has a nice method called removeIf that makes things easier and safer\"Here is the code that solve your problem:Now your set contains only odd values."},
{"body": "When you have \"Mark occurrences\" enabled in Eclipse, placing the cursor on any type/variable/method/etc will highlight all occurrences in the text editor and place a faint bar in the right ruler to show you the location of other occurrences in the file.Does anyone know where in the Preferences you can change what color is used to highlight the other occurrences in the side ruler? The color is way too faint for me with my current monitor/Windows Aero theme.I tried to go into Preferences > General > Appearance > Color and Fonts change the color for \"Color labels - match highlight\" but this didn't seem to apply.Here is a screenshot with what I am talking about:The color in the bar is the same as the color the text is highlighted with in the editor. It is set by going toPreferences > General > Editors > Text Editors > Annotationsand changing the Occurrences and Write Occurrences colors.Right click on the marker and select the only menu item \"preferences\", this opens the preferences dialog: General/Editors/text Editor/Annotation.The updates do not apply immediatly after using the Apply button, only after closing with OK and eventually reselect.The bar is called the Overview Bar or Overview Ruler (in case you need to reference it) and, as has been mentioned, the color of occurences can be changed by navigating to:and changing the color for Occurrences.One difference to note in Eclipse Juno (most other responses seem to refer to Indigo) is that the change won't take effect until you restart the program.You'll want to change the \"Occurrences\" and \"Write Occurrences\" colors. This can be done in the Annotations menu, which is located \u2014 as Colin said \u2014 in the Preferences menu under the pathGeneral > Editors > Text Editors > AnnotationsIf you have an occurrence marked in the overview ruler (the column to the right of the scrollbar), you can open the Annotations menu directly by right-clicking on the occurrence and selecting Preferences from the context menu.The color of \"occurrences\" is used for instances where the variable is being read, but not modified, in the code (e.g.  in ). The color of \"write occurrences\" is used where the variable gets modified/written to in the code (e.g.  in ).See also the , about halfway down the page (link is for Indigo, but should be good for other recent versions as well).Go to Windows/Preferences/Java/Editor/Mark Occurrences and check the box \"Mark Occurrences of the selected element in the current file.\"After changed the color of \"occurances\", restart your Eclipse IDE"},
{"body": "I'm currently using the jar-with-dependencies assembly to create such a jar.  However, the name of my jar is a bit long.  Since this jar is being used by RPG programs on an AS400, I'd like to shorten it to make life a bit easier for those developers.  But, other than by hand, I've not found a way to rename the jar from the usual .  I'd like something like  Is there anyway to do this without basically copying the jar-with-dependencies assembly descriptor and calling it full? Additionally, I want to continue to have the jar without the classpath assembled stored in the repository.I need two artifacts.  The jar with my classifier holding the region which the build is for.  The jar with all dependencies which also includes the region. and  should be stored in the repository.  In the first example the classifier is region-full, in the 2nd it's region.  The latter is working.You can specify the  property to give the jar the name you want, and specify that  should be false to avoid the \"jar-with-dependencies\" suffix.The configuration below will output a jar called \"test.jar\"Update: based on your comments, using the built-in descriptor won't work . I believe this is down to a bug in the recent versions of the assembly-plugin - they've removed support for classifiers, but the id is fixed if you use a built-in descriptor, so you end up with a big daft name.As a workaround, you can copy the assembly descriptor used by the  descriptor and modify the id.This example would result in the assembly id being appended to the finalName, so if you need to have a name of , you can specify the finalName as  and the assembly id as . This will result in a file in target called region-full.jar, but note it will still be installed to the Maven repository as an attached artifact with  used as the classifier. As long as this id is different to that for your other assembly there should be no collision though.The pom configuration would look like this.and the jar-assembly.xml in src/main/assembly like this:Thanks to the posts here and some digging in the  I've come up with the following configuration for a general one-off repacked executable jar assembly with a custom name.In pom.xml:In assembly.xml:This will produce  with all of its dependencies re-packaged into that same jar and the specified .I think I've found a way to configure this directly in the pom without needing a separate jar-assembly.xml.It's basically the same as Rich's answer, except the finalName is specified with the artifactId and version.I'm going to give Rich the credit for pointing me in the right direction, but wanted to post the solution that worked for me as Rich's was slightly off:My jar-assembly.xml looked like this which allowed the assembly id to change for the region which was stored as an property in my profile:I did not use the finalName parameter in the maven-assembly-plugin settings as this built my project with my project-name-version-env-full.jar name where env-full was the classifier.  Imagine my surprise when I learned the assembly xml could be parameterized by items in the build.  This was exactly what I was looking for.This worked for me"},
{"body": "I'm not a good java programmer, it's just my hobby, but I'm eager to know more than average stuff.I want to solve a mathematical problem with multiple threads in java. my math problem can be separated into work units, that I want to have solved in several threads.but I don't want to have a fixed amount of threads working on it, but instead a coresponding amount of threads to the amount of cpu cores.\nand my problem is, that I couldn't find an easy tutorial in the internet for this. all I found are examples with fixed threads.So could you help me with a link to a good tuturial or could give me an easy and good example? That would be really nice :)You can determine the number of processes available to the Java Virtual Machine by using the static Runtime method, .  Once you have determined the number of processors available, create that number of threads and split up your work accordingly.: To further clarify, a Thread is just an Object in Java, so you can create it just like you would create any other object.  So, let's say that you call the above method and find that it returns 2 processors.  Awesome.  Now, you can create a loop that generates a new Thread, and splits the work off for that thread, and fires off the thread.  Here's some psuedocode to demonstrate what I mean:For more information on creating your own thread, .  Also, you may want to look at  for the creation of the threads.You probably want to look at the java.util.concurrent framework for this stuff too.\nSomething like:orThis is a lot nicer than coping with your own thread pools etc.Doug Lea (author of the concurrent package) has this paper which may be relevant:\nThe Fork Join framework has been added to Java SE 7. Below are few more references:\nArticle by Brian GoetzOn the Runtime class, there is a method called availableProcessors().  You can use that to figure out how many CPUs you have.  Since your program is CPU bound, you would probably want to have (at most) one thread per available CPU.The standard way is the Runtime.getRuntime().availableProcessors() method.\nOn most standard CPUs you will have returned the optimal thread count (which is not the actual CPU core count) here. Therefore this is what you are looking for.Example:Do NOT forget to shut down the executor service like this (or your program won't exit):Here just a quick outline how to set up a future based MT code (offtopic, for illustration):Then you need to keep track on how many results you expect and retrieve them like this: from With this API, you don't need to pass number of cores to .Implementation of this API from  API from  or , which returns  pass  as parameter to ."},
{"body": "Suppose we have the following classes:Now lets call  in class A:The output is, as expected counting down from 10.   Let's get to the the confusing part. Now we call  in class B.::How does this happen? I know this is a devised example, but it makes me wonder.Older question with a .This is expected. This is what happens for an instance of .As such, the calls are alternating between  and .This doesn't happen in the case of an instance of  because the overriden method won't be called.Because  in  refers to  which is  in second case. So,  and  will be called in  function .in The other answers have all explained the essential point, that once an instance method is overridden it stays overridden and there's no getting it back except through .  invokes .  then invokes , which resolves to the override in . And we ping pong back and forth until the end of the universe or a , whichever comes first.It would be nice if one could write  in  to get its own implementation, but that would probably break things and have other unfortunate consequences, so  in  invokes  and so forth.There is a way to get the expected behavior, but it requires foresight. In other words, you must know in advance that you want a  in a subtype of  to get trapped, so to speak, in the  implementation. It is done like so:Since  invokes  and  can never be overridden,  is assured that it is calling its own logic. in class  calls the super class's method explicitly, so  of  is called once.Then,  in class A would call the  method in class  which overrides  of class , since it is executed on an instance of class .Then 's  would call 's  explicitly, and so on.That actually cannot go any other way.When you call , then it prints  then calls the implementation of this method in  with . So you call , which prints  which calls the  method on the current instance which is  with input parameter , so it calls , which then calls the super implementation with  which is , which then recursively calls the current instance recursive with  which is , and you'll get the loop that you see here.This is all because if you call the method of the instance in the superclass, you'll still call the implementation of the instance on which you're calling it.Imagine this,You'll get \"BARK\" instead of a compilation error such as \"the abstract method cannot be called on this instance\" or a runtime error  or even  or something like that. So this is all to support .When a  instance's  method calls the class implementation, the instance being acted on is still of . Therefore when the super class's implementation calls  without further qualification, . The result is the never-ending loop you're seeing. "},
{"body": "I have added three methods with parameters:When I am calling  , then compiler throws error as . So is the issue because  and  methods or  and  methods?Java will always try to use the most specific applicable version of a method that's available (see ).,  and  can all take  as a valid value. Therefore all 3 version are applicable, so Java will have to find the most specific one.Since  is the super-type of , the array version is more specific than the -version. So if only those two methods exist, the  version will be chosen.When both the  and  versions are available, then  of them are more specific than  but none is more specific than the other, so Java can't decide which one to call. In this case you'll have to explicitly mention which one you want to call by casting the argument to the appropriate type.Note that in practice this problem occurs far more seldom than one might think. The reason for this is that it only happens when you're explicitly calling a method with  or with a variable of a rather un-specific type (such as ).On the contrary, the following invocation would be perfectly unambiguous:Although you're still passing the value , Java knows exactly which method to call, since it will take the type of the variable into account.Each pair of these three methods is ambiguous by itself when called with a  argument. Because each parameter type is a reference type. The following are the three ways to call one specific method of yours with null.May I suggest to remove this ambiguity if you actually plan to call these methods with  arguments. Such a design invites errors in the future. is a valid value for any of the three types; so the compiler cannot decide which function to use. Use something like  or  instead.Every class in Java extends Object class.Even Integer class also extends Object. Hence both Object and Integer are considered as Object instance. So when you pass null as a parameter than compiler gets confused that which object method to call i.e. With parameter Object or parameter Integer since they both are object and their reference can be null. But the primitives in java does not extends Object.I Have tried this and when there is exactly one pair of overloaded method and one of them has a parametar type Object then the compiler will always select the method with more specific type.  But when there is more than one specific type, then the compiler throws an ambiguous method error. Since this is a compile time event, This scenario can only happen when one intentionally pass null to this method.  If this is intentionally then it is better to overload this method again with no parameter or create another method altogether.  "},
{"body": "How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.Hard one :-)Wowww! That was something. ;-) But try the same in Java, just for fun!By the way, I tested that in a shell, so some errors likely remain.EnjoyBecause mail-box names can change from one country to another, I recommend doing  and picking an item in it before  to avoid this error:I'm not an expert on Perl, but what I do know is that GMail supports IMAP and POP3, 2 protocols that are completely standard and allow you to do just that. Maybe that helps you to get started. untestedTake a look at :There are two ways to get an attachment:1 -> By sending a reference to a specific attachment returned by 2 -> Or by sending the attachment ID and message ID( Returns a reference to a scalar that holds the data from the attachment. )Within gmail, you can filter on \"has:attachment\", use it to identify the messages you should be getting when testing. Note this appears to give both messages with attached files (paperclip icon shown), as well as inline attached images (no paperclip shown).There is no Gmail API, so IMAP or POP are your only real options. The  may be of some assistance as well as this very terse article on . Some  here on SO may also help.This  may help too. Unfortunately from what I can see, there is no attachment information contained within the imap_header, so downloading the body is required to be able to see the X-Attachment-Id field. (someone please prove me wrong).If any of you have updated to python 3.3 I took the 2.7 script from  and updated it to 3.3.  Also fixed some issues with the way gmail was returning the information.The question is quite old and at that time Gmail API was not available.  But now Google provides Gmail API to access IMAP.  See Google's Gmail API . Also see  on pypi.Maven Dependency:Since Gmail supports the standard protocols POP and IMAP, any platform, tool, application, component, or API that provides the client side of either protocol should work.I suggest doing a Google search for your favorite language/platform (e.g., \"python\"), plus \"pop\", plus \"imap\", plus perhaps \"open source\", plus perhaps \"download\" or \"review\", and see what you get for options.There are numerous free applications and components, pick a few that seem worthy, check for reviews, then download and enjoy.You should be aware of the fact that you need SSL to connect to GMail (both for POP3 and IMAP - this is of course true also for their SMTP-servers apart from port 25 but that's another story).Here's something I wrote to download my bank statements in  (dynamic language for the Java Platform).Have you taken a look at the  at wikipedia?In particular,  is an open source add-on that you may be able to use as-is, or perhaps study for inspiration?For Java, you will find  of use. It's a set of APIs to communicate with Google Mail via Java (the screenshot on the homepage is a demonstration email client built around this)"},
{"body": "When I run maven test, java.lang.OutOfMemoryError happens. I google it for solutions and have tried to , but it did not work. \nAnyone know other solutions for this problem ,BTW I am using maven 3.0Thanks in advancePaste the error message here when run \"mvn test -e\"Setting the  options using  does work, it does configure the JVM used to start Maven. That being said, the maven-surefire-plugin  a new JVM by default, and your  are thus not passed.To configure the sizing of the JVM used by the maven-surefire-plugin, you would either have to: In the later case, something like this: I have to say that I tend to agree with Stephen here, there is very likely something wrong with one of your test and I'm not sure that giving more memory is the right solution to \"solve\" (hide?) your problem.For those new to Maven (like me) here is the whole config that goes in the build section of your pom. Cheers. The chances are that the problem is in one of the unit tests that you've asked Maven to run.As such, fiddling with the heap size is the wrong approach.  Instead, you should be looking at the unit test that has caused the OOME, and trying to figure out if it is the fault of the unit test or the code that it is testing.Start by looking at the stack trace.  If there isn't one, run  again with the  option.I have solved this problem on my side by 2 ways:Set the environment variable:MAVEN_OPTS=\"-Xmx1024m\"Not only heap memory. also increase perm size  to resolve that exception in maven use these variables in environment variable.Example  : "},
{"body": "I'm trying to work with  in Java. I want to implement arithmetic functions.  For this, I will first require a way to normalize the functions.  I know I can't add 1/6 and 1/2 until I have a common denominator. I will have to add 1/6 and 3/6.  A naive approach would have me add 2/12 and 6/12 and then reduce.  How can I achieve a common denominator with the least performance penalty?  What algorithm is best for this?Version 8 (thanks to ):I have removed all previous versions.  My thanks to:It just so happens that I wrote a BigFraction class not too long ago, for .  It keeps a BigInteger numerator and denominator, so it'll never overflow.  But it'll be a tad slow for a lot of operations that you know will never overflow.. anyway, use it if you want it.  I've been dying to show this off somehow. :): Latest and greatest version of this code, including unit tests is  and also . I'm leaving my original code here so that this answer isn't just a link...In fact, try this on for size.  It runs but may have some issues:Output is:Please make it an immutable type! The value of a fraction doesn't change - a half doesn't become a third, for example. Instead of setDenominator, you could have withDenominator which returns a  fraction which has the same numerator but the specified denominator.Life is  easier with immutable types.Overriding equals and hashcode would be sensible too, so it can be used in maps and sets. Outlaw Programmer's points about arithmetic operators and string formatting are good too.As a general guide, have a look at BigInteger and BigDecimal. They're not doing the same thing, but they're similar enough to give you good ideas. has had a  class for quite some time. Most times the answer to, \"Boy I wish Java had something like  in the core library!\" can be found under the umbrella of the .Well, for one, I'd get rid of the setters and make Fractions immutable.You'll probably also want methods to add, subtract, etc., and maybe some way to get the representation in various String formats.EDIT: I'd probably mark the fields as 'final' to signal my intent but I guess it's not a big deal...Not strictly necessary. (In fact if you want to handle equality correctly, don't rely on double to work properly.) If b*d is positive, a/b < c/d if ad < bc. If there are negative integers involved, that can be handled appropriately...I might rewrite as:The use of  here is to ensure there's not an overflow if you multiply two large s. handle If you can guarantee that the denominator is always nonnegative (if it's negative, just negate both numerator and denominator), then you can get rid of having to check whether b*d is positive and save a few steps. I'm not sure what behavior you're looking for with zero denominator.Not sure how performance compares to using doubles to compare. (that is, if you care about performance that much) Here's a test method I used to check. (Appears to work properly.)(p.s. you might consider restructuring to implement  or  for your class.)One very minor improvement could potentially be to save the double value that you're computing so that you only compute it on the first access.  This won't be a big win unless you're accessing this number a lot, but it's not overly difficult to do, either.One additional point might be the error checking you do in the denominator...you automatically change 0 to 1.  Not sure if this is correct for your particular application, but in general if someone is trying to divide by 0, something is very wrong.  I'd let this throw an exception (a specialized exception if you feel it's needed) rather than change the value in a seemingly arbitrary way that isn't known to the user.In constrast with some other comments, about adding methods to add subtract, etc...since you didn't mention needing them, I'm assuming you don't.  And unless you're building a library that is really going to be used in many places or by other people, go with YAGNI (you ain't going to need it, so it shouldn't be there.)There are several ways to improve this or any value type:Basically, take a look at the API for other value classes like , Integer and do what they do :)If you multiply the numerator and denominator of one Fraction with the denominator of the other and vice versa, you end up with two fractions (that are still the same values) with the same denominator and you can compare the numerators directly. Therefore you wouldn't need to calculate the double value:how I would improve that code:You have a compareTo function already ... I would implement the Comparable interface.May not really matter for whatever you're going to do with it though.If you're feeling adventurous, take a look at . It has a  class that represents fractions.I would say throw a ArithmeticException for divide by zero, since that's really what's happening:Instead of \"Divide by zero.\", you might want to make the message say \"Divide by zero: Denominator for Fraction is zero.\"Once you've created a fraction object why would you want to allow other objects to set the numerator or the denominator?  I would think these should be read only.  It makes the object immutable...Also...setting the denominator to zero should throw an invalid argument exception (I don't know what it is in Java)Timothy Budd has a fine implementation of a Rational class in his \"Data Structures in C++\".  Different language, of course, but it ports over to Java very nicely.I'd recommend more constructors.  A default constructor would have numerator 0, denominator 1.  A single arg constructor would assume a denominator of 1.  Think how your users might use this class.No check for zero denominator?  Programming by contract would have you add it.I'll third or fifth or whatever the recommendation for making your fraction immutable.  I'd also recommend that you have it extend the  class.  I'd probably look at the  class, since you're probably going to want to implement many of the same methods.  You should probably also implement  and  since this behavior will probably be expected.  Thus, you will need to implement compareTo().  You will also need to override equals() and I cannot stress strongly enough that you also override hashCode().  This might be one of the few cases though where you don't want compareTo() and equals() to be consistent since fractions reducable to each other are not necessarily equal.A clean up practice that I like is to only have only one return.  Use Rational class from  library. It's the best thing for fractional arithmetic I seen in Java.I cleaned up :Initial remark:Never write this:This is much better Just create to create a good habit.By making the class immutable as suggested, you can also take advantage of the double to perform the equals and hashCode and compareTo operations Here's my quick dirty version:About the static factory method, it may be useful later, if you subclass the Fraction to handle more complex things, or if you decide to use a pool for the most frequently used objects. It may not be the case, I just wanted to point it out. :) See  first item.Might be useful to add simple things like reciprocate, get remainder and get whole.Even though you have the methods compareTo(), if you want to make use of utilities like Collections.sort(), then you should also implement Comparable.Also, for pretty display I recommend overriding toString()And finally, I'd make the class public so that you can use it from different packages.This function simplify using the eucledian algorithm is quite useful when defining fractionsFor industry-grade Fraction/Rational implementation, I would implement it so it can represent NaN, positive infinity, negative infinity, and optionally negative zero with operational semantics exactly the same as the IEEE 754 standard states for floating point arithmetics (it also eases the conversion to/from floating point values). Plus, since comparison to zero, one, and the special values above only needs simple, but combined comparison of the numerator and denominator against 0 and 1 - i would add several isXXX and compareToXXX methods for ease of use (eg. eq0() would use numerator == 0 && denominator != 0 behind the scenes instead of letting the client to compare against a zero valued instance). Some statically predefined values (ZERO, ONE, TWO, TEN, ONE_TENTH, NAN, etc.) are also useful, since they appear at several places as constant values. This is the best way IMHO."},
{"body": "This Java code:will output this:In C++ I can pass the  variable as pass by reference to avoid shadowing i.e. creating a copy of the same variable as below:and the C++ output will be this:My question is - What's the equivalent code in Java to get the same output as the C++ code, given that ?You have several choices.  The one that makes the most sense really depends on what you're trying to do.then pass a reference to a MyToy to your method.This choice would require a small change to the callsite in main so that it reads, .If the two functions are methods on the same class or class instance, you could convert toyNumber into a class member variable.This is considered a hack, but is sometimes employed to return values from inline class invocations.Java is not  it is But all variables of object type are actually pointers.So if you use a Mutable Object you will see the behavior you wantOutput of this code:You can see this behavior in Standard libraries too.\nFor example Collections.sort(); Collections.shuffle();\nThese methods does not return a new list but modifies it's argument object.Output of this code:Make athen pass a reference to an instance of it. Note that a method that mutates state through its arguments is best avoided, especially in parallel code.You cannot pass primitives by reference in Java. All variables of object type are actually pointers, of course, but we call them \"references\", and they are also always passed by value.In a situation where you really need to pass a primitive by value, what people will do sometimes is declare the parameter as an array of primitive type, and then pass a single-element array as the argument. So you pass a reference int[1], and in the method, you can change the contents of the array.For a quick solution, you can use AtomicInteger or any of the atomic variables which will let you change  the value inside the method using the inbuilt methods. Here is sample code:Output:"},
{"body": "I'm trying to implement a TCP connection, everything works fine from the server's side but when I run the client program (from client computer) I get the following error:I tried changing the socket number in case it was in use but to no avail, does anyone know what is causing this error & how to fix it.The Server Code:The Client Code:This exception  occurs when there is no service listening on the IP/port you are trying to connect to. However, a number of things could be causing the error:I would check:The simplest starting point is probably to try to connect manually from the client machine using telnet or Putty. If that succeeds, then the problem is in your client code. If it doesn't, you need to work out  it hasn't.  may help you on this front.You have to connect your client socket to the remote ServerSocket. Instead ofdo The client must connect to  which should match the name or IP of the box on which your  was instantiated (the name must be reachable from the client machine). BTW: It's not the name that is important, it's all about IP addresses...I tried your code out and I didn't have any problems on my machine. it has to be something blocking your connection or else you are starting them in the wrong order. Are you making sure that your server isn't getting closed when you start the client up. My process was this. put both class file in one directory, then opened 2 command prompts to that directory to execute them separately. if your using an IDE it may be closing the server automatically which is why i recommend doing it this wayI had the same problem with Mqtt broker called vernemq.but solved it by adding the following.to show the list o allowed ips and ports for vernemqto add any ip and your new port. now u should be able to connect without any problem. Hope it solves your problem.\nI had the same problem, but running the Server before running the Client fixed it. Hope my experience may be useful to someone. I faced the problem with the same exception stack trace and I couldn't understand what the issue was. The Database server which I was trying to connect was running and the port was open and was accepting connections.The issue was with internet connection. The internet connection that I was using was not allowed to connect to the corresponding server. When I changed the connection details, the issue got resolved.i got this error because  that try to accept number of clients inside it (I did not finished accepting all clints)so be careful where to close your SocketIn my case, I gave the socket the name of the server (in my case \"raspberrypi\"), and instead an IPv4 address made it, or to specify, IPv6 was broken (the name resolved to an IPv6)Port number always diffrent at both endI had same problem and the problem was that I was not closing socket object.After using socket.close(); problem solved.\nThis code works for me.ClientDemo.javaand \nServerDemo.javaIt could be that there is a previous instance of the client still running and listening on port 5000.try  from the Internet (you can turn off wifi)."},
{"body": "I'm trying to figure out what a Java applet's class file is doing under the hood. Opening it up with Notepad or Textpad just shows a bunch of gobbledy-gook.Is there any way to wrangle it back into a somewhat-readable format so I can try to figure out what it's doing? is the best decompiler at the moment. it can handle newer features in Java, as compared to the getting-dusty JAD.If you don't mind reading bytecode, javap should work fine. It's part of the standard JDK installation.You want a java decompiler, you can use the command line tool  to do this.  Also,  describes how you can decompile a class file.Using  to decompile it is probably your best option. Unless the code has been obfuscated, it will produce an okay result.cpuguru, if your applet has been compiled with javac 1.3 (or less), your best option is to use Jad.Unfortunately, the last JDK supported by JAD 1.5.8 (Apr 14, 2001) is JDK 1.3.If your applet has been compiled with a more recent compiler, you could try  : this decompiler is under development, nevertheless, it generates correct Java sources, most of time, for classes compiled with the JDKs 1.4, 1.5 or 1.6.DarenW, thank you for your post. JD-GUI is not the best decompiler yet ... but I'm working on :)That's compiled code, you'll need to use a decompiler like JAD: what you are looking for is a java de-compiler.  I recommend JAD   It's free for non commercial use and gets the job done. Note: this isn't going to make the code exactly the same as what was written. i.e. you're going to lose comments and possibly variable names, so it's going to be a little bit harder than just reading normal source code.    If the developer is really secretive they will have obfuscated their code as well, making it even harder to read. As suggested you can use JAD to decompile it and view the files. To make it easier to read you can use the JADclipse plugin for eclipse to integrate JAD directly to eclipse or use DJ Java Decompiler which is much easier to use than command line JADJAD is an excellent option if you want readable Java code as a result.  If you really want to dig into the internals of the  file format though, you're going to want .  It's bundled with the JDK and allows you to \"decompile\" the hexadecimal bytecode into readable ASCII.  The language it produces is still bytecode (not anything like Java), but it's fairly readable and extremely instructive.Also, if you  want to, you can open up any  file in a hex editor and read the bytecode directly.  The result is identical to using .You need to use a decompiler.  Others have suggested JAD, there are other options, JAD is the best.I'll echo the comments that you may lose a bit compared to the original source code.  It is going to look especially funny if the code used generics, due to erasure.JAD and/or JADclipse Eclipse plugin, for sure.There is no need to decompile Applet.class. The public Java API classes sourcecode comes with the JDK (if you choose to install it), and is better readable than decompiled bytecode. You can find compressed in src.zip (located in your JDK installation folder).If the class file you want to look into is open source, you should not decompile it, but instead attach the source files directly into your IDE. that way, you can just view the code of some library class as if it were your ownjd-gui \"\" is the best and user friendly option for decompiling .class file.... is a great decompiler for modern Java written i Java 6."},
{"body": "I am considering creating my own website using Java and am trying to decide what framework to use. However, doing a quick search for Java frameworks returns more than 50 to choose from!My website is just going to be for my own enjoyment of building it in the beginning, but if it becomes popular, it would be good for it to have some scalability, or to at least be able to redesign for that.What are the main differences between the more popular frameworks? Are there instances where one significantly outperforms the others? For example, high-traffic enterprise applications versus low-traffic small applications. I'm also wondering if some are much easier to learn and use than others.Is there anyone who has experience with some of these frameworks and can make a recommendation? Does the sheer number of choices just serve as an early warning to avoid Java-based web development where possible?I've used , , , and  fairly extensively.  I'd really recommend you look those over and pick the one that appears the easiest for you, and to most closely fit the way you prefer to work.Of them, the most comfortable for me to work with was , due to the lightweight nature of component building and simplicity of page templating.  That goes doubly so if you are using your own db code instead of Hibernate or some other framework (I was never completely happy with Wicket Hibernate or Spring Integration). is great if you don't mind writing all of your layout in Java.  I know that is different now, but I still think that product serves a fairly narrow niche.  They change the development model with every major release as well it seems. is a great product, but it is obviously very different from the others in terms of development model as it is led mainly by one dude.  Howard Lewis Ship is no doubt quite smart, but I am disappointed with their decision to basically forget backwards compatibility with each release.  Again, though, for your needs this may not matter, and I've always found the Tapestry products pleasurable to work against. has been out for years, and still feels like something that a  guy built to fix all of the problems of Struts.  Without really understanding all of the problems with Struts.  It still has an unfinished feel to it, although the product is obviously very flexible.  I use it and have some fondness for it, with great hopes for its future.  I think the next release (2.0) to be delivered in JEE6 will really bring it into its own, with a new template syntax (similar to Facelets) and a simplified component model (custom components in only 1 file... finally).And, of course, there are a million smaller frameworks and tools that get their own following ( for basic needs, raw , Struts, etc).  I generally prefer component oriented frameworks myself, though.  In the end, I'd recommend just taking a look at Tapestry, Wicket, and JSF and just picking the one that feels the best to you.  You'll probably find one that just fits the way you like to work very quickly.My favorite is the Spring Framework. With 2.5 Spring MVC is soooo kick ass, with new annotations, convention over configuration features, etc.If you're just doing something super simple you could also just try using the regular Servlet API and not bother with a framework.I recommend the component oriented  framework. It allows you to write your web application in plain old Java code, you can use POJOs as the model for all components and don't need to mess around with huge XML configuration files. I had successfully developed an online banking application with Struts when I discovered Wicket and saw how easy web application development can be!I've recently started using the . If you're looking for a request based framework that's really easy to use, but doesn't impose any limits on what you are doing I'd highly recommend it.It's similar to struts, but it goes way beyond it. There are even some plugin projects that enable you to do use hibernate or jpa with very little configuration.There are a lot of good frameworks out there though I've heard wicket is a good one as well, but I haven't used it.Another one to consider would be Grails.Although it isn't strictly a Java framework, it depends on Groovy (if you haven't seen this before, this is a dynamic language that runs on the JVM). Most valid Java is also valid Groovy, so it is pretty easy to learn.My last project used Grails, and whilst I'd never used Groovy before, I discovered:There is a downside: it is a very \"clever\" framework that hides a lot from you, so when things go wrong it can be very time consuming to find the problem.The project I mentioned would simply not have shipped on time or on budget if we'd gone for a more traditional framework (even one that we're familar and skilled with such as SpringMVC), so Grails is definitely one that we'll continue to pick in the future.(but +1 for Wicket and Stripes, two excellent frameworks).Haven't tried it myself, but I thinkhas a lot of potential...coming from php and classic asp, it's the first java web framework that sound promising to me....UPDATE: Tapestry 5.2 is out, so it's not abandoned, as it previously appeared to be. My experience is with Tapestry 4, not 5, so your mileage may vary. My opinion of Tapestry has changed over the years; I have modified this post to reflect it.I can no longer recommend Tapestry as I did previously. Tapestry 5 appears to be a significant improvement, but my main issue with Tapestry is not with platform itself; it's with the people behind it.Historically, every major version update of Tapestry has broken backwards compatibility with extreme prejudice, far more than one might expect. This seems to be due to the incorporation of new coding techniques or technologies that require significant rewrites.Howard Lewis Ship (the principal author of Tapestry) is certainly a brilliant developer, but I can't say I care for his management of the Tapestry project. Development of Tapestry 5 began almost immediately after Tapestry 4 shipped. From what I can tell, Ship pretty much devoted himself to that, leaving Tapestry 4 in the hands of other contributors, who I feel are not nearly as capable as Ship. After having made the painful switch from Tapestry 3 to Tapestry 4, I felt that I had been abandoned almost immediately.Of course, with the release of Tapestry 5, Tapestry 4 became a legacy product. I wouldn't have a problem with this if the upgrade path wasn't so brutal . So now our development team is in the rather unenviable position: We could continue to use an essentially abandoned web platform (Tapestry 4), make the heinous upgrade to Tapestry 5, or give up on Tapestry entirely and rewrite our application using another platform. None of these options is very attractive.Tapestry 5 is supposedly written so as to reduce the likelihood of update breakage from this point forward. A good example is in the page classes: in previous incarnations, page classes descended from a base class provided by Tapestry; incompatible API changes in this class were the cause of a large number of backward compatibility problems. In Tapestry 5, pages are POJOs which are enhanced at runtime with the \"magic Tapestry fairy dust\" via annotations. So as long as the contract for the annotations is maintained, changes to Tapestry won't affect your page classes.If this is right, then writing a new application using Tapestry 5 could turn out well. But personally, I don't feel like putting my hand on the burner again. If you are doing something RIAish, you might want to take look at . It's an open source UI-oriented AJAX framework that, to me, is nice to use (I come from a PHP background myself).There's a  that compares doing the same application (i.e. two applications with the same set of features) in Icefaces and Vaadin. In a nutshell, it states that the UI development was considerably faster. Even though the study is hosted at the company's wiki, I can assure that it's objective, genuine and truthful, although I can't force you in believing me.After a long while of testing various solutions, for me it turned out to be:One month of an extraordinarily steep learning curve, but now I am happy.I would also like to mention that I was just a little step away from skipping all that Java stuff and learing Scala/LIFT instead. As far as I am concerned, everything in Java that is related with cutting edge web development (comet, async communication,  (yes, even with Spring Security!)) still is a bit of a hack (proove me wrong by evidence, pleeease!). To me, Scala/LIFT seems to be a more out-of-the-box and all-in-one solution.The reason why I finally decided  to go with Scala isCheers\nEr My pick is Wicket!!I've heard good things about the Spring Framework too.  In general, though, I've been underwhelmed by most Java web frameworks I've looked at (esp Struts).  For a simple app I'd definitely consider using \"raw\" servlets and JSPs and not worry about adopting a framework.  If the servlets are well written, it should be straightforward in the future to port to a framework if necessary when the app grows in complexity.All of them - that's the problem ;-)I think for your modest requirements, you just need to code up servlets or simple jsp pages that you can serve from Tomcat server. I dont think you need any kind of web-framework (like struts) for personal web-site dataSaying \"use JSF\" is a little to simple. When you decide to use JSF, you have to choose a component library on top of it. Will you use MyFaces Tomahawk, Trinidad, Tobago ()? Or maybe ICEfaces ()? Oh, and if you use ICEfaces, will you use JSPs or Facelets for your views?In my opinion it is to hard to tell. Nobody has the time to evaluate all the promising alternatives, at least in the projects I work on, because they are not big enough to do three month evaluation phases. However, you should look around for some that has a big and active community and isn't gone in a year. JSF is around for some time, and since it gets pushed by sun, it will be around for some more. I can't say if it's the best choice, but it will be a good one. - the good oneFor high traffic sites I'd use a framework that doesn't manage client state on the server - Wicket, JSF and Tapestry are managing client state on the server. I'd only use those frameworks (Wicket is my favourite) if the application should be more like a desktop application. But I'd try to use a more scalable and simple REST+AJAX approach though.Spring MVC would be a candidate, but since Spring MVC 3 it has a strange annotation overloaded programming model which doesn't use the benefits of static typing. There ore other ugly things like output parameters in methods combined with a usual return, so there are two output channels of one method. Spring MVC also tends to reeinvent the wheel and you'll have more to configure compared to other frameworks. I cannot really recommend Spring MVC though it has some nice ideas.Grails is a convenient way to use Spring MVC and other established frameworks like Hibernate. Coding is fun and you'll quickly see results.And don't forget that the Servlet API with a few little helpers like FreeMarker for templating is very powerful.I have evaluated quite a few frameworks and Vaadin () has percolated all the way to the top. You should at least give it a short evaluation. Cheers! My pick would be Wicket (for large projects and a predictable user base), GWT (for large projects that are mostly public facing) or just a service framework (like Jersey/ JAXRS) together with a JavaScript toolkit (for small to medium projects).I recommend Seam, especially if you need persistence.See a few comments on some Java application Frameworks (second paragraph):For  GUI you can use JSF with  library.\nRichfaces UI components are easy to use and handy references available with code demonstration in the demo site. Probably later when your site has more data to handle and lot of information has to be transacted in database you can plug any database access framework (ORM) with it. Can't believe no one has mentioned GWTMy favorite way to go for really simple apps is Apache VelocityTools (VelocityLayoutServlet) with Velosurf ().For more complex apps, Spring MVC or Struts 2.Try HybridJava - that is much simpler than anything else.I would say  or "},
{"body": "So I'm declaring and initializing an int array:Say I do this instead... ...  will print to standard out. Also, if I do this:...  will print to standard out. So how is Java initializing my array by default? Is it safe to assume that the default initialization is setting the array indices to  which would mean I don't have to loop through the array and initialize it? Thanks.Everything in a valid Java program not explicitly set to something by the programmer, is initialized to a zero value.  When you create an array of something, all entries are also zeroed.  So your array contains five zeros right after it is created by .From the : clearly says and this is irrespective of whether the array is an instance variable or local variable or class variable.Default values for primitive types : For objects default values is .According to java,Java says that the default length of a JAVA array at the time of initialization will be 10.But the  method returns the number of inserted elements in the array, and since at the time of initialization, if you have not inserted any element in the array, it will return zero.Every class in Java have a constructor ( A constructor is a method which is called when a new object is created , which initializes the fields of the class variables ) . So when you are creating an instance of the class , constructor method is called while creating the object and all the data values are initialized at that time .For object of integer array type all values in the array are initialized to 0(zero) in the constructor method .\nSimilarly for object of boolean array , all values are initialized to false . Thorbj\u00f8rn Ravn Andersen answered for most of the data types. Since there was a heated discussion about array,Quoting from the jls spec \n\"array component is initialized with a default value when it is created\"I think irrespective of whether array is local or instance or class variable it will with default values"},
{"body": "I know that multiple inheritance is not allowed in Java and C#. Many books just say, multiple inheritance is not allowed. But it can be implemented by using interfaces. Nothing is discussed about why it is not allowed. Can anybody tell me precisely why it is not allowed?The short answer is: because the language designers decided not to.Basically, it seemed that both the .NET and Java designers did not allow multiple inheritance because they reasoned that adding MI  to the languages while providing .For a more fun and in-depth read, there are some articles available on the web with interviews of some of the language designers. For example, for .NET, Chris Brumme (who worked at MS on the CLR) has explained the reasons why they decided not to:For Java, you can read :Multiple inheritance of  is what is not allowed.  The problem is that the compiler/runtime cannot figure out what to do if you have a Cowboy and an Artist class, both with implementations for the draw() method, and then you try to create a new CowboyArtist type.  What happens when you call the draw() method?  Is someone lying dead in the street, or do you have a lovely watercolor?I believe it's called the double diamond inheritance problem.Because Java has a greatly different design philosophy from C++.  (I'm not going to discuss C# here.)In designing C++, Stroustrup wanted to include useful features, regardless of how they could be misused.  It's possible to screw up big-time with multiple inheritance, operator overloading, templates, and various other features, but it's also possible to do some very good things with them.The Java design philosophy is to emphasize safety in language constructs.  The result is that there are things that are a lot more awkward to do, but you can be a lot more confident that the code you're looking at means what you think it does.Further, Java was to a large extent a reaction from C++ and Smalltalk, the best known OO languages.  There are plenty of other OO languages (Common Lisp was actually the first one to be standardized), with different OO systems that handle MI better.Not to mention that it's entirely possible to do MI in Java, using interfaces, composition, and delegation.  It's more explicit than in C++, and therefore is clumsier to use but will get you something you're more likely to understand at first glance.There is no right answer here.  There are different answers, and which one is better for a given situation depends on applications and individual preference.\nJava is very popular and easy to code, because of its simplicity.So what ever java developers feel difficult and complicated to understand for programmers, they tried to avoid it. One such kind of property is multiple inheritance. Diamond problem.: This is the ambiguity existing in diamond problem.It is not impossible to solve this problem, but it creates more confusion and complexities to the programmer while reading it.\n: But any way you can always implement multiple inheritance indirectly by using interfaces.The main (although by no means the only) reason people steer away from MI is the so called \"diamond problem\" leading to ambiguity in your implementation. This  discusses it and explains better than I could. MI can also lead to more complex code, and a lot of OO designers claim that you do't need MI, and if you do use it your model is probably wrong. I'm not sure I agree with this last point, but keeping things simple is always a good plan.In C++ multiple inheritance was a major headache when used improperly. To avoid those popular design issues multiple interfaces \"inheritance\" was forced instead in modern languages (java, C#).Another reason is that single-inheritance makes casting trivial, emitting no assembler instructions (other than checking for the compatibility of the types where required). If you had multiple-inheritance, you'd need to figure out where in the child class a certain parent starts. So performance is certainly a perk (although not the only one).Multiple Inheritance isTherefore, it can be considered a wise choice to  include Multiple Inheritance into the Java language.I take the statement that \"Multiple inheritance is not allowed in Java\" with a pinch of salt.Multiple Inheritance is defined when a \"Type\" inherits from more than one \"Types\". And interfaces are also classified as types as they have behavior. So Java does have multiple inheritance. Just that it is safer.Dynamic loading of classes makes the implementation of multiple inheritance difficult.In java  actually they avoided the complexity of multiple inheritance instead by using single inheritance and interface. \nComplexity of multiple inheritance is very high in a situation like below explained\nWe have two classes B and C inheriting from A. Assume that B and C are overriding an inherited method and they provide their own implementation. Now D inherits from both B and C doing multiple inheritance. D should inherit that overridden method, jvm can't able to decide which overridden method will be used?In c++ virtual functions are used to handle and we have to do explicitly.This can be avoided by using interfaces, there are no method bodies. Interfaces cannot be instantiated\u2014they can only be implemented by classes or extended by other interfaces.Java has concept, i.e. polymorphism. There are 2 types of polymorphism in java. There are method overloading and method overriding. Among them, method overriding happens with super- and subclass relationship. If we are creating an object of a subclass and invoking the method of superclass, and if subclass extends more than one class, which super class method should be called?Or , while calling superclass constructor by , which super class constructor will get called?This decisions are impossible by current java API features. so multiple inheritance is not allowed in java.Back in the old days ('70s) when Computer Science was more Science and less mass production the programmers had time to think about good design and good implementation and as a result the products (programms) had high quality ( eg. TCP/IP design and implementation ). \nNowadays, when everybody is programming, and the managers are changing the specs before deadlines, subtle issues like the one descriped in the wikipedia link from Steve Haigh post are difficult to track; therefore, the \"multiple inheritance\" is limited by compiler design. If you like it, you can still use C++ .... and have all the freedom you want :) Actually multiple inheritance will arise a the complexity if the inherited classes have same function. ie the compiler will have a confusion which one has to chose (diamond problem). So in Java that complexity removed and gave interface to get the functionality like multiple inheritance gave. We can use interface Multiple Inheritance is not allowed in Java directly , but through interfaces it is allowed.Reason :  Introduces more complexity and ambiguity. Interfaces are completely abstract classes in Java that provide you with a uniform way to properly delineate the structure or inner workings of your program from its publicly available interface, with the consequence being a greater amount of flexibility and reusable code as well as more control over how you create and interact with other classes. More precisely, they are a special construct in Java with the additional characteristic that allow you to perform a kind of multiple inheritance i.e. classes that can be upcast to more than one class.Lets take simple example.You can find answer from this documentation  If multiple inheritance is allowed and when you create an object by instantiating that class, that object will inherit fields from all of the class's super classes. It will cause two issues.Even though multiple inheritance of state is now allowed, still you can implement : Ability of a class to implement more than one interface. (through default methods in interfaces) : Ability to inherit method definitions from multiple classesRefer to this related SE question for additional info:Imagine this Example:\nI have a class It has  method:There is another class  that one also has same method Now I have a child class Circle, it derives from both Shape1 and Shape2;Now when I create object for Circle, and call the method, system does not know which calculate area method to be called. Both has same signatures. So compiler will get confuse. That's why multiple inheritances are not allowed.But there can be multiple interfaces because interfaces do not have method definition. Even both the interfaces have same method, both of them do not have any implementation and always method in the child class will be executed."},
{"body": "I often encounter methods which look like the following:What happens if this method is called without passing it final parameters. i.e. an Object1 that is later changed (so is not declared as final) can be passed to this method just fineJava always makes a copy of parameters before sending them to methods. This means the final doesn't mean any difference for the calling code. This only means that inside the method the variables can not be reassigned. (note that if you have a final object, you can still change the attributes of the object).There is a circumstance where you're  to declare it final --otherwise it will result in compile error--, namely passing them through into anonymous classes. Basic example:Removing the  modifier would result in compile error, because it isn't guaranteed anymore that the value is a runtime constant. Changing the value from outside the anonymous class would namely cause the anonymous class instance to behave different after the moment of creation.Java is only pass-by-value. (or better - pass-reference-by-value)So the passed argument and the argument within the method are  handlers pointing to the same object (value). Therefore if you change  of the object, it is reflected to every other variable that's referencing it. But if you re-assign a new object (value) to the argument, then other variables pointing to this object (value) do not get re-assigned.The  keyword on a method parameter means absolutely nothing to the caller. It also means absolutely nothing to the running program, since its presence or absence doesn't change the bytecode. It only ensures that the compiler will complain if the parameter variable is reassigned within the method. That's all. But that's enough.Some programmers (like me) think that's a very good thing and use  on almost every parameter. It makes it easier to understand a long or complex method (though one could argue that long and complex methods should be refactored.) It also shines a spotlight on method parameters that  marked with .Consider this implementation of foo():Because the  instance would outlive the method, this wouldn't compile without the  keyword --  tells the compiler that it's safe to take a copy of the reference (to refer to it later). Thus, it's the  that's considered final, not the . In other words: As a caller, you can't mess anything up... means you can't change the value of that variable once it was assigned.Meanwhile, the use of  for the arguments in those methods means .\nThis only means that inside the method the  variables can not be reassigned.If you declare any parameter as final, you cannot change the value of it.Ouput : Compile Time Error For more detail visit: Nearly all of the things have been said about  method parameters in ; but I would like to add a tiny simple thing that you can think of this  method parameter like  pass-by-reference parameters in  like =>@stuXnet, I could make the exact opposite argument. If you pass an object to a function, and you change the properties of the passed object then the caller of the function will see the changed value in its variable. This implies a pass by reference system, not pass by value.What is confusing is the definition of pass by value or pass by reference in a system where the use of pointers is completely hidden to the end user. Java is definitely NOT pass by value, as to be such, would mean one could mutate the passed object and the original would be unaffected. Notice you cannot mutate primitives you can only assign them to variables. So testing a\nPass by reference or by value by using primitives is not a test.  What you cannot do in Java that can be done in other languages is to reassign the caller's variables to a new value because there are no pointers in Java, so this makes it confusing. final keyword in the method input parameter is not needed. Java creates a copy of the reference to the object, so putting final on it doesn't make the object final but just the reference, which doesn't make senseStrings are immutable, so actully you can't change the String afterwards (you can only make the variable that held the String object point to a different String object).However, that is not the reason why you can bind any variable to a  parameter. All the compiler checks is that the parameter is not reassigned  the method. This is good for documentation purposes, arguably good style, and may even help optimize the byte code for speed (although this seems not to do very much in practice). But even if you do reassign a parameter within a method, the caller doesn't notice that, because java does all parameter passing by value. After the sequencethe fields of a may have changed, but a is still the same object it was before. In pass-by-reference languages this may not be true."},
{"body": "How can I open a link in default browser with a button click, along the lines of?Use the  method.  It opens a URI in the user's default browser.note: you have to include necessary imports from A solution without the Desktop environment is . This solution is more general as on Linux, Desktop is not always available.The lenghty answer is posted at "},
{"body": "I always thought that  operator in Java is used for verifying whether both its boolean operands are , and the  operator is used to do Bit-wise operations on two integer types.Recently I came to know that  operator can also be used verify whether both its boolean operands are , the only difference is that it checks the RHS operand even if the LHS operand is false.Is the  operator in Java internally overloaded? Or is there some other concept behind this? & <-- verifies both operands\n&& <-- stops evaluating if the first operand evaluates to false since the result will be false <-- this means evaluate  then evaluate  then do the &. the problem is that for x=0 this will throw an exception. <-- this means evaluate  and only if this is true then evaluate  so if you have x=0 then this is perfectly safe and won't throw any exception if (x != 0) evaluates to false the whole thing directly evaluates to false without evaluating the .EDIT: <-- this means evaluate  then evaluate  then do the . <-- this means evaluate  and only if this is  then evaluate  and do the .Besides not being a lazy evaluator by evaluating both operands, I think the main characteristics of bitwise operators compare each bytes of operands like in the following example:It depends on the type of the arguments...For integer arguments, the single ampersand (\"&\")is the \"bit-wise AND\" operator. The double ampersand (\"&&\") is not defined for anything but two boolean arguments.For boolean arguments, the single ampersand constitutes the (unconditional) \"logical AND\" operator while the double ampersand (\"&&\") is the \"conditional logical AND\" operator. That is to say that the single ampersand always evaluates both arguments whereas the double ampersand will only evaluate the second argument if the first argument is true.For all other argument types and combinations, a compile-time error should occur.&& is a short circuit operator whereas & is a AND operator.Try this.it's as specified in the :The \"trick\" is that  is an  as well as an . So why not, seeing this as an example for  is reasonable. and  are called short circuit operators. When they are used, for  - if the first operand evaluates to , then the rest of the operands are not evaluated. For  - if the first operand evaluates to , the rest of them don't get evaluated at all.so  in this example the variable x won't get incremented if a was .\u2018&&\u2019 : - is a Logical AND operator produce a boolean value of true or false based on the logical relationship of its arguments.For example: - Condition1 && Condition2If Condition1 is false, then (Condition1 && Condition2) will always be false, that is the reason why this logical operator is also known as Short Circuit Operator because it does not evaluate another condition. If Condition1 is false , then there is no need to evaluate Condtiton2.If Condition1 is true, then Condition2 is evaluated, if it is true then overall result will be true else it will be false.\u2018&\u2019 : - is a Bitwise AND Operator. It produces a one (1) in the output if both the input bits are one. Otherwise it produces zero (0).For example:-int a=12; // binary representation of 12 is 1100int b=6; // binary representation of 6 is 0110int c=(a & b); // binary representation of (12 & 6) is 0100The value of c is 4.for reference , refer this With booleans, there is no output difference between the two. You can swap && and & or || and | and it will never change the result of your expression.The difference lies behind the scene where the information is being processed. When you right an expression \"(a != 0) & ( b != 0)\"  for a= 0 and b = 1, The following happens:When you write an expression  when a= 0 and b = 1, the following happens:Less steps, less processing, better coding, especially when doing many boolean expression or complicated arguments.I think my answer can be more understandable:There are two difference between   and . and  can be logical , when the  or  left and right expression result all is true, the whole operation result can be true.when  and  as  logical , there is different,:when use  as logical , if the left expression result is false, the right expression will not execute.Take the example :If use :An other more example: can be use as Bitwise  operator,   can not.From the wiki page:& is a bitwise operator plus used for checking both conditions because sometimes we need to evaluate both condition.\nBut && logical operator go to 2nd condition when first condition give true.all answers are , and it seems that  more answer \nbut I just wonted to point out something about  operator called In expressions using operator &&, a condition\u2014we\u2019ll call this the \u2014may require another condition to be true for the evaluation of the dependent condition to be meaningful. In this case, the dependent condition should be placed after the && operator to prevent errors.Consider the expression . The dependent condition  must  the  operator to prevent the possibility of division by zero.another example   and another thing:  and  are called  because the second argument is executed or evaluated  the  argument does  to  the  of the References:  "},
{"body": "I have switched to JUnit4.4 from JUnit3.8. I run my tests using ant, all my tests run successfully but test utility classes fail with \"No runnable methods\" error. The pattern I am using is to include all classes with name *Test* under test folder.I understand that the runner can't find any method annotated with @Test attribute. But they don't contain such annotation because these classes are not tests.\nSurprisingly when running these tests in eclipse, it doesn't complain about these classes.In JUnit3.8 it wasn't a problem at all since these utility classes didn't extend TestCase so the runner didn't try to execute them. I know I can exclude these specific classes in the junit target in ant script. But I don't want to change the build file upon every new utility class I add. I can also rename the classes (but giving good names to classes was always my weakest talent :-) )Is there any elegant solution for this problem?Assuming you're in control of the pattern used to find test classes, I'd suggest changing it to match  rather than . That way  won't get matched, but  will.Annotate your util classes with @Ignore. This will cause JUnit not to try and run them as tests.My specific case has the following scenario.  Our tests all extend and JUnit was trying to run BaseTixContainerTest.  Poor BaseTixContainerTest was just trying to setup the container, setup the client, order some pizza and relax... man.  As mentioned previously, you can annotate the class with But that caused JUnit to report that test as skipped (as opposed to completely ignored).  That kind of irritated me. So I made BaseTixContainerTest abstract, and now JUnit truly ignores it.To prevent JUnit from instantiating your test base class just make it (@Ignore reports it as ignored which I reserve for  ignored tests.)Ant now comes with the  attribute which was designed to do exactly what you seem to be looking for. No need to change your base classes to abstract or add annotations to them.What about adding an empty test method to these classes? Be careful when using an IDE's code-completion to add the import for . It has to be  and not , for example. If you do the latter, you'll get the \"no runnable methods\" error.I was also facing a similar issue (\"no runnable methods..\") on running the simplest of simple piece of code (Using @Test, @Before etc.) and found the solution nowhere. I was using Junit4 and Eclipse SDK version 4.1.2. Resolved my problem by using the latest Eclipse SDK 4.2.2. I hope this helps people who are struggling with a somewhat similar issue."},
{"body": "When trying to start my JUnit-Test out of Eclipse, I get a \"ClassNotFoundException\". When running \"mvn test\" from console - everything works fine. Also, there are no problems reported in Eclipse.My project structure is the following:edit: How can the class not be found? It's a simple HelloWorld-Application with no special libraries.Here's my JUnit's run-configuration:\nTestclass (but as I said; it doesn't work with a simple HelloWorld either...):Carlos approach helped!\nTry to check the classpath of the junit run configuration:works for me.I've come across that situation several times and, after a lot of attempts, I found the solution. Go one by one though each source-folder of your project and set the output folder that maven would use. For example, your web project's  should have  under the web project, test classes should have  also under the web project and so.Using this configuration will allow you to execute unit tests in eclipse.Just one more advice, if your web project's tests require some configuration files that are under the resources, be sure to include that folder as a source folder and to make the proper build-path configuration.Hope it helps.your build classpath is correct, which is why you can compile.  the classpath for your JUnit needs to be checked.  go to the Run menu and choose 'open run dialog.'  in there you should see a tree on the left with JUnit as an option.  open that node and find and select your test.  on the right pane you will see a tab for classpath.  take a look to ensure that your class that the test is trying to instantiate would be found.this seems to be an issue with maven and its behavior after a release changed the default Eclipse output folders.  i have seen solutions described where with the first three, there were reports of the issue recurring.  the last looks best to me, but if it doesnt work, please try the others. and  is some infoThe problem might be missing the class file in your build folder. One solution is clean the project and rebuild it. This was my solution to the problem. Of course, many things can cause it to occur. For me it was that Maven2 (not the plugin for Eclipse) was setting the eclipse profile up to use a different builder (aspectJ) but I did not have the plugin in eclipse./Cheers\nRamon BucklandThere are many convoluted suggestions here.I've encountered this problem multiple times with Maven projects after moving resources around by drag 'n' drop, or performing refactoring of class names.If this occurs, simply copy (not move) the problem Test Case () via terminal/file browser to another location,  in Eclipse and choose to delete on disk when given the option, move/copy the copied file to the original file location, then select your project in Eclipse and press F5 to refresh resources.This is quick and easy to do, and has fixed the problem permanently for me every time.Sachin's right:\nEven with correct class path, the problems tab will show that some dependency or the Resource/project has error that needs to be fixed in order for maven to automatically build and create classes when you create or make a change in your test class.\"Hi,Its very Old Jul (which year) but I had the same problem .Actual issue found that eclipse was not able to generate class file for the java file , classpath was proper.See the problem tab and check if your project is missing something/file. you can create a new proj and add files one by one and build them until it stops compiling and creating classes ( check the workspace/proj/bin/package/ folder for classes )its wierd but true , ecplise was failing in compliation because 4 of 20 java files were using a single image which was missing. and as result none of the java file was compiled .CLASSPATH is not a issue here.\"We had the exact exception (using SpringSource Tools, tomcat, on Win7) and the cause was that we had refactored a filename (renamed a file) from SubDomain.java to Subdomain.java (D vs d) and somehow it collided though SpringSource was showing the new name Subdomain.java. The solution was to delete the file (via SpringSource) and create it again under the name Subdomain.java and copy-pasting its former content. Simple as that.I had the exact same problem but I figured it out! Go to your project file and right click on it, then click  or hit F5. Then try and run it.  If it still doesn't work then just forget it, as I had the EXACT same problem and it just means you version of Eclipse is garbage.All I did was Properties -> Java Build Path -> Order and Export -> Enabled all unchecked boxes -> moved Junit all the way upHmm, looks a little bizarre, try running it with the following annotation at the top of the class:and let me know how you get on with it.    Check that you have build automatically enabled as well.  If you want to make sure your test classes are being compiled correctly clear out the Maven target folder (and any bin folder that Eclipse may be using).  Are you using m2eclipse as well, as I find it to be a little problematic.The solution to my problem which was similar: the libs were invalid. If you look in the .classpath file of the project, you'll see classpathentry tags with the key/value kind=\"lib\". Some of mine were incorrect.I didn't discover this until I turned off Validation settings. That is, there were so many errors in the JSP files, etc, that the classpath errors weren't evident (or possibly even showing up). As a result, nothing was being compiled into the destination output folders, but no helpful errors on why.click on  and check each  folder is still valid exist or recently removed. Correct any missing path or incorrect path and rebuild and run the test. It will fix the problem.  Maven 2 LifeCycle >> test I had tried all of the solutions on this page: refresh project, rebuild, all projects clean, restart Eclipse, re-import (even) the projects, rebuild maven and refresh.  Nothing worked.  What  work was copying the class to a  which runs fine -- bizarre but true.After putting up with this for some time, I just fixed it by:Something must have been screwed up with the cached run configuration.I was hit with this issue also and was able to come up with a sufficient solution for my case.  If your Eclipse project has a .classpath file in your project root (see it in Navigator view instead of Package Explorer view), be sure that your Maven classpathentry appears prior to your JRE Container classpathentry.If your project does not have a .classpath file, you can edit your project's Java Build Path to switch the Order and Export.  If your project has the .classpath file and you only change your ordering in the Java Build Path, you will see that the ordering is not impacted and the issue will continue to occur.And a project->clean never hurts things after you make the change.Deleting the project from eclipse (Not from hard disk) which in a way is cleaning the workspace and reimporting the project into eclipse again worked for me.I solve that Bulit path--->libraries--->add library--->Junit  check junit4Have you tried right clicking on your project root, selecting \"properties\", and making sure that the CLASSPATH is correct?  If I recall correctly, that's how you do it.Anything about the way Eclipse runs unit tests that requires you to add the junit JAR to the runtime CLASSPATH in a special way?I use IntelliJ, so I don't have these issues.  I'd check Eclipse myself, but I prefer not having it on my desktop.Please point to correct JDK from Windows > Preferences > Java > Installed JRE.Do not point to jre, point to a proper JDK. I pointed to JDK 1.6U29 and refreshed the project.Hereafter, the issue is gone and jUnit Tests are working fine.Thanks,\n\n-TapasI've run into a same error in Eclipse recently, i.e., the Eclipse IDE couldn't find the Unit test class no matter how I change the configurations. Learning from the previous posts here and in other web sites, I've double checked and triple checked the classpath and source info, and move up and down the source folder and libraries, in both the \"Run Configuration\" and the \"Java Build Path\" config windows, and I've also cleaned the Project and rebuilt it, but none of the tricks work for me. The specific Java project is an old ANT compiled project and have lots of jars included in Eclipse library.Then, I changed the unit test class to add a main() method and right click it to \"Run As\" a Java Application instead of JUnit test, and suddenly, Eclipse seems to wake up and identified the class correctly. Afterwards, I switched it back to a Unit test application, and it is still working.This seems to be a bug in Eclipse, I am guessing the large number of libraries (>260) may confused the JVM's ability to locate my JUnit class. Make sure your test launch configuration does NOT contain the following lines, OR try enabling automated Maven dependency management.I tried everything I read in this long post and, incredibly, what worked for me was, rather than clicking on the test class and selecting , clicking on the test  and running as . I have no idea why?JUnit test from inside eclipse gave me also NoClassDefFoundError.\nRunning 'mvn clean test' from command line gave me following error on several jars:\ninvalid LOC header (bad signature)\nDeleting these jars from local m2 repository and running 'mvn clean test' again\nsolved my problem.I had the same problem. All what I did was, i). Generated Eclipse artifacts ii). Refresh the project and rerun your junit test. Should work fine. Furthermore, DOUBLE-CHECK the eclipse \"Web Deployment Assembly\" dialog.  This can be found: Project Properties->Deployment Assembly.   Recently I had an eclipse plugin modify one of my web projects, and it added ~mysteriously~ added  the maven test directories  /src/test/java, /src/test/resources to the Deployment Assembly.   UGGGG!!!   Which is why my project worked fine when I built & deployed just straight maven to tomcat, no ClassNotFoundExceptions...  However, when I did the deploy through Eclipse, Whammo!! I start getting ClassNotFoundExceptions because the TestCode is getting deployed.  EricThat means your pom.xml has unresolved issues. Open the problems view solve accordingly. Then you will be able to run the test cases successfully without encountering the classnotfoundexception.Changing the order of classpath artifacts in the Java Build Path resolved it for me.This should fix it.JUnit 4.4 is not supported by the JMockit/JUnit integration. Only\nversions 4.5 or newer are supported that. while running web applications Most of us will get this Exception. When you got this error you have place .class files in proper folder. In web applications all .class files should sit in WEB-INF\\Classes folder.\nif you are running web app in Eclipse please follow the stepsStep 1: Right click on Project folder and Select Properties\nStep 2: Click on \"Java Build Path\" you will see different tabs like \"source\" , \"projects\", \"libraries\" etc\nStep 3: select Source folder. under this you will see your project details\nStep 4: in the \"Source\" folder you will see Default Output Folder option. here you have to give the classes folder under WEB-INF.\njust give the path like projectname/WebContent/WEB-INF/classes\nthe structure depends on your application\nplease do remember here you no need to create \"classes\" folder. Eclipse will create it for you.\nStep 5: click on \"OK\" and do the project clean and Build. that's it your app will run now."},
{"body": "Character.isLetter(c) returns true if the character is a letter. But is there a way to quickly find if a String only contains the base characters of ASCII?Using , you could just write:From Guava 19.0 on, you should use  instead.You can do it with  .Here is another way not depending on a library but using a regex.You can use this single line:Whole example program:Iterate through the string and make sure all the characters have a value less than 128.Java Strings are conceptually encoded as UTF-16.  In UTF-16, the ASCII character set is encoded as the values 0 - 127 and the encoding for any non ASCII character (which may consist of more than one Java char) is guaranteed not to include the numbers 0 - 127Or you copy the code from the  class.commons-lang3 from Apache contains valuable utility/convenience methods for all kinds of 'problems',  including this one. Iterate through the string, and use charAt() to get the char.  Then treat it as an int, and see if it has a unicode value (a superset of ASCII) which you like.Break at the first you don't like.try this:It was possible. Pretty problem."},
{"body": "I have milliseconds in certain log file generated in server, I also know the locale from where the log file was generated, my problem is to convert milliseconds to date in specified format.\nThe processing of that log is happening on server located in different time zone. While converting to \"SimpleDateFormat\" program is taking date of the machine as such formatted date do not represent correct time of the server. Is there any way to handle this elegantly ?Output:You may use  class and then use  to format the .If the millis value is number of millis since Jan 1, 1970 GMT, as is standard for the JVM, then that is independent of time zone. If you want to format it with a specific time zone, you can simply convert it to a GregorianCalendar object and set the timezone. After that there are numerous ways to format it.The easiest way to do this is to use the  and specify both the timestamp in milliseconds and the DateTimeZone you want.I strongly recommend avoiding the built-in Java Date and Calendar classes; they're terrible.The other answers use outmoded or incorrect classes.Avoid the old date-time classes such as java.util.Date/.Calendar. They have proven to be poorly designed, confusing, and troublesome. The  framework comes built into Java 8 and later. Much of the functionality is  and further . Made by the some of the same folks as had made .An  is a moment on the timeline in  with a resolution of . Its  is first moment of 1970 in UTC.Assuming your input data is a count of milliseconds from 1970-01-01T00:00:00Z (not clear in the Question), then we can easily instantiate an .Apply a time zone using a , to get a .You can apply the  of the JVM. Beware that the default can change at any moment . Any code in any thread of any app within the JVM can change the current default. If important, ask the user for their desired/expected time zone.My SolutionThe SimpleDateFormat class has a method called SetTimeZone(TimeZone) that is inherited from the DateFormat class. Easiest way:I do it like this:You can also use  with following parameters:Below is  my solution to get date from miliseconds to date format. You have to use  to get this code run."},
{"body": "When using the Spring 3.0 capability to annotate a scheduled task, I would like to set the  as parameter from my configuration file, instead of hard-wiring it into my task class, like currently...Unfortunately it seems that with the means of the Spring Expression Language (SpEL)  returns a String object which in turn is not able to be auto-boxed to a long value as required by the  parameter.I guess the  annotation is out of question. So maybe a solution for you would be to use  XML configuration. Let's consider this example (copied from ):... or if the cast from String to Long didn't work, something like this would:Again, I haven't tried any of these setups, but I hope it might help you a bit.Spring v3.2.2 has added String parameters to the original 3 long parameters to handle this. ,  and  are now available too.You can use the  annotation, but together with the  parameter only:Your 5 seconds interval could be expressed as . However as I understand you cannot provide less than 1 second precision.I guess you can convert the value yourself by defining a bean. , but I guess the approach similar to the following might be useful for you:where:"},
{"body": "I have seen classes which implement both  and .  What does this mean?  Why would I use one over the other?The text below comes from A comparable object is capable of comparing itself with another object. The class itself must implements the  interface in order to be able to compare its instances.A comparator object is capable of comparing two different objects. The class is not comparing its instances, but some other class\u2019s instances. This comparator class must implement the  interface.Implementing  means \"I can compare myself with another object.\" This is typically useful when there's a single natural default comparison.Implementing  means \"I can compare two other objects.\" This is typically useful when there are multiple ways of comparing two instances of a type - e.g. you could compare people by age, name etc.Comparable lets a class implement its own comparison:By comparison, Comparator is an external comparison:In both implementations, you can still .\nWith generics, you can declare so, and have it checked at compile-time. This improves safety, but it is also a challenge to determine the appropriate value.As a guideline, I generally use the most general class or interface to which that object could be compared, in all use cases I envision... Not very precise a definition though ! :-( is for providing a default ordering on data objects, for example if the data objects have a natural order.A  represents the ordering itself for a specific use.     is usually preferred. But sometimes a class already implements , but you want to sort on a different property. Then you're forced to use a .Some classes actually provide  for common cases; for instance, s are by default case-sensitive when sorted, but there is also a static  called . is for objects with a natural ordering. The object itself knows how it is to be ordered.\n is for objects without a natural ordering or when you wish to use a different ordering.here are few differences between Comparator and Comparable I found on web :site:How to use Comparator and Comparable in Java? With exampleRead more:  is used to compare itself by using with another object. is used to compare two datatypes are objects.If you see then logical difference between these two is  in Java compare two objects provided to him, while  interface compares \"this\" reference with the object specified. in Java is used to implement natural ordering of object. In Java API String, Date and wrapper classes implement  interface.If any class implement  interface in Java then collection of that object either  or  can be sorted automatically by using  or  method and object will be sorted based on there natural order defined by  method.Objects which implement  in Java can be used as keys in a sorted map or elements in a sorted set for example , without specifying any .My annotation lib for implementing Comparable and Comparator:Click the link to see more examples. "},
{"body": "Where can I get an inexpensive Java code signing certificate? Everywhere I look they want USD200 to USD300 per year! Unfortunately I cannot use a self-signed one as I'm trying to get rid of the scary warnings so that users will be more likely to accept my application. And as far as I know (per Stack Overflow question ), it has to be a code signing certificate, it cannot be an  certificate.What about ? They offer code signing certificates for 49.90$ for 2 years (with wild card capabilities). I haven't tried using it, so no guarantees, but it looks good. \nStartSSL is no longer a valid option, even given the previous limitations. ,  and stopped trusting them. So I would encourage everyone their use, given this development. Giving the current state of affairs, this should  be the  anymore. Sorry!How about $80 a year? Tucows  resell for Comodo at their . Again, apparently, they give further discount for 3 years (~$199).I can't confirm any of this without creating an account there (which is, frankly, above my pay grade) but if it is that much and it does work with Java, $66 a year for 3 years doesn't seem too steep.Hopefully GoDaddy will add this to their bag of tricks one day.The prices are as follows:And , they can be used for signing Java apps. Happy days.You can tell if a CA's certs will work for Java code-signing by examining the Java cacerts file, which lists all the CAs known to Java. If their cert is in this file, then Java will not complain about the signed code. If it isn't, then it will warn the users. For example:Note that I had to enter the default keystore password, . This command should work on Windows as well, although you'll have to change the path to the cacerts file and you won't have grep. Use more instead and page through until you find or don't find what you're looking for.As of today, Comodo is in the cacerts file, and startssl aren't. So a startssl cert wouldn't be much good for Java code.You can also get heavily discounted Comodo certificates from:Another good option (don't know how long this will last) is  They give you a real GlobalSign certificate for $99 (usually $229).Despite the lack of branding, the site is run by GlobalSign themselves, and was registered just over two months ago. I have a feeling that they're doing price-testing to see how many more sales they get.Cheapest I can find is $149/year (if you buy 3 years at once) from . Not great, I know! has code-signing certs for $179.95/year and you only need to buy 1 year.  They don't talk about Java.  I don't know if they are different than what you use to sign Microsoft based stuff."},
{"body": "I am looking for a way to view all compile errors in IntelliJ, similar to how they are displayed in Eclipse.  I tried searching here and Google but have not really found a solution.  I really like IntelliJ, I recently converted to it from Eclipse, and I hope this is just something I am missing and not a fundamental deficiency.I think this comes closest to what you wish:(From ):The above can be combined with a recently introduced option in Compiler settings to get a view very similar to that of Eclipse.Things to do:Here is a comparison of what the same project (with a compilation error) looks like in Intellij IDEA 13.xx and Eclipse Kepler: Relevant Links:\nThe maven project shown above : \nFAQ For 'Eclipse Mode' / 'Automatically Compile' a project : "},
{"body": "I'm working on a simple JSP/Servlet/Tomcat webapp for my class. The professor asked us to use a folder structure that is slightly different than the default dynamic web project structure. Rather than using the webcontent folder he wants all of our source code under src/main/java and src/main/webapp.When I run the app my welcome file displays fine, but when I try to access my servlets I get:java.lang.ClassNotFoundException. I'm pretty sure it's a build path error. I have final/src on the build path but I am receiving the warning  I have this in my deployment assembly: When I exclude main/ the warning goes away, but it doesn't fix the problem. I would appreciate any advice. Thanks. I had the same problem even when I created a fresh project. \nI was creating the Java project within Eclipse, then mavenize it, then going into java build path properties removing  and adding  and . When I run Maven update it used to give nested path error. \nThen I finally realized -because I had not seen that entry before- there is a  line in pom file written when I mavenize it. It was resolved after removing it.I wanted to throw in a non-mavenish answer to this thread.Due to version control and strict directory structure reasons, I was unable to follow Acheron's answer (the best answer) of doing something similar to removing  and adding  and  to the build path.I had actually been off-and-on battling this nested build path issue for a couple weeks.  The answer to the problem is hinted in the error message:In your build path, you need to edit your  by clicking on  and then :There you can add  as an .  Then it should allow you to add  to the build path as a separate source folder.Try this:From the libraries tab:Remove your web app libraries:Add them back in:Highlighting \"Web App Libraries\":You have to separate your sources and your target directory where the build output goes. It's also important to note that no class files ever can end up in the source directory. This is not against your professor's advice - actually he's promoting the maven standard source structure going for ./src/main/java and ./src/main/webapp. The second one should hold eg. the mandatory WEB-INF/web.xml file but you will never put actual classes there.What you need to change is your target directory. I suggest going with the same standards and choosing the name \"./target\" for this. All the built files will go in here and packaging that up will result a correct deployable artifact. Should you migrate to using maven later, it'll also help doing this in a scripted, repeatable way.Hope that clears up your issue.For Eclipse compiler to work properly you need to remove final/src from the source path and add final/src/main/java instead. This may also solve your problem as now the build directory won't be inside the Java source folder.I had the same issue and correct answer above did not work for me. What I did to resolve it was to go to  and under the source tab I removed all the sources (which only had one source) and reconfigured them from there. I ended up removing the project from eclipse and import the maven project again in order to clear up the error.Make two folders:  to store the source java code, and\n.You cannot put the source and the webroot together. I think you may misunderstand your teacher."},
{"body": "I have installed java in my  machine using the command . But I am unable to compile a class using javac.Do I need to install any other package? I have tried to locate the  executable but i am unable to locate it. is linked as follows:\n -> \n -> I have seen the following output by :You installed the Java Runtime Environment (JRE) only, which . For , you have to install the . You can install  or , which both include .By the way: you can find out which package provides  with a , e.g.Another note: using  and  is only one possibility to install the JDK. Many people prefer Sun/Oracle's \"original\" SDK. See  and links for alternatives.Worked for me : use the following command:sudo yum install java-1.6.0-openjdk-develI don't know exactly what  will actually install. But to check for javac existence do:preferably as root. If it's not there you've probably only installed the Java runtime (JRE) and not the Java Development Kit (JDK). You're best off getting this from the : as the Linux repos may be slightly behind with latest versions and also they seem to only supply the open-jdk as opposed to the Oracle/Sun one, which I would prefer given the choice.Is the javac executable in a directory that is part of your PATH?I don't know the CentOS equivalent of the Windows path but if you cd to the java sdk directory and run ./javac does anything happen?follow these steps:open terminal go to your root dictionary by typing you will see Library folder Now follow this path Once you get into  you can see the  fileNow you need to get the path of this folder for that just write this command get the path for your ."},
{"body": "I've recently overheard people saying that s (DTO) are an . Can someone please explain why? What are the alternatives?. Once as domain objects, and once as data transfer objects. This , so the architecture needs to get a huge benefit from this separation to be worth it.DTOs are not an anti-pattern. When you're sending some data across the wire (say, to an web page in an ajax call), you want to be sure that you conserve bandwidth by only sending data that the destination will use. Also, often it is convenient for the presentation layer to have the data in a slightly different format than a native business object.I know this is a java-oriented question, but in .Net languages anonymous types, serialization, and linq allow DTOs to be constructed on-the-fly, which reduces the setup and overhead of using them. says:I don't think DTO's are an anti-pattern per se, but there are antipatterns associated with the use of DTO's.  Bill Dudney refers to DTO explosion as an example:There are also a number of abuses of DTO's mentioned here:They originated because of three tier systems (typically using EJB as technology) as a means to pass data between tiers.  Most modern day Java systems based on frameworks such as Spring take a alternative simplified view using POJOs as domain objects (often annotated with JPA etc...) in a single tier...  The use of DTO's here is unnecessary.OO purists would say that DTO is anti-pattern because objects become data table representations instead of real domain objects. Some consider DTOs an anti-pattern due to their possible abuses, they're often used when they shouldn't be/don't need to be. vaguely describes some abuses.If you're building a distributed system, then DTO's are certainly not an anti pattern. Not everyone will develop in that sense, but if you have a (for example) Open Social app all running off JavaScript. It will post a load of data to your API. This is then deserialized into some form of object, typically a DTO/Request object. This can then be validated to ensure the data entered is correct before being converted into a model object. In my opinion, it's seen as an anti-pattern because it's mis-used. If you're not build a distributed system, chances are you don't need them. The intention of a  is to store data from different sources and then transfer it into a database (or ) at once. However, , since the DTO not only stores data, but also transfers it from or to the database/facade. The need to separate data objects from business objects is not an antipattern, since it is probably required to  anyway. Instead of DTOs you should use the Aggregate and Repository Patterns, which separates the collection of objects () and the data transfer (). To transfer a group of objects you can use the  pattern, that holds a set of Repositories and a transaction context; in order to transfer each object in the aggregate separately within the transaction. DTO becomes a necessity and not and an ANTI-PATTERN, is when you have all your domain objects load associated objects EAGERly.\nIf you don't make DTOs, you will have unecessary transfered objects from your business layer to your client/web layer.\nTo limit overhead for this case, transfer rather DTOs.I think the people mean it could be an anti-pattern if you implement all remote objects as DTO's. A DTO is merely just a set of attributes and if you have big objects you would always transfer all the attributes even if you do not need or use them. In the latter case prefer using a Proxy pattern."},
{"body": "The following function produces today's date; how can I make it produce only yesterday's date?This is the output:I only need yesterday's date like below. Is it possible to do this in my function?You are subtracting the wrong number:Use  instead:Then, modify your method to the following:You can do following:Note: if you want further backward date multiply number of day with 24*60*60*1000 for example:Similarly, you can get future date by adding the value to System.currentTimeMillis(), for example:Use Calender ApiTry this one:Try this;changed from your code :}but you do better using .There is no direct function to get yesterday's date.To get yesterday's date, you need to use  by subtracting ."},
{"body": "I am very familiar with C# but starting to work more in Java. I expected to learn that enums in Java were basically equivalent to those in C# but apparently this is not the case. Initially I was excited to learn that Java enums could contain multiple pieces of data which seems very advantageous (). However, since then I have found a lot of features missing that are trivial in C#, such as the ability to easily assign an enum element a certain value, and consequently the ability to convert an integer to an enum without a decent amount of effort (i.e. ).So my question is this: is there any benefit to Java enums over a class with a bunch of public static final fields? Or does it just provide more compact syntax?EDIT: Let me be more clear. What is the benefit of Java enums over a class with a bunch of public static final fields ? For example, in the planets example at the first link, what is the advantage of an enum over a class with these public constants:As far as I can tell, casablanca's answer is the only one that satisfies this.Technically one could indeed view enums as a class with a bunch of typed constants, and this is in fact how enum constants are implemented internally. Using an  however gives you useful methods () that you would otherwise have to implement yourself, such as .Nobody mentioned the ability to use them in  statements; I'll throw that in as well.This allows arbitrarily complex enums to be used in a clean way without using , potentially confusing  sequences, or non-string/int switching values. The canonical example is a state machine.There is less confusion. Take  for instance. It has a constructor that takes the name of the  you want, its size and its style (). To this day I cannot remember if style or size goes first. If  had used an  for all of its different styles (, , , ), its constructor would look like , preventing any confusion. Unfortunately, s weren't around when the  class was created, and since Java has to maintain reverse compatibility, we will always be plagued by this ambiguity.Of course, this is just an argument for using an  instead of  constants. Enums are also perfect for  and implementing default behavior while allowing for later customization (I.E. the ). An example of the latter is 's  and : if a developer wanted to create his own non-standard , he could.The primary advantage is type safety. With a set of constants, any value of the same intrinsic type could be used, introducing errors.  With an enum only the applicable values can be used.For examplevsThere are many good answers here, but none mentiones that there are  of the Collection API classes/interfaces :These enum specific classes only accept  instances (the  only accept s only as keys), and whenever possible, they revert to compact representation and bit manipulation in their implementation.If our  type has no more that 64 elements (most of real-life  examples will qualify for this), the implementations store the elements in a single  value, each  instance in question will be associated with a bit of this 64-bit long . Adding an element to an  is simply just setting the proper bit to 1, removing it is just setting that bit to 0. Testing if an element is in the  is just one bitmask test! Now you gotta love s for this!The first benefit of enums, as you have already noticed, is syntax simplicity. But the main point of enums is to provide a well-known set of constants which, by default, form a range and help to perform more comprehensive code analysis through type & value safety checks.Those attributes of enums help both a programmer and a compiler. For example, let's say you see a function that accepts an integer. What that integer could mean? What kind of values can you pass in? You don't really know right away. But if you see a function that accepts enum, you know very well all possible values you can pass in.For the compiler, enums help to determine a range of values and unless you assign special values to enum members, they are well ranges from 0 and up. This helps to automatically track down errors in the code through type safety checks and more. For example, compiler may warn you that you don't handle all possible enum values in your switch statement (i.e. when you don't have  case and handle only one out of N enum values). It also warns you when you convert an arbitrary integer into enum because enum's range of values is less than integer's and that in turn may trigger errors in the function that doesn't really accept an integer. Also, generating a jump table for the switch becomes easier when values are from 0 and up.This is not only true for Java, but for other languages with a strict type-checking as well. C, C++, D, C# are good examples.example:Limitation of java Constants1) : First of all it\u2019s not type-safe; you can assign any valid int value to int e.g. 99 though there is no coin to represent that value.2) : printing value of any of these constant will print its numeric value instead of meaningful name of coin e.g. when you print NICKLE it will print \"5\" instead of \"NICKLE\"3) : to access the currencyDenom constant we need to prefix class name e.g. CurrencyDenom.PENNY instead of just using PENNY though this can also be achieved by using static import in JDK 1.5Advantage of enum1) Enums in Java are type-safe and has there own name-space. It means your enum will have a type for example \"Currency\" in below example and you can not assign any value other than specified in Enum Constants.2) Enum in Java are reference type like class or interface and you can define constructor, methods and variables inside java Enum which makes it more powerful than Enum in C and C++ as shown in next example of Java Enum type.3) You can specify values of enum constants at the creation time as shown in below example:\npublic enum Currency {PENNY(1), NICKLE(5), DIME(10), QUARTER(25)};\nBut for this to work you need to define a member variable and a constructor because PENNY (1) is actually calling a constructor which accepts int value , see below example.}; refrence:enum Benefits:\nAdd a method converting int to enum which does that. Just add static HashMap containing the mapping.If you really want to convert ord=VAL_200.ordinal() back to val_200 just use: EnumX.values()[ord]An enum is implictly final, with a private constructors, all its values are of the same type or a sub-type, you can obtain all its values using , gets its  or  value or you can look up an enum by number or name.You can also define subclasses (even though notionally final, something you can't do any other way)You get compile time checking of valid values when you use an enum.  Look at Another important difference is that java compiler treats  fields of  and  as literals. It means these constants become inline. It's similar to   preprocessor. see this SO . This is not the case with enums.The biggest advantage is enum Singletons are easy to write and thread-safe :andboth are similar and it handled Serialization by themselves by implementing  I think an  can't be , because under the hood compiler generates subclasses for each  entry.More information From "},
{"body": "I am struggling with this error:I don't understand why this error occurs.I am trying to appear notification at specific time and after searching for a time i found this . I tried everything but my code gives error.Please help me to solve this problem.Here is my MainActivity code:and here is my ReminderService code:and here is my manifest.xml:I don't know where I am going wrong. Am I missing some code?You need to add an empty constructor to your class Explanation from the :The  is used to name the worker thread.: this is only applicable to intent service.Declare a  for If you have your Service declared as an , you also need to make the class Without that you\u00b4ll get the error even if your constructor is correctYou need to add the  to your  class. This is only implicitly added if you don't write a constructor of your own (which you have). See here: "},
{"body": "What is mutex and semaphore in Java ? What is the main difference ?Semaphore can be counted, while mutex can only count to 1.Suppose you have a thread running which accepts client connections. This thread can handle 10 clients simultaneously. Then each new client sets the semaphore until it reaches 10. When the Semaphore has 10 flags, then your thread won't accept new connectionsMutex are usually used for guarding stuff. Suppose your 10 clients can access multiple parts of the system. Then you can protect a part of the system with a mutex so when 1 client is connected to that sub-system, no one else should have access. You can use a Semaphore for this purpose too. A mutex is a .Unfortunately everyone has missed the most important difference between the semaphore and the mutex; the concept of \"\". Semaphores have no notion of ownership, this means that any thread can release a semaphore (this can lead to many problems in itself but can help with \"death detection\"). Whereas a mutex does have the concept of ownership (i.e. you can only release a mutex you have acquired).\nOwnership is incredibly important for safe programming of concurrent systems. I would always recommend using  mutex in preference to a semaphore (but there are performance implications). Mutexes also may support priority inheritance (which can help with the priority inversion problem) and recursion (eliminating one type of deadlock). It should also be pointed out that there are \"binary\" semaphores and \"counting/general\" semaphores. Java's semaphore is a counting semaphore and thus allows it to be initialized with a value greater than one (whereas, as pointed out, a mutex can only a conceptual count of one). The usefulness of this has been pointed out in other posts. So to summarize, unless you have multiple resources to manage, I would always recommend the mutex over the semaphore. Mutex is basically mutual exclusion. Only one thread can acquire the resource at once. When one thread acquires the resource, no other thread is allowed to acquire the resource until the thread owning the resource releases. All threads waiting for acquiring resource would be blocked.Semaphore is used to control the number of threads executing. There will be fixed set of resources. The resource count will gets decremented every time when a thread owns the same. When the semaphore count reaches 0 then no other threads are allowed to acquire the resource. The threads get blocked till other threads owning resource releases.In short, the main difference is  A mutex is used for serial access to a resource while a semaphore limits access to a resource up to a set number. You can think of a mutex as a semaphore with an access count of 1. Whatever you set your semaphore count to, that may threads can access the resource before the resource is blocked.Feabhas's answer is quite important - the mutex checks the thread attempting to release the mutex actually owns it. I've had this as an interview question so its worth trying to remember it.A semaphore is a counting synchronization mechanism, a mutex isn't. A mutex is often known as a binary semaphore. Whilst a semaphore can be created with any non-zero count a mutex is conceptually a semeaphore with an upper count of 1.This question has relevant answers and link to official Java guidance: You compare the incomparable, technically there is no difference between a Semaphore and mutex  it doesn't make sense.\nmutex it's just a significant name like any name in your application logic, it's mean that you\ninitialize a semaphore at \"1\", it's used generally to protect a resource or a protected variable to ensure the mutual exclusion.Mutex is binary semaphore. It must be initialized with 1, so that the First Come First Serve principle is met. This brings us to the other special property of each mutex: . Ergo we have obtained mutual exclusion over some resource. Now you could see that a mutex is a special case of general semaphore."},
{"body": "I am using the String split method and I want to have the last element.\nThe size of the Array can change.I want to split the above Strings and get the last item:I don't know the sizes of the arrays at rumtime :(Save the array in a local variable and use the array's  field to find its length. Subtract one to account for it being 0-based:Or you could use  method on Stringusing a simple, yet generic, helper method like this:you can rewrite:as:Now  has the value directoryWith :, You mean you don't know the sizes of the arrays at compile-time? At run-time they could be found by the value of  and  .Since he was asking to do it all in the same line using split so i suggest this:I always avoid defining new variables as far as I can, and I find it a very good practiceYou can use the  class in Apache Commons: "},
{"body": "I have two tables: tracks and waypoints, a track can have many waypoints, but a waypoint is assigned to only 1 track. In the way points table I have a column called \"trackidfk\" which inserts the track_ID once a track is made, however I have not setup Foreign Key constraints on this column.When I delete a track I want to delete the assigned waypoints, is this possible?. I read about using Triggers but I don't think they are supported in Android.To create the waypoints table:Foreign key constraints with on delete cascade are supported, but you need to enable them.\nI just added the following to my , which seems to do the trick.I declared my referencing column as follows.Since Android 4.1 (API 16)  supports:As the post from e.shishkin says from API 16 up you should enable foreign key constraints in the  method using the Whatever @phil mentioned is good. But you can use another default method available in \n     Database itself to set the foreignkey. That is setForeignKeyConstraintsEnabled(true). For Docs refer  I don't think SQLite supports this out of the box. What I'm doing in my apps is:That way I'm sure that either all the data is deleted or none.Triggers are supported by android and that type of cascade delete is not supported by sqlite.  An example of using triggers on android can be found .  Though using transactions as Thorsten stated is probably just as easy as a trigger.SQLite version in android 1.6 is 3.5.9 so it doesn't support foreign keys...\n\"This document describes the support for SQL foreign key constraints introduced in SQLite version 3.6.19.\"In Froyo it's SQLite version 3.6.22, so ...EDIT: \nto see sqlite version : adb shell sqlite3 -versionNever too old of a question to answer with a more complete answer.Foreign keys with \"on delete cascade\" are supported in SQLite in Android 2.2 and up. But be careful when using them: sometimes an error is reported when firing up one foreign key on one column, but the real problem lies in either another column foreign key constraint in the child table, or some other table thet references this table.Looks like SQLite checks all constraints when firing up one of them. It is actually mentioned in the documentation. DDL versus DML constraint checks."},
{"body": "I have a string arraylist  which contains names of people. I want to sort the arraylist in alphabetical order.I tried to sort the list in above way. But it is displaying the sorted array as:but I don't want to make it case sensitive. I want the result as:Custom  should helpOr if you are using Java 8:The simplest thing to do is:try this codeYou need to use custom comparator which will use , not compareTo.Based on the above mentioned answers, I managed to compare my custom Class Objects like this:Starting from  you can use :It gets a stream from that , then it sorts it (ignoring the case). After that, the stream is converted to an array which is converted to an .If you print the result using:you get the following output:"},
{"body": "Anyone knows some good SQL builder library for Java like  (not maintained anymore it seems). Preferably, a project in active development.Preferably with syntax like , something that will allow to make a query like  and  are two popular choices.I can recommend . It provides a lot of great features, also a intuitive DSL for SQL and a extremly customable reverse-engineering approach. is my best choice:here is create example(groovy):Hibernate Criteria API (not plain SQL though, but very powerful and in active development):You can use the following library:The library is built on the top of the Hibernate \"create sql query\" so it supports all databases supported by Hibernate (the Hibernate session and JPA providers are supported). The builder patter is available and so on (object mappers, result mappers).You can find the examples on github page, the library is available at Maven central of course."},
{"body": "I am working at a commercial android application.\nI am also using some libraries licensed under different license types some of them stating the following:(One of them is licensed under  for example).There is more than one library. When I do the build with  or with  I obtain the following build error:The answers that I found until now on the internet and stackoverflow suggest to remove the license.txt(notice.txt or other files that could interfere like this) from packaging by adding to  file the following:See for example: According to the license of those libraries( for instance), the license and notice files should be .  How can I add multiple files related to licensing(such as ,  etc) from gradle into my project in order to be compliant with the licenses( licences texts will be concatenated)?There is a solution if you have only one license using the name  (read: all  copies are identical):Add following into respective build.gradle file I faced the same issue with my application.\nYou need to make sure you have not added any libraries twice.\nIf you have followed the firebase documentation \nThen you should not add firebase library inside android studio\ni.e.\nfile->project structure->cloud->firebaseYou have to do only one of the both, to use firebase in your android application.At the end clean and rerun your app.You can add multiple licence in gradle Surely it will work"},
{"body": "Is there any way to pass class as a parameter in Java and fire some methods from that class?I am using Google Web Toolkit and it does not support reflection. To call the method, you call it this way:UseA  is also a Java object, so you can refer to it by using its type.Read more about it from .I am not sure what you are trying to accomplish, but you may want to consider that passing a class may not be what you really need to be doing.  In many cases, dealing with Class like this is easily encapsulated within a factory pattern of some type and the use of that is done through an interface.  here's one of dozens of articles on that pattern: using a class within a factory can be accomplished in a variety of ways, most notably by having a config file that contains the name of the class that implements the required interface.  Then the factory can find that class from within the class path and construct it as an object of the specified interface.This kind of thing is not easy. Here is a method that calls a static method: \nWait, I just saw the gwt tag on the question. You can't use reflection in GWTAs you said GWT does not support reflection. You should use deferred binding instead of reflection, or third party library such as  for reflection suppport at gwt layer. Have a look at the reflection tutorial and reflection API of Java:and Se these:\nhere is the explaniation for the template methods."},
{"body": "Since weak references can be claimed by the garbage collector at any time, is there any practical reason for using them?If you want to keep a reference to something as long as it is used elsewhere e.g. a Listener, you can use a weak reference.WeakHashMap can be used as a short lived cache of keys to derived data.  It can also be used to keep information about objects used else where and you don't know when those objects are discarded.BTW Soft References are like Weak references, but they will not always be cleaned up immediately.  The GC will always discard weak references when it can and retain Soft References when it can.There is another kind of reference called a Phantom Reference.  This is used in the GC clean up process and refers to an object which isn't accessible to \"normal\" code because its in the process of being cleaned up.Of course there are practical reasons to use it. It would be awfully strange if the framework designers went to the enormous expense of building a weak reference system that was , don't you think?I think the question you intended to ask was:There are many. A common one is to achieve a performance goal. When performance tuning an application one often must make a tradeoff between more memory usage and more time usage. Suppose for example there is a complex calculation that you must perform many times, but the computation is \"pure\" -- the answer depends only on the arguments, not upon exogenous state. You can build a cache -- a map from the arguments to the result -- but that then uses memory. You might never ask the question again, and that memory is would then be wasted.Weak references possibly solve this problem; the cache can get quite large, and therefore time is saved if the same question is asked many times. But if the cache gets large enough that the garbage collector needs to reclaim space, it can do so safely. The downside is of course that the cleanup policy of the garbage collector is tuned to meet the goals of the whole system, not your specific cache problem. If the GC policy and your desired cache policy are sufficiently aligned then weak references are a highly pragmatic solution to this problem.If a  is the  reference to an object, and you want the object to hang around, you should probably be using a  instead.WeakReferences are best used in cases where there will be other references to the object, but you can't (or don't want to have to) detect when those other references are no longer used. Then, the  reference will prevent the object from being garbage collected, and the WeakReference will just be another way of getting to the same object.Two common use cases are:We use it for that reason - in our example, we have a variety of listeners that must register with a service.  The service keeps weak references to the listeners, while the instantiated classes keep strong references.  If the classes at any time get GC'ed, the weak reference is all that remains of the listeners, which will then be GC'ed as well.  It makes keeping track of the intermediary classes much easier.The most common usage of weak references is for values in \"lookup\" Maps.With normal (hard) value references, if the value in the map no longer has references to it elsewhere, you often don't need the lookup any more. With weakly referenced map values, once there are no other references to it, the object becomes a candidate for garbage collectionThe fact that the map itself has a (the only) reference to the object does not stop it from being garbage collected because the reference is a  reference To prevent memory leaks, see this  for details. I use it generally for some type of cache. Recently accessed items are available immediately and in the case of cache miss you reload the item (DB, FS, whatever).I use  to encode links in a graph.  If a node is deleted, the links automatically disappear."},
{"body": "I'm running Windows 8.1 x64 with Java 7 update 45 x64 (no 32 bit Java installed) on a Surface Pro 2 tablet.The code below takes 1688ms when the type of i is a long and 109ms when i is an int. Why is long (a 64 bit type) an order of magnitude slower than int on a 64 bit platform with a 64 bit JVM?My only speculation is that the CPU takes longer to add a 64 bit integer than a 32 bit one, but that seems unlikely. I suspect Haswell doesn't use ripple-carry adders.I'm running this in Eclipse Kepler SR1, btw.Edit: Here are the results from equivalent C++ code compiled by VS 2013 (below), same system.   Those results were in debug 32 bit mode.In 64 bit release mode:  long long:  906ms int: 1047msThis suggests that the result I observed is JVM optimization weirdness rather than CPU limitations.Edit: Just tried this again in Java 8 RTM, no significant change.My JVM does this pretty straightforward thing to the inner loop when you use s:It cheats, hard, when you use s; first there's some screwiness that I don't claim to understand but looks like setup for an unrolled loop:then the unrolled loop itself:then the teardown code for the unrolled loop, itself a test and a straight loop:So it goes 16 times faster for ints because the JIT unrolled the  loop 16 times, but didn't unroll the  loop at all.For completeness, here is the code I actually tried:The assembly dumps were generated using the options .  Note that you need to mess around with your JVM installation to have this work for you as well; you need to put some random shared library in exactly the right place or it will fail.The JVM stack is defined in terms of , whose size is an implementation detail but must be at least 32 bits wide. The JVM implementer  use 64-bit words, but the bytecode can't rely on this, and so operations with  or  values have to be handled with extra care. In particular,  are defined on exactly the type .In the case of your code, disassembly is instructive. Here's the bytecode for the  version as compiled by the Oracle JDK 7:Note that the JVM will load the value of your static  (0), subtract one (3-4), duplicate the value on the stack (5), and push it back into the variable (6). It then does a compare-with-zero branch and returns.The version with the  is a bit more complicated:First, when the JVM duplicates the new value on the stack (5), it has to duplicate two stack words. In your case, it's quite possible that this is no more expensive than duplicating one, since the JVM is free to use a 64-bit word if convenient. However, you'll notice that the branch logic is longer here. The JVM doesn't have an instruction to compare a  with zero, so it has to push a constant  onto the stack (9), do a general  comparison (10), and then branch on the value of  calculation.Here are two plausible scenarios:I recommend you  to eliminate the effect of having the JIT kick in, and also trying this with a final condition that isn't zero, to force the JVM to do the same comparison on the  that it does with the .Basic unit of data in a Java Virtual Machine is word. Choosing the right word size is left upon the implementation of the JVM. A JVM implementation should choose a minimum word size of 32 bits. It can choose a higher word size to gain efficiency. Neither there is any restriction that a 64 bit JVM should choose 64 bit word only.The underlying architecture doesn't rules that the word size should also be the same. JVM reads/writes data word by word. This is the reason why it might be taking longer for a  than an .    you can find more on the same topic.I have just written a benchmark using .The  are quite consistent with the original code: a ~12x speedup for using  over . It certainly seems that the loop unrolling  or something very similar is going on.This is my code; note that it uses a freshly-built snapshot of , since I could not figure out how to code against their existing beta release.For the record, this version does a crude \"warmup\":The overall times improve about 30%, but the ratio between the two remains roughly the same.For the records:if i use(changed \"l--\" to \"l = l - 1l\") long performance improves by ~50%I don't have a 64 bit machine to test with, but the rather large difference suggests that there is more than the slightly longer bytecode at work.I see very close times for long/int (4400 vs 4800ms) on my 32-bit 1.7.0_45. Confirmed to be not causing the issue.EDIT:  (Not the case)."},
{"body": "The  state:The levels in descending order are:My example sets the  to , so I was expecting to see 2 messages for each loop.  Instead I see a single message for each loop (the  messages are missing).What needs changing in order to see the  (,  or ) output?Thanks to , this version works according to my expectation.  It displays 3x messages, & 3x messages.Loggers only log the message, i.e. they create the log records (or logging requests). They do not publish the messages to the destinations, which is taken care of by the Handlers. Setting the level of a logger, only causes it to  log records matching that level or higher.You might be using a  (I couldn't infer where your output is System.err or a file, but I would assume that it is the former), which defaults to publishing log records of the level . You will have to configure this handler, to publish log records of level  and higher, for the desired outcome.I would recommend reading the  guide, in order to understand the underlying design. The guide covers the difference between the concept of a Logger and a Handler.The java.util.logging properties file (by default, this is the  file in ) can be modified to change the default level of the ConsoleHandler:This is not recommended, for it would result in overriding the global configuration. Using this throughout your code base will result in a possibly unmanageable logger configuration.java.util.logging has a root logger that defaults to , and a ConsoleHandler attached to it that also defaults to .\n is lower than , so fine messages are not displayed by default.Create a logger for your whole application, e.g. from your package name or use , and hook your own ConsoleLogger to it.\nThen either ask root logger to shut up (to avoid duplicate output of higher level messages), or ask your logger to  to root.Alternatively, you may lower the root logger's bar.You can set them by code:Or with logging configuration file, if you are :By lowering the global level, you may start seeing messages from core libraries, such as from some Swing or JavaFX components.\nIn this case you may set a  on the root logger to filter out messages not from your program.provides a jar file that will help you work out why your logging in not working as expected.\nIt gives you a complete dump of what loggers and handlers have been installed and what levels are set and at which level in the logging hierarchy.I found my actual problem and it was not mentioned in any answer: some of my unit-tests were causing logging initialization code to be run multiple times within the same test suite, messing up the logging on the later tests."},
{"body": "How do I bypass invalid SSL certificate errors with Apache  4.0?You need to create a SSLContext with your own TrustManager and create HTTPS scheme using this context. Here is the code,All of the other answers were either deprecated or didn't work for HttpClient 4.3.Here is a way to allow all hostnames when building an http client.Or if you are using version 4.4 or later, the updated call looks like this: Just for the record, there is a much simpler way to accomplish the same with HttpClient 4.1For the record, tested with httpclient 4.3.6 and compatible with Executor of fluent api:If all you want to do is get rid of invalid hostname errors you can just do:For Apache HttpClient 4.4:  This is extracted from our actual working implementation. The other answers are popular, but for HttpClient 4.4 they don't work. I spent hours trying & exhausting possibilities, but there seems to have been extremely major API change & relocation at 4.4.See also a slightly fuller explanation at: Hope that helps!This is how I did it - Initialising DefaultHTTPClient - Mock SSL Factory - If behind a proxy, need to do this - We are using HTTPClient 4.3.5 and we tried almost all solutions exist on the stackoverflow but nothing,\nAfter thinking and figuring out the problem, we come to the following code which works perfectly,\njust add it before creating HttpClient instance.Just had to do this with httpclient-4.5 and it seems like they've deprecated a few things since 4.4 so here's the snippet that works for me and uses the most recent API:In extension to  it will be nice to override the hostnameverifier.To accept all certificates in HttpClient 4.4.x you can use the following one liner when creating the httpClient:a full working version for Apache HttpClient 4.1.3 (based on oleg's code above, but it still needed an allow_all_hostname_verifier on my system):Note I'm re-throwing all exceptions because really, there's not much I can do if any of this fails in a real system!If you are using the , you need to set it up via the :... where  is the SSLContext created as shown in the 's answer.After that, you can do your http requests as:Tested with 4.3.3}With fluent 4.5.2 i had to make the following modification to make it work.If you encountered this problem when using AmazonS3Client, which embeds Apache HttpClient 4.1, you simply need to define a system property like this so that the SSL cert checker is relaxed:-Dcom.amazonaws.sdk.disableCertChecking=trueMischief managedfwiw, an example using \"RestEasy\" implementation of JAX-RS 2.x to build a special \"trust all\" client..."},
{"body": "I want to read a text file containing space separated values. Values are integers.\nHow can I read it and put it in an array list?Here is an example of contents of the text file:I want to have it in an arraylist as . How can I do it in Java?You can use  to get all lines of a text file into a .Tutorial: You can use  to split a  in parts based on a regular expression.Tutorial: You can use  to convert a  into an .Tutorial: You can use  to add an element to a .Tutorial: So, in a nutshell (assuming that the file doesn't have empty lines nor trailing/leading whitespace).If you happen to be at Java 8 already, then you can even use  for this, starting with .Tutorial:  Java 1.5 introduced the  class for handling input from file and streams.It is used for getting integers from a file and would look something like this:Check the API though. There are many more options for dealing with different types of input sources, differing delimiters, and differing data types.This example code shows you how to read file in Java.Look at this example, and try to do your own:Just for fun, here's what I'd probably do in a real project, where I'm already using all my favourite libraries (in this case , formerly known as ).Benefit: Not much own code to maintain (contrast with e.g. ). : Although it is worth noting that in this case  doesn't have any more code!Drawback: you obviously may not want to add new library dependencies just for this. Use  (IO and Lang) for simple/common things like this.Imports:Code:Done.Using Java 7 to read files with NIO.2Import these packages:This is the process to read a file:To read all lines of a file at once:All the answers so far given involve reading the file line by line, taking the line in as a , and then processing the .There is no question that this is the easiest approach to understand, and if the file is fairly short (say, tens of thousands of lines), it'll also be acceptable in terms of efficiency. , it's a very inefficient way to do it, for two reasons:If you care about speed, you are much better off reading a block of data and then processing it byte by byte rather than line by line. Every time you come to the end of a number, you add it to the  you're building.It will come out something like this:The code above assumes that this is ASCII (though it could be easily tweaked for other encodings), and that anything that isn't a digit (in particular, a space or a newline) represents a boundary between digits. It also assumes that the file ends with a non-digit (in practice, that the last line ends with a newline), though, again, it could be tweaked to deal with the case where it doesn't.It's  than any of the -based approaches also given as answers to this question. There is a detailed investigation of a very similar issue . You'll see there that there's the possibility of improving it still further if you want to go down the multi-threaded line.read the file and then do whatever you want \njava8\nFiles.lines(Paths.get(\"c://lines.txt\")).collect(Collectors.toList());"},
{"body": "Title is the entire question. Can someone give me a reason why this happens?Yes - because it does begin with the empty string. Indeed, the empty string logically occurs between every pair of characters.Put it this way: what definition of \"starts with\" could you give that would preclude this? Here's a simple definition of \"starts with\" that doesn't:\"x starts with y if the first  characters of x match those of y.\"An alternative (equivalent) definition:\"x starts with y if \"I will try to elaborate on what Jon Skeet said.Let's say  x, y and z are strings and + operator is in fact concatenation, then:If we can split z to write z = x + y that means that z starts with x.\nBecause every string z can be split to z = \"\" + z it follows that every string starts with \"\".So, because (\"\" + \"abcd\") == \"abcd\" it follows that \"abcd\" starts with \"\"This method compares the value parameter to the substring at the beginning of this string that is the same length as value, and returns a value that indicates whether they are equal.  true if the character sequence represented by the argument is a prefix of the character sequence represented by this string; false otherwise.  or is equal to this String object as determined by the equals(Object) method.I'll start with a related fact that is easier to understand.Why? The  of  states that  is a subset of  if every element of  is an element of . Conversely,  is not a subset of  if there is an element of  that is not an element of .Now fix a set . I'll establish that the empty set is a subset of . I'll do this by showing that it is not the case that the empty set is not a subset of . If the empty set were not a subset of  then I could find an element of the empty set that is not in . But the empty set does not have any elements and thus I can not find an element that is not in . Therefore, it is not the case that the empty set is not a subset of . Thus, the empty set must be a subset of .First, we must agree on our definition of . Let  and  be s We say that    if  and the first  characters of  match those of . That is,  and for every  such that ,  is true. Conversely, we would say that  does not start with  if the statement or  and there is an  such that  and is true. In plain English,  is shorter than , or, if not, there is a character in  not matching the character as the same position in .Now fix a string . I'll establish that  starts with the empty string. I'll do this by showing that it is not the case that  does not start with the empty string. If  does not start with the empty string then  or  and there is an  such that . But  and  is equal to zero so it is impossible for  to be true. Similarly, since ``String.Empty.LengthInt32 index0 <= index < String.Empty.Length`. Therefore or  and there is an  such that is false. Therefore, it is not the case that  does not start with the empty string. Thus,  must start with the empty string.The following is an implementation of  coded as an extension to .The above two bolded facts are examples of . They are true by virtue of the fact that the statements defining them ( and ) are  over empty universes. There are no elements in the empty set, so there can not be any elements of the empty set not in some other fixed set. There are no characters in the empty string, so there can not be a character as some position in the empty string not matching the character in the same position in some other fixed string.Let's just say  returns false.if so then what does the following expression eval to, true or false:it turns out that evals to true, so the string does start with the empty string ;-), or put in other words, the substring of \"abcd\" starting at position 0 and having 0 length equals the empty string \"\". Pretty logical imo.In C# this is how the  tells it to react;THE REAL ANSWER:It has to be that way otherwise you'd have the case where and then we'd have Y2K all over again because all the bank software that depends on equal strings starting with themselves will get our accounts mixed up and suddenly Bill Gates will have my wealth and I'd have his, and damn it! Fate just isn't that kind to me.The first N characters of the two strings are identical. N being the length of the second string, i.e. zero.Just for the record,  internally calls the method  which makes the following check explicitly:Because a string begins well with \"nothing\".If you think of it in regular expressions terms, it makes sense.\nEvery string (not just \"abcd\", also \"\" and \"sdf\\nff\") , \nreturns true when evaluating the regular expression of 'starts with empty string'."},
{"body": "Can someone help me with this? Every example I find is about doing this alphabetically, while I need my elements sorted by date.My ArrayList contains objects on which one of the datamembers is a DateTime object. On DateTime I can call the functions:So to compare I could do something like:I don't really know what to do inside the if block. Any ideas?You can make your object comparable:And then you sort it by calling:However sometimes you don't want to change your model, like when you want to sort on several different properties. In that case, you can create comparator on the fly:However, the above works only if you're certain that dateTime is not null at the time of comparison. It's wise to handle null as well to avoid NullPointerExceptions:Or in the second example:You can use Collections.sort method. It's a static method. You pass it the list and a comparator. It uses a modified mergesort algorithm over the list. That's why you must pass it a comparator to do the pair comparisons.Note that if myList is of a comparable type (one that implements Comparable interface) (like Date, Integer or String) you can omit the comparator and the natural ordering will be used.Given  that has a  member with a  method, you can sort an  that contains  elements by the  objects like this:Since Java 8 the  interface provides the  method. Combined with  expression the easiest solution would beAll the answers here I found to be un-neccesarily complex for a simple problem (at least to an experienced java developer, which I am not). I had a similar problem and chanced upon this (and other) solutions, and though they provided a pointer, for a beginner I found as stated above. My solution, depends on where in the the Object your Date is, in this case, the date is the first element of the Object[] where  is the ArrayList containing your Objects.With introduction of Java 1.8, streams are very useful in solving this kind of problems:This is how I solved:Hope it help you.?This may be an old response but I used some examples from this post to create a comparator that would sort an  of  by one object in the list, that being the timestamp.  I have these objects:The map objects are as follows:That mapping is what I use to load all my objects into the array list, using the  function, within a loop.Now, I created my own comparator:I can now just call the Comparator at any time on the array and it will sort my array, giving me the Latest timestamp in position 0 (top of the list) and the earliest timestamp at the end of the list.  New posts get put to the top basically.This may help someone out, which is why I posted it.  Take into consideration the return statements within the compare() function.  There are 3 types of results.  Returning 0 if they are equal, returning >0 if the first date is before the second date and returning <0 if the first date is after the second date.  If you want your list to be reversed, then just switch those two return statements!  Simple =]Pass the ArrayList In argument.The best answer IMHO from Tunaki using Java 8 lambda"},
{"body": "I got a native library that needs to be added to . With JVM argument  I can set the path as I want.My problem is that my other library (pentaho reporting) searches fonts based on the default java.library.path (including system directories etc) and the manual setting overrides the default path..So : how can I  a path entry to the default java.library.path instead of overriding it (which seems to be done with -Djava.library.path)? (I wouldn't want to add the default path by hand, which wouldn't be nice for the sake of deployment)EDIT: Sorry for missing details; I'm working with Eclipse. (The deployment is done with JNLP and there I can use   under )Had forgotten this issue... I was actually asking with Eclipse, sorry for not stating that originally.\nAnd the answer seems to be too simple (at least with 3.5; probably with older versions also):Java run configuration's Arguments : VM arguments:Must not forget the quotation marks, otherwise there are problems with spaces in PATH.If you want to add a native library without interfering with  at development time in Eclipse (to avoid including absolute paths and having to add parameters to your launch configuration), you can supply the path to the native libraries location for each Jar in the  dialog under . Note that the native library file name has to correspond to the Jar file name. See also this .SWT puts the necessary native DLLs into a JAR. Search for \"org.eclipse.swt.win32.win32.x86_3.4.1.v3449c.jar\" for an example.The DLLs must be in the root of the JAR, the JAR must be signed and the DLL must appear with checksum in the META-INF/MANIFEST.MF for the VM to pick them up. states that there is no substitution mechanics implemented in Eclipse's launcher, at least no up to release Juno.Thus it is (almost) impossible to append or prepend another library folder to java.library.path when launching Eclipse without prior knowledge of the default setting.I wrote almost, cause it should be possible to let Eclipse startup, dump the content of java.library.path and stop Eclipse in one command. The dump would the be parsed and then taken as the input for launching Eclipse, i.e.In Windows, like this: -Djava.library.path=\"C:/MyLibPath;%PATH%\" %PATH% is your old -Djava.library.pathCan you get round this by calling programmatically to load your native library? This method (unlike ) allows you to specify an absolute path.Window->Preferences->Java->Installed JREs. Then choose your current JRE(JDK) and click Edit.\nFill Default VM Arguments: -Djava.library.path=/usr/local/xuggler/lib.\nDone!As I can't add a comment yet I'll post another reply:The solution offered by Rob Elsner in one of the comments above works perfectly (OSX 10.9, Eclipse Kepler). One has to append their additional paths to that separated by \":\".In UNIX systems, you can append to the LD_LIBRARY_PATH environment variable. On Windows, the JVM automatically sets the system property, java.library.path, to PATH; so if the dll is on your PATH, then you're set.The native library file name has to correspond to the Jar file name. This is very very important.\nPlease make sure that jar name and dll name are same.\nAlso,please see the post from Fabian Steeg\nMy download for jawin was containing different names for dll and jar.\nIt was jawin.jar and jawin.dll, note extra 'd' in dll file name.\nI simply renamed it to jawin.dll and set it as a native library in eclipse as mentioned in post\n\"\"For some reason I couldn't get multiple folders to work (well it did for a while but as soon as I needed more dlls and added more folders, none with white spaces in the path). I then copied all needed dlls to one folder and had that as my  and it worked. I don't have an explanation - if anyone does, it would be great.Many of the existing answers assume you want to set this for a particular project, but I needed to set it for Eclipse  in order to support integrated authentication for the SQL Server JDBC driver.To do this, I followed  for launching Eclipse from the Java commandline instead of its normal launcher.  Then I just modified that script to add my -Djava.library.path argument to the Java commandline.On Windows, I have found that the important thing is to  rather than from the Start Menu or a shortcut, provided that the native DLL is in a directory in your PATH. Apparently, this ensures that the proper directory is on the path."},
{"body": "When writing utility classes in Java, what are some good guidelines to follow?Should packges be \"util\" or \"utils\"? Is it ClassUtil or ClassUtils? When is a class a \"Helper\" or a \"Utility\"? Utility or Utilities? Or do you use a mixture of them?The standard Java library uses both Utils and Utilities:Apache uses a variety of Util and Utils, although mostly Utils:Spring uses a lot of Helper and Utils classes:So, how do you name your utility classes?Like many such conventions, what's important is not so much what convention you use, as that you use it consistently. Like, if you have three utility classes and you call them CustomerUtil, ProductUtils, and StoreUtility, other people trying to use your classes are going to constantly get confused and type CustomerUtils by mistake, have to look it up, curse you a few times, etc. (I heard a lecture on consistency once where the speaker put up a slide showing an outline of his speech with three main points, labeled \"1\", \"2nd\", and \"C\".)Never ever ever make two names that differ only in some subtlety of spelling, like having a CustomerUtil and a CustomerUtility. If there was a good reason to make two classes, then there must be something different about them, and the name should at least give us a clue what that difference is. If one contains utility functions related to name and address and the other contains utility functions related to orders, then call them CustomerNameAndAddressUtil and CustomerOrderUtil or some such. I regularly go nuts when I see meaningless subtle differences in names. Like just yesterday I was working on a program that had three fields for freight costs, named \"freight\", \"freightcost\", and \"frght\". I had to study the code to figure out what the difference between them was.There is no standard rule/convention in Java world for this. However, I prefer adding \"s\" at the end of Class name as @colinD has mentioned. That seems pretty standard to what  ( java collection as well as google collection)As long as Helper and Util goes, I will call something a Helper when it has APIs that help to achieve a specific functionality of a package ( considering a package as to implement a module); mean while a Util may be called in any context. For example in an application related to bank accounts, all number specific utility static APIs would go to All \"Account\" specific business rule helping APIs would go to After all, it is a matter of providing better documentation and cleaner code.I like the convention of just adding \"s\" to the type name when the type is an interface or a class you don't control. Examples of that in the JDK include  and . It's also the convention used in Google Collections.When you're dealing with a  you have control over, I'd say utility methods belong on the class itself generally.I think that 'utils' should be the package name. The class names should specify the purpose of the logic inside it. Adding the sufix -util(s) is redundant. I'm pretty sure the words \"helpers\" and \"utilities\" are used interchangeably. Anyway judging by the examples you provided, I'd say if your classname is an abbreviation (or has abbreviations in it like \"DomUtil\") then call your package \"whatever.WhateverUtil\" (or Utils if there's more than one utility in your package). Else if it has a full name instead of an abbreviation, then call it \"whatever.WhateverUtilities\".It's really up to you, but so long as coders know what you're talking about, you're good-to-go. If you're doing this professionally as a job for somebody though, ask them what their coding standards are before taking my advice. Always go with the shop standards no matter what  as that will help you keep your job. :-)"},
{"body": "I'm working on two projects in eclipse and I would like to import some classes from project a to project b. What should I do?Is there a way of doing it without adding the project to the build path ?add project A to project B's build path.Follow these steps:\nEdits by \nRight click on project B's folder in eclipse --> properties --> build path --> projects --> add.\nNow add project A"},
{"body": "I am trying to understand what JMS and how it is connected to AMQP terminology.\nI know JMS is an API and AMQP is a protocol. Here are my assumptions (and questions as well)Some of the above may be dumb. :-) But trying to wrap my head around it.Your question is a bit messy and like a tough Question of a question paper :)(As teachers always try to ask simple questions making complex :D I hope you are not a teacher :) )Let see all of these one by one.\nAs you know\nThe Java Message Service . JMS is a part of the Java Platform, Enterprise Edition, and is defined by a specification developed under the Java Community Process as JSR 914. (From WIKI).\n \n And the most important thing\n(From WIKI).\nSome imp things you should know\n Keep in mind that AMQP is a Messaging technologies that do not implement the JMS API.\n JMS is API and AMQP is a protocol.So it doesn't make sense to say that what is default protocol of JMS, of course client applications use HTTP/S as the connection protocol when invoking a WebLogic Web Service.\n JMS is only a API spec. It doesn't use any protocol. A JMS provider (like ActiveMQ) could be using any underlying protocol to realize the JMS API. For ex: Apache ActiveMQ can use any of the following protocols: AMQP, MQTT, OpenWire, REST(HTTP), RSS and Atom, Stomp, WSIF, WS Notification, XMPPI suggest you to see  Good Luck :)Let's start from the basis.   (Message Oriented Middleware), developed with Erlang (a TLC-oriented programming language) and  (Advance Message Queuing Protocol). \nCurrently, many Client APIs (e.g., Java, C++, RESTful, etc.) are available to enable the usage of RabbitMQ messaging services. (Java Messaging Service) is a JCP standard defining a  to be implemented by a MOM. An example of MOM that implements (i.e. is compatible with) the JMS APIs is ActiveMQ; there's also HornetMQ, and others. Such middlewares get the JMS APIs and implement the exchange patterns accordingly.According to above, taken the skeleton of JMS APIs, an instance of RabbitMQ and its Java Client APIs, it is possible to develop a JMS implementation making use of RabbitMQ: the only thing that one has to do, at that point, is implementing the exchange pattern (over RabbitMQ) according to the JMS specification.The key is:  (in this case, RabbitMQ).JMS, when it was defined did not define a protocol between the JMS client and a messaging server. The JMS client, which implement the JMS API can use whatever protocol to communicate with messaging server. The client just need to be compliant with JMS api. Thats all. Ususally JMS clients use a custom protocol that their messaging server understands.AMQP on other hand is a protocol between a messaging client and messaging server. A JMS client can use AMQP as the protocol to communicate with the messaging server. And there are clients like that available. I had similar questions on JMS and AMQP. While the discussion here answer the questions. This link from spring.io also explains it nicely and worth taking a look, hence sharing...  JMS is an API, so some JMS API's are implemented over the AMQP protocol (like ) while most JMS APIs use other protocols. If the version of the AMQP protocol is the same, such a client should be able to communicate with another AMQP client.It depends on your configuration of that JMS API. For ActiveMQ, it could be  but by default it is 'openwire'I suspect you may be looking for  which says, in part:"},
{"body": "Is there a way to configure log4j so that it outputs different levels of logging to different appenders?  I'm trying to set up multiple log files.  The main log file would catch all INFO and above messages for all classes.  (In development, it would catch all DEBUG and above messages, and TRACE for specific classes.)  Then, I would like to have a separate log file.  That log file would catch all DEBUG messages for a specific subset of classes, and ignore all messages for any other class.  Is there a way to get what I'm after?Thanks,\nDanThis should get you started:Perhaps something like this?Thus, all info messages are written to server.log; by contrast, foo.log contains only com.example.foo messages, including debug-level messages.I had this question, but with a twist - I was trying to log different content to different files.  I had information for a LowLevel debug log, and a HighLevel user log.  I wanted the LowLevel to go to only one file, and the HighLevel to go to both a file, and a syslogd.My solution was to configure the 3 appenders, and then setup the logging like this:The part that was difficult for me to figure out was that the 'log4j.logger' could have multiple appenders listed. I was trying to do it one line at a time.Hope this helps someone at some point!For the main logfile/appender, set up a  to limit what is actually logged in the appender to INFO and above, regardless of whether or not the loggers have DEBUG, TRACE, etc, enabled.As for catching DEBUG and nothing above that... you'd probably have to write a custom appender.However I'd recommend not doing this, as it sounds like it would make troubleshooting and analysis pretty hard: "},
{"body": "I am trying to set up a large-scale REST services server.  We're using Spring Boot 1.2.1 Spring 4.1.5, and Java 8.  Our controllers are implementing @RestController and the standard @RequestMapping annotations.My problem is that Spring Boot sets up a default redirect for controller exceptions to \"/error\".  From the docs:Coming from years writing REST applications with Node.js, this is, to me, anything but sensible.  Any exception a service endpoint generates should return in the response.  I can't understand why you'd send a redirect to what is most likely an Angular or JQuery SPA consumer which is only looking for an answer and can't or won't take any action on a redirect.What I want to do is set up a global error handler that can take any exception - either purposefully thrown from a request mapping method or auto generated by Spring (404 if no handler method is found for the request path signature), and return a standard formatted error response (400, 500, 503, 404) to the client without any MVC redirects.  Specifically, we are going to take the error, log it to NoSQL with a UUID, then return to the client the right HTTP error code with the UUID of the log entry in the JSON body.The docs have been vague on how to do this.  It seems to me that you have to either create your own  implementation or use  in some fashion, but all the examples I've see still include forwarding the response to some kind of error mapping, which doesn't help.  Other examples suggest that you'd have to list every Exception type you want to handle instead of just listing \"Throwable\" and getting everything.Can anyone tell me what I missed, or point me in the right direction on how to do this without suggesting up the chain that Node.js would be easier to deal with?  An annoymous user suggested an edit and got rejected, but his suggestion looks good and helpful so I'm adding it:Using Spring Boot 1.3.1.RELEASE It is easy and less intrusive to add the following properties to the application.properties:If working with a full RESTful Application, it is very important to disable the automatic mapping of static resources since if you are using Spring Boot's default configuration for handling static resources then the resource handler will be handling the request (it's ordered last and mapped to /** which means that it picks up any requests that haven't been handled by any other handler in the application) so the dispatcher servlet doesn't get a chance to throw an exception.Using Spring Boot 1.2.7.RELEASE I found a much less intrusive way of setting the \"throExceptionIfNoHandlerFound\" flag.  Replace the DispatcherServlet replacement code below (Step 1) with this in your application initialization class:In this case, we're setting the flag on the existing DispatcherServlet, which preserves any auto-configuration by the Spring Boot framework.  One more thing I've found - the @EnableWebMvc annotation is deadly to Spring Boot.  Yes, that annotation enables things like being able to catch all the controller exceptions as described below, but it also kills a LOT of the helpful auto-configuration that Spring Boot would normally provide.  Use that annotation with extreme caution when you use Spring Boot.After a lot more research and following up on the solutions posted here (thanks for the help!) and no small amount of runtime tracing into the Spring code, I finally found a configuration that will handle all Exceptions (not Errors, but read on) including 404s. tell SpringBoot to stop using MVC for \"handler not found\" situations.  We want Spring to throw an exception instead of returning to the client a view redirect to \"/error\".  To do this, you need to have an entry in one of your configuration classes:The downside of this is that it replaces the default dispatcher servlet. This hasn't been a problem for us yet, with no side effects or execution problems showing up.  If you're going to do anything else with the dispatcher servlet for other reasons, this is the place to do them. Now that spring boot will throw an exception when no handler is found, that exception can be handled with any others in a unified exception handler:Keep in mind that I think the \"@EnableWebMvc\" annotation is significant here.  It seems that none of this works without it.  And that's it - your Spring boot app will now catch all exceptions, including 404s, in the above handler class and you may do with them as you please.One last point - there doesn't seem to be a way to get this to catch thrown Errors.  I have a wacky idea of using aspects to catch errors and turn them into Exceptions that the above code can then deal with, but I have not yet had time to actually try implementing that.  Hope this helps someone.Any comments/corrections/enhancements will be appreciated.I think  meets your requirements. A sample piece of code for HTTP 400:You can check this With Spring Boot 1.4+ new cool classes for easier exception handling were added that helps in removing the boilerplate code.A new  is provided for exception handling, it is combination of  and . You can remove the  on the  method when use this new annotation.i.e.  For handling 404 errors adding  annotation and the following to application.properties was enough:\nYou can find and play with the sources here:\nWhat about this code ? I use a fallback request mapping to catch 404 errors.By default Spring Boot gives json with error details.It also works for all kind of request mapping errors. Check this article\nIf you want to create log it to NoSQL. You can create @ControllerAdvice where you would log it and then re-throw the exception. \nThere is example in documentation\nFor REST controllers, I would recommend to use .If Spring Boot aims to embed some auto-configuration, this library does more for exception handling. You just need to add the dependency:And then define one or more advice traits for your exceptions (or use those provided by default)Then you can defined the controller advice for exception handling as:Solution with \n and\n\nworked for me with Spring Boot 1.3.1, while was not working on 1.2.7"},
{"body": "I want to limit the maximum memory used by the JVM. Note, this is not just the heap, I want to limit the total memory used by this process.use the arguments  . Use  or  after the numbers for indicating Megs and Gigs of bytes respectively.  indicates the minimum and  the maximum.You shouldn't have to worry about the stack leaking memory (it is highly uncommon).  The only time you can have the stack get out of control is with infinite (or really deep) recursion.You need to run the JVM with the following command line argument.Example:That will allow a max of 1GB of memory for the JVM.The answer above is kind of correct, you can't gracefully control how much native memory a java process allocates. It depends on what your application is doing.That said, depending on platform, you may be able to do use some mechanism, ulimit for example, to limit the size of a java or any other process.Just don't expect it to fail gracefully if it hits that limit. Native memory allocation failures are much harder to handle than allocation failures on the java heap. There's a fairly good chance the application will crash but depending on how critical it is to the system to keep the process size down that might still suit you.If you want to limit memory for jvm (not the heap size ) \nulimit -v To get an idea of the difference between jvm and heap memory , take a look at this excellent article\nI've never used it.  Maybe you'll find it useful.  The spelling error is not mine."},
{"body": "The title is in reference to Is this a branch prediction effect, too? Beware: here the processing for the sorted array is !!Consider the following code:This prints out a value of around 720 on my machine.Now if I activate the collections sort call, that value drops down to 142. Why?!?The results  conclusive, they don't change if I increase the number of iterations/time.Java version is 1.8.0_71 (Oracle VM, 64 bit), running under Windows 10, JUnit test in Eclipse Mars.Seems to be related to contiguous memory access (Double objects accessed in sequential order vs in random order). The effect starts vanish for me for array lengths of around 10k and less.Thanks to assylias for providing :It looks like caching / prefetching effect.The clue is that you compare Doubles (objects), not doubles (primitives). When you allocate objects in one thread, they are typically allocated sequentially in memory. So when  scans a list, it goes through sequential memory addresses. This is good for CPU cache prefetching heuristics.But after you sort the list, you still have to do the same number of memory lookups in average, but this time memory access will be in random order. to prove that the order of allocated objects matters.I think we are seeing the effect of memory cache misses:When you create the unsorted listall the double are most likely allocated in a contiguous memory area.\nIterating through this will produce few cache misses.On the other hand in the sorted list the references point to memory in a chaotic manner.Now if you create a sorted list with contiguous memory:this sorted list has the same performance than the original one (my timing).As a simple example that confirms the  and the  (+1!): The following does a simple comparison of both options:It is also not implemented as a JMH benchmark, but similar to the original code, with only slight modifications to observe the effect: The output on my machine isnicely showing that the timings are exactly the opposites of another: If random numbers are sorted, then the sorted version is slower. If sequential numbers are shuffled, then the shuffled version is slower."},
{"body": "I have a problem deserializing a json string with Gson.\nI  receive an array of commands. The command can be start,  stop , some other type of command. Naturally I have polymorphism, and start/stop command inherit from command. How can I serialize it back to the correct command object using gson?Seems that I get only the base type, that is the declared type and never the runtime type.This is a bit late but I had to do exactly the same thing today. So, based on my research and when using gson-2.0 you really don't want to use the  method, but rather the more mundane . And you certainly don't need to do  or write adapters for the derived classes: just one adapter for the base class or interface, provided of course that you are happy with the default serialization of the derived classes. Anyway, here's the code (package and imports removed) (also available in ):The base class (interface in my case):The two derived classes, Cat:And Dog:The IAnimalAdapter:And the Test class:When you run the Test::main you get the following output:I've actually done the above using the  method too, but that seemed to require implementing custom DogAdapter and CatAdapter serializer/deserializer classes which are a pain to maintain any time you want to add another field to Dog or to Cat.Gson currently has a mechanism to  that reportedly can be configured for simple polymorphic deserialization, but I don't see how that's the case, as a Type Hierarchy Adapter appears to just be a combined serializer/deserializer/instance creator, leaving the details of instance creation up to the coder, without providing any actual polymorphic type registration.It looks like Gson will soon have the  for simpler polymorphic deserialization.  See  for more info.If use of the new  isn't possible, and you gotta use Gson, then I think you'll have to roll your own solution, registering a custom deserializer either as a Type Hierarchy Adapter or as Type Adapter.  Following is one such example.GSON has a pretty good test case here showing how to define and register a type hierarchy adapter. To use that do this:Serialize method of the adapter can be a cascading if-else check of what type it is serializing.Deserializing is a bit hacky. In the unit test example, it checks for existence of tell-tale attributes to decide which class to deserialized to. If you can change the source of the object you're serializing, you can add a 'classType' attribute to each instance which holds the FQN of the instance class's name. This is so very un-object-oriented though.Marcus Junius Brutus had a great answer (thanks!).  To extend his example, you can make his adapter class generic to work for all types of objects (Not just IAnimal) with the following changes:And in the Test Class:Long time has passed, but I couldn't find a really good solution online.. \nHere is small twist on @MarcusJuniusBrutus's solution, that avoids the infinite recursion.Keep the same deserializer, but remove the serializer - Then, in your original class, add a field with .\nThe trick is now to initialize this in the constructor , so make your interface into a an abstract class.The reason there is no infinite recursion here is that we pass the actual runtime class (i.e. Dog not IAnimal) to . This will not call our type adapter, as long as we use  and not If you want manage a TypeAdapter for a type and an other for his sub type, you can use a TypeAdapterFactory like this :This factory will send the most accurate TypeAdapter"},
{"body": "I have looked around quite a bit and haven't found the best solution to convert an existing IntelliJ project to Gradle. I work in a team environment and we currently share the .ipr file as we have a few build configurations that we track. We will be getting rid of those in favor of Gradle eventually but I can't screw things up too much until the Gradle conversion is done.Also, our Java source files are located in the root of the src directory instead of src/main/java as is standard.Is there a way I can add Gradle to my project that won't make me delete and recreate my IntelliJ project and won't screw everyone else up when they do a Git pull?Why don't you just add:in your root project folder, and use plugin for example:and with this fire from command line:and after that:After that everything should work Another way, simpler.Add your file to the root of your project. Close the project. Manually remove *.iml file. Then choose \"Import Project...\", navigate to your project directory, select the  file and click OK.There is no need to remove any  files. Follow this:I'm not able to add a comment due to reputation. I'm using Version 12I solved a similar problem by creating an entirely new project and \"Checking out from Version Control\"\nMerging the two projects later was fairly easy.Have you tried something similar ?Just as a future reference, if you already have a  project all you need to do is doing a  in your project directory which will generates  and other dependencies, then do a  in the same directory. "},
{"body": "I use both ruby on rails and Java.  I really enjoy using migrations when I am working on a rails project.  so I am wondering is there a migrations like tool for Java? If there is no such tool is it a good idea to use migrations as a tool to control a database used by a Java project? I've used Hibernate's SchemaUpdate to perform the same function as migrations.  It's actually easier than migrations because every time you start up your app, it examines the database structure and syncs it up with your mappings so there's no extra rake:db:migrate step and your app can never be out of sync with the database it's running against.  Hibernate mapping files are no more complex than Rails migrations so even if you didn't use Hibernate in the app, you could take advantage of it.  The downside is that it's not as flexible as far as rolling back, migrating down, running DML statements. As pointed out in the comments, it also doesn't drop tables or columns. I run a separate method to do those manually as part of the Hibernate initialization process.I don't see why you couldn't use Rails migrations though - as long as you don't mind installing the stack (Ruby, Rake, Rails), you wouldn't have to touch your app.For a  between have a look at This should be a good start for you and anyone else to  is another project in this domain worth checking out. has a  utility that is patterned after the one from Rails.  Since it's implemented in Groovy, you should be able to use it from any of your Java projects.There are also two independent implementations of rails-like migrations for Java:1)  Maven-based migrations from 2)  Ant-based tasks from  (my personal favorite)Although these packages were written for Maven and Ant specifically, with some work you can adapt them to just about anything.I ran across this post while researching the same question. I haven't come to any conclusions about the best tool or approach yet, but one tool that I've come across which hasn't been mentioned in other answers so far is . I'd be interested to read any comparisons of these tools.Some other relevant resources: Martin Fowler and Pramod Sadalage's somewhat aged post on , and the book  by Sadalage and Scot Ambler. seems like a candidate, but the project doesn't look mature enough for production usage.There is also  which has been initially developed inside  but is now a dedicated project. We are currently using it and are very satisfied (which doesn't mean there aren't any good alternatives). I list more of them in my  bookmarks (with a focus on tools supporting Maven)."},
{"body": "Now that maven-3 did  for the <uniqueVersion>false</uniqueVersion> for snapshot artefacts it seems that you really need to use timestamped SNAPSHOTS. Especially m2eclipse, which does use maven 3 internally seems to be affected with it, update-snapshots does not work when the SNAPSHOTS are not unique.It seemed best  to set all snapshots to uniqueVersion=falseNow, it seems no big problem to switch to the timestamped version, after all they are managed by a central nexus repository, which is able to delete old snapshots in regular intervalls.The problem are the local developer workstations. Their local repository quickly does grow  large with unique snapshots.How to deal with this problem ?Right now i see the folowing possible solutions:What is the best way to keep your local repository from filling up your hard drive space ?Update:To verify the beaviour and to give more info i setup a small nexus server, build two projects (a and b) and try:a:b:Now, when i use maven and run \"deploy\" on \"a\", i'll havein the local repository. With a new timestamp version each time i run the deploy target. The same happens when i try to update Snapshots from the nexus server (close \"a\" Project, delete it from local repository, build \"b\")In an environment where lots of snapshots get build (think hudson server ...), the local reposioty fills up with old versions To test how and why this is failing i did some more tests. Each test is run against clean everything (de/glauche gets delete from both machines and nexus)local repository on machine A does contain snapshot.jar + snapshot-timestamp.jar BUT: only one timestamped jar in nexus, metadata reads:Ok, next try with maven 3.0.1 (after removing all traces of project a)So, to recap: The \"deploy\" goal in maven3 works better than in 2.2.1, the local repository on the creating machine looks fine.\nBut, the receiver always ends up with lots of timestamed versions ...What am i doing wrong ?I also did test various other configurations, first replace nexus with artifactory -> same behaviour. Then use linux maven 3 clients to download the snapshots from the repository manager -> local repository still has timestamped snapshots :(The  configuration applied to artifacts that were deployed (via mvn deploy) to a Maven repository such as Nexus.  To remove these from Nexus, you can easily create an automated job to purge the SNAPSHOT repository every day.  It can be configured to retain a certain number of shapshots or keep them for a certain period of time.  Its super easy and works great.Artifacts in the local repository on a developer machine get there from the \"install\" goal and do not use these timestamps...they just keep replacing the one and only SNAPSHOT version unless you are also incrementing the revision number (e.g. 1.0.0-SNAPSHOT to 1.0.1-SNAPSHOT).This plugin removes project's artifacts from local repository. Useful to keep only one copy of large local snapshot.Well I didn't like any of proposed solutions. Deleting maven cache often significantly increases network traffic and slows down build process. build-helper-maven-plugin helps only with one artifact, I wanted solution that can purge all outdated timestamped snapshot artifacts from local cache in one simple command. After few days of searching, I gave up and decided to write small program. The final program seems to be working quite well in our environment. So I decided to share it with others who may need such tool. Sources can be pulled from github: As far as the remote repository piece of this,  I think the previous answers that discuss a purging of SNAPSHOTs on a regular interval will work.  But no one has addressed the local-developer workstation synchronization part of your question.We have not started using Maven3 yet, so we've yet to see SNAPSHOTs starting to build up on local machines.But we have had different problems with m2eclipse.  When we have \"Workspace Resolution\" enabled and the project exists within our workspace, source updates usually keep us on the bleeding edge.  But we've found it's very difficult to get m2eclipse to update itself with recently published artifacts in Nexus.  We're experiencing similar problems within our team and it's particularly problematic because we have a very large project graph... there are a lot of dependencies that won't be in your workspace but will be getting SNAPSHOTs published frequently.I'm pretty sure this boils back to an issue in m2eclipse where it doesn't handle SNAPSHOTs exactly as it should.  You can see in the Maven console within eclipse where m2eclipse tells you it's skipping the update of a recently published SNAPSHOT because it's got a cached version.  If you do a -U from a run configuration or from the command line,  will pick up the metadata change.  But an \"Update Snapshots...\" selection should tell m2eclipse to have Maven expire this cache.  It doesn't appear to be getting passed along.  There appears to be a bug out there that is filed for this if you're interested in voting for it:\nYou made mention of this in a comment somewhere.The best workaround for this problem seems to be having developers purge their local workstations when things start to break down from within m2eclipse.  Similar solution to a different problem...  Others have reported problems with Maven 2.2.1 and 3 backing m2eclipse, and I've seen the same.I would hope if you're using Maven3 you can configure it to only pull the latest SNAPSHOT, and cache that for the amount of time the repository says (or until you expire it by hand).  Hopefully then you won't need to have a bunch of SNAPSHOTs sitting in your local repository.That is unless you're talking about a build server that is manually doing a  on them.  As far as how to prevent SNAPSHOTs from building up on an environment like a build server, we've kind of dodged that bullet by having each build use its own workspace and local repository (though, in Maven 2.2.1, certain things such as POMs seem to always come out of the ~/.m2/repository)  The extra SNAPSHOTs really only stick around for a single build and then they get dropped (and downloaded again from scratch).  So we've seen this approach does end up eating up more space to begin with, but it tends to remain more stable than having everything resolved out of a single repository.  This option (on Hudson) is called \"Use private Maven repository\" and is under the Advanced button of the Build section on project configurations when you've selected to build with Maven.  Here is the help description for that option:Hope this helps - if it doesn't address your problem please let me know where I missed., deleting timestamped files like  can be very simple:Install , save the script into a file and schedule the execution at each week, start, logon, whatever suits you.Or, you can even wire the execution into maven build, using . Notice, how is the repository location set by maven into the property  and then binded through configuration into variable :Add following parameter into your POM file "},
{"body": "The library in question is .I want is to have the native library, JNI library, and all Java API classes in one JAR file to avoid redistribution headaches.There seems to be , butThe question is, can I bundle everything in one JAR and redistribute it? If yes, how?P.S.: Yes, I realize it may have portability implications.is great article, which solves my issue ..In my case I've got the following code for initialize the library:Take a look at . It will wrap your application up in a single jar file with a specialised class loader which handles \"jars within jars\" among other things.It  by unpacking them to a temporary working folder as required.(Disclaimer: I've never used One-JAR, haven't needed to as yet, just had it bookmarked for a rainy day.) is a class loader to load classes, native libraries and resources from a single monster JAR and from JARs inside the monster JAR.You will probably have to unjar the native library to the local file system.  As far as I know the bit of code that does the native loading looks at the file system.This code should help get you started (I haven't looked at it in a while, and it is for a different purpose but should do the trick, and I am pretty busy at the moment, but if you have questions just leave a comment and I'll answer as soon as I can)."},
{"body": "I am writing a Java utility which helps me to generate loads of data for performance testing.  It would be  cool to be able to specify a regex for Strings so that my generator spits out things which match this.  Is there something out there already baked which I can use to do this?  Or is there a library which gets me most of the way there?Thanks As mentioned in the comments, there is a library available at Google Code to acheive this:\nSee also  as suggested by Firstly, with a complex enough regexp, i believe this can be impossible. But you should be able to put something together for simple regexps.If you take a look at the source code of the class java.util.regex.Pattern, you'll see that it uses an internal representation of Node instances. Each of the different pattern components have their own implementation of a Node subclass. These Nodes are organised into a tree.By producing a visitor that traverses this tree, you should be able to call an overloaded generator method or some kind of Builder that cobbles something together. is capable of doing it as well:It's too late to help the original poster, but it could help a newcomer.  is a useful java library that provides many features for using regexes to generate strings (random generation, generating a string based on its index, generating all strings...).Example :Visual Studio Team System does include something like this. Not much help for Java though, so sorry.I've gone the root of rolling my  library for that (In c# but should be easy to understand for a Java developer).Rxrdg started as a solution to a problem of creating test data for a real life project. The basic idea is to leverage the existing (regular expression) validation patterns to create random data that conforms to such patterns. This way valid random data is created. It is not that difficult to write a parser for simple regex patterns. Using an abstract syntax tree to generate strings should be even easier.On stackoverflow podcast 11:This is probably not what you are looking for, but it might be a good starting off point, instead of creating your own.I can't seem to find anything in google, so I would suggest tackling the problem by parsing a given regular expression into the smallest units of work (\\w, [x-x], \\d, etc) and writing some basic methods to support those regular expression phrases.So for \\w you would have a method getRandomLetter() which returns any random letter, and you would also have getRandomLetter(char startLetter, char endLetter) which gives you a random letter between the two values.I know there's already an accepted answer, but I've been using  (the one mentioned in Craig's answer) and it works REALLY well for everything I've thrown at it. It's quick and that leaves me wanting to use the same regex to generate the real data for things like registration codes that this thing spits out.It takes a regex like:and it generates tons of unique codes like:Is this some big secret algorithm that RedGate figured out and we're all out of luck or is it something that us mere mortals actually could do?You'll have to write your own parser, like the author of String::Random (Perl) did. In fact, he doesn't use regexes anywhere in that module, it's just what perl-coders are used to.On the other hand, maybe you can have a look at , to get some pointers.EDIT: Damn, blair beat me to the punch by 15 seconds.It's far from supporting a full PCRE regexp, but I wrote the following Ruby method to take a regexp-like string and produce a variation on it. (For language-based CAPTCHA.)I am on flight and just saw the question: I have written easiest but inefficient and incomplete solution. I hope it may help you to start writing your own parser:Adding another tool I did not see listed here, that worked for me.\n(I tried the C# solution from Goran - Rxrdg - but with me the solution does not build).The link below is pretty simple and easy, and did the job for me:\nIf you want to generate \"critical\" strings, you may want to consider:EGRET \nthat generates \"evil\" strings covering your regular expressionsMUTREX \nthat generates fault-detecting strings by regex mutationBoth are academic tools (I am one of the authors of the latter) and work reasonably well."},
{"body": "I'm baffled that I can't find a quick answer to this.  I'm essentially looking for a datastructure in Java which implements the  interface, but which stores its members in a sorted order.  I know that you can use a normal  and use  on it, but I have a scenario where I am occasionally adding and often retrieving members from my list and I don't want to have to sort it every time I retrieve a member in case a new one has been added.  Can anyone point me towards such a thing which exists in the JDK or even 3rd party libraries?:  The datastructure will need to preserve duplicates.:  I found all of this very interesting and learned a lot.  Aioobe in particular deserves mention for his perseverance in trying to achieve my requirements above (mainly a sorted java.util.List implementation which supports duplicates).  I have accepted his answer as the most accurate for what I asked and most thought provoking on the implications of what I was looking for even if what I asked wasn't exactly what I needed.  The problem with what I asked for lies in the List interface itself and the concept of optional methods in an interface.  To quote the javadoc:Inserting into a sorted list doesn't have precise control over insertion point.  Then, you have to think how you will handle some of the methods.  Take  for example:You are now left in the uncomfortable situation of either\n1) Breaking the contract and implementing a sorted version of add\n2) Letting  add an element to the end of the list, breaking your sorted order\n3) Leaving  out (as its optional) by throwing an  and implementing another method which adds items in a sorted order.Option 3 is probably the best, but I find it unsavory having an add method you can't use and another sortedAdd method which isn't in the interface.Other related solutions (in no particular order):Here is a \"minimal\" solution.The insert runs in linear time, but that would be what you would get using an ArrayList anyway (all elements to the right of the inserted element would have to be shifted one way or another).Inserting something non-comparable results in a ClassCastException. (This is the approach taken by  as well: )Note that overriding  (or  for that matter) to insert elements in a sorted fashion would be a . What you  do, is to override this method to throw an .From the docs of :Same reasoning applies for both versions of , both versions of  and . (All of which are optional operations according to the list interface.)....prints:Use .Have a look at   You can try  .Lists typically preserve the order in which items are added. Do you definitely need a , or would a sorted  (e.g. ) be okay for you? Basically, do you need to need to preserve duplicates?It might be a bit too heavyweight for you, but  has a  that is perfect to use as the model of a table or JListAioobe's approach is the way to go. I would like to suggest the following improvement over his solution though.aioobe's solution gets very slow when using large lists. Using the fact that the list is sorted allows us to find the insert point for new values using binary search.I would also use composition over inheritance, something along the lines of You could subclass ArrayList, and call Collections.sort(this) after any element is added - you would need to override two versions of add, and two of addAll, to do this.Performance would not be as good as a smarter implementation which inserted elements in the right place, but it would do the job. If addition to the list is rare, the cost amortised over all operations on the list should be low.I think the choice between SortedSets/Lists and 'normal' sortable collections depends, whether you need sorting only for presentation purposes or at almost every point during runtime. Using a sorted collection may be much more expensive because the sorting is done everytime you insert an element. If you can't opt for a collection in the JDK, you can take a look at the Since the currently proposed implementations which do implement a sorted list by breaking the Collection API, have an own implementation of a tree or something similar, I was curios how an implementation based on the TreeMap would perform. (Especialy since the TreeSet does base on TreeMap, too)If someone is interested in that, too, he or she can feel free to look into it:Its part of the , you can add it via Maven dependency of course. (Apache License)Currently the implementation seems to compare quite well on the same level than the guava SortedMultiSet and to the TreeList of the Apache Commons library.But I would be happy if more than only me would test the implementation to be sure I did not miss something important.Best regards!I had the same problem. So I took the source code of java.util.TreeMap and wrote . It implements my own :The implementation is based on updating node weights in the red-black tree when it is changed. Weight is the number of child nodes beneath a given node, plus one - self. For example when a tree is rotated to the left:updateWeight simply updates weights up to the root:And when we need to find the element by index here is the implementation that uses weights:Also comes in very handy finding the index of a key:You can find the result of this work at TreeSet/TreeMap (as well as their indexed counterparts from the indexed-tree-map project) do not allow duplicate keys , you can use 1 key for an array of values. If you need a SortedSet with duplicates use TreeMap with values as arrays. I would do that."},
{"body": "Since I received no positives answers to my  question. I will try to write a Java FTP upload applet myself.My question is: \"Can you recommend a Java FTP client library for me to use?\"I want it to be:I found   of some libraries, but since this article is from 2003, maybe some new developments have happened :)Check out Apache , which contains FTP utilities. Off the top of my head I'm not sure if it meets all of your requirements, but it's certainly free!ftp4j is the best one, both for features and license:Yes, EnterpriseDT's  is stable (first released in 2000), has all the features you might need, and is open source as well. It's used in a bunch of open source projects (as well as in many commercial projects), and is acknowledged to be . As another poster noted, if you do wish to upgrade to SFTP and/or FTPS, it is a simple upgrade path with very few code changes required.I used cyaCommons-net surely. :) Most open source projects use it these days.ycI have successfully used the  library, which is free and open source. I can't compare it to other libraries (like the Apache Commons Net library) since I haven't used them. It does provide a simple upgrade path to SFTP (over SSH) and FTPS (over SSL), though that is a pay-for commercial product.Apache commons-nets get updates more frequently recently, while Enterprise DT library seems to update even more frequently.You have also this  which lists different options for FTP clients.commons-net is good, but  can give you some of the more advanced features you are looking for.I was downloading video files. Apache's FTPClient fumbled, it downloaded the video reasonably fast. but when I tried to play the video back, it lost chunks out of the middle of the video. ftp4j would download the whole video with no loss.ftp4j ftw"},
{"body": "How do you detect if  has been called on a socket on the remote side?The  method won't help, it will return  even if the remote side has closed the socket. Try this: Start the server, start the client. You'll see that it prints \"connected: true\" twice, even though the socket is closed the second time.The only way to really find out is by reading (you'll get -1 as return value) or writing (an  (broken pipe) will be thrown) on the associated Input/OutputStreams.Since the answers deviate I decided to test this and post the result - including the test example.The server here just writes data to a client and does not expect any input.The server:You can also check for socket output stream error while writing to client socket.The method Socket.Available will immediately throw a SocketException if the remote system has disconnected/closed the connection."},
{"body": "I hear nowadays a lot about the Spring Framework. Why is there so much buzz around the Spring Framework in the industry?I already gave a partial answer in  but I'll add some links in this answer. Actually, I won't cover or discuss the technical qualities of Spring as they aren't new and don't explain the buzz in my opinion. Instead, consider the following events and acquisitions:As you can see, there have been lots of changes in the SpringSource sphere during the past year, with some pretty big moves during this summer. Don't you see the big picture now? Well, look at the resulting stack: with Java, Groovy, Grails as languages, Spring as container, tc Server as underlying application server, Hyperic for health and monitoring, VMware for virtualization, CloudFoundry as management and provisioning system, VMware/SpringSource has . And by complete, I mean really complete as this stack covers everything - except the JVM - to put Java on the Cloud: the software, the platform and the infrastructure i.e. all the different flavors of cloud computing.In other words, while others are still preparing themselves for it, VMware and SpringSource are already ready for the SaaS/PaaS/IaaS wave. This is exciting, this is where innovation goes, this creates (or at least feeds) the trend, this puts a lot of pressure on Java, the Application Server market, Java EE,... and this explains IMO the buzz around VMware/SpringSource. More than the upcoming arrival of Spring 3.0 :). Software as a Service\n Platform as a Service\n Infrastructure as a Service  Spring has been around for a while, it introduced important new design patterns, and it is indirectly responsible for reforming But I'm thinking you are hearing about it now because in August, VMware bought SpringSource for $420 million. That's rather high for an open source developer and consulting company...Let me try to explain you why spring, what is there in spring and what made spring so popular.The basic Idea of Spring Framework isI think you may want to read about , and .Spring is (among several other things) an inversion of control container.In the primordial days of crusty old J2EE, Spring Framework came along and made it possible to inject JNDI registered services into EJBs. Gee, you could actually begin to design an EJB to where it could be unit tested without having to fire up a J2EE app server - just mock the JNDI services that it collaborated with via Spring dependency injection.Well, for it's day, that was a not so minor miracle.These days, if you want to know why Spring continues to rock, check out this book and learn about this development stack, and how Spring is instrumental as the core bean factory mechanism to everything that surrounds it - from BlazeDS services to iBATIS or Hibernate to ActiveMQ messaging beans:And check out this article:Well it provides a great additional framework that lets you concentrate on writing less framework code and more application code.It provides things like:and a whole lot more.A lot of these concepts are fairly complex and because they provide the framework it means you can just plug in their components and leverage what has already been created for you."},
{"body": "Let's say the bottleneck of my Java program really is some tight loops to compute a bunch of vector dot products. Yes I've profiled, yes it's the bottleneck, yes it's significant, yes that's just how the algorithm is, yes I've run Proguard to optimize the byte code, etc.The work is, essentially, dot products. As in, I have two  and I need to compute the sum of pairwise products. I know processor instruction sets exist to perform these kind of operations quickly and in bulk, like SSE or MMX.Yes I can probably access these by writing some native code in JNI. The JNI call turns out to  be pretty expensive.I know you can't guarantee what a JIT will compile or not compile. Has anyone  heard of a JIT generating code that uses these instructions? and if so, is there anything about the Java code that helps make it compilable this way?Probably a \"no\"; worth asking.So, basically, you want your code to run faster. JNI is the answer. I know you said it didn't work for you, but let me show you that you are wrong.Here's :and :We can compile and run that with  using commands line these:With an Intel Core i7-3632QM CPU @ 2.20GHz, Fedora 20, GCC 4.8.3, and OpenJDK 7 or 8, I get this kind of output:Or roughly 1.6 times faster. We need to use direct NIO buffers instead of arrays, but . On the other hand, manually unrolling the loop does not provide a measurable boost in performance, in this case.At least according to this  it is possible to aid the JIT compiler to identify your code as a vector operation. It does require some hinting, but it's at least possible. \"It is evident that most of the improvement comes as a result of persuading the JIT to recognise places where SIMD operations can be written as instructions accessing the SSE registers. By enabling this behaviour, the amount of floating-point arithmetic per cycle increases and as a consequence the rate at which the computation proceeds increases\"[Edit:15/10/2015] To address some of the scepticism expressed by others here I suggest anyone who wants to prove to themselves or other use the following method:Example:The result with and without the flag (on recent Haswell laptop, Oracle JDK 8u60):\n-XX:+UseSuperWord :  475.073 \u00b1 44.579  ns/op (nanoseconds per op)\n-XX:-UseSuperWord : 3376.364 \u00b1 233.211 ns/opThe assembly for the hot loop is a bit much to format and stick in here  but here's a snippet(hsdis.so is failing to format some of the AVX2 vector instructions so I ran with -XX:UseAVX=1): -XX:+UseSuperWord(with '-prof perfasm:intelSyntax=true')Have fun storming the castle!In HotSpot versions beginning with Java 7u40, the server compiler provides support for auto-vectorisation. According to However, this seems to be true only for \"simple loops\" - at least for the moment. For example, accumulating an array cannot be vectorised yet You could write OpenCl kernel to do the computing and run it from java . Code can be run on CPU and/or GPU and OpenCL language supports also vector types so you should be able to take explicitly advantage of e.g. SSE3/4 instructions.I'm guessing you wrote this question before you found out about netlib-java ;-) it provides exactly the native API you require, with machine optimised implementations, and does not have any cost at the native boundary due thanks to memory pinning.Have a look at . They show that Java HotSpot VM server compiler supports auto-vectorization using Super-word Level Parallelism, which is limited to simple cases of inside the loop parallelism. This article will also give you some guidance whether your data size is large enough to justify going JNI route.I dont believe most if any VMs are ever smart enough for this sort of optimisations. To be fair most optimisations are much simpler, such as shifting instead of multiplication whena power of two. The mono project introduced their own vector and other methods with native backings to help performance."},
{"body": "Which one of the 2 options is better and faster to clear an ArrayList, and why?orIt happens that I have to, at random times, clear all entries from my ArrayList and I have no way to know how many new entries there will be in the future, there might be 0 or a 1000. Which method is faster and better, and why?It's hard to know without a benchmark, but if you have lots of items in your ArrayList and the average size is lower, it might be faster to make a new ArrayList.  would remove the elements without reducing the capacity of the list.Here mylist got cleared, the references to the elements held by it got nulled out, but it keeps the same backing array. Then mylist was reinitialized and got a new backing array, the old one got GCed. So one way holds onto memory, the other one throws out its memory and gets reallocated from scratch (with the default capacity). Which is better depends on whether you want to reduce garbage-collection churn or minimize the current amount of unused memory. Whether the list sticks around long enough to be moved out of Eden might be a factor in deciding which is faster (because that might make garbage-collecting it more expensive).I think that the answer is that it depends on a whole range of factors such as:These make it hard to predict which will be better.  But my intuition is that the difference will not be that great.Two bits of advice:The first one  will keep the same list just clear the list. The second one  creates a new  in memory.Suggestion: First one because that's what is is designed to do.If there is a good chance that the list will contain as much elements as it contains when clearing it, and if you're not in need for free memory, clearing the list is a better option. But my guess is that it probably doesn't matter. Don't try to optimize until you have detected a performance problem, and identified where it comes from.Tried the below program , With both the approach. \n1. With clearing the arraylist obj in for loop\n2. creating new New Arraylist in for loop. and to my surprise. the memory allocation didnt change much.  Before loop total free memory: 64,909 :: After loop total free memory: 64,775 ::  Before loop total free memory: 64,909 :: \nAfter loop total free memory: 64,765 ::So this says there is not much difference in using arraylist.clear from memory utilization perspective.   is going to keep the same ArrayList but the same memory allocation.  is going to allocate new memory for your ArrayList.The big difference is that ArrayLists will expand dynamically as you need more space.  Therefore, if you call  you will still, potentially, have a large amount of memory allocated for an ArrayList that might not be needed.That said  will be faster but if memory maters you might want to allocate a new ArrayList.I would suggest using list.clear() rather than allocating a new object. When you call the \"new\" keyword, you are creating more space in memory. In reality, it doesn't matter much. I suppose that if you know how large the list will be, it might be a good idea to create a new space but then specify how large the array will be.The truth is, it's not going to matter unless you're doing scientific programming. In that case, you need to go learn C++."},
{"body": "3 questions:The connection timeout is the timeout in making the initial connection; i.e. completing the TCP connection handshake.  The read timeout is the timeout on waiting to read data. Specifically, if the server fails to send a byte <timeout> seconds after the last byte, a read timeout error will be raised.It means that the connection attempt can potentially block for ever.  There is no infinite loop, but the attempt to connect can be unblocked by another thread closing the socket.  (A  call may also do the trick ... not sure.)It means that a call to  on the socket stream may block for ever.  Once again there is no infinite loop, but the  can be unblocked by a  call, closing the socket, and (of course) the other end sending data or closing the connection.These are timeout values enforced by JVM for TCP connection establishment and waiting on reading data from socket.If the value is set to infinity, you will not wait forever. It simply means JVM doesn't have timeout  and OS will be responsible for all the timeouts. However, the timeouts on OS may be really long. On some slow network, I've seen timeouts as long as 6 minutes.Even if you set the timeout value for socket, it may not work if the timeout happens in the native code. We can reproduce the problem on Linux by connecting to a host blocked by firewall or unplugging the cable on switch.The only safe approach to handle TCP timeout is to run the connection code in a different thread and interrupt the thread when it takes too long."},
{"body": "I have a function that uses Pattern.compile and a Matcher to search a list of strings for a pattern.  This function is used in multiple threads.  Each thread will have a unique pattern passed to the Pattern.compile when the thread is created.  The number of threads and patterns are dynamic, meaning that I can add more patterns and threads during configuration.Do I need to put a \"synchronize\" on this function if it uses regex?  Is regex in java thread safe?TIA, from the Java API documentation for the If you are looking at performance centric code, attempt to reset the Matcher instance using the reset() method, instead of creating new instances. This would reset the state of the Matcher instance, making it usable for the next regex operation. In fact, it is the state maintained in the Matcher instance that is responsible for it to be unsafe for concurrent access.While you need to remember that thread safety has to take into account the surrounding code as well, you appear to be in luck.  The fact that  are created using the Pattern's  factory method and lack public constructors is a positive sign.  Likewise, you use the  static method to create the encompassing .So, in short, if you do something like the example:you should be doing pretty well.Follow-up to the code example for clarity: note that this example strongly implies that the Matcher thus created is thread-local with the Pattern and the test.  I.e., you should not expose the Matcher thus created to any other threads.Frankly, that's the risk of any thread-safety question.  The reality is that  code can be made thread-unsafe if you try hard enough.  Fortunately, there are   that teach us a whole bunch of ways that we could ruin our code.  If we stay away from those mistakes, we greatly reduce our own probability of threading problems.A quick look at the code for  shows a bunch of member variables including the text that is being matched, arrays for groups, a few indexes for maintain location and a few s for other state.  This all points to a stateful  that would not behave well if accessed by multiple .  So does the :This is only an issue if, as @Bob Cross points out, you go out of your way to allow use of your  in separate s.  If you need to do this, and you think that synchronization will be an issue for your code, an option you have is to use a  storage object to maintain a  per working thread.To sum up, you can reuse (keep in static variables) the compiled Pattern(s) and tell them to give you new Matchers when needed to validate those regex pattens against some stringsee  (near the end) regarding the RegEx pattern used above for validating e-mails (in case it doesn't fit ones needs for e-mail validation as it is posted here)"},
{"body": "I have a java complied package to speak with the https server on net. Running the compilation gives the following exception:I think this is due to the connection established with the client machine is not secure.  Is there any way to configure the local machine or ports in order to connect to the remote https server?It is due to the fact that you are talking to an HTTP server, not an HTTPS server. Probably you didn't use the correct port number for HTTPS.You should have a local SMTP domain name that will contact the mail server and establishes a new connection as well you should change the SSL property in your programming below I got the same error message when I forgot to log in to the company firewall, before performing a POST request through a proxy.I got the same error. it was because I was accessing the https port using http.. The issue solved when I changed http to https. I face the same issue from Java application built in Jdevelopr 11.1.1.7 IDE. I solved the issue by unchecking the use of proxy form Project properties.You can find it in the following:\nProject Properties -> (from left panle )Run/Debug/Profile ->Click (edit) form the right panel -> Tool Setting from the left panel -> uncheck (Use Proxy) option.It worked for me now, I have change the setting of my google account as below:      Though I have enabled SSL and TSL while running program in this  of same post. I spend a lot of time but than I realized and found this link.\nAnd done 2 following steps and setting control in google. : Now I am able to send mail using above program.As EJP said, it's a message shown because of a call to a non-https protocol.\nIf you are sure it is HTTPS, check your bypass proxy settings, and in case add your webservice host url to the bypass proxy listAdding this as an answer as it might help someone later.I had to force jvm to use the IPv4 stack to resolve the error. My application used to work within company network, but while connecting from home it gave the same exception. No proxy involved. Added the jvm argument \n    and all the  requests were behaving normally.if connection is FTPS test:FTPSClient ftpClient = new FTPSClient(protocol, false);protocol = TLS,SSL\nand false = isImplicit.Another reason is maybe \"access denided\", maybe you can't access to the URI and received blocking response page for internal network access. If you are not sure your application zone need firewall rule, you try to connect from terminal,command line. \nFor GNU/Linux or Unix, you can try run like this command and see result is coming from blocking rule or really remote address: Maybe your default cerficate has expired. to renew it through admin console go \"Security >SSL certificate and key management > Key stores and certificates > NodeDefaultKeyStore > Personal certificates\"  select the \"default\" alias and click on \"renew\" after then restart WAS.If you're running the Java process from the command line on Java 6 or earlier, adding this switch solved the issue above for me:-Dhttps.protocols=\"TLSv1\""},
{"body": "What exactly are the differences between  and ? When I run both of these commands, they both seem to do the same thing.  Well, both will clean.  That means they'll remove the target folder.   The real question is what's the difference between package and install?   will compile your code and also package it.  For example, if your pom says the project is a jar, it will create a jar for you when you package it and put it somewhere in the target directory (by default). will compile and package, but it will also put the package in your local repository.  This will make it so other projects can refer to it and grab it from your local repository.  Package & install are various phases in maven build lifecycle. package phase will execute all phases prior to that & it will stop with packaging the project as a jar. Similarly install phase will execute all prior phases & finally install the project locally for other dependent projects. For understanding maven build lifecycle please go through the following link "},
{"body": " has been out for a while now, but I cannot find any good resources on the configuration of the , specifically the new .\nMy questions:The G1 garbage collector is not the default in my installation of Java, version 1.7.0_01. You can see for yourself by using with some extra command line options:You don't need to enable experimental options to turn on the G1 collector any more, though:I don't know where you can find any good documentation.Oracle finally made G1 official in Java 7 U4:\nDescription:\nCommand line options:\nStill, I do not think it is the default collector in Java 7. For servers the default is the Parallel Collector as in Java 6.Yes, G1 is the new standard garbage collector in Java 1.7 JVM. you can find plenty of information on how to use and configre the new garbage collector:I have also found  article very helpful in understanding the inners of G1.Even more info .The rule on  is still applicable in Java 7 (and AFAIK, Java 8):But also consider: For example, if on Windows x64 you run...As of Java 7, simply . Perhaps also of interest is  you would want to:I've not used G1 myself, but  that it adheres to the same basic \"throughput / ergonomic\" flags used to tune the other parallel collectors. In my experience with the Parallel GC,  has been the pivotal one in providing the expected speed-memory tradeoff. YMMV.G1-specific options are listed Don't know,  It can be a pain to find, can't it? Probably the best \"hub\" page I've found is this one:Some deep reading required, but worth the time if you need to do some tuning. Particularly insightful is: G1 is not default collector in Java 7.  will enable G1GC There are many. Have a look at this  article for complete information..Here is a list of important options and their default values. This list applies to the latest Java HotSpot VM, build 24. You can adapt and tune the G1 GC  settings on the JVM command line.Sets the size of a G1 region. The value will be a power of two and can range from 1MB to 32MB. The goal is to have around 2048 regions based on the minimum Java heap size.Sets a target value for desired maximum pause time. The default value is 200 milliseconds. The specified value does not adapt to your heap size.Sets the percentage of the heap to use as the minimum for the young generation size. The default value is 5 percent of your Java heap. Sets the percentage of the heap size to use as the maximum for young generation size. The default value is 60 percent of your Java heap.Sets the value of the STW worker threads. Sets the value of n to the number of logical processors. The value of n is the same as the number of logical processors up to a value of 8.If there are more than eight logical processors, sets the value of n to approximately 5/8 of the logical processors. This works in most cases except for larger SPARC systems where the value of n can be approximately 5/16 of the logical processors.Sets the number of parallel marking threads. Sets n to approximately 1/4 of the number of parallel garbage collection threads (ParallelGCThreads).Sets the Java heap occupancy threshold that triggers a marking cycle. The default occupancy is 45 percent of the entire Java heap.Sets the occupancy threshold for an old region to be included in a mixed garbage collection cycle. The default occupancy is 65 percentSets the percentage of heap that you are willing to waste. The Java HotSpot VM does not initiate the mixed garbage collection cycle when the reclaimable percentage is less than the heap waste percentageSets the target number of mixed garbage collections after a marking cycle to collect old regions with at most G1MixedGCLIveThresholdPercent live data. The default is 8 mixed garbage collectionsSets an upper limit on the number of old regions to be collected during a mixed garbage collection cycle. The default is 10 percent of the Java heapSets the percentage of reserve memory to keep free so as to reduce the risk of to-space overflows. The default is 10 percent. When you increase or decrease the percentage, make sure to adjust the total Java heap by the same amount.You have re-configured many G1GC parameters, which are not required if you follow above documentation page. Please cross check with above recommendations especially on  and , which are to be based on your CPU cores. Remove re-configuration of un-necessary parameters.  from oracle:When you evaluate and fine-tune G1 GC, keep the following recommendations in mind:There are some changes with Java 7. Have a look at this Refer to oracle documentation page about  and related SE question:The documentation available at  (the link provided by Wojtek) seems to be the only official link with info but the info seems outdated as some of the flags mentioned there were only available in the test builds, they no longer exist in the production releases. Some one from Oracle should provide some updated documentation on the G1 GC.No G1 is not default garbage collector in jdk 1.7.0_02.\nThe default garbage collector depends upon the class of machine.\nIf the machine is of Server class then the default garbage collector is Throughput Collector.\nIf the machine is of Client class then the default garbage collector is Serial Collector.By default you don't really want to use G1 collector, as it is not really better than the others. It is only good for special purposes.In low latency application is is sligthly better than CMS, as it has a little bit shorter, and more predictable pause times. In exchange the throughput is much worse than CMS in exchange.So it is only good if the latency is important, but the throughput is not important at all. If both are important, then stay with CMS."},
{"body": "In a simulation server environment where users are allowed to submit their own code to be run by the server, it would clearly be advantageous for any user-submitted code to be run in side a sandbox, not unlike Applets are within a browser.  I wanted to be able to leverage the JVM itself, rather than adding another VM layer to isolate these submitted components.This kind of limitation appears to be possible using the existing Java sandbox model, but is there a dynamic way to enable that for just the user-submitted parts of a running application? was designed to solve this, but unfortunately it doesn't have an implementation yet.This is a pretty detailed topic, and I'm mostly writing this all off the top of my head.But anyway, some imperfect, use-at-your-own-risk, probably buggy (pseudo) code:Obviously such a scheme raises all sorts of security concerns. Java has a rigorous security framework, but it isn't trivial. The possibility of screwing it up and letting an unprivileged user access vital system components shouldn't be overlooked.That warning aside, if you're taking user input in the form of source code, the first thing you need to do is compile it to Java bytecode. AFIAK, this cannot be done natively, so you'll need to make a system call to javac, and compile the source code to bytecode on disk.  a tutorial that can be used as a starting point for this.\n: as I learned in the comments, you actually can compile Java code from source natively using Once you have JVM bytecode, you can load it into the JVM using a   function. To set a security context for this loaded class you will need to specify a . The minimal constructor for a  requires both a CodeSource and a . The PermissionCollection is the object of primary use to you here- you can use it to specify the exact permissions the loaded class has. These permissions should be ultimately enforced by the JVM's .There's a lot of possible points of error here, and you should be extremely careful to completely understand everything before you implement anything.The  is a library for executing Java code with a limited set of permissions. \nIt can be used to allow access to only a set of white-listed classes and resources. It doesn't seem\nto be able to restrict access to individual methods. It uses a system with a custom class loader and\nsecurity manager to achieve this.I have not used it but it looks well designed and reasonably well documented.@waqas has given a very interesting answer explaining how this is possible to implement yourself. But it is much safer to leave such security critical and complex code to experts.Notice though that the project has not been updated since 2013 and the the creators describe it as \"experimental\". Its home page has disappeared but the Source Forge entry remains. Example code adapted from the project web site:To address the problem in the accepted answer whereby the custom  will apply to all threads in the JVM, rather than on a per-thread basis, you can create a custom  that can be enabled/disabled for specific threads as follows: is just a simple implementation of  to ensure that only authorised code can enable/disable the security manager. It looks like this:Well it's very late to give any suggestions or solutions, but still I was facing similar kind of issue, kind of more research oriented. Basically I was trying to provide a provision and automatic evaluations for programming assignments for Java course in e-learning platforms.I know this sounds a quite complex and lot of tasks, but Oracle Virtual Box already provides Java API to create or clone virtual machines dynamically.\n (Note, even VMware also provides API for doing same)And for the minimum size and configuration Linux distribution you can refer to this one here ,So now if students messes up or tries to do it, may be with memory or file system or networking, socket, maximum he can damage his own VM.Also internally into these VM's you can provide additional security like Sandbox (security manager ) for Java or creating user specific accounts on Linux and thus restricting access.Hope this helps !!Here's a thread-safe solution for the problem:Please comment!CUArnoYou will probably need to use a custom  and/or . For lots of detail, see  and  from Sun."},
{"body": "Suppose i have a page that lists the objects on a table and i need to put a form to filter the table. The filter is sent as an Ajax GET to an URL like that: And instead of having lots of parameters on my Controller like:And supposing i have MyObject as:I wanna do something like:Is it possible? \nHow can i do that?You can absolutely do that, just remove the  annotation, Spring will cleanly bind your request parameters to your class instance:I will add some short example from me.The DTO class:Request mapping inside controller class:Query:Result:I hope it helps :)I have a very similar problem. Actually the problem is deeper as I thought. I am using jquery  which uses  as default. Unfortunately I based my system on that and when I needed a complex object as a  I couldn't just make it happen.In my case I am trying to send user preferences with something like;On client side the actual raw data sent to the server is; parsed as;and the server side is;I tried , added setter/getters, constructors with all possibilities to  but no chance as it recognized the sent data as 5 parameters but in fact the mapped method has only 2 parameters. I also tried Biju's solution however what happens is that, spring creates an UserPreferences object with default constructor and doesn't fill in the data.I solved the problem by sending JSon string of the preferences from the client side and handle it as if it is a String on the server side;client:server:to brief, I did the conversion manually inside the REST method. In my opinion the reason why spring doesn't recognize the sent data is the content-type."},
{"body": "What are .jspf files in JSP? As I know the compiler will look for .jsp files to compile, then how are the .jspf files compiled?As others have noted, .jspf files are JSP fragments. They're designed to be statically included in another JSP file, not compiled on their own:You'll note that this example comes from the  directory. This means that it is not accessible outside of the web application; there's no way to construct a URL that can retrieve it. If you put them in the same directory as \"normal\" JSP files, you can construct such a URL; Tomcat, for example will retrieve the page as a text document. A front-end web-server, however, can block these URLS.I like JSPF files as a first step in . Since they're statically included, you can extract a small chunk of the file without making provision for scriptets or variables, leading to pages that are somewhat more maintainable (and I want to stress, it's a  step; dynamic includes and taglibs are usually a better long-term solution). When refactoring, I believe in keeping the fragments close to their parent files; this is when having a web-server to block URLs becomes useful.JSP Fragments can be compared to server side includes. These fragments are not compiled on their own, however there are compiled along side the page in which its included. If I've to display different pages base on a user preference, i will opt for jspf. .jspf files are generally files that are included in .jsp files via the include directive. The 'f' stands for 'fragment' as these files are not full JSPs in and of themselves.  Since .jspf is a fragment of a jsp hence it may not be complete and compilable source, so most of the time it can't be compiled independently of another, complete, source that references them. :  that .jspf is for JSP fragments. A fragment may not be complete and compilable source, so they likely can't be compiled independently of another, complete, source that references them.They're mentioned in  in the same context - a naming convention for JSP Fragments.In many web frameworks, it's possible to assemble views and pages from smaller, shared views and pages. Using JSP, these smaller pieces are called . As the name implies, they're not necessarily a complete representation without some larger context.Other languages and frameworks have their own term for the equivalent concept. In Ruby on Rails, for example, they're called ."},
{"body": "I have a crazy question about Java switches.Scenario 1 - When the  is two it successfully print the value as 2.\nScenario 2 - When I'm going to comment  in  it squawks saying the .Questions : \nScenario 1 : If the execution flow doesn't go to  (when the ), then how does it know the type of the value variable as ?\nScenario 2 : If the compiler knows the type of the value variable as , then it must have accessed to the  expression in .(Declaration and Initialization). Then why does it sqawrk When I'm going to comment  in , saying the .Switch statements are odd in terms of scoping, basically. From :In your case,  is in the same  as  and appears after it, even though  will never execute... so the local variable is in scope and available for  despite you logically never \"executing\" the declaration. (A declaration isn't really \"executable\" although initialization is.)If you comment out the  assignment, the compiler still knows which variable you're referring to, but you won't have gone through any execution path which assigns it a value, which is why you get an error as you would when you try to read any other not-definitely-assigned local variable.I would strongly recommend you  to use local variables declared in other cases - it leads to highly confusing code, as you've seen. When I introduce local variables in switch statements (which I try to do rarely - cases should be very short, ideally) I usually prefer to introduce a new scope:I believe this is clearer.The variable has been declared (as an int), but not initialized (assigned an initial value).  Think of the line:As:The  part tells the compiler at compile time that you have a variable called value which is an int. The  part initializes it, but that happens at run-time, and doesn't happen at all if that branch of the switch isn't entered.From  "},
{"body": "I'm having trouble with a brand new project in a brand new installation of Eclipse. Repro steps:Expected: Brand new project works fine.Actual: There are two errors:What am I doing wrong here? Perhaps I don't actually have the Java 7 JDK on my machine. How can I be sure? Looks like Java 7 is in fact not out yet. Sweet. 1) Find out where java is installed on your drive, open a cmd prompt, go to that location and run \".\\java -version\" to find out the exact version. Or, quite simply, check the add/remove module in the control panel.2) After you actually install jdk 7, you need to tell Eclipse about it. Window -> Preferences -> Java -> Installed JREs.To set JDK you can watch this video : \n. Then when you'll have JDK:1)Go to configure build path . \n2)Remove unbound JRE library .\n3)Add library --> JRE System library .Then project compile and done .. Have you actually downloaded and installed one of the milestone builds from  ?You can have a play with the features, though it's not stable so you shouldn't be releasing software against them.Most of the time after the installation of Eclipse eclipse.ini is changed.\nIf you change the jdk in eclipse.ini then eclipse will use this jdk by default.Let's say you install a new version of Eclipse and you have forgotten to change the eclipse.ini related to the jdk. Then Eclipse finds a jdk for you.\nLet's say it is java 1.6 that was automatically discovered (you did nothing).If you use maven (M2E) and you reference a 1.7 jdk then you will see the frustrating message.\nBut normally it is not displayed because you configure the correct jdk in eclipse.ini.That was my case. I made reference into the pom to a jdk that was not configured into Eclipse.In the screenshot you can see that 1.7 is configured and seen by Eclipse. In this case, you should make reference into the pom to a jre that is compatible with 1.7! If not -> frustrating message!Cause : This is common scenario when we import new project with different lib and JAR path. I faced this issue and got resolved using exact following steps:This will point your system's proper & valid JRE path, which did thing for me.\nUpdated  file with key-value property to because, that is my JAVA version. Also, selected  as my project libraryUpdated eclipse.ini file with key value property\n-Dosgi.requiredJavaVersion=1.7 (or) 1.8 whichever applicable. \n- it works for me. "},
{"body": "in the case of using PreparedStatement with a single common connection without any pool, can I recreate an instance for every dml/sql operation mantaining the power of prepared statements? I mean:instead of:my question arises by the fact that I want to put this code into a multithreaded environment, can you give me some advice? thanksThe second way is a tad more efficient, but a much better way is to execute them in batches:You're however dependent on the JDBC driver implementation how many batches you could execute at once. You may for example want to execute them every 1000 batches:As to the multithreaded environments, you don't need to worry about this if you acquire and close the connection and the statement in the shortest possible scope  according the normal JDBC idiom using  statement as shown in above snippets.If those batches are transactional, then you'd like to turn off autocommit of the connection and only commit the transaction when all batches are finished. Otherwise it may result in a dirty database when the first bunch of batches succeeded and the later not.The loop in your code is only an over-simplified example, right?It would be better to create the PreparedStatement only once, and re-use it over and over again in the loop.In situations where that is not possible (because it complicated the program flow too much), it is still beneficial to use a PreparedStatement, even if you use it only once, because the server-side of the work (parsing the SQL and caching the execution plan), will still be reduced.To address the situation that you want to re-use the Java-side PreparedStatement, some JDBC drivers (such as Oracle) have a caching feature: If you create a PreparedStatement for the same SQL on the same connection, it will give you the same (cached) instance.About multi-threading: I do not think JDBC connections can be shared across multiple threads (i.e. used concurrently by multiple threads) anyway.Every thread should get his own connection from the pool, use it, and return it to the pool again."},
{"body": "Suppose I have a method that returns a read-only view into a member list:Further suppose that all the client does is iterate over the list once, immediately. Maybe to put the players into a JList or something. The client does  store a reference to the list for later inspection!Given this common scenario, should I return a stream instead?Or is returning a stream non-idiomatic in Java? Were streams designed to always be \"terminated\" inside the same expression they were created in?The answer is, as always, \"it depends\".  It depends on how big the returned collection will be.  It depends on whether the result changes over time, and how important consistency of the returned result is.  And it depends very much on how the user is likely to use the answer.  First, note that you can always get a Collection from a Stream, and vice versa:So the question is, which is more useful to your callers.  If your result might be infinite, there's only one choice: Stream.If your result might be very large, you probably prefer Stream, since there may not be any value in materializing it all at once, and doing so could create significant heap pressure.If all the caller is going to do is iterate through it (search, filter, aggregate), you should prefer Stream, since Stream has these built-in already and there's no need to materialize a collection (especially if the user might not process the whole result.)  This is a very common case.  Even if you know that the user will iterate it multiple times or otherwise keep it around, you still may want to return a Stream instead, for the simple fact that whatever Collection you choose to put it in (e.g., ArrayList) may not be the form they want, and then the caller has to copy it anyway.  if you return a stream, they can do  and get it in exactly the form they want.The above \"prefer Stream\" cases mostly derive from the fact that Stream is more flexible; you can late-bind to how you use it without incurring the costs and constraints of materializing it to a Collection.  The one case where you must return a Collection is when there are strong consistency requirements, and you have to produce a consistent snapshot of a moving target.  Then, you will want put the elements into a collection that will not change.So I would say that most of the time, Stream is the right answer -- it is more flexible, it doesn't impose usually-unnecessary materialization costs, and can be easily turned into the Collection of your choice if needed.  But sometimes, you may have to return a Collection (say, due to strong consistency requirements), or you may want to return Collection because you know how the user will be using it and know this is the most convenient thing for them.  I have a few points to add to .It's quite common to return a Stream from a \"getter\" style method call. See the  in the Java 8 javadoc and look for \"methods... that return Stream\" for the packages other than . These methods are usually on classes that represent or can contain multiple values or aggregations of something. In such cases, APIs typically have returned collections or arrays of them. For all the reasons that Brian noted in his answer, it's very flexible to add Stream-returning methods here. Many of these classes have collections- or array-returning methods already, because the classes predate the Streams API. If you're designing a new API, and it makes sense to provide Stream-returning methods, it might not be necessary to add collection-returning methods as well.Brian mentioned the cost of \"materializing\" the values into a collection. To amplify this point, there are actually two costs here: the cost of storing values in the collection (memory allocation and copying) and also the cost of creating the values in the first place. The latter cost can often be reduced or avoided by taking advantage of a Stream's laziness-seeking behavior. A good example of this are the APIs in :Not only does  have to hold the entire file contents in memory in order to store it into the result list, it also has to read the file to the very end before it returns the list. The  method can return almost immediately after it has performed some setup, leaving file reading and line breaking until later when it's necessary -- or not at all. This is a huge benefit, if for example, the caller is interested only in the first ten lines:Of course considerable memory space can be saved if the caller filters the stream to return only lines matching a pattern, etc.An idiom that seems to be emerging is to name stream-returning methods after the plural of the name of the things that it represents or contains, without a  prefix. Also, while  is a reasonable name for a stream-returning method when there is only one possible set of values to be returned, sometimes there are classes that have aggregations of multiple types of values. For example, suppose you have some object that contains both attributes and elements. You might provide two stream-returning APIs:That is how they are used in most examples.  Note: returning a Stream is not that different to returning a Iterator (admitted with much more expressive power)IMHO the best solution is to encapsulate why you are doing this, and not return the collection.e.g.or if you intend to count themI think it depends on your scenario. May be, if you make your  implement , it is sufficient. or in the a functional style:But if you want a more complete and fluent api, a stream could be a good solution. I would probably have 2 methods, one to return a  and one to return the collection as a .This is the best of both worlds.  The client can choose if they want the List or the Stream and they don't have to do the extra object creation of making an immutable copy of the list just to get a Stream.This also only adds 1 more method to your API so you don't have too many methods"},
{"body": "We have a Java-application that needs to be brought to the foreground when a telecontrol mechanism activates something in the application.In order to get this we have realised in the called method of the Class which represents the Frame of our application (extension of a JFrame) following implementation:Under Windows XP this works the first time it is called, on the second time only the tab in the taskbar flashes, the frame doesn't come to the front anymore. Same goes for Win2k. On Vista it seems to work fine.Anyone ideas?A possible solution is:I had the same problem with bringing a  to the front under Ubuntu (Java 1.6.0_10). And the only way I could resolve it is by providing a . Specifically, I had to set my  to always stay on top whenever  is invoked, and provide  event handler to . So, here is the code that could be placed into a base , which is used to derive all application frames.Whenever your frame should be displayed or brought to front call .Since I moved to Ubuntu 9.04 there seems to be no need in having a  for invoking  -- as can be observed; this code was moved to the methods  and .Please note that method  should always be invoked on EDT.Windows has the facility to prevent windows from stealing focus; instead it flashes the taskbar icon.  In XP it's on by default (the only place I've seen to change it is using TweakUI, but there is a registry setting somewhere).  In Vista they may have changed the default and/or exposed it as a user accessible setting with the out-of-the-box UI.Preventing windows from forcing themselves to the front and taking focus is a feature since Windows 2K (and I, for one, am thankful for it).That said, I have a little Java app I use to remind me to record my activities while working, and it makes itself the active window every 30 minutes (configurable, of course).  It always works consistently under Windows XP and never flashes the title bar window.  It uses the following code, called in the UI thread as a result of a timer event firing:(the first line restores if minimized... actually it would restore it if maximized too, but I never have it so).While I usually have this app minimized, quite often it's simply behind my text editor.  And, like I said, it always works.I do have an idea on what your problem could be - perhaps you have a race condition with the setVisible() call.  toFront() may not be valid unless the window is actually displayed when it is called; I have had this problem with requestFocus() before.  You may need to put the toFront() call in a UI listener on a window activated event. At some point in time the above code stopped working, perhaps at Java 6 or 7. After some investigation and experimentation I had to update the code to override the window's  method do this (in conjunction with modified code from what is above):As of Java 8_20, this code seems to be working fine.Here's a method that REALLY works (tested on Windows Vista) :DThe fullscreen variable indicates if you want the app to run full screen or windowed.This does not flash the task bar, but bring the window to front reliably.Hj, all methods of yours are not working for me, in Fedora KDE 14. I have a dirty way to do bring a window to front, while we're waiting for Oracle to fix this issue.And, this works perfectly in my Fedora KDE 14  :-)This simple method worked for me perfectly in Windows 7:I tested your answers and only  worked for me. Although I couldn't manage to restore the window to its previous state (maximized/normal). I found this mutation better:That is  instead of .Simplest way I've found that doesn't have inconsistency across platforms:setVisible(false);\nsetVisible(true);The rules governing what happens when you .toFront() a JFrame are the same in windows and in linux :-> if a window of the existing application is currently the focused window, then focus swaps to the requested window\n-> if not, the window merely flashes in the taskbarBUT : -> new windows automatically get focusSo let's exploit this ! You want to bring a window to the front, how to do it ? Well :Or, in java code :There are numerous  in the javadoc for the toFront() method which may be causing your problem. But I'll take a guess anyway, when \"only the tab in the taskbar flashes\", has the application been minimized? If so the following line from the javadoc may apply:\"If this Window is visible, brings this Window to the front and may make it the focused Window.\" To avoid the window losing focus when its returning to visible after being hidden all that is needed is:Like so:"},
{"body": "I'm using google-api-client-java 1.2.1-alpha to execute a POST request, and am getting the following stacktrace when I execute() the HttpRequest.  It happens immediately after I catch and ignore a 403 error from a previous POST to the same URL, and re-used the transport for the subsequent request.  (It's in a loop inserting multiple entries to the same ATOM feed).Is there something I should be doing to 'clean up' after a 403?Why would the code below me be trying to acquire a  connection?You need to consume the response body before you can reuse the connection for another request. You should not only read the response status, but read the response  fully to the last byte whereby you just ignore the read bytes.I was facing a similar issue when using the HttpClient with Jetty to build a test framework. I had to create multiple requests to the Servelet from my client, but It was giving the same exception when executed.I found an alternative at You can also use this following method to instantiate your client. A similar exception message (since at least Apache Jarkata Commons HTTP Client 4.2) is:  This exception can happen when two or more threads interact with a single .How can you make a 4.2  instance threadsafe ( in the sense that two or more threads can interact with it without getting above error message)? Provide  with a connection-pooling  in the form of !This is an often-asked question.  BalusC's response is correct.  Please catch , and call HttpResponseException..().  If you need to read the error message, use response.() if you don't know the response content type, else if you do know the content type use response.(MyType.class).A simple code snippet from  in  (though usually you'll want to do something smarter in a real application):Full disclosure: I am an owner of the  project.I had the same issue with a jax-rs (resteasy)  object in my unit tests.\nI solved this with a call to \nThe releaseConnection()-Method is only on the resteasy  object, so I had to add a cast from  to .Ok, i have similar problem, all those solution not work, i tested on some device, problem was date in device, it was 2011 instead 2013, check also this can help. Try thisRead the InputStream like this:"},
{"body": "I often find when debugging a program it is convenient, (although arguably bad practice) to insert a return statement inside a block of code. I might try something like this in Java ....of course, this would yield the compiler error.I could understand why a warning might be justified as having unused code is bad practice. But I don't understand why this needs to generate an error. Is this just Java trying to be a Nanny, or is there a good reason to make this a complier error?Because unreachable code is meaningless to the compiler. Whilst making code meaningful to people is both paramount and harder than making it meaningful to a compiler, the compiler is the essential consumer of code. The designers of Java take the viewpoint that code that is not meaningful to the compiler is an error. Their stance is that if you have some unreachable code, you have made a mistake that needs to be fixed.There is a similar question here: , in which the author says \"Personally I strongly feel it should be an error: if the programmer writes a piece of code, it should always be with the intention of actually running it in some scenario.\" Obviously the language designers of Java agree.Whether unreachable code should prevent compilation is a question on which there will never be consensus. But this is why the Java designers did it.A number of people in comments point out that there are many classes of unreachable code Java doesn't prevent compiling. If I understand the consequences of G\u00f6del correctly, no compiler can possibly catch all classes of unreachable code.Unit tests cannot catch every single bug. We don't use this as an argument against their value. Likewise a compiler can't catch all problematic code, but it is still valuable for it to prevent compilation of bad code when it can.The Java language designers consider unreachable code an error. So preventing it compiling when possible is reasonable.(Before you downvote: the question is not whether or not Java should have an unreachable statement compiler error. The question is  Java has an unreachable statement compiler error. Don't downvote me just because you think Java made the wrong design decision.)There is no definitive reason why unreachable statements must be not be allowed; other languages allow them without problems. For your specific need, this is the usual trick:It looks nonsensical, anyone who reads the code will guess that it must have been done deliberately, not a careless mistake of leaving the rest of  statements unreachable.Java has a little bit support for \"conditional compilation\"It is Nanny. \nI feel .Net got this one right - it raises a warning for unreachable code, but not an error. It is good to be warned about it, but I see no reason to prevent compilation (especially during debugging sessions where it is nice to throw a return in to bypass some code). I only just noticed this question, and wanted to add my $.02 to this.In case of Java, this is not actually an option. The \"unreachable code\" error doesn't come from the fact that JVM developers thought to protect developers from anything, or be extra vigilant, but from the requirements of the JVM specification.Both Java compiler, and JVM, use what is called \"stack maps\" - a definite information about all of the items on the stack, as allocated for the current method. The type of each and every slot of the stack must be known, so that a JVM instruction doesn't mistreat item of one type for another type. This is mostly important for preventing having a numeric value ever being used as a pointer. It's possible, using Java assembly, to try to push/store a number, but then pop/load an object reference. However, JVM will reject this code during class validation,- that is when stack maps are being created and tested for consistency.To verify the stack maps, the VM has to walk through all the code paths that exist in a method, and make sure that no matter which code path will ever be executed, the stack data  for every instruction agrees with what any previous code has pushed/stored in the stack. So, in simple case of:at line 3, JVM will check that both branches of 'if' have only stored into a (which is just local var#0) something that is compatible with Object (since that's how code from line 3 and on will treat local var#0).When compiler gets to an unreachable code, it doesn't quite know what state the stack might be at that point, so it can't verify its state. It can't quite compile the code anymore at that point, as it can't keep track of local variables either, so instead of leaving this ambiguity in the class file, it produces a fatal error.Of course a simple condition like  will fool it, but it's not really fooling - it's giving it a potential branch that can lead to the code, and at least both the compiler and the VM can determine, how the stack items can be used from there on.P.S. I don't know what .NET does in this case, but I believe it will fail compilation as well. This normally will not be a problem for any machine code compilers (C, C++, Obj-C, etc.)One of the goals of compilers is to rule out classes of errors.  Some unreachable code is there by accident, it's nice that javac rules out that class of error at compile time.For every rule that catches erroneous code, someone will want the compiler to accept it because they know what they're doing.  That's the penalty of compiler checking, and getting the balance right is one of the tricker points of language design.  Even with the strictest checking there's still an infinite number of programs that can be written, so things can't be that bad.While I think this compiler error is a good thing, there is a way you can work around it.\nUse a condition you know will be true:The compiler is not smart enough to complain about that.It is certainly a good thing to complain the more stringent the compiler is the better, as far as it allows you to do what you need.\nUsually the small price to pay is to comment the code out, the gain is that when you compile your code works. A general example is Haskell about which people screams until they realize that their test/debugging is main test only and short one. I personally in Java do almost no debugging while being ( in fact on purpose) not attentive.If the reason for allowing  is to allow flags, then the fact that  does not generate a compile time error seems like inconsistency in the policy of generating CodeNotReachable exception, since the compiler 'knows' that  is not a flag (not a variable).Two other ways which might be interesting, but don't apply to switching off part of a method's code as well as :Now, instead of saying  you might want to say  and add  to the jvm arguments. The good point is that this allows for some granularity and requires adding an extra parameter to the jvm invocation so there is no need of setting a DEBUG flag in the code, but by added argument at runtime, which is useful when the target is not the developer machine and recompiling & transferring bytecode takes time.There is also the  way, but this might be an overkill, if you put it in Java in a JSP then it will terminate the server.Apart from that Java is by-design a 'nanny' language, I would rather use something native like C/C++ for more control."},
{"body": "I'm relatively new to the Maven mantra, but I'm trying to build a command-line runnable jar with Maven. I've setup my dependencies, but when I run  and attempt to run the jar, two things happen. First, no main class is found, which is correctable. When I've corrected this, I get errors on run stating that classes cannot be found.Maven is not packaging my dependency libraries inside of the jar, so I am unable to run the jar as a stand-alone application. How do I correct this?The easiest way to do this would be to create an assembly using the  and the predefined  descriptor. You'll also need to generate a manifest with a main-class entry for this uber jar. The snippet below shows how to configure the assembly plugin to do so:Then, to generate the assembly, just run:If you want to generate the assembly as part of your build, simply bind the  mojo to the package phase:And simply run:Maven is not packaging your dependencies inside your jar file, because you don't usually do this with Java programs.Instead you deliver the dependencies together with your jar file and mention them in .To go this route, you'll need to enable the  property (documented ) for the .If you really want to include all your dependencies in your jar file, then you can use the Maven Assembly plugin to create a .This is what I would do for small projects. Most of the time you don't want one huge jar.\nmvn clean dependency:copy-dependencies package\njava -cp myjar.jar:./dependency/* com.something.MyClassI Agree with Joachim Sauer, Instead of using jar-with-dependency you should configure the jar plugin like that in your pom.xml:And use this assembly configuration to add the jar dependencies to you assembly:Just add the below code in pom.xml and Run as: maven:install . The jar will be created in target folder of eclipse which can be used as \"java -jar Hello.jar\" . but make sure that name of main class is given com.abc.HelloWorld.javaUse onejar plugin: It creates a runnable jar file that include all your dependencies."},
{"body": "I have an ArrayList that I want to iterate over it. While iterating over it I have to remove elements at the same time. Obviously this throws a .What is the best practice to handle this problem? Should I clone the list first?I remove the elements not in the loop itself but another part of the code.My code looks like this:a.doSomething might call Test.removeA();Two options:As an example of the second option, removing any strings with a length greater than 5 from a list:From the JavaDocs of the ArrayListOne option is to modify the  method to this -But this would mean your  should be able to pass the  to the  method. Not a very good idea.Can you do this in two step approach : \n In the first loop when you iterate over the list , instead of removing the selected elements ,  them as . For this , you may simply copy these elements ( shallow copy ) into another .Then , once your iteration is done , simply do a  from the first list all elements in the second list.Here is an example where I use a different list to add the objects for removal, then afterwards I use stream.foreach to remove elements from original list :Do somehting simple like this:You should really just iterate back the array in the traditional wayEvery time you remove an element from the list, the elements after will be push forward. As long as you don't change elements other than the iterating one, the following code should work.You are trying to remove value from list in advanced \"for loop\", which is not possible, even if you apply any trick (which you did in you code).\nBetter way is to code iterator level as other advised here.I wonder how people have not suggested traditional for loop approach.This works as well.\"Should I clone the list first?\"That will be the easiest solution, remove from the clone, and copy the clone back after removal.An example from my rummikub game:In Java 8 you can use the Collection Interface and do this by calling the removeIf method:More information can be found "},
{"body": "In Java, I'm dynamically creating a set of files and I'd like to change the file permissions on these files on a linux/unix file system.  I'd like to be able to execute the Java equivalent of . Is that possible Java 5? If so, how?I know in Java 6 the File object has setReadable()/setWritable() methods.   I also know I could make a system call to do this, but I'd like to avoid that if possible.  Full control over file attributes is available in Java 7, as part of the \"new\" New IO facility (). For example, POSIX permissions can be set with In earlier versions of Java, using native code of your own, or -ing command-line utilities are common approaches.In addition to erickson's suggestions, there's also , which allows you to call native libraries without using jni.  It's shockingly easy to use, and I've used it on a couple of projects with great success.  The only caveat is that it's slower than jni, so if you're doing this to a very large number of files that might be an issue for you.(Editing to add example)Here's a complete jna chmod example:for windows 7 with nio 2.0:Prior to Java 6, there is no support of file permission update at Java level. You have to implement your own native method or call  to execute OS level command such as .Starting from Java 6, you can use to set file permissions. But it doesn't simulate the POSIX file system which allows to set permission for different users. File.setXXX() only allows to set permission for owner and everyone else.Starting from Java 7, POSIX file permission is introduced. You can set file permissions like what you have done on *nix systems. The syntax is :This method can only be used on POSIX file system, this means you cannot call it on Windows system.For details on file permission management, recommend you to read .for Oralce Java 6:works under solaris/linux.You can use the methods of the File class: \nIn addition to erickson's answer here a helpful link with working code examples on using PosixFilePermissions:If you want to set 777 permission to your created file than you can use following method:Apache ant chmod (not very elegant, adding it for completeness) credit shared with @msorskyReference : There is an  which works very much similar to the UNIX chmod. It works with java se 7+ though."},
{"body": "Is there any advantage of using instead of? As far as I can tell the following fragments are almost equivalent:Except that in case #2 the latch cannot be reused and more importantly you need to know in advance how many threads will be created (or wait until they are all started before creating the latch.)So in what situation might the latch be preferable?CountDown latch is frequently used for the exact opposite of your example. Generally, you would have many threads blocking on \"await()\" that would all start simultaneously when the countown reached zero.You could also use this as an MPI-style \"barrier\" that causes all threads to wait for other threads to catch up to a certain point before proceeding.That all said, the CountDown latch can safely be used in the manner you've shown in your example. is used to start a series of threads and then wait until all of them are complete (or until they call  a given number of times.Semaphore is used to control the number of concurrent threads that are using a resource. That resource can be something like a file, or could be the cpu by limiting the number of threads executing. The count on a Semaphore can go up and down as different threads call  and .In your example, you're essentially using Semaphore as a sort of CountLatch. Given that your intent is to wait on all threads finishing, using the  makes your intention clearer. definition from javadocs:However, no actual permit objects are used; the  just keeps a count of the number available and acts accordingly. Semaphores are used to control the number of concurrent threads that are using a resource.That resource can be something like a shared data, or a block of code () or any file. The count on a Semaphore can go up and down as different threads call () and (). But at any point of time, you can't have more number of threads greater than Semaphore count. Have a look at this  for semaphore uses. definition from javadocs: works by having a counter initialized with number of threads, which is decremented each time a thread complete its execution. When count reaches to zero, it means all threads have completed their execution, and thread waiting on latch resume the execution.Have a look at this  to understand CountDownLatch concepts clearly.Have a look at  at this  too. It has some similarities to .Say you walked in to golf pro shop, hoping to find a foursome,When you stand in line to get a tee time from one of the pro shop attendants, essentially you called , once you get a tee time, you called .Note: any of the free attendants can service you, i.e. shared resource.Now you walk up to starter, he starts a  and calls  to wait for others, for your part you called checked-in i.e. . and so does rest of the foursome. When all arrive, starter gives go ahead( call returns)Now, after nine holes when each of you take a break, hypothetically lets involve starter again, he uses a 'new'  to tee off Hole 10, same wait/sync as Hole 1.However, if the starter used a  to begin with, he could have reset the same instance in Hole 10 instead of a second latch, which use & throw.Looking at the freely available source, there is no magic in the implementation of the two classes, so their performance should be much the same. Choose the one that makes your intent more obvious.CountdownLatch makes threads wait on the await() method, until such a time as the count has reached zero.  So maybe you want all your threads to wait until 3 invocations of something, then all the threads can go.  A Latch generally can not be reset.A Semaphore allows threads to retrieve permits, which prevents too many threads from executing at once, blocking if it cannot get the permit(s) it requires to proceed.  Permits can be returned to a Semaphore allowing the other waiting threads to proceed."},
{"body": "I'm rolling J2EE code that adheres to Servlet 2.5 and I'm wondering what are the major differences between 2.5 and 3. Pointers to official Sun docs and personal experiences are most appreciated.If I shouldn't be concerning myself with 3 for the time being, just say so. Thanks!UPDATEJust as an update and to be more explicit, these are the main differences between servlets 2.5 and 3 (I'm not trying to be exhaustive, I'm just mentioning the most interesting parts):In servlets 2.5, to declare a servlet with one init parameter you need to add this to :In servlets 3,  is optional and you can use annotations instead of XML. The same example:For filters, you need to add this in  in servlets 2.5:Equivalent using annotations in servlets 3:For a listener (in this case a ServletContextListener), in servlets 2.5:The same using annotations:In servlets 3, a  can add dynamically servlets, filters and listeners using the following methods added to : ,  and Example: say that some servlet container has five threads in its thread pool, and there is a time-consuming process to be executed per request (like a complex SQL query).An example of asynchronous support:Servlets 2.5:Servlets 3:The interface  also has methods to get the request object, response object and add listeners to notify them when a process has finished.In servlets 3, the interface  has been added two new methods:  and .For more details, have a look at the .Servlet 3.0 has not yet been released, but it looks like it's very close. The most important changes in 3.0 are: Pluggability, Ease of development, Async Servlet, Security. Whether or not these are important to you is impossible for me to say.The most significant of these is probably the support for asynchronous Servlets. Here's  that describes this in detail. The full specification can be downloaded .As Don mentioned, the main areas of improvements and additions are:Check out the Javaone 2008 presentation \"\" for details.Servlet 3 supports annotation to eliminate "},
{"body": "I'm loading a text file from within a package in a compiled JAR of my Java project. The relevant directory structure is as follows:The code being used to load the file is:The print out will always print , no matter what I use. I'm not sure why the above wouldn't work, so I've also tried:Neither of these work.     so far on the topic, but none of them have been helpful - usually, they just say to load files using the root path, which I'm already doing. That, or just load the file from the current directory (just load ), which I've also tried. The file is being compiled into the JAR in the appropriate location with the appropriate name. How do I solve this? loads resources using system class loader, it obviously fails because it does not see your JARs loads resources using the same class loader that loaded Lifepaths class and it should have access to resources in your JARsThe rules are as follows:And try:instead of(not sure if it makes a difference, but the former will use the correct ClassLoader/ JAR, while I'm not sure with the latter)So there are several ways to get a resource from a jar and each has slightly different syntax where the path needs to be specified differently.The best explanation I have seen is this article from . I'll summarize here, but if you want to know more you should check out the article.Methods1) .  Format: \"/\"-separated names; no leading \"/\" (all names are absolute). Example: 2) Format: \"/\"-separated names; leading \"/\" indicates absolute names; all other names are relative to the class's packageExample: Don't use absolute paths, make them relative to the 'resources' directory in your project. Quick and dirty code that displays the contents of MyTest.txt from the directory 'resources'.You might want to try this to get the stream i.e first get the url and then open it as stream. I once had a similar question: There seems to be issue with the ClassLoader that you are using. Use the contextClassLoader to load class.  This is irrespective of whether it is in a static/non-static method......Don't know if of help, but in my case I had my resource in the /src/ folder and was getting this error.\nI then moved the picture to the bin folder and it fixed the issue.Make sure your resource directory (e.g. \"src\") is in your classpath (make sure it's a source directory in your build path in eclipse).Make sure clazz is loaded from the main classloader.Then, to load src/initialization/Lifepaths.txt, use Why:\n looks up foo from , . The leading \"/\" makes it load from the root of any directory in the classpath of clazz.Unless you're in a container of some kind, like Tomcat, or are doing something with ClassLoaders directly, you can just treat your eclipse/command line classpath as the only classloader classpath.What worked for me was to add the file under My Project/Java Resources/src and then use I didn't need to explicity add this file to the path (adding it to /src does that apparently)I found myself in a similar issue. Since I am using maven I needed to update my pom.xml to include something like this:Note the resource tag in there to specify where that folder is. If you have nested projects (like I do) then you might want to get resources from other areas instead of just in the module you are working in. This helps reduce keeping the same file in each repo if you are using similar config data @Emracool... I'd suggest you an alternative. Since you seem to be trying to load a *.txt file. Better to use  rather then this annoying  or . At least your code will execute properly.  "},
{"body": "I have How can i retrieve the session if am using entitymanager or how can i get the result from my detachedcriteria ?To be totally exhaustive, things are different if you're using a JPA 1.0 or a JPA 2.0 implementation.With JPA 1.0, you'd have to use . But keep in mind that   i.e. non portable from application server using Hibernate to the other. For example  you would do:But , you'd have to do:I agree, that's horrible, and the spec is to blame here (not clear enough).With JPA 2.0, there is a new (and much better)  method that is to be preferred over  for new applications.So with Hibernate as JPA 2.0 implementation (see ), you would do:See the section \"\" in the :This will explain better."},
{"body": "I am looking at an algorithm that can map between characters with diacritics (, , , , ) and their \"simple\" character.For example:Etc.I have done this recently in Java:This will do as you specified:but it will fail on for example Bia\u0142ystok, because the  character is not diacritic.If you want to have a full-blown string simplifier, you will need a second cleanup round, for some more special characters that are not diacritics. Is this map, I have included the most common special characters that appear in our customer names. It is not a complete list, but it will give you the idea how to do extend it. The immutableMap is just a simple class from google-collections.The core java.text package was designed to address this use case (matching strings without caring about diacritics, case, etc.).Configure a  to sort on  differences in characters. With that, create a  for each string. If all of your code is in Java, you can use the  directly. If you need to store the keys in a database or other sort of index, you can .These classes use the  case folding data to determine which characters are equivalent, and support various  strategies.Note that collators are locale-specific. This is because \"alphabetical order\" is differs between locales (and even over time, as has been the case with Spanish). The  class relieves you from having to track all of these rules and keep them up to date.It's part of  as of ver. 3.1.returns You could use the  from :But there is still some work to do, since Java makes strange things with unconvertable Unicode characters (it does not ignore them, and it does not throw an exception). But I think you could use that as an starting point.There is a  on character folding on the unicode website which has a lot of relevant material. See specifically Section 4.1. \"Folding algorithm\".Here's a  of diacritic marker removal using Perl.These existing SO questions are related:Please note that not all of these marks are just \"marks\" on some \"normal\" character, that you can remove without changing the meaning.In Swedish, \u00e5 \u00e4 and \u00f6 are true and proper first-class characters, not some \"variant\" of some other character. They sound different from all other characters, they sort different, and they make words change meaning (\"m\u00e4tt\" and \"matt\" are two different words).Unicode has specific diatric characters (which are composite characters) and a string can be converted so that the character and the diatrics are separated. Then, you can just remove the diatricts from the string and you're basically done.For more information on normalization, decompositions and equivalence, see The Unicode Standard at the .However, how you can actually achieve this depends on the framework/OS/... you're working on. If you're using .NET, you can use the  method accepting the  enumeration.The easiest way (to me) would be to simply maintain a sparse mapping array which simply changes your Unicode code points into displayable strings.Such as:The use of a  array will allow you to efficiently represent replacements even when they in widely spaced sections of the Unicode table. String replacements will allow arbitrary sequences to replace your diacritics (such as the  grapheme becoming ).This is a language-agnostic answer so, if you have a specific language in mind, there will be better ways (although they'll all likely come down to this at the lowest levels anyway).Something to consider: if you go the route of trying to get a single \"translation\" of each word, you may miss out on some possible alternates.For instance, in German, when replacing the \"s-set\", some people might use \"B\", while others might use \"ss\".  Or, replacing an umlauted o with \"o\" or \"oe\".  Any solution you come up with, ideally, I would think should include both.In Windows and .NET, I just convert using string encoding. That way I avoid manual mapping and coding. Try to play with string encoding.In case of German it's not wanted to remove diacritics from Umlauts (\u00e4, \u00f6, \u00fc).\nInstead they are replaced by two letter combination (ae, oe, ue)\nFor instance, Bj\u00f6rn should be written as Bjoern (not Bjorn) to have correct pronounciation.For that I would have rather a hardcoded mapping, where you can define the replacement rule individually for each special character group.For future reference, here is a C# extension method that removes accents."},
{"body": "Does maven require a connection to the internet at some point to be able to use it? Meaning specifically getting the internal maven plugins for compiling, cleaning, packaging, etc? You can run maven in offline mode . Of course any artifacts not available in your local repository will fail. Maven is not predicated on distributed repositories, but they certainly make things more seamless. Its for this reason that many shops use internal mirrors that are incrementally synced with the central repos. In addition, the  can be used to ensure you have all of your dependencies installed locally before you begin to work offline.If you have a PC with internet access in your LAN, you should install a local Maven repository.I recommend . This is what we use in our organization, it is really easy to setup.After setting up Artifactory you just need to change Maven's  in the development machines:We used this solution because we had problems with internet access in our development machines and some artifacts downloaded corrupted files or didn't download at all. We haven't had problems since.Maven needs the dependencies in your local repository. The easiest way to get them is with internet access (or harder using other solutions provided here).So assumed that you can get temporarily internet access you can prepare to go offline using the  with its  goal. This will download all your project dependencies to your local repository (of course changes in the dependencies / plugins will require new internet / central repository access).You have two options for this:1.) make changes in the  add this in first tag 2.) use the -o tag for offline command.Does this work for you?Don't forget to add it to your plugin repository and point the url to wherever your repository is.If not, you may need to run a local server, e.g. apache, on your machines.In preparation before working offline just run\nBefore going offline you have to make sure that everything is in your local repo, which is required while working offline. Running \"mvn dependency:go-offline\" for the project(s)/pom(s), you intend to work on, will reduce the efforts to achieve this. But it\u00b4s usually not the whole story, because dependency:go-offline will only download the \"bare build\" plugins (). So you have to find a way to download deploy / test / site plugins (and maybe others) and their dependencies into your repo.Furthermore dependency:go-offline does not download the pom\u00b4s artifact itself, so you have to dependency:copy it if required.Sometimes - as MaDa wrote - you do not know, what you will need, while being offline, which makes it pretty impossible to have a \"sufficient\" repo.Anyway having a properly filled repo you only have to add \"<offline>true</offline>\" to Maven\u00b4s settings.xml to go offline.Do not change the Maven profile (id) you used to fill your repo, while being offline. Maven recognizes the downloaded artifacts in its metadata with an \"identity\", which is bound to the profile id.The workaround has been to specify a , either within  file with  or by running  with  parameter. \nAfter initial project build, all necessary artifacts should be cached, and then you can reference repository location the same ways, while running Maven build in offline mode ().Answering your question directly: it does not require an internet connection, but access to a repository, on LAN or local disk (use hints from other people who posted here).If your project is not in a mature phase, that means when POMs are changed quite often, offline mode will be very impractical, as you'll have to update your repository quite often, too. Unless you can get a copy of a repository that has everything you need, but how would you know? Usually you start a repository from scratch and it gets cloned gradually during development (on a computer connected to another repository). A copy of the repo1.maven.org public repository weighs hundreds of gigabytes, so I wouldn't recommend brute force, either.orJust use Maven repository servers like Sonatype Nexus  or JFrog Artifactory .After one developer builds a project, build by next developers or Jenkins CI will not require Internet access.Maven repository server also can have proxies configured to access Maven Central (or more needed public repositories), and they can have cynch'ed list of artifacts in remote repositories.If you're using IntelliJ, you can simply go to  ->  ->  ->  and check/uncheck .My experience shows that the -o option doesn't work properly and that the go-offline goal is far from sufficient to allow a full offline build: The solution I could validate includes the use of the  maven option rather than the  (offline) one and\nthe use of the  in place of the In addition, I had to copy every  files of the local-repo into the  form expected by maven.See the solution I found ."},
{"body": "In case of the , What is the difference between  and third party dynamic code generation API s such as ? What is the difference between using both the approaches and when should one prefer one over another?JDK Dynamic proxy can only proxy by interface (so your target class needs to implement an interface, which will also be implemented by the proxy class).CGLIB (and javassist) can create a proxy by subclassing. In this scenario the proxy becomes a subclass of the target class. No need for interfaces.So Java Dynamic proxies can proxy:  where CGLIB can proxy: JDK proxies are implemented rather naively with only one interception dispatcher, the . This requires a virtual method dispatch to an implementation which cannot always be inlined. Cglib allows to create specialized byte code what can sometimes improve performance. Here are some comparisons for implementing an interface with 18 stub methods:The time is noted in nanoseconds with standard deviation in braces. You can find more details on the benchmark in , where Byte Buddy is a more modern alternative to cglib. Also, note that cglib is no longer under active development. Dynamic implementations of interfaces at runtime using . Spring uses dynamic proxies for transactions as follows:The generated proxy comes on top of bean. It adds transnational behavior to the bean. Here the proxy generates dynamically at runtime using JDK Reflection API.   When an application is stopped, the proxy will be destroyed and we will only have interface and bean on the file system.In the above example we have interface. But in most of implementation of interface is not best. So bean does not implement an interface, in that case we uses inheritance:In order to generate such proxies, Spring uses a third party library called .   CGLib (ode eneration rary) is built on top of , this is mainly used the generate proxy extending bean and adds bean behavior in the proxy methods.  "},
{"body": "I'm sending some parameters from a form in this way:I know I can get all the params in the controller method by adding a parameter likeI want to bind the parameters myParam[] (not the other ones) to a list or array (anything that keeps the index order), so I've tried with a syntax like:andbut none of them are binding the myParams. Even when I add a value to the map it is not able to bind the params:Is there any syntax to bind some params to a list or array without having to create an object as @ModelAttribute with a list attribute in it?ThanksArrays in  are used for binding several parameters of the same name:If you need to bind -style indexed parameters, I guess you need  anyway.Or you could just do it that way:That works for example for forms like this:This is the simplest solution :)One way you could accomplish this (in a hackish way) is to create a wrapper class for the List. Like this: Then your controller method signature would look like this:No need to use the @RequestParam or @ModelAttribute annotation if the collection name you pass in the request matches the collection field name of the wrapper class, in my example your request parameters should look like this:Just complementing what Donal Fellows said, you can use List with @RequestParamHope it helps!Subscribing what basil said in a comment to the question itself, if  then you can use @RequestParam List groupVal.Then calling the service with the list of params is as simple as:Change hidden field value with checkbox toggle like below..."},
{"body": "I am practicing for an exam, and found a sample problem that I don't understand. For the following code, find what the output is: The output of this code is , but I don't understand why. Can anyone help me?The first thing you should note is that   override 's , since the argument is  instead of , so the signatures don't match.Therefore the  method calls  exactly once - when executing  - since that's the only case in which both the static type of the instance  is executed for and the type of the argument are the  class.  is the 4th  statement (which comes after 4 increments of the static  variable), so 4 is printed.All the other  statements execute 's , and therefore print nothing.A more detailed explanation : calls 's  regardless of the type of the argument, since the static (compile time) type of  is , and the  class doesn't override that method. The  class doesn't have an  method with a single  argument, so  can't be called, regardless of the dynamic (runtime type) of . can execute either 's  or 's equals, since the compile time type of  is , and the  class has two  methods (one inherited from the  class and the other defined in the  class). The method being chosen depends on the compile time type of the argument :\n1. When the argument is  (as in  or ), 's  is called and nothing is printed.\n2. When the argument is , as in , both versions of  match that argument, but due to the rules of method overloading, the method with the most specific argument -  - is chosen and the  variable is printed.The equals method in Test takes an instance of Test.All the previous attempts have been made with an instance of Object, which take the inherrited method from the Object class:Since there is no print in there, it won't print any value.Your  will increment the value of count, so the moment when you actually call yourmethod, that does print that value, the value of count is 4. is the only line which has the right arguments that match the method signature  so it's the only line in the program which actually calls that print statement. This question is designed to teach you a few things.Essentially the trick here is that Test implicitly extends Object like all java classes do. Object contains an equals method that takes type Object. t1 and t2 are typed such that at run time the arguments never match the method signature of equals that is defined in Test. Instead it's always calling into the equals method in Object.java because either the base type Is Object in which case the only methods you have access to are the ones defined in Object.java or  the derived type is Object in which case Cannot be entered because in that case at runtime the argument is of type Object which is a Superclass of Test, not a subclass. So instead it looks at the equals method in the Test.java's implicitly typed superclass Object.java which also contains an equals method, which just happens to have a method signature of which in this case match our arguments at runtime so this equals method is the one that executes.Notice in the case of  both the base type and the derived type of t3 are Test.this means that at runtime you are calling the equals method in Test.java and the argument you are passing in is actually of type Test so the method signatures match and the code inside Test.java executes. At this point .Bonus bit of knowledge for you:annotation you may have seen in a few places explicitly instructs the compiler to fail if it does not find method with the exact same signature somewhere in a Superclass. This is useful to know if you definitely  to override a method and you want to be absolutely sure that you really are overriding the method and you haven't accidentally changed the method in either the superclass or subclass but not both and Introduced a runtime error where the wrong implementation of the method is being called causing unwanted behavior.There's two key things that you should know."},
{"body": "Is there a way in Eclipse to select a Java class, and then bring up a list of all Java files where that class is used within a project?right-click on the class, and select references/ProjectFor searching the all workspace, ++Put the cursor on the class name (works for methods, constructors, fields, etc, too), press ++ and enjoy."},
{"body": "I would like to have the javadoc comments contained in a jar file show in eclipse when I hover over a class.For example, after downloading JODA-2.0, three jars are obtained:In eclipse, [right click project -> Properties -> Java Build Path -> Libraries -> ADD JARs...] includes the binary in the project (can reference those classes) for joda-time-2.0.jar.But how can I link in the sources/javadoc comments contained in the other two jar files so that when I hover over those classes I see the javadocs?Adding the other two jars (joda-time-2.0-javadoc.jar and joda-time-2.0-sources.jar) to the build path does not link the javadocs or the source.You can try to CTRL + click on a class that has no source attached (do that in editor). When it shows you some info about the class you'll see the button that guides to attach source dialog. Click it and in dialog that pops up pick the source/javadoc location for your class.You can also do that from project build path settings you are mentioning: pick libraries tab, expand the library (jar) you want and you'll be offered to pick: source attachment, javadoc attachment, native library location, etc. You just pick whatever you want and edit its current settings.Or you can do as @JB Nizet said...You can also edit the classpathentry in the file \".classpath\" in your eclipse project. This can be helpful if you want to modify many entries at once or if you want to generate the path.\ne.g.:Right-click on the jar (the one with the class files), choose \"Properties\", the \"Javadoc location\", and choose the jar file with the javadoc. Do similarly for the source jar, using \"Java source attachment\"."},
{"body": "We normally create objects using the  keyword, like:Strings are objects, yet we do not use  to create them:Why is this? Can I make a String with ?In addition to what was already said, String  [ie, Strings like  but not like ] in Java are interned - this means that every time you refer to \"abcd\", you get a reference to a single  instance, rather than a new one each time.  So you will havebut if you hadthen its possible to have(and in case anyone needs reminding, always use  to compare Strings;  tests for physical equality)Interning String literals is good because they are often used more than once.  For example, consider the (contrived) code:If we didn't have interning of Strings, \"Next iteration\" would need to be instantiated 10 times, whereas now it will only be instantiated once.Strings are \"special\" objects in Java. The Java designers wisely decided that Strings are used so often that they needed their own syntax as well as a caching strategy. When you declare a string by saying:myString is a reference to String object with a value of \"something\". If you later declare:Java is smart enough to work out that myString and myOtherString are the same and will store them in a global String table as the same object. It relies on the fact that you can't modify Strings to do this. This lowers the amount of memory required and can make comparisons faster.If, instead, you writeJava will create a brand new object for you, distinct from the myString object.Hope this clears a few doubts. :)It's a shortcut. It wasn't originally like that, but Java changed it.This  talks about it briefly. The Java Specification guide talks about it also. But I can't find it online.String is subject to a couple of optimisations (for want of a better phrase). Note that String also has operator overloading (for the + operator) - unlike other objects. So it's very much a special case.In Java, Strings are a special case, with many rules that apply only to Strings.  The double quotes causes the compiler to create a String object.  Since String objects are immutable, this allows the compiler to intern multiple strings, and build a larger string pool.  Two identical String constants will always have the same object reference.  If you don't want this to be the case, then you can use new String(\"\"), and that will create a String object at runtime.  The intern() method used to be common, to cause dynamically created strings to be checked against the string lookup table.  Once a string in interned, the object reference will point to the canonical String instance.  When the classloader loads a class, all String constants are added to the String pool.Syntactic sugar. Thesyntax is still available.You can still use , but it would be harder to create new strings without string literals ... you would have to use character arrays or bytes :-) String literals have one additional property: all same string literals from any class point to same string instance (they are interned).There's almost no need to new a string as the literal (the characters in quotes) is already a String object created when the host class is loaded. It is perfectly legal to invoke methods on a literal and don, the main distinction is the convenience provided by literals. It would be a major pain and waste of tine if we had to create an array of chars and fill it char by char and them doing a new String(char array).The literal pool contains any Strings that were created without using the keyword .There is a difference : String without new reference is stored in String literal pool and String with new says that they are in heap memory.String with new are elsewhere in memory just like any other object.Output:I created two separate objects, both have a field(ref) 'Name'. So even in this case \"Jan Peter\" is shared, if I understand the way java deals..                 Feel free to create a new String with The usual notation  is more or less a convenient shortcut - which should be used for performance reasons except for those pretty rare cases, where you  need Strings that qualify for the equationIn response to the comment: this was  intended to be an advise but just an only a direct response to the questioners thesis, that  for Strings, which simply isn't true. Hope this edit (including the above) clarifies this a bit. BTW - there's a couple of good and much better answers to the above question on SO.Because String is an immutable class in java. Now why it is immutable?\nAs String is immutable so it can be shared between multiple threads and we dont need to synchronize String operation externally. \nAs String is also used in class loading mechanism. So if String was mutable then java.io.writer could have been changed to abc.xyz.mywriter"},
{"body": "I've got a question of some strange String pool behavior.\nI'm using  to compare equal Strings to find out whether they're in the pool or not.The output is:which is a big surprise for me. Could anyone explain this please?\nI think something about this is taking place at the compilation time. But why does adding  to a String makes any difference at all?is a , whereasisn't. Therefore the former compiles into just the string constant \"555\" and the latter compiles into the actual method invocation and concatenation, resulting in a fresh String instance.After decompiling this lineI got this bytecodewhich is equivalent tothat means expression  compiles to boolean . For  javac built this bytecodewhich is equivalent to which will always produce false since here we're comparing 2 disctinct objects.In the second case the compiler COULD have recognized that  is a no-op of sorts, since  is a compile-time value known to be zero length.  But the compiler is still required to check the result from  for null (since the null check would occur as a result of the  operation in the non-optimized case), so it's simplest to just not attempt the optimization.As a result, the compiler generates code to perform the concatenation, and a new string is created.\nString computed by constant expression are done at compile time and treated as constants or literals means the value of the string or expression is known or evaluated at compile time hence the compiler can check the same value in string pool and the return the same string object reference.\nString expressions whose values are known or can not be evaluated at compile but depends on the input or condition of run-time  then the compiler will not know the value of the string and hence always land up using StringBuilder to append the string and always returns a new string .\nI guess this example will clarify it better."},
{"body": "So I need to remove a file from a jar / war file.\nI was hoping there was something like \"jar -d myjar.jar  file_I_donot_need.txt\"But right now the only way I can see of doing this from my Linux command line (without using WinRAR/Winzip or linux equivalent) is toPlease tell me there is a shorter way? jar is just a zip file after all. Definitely much faster than uncompressing/recompressing. In Java you can copy all the entries of a jar except the one you want to delete. i.e. you have to make a copy but don't need to create the individual files.You can do this byIn case you want to delete file in order to unsign signed jar, you can probably just make the .RSA file zero-sized. This can be accomplished with just . See  . (Worked for me, though I admit it's hack.)"},
{"body": "In practice can I assume that all int arrays in Java will start out filled with zeros? for all machines in which the JVM runs?Is this true for all types? char? boolean? enums?Where is this officially documented?The textbooks I have say that int arrays are set to zero but they also recommend that one should write a for-loop to set all values to zero just \"to be clearer\". is the right place to look for such information:  Default values themselves are given in .Yes. Primitive types in Java are always zero-initialized. References are also initialized to null.It should be Java Language Specification .  instead of \"For type byte, the default value is zero, that is, the value of (byte)0.\nFor type short, the default value is zero, that is, the value of (short)0.\nFor type int, the default value is zero, that is, 0.\nFor type long, the default value is zero, that is, 0L.\nFor type float, the default value is positive zero, that is, 0.0f.\nFor type double, the default value is positive zero, that is, 0.0d.\nFor type char, the default value is the null character, that is, '\\u0000'.\nFor type boolean, the default value is false.\nFor all reference types (\u00a74.3), the default value is null.\"Your textbook is wrong!  Writing such code is pointless, and a waste of your time typing it and the computers time running it.As others have said, the compiler guarantees that variables outside of methods (class/instance variables) are given a value of 0, false, or null.  As you probably know the compiler does not give variables inside of methods values, and instead forces you to give them a value before they are used.You will find, if you do things \"right\" that about 90%-95% of your \"variables\" never change after they are given a value.  However, new programmers tend to do things like this:this prevents you from being able to mark x as \"final\".  If you are able to mark x as \"final\" then it prevents accidental modification of the value, which prevents bugs.I would write the code like:This is called a blank final (a final variable that doesn't have a value when it is declared).If you remember that class/instance variables are initialized by the runtime then you will, hopefully, not write code to initialize them with throw away values, and then you can mark them as final.My personal practice is to always mark everything as final until I find that I need to modify it, and to never initialize a variable until I know the actual value I want it to have.  Doing this make the code faster (not noticeable since assignments are generally very quick) and safer since I rarely accidentally modify a value when I should not."},
{"body": "I have the following piece of code:Upto this part the code is fine, but I am not able to instantiate 'in' within the main method like  as it is showing . What is the way I can do it? I do not want to make my Inner class static.You have to have a reference to the other outer class as well.If Inner was static then it would be A \"regular\" inner class has a hidden (implicit) pointer to a parent class instance. This allows the compiler to generate the code to chase the pointer for you without you having to type it. For instance, if there is a variable \"a\" in the parent class then the code in your inner class can just do \"a=0\", but the compiler will generate code for \"parentPointer.a=0\" maintaining the hidden pointer under the covers.This means when you create an instance of an inner class you have to have an instance of a parent class to link it to. If you do this creation inside a method of the parent class then the compiler knows to use \"this\" as the implicit pointer. If you want to link to some other parent instance then you use a special \"new\" syntax (see code snippet below). If you make your inner class \"static\" then there is no hidden pointer and your inner class cannot reference members of the parent class. A static inner class is identical to a regular class, but its name is scoped inside the parent.Here is a snippet of code that demonstrates the syntax for creating static and non-static inner classes:If you want to create  from within a method, do it from an instance method of the class :Alexei Kaigorodov's is the right answer.  His solution allows you to instantiate inner classes from within a static method, such as a main() of the same class.  Otherwise, you can't instantiate an inner class within a static method.  It does not compile.  Alexei's solution does compile and it does allow you to instantiate inner classes from a static method.  The other answers are interesting side-notes, but I don't find them responsive to the actual question."},
{"body": "In some interfaces i wrote I'd like to name generic type parameter with more than one character to make the code more readable.Something like....Instead of this...But when it comes to methods, the type-parameters look like java-classes which is also confusing.This seems like Key and Value are classes. I found or thought of some notations, but nothing like a convention from sun or a general best-practice.Alternatives i guesed of or found...Oracle recommends the following in :I'd stick to it to avoid the confusion among the developers and possible maintainers.A good discussion can be found in the comments on the DZone page, .See the comment by Erwin Mueller. His suggestion makes perfect obvious sense to me: . Call an apple an apple, a car a car. The name in question is the name of a data type, right? (In , a class essentially defines a new data type.) So call it a \u201cType\u201d.Mueller\u2019s example, drawn from the original post\u2019s article:A duplicate Question provides  by Andy Thomas. Note the excerpt from Google\u2019s style guide that suggests a multi-character type name should end in a single uppercase .You can use javadoc to at least give users of your generic class a clue.  I still don't like it (I agree with @chaper29) but the docs help.  eg,The other thing I have been known to do is use my IDE to refactor a class breaking the convention.  Then work on the code and refactor back to single letters.  Makes it easier for me anyway if many type parameters are used.  Yes, you can use multi-character names for type variables, as long as they are clearly distinguished from class names.This differs from the convention suggested by Sun with the introduction of generics in 2004. However:Readability is good. Compare:to:or, with Google's multi-character convention: allows both single-letter names and multi-character class-like names ending in T. Single-character names are not the only way to distinguish type parameters from class names, as we've seen above.It's true that the @param JavaDoc elements can provide a longer description. But it's also true that the JavaDocs are not necessarily visible. (For example, there's a content assist in Eclipse that shows the type parameter names.)Many of Sun's original conventions are followed nearly universally in Java programming. However, this particular convention is not. The best choice among competing conventions is a matter of opinion. The consequences of choosing a convention other than Oracle's in this case are minor. You and your team can choose a convention that best meets your needs.The reason why the  reccommends using single letter is the following:I think with modern IDEs that reason is no longer valid as eg. IntelliJ Idea shows generic type parameters with different colors than regular classes.\nBecause of that distinction I use longer descriptive names for my generic types, with same convention as regular types. I avoid adding prefixes and suffixes such as T or Type as I consider them unnecessary noise and no longer needed to visually distinguish generic types.Note: As I am not a user of Eclipse or Netbeans, I do not know whether they offers a similliar feature."},
{"body": "I want Eclipse to automatically suggest to me all possible options, while I'm writing some variable/class name or keyword, like in Flash Develop or Visual Studio.Is it possible?If not, with which Java IDE can I get this?I'm specifically asking about a way to  get the same thing I get using  + , while I'm typing.You can also set auto completion to open automatically while typing.Simply write  in  field, in Java/Editor/Content Assist (Window->Preferences).See this  for more details.Use the  shortcut for getting all possible autocomplete options available in a particular context in the editor.Auto Complete will also allow you to insert custom code templates into the editor, with placeholders for various inputs. For instance, attempting to auto complete the word \"test\" in a Java editor, in the context of a class body, will allow you to create a unit test that uses JUnit; you'll have to code the body of the method though. Some code templates like the former, come out of the box.+Yes. If the suggestion doesn't compare automatically, then press crtl + space button.Since you asked about other Java IDE, I suggest IntelliJ by JetBrains.\nJust look at it: not only does it support auto completion as you type, but also it support import package once you select the auto completion. Before someone said \"Eclipse is free\", note that IntelliJ has free community edition as well: See if your settings are correct also:Window -> Preferences -> Java -> Editor -> content assist. See if the \"completion inserts\" is checked off along with anything else there you want to help auto complete.Its simple\nthese are the steps:\n1. first go to the following settings\n   Window -> Preferences -> Java -> Editor -> content assist -> advanced\n2. there will be two boxes having checkboxes.\n3. check everthing in there and click apply.\n4. now ofcourse when you'll be coding there will be auto code completion feature automatically.Pressing + opens up the auto-completion dialog in Eclipse. In the Java Perspective it opens automatically after you typed a  (normally with a short delay).Now in eclipse Neon this feature is present. No need of any special settings or configuation .On + the code suggestion is available Steps:All the commands and variables which begin with that letter are now going to appear"},
{"body": "How does  annotation work in JPA?I found various answers whose extract is as follows:But I am still not sure how it works.Also as from the following lines:Does it mean that we should declare our version field as ?Let's say an entity  has an annotated  property:On update, the field annotated with  will be incremented and added to the  clause, something like this:If the  clause fails to match a record (because the same entity has already been updated by another thread), then the persistence provider will throw an .No but you could consider making the setter protected as you're not supposed to call it. Although @Pascal answer is perfectly valid, from my experience I find the code below helpful to accomplish optimistic locking:Why? Because:First point doesn't matter if application uses  JPA for inserting data into the database, as JPA vendor will enforce  for  field at creation time. But almost always plain SQL statements are also in use (at least during unit/ integration testing).Every time an entity is updated in the database the version field will be increased by one. Every operation that updates the entity in the database will have appended  to its query.In checking affected rows of your operation the jpa framework can make sure there was no concurrent modification between loading and persisting your entity because the query would not find your entity in the database when it's version number has been increased between load and persist.Version used to ensure that only one update in a time. JPA provider will check the version, if the expected version already increase then someone else already update the entity so an exception will be thrown.So updating entity value would be more secure, more optimist.If the value changes frequent, then you might consider not to use version field. For an example \"an entity that has counter field, that will increased everytime a web page accessed\"Just adding a little more info.JPA manages the version under the hood for you, however it doesn't do so when you update your record via , in such cases you need to manually add the version increment to the query.Pedro"},
{"body": "The Java Docs for the method\n\nincludes this in the returns description:How do I do a similar thing and initialize a String array (or any other array for that matter) to have a length 0?As others have said,will indeed create an empty array. However, there's one nice thing about arrays - their size can't change, so you can always use the same empty array reference. So in your code, you can use:and then just return  each time you need it - there's no need to create a new object each time.?Butwon't work as the type information is missing.Ok I actually found the answer but thought I would 'import' the question into SO anyway\nor\nMake a function which will not return null instead return an empty array you can go through below code to understand. "},
{"body": "How to create Java Gradle project from command line?It should create  like on the picture below.UPDATE: .1. From \nI need to create file  with 2 lines.2. Add to  task below, than execute .3. Then run  (or corresponding string to other IDE plugin configured)So is there way to do it in one command?To create a Java project: create a new project directory, jump into it and executeSource folders and a Gradle build file (including a wrapper) will be build.The gradle guys are doing their best to solve all (y)our problems ;-). \nThey recently (since 1.9) added a new feature (incubating): the \"build init\" plugin\nSee: Unfortunately you cannot do it in one command. There is an open .Currently you'll have to do it by hand. If you need to do it often, you can create a , or just prepare your own project skeleton and copy it when needed.The JIRA issue mentioned above has been resolved, as of May 1, 2013, and fixed in 1.7-rc-1. The documentation on the  is available, although it indicates that this feature is still in the \"incubating\" lifecycle.Finally after comparing all solution, I think starting from  file can be convenient. Gradle distribution has  folder with a lot of examples, and there is  comand see . But they all needs some editing.You can use  below as well, then run The result is like below. That can be used without any Gradle plugin for Eclipse,\nor with  alternative to If you are using Eclipse, for an existing project (which has a  file) you can simply type  which will create all the Eclipse files and folders for this project.It takes care of all the dependencies for you and adds them to the project resource path in Eclipse as well.I could handle it using a groovy method in  to create all source folders for java, resources and test. Then I set it to run before  task.Now we can setup a new gradle Java EE project to eclipse with only one command. I put this example at I just tried with with Eclipse Neon.1 and Gradle:On windows 10 with Java Version:And it failed miserably as you can see in Eclipse.\nBut sailed like a soaring eagle in Intellij...I dont know Intellij, and a huge fan of eclipse, but common dudes, this means NO ONE teste Neon.1 for the simplest of use cases...to import a gradle project.\nThat is not good enough.\nI am switching to Intellij for gradle projects:"},
{"body": "I need to use mapview control in android and I can't seem to understand how to run .\nIs it installed with eclipse? I can't seem to find a download link.Thanks is part of the standard java distribution.In a windows 64-bit machine, you would normally find the jdk at It is used for managing keys and certificates you can sign things with, in your case, probably a jar file.If you provide more details of what you need to do, we could probably give you a more specific answer.keytool is a tool to manage key and certificates. It is provided with any standard JDK distribution and can be located in .For me it turned out to be in c/Program Files/Java/jdk1.7.0_25/bin (Windows 8). A more general answer to this question is that it will most likely be in the bin sub directory of wherever your jdk is installed. If you are working with a Mac... the keytool is part of the Java SDK and can be found in the following location /System/Library/Java/JavaVirtualMachines/[VERSION].jdk/Contents/Home/bin/keytoolhere: \nC:\\Program Files\\Java\\jre7\\bin\nit is an exe keytool.exeIf you have java installed of course keytool is in there. What you need to do is to add it on your PATH variable.It is in path/to/jdk/bin.\nMake sure that $JAVA_HOME is defined, and $JAVA_HOME/bin is added to $PATH, or else the 'keytool' command won't be recognized when called."},
{"body": "I am trying to modify some legacy code from while back and getting the following kind of errors:Access restriction: The method create(JAXBRIContext, Object) from the type Headers is not accessible due to restriction on required library ..\\jre\\lib\\rt.jar for these import statements:Been searching what this might mean and how to fix it, however not been able to find a clear answer. Some posts seem to suggest that I have some JARs included that implement classes that are now available as part of the core java distribution, but as far as I can see none of the JARs I include contain different/older versions of the above classes.Anyone able to tell me what this error is all about and how I might go about fixing this? Thanks for your help already in advance,OlliI ran into something similar, I think that the cause of the warning is Eclipse trying to discourage you from using the internal  packages that are installed as part of your workspace JRE but which are not part of the public Java API.As Justin says in his answer, changing your compiler settings can hide the warning. A more fine-grained approach is to modify your build path to explicitly allow access to the package in question:After adding this access rule, your project should build without these warning.Excellent answer already provide onsite .See the summary below:Not a true solution, but everywhere I looked the solution suggested was to simply tell Eclipse that those aren't errors. You can change it by going to Properties --> Java Compiler --> Errors Warnings --> Deprecated and restrited APIs --> Forbidden reference (acess rule), Change it from Error to Warning or Ignore.i've solved this issue with these steps: expand your project, right click \"JRE System Library\" > Properties > choose 3rd option \"Workspace default JRE\" > OK . Hope it help you too\nRemove existing JRE System Library, then Error will be removed.I had the same problem when my plugin was depending on another project, which exported some packages in its manifest file. Instead of changing access rules, I have managed to solve the problem by adding the required packages into its Export-Package section. This makes the packages legally visible. Eclipse actually provides this fix on the \"Access restriction\" error marker.In the eclipse environment where you execute your java programs, take the following steps:I'm responding to this question because I had a different way of fixing this problem than the other answers had. I had this problem when I refactored the name of the plugins that I was exporting. Eventually I had to make sure to fix/change the following.This worked for me, but your mileage may vary.I just changed project facet to 1.7 and it worked.Go to BuildpathRemove Existing JRE and add new JRE library which contain Jdk1.6\nand finish \nNow clean all project and build again I think this way you can resolved your error"},
{"body": "How to split the string  to substrings of equal size in Java.\nEg.  of 4 equal size should give the output.Here's the regex one-liner version: is a zero-width assertion that matches the position where the previous match ended.  If there  no previous match, it matches the beginning of the input, the same as .  The enclosing lookbehind matches the position that's four characters along from the end of the last match.Both lookbehind and  are advanced regex features, not supported by all flavors.  Furthermore,  is not implemented consistently across the flavors that do support it.  This trick will work (for example) in , Perl, .NET and JGSoft, but not in  (PCRE), Ruby 1.9+ or TextMate (both Oniguruma).  JavaScript's  (sticky flag) isn't as flexible as , and couldn't be used this way even if JS did support lookbehind.I should mention that I don't necessarily  this solution if you have other options.  The non-regex solutions in the other answers may be longer, but they're also self-documenting; this one's just about the  of that. ;)Also, this doesn't work in Android, which doesn't support the use of  in lookbehinds.Well, it's fairly easy to do this by brute force:I don't think it's really worth using a regex for this.EDIT: My reasoning for not using a regex:This is very easy with :Output:Or if you need the result as an array, you can use this code:Reference:Note: Splitter construction is shown inline above, but since Splitters are immutable and reusable, it's a good practice to store them in constants:If you're using Google's  general-purpose libraries (and quite honestly, any new Java project probably  be), this is insanely trivial with the  class:and that's . Easy as!You can use  from  (handling exceptions) or from  (it handles exceptions for you)Put it inside a loop and you are good to go.I'd rather this simple solution:I asked @Alan Moore in a comment to the  how strings with newlines could be handled. He suggested using DOTALL.Using his suggestion I created a small sample of how that works:But I like @Jon Skeets solution in  also. For maintainability in larger projects where not everyone are equally experienced in Regular expressions I would probably use Jons solution.Another brute force solution could be, Where the code just steps through the string with substringsResult"},
{"body": "Is there any other way besides using  to get image height and width?Because I encounter an issue that locks up the thread.This error only occurs on a Sun app server and therefore I suspect that it is a Sun bug.Here is something very simple and handy.  I have found another way to read an image size (more generic). \nYou can use ImageIO class in cooperation with ImageReaders. \nHere is the sample code:Note that getFileSuffix is method that returns extension of path without \".\" so e.g.: png, jpg etc.\nExample implementation is:This solution is very quick as only image size is read from the file and not the whole image. I tested it and there is no comparison to ImageIO.read performance. I hope someone will find this useful.This is a rewrite of the great post by @Kay, which throws IOException and provides an early exit:I guess my rep is not high enough for my input to be considered worthy as a reply.I tried to test performance using some of the various approaches listed. It's hard to make a rigorous test as many factors affect the result. I prepared two folders, one with 330 jpg files and another one with 330 png files. The average file size was 4Mb in both cases. Then I called getDimension for each file. Each implementation of getDimension method and each image type was tested separately (separate run). Here is the execution times that I got (first number for jpg, second number for png): It's obvious that some methods load the whole file in order to get dimensions while others get by just reading some header information from the image. I think these numbers may be useful when application performance is critical.Thank you everyone for the contribution to this thread - very helpful.You can load jpeg binary data as a file and parse the jpeg headers yourself. The one you are looking for is the 0xFFC0 or Start of Frame header:For more info about the headers check out wikipedia's jpeg entry or I got the above info .I used a method similar to the code below which I got from  at the sun forums:}I found this free class, work perfectly:Simple way:Try using the ImageInfo freely available class, I've used it for the same purpose:You could use the Toolkit, no need for ImageIOIf you don't want to handle the loading of the image doTo get a Buffered Image with ImageIO.read is a very heavy method, as it's creating a complete uncompressed copy of the image in memory. For png's you may also use pngj and the code:You can get width and height of image with BufferedImage object using java.To get size of emf file without EMF Image Reader you can use code:"},
{"body": "What is the fastest way to strip all non-printable characters from a  in Java?So far I've tried and measured on 138-byte, 131-character String:My best try was the following:Any thoughts on how to make it even faster?Bonus points for answering a very strange question: why using \"utf-8\" charset name directly yields better performance than using pre-allocated static const ?I've tried my best to collected all the proposed solutions and its cross-mutations and published it as a . Currently it sports 17 algorithms. One of them is \"special\" -  algorithm () employs intricate reflection tricks thus achieving stellar speeds, but it messes up JVM strings' state, thus it's benchmarked separately.You're welcome to check it out and run it to determine results on your box. Here's a summary of results I've got on mine. It's specs:Different algorithms show ultimately different results given a different set of input data. I've ran a benchmark in 3 modes:This mode works on a same single string provided by  class as a constant. The showdown is:In charted form:\nSource string provider pre-generated lots of random strings using (0..127) character set - thus almost all strings contained at least one control character. Algorithms received strings from this pre-generated array in round-robin fashion.In charted form:\nSame as previous, but only 1% of strings was generated with control characters - other 99% was generated in using [32..127] character set, so they couldn't contain control characters at all. This synthetic load comes the closest to real world application of this algorithm at my place.In charted form:\nIt's very hard for me to decide on who provided the best answer, but given the real-world application best solution was given/inspired by Ed Staub, I guess it would be fair to mark his answer. Thanks for all who took part in this, your input was very helpful and invaluable. Feel free to run the test suite on your box and propose even better solutions (working JNI solution, anyone?).If it is reasonable to embed this method in a class which is not shared across threads, then you can reuse the buffer: etc...This is a big win - 20% or so, as I understand the current best case.If this is to be used on potentially large strings and the memory \"leak\" is a concern, a weak reference can be used.using 1 char array could work a bit betterand I avoided repeated calls to another micro-optimization that might work isWell I've beaten the current best method (freak's solution with the preallocated array) by about 30% according to my measures. How? By selling my soul.As I'm sure everyone that has followed the discussion so far knows this violates pretty much any basic programming principle, but oh well. Anyways the following only works if the used character array of the string isn't shared between other strings - if it does whoever has to debug this will have every right deciding to kill you (without calls to substring() and using this on literal strings this should work as I don't see why the JVM would intern unique strings read from an outside source). Though don't forget to make sure the benchmark code doesn't do it - that's extremely likely and would help the reflection solution obviously.Anyways here we go:For my teststring that gets  vs.  for the old variant. I'm quite sure the only way to beat that could be to write it in C (probably not though) or some completely different approach nobody has thought about so far. Though I'm absolutely not sure if the timing is stable across different platforms - produces reliable results on my box (Java7, Win7 x64) at least.You could split the task into a several parallel subtasks, depending of processor's quantity.IANA low-level java performance junkie, but have you tried ? It appears that it could allow some CPU's to perform checks in parallel.Also,  has some fun ideas for optimizations.I was so free and wrote a small benchmark for different algorithms. It's not perfect, but I take the minimum of 1000 runs of a given algorithm 10000 times over a random string (with about 32/200% non printables by default). That should take care of stuff like GC, initialization and so on - there's not so much overhead that any algorithm shouldn't have at least one run without much hindrance.Not especially well documented, but oh well.  - I included both of ratchet freak's algorithms and the basic version. At the moment I randomly initialize a 200 chars long string with uniformly distributed chars in the range [0, 200).If you mean  etc.: This shouldn't be faster - except for some better caching - since  is used internally, if the charset is not cached.One thing might be that you're using different charsets (or maybe some of your code does transparently) but the charset cached in  doesn't change."},
{"body": "I would like to compile my Java program in Eclipse but not to run it. I can't understand how to do it.How can I compile a Java program to  files in Eclipse without running it?You can un-check the build automatically in Project menu and then build by hand by type Ctrl + B, or clicking an icon the appears to the right of the printer icon.You will need to go to ,then build your project. This will work, even when your source code does not contain any main method to run as an executable program. The .class files will appear in the bin folder of your project, in your workspace. In the case that you delete your .class file in Eclipse and then try to build it again from the .java file it will do nothing. If you try to run the .java file without the .class file you will get an error that it can not find the main class.You will either have to change and re-save the .java file then build it again, or else you have to run Clean on the project then build again.Go to the project explorer block ...\nright click on project name \nselect \"Build Path\"-----------> \"Configuration Build Path\"then the pop up window will get open.in this pop up window you will find 4 tabs. 1)source 2) project 3)Library 4)order and export Click on 1) Source select the project (under which that file is present which you want to compile)and then click on ok....Go to the workspace location of the project open a bin folder and search that class file ...you will get that java file compiled...just to cross verify check the changed timing.hope this will help.Thanks.Right click on It will compile all files in your project and updates your build folder, all without running.Try this in your console:If you also need any external library, try:"},
{"body": "This is not really a question, however, I would like to share some of my working code here for your reference when you need.As we know that  is deprecated from API22 and comletely removed since API23. At the moment, we cannot access  anymore (404).  So, the following is my working sample code for . It's working, tested with . Of course, the code perhaps is just a basic sample that posts two existed drawable files, also is not the best solution for all cases, and not good tuning.Any suggestions for better / more beautiful code will be appreciated.Hope this helps!For text part, please refer to @RacZo's answer below.I rewrite your code @RacZo and @BNK more modular and easy to use likeCheck full of code  at my .Nice answer @BNK!Just want to add to the answer... I was trying to figure how to append text fields to the body and created the following function to do it:It is working pretty well, so I hope it helps .for those one who is struggling like me to send utf-8 parameters and still no luck ...\nthe problem i had was in the dataOutputStream , and change the code of @RacZo to below codehope this work for some one like me"},
{"body": "Currently I have a Spring Boot application using Spring Data REST. I have a domain entity  which has the  relationship to another domain entity, . These classes are structured as follows:Post.java:Comment.java:Their Spring Data REST JPA repositories are basic implementations of :PostRepository.java:CommentRepository.java:The application entry point is a standard, simple Spring Boot application. Everything is configured stock.Application.javaEverything appears to work correctly. When I run the application, everything appears to work correctly. I can POST a new Post object to  like so:Body: \nResult at :However, when I perform a GET at  I get an empty object  returned,  and if I try to POST a comment to the same URI, I get an HTTP 405 Method Not Allowed.What is the correct way to create a  resource and associate it with this ? I'd like to avoid POSTing directly to  if possible.Assuming you already have discovered the post URI and thus the URI of the association resource (considered to be  in the following), it generally takes these steps:Note, that in the last step, according to the specification of , you can submit multiple URIs identifying comments separated by a line break to assign multiple comments at once.A few more notes on the general design decisions. A post/comments example is usually a great example for an aggregate, which means I'd avoid the back-reference from the  to the  and also avoid the  completely. If the comments don't have a lifecycle on their own (which they usually don't in an composition-style relationship) you rather get the comments rendered inline directly and the entire process of adding and removing comments can rather be dealt with by using . Spring Data REST has added  in the latest release candidate for the upcoming version 2.2.You have to post the comment first and while posting the comment you can create an association posts entity.It should look something like below :and it will work perfectly fine.I faced the same scenario and I had to remove the repository class for the sub entity as I have used one to many mapping and pull data thru the main entity itself. Now I am getting the entire response with data."},
{"body": "I'm currently looking for ways to create automated tests for a  (Java API for RESTful Web Services) based web service. I basically need a way to send it certain inputs and verify that I get the expected responses. I'd prefer to do this via JUnit, but I'm not sure how that can be achieved.What approach do you use to test your web-services? As entzik pointed out, decoupling the web service from the business logic allows me to unit test the business logic. However, I also want to test for the correct HTTP status codes etc. comes with a great RESTful client API that makes writing unit tests really easy. See the unit tests in the examples that ship with Jersey. We use this approach to test the REST support in , if you are interested the You can try out  which makes it  simple to test REST services and validating the response in Java (using JUnit or TestNG).As James said; There is built-in  for Jersey. A simple hello world example can be like this:pom.xml for maven integration. When you run . Frameworks start a grizzly container. You can use jetty or tomcat via changing dependencies.ExampleApp.javaHelloWorld.javaHelloWorldTest.javaYou can check  sample application.Though its too late from the date of posting the question, thought this might be useful for others who have a similar question. \nJersey comes with a test framework called the  which allows you to test your RESTful Web Service, including the response status codes. You can use it to run your tests on lightweight containers like Grizzly, HTTPServer and/or EmbeddedGlassFish. Also, the framework could be used to run your tests on a regular web container like GlassFish or Tomcat. You probably wrote some java code that implements your business logic and then you have generated the web services end point for it.An important thing to do is to independently test your business logic. Since it's pure java code you can do that with regular JUnit tests. Now, since the web services part is just an end point, what you want to make sure is that the generated plumbing (stubs, etc) are in sync with your java code. you can do that by writing JUnit tests that invoke the generated web service java clients. This will let you know when you change your java signatures without updating the web services stuff.If your web services plumbing is automatically generated by your build system at every build, then it may not be necessary to test the end points (assuming it's all properly generated). Depends on your level of paranoia.I use Apache's  to call Restful Services. The HTTP Client library allows you to easily perform get, post or whatever other operation you need. If your service uses JAXB for xml binding, you can create a JAXBContext to serialize and deserialize inputs and outputs from the HTTP request.Take a look at . This can  generate a proxy implementation for your JAX-RS webservice class using jersey client behind the scene. Effectively you will call you webservice methods as simple java methods from your unit tests. Handles http authentication as well.There is no code generation involved if you need to simply run tests so it is convenient.  Dislclaimer: I am the author of this library.I certainly would not assume that the person who wrote the JAX-RS code and is looking to unit test the interface is somehow, for some bizarre, inexplicable reason, oblivious to the notion that he or she can unit testing other parts of the program, including business logic classes. It's hardly helpful to state the obvious and the point was repeatedly made that the responses need to be tested, too. Both Jersey and RESTEasy have client applications and in the case of RESTEasy you can use the same annoations (even factor out annotated interface and use on the client and server side of your tests). REST not what this service can do for you; REST what you can do for this service. Keep it simple. Have a look at  which can be imported from Maven Central.Usage example:As I understand the main purpose of the auther of this issue is to decouple JAX RS layer from business one. And unit test only the first one. Two basic problems here we have to resolve:The first one is solved with Arquillian.\nThe second one is perfectly described in Here is an example of the code, it may differ if you use another application server, but I hope you'll get the basic idea and advantages.A couple of notes:Hope, it'll help."},
{"body": "Can one develop an entire application using JavaFX and run it on iOS, Android or Windows Phone 8, without writing platform-specific code? is a good resource for how everything was started and what was the state of JavaFX on embedded and mobile in beginning of 2014. But,  has changed since then and the users who stumble on this thread do not get the updated information.Most of my points are related to Invariant's answer, so I would suggest to go through it first.Some bad news first:Now, some good news:If you are not the DIY kind, I would suggest to install the IDE plugin on your favourite IDE and get started.Most of the documentation on how to get started can be found  and some of the samples can be found .Yes you can run JavaFX application on iOS, android, desktop, RaspberryPI (no windows8 mobile yet).   If you are going to develop serious  applications here is some more info At present for JavaFX Oracle priority list is Desktop (Mac,windows,linux)  .For iOS/android oracle done most of the hardwork and opnesourced javafxports of these platforms as part of OpenJFX ,but there is no JVM from oracle for ios/android.Community is putting all together by filling missing piece(JVM) for ios/android,Community made good progress in running JavaFX  on ios ( / android(). If you want you can also contribute to the community by sponsoring () or start developing apps and report issues. Johan Vos created a website for javafx ports ,check this for updated info ..Oracle JavaFX from  supports only . On these platforms, JavaFX applications are typically run on JVM from Java SE or OpenJDK.There is also a  project, which is an open-source project sponsored by a . It aims to port JavaFX  to Android and iOS.On Android, this library can be used like any other Java library; the . It's what people mean by saying that \"Android runs Java\".On iOS, situation is a bit more complex, as neither Java SE nor OpenJDK supports Apple mobile devices. Till recently, the only sensible option was to use  ahead-of-time Java compiler for iOS. Unfortunately, on 15 April 2015, .One possible alternative is Intel's . Till recently, it was a proprietary technology, but on 11 August 2016 it was . Although it can be possible to compile an iOS JavaFX app using  JavaFXPorts' JavaFX implementation, there is no evidence for that so far. As you can see, the situation is dynamically changing, and this answer will be hopefully updated when new information is available.With Windows Phone it's simple: there is no JavaFX support of any kind.Possible. You can get commercial sport also. "},
{"body": " is declared as .But you can call  to reassign it.Huh? How is this possible if it's ?(same point applies to  and )And more importantly, if you can mutate the public static final fields, what does this mean as far as the guarantees (if any) that  gives you? (I never realized nor expected System.in/out/err behaved as  variables):By the way, actually you can mutate  fields via reflection by calling  on them (or by using  methods). Such techniques are used during deserialization, by Hibernate and other frameworks, etc, but they have one limitation: code that have seen value of final field before modification is not guaranteed to see the new value after modification. What's special about the fields in question is that they are free of this limitation since they are treated in special way by the compiler.Java uses a native method to implement ,  and .On my JDK1.6.0_20,  looks like this:You still can't \"normally\" reassign  variables, and even in this case, you aren't directly reassigning the field (i.e. you still can't compile \"\"). Native methods allow some things that you simply can't do in regular Java, which explains why there are restrictions with native methods such as the requirement that an applet be signed in order to use native libraries.To extend on what Adam said, here is the impl:and setOut0 is defined as:Depends on the implementation.  The final one may never change but it could be a proxy/adapter/decorator for the actual output stream, setOut could for example set a member that the out member actually writes to.  In practice however it is set natively.the  which is declared as final in System class is a class level variable.\nwhere as out which is in the below method is a local variable.\nwe are no where passing the class level out which is actually a final one into this method usage of the above method is as below:now the data will be diverted to the file.\nhope this explanation makes the sense.So no role of native methods or reflections here in changing  purpose of the final keyword.As far as how, we can take a look at the source code to :In other words, JNI can \"cheat\". ; )"},
{"body": "What would be a use case for a use of a Mockito spy?It seems to me that every spy  use case can be handled with a mock, using callRealMethod.One difference I can see is if you want most method calls to be real, it saves some lines of code to use a mock vs. a spy. Is that it or am I missing the bigger picture?The answer is in : was introduced after , but spy() was left there of course, to ensure backward compatibility.Otherwise, you're right: all the methods of a spy are real unless stubbed. All the methods of a mock are stubbed unless  is called. In general, I would prefer using , because it doesn't force me to use the  idiom instead of the traditional If there is an object with 8 methods and you have a test where you want to call 7 real methods and stub one method you have two options:The  on  recommends using a spy for partial mocks.When Mockito creates a mock \u2013 it does so from the Class of a Type, not from an actual instance. The mock simply creates a bare-bones shell instance of the Class, entirely instrumented to track interactions with it. On the other hand, the spy will wrap an existing instance. It will still behave in the same way as the normal instance \u2013 the only difference is that it will also be instrumented to track all the interactions with it.In the following example \u2013 we create a mock of the ArrayList class:As you can see \u2013 adding an element into the mocked list doesn\u2019t actually add anything \u2013 it just calls the method with no other side-effect. A spy on the other hand will behave differently \u2013 it will actually call the real implementation of the add method and add the element to the underlying list:Here we can surely say that the real internal method of the object was called because when you call the size() method you get the size as 1, but this size() method isn\u2019t been mocked!  The internal real size() method is called as size() isn\u2019t mocked (or stubbed) and hence we can say that the entry was added to the real object.Source:   + self notes."},
{"body": "I have found lots of books in java saying switch statement is faster than if else statement. But I didnot find antwhere saying .I have a situation i have to choose any one item out of two i can use either of the following wayor using if statement like the followingIn the above example which Because there are special bytecodes that allow efficient switch statement evaluation when there are a lot of cases.If implemented with IF-statements you would have a check, a jump to the next clause, a check, a jump to the next clause and so on. With switch the JVM loads the value to compare and iterates through the value table to find a match, which is faster in most cases.A  statement is not always faster than an  statement.  It scales better than a long list of  statements as  can perform a lookup based on all the values.  However, for a short condition it won't be any faster and could be slower.At the bytecode level, subject variable is loaded only once into processor register from a memory address in the structured .class file loaded by Runtime,and this is in a switch statement; whereas in an if-statement, a different jvm instruction is produced by your code-compiling DE, and this requires that each variable be loaded in to registers although same variable is used as in next preceeding if-statement. If you know of coding in assembly language then this would be commonplace; although java compiled coxes are not bytecode, or direct machine code, the conditional concept hereof is still consistent.\nWell, I tried to avoid deeper technicality upon explaining. I hope I had made the concept clear and demystified. Thank you.If you are performing an insane amount of checks like 100+ you may want to consider some abstraction.You have incoming packets that range from ids 0 through 255. You use maybe 150 of them. You may want to consider something like the below instead of a switch of 150 ids.I should also point out that index list isn't really needed and would probably slow the code down anyways. It was merely a suggestion so you don't have empty locations. Also not to mention is this situation you're only losing out of 106 indexes. I'm not 100% sure, but I believe each of these are pointing to null anyways so no real memory issues would be present."},
{"body": "I am trying to understand more about java, especially about memory management and threads.\nFor this reason I have recently found interest in looking at thread dumps.Here are few lines taken from a web app using VisualVM, a built-in tool for java:First I have questions about some variable names: Then for the stack trace itself:I thought that the word locked was related in someway to a wait condition, however, I was wrong.  In fact, I am wondering why locked is repeated three times, but the thread is in runnable state as seen in the same dump:Then last of all, this was the worst of them:This thread is in runnable state, but it's waiting on condition. What condition and what is 0x00000?Why the stack trace is so short without any evidence of the thread class?If you could answer to all my questions I would be very grateful.ThanksThe TID is thead id and NID is: Native thread ID. This ID is highly platform dependent. It's the NID in jstack thread dumps.  On Windows, it's simply the OS-level thread ID within a process.  On Linux and Solaris, it's the PID of the thread (which in turn is a light-weight process).  On Mac OS X, it is said to be the native pthread_t value.Go to this link: : for a definition and a further explanation of these two terms. On IBM's site I found this link: . that covers this in greater detail:It explains what that waiting on means:\nA lock prevents more than one entity from accessing a shared resource. Each object in Java\u2122 has an associated lock (gained by using a synchronized block or method). In the case of the JVM, threads compete for various resources in the JVM and locks on Java objects.Then it describes the monitor as a special kind of locking mechanism that is used in the JVM to allow flexible synchronization between threads. For the purpose of this section, read the terms monitor and lock interchangeably.Then it goes further:Here is a more in-depth explanation of what you are seeing on the lines from the thread dump. A Java thread is implemented by a native thread of the operating system. Each thread is represented by a line in bold such as:*The following 6 items explains this as I've matched them from the example, values in the brackets[]:  Definition of the ReferenceQueue is:\nReference queues, to which registered reference objects are appended by the garbage collector after the appropriate reachability changes are detected. The finalizer thread runs so the garbage collection operates to clean up resources associated with an object.  If I'm seeing it corectly, the finalizer can't get the lock to this object: java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118) because the java object is running a method, so the finalizer thread is locked until that object is finished with it's current task.  Also, the finalizer isn't just looking to reclaim memory, it's more involved than that for cleaning up resources.  I need to do more study on it, but if you have files open, sockets, etc... related to an objects methods, then the finalizer is going to work on freeing those items up as well.It is a pointer in memory to the thread.  Here is a more detailed description:C.4.1 Thread InformationThe first part of the thread section shows the thread that provoked the fatal error, as follows:The thread pointer is the pointer to the Java VM internal thread structure. It is generally of no interest unless you are debugging a live Java VM or core file.This last description came from: Here are a few more links on thread dumps: Further to @James Drinkard's excellent answer:Note that, depending on the underlying implementation, the  of a thread that is blocked in a native method may be reported as , where   It turns out that this description also encompasses being blocked in an OS call such as a poll or read operation - presumably because there is no guarantee that the JVM can know when a native method call has blocked at the OS level.Many discussions of JVM thread dumps that I've seen either ignore this possibility completely, or blithely skim over it without considering the implications - not least of which is that monitoring tools may confusingly report that several such threads are 'running', and furthermore that they are all running at 100%.Try  This is probally enough for many cases."},
{"body": "I was reading the JavaDoc for Threadlocal hereand it says\n\"ThreadLocal instances are typically private static fields in classes that wish to associate state with a thread (e.g., a user ID or Transaction ID). \"But my question is why did they choose to make it static (typically) - it makes things a bit confusing to have \"per thread\" state but the fields are static?Because if it were an instance level field, then it would actually be \"Per Thread - Per Instance\", not just a guaranteed \"Per Thread.\"  That isn't normally the semantic you're looking for.  Usually it's holding something like objects that are scoped to a User Conversation, Web Request, etc.  You don't want them also sub-scoped to the instance of the class.\nOne web request => one Persistence session.\nNot one web request => one persistence session per object.Either make it static or if you are trying to avoid any static fields in your class - make the class itself a singleton and then you can safely use the an instance level ThreadLocal as long as you have that singleton available globally.It doesn't have to be. The important thing is that it should be a singleton.The reason is that the variables are accessed via a pointer associated with the thread.  They act like global variables with thread scope, hence static is the closest fit.  This is the way that you get thread local state in things like pthreads so this might just be an accident of history and implementation.A use for an threadlocal on a per instance per thread is if you want something to be visible in all methods of an object and have it thread safe without synchronizing access to it like you would so for an ordinary field. "},
{"body": "I just saw code similar to this:When ran, this block of code will print out:I understand why the first is : because the two objects are separate objects, so the  compares the references. But I can't figure out, why is the second statement returning ? Is there some strange autoboxing rule that kicks in when an Integer's value is in a certain range? What's going on here?The  line is actually guaranteed by the language specification. From :The discussion goes on, suggesting that although your second line of output is guaranteed, the first isn't (see the last paragraph quoted below):Yep the first output is produced for comparing reference; 'a' and 'b' - these are two different reference. In point 1, actually two references are created which is similar as - The second output is produced because the JVM tries to save memory, when the  falls in a range (from -128 to 127). At point 2 no new reference of type Integer is created for 'd'. Instead of creating new object for the Integer type reference variable 'd', it only assigned with previously created object referenced by 'c'. All of these are done by JVM. These memory saving rules are not only for Integer. for memory saving purpose, two instances of the following wrapper objects (while created through boxing), will always be == where their primitive values are the same - Integer objects in some range (I think maybe -128 through 127) get cached and re-used.  Integers outside that range get a new object each time.My guess is that Java keeps a cache of small integers that are already 'boxed' because they are so very common and it saves a heck of a lot of time to re-use an existing object than to create a new one.Yes, there is a strange autoboxing rule that kicks in when the values are in a certain range. When you assign a constant to an Object variable, nothing in the language definition says a new object  be created. It may reuse an existing object from cache.In fact, the JVM will usually store a cache of small Integers for this purpose, as well as values such as Boolean.TRUE and Boolean.FALSE.In Java the boxing works in the range between -128 and 127 for an Integer. When you are using numbers in this range you can compare it with the == operator. For Integer objects outside the range you have to use equals.That is an interesting point. \nIn the book  suggests always to override equals for your own classes. Also that, to check equality for two object instances of a java class always use the equals method. returns:In Java 5, a new feature was introduced to save the memory and improve performance for Integer type objects handlings. Integer objects are cached internally and reused via the same referenced objects.For more detail pls go through below Link:If we check the source code of  obeject, we will find the source of  method just like this:  which can explain why  objects, which in the range from -128 () to 127 (), are the same referenced objects during the autoboxing. And we can see there is a class  takes care of the  cache array, which is a private static inner class of  class.There is another interesting example may help us understand this weird situation:"},
{"body": "I have a JSON file like this:Before when files had a root element I would use:code but I can't think how to code the  class as the root element is an array.I have tried using:with: But haven't had any luck. How else can I read this using this method?P.S I have got this to work using: But I would prefer to know how to do it (if possible) with both methods.Problem is caused by comma after last element of your array (after each ). If you remove it and change your data to \nwill work fine.Seems to work fine. But there is an extra  Comma in your string.sample call:"},
{"body": "Please help me understand where to use a regular JOIN and where a JOIN FETCH.For example, if we have these two queriesandIs there any difference between them? If yes, which one to use when?In this two queries, you are using JOIN to query all employees that have at least one department associated.But, the difference is: in the first query you are returning only the Employes for the Hibernate. In the second query, you are returning the Employes  all Departments associated. So, if you use the second query, you will not need to do a new query to hit the database again to see the Departments of each Employee.You can use the second query when you are sure that you will need the Department of each Employee. If you not need the Department, use the first query.I recomend read this link if you need to apply some WHERE condition (what you probably will need): If you don't use  and the Departments continue to be returned, is because your mapping between Employee and Department (a ) are setted with . In this case, any HQL (with  or not) query with  will bring all Departments. Remember that all mapping *ToOne ( and ) are EAGER by default.in  i mentioned before on the comment, read this part :this \"JOIN FETCH\" will have it's effect if you have (fetch = FetchType.LAZY) property for a collection inside entity(example bellow).And it is only effect the method of \"when the query should happen\". And you must also know :  when is the association fetched --> your \"FETCH\" typehow is it fetched --> Join/select/Subselect/BatchIn your case, FETCH will only have it's effect if you have department as a set inside Employee, something like this in the entity:when you use you will get  and . when you didnt use fetch you can still get  but hibernate will processing another select to the database to get that set of department.so its just a matter of performance tuning, about you want to get all result(you need it or not) in a single query(eager fetching), or you want to query it latter when you need it(lazy fetching).Use eager fetching when you need to get small data with one select(one big query). Or use lazy fetching to query what you need latter(many smaller query).use fetch when :Dherik : I'm not sure about what you say, when you don't use fetch the result will be of type :  which means a list of Object tables and not a list of Employee. When you use fetch, there is just one select and the result is the list of Employee  containing the list of departements. It overrides the lazy declaration of the entity. If you have @oneToOne mapping set to FetchType.LAZY and you use second query(because you need Department objects to be loaded as part of Employee objects) what Hibernate will do is, it will issue queries to fetch Department objects for every individual Employee object it fetches from DB. Later in the code you might access Department objects via Employee to Department single-valued association and Hibernate will not issue any query to fetch Department object for the given Employee. Remember Hibernate still issues queries equal to the number of Employees it has fetched. Hibernate will issue same number of queries in both above queries if you wish to access Department objects of all Employee objects"},
{"body": "Should logger be declared static or not? Usually I've seen two types of declaration for a logger :orWhich one should be used? what are the pro's and con's of both?The advantage of the non-static form is that you can declare it in an (abstract) base class like follows without worrying that the right classname will be used:However its disadvantage is obviously that a whole new logger instance will be created for every instance of the class. This may not per se be expensive, but it adds a significant overhead. If you'd like to avoid this, you'd like to use the  form instead. But its disadvantage is in turn that you have to declare it in every individual class and take care in every class that the right classname is been used during logger's construction because  cannot be used in static context. However, in the average IDE you can create an autocomplete template for this. E.g.  + .On the other hand, if you obtain the logger by a factory which in turn may cache the already-instantiated loggers, then using the non-static form won't add that much overhead. Log4j for example has a  for this purpose.I used to think that all loggers should be static; however,  brings up some important memory concerns, regarding classloader leaks. Declaring a logger as static prevents the declaring class (and associated classloaders) from being garbage collected in J2EE containers that use a shared classloader. This will result in PermGen errors if you redeploy your application enough times.I don't really see any way to work around this classloader leak issue, other than declaring loggers as non-static.The most important difference is how it affects your log files: in which category do logs go?I would strongly recommend that last option. It has these advantages, compared to the other solutions:It also has disadvantages:Use inversion of control and pass the logger into the constructor. If you create the logger inside the class you are going to have a devil of a time with your unit tests. You are writing unit tests aren't you?"},
{"body": "There are two types of  statements in java - classic:  and shorthand: . Is one faster than the other or are they the same?statement:ternary operator:There's only one type of \"if\" statement there. The other is a conditional expression. As to which will perform better: they could compile to the same bytecode, and I would expect them to behave identically - or so close that you definitely wouldn't want to choose one over the other in terms of performance.Sometimes an  statement will be more readable, sometimes the conditional operator will be more readable. In particular, I would recommend using the conditional operator when the two operands are simple and side-effect-free, whereas if the main purpose of the two branches  their side-effects, I'd probably use an  statement.Here's a sample program and bytecode:Bytecode decompiled with :As you can see, there is a  difference in bytecode here - whether the  occurs within the brance or not (unlike my previous hugely-flawed attempt :) but I would be very surprised if the JITter ended up with different native code.Both of your examples will probably compile to identical or nearly identical bytecode, so there should be no difference in performance.Had there been a difference in execution speed, you should still use the most idiomatic version (which would be the second one for assigning a single variable based on a simple condition and two simple sub-expressions, and the first one for doing more complex operations or operations that do not fit on a single line). These are the same.  Both of them are fairly fast, typically around 10-30 nano-seconds. (depending on usage pattern)  Is this time frame important to you?You should do what you believe is clearest.neither - they will be compiled to the same.Just to add to all the other answers:The second expression is often called tertiary/ternary operator/statement. It can be very useful because it returns an expression. Sometimes it makes the code more clearer for typical short statements."},
{"body": "This is my jTable I will call this method to retrieve the data from database and put it into table modelCurrently I was using this method to refresh the table after updating the table data. I will first clear the table and then restructure the table model again so it will refresh the jTable. But I was thinking is there any best practices or better way to do that? If you want to notify your  about changes of your data, use\nFrom the :The faster way for your case is:The optimized way when one or few cell change:try thisWould it not be better to use  and  that will cause the table to update?I did it like this in my Jtable its autorefreshing after 300 ms;I doubt it will do good with large number of objects like over 500, only other way is to implement TableModelListener in your class, but i did not understand how to use it well. look at "},
{"body": "I want to deploy sources and javadocs with my snapshots. This means that I want to automize the following command:Just to execute:I don't want to have javadoc/sources generation executed during the  phase (i.e. local builds).I know that source/javadoc plugins can be synchronized with the execution of the  plugin but I can't figure out how to wire it to the snapshots releases.See  for a complete example.Just to add an alternative that doesn't require you to muck with plugin configuration:Credit goes to mcbeelen from The article referred to by Dan also mentions another approach that works without modifying poms AND won't go away anytime soon:Which works fine with Maven 3+, along with...Which I have tested from Jenkins deploying to Nexus.This approach was nice because I only had to modify some Jenkins jobs and didn't need to mess with my poms."},
{"body": "I'm working on a Java Selenium-WebDriver. I added andbecause my Applications takes few seconds to load the User Interface. So I set 2 seconds implicitwait. but I got Then I add Now it works fine. Which one is a better way? Well, there are two types of wait: explicit and implicit wait. \nThe idea of explicit wait isThe concept of implicit wait isYou can get difference in details .In such situations I'd prefer using explicit wait ( in particular): function returns your found web element.\nFrom the documentation on :\n\nDetails you can get Usage of  in your case be the following:This approach IMHO better as you do not know exactly how much time to wait and in  polling interval you can set arbitrary timevalue which element presence will be verified through .\nRegards.If using webdriverJs (node.js),The code above makes browser wait for 5 seconds after clicking the button.This thread is a bit older, but thought I'd post what I currently do (work in progress).Though I'm still hitting situations where the system is under heavy load and when I click a submit button (e.g., login.jsp), all three conditions (see below) return  but the next page (e.g., home.jsp) hasn't started loading yet.This is a generic wait method that takes a list of ExpectedConditions.  I have defined various reusable ExpectedConditions (three are below).  In this example, the three expected conditions include document.readyState = 'complete', no \"wait_dialog\" present, and no 'spinners' (elements indicating async data is being requested).Only the first one can be generically applied to all web pages.Depending on the page, I may use one or all of them:There are also predefined ExpectedConditions in the following class:  Using  is an unconditional wait. If your test loads faster you will still have to wait. So in principle using  is the better solution.However, I don't see why  does not work in your case. Did you measure if the  actually takes two seconds before throwing an exception. If so, can you try to use WebDriver's conditional wait as described in  answer?I like to use custom conditions. Here's some code in Python:Whenever you need to wait, you can do it explicitly by checking existance of a certain element (such element may vary from page to page).  returns list - empty or not, you have just to check.click appears to be blocking? - here's another way to wait if you're using WebDriverJS:The code above waits after the button is clicked for the next page to load and then grabs the source of the next page.Sometimes implicit wait seems to get overridden and wait time is cut short.  [@eugene.polschikov] had good documentation on the whys.  I have found in my testing and coding with Selenium 2 that implicit waits are good but occasionally you have to wait explicitly.  It is better to avoid directly calling for a thread to sleep, but sometimes there isn't a good way around it.  However, there are other Selenium provided wait options that help.  and  have proved especially useful.   Implicitly wait and Thread.sleep Both are used for synchronization only..but the difference is we can use Implicitly wait for entire program but Thread.sleep will works for that single code only..Here my suggestion is use Implicitly wait once in the program when every time your Webpage will get refreshed means use Thread.sleep at that time..it will much Better :)Here is My Code :Implicit Wait: During Implicit wait if the Web Driver cannot find it immediately because of its availability, the WebDriver will wait for mentioned time and it will not try to find the element again during the specified time period. Once the specified time is over, it will try to search the element once again the last time before throwing exception. The default setting is zero. Once we set a time, the Web Driver waits for the period of the WebDriver object instance.Explicit Wait: There can be instance when a particular element takes more than a minute to load. In that case you definitely not like to set a huge time to Implicit wait, as if you do this your browser will going to wait for the same time for every element.\nTo avoid that situation you can simply put a separate time on the required element only. By following this your browser implicit wait time would be short for every element and it would be large for specific element.I prefer the following code to wait for 2 seconds.Use this code incase if the page refreshes when you change the control from one input field to another input field within the same page. Pass the corresponding driver reference to this method to find the element. Line1 is used to click outside that makes the refresh. If you have any queries post your comment."},
{"body": "I have an app that makes extensive use of a WebView. When the user of this app does not have Internet connection, a page saying \"web page not available\" and various other text appears. Is there a way to not show this generic text in my WebView? I would like to provide my own error handling. I found out  doesn't actually clear the view.First create your own error page in HTML and put it in your assets folder, Let's call it myerrorpage.html\nThen with onReceivedError:The best solution I have found is to load an empty page in the OnReceivedError event like this:Finally, I solved this. (It works till now..)My solution is like this...Here is my full source. Check this out.Addition:Here is layout....Check out the discussion at . It's quite long, but the consensus seems to be that a) you can't stop the \"web page not available\" page appearing, but b) you could always load an empty page after you get an onReceivedErrorWhen webview is embedded in some custom view such that user almost believes that he is seeing a native view and not a webview. In such scenario showing the \"page could not be loaded\" error is preposterous, what I usually do in such situation is I load blank page and show a toast message as belowYou could use a  request to get the page content and then display that data using the  , this way you are not using multiple server calls. Alternative you can use  to check the  object for validity.Perhaps I misunderstand the question, but it sounds like you're saying you get the error received callback, and you just are asking what is the best way to not show the error? Why don't you just either remove the web view from the screen and/or show another view on top of it?I suppose that if you insist on doing this, you could just check if the resource is there before calling the loadURL function. \nJust simply override the functions and do the check before calling the super()REMARK (maybe off-topic): In http, there is a method called HEAD which is described as follow:This method might be handy.\nAnyway how ever you implement it ... check this code:You could try this check using I would just change the webpage to whatever you are using for error handling:  this can all be found on I've been working on this problem of ditching those irritable Google error pages today. It is possible with the Android example code seen above and in plenty of other forums (ask how I know):IF you put it in shouldOverrideUrlLoading() as one more webclient. At least, this is working for me on my 2.3.6 device.  We'll see where else it works later. That would only depress me now, I'm sure.  The goBack bit is mine. You may not want it.Try thisWe can set the visibility of webView to 0(view.INVISIBLE) and show some message.\nThis code works for my app running on lolipop.try this  , before redirect to another url check for internet conncetion based on that page should be loaded or not.override your WebViewClient method has side-effects, as it cancels the original URL loading."},
{"body": "How much is read from  variable slower than from regular field?More concretely is simple object creation faster or slower than access to  variable?I assume that it is fast enough so that having  instance is much faster then creating instance of  every time. But does that also apply for byte[10] or byte[1000] for example?Edit: Question is what is really going on when calling 's get? If that is just a field, like any other, then answer would be \"it's always fastest\", right?Running unpublished benchmarks,  takes around 35 cycle per iteration on my machine. Not a great deal. In Sun's implementation a custom linear probing hash map in  maps s to values. Because it is only ever accessed by a single thread, it can be very fast.Allocation of small objects take a similar number of cycles, although because of cache exhaustion you may get somewhat lower figures in a tight loop.Construction of  is likely to be relatively expensive. It has a fair amount of state and construction goes through the  SPI mechanism. You may be able to optimise by, for instance, cloning or providing the .Just because it may be faster to cache in a  rather than create does not necessarily mean that the system performance will increase. You will have additional overheads related to GC which slows everything down.Unless your application very heavily uses  you might want to consider using a conventional thread-safe cache instead.In 2009, some JVMs implemented ThreadLocal using an unsynchronised HashMap in the Thread.currentThread() object. This made it extremely fast (though not nearly as fast as using a regular field access, of course), as well as ensuring that the ThreadLocal object got tidied up when the Thread died. Updating this answer in 2016, it seems most (all?) newer JVMs use a ThreadLocalMap with linear probing. I am uncertain about the performance of those \u2013 but I cannot imagine it is significantly worse than the earlier implementation.Of course, new Object() is also very fast these days, and the Garbage Collectors are also very good at reclaiming short-lived objects.Unless you are certain that object creation is going to be expensive, or you need to persist some state on a thread by thread basis, you are better off going for the simpler allocate when needed solution, and only switching over to a ThreadLocal implementation when a profiler tells you that you need to.Good question, I've been asking myself that recently. To give you definite numbers, the benchmarks below (in Scala, compiled to virtually the same bytecodes as the equivalent Java code):available , were performed on an AMD 4x 2.8 GHz dual-cores and a quad-core i7 with hyperthreading (2.67 GHz).These are the numbers:Thread num.: 1\nTotal tests: 200Run times:  (showing last 5)\n 9.0069       9.0036       9.0017       9.0084       9.0074      (avg = 9.1034       min = 8.9986       max = 21.0306     )Thread num.: 2\nTotal tests: 200Run times:  (showing last 5)\n 4.5563       4.7128       4.5663       4.5617       4.5724      (avg = 4.6337       min = 4.5509       max = 13.9476     )Thread num.: 4\nTotal tests: 200Run times:  (showing last 5)\n 2.3946       2.3979       2.3934       2.3937       2.3964      (avg = 2.5113       min = 2.3884       max = 13.5496     )Thread num.: 8\nTotal tests: 200Run times:  (showing last 5)\n 2.4479       2.4362       2.4323       2.4472       2.4383      (avg = 2.5562       min = 2.4166       max = 10.3726     )Thread num.: 1\nTotal tests: 200Run times:  (showing last 5)\n 91.1741      90.8978      90.6181      90.6200      90.6113     (avg = 91.0291      min = 90.6000      max = 129.7501    )Thread num.: 2\nTotal tests: 200Run times:  (showing last 5)\n 45.3838      45.3858      45.6676      45.3772      45.3839     (avg = 46.0555      min = 45.3726      max = 90.7108     )Thread num.: 4\nTotal tests: 200Run times:  (showing last 5)\n 22.8118      22.8135      59.1753      22.8229      22.8172     (avg = 23.9752      min = 22.7951      max = 59.1753     )Thread num.: 8\nTotal tests: 200Run times:  (showing last 5)\n 22.2965      22.2415      22.3438      22.3109      22.4460     (avg = 23.2676      min = 22.2346      max = 50.3583     )Total work:  20000000\nThread num.: 1\nTotal tests: 200Run times:  (showing last 5)\n 12.625       12.631       12.634       12.632       12.628      (avg = 12.7333      min = 12.619       max = 26.698      )Test name:   loop_heap_read\nTotal work:  20000000Run times:  (showing last 5)\n 6.412        6.424        6.408        6.397        6.43        (avg = 6.5367       min = 6.393        max = 19.716      )Thread num.: 4\nTotal tests: 200Run times:  (showing last 5)\n 3.385        4.298        9.7          6.535        3.385       (avg = 5.6079       min = 3.354        max = 21.603      )Thread num.: 8\nTotal tests: 200Run times:  (showing last 5)\n 5.389        5.795        10.818       3.823        3.824       (avg = 5.5810       min = 2.405        max = 19.755      )Thread num.: 1\nTotal tests: 200Run times:  (showing last 5)\n 200.217      207.335      200.241      207.342      200.23      (avg = 202.2424     min = 200.184      max = 245.369     )Thread num.: 2\nTotal tests: 200Run times:  (showing last 5)\n 100.208      100.199      100.211      103.781      100.215     (avg = 102.2238     min = 100.192      max = 129.505     )Thread num.: 4\nTotal tests: 200Run times:  (showing last 5)\n 62.101       67.629       62.087       52.021       55.766      (avg = 65.6361      min = 50.282       max = 167.433     )Thread num.: 8\nTotal tests: 200Run times:  (showing last 5)\n 40.672       74.301       34.434       41.549       28.119      (avg = 54.7701      min = 28.119       max = 94.424      )A thread local is around 10-20x that of the heap read. It also seems to scale well on this JVM implementation and these architectures with the number of processors.@Pete is correct test before you optimise.I would be very surprised if constructing a MessageDigest has any serious overhead when compared to actaully using it.Miss using ThreadLocal can be a source of leaks and dangling references, that don't have a clear life cycle, generally I don't ever use ThreadLocal without a very clear plan of when a particular resource will be removed.Build it and measure it.Also, you only need one threadlocal if you encapsulate your message digesting behaviour into an object. If you need a local MessageDigest and a local byte[1000] for some purpose, create an object with a messageDigest and a byte[] field and put that object into the ThreadLocal rather than both individually."},
{"body": "I am developing on Eclipse on Windows and Code gets deployed on Unix. I am fething the system property values using System.getProperty(\"key\") ... how do I pass this in Eclipse so that I do not have to modify the code and it works on Eclipse for debugging?Any suggestions?Run -> Run configurations, select project, second tab: \u201cArguments\u201d. Top box is for your program, bottom box is for VM arguments, e.g. .You can use java , for using them from eclipse you could:You can add command line arguments to your run configuration. Just edit the run configuration and add -Dmyprop=value (or whatever) to the VM Arguments Box.run configuration -> arguments -> vm arguments(can also be placed in the debug configuration under Debug Configuration->Arguments->VM Arguments)"},
{"body": "The contract of  with regards to , is as follows:This is rather peculiar, because if  and , then we have:The fact that  is a good thing, because it alerts us of programmer error. And yet, that error would not be catched if for various reasons we just switched it around to , which would just \"silently fail\" instead.So the questions are:In contrast, this is what the  says:If  is appropriate for , why isn't it for ?These are the actual words in the  documentation:And what is an object?My argument from this angle is really simple.To the question of whether this asymmetry is inconsistent, I think not, and I refer you to this ancient Zen k\u014dan:At that moment, the compiler reached enlightenment.An exception really should be an  situation.   A null pointer might not be a programmer error.  You quoted the existing contract.  If you decide to go against convention, after all this time, when every Java developer expects equals to return false, you'll be doing something unexpected and unwelcome that will make your class a pariah.I could't disagree more.  I would not rewrite equals to throw an exception all the time.  I'd replace any class that did that if I were its client.Think of how .equals is related to == and .compareTo is related to the comparison operators >, <, >=, <=.If you're going to argue that using .equals to compare an object to null should throw a NPE, then you'd have to say that this code should throw one as well:The difference between o1.equals(o2) and o2.equals(o1) is that in the first case you're comparing something to null, similar to o1 == o2, while in the second case,  so there's no comparison happening at all.Regarding the .compareTo contract, comparing a non-null object with a null object is like trying do this:Obviously this won't compile.  You can use auto-unboxing to make it compile, but you get a NPE when you do the comparison, which is consistent with the .compareTo contract:Not that this is neccessarily an answer to your question, it is just an example of when I find it useful that the behaviour is how it is now.As it stands I can do.And I have no chance of getting a NullPointerException.  If it were changed as you suggested, I would be back to having to do:Is this a good enough reason for the behaviour to be as it is?? I don't know, but it is a useful side-effect.If you take object oriented concepts into account, and consider the whole sender and receiver roles, I'd say that behaviour is convenient. See in the first case you're asking an object if he is equal to nobody. He SHOULD say \"NO, I'm not\".In the second case though, you don't have a reference to anyone So you aren't really asking anyone. THIS should throw an exception, the first case shouldn't.I think it's only asymmetric if you kind of forget about object orientation and treat the expression as a mathematical equality. However, in this paradigm both ends play different roles, so it is to be expected that order matters.As one final point. A null pointer exception should be raised when there's an error in your code. However, Asking an object if he is nobody, shouldn't be considered a programming flaw. I think it's perfectly ok to ask an object if he isn't null. What if you don't control the source that provides you with the object? and this source sends you null. Would you check if the object is null and only afterwards see if they are equals? Wouldn't it be more intuitive to just compare the two and whatever the second object is the comparison will be carried out without exceptions? In all honesty, I would be pissed if an equals method within its body returns a null pointer exception on purpose. Equals is meant to be used against any sort of object, so it shouldn't be so picky on what it receives. If an equals method returned npe, the last thing on my mind would be that it did that on purpose. Specially considering it's an unchecked exception. IF you did raise an npe a guy would have to remember to always check for null before calling your method, or even worse, surround the call to equals in a try/catch block (God I hate try/catch blocks) But oh well...Personally, I'd rather it perform as it does.The  identifies that the problem is in the object against which the equals operation is being performed.If the  was used as you suggest and you tried the (sort of pointless) operation of... where o1= null...\nIs the  thrown because your comparison function is screwed or because o1 is null but you didn't realise?\nAn extreme example, I know, but with current behaviour I feel you can tell easily where the problem lies. In the first case  returns false because  is not equal to , which is perfectly fine. In the second case, it throws  because  is . One cannot call any method on a . It may be a limitation of programming languages in general, but we have to live with it.It is also not a good idea to throw  you are violating the contract for the  method and making things more complex than it has to be.There are many common situations where  is not in any way exceptional, e.g. it may simply represent the (non-exceptional) case where a key has no value, or otherwise stand for \u201cnothing\u201d. Hence, doing  with an unknown  is also quite common, and having to always check for  first would be just wasted effort.As for why  is different, it  a programming error to call  instance method on a null reference , and therefore worthy of an exception. The ordering of  and  in  should be chosen such that  is known to not be . I would argue that in almost all cases this reordering can be done based on what is known about the objects beforehand (e.g., from their origin, or by checking against  for other method calls).Meanwhile if both objects are of unknown \u201cnullness\u201d, then other code almost certainly requires checking at least one of them, or not much can be done with the object without risking the .And since this is the way it is specified, it is a programming error to break the contract and raise an exception for a  argument to . And if you consider the alternative of requiring an exception to be thrown, then every implementation of  would have to make a special case of it, and every call to  with any potentially  object would have to check before calling.It  have been specified differently (i.e., the precondition of  would require the argument to be non-), so this is not to say that your argumentation is invalid, but the current specification makes for a simpler and more practical programming language.Note that the contract is \"for any non-null reference x\". So the implementation will look like: need not be  to be deemed equal to  because the following definition of  is possible:I think it's about convenience and more importantly consistency - allowing nulls to be part of the comparison avoids having to do a  check and implement the semantics of that each time  is called.  references are legal in many collection types, so it makes sense they can appear as the right side of the comparison. Using instance methods for equality, comparison etc., necessarily makes the arrangement asymmetric - a little hassle for the huge gain of polymorphism. When I don't need polymorphism, I sometimes create a symmetric static method with two arguments, . This method then checks whether one or both arguments are null references. If I specifically want to exclude null references, then I create an additional method e.g.  or similar, that does a null check before delegating to the other method.This is a tricky question. For backward compatability you can't do so.Imagine the following scenarioNow with equals returning false else clause will get executed, but not when throwing an exception.Also null is not really equal to say \"2\" so it makes perfect sense to return false. Then it is probably better to insist null.equals(\"b\") to return also false :))But this requirement does make a strange and non symmetric equals relation."},
{"body": "Consider the following code:The program's output is:When I run from the shell, of course, it works as expected:The internets tell me that, due to the fact that pipe behavior isn't cross-platform, the brilliant minds who work in the Java factory producing Java can't guarantee that pipes work.How can I do this?I am not going to do all of my parsing using Java constructs rather than  and , because if I want to change the language, I'll be forced to re-write my parsing code in that language, which is totally a no-go.How can I make Java do piping and redirection when calling shell commands?Write a script, and execute the script instead of separate commands.Pipe is a part of the shell, so you can also do something like this:I ran into a similar problem in Linux, except it was \"ps -ef | grep someprocess\".\nAt least with \"ls\" you have a language-independent (albeit slower) Java replacement.  Eg.:With \"ps\", it's a bit harder, because Java doesn't seem to have an API for it.I've heard that Sigar might be able to help us:\nThe simplest solution, however, (as pointed out by Kaj) is to execute the piped command as a string array.  Here is the full code:As to why the String array works with pipe, while a single string does not... it's one of the mysteries of the universe (especially if you haven't read the source code).  I suspect that it's because when exec is given a single string, it parses it first (in a way that we don't like).  In contrast, when exec is given a string array, it simply passes it on to the operating system without parsing it.Actually, if we take time out of busy day and look at the source code\n(at ), we find that is exactly what is happening:Create a Runtime to run each of the process. Get the OutputStream from the first Runtime and copy it into the InputStream from the second one."},
{"body": "My questions is: Is there a good solution to use regular expression in GWT?I'm not satisfied with the use of String.split(regex) for example. GWT translates the Code to JS and then uses the regex as a JS regex. But I cannot use something like the Java Matcher or Java Pattern. But I would need these for group matching.Is there any possibility or library?I tried Jakarta Regexp, but I had other problems because GWT doesn't emulate all methods of the Java SDK this library uses. I want to be able to use something like this on the client side:The same code using RegExp could be:GWT 2.1 now has a  class that might solve your problem:This answer covers ALL pattern matches, not only one, as in other answers here:Function:...and sample use:If you want a pure GWT solution, I'm not sure it can be done. But if you're willing to use JSNI, you can use JavaScript's RegExp object to get the matched groups and all. You'll need to learn JSNI for GWT and JavaScript RegExp object.The  seems to provide an emulation of java.util.regex.Pattern and friends.\nIt doesn't look complete (Matcher in particular), but might be a good start.The technique they use to plug their own implementations of Java classes for the client side is the  declaration in module XML. It's mentioned in GWT docs, module XML format description under \"Overriding one package implementation with another\". Standard JRE translatable classes in GWT are emulated the same way."},
{"body": "How do I lock compiled Java classes to prevent decompilation?I know this must be very well discussed topic on the Internet, but I could not come to any conclusion after referring them.Many people do suggest obfuscator, but they just do renaming of classes, methods, and fields with tough-to-remember character sequences but what about sensitive constant values?For example, you have developed the encryption and decryption component based on a password based encryption technique. Now in this case, any average Java person can use  to decompile the class file and easily retrieve the password value (defined as constant) as well as  and in turn can decrypt the data by writing small independent program!Or should such sensitive components be built in native code (for example, VC++) and call them via ?Some of the more advanced Java bytecode obfuscators do much more than just class name mangling. , for example, can also scramble your code flow in a way that makes it really hard to follow and works as an excellent code optimizer...Also many of the obfuscators are also able to scramble your string constants and remove unused code.Another possible solution (not necessarily excluding the obfuscation) is to use  and a custom classloader that does the decryption (preferably using native runtime library).Third (and possibly offering the strongest protection) is to use native ahead of time compilers like  or , for example, that compile your Java code directly to a platform specific native binary.In any case You've got to remember that as the saying goes in Estonian \"Locks are for animals\". Meaning that every bit of code is available (loaded into memory) during the runtime and given enough skill, determination and motivation, people can and will decompile, unscramble and hack your code... Your job is simply to make the process as uncomfortable as you can and still keep the thing working...As long as they have access to both the encrypted data and the software that decrypts it, there is basically no way you can make this completely secure. Ways this has been solved before is to use some form of external black box to handle encryption/decryption, like dongles, remote authentication servers, etc. But even then, given that the user has full access to their own system, this only makes things difficult, not impossible -unless you can tie your product directly to the functionality stored in the \"black box\", as, say, online gaming servers.Disclaimer: I am not a security expert.This sounds like a bad idea: You are letting someone encrypt stuff with a 'hidden' key that you give him. I don't think this can be made secure.Maybe asymmetrical keys could work:I'm not sure, but I believe the client can actually encrypt the license key with the public key you gave him. You can then decrypt it with your private key and re-encrypt as well.You could keep a separate public/private key pair per customer to make sure you actually are getting stuff from the right customer - now  are responsible for the keys...No matter what you do, it can be 'decompiled'. Heck, you can just disassemble it. Or look at a memory dump to find your constants. You see, the computer needs to know them, so your code will need to too.What to do about this?Try not to ship the key as a hardcoded constant in your code: Keep it as a per-user setting. Make the user responsible for looking after that key.Take a look at the  article  by Vladimir Roubtsov. It explains why encryption of class files is mostly pointless.@jatanp: or better yet, they can decompile, remove the licensing code, and recompile.  With Java, I don't really think there is a proper, hack-proof solution to this problem.  Not even an evil little dongle could prevent this with Java.My own biz managers worry about this, and I think too much.  But then again, we sell our application into large corporates who tend to abide by licensing conditions--generally a safe environment thanks to the bean counters and lawyers.  The act of decompiling itself can be illegal if your license is written correctly. So, I have to ask, do you  need hardened protection like you are seeking for your application?  What does your customer base look like?  (Corporates?  Or the teenage gamer masses, where this would be more of an issue?)I don't think there exists any effective offline antipiracy method. The videogame industry has tried to find that many times and their programs has always been cracked. The only solution is that the program must be run online connected with your servers, so that you can verify the lincense key, and that there is only one active connecion by the licensee at a time. This is how  or  works. Even tough there are private servers developed for them to bypass the security. Having said that, I don't believe that mid/large corporations use illegal copied software, because the cost of the license for them is minimal (perhaps, I don't know how much you are goig to charge for your program) compared to the cost of a trial version.If you're looking for a licensing solution, you can check out the . It's based on the use of asymmetrical keys. However, it doesn't mean your application cannot be cracked. Every application can be cracked with enough effort. What really important is, as , figuring out how strong protection you need. You can use byte-code encryption with no fear. The fact is that the cited above paper \u201cCracking Java byte-code encryption\u201d contains a logic fallacy. The main claim of the paper is . But this is not true. The assumption missed here is . Nothing can oblige the protected java app not only to launch these classes but even decrypt and pass them to . In other words, if you are in standard JRE you can't intercept  method because the standard java has no API for this purpose, and if you use modified JRE with patched  or any other \u201chacker trick\u201d you can't do it because protected java app will not work at all, and therefore you will have nothing to intercept. And absolutely doesn't matter which \u201cpatch finder\u201d is used or which trick is used by hackers. These technical details are a quite different story. Q: If I encrypt my .class files and use a custom classloader to load and decrypt them on the fly, will this prevent decompilation?A: The problem of preventing Java byte-code decompilation is almost as old the language itself. Despite a range of obfuscation tools available on the market, novice Java programmers continue to think of new and clever ways to protect their intellectual property. In this Java Q&A installment, I dispel some myths around an idea frequently rehashed in discussion forums.The extreme ease with which Java .class files can be reconstructed into Java sources that closely resemble the originals has a lot to do with Java byte-code design goals and trade-offs. Among other things, Java byte code was designed for compactness, platform independence, network mobility, and ease of analysis by byte-code interpreters and JIT (just-in-time)/HotSpot dynamic compilers. Arguably, the compiled .class files express the programmer's intent so clearly they could be easier to analyze than the original source code.Several things can be done, if not to prevent decompilation completely, at least to make it more difficult. For example, as a post-compilation step you could massage the .class data to make the byte code either harder to read when decompiled or harder to decompile into valid Java code (or both). Techniques like performing extreme method name overloading work well for the former, and manipulating control flow to create control structures not possible to represent through Java syntax work well for the latter. The more successful commercial obfuscators use a mix of these and other techniques.Unfortunately, both approaches must actually change the code the JVM will run, and many users are afraid (rightfully so) that this transformation may add new bugs to their applications. Furthermore, method and field renaming can cause reflection calls to stop working. Changing actual class and package names can break several other Java APIs (JNDI (Java Naming and Directory Interface), URL providers, etc.). In addition to altered names, if the association between class byte-code offsets and source line numbers is altered, recovering the original exception stack traces could become difficult.Then there is the option of obfuscating the original Java source code. But fundamentally this causes a similar set of problems.\nEncrypt, not obfuscate?Perhaps the above has made you think, \"Well, what if instead of manipulating byte code I encrypt all my classes after compilation and decrypt them on the fly inside the JVM (which can be done with a custom classloader)? Then the JVM executes my original byte code and yet there is nothing to decompile or reverse engineer, right?\"Unfortunately, you would be wrong, both in thinking that you were the first to come up with this idea and in thinking that it actually works. And the reason has nothing to do with the strength of your encryption scheme."},
{"body": "I noticed some unexpected behavior (unexpected relative to my personal expectations), and I'm wondering if something if there is a bug in the JVM or if perhaps this is a fringe case where I don't understand some of the details of what exactly is supposed to happen.  Suppose we had the following code in a main method by itself:A naive expectation would be that this would print , the largest even representable .  However, I believe integer arithmetic is supposed to \"rollover\" in Java, so adding 1 to  should result in .  Since  is still less than , the loop would keep iterating through the negative even ints.  Eventually it would get back to 0, and this process should repeat as an infinite loop.When I actually run this code, I get non-deterministic results.  The result that gets printed tends to be on the order of half a million, but the exact value varies.  So not only is the loop terminating when I believe it should be an infinite loop, but it seems to terminate randomly.  What's going on?My guess is that this is either a bug in the JVM, or there is a lot of funky optimization going on that makes this expected behavior.  Which is it?Known bug. Related toand others.I think they're considered low-priority to fix because they don't come up in the real world.This is bizarre. It certainly looks like a bug somewhere. I get the same results every time with the same code, but trivial changes to the code change the result. For example:... always prints 2147483640 and truewhereas this:always prints -2147483648 and true.Very, very weird.(That's running an OpenJDK 1.6 VM on Linux.)EDIT: Running OpenJDK 1.7 on Windows 7, I don't see the problem:Try adding I wonder if there is optimization occurring because count is never read from. - another answer gave the link to bugs in Oracle's bug tracker. Drawing from that:However, this is unlikely to occur in practice, because:This seems to be a loop optimizations as I observe the same result but IF I also print out  then the result changes.I.e.Produces 2147483638 while the original code produces 457158 (or similar)"},
{"body": "When  is a , is  guaranteed to be , or might it sometimes be  (depending on the sign of )? can be  or . There are no other values it can take in IEEE 754 arithmetics in round-to-nearest (and in Java, the rounding mode is ). The subtraction of two identical finite values is  as producing  in this rounding mode. , in comments below, cites the IEEE 754 standard as saying, section 6.3:This  shows that in particular  and  are both .Infinities and NaN both produce NaN when subtracted from themselves.The SMT solver Z3 supports IEEE floating point arithmetic. Let's ask Z3 to find a case where . It immediately finds  as well as . Excluding those, there is no  that satisfies that equation.Z3 implements IEEE floating point arithmetic by converting all operations to boolean circuits and using the standard SAT solver to find a model. Barring any bugs in that translation or the SAT solver the result is perfectly precise.Proof for...Note the counterexample for the rounding mode : . For a certain  the result of  is negative zero. Such a case can hardly be found by humans. Yet, with an SMT solver it is easy to find. We can change  to  so that Z3 uses IEEE equality comparison semantics instead of exact equality. After that change, there is again no counter-example because  according to IEEE.I tried making the rounding mode a variable. That would work in theory but Z3 has a bug here. For now we have to manually specify a hard-coded rounding mode. If we could make it a variable we could ask Z3 to prove this statement for  rounding modes in one query."},
{"body": "What does \"\" do in Eclipse?  It syncs the Eclipse project settings with that of the pom. If you for example change important plugin settings, such as the output java version, you will find that Eclipse will ask you to update the project and afterwards the configured Java runtime in the project will have changed to reflect what your Maven pom indicates.That is an important thing to keep in mind: the Maven pom is the lead in this kind of project setup. If you want settings to change, try to do that through the pom and not through Eclipse project settings directly or doing a project update might revert what you have changed. There are usually some things I have to correct myself anyway though, such as build path exclusions that m2eclipse likes to put in and strange deployment assembly configurations.To add on to what @Gimby said - Update Project also provides more options such as  which is extremely helpful when you have dependencies that are looking for the latest. (e.g.:   will find 1.0.* - whatever's the latest.)Updating project is synonymous with Ivy's Resolve.  It will make sure that all referenced dependencies are there, as well as clean the project to make sure that they are included correctly."},
{"body": "How deep do I need to go into the call stack before I get a StackOverflowError? Is the answer platform dependent?It depends on the amount of virtual memory allocated to the stack.  You can tune this with the  VM parameter or with the  constructor.The stack size can be set with the  command line switch but as a rule of thumb, it is deep enough, hundreds if not thousands of calls deep. (The default is platform dependent, but at least 256k in most platforms.)If you get a stack overflow, 99% of the time it's caused by an error in the code.I tested on my system and didn't find any constant value, sometimes stack overflow occurs after 8900 calls, sometimes only after 7700, random numbers.Compare these two calls:\n(1) Static method:(2) Non-static method using a different class:Test recursion class has  as the only method."},
{"body": "A new feature coming in JDK 8 allows you to add to an existing interface while preserving binary compatibility.The syntax is likeThis way for all existing implementations of  when they upgrade to this new version they don't all suddenly have compiles errors around .While this is neat, what happens when you are implementing two interfaces which both have added a new defaulted method which you did not implement?  Let me explain with an example.Has this been defined as part of JDK 8 yet?I found the Java gods talking about something similar here , but its part of private mailing list and I cannot ask them directly.See this for more details on how defaults are going to be used in JDK 8 and extending the Collection interface to support lambdas:\nThe video session to watch is here  This is the designer talking about the feature called Virtual Extensions. He also talks about how this doesn't break backward compatibility.The answer to the duplicate operation is:My answer to your question is: Yes, it is a form of multiple inheritance, because you can inherit behavior from different parents. What's missing is to inherit states, i. e., attributes.I know this is a old post, but as i'm working with this stuff...You will have an error from the compiler, telling you that:Yes, but you can add getters and setters to your interface that the implementing classes then must implement. Nevertheless, the implementing classes don't inherit attributes. So, AFAICS, it's more like a trait-style solution rather than a multiple inheritance style solution. If anyone's still looking for an answer, in case a class implements two interfaces with the same default method then the class needs to resolve the disambiguity by providing an implementation of its own. Look at  tutorial for more details on how inheritance in default methods work.In short: it's a compile time error, must over the method by hand in the implementation.The major purpose to introduce default method in Java 8, is to make interface extendable, without breaking existing implementations (there are so many 3rd party Java libraries).And  like in C++ is actually intended to be avoided, that's definitely not the purpose of default method in Java.2 options:Tips:There are  scenarios:1) First, that was mentioned, where there is 2) Second, when there As far as I see it, it is no multiple inheritance because they are stateless.\nSo virtual extension methods don't support full object or class functionality. "},
{"body": "I have a class that takes objects from a  and processes them by calling  in a continuous loop.  At some point I know that no more objects will be added to the queue.  How do I interrupt the  method so that it stops blocking?Here's the class that processes the objects:And here's the method that uses this class to process objects:If interrupting the thread is not an option, another is to place a \"marker\" or \"command\" object on the queue that would be recognized as such by MyObjHandler and break out of the loop.However, if you do this, the thread might be interrupted while there are still items in the queue, waiting to be processed. You might want to consider using  instead of , which will allow the processing thread to timeout and terminate when it has waited for a while with no new input. I faced the similar problem and used the  approach suggested by  with some minor changes,  Interrupt the thread:Or don't interrupt, its nasty."},
{"body": "I want to access messages in GMail from a Java application using JavaMail and IMAP. Why am I getting a  ?Here is my code:I set the timeout values so that it wouldn't take \"forever\" to timeout. Also,  also has the username and password, which seems redundant with the URL. Is there another way to specify the protocol? (I didn't see it in the JavaDoc for IMAP.)Using imaps was a great suggestion. Neither of the answers provided just worked for me, so I googled some more and found something that worked. Here's how my code looks now.This is nice because it takes the redundant Authenticator out of the picture. I'm glad this worked because the SSLNOTES.txt make my head spin.In JavaMail, you can use  as the URL scheme to use IMAP over SSL. (See  in your JavaMail distribution for more details.) For example, .Similarly, use  to send emails via Gmail. e.g., . Again, read  for more details. Hope it helps!You need to use the following properties for imaps:Notices it's \"imaps\", not \"imap\", since the protocol you're using is imaps (IMAP + SSL)You have to connect to GMail using SSL only. Setting the following properties will force that for you. If you'd like more sample code on using JavaMail with Gmail (e.g. converting Gmail labels to IMAP folder names, or using IMAP IDLE), do check out my program  on .Check . There is a minimal gmail client built using this API.I used following properties to get the store and It works well.Here is what worked for my team and I, given a classic account nickname@gmail.com and a business account employee@business.com :with USERNAME = \"nickname\" in the classic case, and USERNAME = \"employee@business.com\" in the business account case.In the classic case, and if you use an old JavaMail dependency, don't forget to lower the account security here : In both cases check in GMail  if IMAP is enabled for the account.Hope it helps!To go further :You need to have JSSE installed to use SSL with Java"},
{"body": "This is the code I have:And the tests I have, which I run .When I run test  I will see:But when I run the test  all I see is:Quoting from  page..So my understanding is, in test bar, Stupid class is loaded, otherwise I would have seen a null I guess? So Class object is created because class itself is loaded..And now quoting from  page  So I am expecting to see the \"Stupid class loaded!\" text in test bar as well, but I am not.Also quoting from which is not very accurate it seems..What am I missing?The above quote is plain wrong, but it is just one instance of a very widespread misconception. initializes the class by default, but you have the choice of calling an overload that takes a  and supplying . You'll get the class loaded without initializing.In the first case you are loading and initializing a class when you use , that's why the static initializers are run and hence you see  as output . In the second case, you are just assigning a reference of the class,  (use java -verbose:class to see what classes are loaded) but you aren't really initializing it (or to be more precise, not doing anything that forces the initializers to run). Thus you don't see the output as . Try doing something like calling  on the class, it should force the  initialization of the class and you should see My code : ^ - This shows that the class is loaded but not initialized."},
{"body": "Is it correct practice to add Javadoc comments in Interface and add non Javadoc comments in the implementation?Most IDEs generate non JavaDoc comments for implementations when you auto generate comments. Shouldn't the concrete method have the description?For methods that are implementation only (not overrides), sure, why not, especially if they are public.If you have an overriding situation and you are going to replicate any text, then definitely not. Replication is a surefire way of causing discrepancies. As a result, users would have a different understanding of your method based on whether they examine the method in the supertype or the subtype. Use  or don't provide a documentation - The IDEs will take the lowest available text to use in their Javadoc view. As an aside, if your overriding version adds stuff to the documentation of the supertype, you could be in a world of trouble. I studied this problem during my PhD and found that in general folks will never be aware of the extra information in the overriding version if they are invoking through a supertype. Addressing this problem was one of the major feature of the prototype tool that I built - Whenever you invoked a method, you got an indication if its target or any potential overriding targets contained important information (e.g., a conflicting behavior). For instance, when invoking put on a map, you were reminded that if your implementation is a TreeMap, your elements need to be comparable.Both the implementation and the interface should have javadoc. With some tools, you can inherit the documentation of the interface with the @inheritDoc keyword.Somewhat good practice is to putas implementation's javadoc (unless there's something extra to be explained about the implementation's details).@see generates a link to the description in the interface. But i think it is good to add some details about the implementation too.Sjoerd correctly says that both interface and implementation should have JavaDoc. The interface JavaDoc should define the contract of the method - what the method should do, what inputs it takes, what values it should return, and what it should do in cases of error.The implementation documentation should note extensions or restrictions on the contract, and also appropriate details of the implementation, especially performance. Generally, when you override a method, you adhere to the contract defined in the base class/interface, so you don't want to change the original javadoc anyhow. Therefore the usage of  or  tag mentioned in other answers is not needed and actually only serves as a noise in the code. All sensible tools inherit method javadoc from the superclass or interface as specified :The fact that some tools (I'm looking at you, Eclipse!) generate these by default when overriding a method is only a sad state of things, but doesn't justify cluttering your code with useless noise.There can of course be the opposite case, when you actually want to add a comment to the overriding method (usually some additional implementation details or making the contract a bit stricter). But in this case, you almost never want to do something like this:Why? Because the inherited comment can possibly be very long. In such case, who will notice the extra sentence at the end of the 3 long paragraphs?? Instead, just write down the piece of your own comment and that's all. All the javadoc tools always show some kind of  link which you can click to read the base class comment. There is no point in mixing them.For the sake of generated javadoc yes it does matter. If you declare references to a concrete implementation using only the interface then it doesn't since interface's methods will be retrieved by the IDE."},
{"body": "I have a program like this:If I try to execute it, i am getting compiler error as :  based on java default values i should get the below output right??Will final variables have dafault values?if I change my code like this,I am getting output as:Can anyone please explain this behavior.., chapter \"Initializing Instance Members\":That is to say:behaves exactly like:As you can thus see, once an instance has been created, the final field has not been , while (from ):While it does not seem to be stated explitely in the docs (at least I have not been able to find it), a final field must temporary take its default value before the end of the constructor, so that it has a  if you read it before its assignment.Default values: On your second snippet, x is initialized on instance creation, so the compiler does not complain:Also note that the following approach doesn't work. Using default value of final variable is only allowed through a method. is  that you  assign the default value to blank final instance variable in constructor (or in  which is pretty the same). That is why you get the error in the first case. However it doesn't say that you can not access it in constructor before. Looks weird a little bit, but you can access it before assignment and see default value for int - 0.    As mentioned by @I4mpi,   the rule that each value should be  before any access:However, it also has an  in regards to constructors and fields:So in second case the value  is  at the beginning of the constructor, because it contains the assignment at the end of it. If you don't initialize  you'll get a compile-time error since  is never initialized. Declaring  as final means that it can be initialized only in the constructor or in  (since this block will be copied by the compiler into every constructor). The reason that you get  printed out before the variable is initialized is due to the behavior  defined in the  (see: \"Default Values\" section):The first error is the compiler complaining that you have a final field, but no code to initialize it - simple enough.In the second example, you have code to assign it a value, but the sequence of execution means you reference the field both before and after assigning it.The pre-assigned value of any field is the default value.All non-final fields of a class initialize to a default value ( for nummeric data types,  for boolean and  for reference types, sometimes called complex objects). These fields initialize before a constructor (or instance initialization block) executes independent of whether or not the fields was declared before or after the constructor. fields of a class has  and must be explicitly initialized just once before a class constructor has finished his job.Local variables on the inside of an execution block (for example, a method) has no default value. These fields must be explicitly initialized before their first use and it doesn't matter whether or not the local variable is marked as final.Let me put it in the simplest words I can. variables need to be initialized, this is mandated by the Language Specification.\nHaving said that, please note that it is not necessary to initialize it at the time of declaration. It is required to initialize that before the object is initialized.We can use initializer blocks to initialize the final variables. Now, initializer blocks are of two types\n and The block you used is a non-static initializer block. So, when you create an object, Runtime will invoke constructor and which in turn will invoke the constructor of the parent class.After that, it will invoke all the initializers (in your case the non-static initializer). In your question, : Even after the completion of initializer block the final variable remains un-initialized, which is an error compiler will detect.In : The initializer will initialize the final variable, hence the compiler knows that before the object is initialized, the final is already initialized. Hence, it will not complain.Now the question is, why does  takes a zero. The reason here is that compiler already knows that there is no error and so upon invocation of init method all the finals will be initialized to defaults, and a flag set that they can change upon actual assignment statement similar to .\nSee the init invocation below:As far as I'm aware, the compiler will always initialize class variables to default values (even final variables). For example, if you were to initialize an int to itself, the int would be set to its default of 0. See below:The above would print the following:No. You are not seeing that output because you are getting a compile-time error in the first place. Final variables do get a default value, but the Java Language Specification (JLS) requires you to initialize them by the end of the constructor (LE: I'm including initialization blocks here), otherwise you'll get a compile-time error which will prevent your code to be compiled and executed. Your second example respects the requirement, that's why (1) your code compiles and (2) you get the expected behaviour. In the future try to familiarize yourself with the JLS. There's no better source of information about the Java language."},
{"body": "Looking at the last JUnit test case I wrote, I called log4j's BasicConfigurator.configure() method inside the class constructor.  That worked fine for running just that single class from Eclipse's \"run as JUnit test case\" command.  But I realize it's incorrect: I'm pretty sure our main test suite runs all of these classes from one process, and therefore log4j configuration should be happening higher up somewhere.But I still need to run a test case by itself some times, in which case I want log4j configured.  Where should I put the configuration call so that it gets run when the test case runs standalone, but not when the test case is run as part of a larger suite?The  class determines which log4j config to use in a  which runs when the class is loaded.  There are three options intended for end-users:See also the .I generally just put a log4j.xml file into src/test/resources and let log4j find it by itself: no code required, the default log4j initialisation will pick it up. (I typically want to set my own loggers to 'DEBUG' anyway)You may want to look into to . It is a facade that wraps around Log4j that doesn't require an initial setup call like Log4j. It is also fairly easy to switch out Log4j for Slf4j as the API differences are minimal.I use system properties in log4j.xml:and start tests with:"},
{"body": "I noticed in the Java 6 source code for String that hashCode only caches values other than 0. The difference in performance is exhibited by the following snippet: gives the following output:So my questions are:For your amusement, each line here is a string that hash to 0:You're worrying about nothing.  Here's a way to think about this issue.Suppose you have an application that does nothing but sit around hashing Strings all year long.  Let's say it takes a thousand strings, all in memory, calls hashCode() on them repeatedly in round-robin fashion, a million times through, then gets another thousand new strings and does it again.And suppose that the likelihood of a string's hash code being zero were, in fact, much greater than 1/2^32.  I'm sure it is  greater than 1/2^32, but let's say it's a lot worse than that, like 1/2^16 (the square root! now that's a lot worse!).In this situation, you have more to benefit from Oracle's engineers improving how these strings' hash codes are cached than anyone else alive. So you write to them and ask them to fix it. And they work their magic so that whenever s.hashCode() is zero, it returns  (even the first time! a 100% improvement!). And let's say that they do this without degrading the performance at all for any other case.Hooray!  Now your app is... let's see... 0.0015% faster!What used to take an entire day now takes only 23 hours, 57 minutes and 48 seconds!And remember, we set up the scenario to give every possible benefit of the doubt, often to a ludicrous degree.Does this seem worth it to you? since posting this a couple hours ago, I've let one of my processors run wild looking for two-word phrases with zero hash codes. So far it's come up with: bequirtle zorillo, chronogrammic schtoff, contusive cloisterlike, creashaks organzine, drumwood boulderhead, electroanalytic exercisable, and favosely nonconstruable. This is out of about 2^35 possibilities, so with perfect distribution we'd expect to see only 8. Clearly by the time it's done we'll have a few times that many, but not outlandishly more. What's more significant is that I've now come up with a few interesting band names/album names!  No fair stealing!It uses 0 to indicate \"I haven't worked out the hashcode yet\". The alternative would be to use a separate Boolean flag, which would take more memory. (Or to not cache the hashcode at all, of course.)I don't expect  strings hash to 0; arguably it would make sense for the hashing routine to deliberately avoid 0 (e.g. translate a hash of 0 to 1, and cache that). That would increase collisions but avoid rehashing. It's too late to do that now though, as the String hashCode algorithm is explicitly documented.As for whether this is a good idea in general: it's an certainly efficient caching mechanism, and  (see edit) be even better with a change to avoid rehashing values which end up with a hash of 0. Personally I would be interested to see the data which led Sun to believe this was worth doing in the first place - it's taking up an extra 4 bytes for every string ever created, however often or rarely it's hashed, and the only benefit is for strings which are hashed .EDIT: As KevinB points out in a comment elsewhere, the \"avoid 0\" suggestion above may well have a net  because it helps a  case, but requires an extra comparison for  hash calculation.I think there's something important that the other answers so far are missing: the zero value exists so that the hashCode-caching mechanism works robustly in a multi-threaded environment.If you had two variables, like cachedHashCode itself and an isHashCodeCalculated boolean to indicate whether cachedHashCode had been calculated, you'd need thread synchronization for things to work in a multithreaded environment.  And synchronization would be bad for performance, especially since Strings are very commonly reused in multiple threads.My understanding of the Java memory model is a little sketchy, but here's roughly what's going on:The hashCode caching mechanism in java.lang.String is set up to rely on point 5 above.  You might understand it better by looking at the source of java.lang.String.hashCode().  Basically, with multiple threads calling hashCode at once, hashCode might end up being calculated multiple times (either if the calculated value is zero or if multiple threads call hashCode at once and both see a zero cached value), but you can be sure that hashCode() will always return the same value.  So it's robust, and it's performant too (because there's no synchronization to act as a bottleneck in multi-threaded environments).Like I said, my understanding of the Java memory model is a little sketchy, but I'm pretty sure I've got the gist of the above right.  Ultimately it's a very clever idiom for caching the hashCode without the overhead of synchronization.0 isn't cached as the implementation interprets a cached value of 0 as \"cached value not yet initialised\".  The alternative would have been to use a , whereby null implied that the value was not yet cached.  However, this would have meant an additional storage overhead.Regarding the probability of a String's hash code being computed as 0 I would say the probability is quite low and can happen in the following cases:From :This turns out to be a good question, related to a .The value zero is reserved as meaning \"the hash code is not cached\".According to the Javadoc, the formula for a String's hashcode is:using  arithmetic, where  is the ith character of the string and  is the length of the string.  (The hash of the empty String is defined to be zero as a special case.)My intuition is that the hashcode function as above gives a uniform spread of String hash values across the range of  values.  A uniform spread that would mean that the probability of a randomly generated String hashing to zero was 1 in 2^32.The best strategy is to ignore the issue.  If you are repeatedly hashing the same String value, there is something rather strange about your algorithm.This is a space versus time trade-off.  AFAIK, the alternatives are:I think that the Java designers have made the right call for Strings, and I'm sure that they have done extensive profiling that confirms the soundness of their decision.  However, it  follow that this would  be the best way to deal with caching.(Note that there are two \"common\" String values which hash to zero; the empty String, and the String consisting of just a NUL character.  However, the cost of calculating the hashcodes for these values is small compared with the cost of calculating the hashcode for a typical String value.)Well folks, it keeps 0 because if it is zero length, it will end up as zero anyways.And it doesn't take long to figure out that the len is zero and so must the hashcode be.So, for your code-reviewz! Here it is in all it's Java 8 glory:As you can see, this will always return a quick zero if the string is empty:The \"avoid 0\" suggestion seems appropriate to recommend as best practice as it helps a genuine problem (seriously unexpected performance degradation in constructible cases that can be attacker supplied) for the meager cost of a branch operation prior to a write. There is some remaining 'unexpected performance degradation' that can be exercised if the only things going into a set hash to the special adjusted value. But this is at worst a 2x degradation rather than unbounded.Of course, String's implementation can't be changed but there is no need to perpetuate the problem."},
{"body": "Given a stream such as , how can I most elegantly transform it into given form: (assuming, of course, I've defined class Pair)? This isn't strictly about ints or primitive streams. The answer should be general for a stream of any type.My  library which extends standard streams provides a  method for all stream types. For primitive streams it does not change the stream type, but can be used to make some calculations. Most common usage is to calculate differences:For object stream you can create any other object type. My library does not provide any new user-visible data structures like  (that's the part of library concept). However if you have your own  class and want to use it, you can do the following:Or if you already have some :This functionality is implemented using . It has quite low overhead and can parallelize nicely. Of course it works with any stream source, not just random access list/array like many other solutions. In many tests it performs really well.  a JMH benchmark where we find all input values preceding a larger value using different approaches (see  question).The Java 8 streams library is primarily geared toward splitting streams into smaller chunks for parallel processing, so stateful pipeline stages are quite limited, and doing things like getting the index of the current stream element and accessing adjacent stream elements are not supported.A typical way to solve these problems, with some limitations, of course, is to drive the stream by indexes and rely on having the values being processed in some random-access data structure like an ArrayList from which the elements can be retrieved. If the values were in , one could generate the pairs as requested by doing something like this:Of course the limitation is that the input cannot be an infinite stream. This pipeline can be run in parallel, though.There is not elegant, it's a hackish solution, but works for infinite streamsNow you can limit your stream as long as you want I hope there is better solution, something like clojure I've implemented a spliterator wrapper which takes every  elements  from the original spliterator and produces :Following method may be used to create a consecutive stream:Sample usage:You can do this in  (I contribute to this library), using the sliding operator.Or Assuming the Pair constructor can accept a Collection with 2 elements. If you wanted to group by 4, and increment by 2 that is also supported.Equivalant static methods for creating a sliding view over java.util.stream.Stream are also provided in cyclops-streams  class.Note :- for single-threaded operation ReactiveSeq would be more appropriate. LazyFutureStream extends ReactiveSeq but is primarily geared for concurrent / parallel use (it is a Stream of Futures).LazyFutureStream extends ReactiveSeq which extends Seq from the awesome jOO\u03bb (which extends java.util.stream.Stream), so the solutions Lukas' presents would also work with either Stream type. For anyone interested the primary differences between the window / sliding operators are the obvious  relative power / complexity trade off and suitability for use with infinite streams (sliding doesn't consume the stream, but buffers as it flows). The  provides the windowed functionnality. Given a Pair class and a Stream, you can do it like this:Now the  stream contains:If you're willing to use a third party library and don't need parallelism, then  offers SQL-style window functions as followsYieldingThe  function accesses the next value in traversal order from the window.A question in the comments was asking for a more general solution, where not pairs but n-tuples (or possibly lists) should be collected. Here's thus an alternative approach:Yielding a list of listsWithout the , the result would beDisclaimer: I work for the company behind jOO\u03bbWe can use  (very powerful  library)You can do this with the Stream.reduce() method (I haven't seen any other answers using this technique).In your case, I would write my custom IntFunction which keeps track of the last int passed and use that to map the original IntStream.The operation is essentially stateful so not really what streams are meant to solve - see the \"Stateless Behaviors\" section in the :One solution here is to introduce state in your stream through an external counter, although it will only work with a sequential stream.An elegant solution would be to use . Something like:This is pretty concise and elegant, however it uses a list as an input. An infinite stream source cannot be processed this way.Another (lot more troublesome) issue is that zip together with the entire Streams class has been lately removed from the API. The above code only works with  or older releases. So with the latest JDK I would say there is no elegant FP style solution and right now we can just hope that in some way zip will be reintroduced to the API.This is an interesting problem. Is my  attempt below any good?I believe it does not lend itself to parallel processing, and hence may be disqualified. As others have observed, there is, due to the nature of the problem, some statefulness required.I was faced with a similar problem, in which I wanted what was essentially the Oracle SQL function LEAD. My attempt to implement that is below.You can achieve that by using a bounded queue to store elements which flows through the stream (which is basing on the idea which I described in detail here: )Belows example first defines instance of BoundedQueue class which will store elements going through the stream (if you don't like idea of extending the LinkedList, refer to link mentioned above for alternative and more generic approach). Later you just combine two subsequent elements into instance of Pair:I agree with @aepurniet\nbut instead map you have to use mapToObjRun a  loop that runs from 0 to  of your stream"},
{"body": "I have read \"\" but I'm still confused. How do I know when I should mark a variable volatile? What if I get it wrong, either omitting a volatile on something that needs it or putting volatile on something that doesn't? What are the rules of thumb when figuring out what variables should be volatile in multithreaded code?You basically use it when you want to let a member variable be accessed by multiple threads but do not need compound atomicity (not sure if this is the right terminology).the above is a bad example, because you  compound atomicity.Now to a valid example:Now, why can't you just use ? In fact you can (in the sense that that your program won't blow up or something), but the change to  by the other thread may or may not be \"visible\" to the main thread.  Basically this means that it is even possible that your app. keeps writing  forever if you  use  (in practice, the value tends to become eventually visible. However, you should not risk not using volatile when necessary, since it can lead to nasty bugs (caused by in-completely constructed objects etc.).If you put  keyword on something that doesn't need , it won't affect your code's correctness (i.e. the behaviour will not change). In terms of performance, it will depend on the JVM implementation. In theory you might get a tiny performance degradation because the compiler can't do reordering optimisations, have to invalidate CPU cache etc., but then again the compiler could prove that your field cannot ever be accessed by multiple threads and remove the effect of  keyword completely and compile it to identical instructions.  \nResponse to this comment:  You can and it will behave correctly. Anything that you can with  can be done with , but not vice versa. There are two reasons you might prefer  if you can:  Volatile is most useful in lock-free algorithms. You mark the variable holding shared data as volatile when you are not using locking to access that variable and you want changes made by one thread to be visible in another, or you want to create a \"happens-after\" relation to ensure that computation is not re-ordered, again, to ensure changes become visible at the appropriate time.The  describes which operations can be re-ordered and which cannot.The  can also be used to safely publish immutable objects in a multi-threaded Environment.Declaring a field like  secures that all threads always see the currently available instance reference.See  for more on that topic.Actually disagree with the example given in the top voted answer, to my knowledge it does  properly illustrate volatile semantics as per the Java memory model. Volatile has way more complex semantics. In the example provided, the main thread could continue to print \"Today's temperature is 0\" forever even if there is another thread running that is supposed to update the temperature if that other thread never gets scheduled.A better way to illustrate volatile semantics is with 2 variables.   For simplicity's sake, we will assume that the only way to update the two variables is through the method .For simplicity's sake, we will assume that only 2 threads are running, main thread and thread 2.the last two assignment instructions can  be reordered for optimization purposes by either the compiler, runtime or the hardware.Once the main thread reads the volatile variable temperature (in the process of printing it),1) There is a guarantee that it will see the  value of this volatile variable regardless of how many threads are writing to it, regardless of which method they are updating it in, synchronized or not.2) If the system.out statement in the main thread runs,  the time instant at which thread 2 has run the statement temperature = temp,  both yesterday's temperature and todays temperature will be guaranteed to print the values set in them by thread 2 when it ran the statement temperature=temp.This situation gets a  more complex if a) Multiple threads are running and b) There are other methods than just the setTemperatures method that can update the variable yesterday's temperature and todays temperature that are actively being called by these other threads. I think it would take a decent size article to analyze the implications based on how the Java Memory Model describes the volatile semantics. In short, attempting to just use volatile for synchronization is extremely risky, and you would be better off sticking to synchronizing your methods. From java concurrency  :This means that changes to a volatile variable are always visible to other threads. It also means that when a thread reads a volatile variable, it sees not just the latest change to the volatile, but also the side effects of the code that led up the change.Regarding your query:If you feel that all reader threads always get latest value of a variable, you have to mark variable as , volatile modifier guarantees memory consistency. If you have multiple threads to write and read variables,  modifier alone does not guaranty memory consistency.  You have to  the code or use high level  constructs like , ,  etc. Related SE questions/articles: article\"The volatile keyword is used on variables that may be modified simultaneously by other threads.\"\"Since other threads cannot see local variables, there is never any need to mark local variables volatile. You need synchronized to co-ordinate changes to variables from different threads, but often volatile will do just to look at them.\""},
{"body": "I am new to Maven, I have a Java based web project with maven configured in my MyEclipse.\nNow if I modified any java files then do I need to do  or ?from So the answer to your question is, it depends on whether you want it in installed into your local repo. Install will also run package because it's higher up in the goal phase stack. is the option that is most often used.\n is seldom used, only if you're debugging some issue with the maven build process.    See:   Note that  will only create a jar file.\n will do that  install the jar (and class etc.) files in the proper places if other code depends on those jars.  I usually do a ; this deletes the  directory and recreates all jars in that location.\nThe clean helps with unneeded or removed stuff that can sometimes get in the way.\nRather then debug (some of the time) just start fresh all of the time.  From the ,  will run the project's integration tests,  won't.If you really need to not install the generated artifacts, use at least .package - takes the compiled code and package it in its distributable format, such as a JAR or WAR file.\ninstall - install the package into the local repository, for use as a dependency in other projects locallyIf you're  using a  repository (like artifactory), use plain old:\n   Pretty old topic but AFAIK, if you run your own repository (eg: with  artifactory) to share jar among your team(s), you might want to use instead. This way, your continuous integration server can be sure that all dependencies are correctly pushed into your remote repository. If you missed one, mvn will not be able to find it into your CI local m2 repository.Also you should note that if your project is consist of several modules which are dependent on each other, you should use \"install\" instead of \"package\", otherwise your build will fail, cause when you use install command, module A will be packaged and deployed to local repository and then if module B needs module A as a dependency, it can access it from local repository.The  way is  if you did things correctly for the core part of your build then there should be no need to install your packages in the local repository.In addition if you use Travis you can \"cache\" your dependencies because it will not touch your  if you use package for your own project.In practicality if you even attempt to do a  you usually need to do a  before.  There's just too many bugs with either  or it's numerous poorly maintained plugins.It depends on what you're trying to achieve after changing the Java file. Until you want to test the maven process, you never need to do anything. Eclipse/MyEclipse will build what is necessary and put the output in the appropriate place within your project. You can also run or deploy it (if it's a web project, for example), without your needing to explicitly do anything with maven. In the end, to install your project in the maven repository, you will need to do a maven install. You may also have other maven goals that you wish to execute, which MyEclipse won't do automatically.As I say, it depends on what you want to do."},
{"body": "I need a  datastructure for my use case. I should be able to push items into the datastructure and I only want to retrieve the last item from the Stack . The  says :I definitely do not want synchronized behavior here as I will be using this datastructure local to a method . Apart from this why should I prefer  over  here ?P.S: The javadoc from Deque says :For one thing, it's more sensible in terms of inheritance. The fact that  extends  is really strange, in my view. Early in Java, inheritance was overused IMO -  being another example.For me, the crucial word in the docs you quoted is .  exposes a set of operations which is all about being able to fetch/add/remove items from the start or end of a collection, iterate etc - and that's it. There's deliberately no way to access an element by position, which  exposes  it's a subclass of .Oh, and also  has no interface, so if you know you need  operations you end up committing to a specific concrete class, which isn't usually a good idea.Here is my interpretation of inconsistency mentioned in the description of Stack class.If you look at General-purpose Implementations  - you'll see there is a consistent approach to implementation of set, map and list. But Stack class: 1) don't have its own interface; 2) is a subclass of Vector class - which is based on resizable array; so where is linked list implementation of stack?In Deque interface we don't have such problems including two implementations (resizable array - ArrayDeque; linked list - LinkedList).Deque is used is situation where you want to retrieve elements from both head and tail. If you want a simple stack there is no need to go for a deque.  "},
{"body": "The official Redis homepage lists JDBC-Redis and JRedis. What are the advantages / disadvantages of each ? Are there any other options ? You can use also , which is also in the . It is compatible with the latest version of Redis.As of June 2012, Jedis is the Java client library recommended by the Redis official page.I've tried JDBC-Redis, Jredis and Jedis.\nJDBC-Redis is not good at performance. JRedis and Jedis are both fast, I use Jredis for times but now I prefer Jedis because it's simple, and I can handle network connection errors as I want.Both  and  are being actively developed. I personally use Jedis since it seems to be more actively developed.Spring provides a wrapper around both implementations and they're providing serialization/deserialization, amongst other things: Spring Data now added support for a 3rd library called  (Redis Java Client) -- I don't know what the pros/cons for it are, though.An easier solution is to not worry about working at the lowest level but use an Object Hash Mapper (OHM) like JOhm instead. JOhm lets users decorate their existing objects with familiar annotations to allow persistence to Redis without any invasive code changes. It does not even need any external configuration. You can think of the OHM as a NoSQL counterpart to the ORM of RDBMS. JOhm is hosted just an update: it seems jredis is not that active anymore, jedis however is going strong and had some great features implemented recently, it s also the same developer of JOhm.extract from their readme on github: Ok.. so what can I do with Jedis?\n[...]TransactionsPipeliningPublish/SubscribePersistencecontrol commandsRemote server control commandsConnection poolingSharding (MD5, MurmureHash)Key-tags for shardingSharding with pipeliningI was using jredis until recently on half a dozen of projects, moved them all to jedis in no time, without surprises.Jedis is a very good client. I have used jedis to make some performance test against redis. 50 clients, 1m requests completed in 20 seconds(on a old intel 2core 2.6g machine, 100m network). I believe the performance can be much higher if I can use 1000m network to do the test. JDBC-Redis is just a JDBC wrapper for JRedis database.\nIf you plan on using your code with different back-ends then JDBC is a good way to go. NOTE: It is not a complete JDBC implementation and the NOSQL will bleed through.\nIf you are going to stay with Redis then I would suggest using the API, which will give you more flexibility. Use a DAO layer pattern to encapsulate your DB Access and down the road that is all you will need to change."},
{"body": "There are at the moment, two ways to mark code as depreacted in java.Via JavaDocOr as an annotation:This is my problem - I find it a bit too much to declare both, when marking a method as deprecated when using Eclipse. I really just want to use one of them.However does using the annotation give the compiler actual useful additional information?But only using the annotation, I cannot state why the method is deprecated - I can only do that with JavaDoc, and deprecating a method without specying why is bad.So, can I only use one of them? Or should I really just learn to specify both?You should use both. The Annotation allows the compiler to display a warning whenever a deprecated method is used, and the javadoc explains why. Both are important.As per Oracle's Java Annotations :From the :So basically, if you want a guarantee that there will be compiler warnings, you need to use the annotation. And because of some API designer's breathtaking incompetence, you need to specify the javadoc tag as well to give an explanation.Personally, I'd say the annotation is useless and should be omitted until it's fixed, since any good compiler or IDE will display warnings with the javadoc tag as well.You should specify both.The annotation lets the compiler know about it and trigger warnings when the method is used.\nThe JavaDoc attribute lets developers know about before they start using it.These are two very different things!You should write both.\nThe @Deprecated Anotation is for the Compiler and the @deprecated JavaDoc tag is for the Person who wants to now why this is deprecated.An example can look like this:This can be easily dealt with a good IDE.Eclipse Neon, for eg. automatically adds @Deprecated annotation, when I create a javadoc @deprecated on a method or field.So I simply write the javadoc with the appropriate explanation and let the IDE take care of adding the @Deprecated annotation, the minute I save the file."},
{"body": "While browsing the code for the Java 8 version of ForkJoinPool(which has a few interesting changes from Java 7) I ran across this construct ():I'm struggling with why you would write it like this instead of justIs it just a semantics/readability choice, since you could read the first construct as ? Or is there some additional benefit I'm missing?If you read the comments at top of the file, just below the class declaration, there is a section which explains the use of this construct: makes extensive use of  from  and most of the occurrences of  in  can \u2014 as mentioned by other answers \u2014 be explained by this comment under the heading Style notes:The choice to use write a -loop with an empty body as  seems however to be a mostly stylistic choice. This is perhaps clearer in , which happened to be updated in Java 8.In the Java 7  you can find this:While much of the code around it has also changed, it is clear that the replacement in Java 8 is this:The first version has the weakness that if the lone semicolon happened to be deleted it would change the meaning of the program depending on the following line.As seen below, bytecode generated by  and  is slightly different, but not in any way that should affect anything when run.Java code:Generated code:Leaving aside any potential performance benefits, there is a clear readability benefit.With  the trailing semicolon is not always obvious at first glance, you may be confused into thinking that the following statement or statements are inside the loop. For example:It would be very easy to misread the above as having the if statement inside the loop, and even if you did read it correctly it would be easy to think that it was a programming mistake and the if should be inside the loop.With  though it is immediately at a glance clear that there is no body to the loop.If you will read comment above the code, It is mentioned that...If the caller is not a , this method is behaviorally equivalent toSo it is just another form to implement above code in else part...!!In  it is mentioned that, And if you will see implementation of , It is updating the lock and returns  if blocking is unnecessary.Blank while loops are used to provide an interrupt until some condition reset to true/false.Here,  is a blocker/interrupt until  will be  when  is . Loop will continue execution while  is not releasable () and  is not blocked !! Execution will be out of loop as soon as  will set to true.Note that,  does not update CAS variable, but it guarantee that program will wait until variable gets updated (force to wait until variable gets updated).  You can easily make something like this with:"},
{"body": "Can someone explain this to me. As long as there is only a single implementation of the interface and that implementation is annotated with  with Spring's component scan enabled, Spring framework can find out the (interface, implementation) pair. If component scan is not enabled, then you have to define the bean explicitly in your application-config.xml (or equivalent spring configuration file).Once you have more than one implementation, then you need to qualify each of them and during auto-wiring, you would need to use the  annotation to inject the right implementation, along with  annotation. If you are using @Resource (J2EE semantics), then you should specify the bean name using the  attribute of this annotation.Firstly, it is always a good practice to code to interfaces in general. Secondly, in case of spring, you can inject any implementation at runtime. A typical use case is to inject mock implementation during testing stage.Your bean configuration should look like this:Alternatively, if you enabled component scan on the package where these are present, then you should qualify each class with  as follows:Then  in  will be injected with an instance of type .Also it may cause some warnigs in logs like a . And many other reasons for this are described here "},
{"body": "I am a newbie in java and wanted to use curl in java. What is my question is curl built-in in java or I have to install it from any 3rd party source to use with Java. If so, how to install curl in java. I have been googling for a long time but didnt find any help. Hope anyone can help me out there. Thanks in advance.You can make use of  and/or . Also see the  on the subject. It's however a bit verbose. To end up with less verbose code, you may want to consider  instead.By the way: if your next question is \"How to process HTML result?\", then the answer is \". .\".The  object allows you to execute external command line applications from Java and would therefore allow you to use cURL however as the other answers indicate there is probably a better way to do what you are trying to do. If all you want to do is download a file the URL object will work great.Some people have already mentioned ,  and . If you need all the control and extra features that the curl library provides you (and more), I'd recommend .Using standard java libs, I suggest looking at the HttpUrlConnection class\nIt can handle most of what curl can do with setting up the connection.\nWhat you do with the stream is up to you.Curl is a non-java program and must be provided outside your Java program.You can easily get much of the functionality using , unless there is some specific functionality like \"resume transfer\" you need (which is tedious to code on your own)"},
{"body": "I want to use the JRE 1.7 that I downloaded .So I correctly install the .pkg file, and when I try  in the terminal I get this :But in Eclipse I can't use anything else than JRE 1.6. When I go in Properties > Java Build Path > Add Library > JRE System Library, I can't find the 1.7 (there is only option for it :  with this issue : What should I do ? ThanksThe download from  which installs in  is only the JRE, for development you probably want to download the JDK from  and install that instead.  This will install the JDK at  which you can then add to Eclipse via Preferences -> Java -> Installed JREs.Try editing your eclipse.ini file and add the following at the topOf course the path may be slightly different, looks like I have an older version...I'm not sure if it will add itself automatically. If not go intoPreferences --> Java --> Installed JREsClick Add and follow the instructions there to add itYou need to tell Eclipse which JDK/JRE's you have installed and where they are located.This is somewhat burried in the Eclipse preferences: In the Window-Menu select \"Preferences\". In the Preferences Tree, open the Node \"Java\" and select \"Installed JRE's\". Then click on the \"Add\"-Button in the Panel and select \"Standard VM\", \"Next\" and for \"JRE Home\" click on the \"Directory\"-Button and select the top level folder of the JDK you want to add.Its easier than the description may make it look."},
{"body": "I'm working on a high-performance Android application (a game), and though I try to code for readability first, I like to keep in the back of my mind a picture of what is happening under the hood. With C++, I've developed a fairly good intuition about what the compiler will and won't do for me. I'm trying to do the same for Java/Android.Hence this question. I could find very little about this topic on the web. Will the Java compiler, Dalvik converter (dx) and/or JITter (on Android 2.2+) perform optimizations like the following?Etcetera...This is Ben, one of the engineers working on the JIT @ Google. When Bill and I started on this project, the goal was to deliver a working JIT as soon as possible with minimal impact to resource contention (eg memory footprint, CPU hijacked by the compiler thread) so that it can run on low-end devices as well. Therefore we used a very primitive trace based model. That is, the compilation entity passed to the JIT compiler is a basic block, sometimes as short as a single instruction. Such traces will be stitched together at runtime through a technique called chaining so that the interpreter and code cache lookup won't be invoked often. To some degree the major source of speedup comes from eliminating the repeated interpreter parsing overhead on frequently executed code paths.That said, we do have quite a few local optimizations implemented with the Froyo JIT:In Gingerbread we added simple inlining for getters/setters. Since the underlying JIT frontend is still simple trace based, if the callee has branches in there it won't be inlined. But the inline cache mechanism is implemented so that virtual getters/setters can be inlined without problems.We are currently working on enlarging the compilation scope beyond a simple trace so that the compiler has a larger window for code analysis and optimization. Stay tuned.I'm sure that my answer will not answer all of your questions but I guess it is a win if it answers even one.You seem to have a profound knowledge on the subject and know what you want so you might want to do the following. Build an example application containing the aspects you want to investigate on.Take the APK you get and run it through the . Reverse engineering your own code to do just what you are intending is perfectly fine as we know.The APK Tool will extract and decode your resources and will reverse engineer  files to  files. You might want to look up the  project too to get more information about how to read the  files and about its limitations.Again I'm pretty sure that this is not going to answer all of your questions but it might be a good start.First, let me preface this by saying that I'm not an expert on dalvik, and some of my responses may be wrong. But I have dug into the JIT code in dalvik, and I'm quite familiar with the bytecode that dalvik runs.Also, I'd like to mention another avenue of approach to you - dx and dalvik are both open source, so you can dig into them all you like. Although, they're obviously not small codebases, so would take a fair bit of effort to dig into them at that level"},
{"body": "How can an anonymous class extend a superclass or implement an interface?Anonymous classes  extend or implement something, like any other Java class, even if it's just .For example:Here,  is an object of an anonymous class which implements .An anonymous class can extend another class using the same syntax:What you can't do is implement more than one interface. You need a named class to do that. Neither an anonymous inner class, nor a named class, however, can extend more than one class.An anonymous class usually implements an interface:If you mean whether you can implement  or more interfaces, than I think that's not possible. You can then make a private interface which combines the two. Though I cannot easily imagine why you would want an anonymous class to have that:Anonymous classes  extend superclass or implements interfaces. for example:Moreover, although anonymous class cannot implement multiple interfaces, you can create an interface that extends other interface and let your anonymous class to implement it.An anonymous class is extending or implementing while creating its object\nFor example : Here anonymous class is implementing Interface.here anonymous Class is extending a abstract Class."},
{"body": "How can I  + (which normally would kill the process)\nin a CLI (command line interface) Java application?Does a multi-platform solution exist (Linux, Solaris, Windows)?I'm using 's , but if necessary, I could use some other method\nto read characters from standard input.This should be able to intercept the signal, but only as an intermediate step before the JVM completely shutdowns itself, so it may not be what you are looking after.You need to use a  () to intercept the  signal triggered by a + (on Unix as well as on Windows).\nSee  (pdf, page 8 and 9).I am assuming you want to shutdown gracefully, and not do short circuit the shutdown process.  If my assumption is correct, then you should look at .In order to be able to handle + without shutting down for some reason, you'll need to use some form of signal handling (since the + input isn't actually passed directly to your application, but instead is handled by the OS which generates a SIGINT that is then passed to Java.See  for details on signal handling.(If you're just wanting to gracefully shutdown, akf's answer will suffice.)Some links about how to handle SIGTERM - that is the signal the program is getting on the OS side:That should work on POSIX operating systems - that is, Mac and Unix should work, on windows I'm not sure, I remember hearing it is also POSIX compatible to some extent, but might varty a lot with different versions."},
{"body": "I have a problem importing an external project. I go File -> Import... -> Existing Projects into Workspace, choose the folder where the project is located and everything is imported - but the package names of the project don't seem to be what Eclipse expects. The package names all have a prefix:etc.But Eclipse expectsetc. because the directory is src/prefix1/prefix/package1I don't really want to mess around with external code. How do I tell Eclipse to ignore the directory \"src/prefix1\"? Or what else can I do?Just go into the build path and the source path to be  instead of .It may be easiest to right-click on the  directory and select \"Build Path / Remove from build path\", then find the  directory, right click and select \"Build Path / Use as source folder\".I just ran into this problem, and since Mr. Skeet's solution did not work for me, I'll share how I solved this problem.It turns out that I opened the java file under the 'src' before declaring it a source directory.After right clicking on the 'src' directory in eclipse, selecting 'build path', and then 'Use as Source Folder' the already  (F5 refreshing it did not work).Provided the path to the java file from \"prefix1\" onwards lines up with the package in the file (example from the requester's question prefix1.prefix.packagename2). This should workEclipse should no longer complain about 'src.'Move your problem *.java files to other folder.Click 'src' item and press \"F5\".Red crosses will dissaperar.Return your *.java files to \"package path\", click 'src' item and press \"F5\".All should be ok.If you have imported an existing project, then just remove your source folders and then add them again to build path, and restart eclipse. Most of the times eclipse will keep showing the error till you restart.I get this problem in Eclipse sometimes when importing an Android project that does not have a .classpath file.   The one that Eclipse creates is not exactly the same one that Android expects.  But, the Android .classpath files are usually all relative, so I just copy a correct .classpath file from another project over the incorrect .classpath.  I've created a video that shows how I do this:  Suppose your project has a package like\n  (declared package)Your package explorer shows\npackage top level named name1.name2\nsub packages named name3.name4You will have errors because Eclipse extracts the package name from the file directory structure on disk starting at the point you import from.My case was a bit more involved, perhaps because I was using a symbolic link to a folder outside my workspace.  I first tried Build Path.Java Build Path.Source Tab.Link Source Button.Browse to the folder before name1 in your package.Folder-name as you like (i think). But had issues.Then I removed the folder from the build path and tried File > Import... > General > File System > click Next > From Directory > Browse... to folder above name1 > click Advanced button > check Create links in workspace > click Finish button.Go to src folder of the project and copy all the code from it to some temporary location and build the project. And now copy the actual code from temporary location to project src. And run the build again. Problem will be resolved.None these answers worked in my case.  All of my projects (several modules) suddenly had this issue.  Without knowing how or why this happened, I was able to quickly resolve this by deleting all the projects from Spring Tool Suite (without checking the delete from disk box), then re-importing them."},
{"body": "Is it possible to have a different set of dependencies in a maven pom.xml file for different profiles?e.g.I'd like to pick up a different dependency jar file in one profile that has the same class names and different implementations of the same interfaces.To quote the :(Emphasis is mine)Just put the dependency for the  profile inside the profile declaration itself and do the same for .Your groupId, artifactId should be tokenized in your profiles as properties and you can move your dependencies to the generic section."},
{"body": "I'm not really sure what is causing it as it is correctly listed in the manifest:I also added \"Android Private Libraries\" to build path, and moved it to the top of \"Order and Export\", but it still gave me the same error.EDIT: I rebuilt the project completely, and was unable to reproduce the error.  Not sure what was causing it.I had the same issue for my project.It happened due to the conflict in android support library version between my project and the library project that i added in my project. ... Everything will work...This following method worked for me. \nRight click on your  and select . The \"Properties for \" panel will open. From the menu on the left go to  ->  .\nFrom the list below uncheck th box next to . \nFinally  and run.Hope it worksIf you are using Eclipse try Project -> CleanThis happens if we change Build Path of the APP, this can be in any case of Adding or Removing or Changing Libraries or .jar file. The Best solution is to 1) Create libs folder under project root \n2) Copy and paste the jar file into it\n3) Configure the build path (Add jar)\n4) Clean and run\n\ncheers :-)If you get this error while using the new Instant Run feature in Android Studio 2.0 and above then this is some kind of bug on their side. \n\nTo fix this you will have to stop your app manually on Device/Emulator if it's not stopped then from Android Studio select .\n\nThen click the  button or I had same issue, this worked for me 1) Full path of activity in mainfest in place of relative path.2) Delete 'build' folder and clean project.I met the same problem .\nand I found the sample code was \nput in directory \"JAVA\" \ninstead of directory \"src\".\nAfter move code to src ,\nthe problem was solved.Hope it works~Believe me or not... I tried out almost each answer I had found here on stackoverflow. Nothing would help, until I just restarted the machine. My Android Studio works on Ubuntu 16.04 LTS.For any one who is having multidex enable write thisinside write a class  like belowand in  write this  inside Application tagI had this issue recently and I am using Android Studio 0.8.4The problem was the fact that I decided to rename an XML menu layout file that was called main.xml.Right click on it and chose . Before renaming it, be sure uncheck  and pressed . Because my file was originally named , it renamed critical paths in the app.iml and build.gradle, mainly the java.srcDirs in the build.gradle, since the path is defined as .I hope this helps anyone that may be experiencing this issue.I faced this error once when I defined a class that extended a view but referred to this custom view in the layout file with the wrong name. Instead of , I had included  in the XML layout file.I ran into the same issue. I solved it by first deleting the build folder in your android project folder and the build folder in your app folder.\nthen clean your project and build.I had this issue, raised by several causes, but i see this in your stacktrace \"\",  I found a diference in my  before it stop working.I've ADDED the line: this is the final version:Now it works! =)I had the same exact issue. As @weiweia suggested, move the code from the java directory to src worked for me. I also removed the Android Dependencies from Project --> Properties --> Java Build Path --> Order and Export, and made sure only to include Library Projects in the Android screen. I had this problem for quite a while, and like everybody else the answers above didn't apply to my project. In my project I had linked up a project to my project and it was throwing ClassDefNotFoundError every time some code for the other project was executed. So this was my solution. I went to project properties of my project and Java Build Path. Pressed the \"Source\"-tab and \"link source\" from src-folder of the other project to my own project and named a new folder \"core-src\". Hopes this solution helps someoneI had the same issue. I am using Xamarin.Android.The problem in my case was that I changed the versionCode and versionName.I had no problem when I had them set like this:The issue appeared when I changed it to this (versionCode 2 and versionName 0.0.1):I fixed the issue by changing to versionCode 2 and versionName 1.0.0.1, like so:I am unsure why this was a problem, maybe Android doesn't like a lower versionName with a higher versionCode?I found the following on Just in case anybody faces the same problem as me and no suggest\nanswer here helps.For me the cause was, that the Android studio refactor is buggy.\nI moved an innerclass outside of a class, which was a View and therefore\nalso had a xml, where the direct path was set. This path will not get\nrefactored by studio! And no error will be thrown. Hope this helps anybody. Cheers.I had this problem after upgrading from version 18.\nAfter the upgrade I had the following:\nProject Build Target was 5.01, targetSDKVersion=21\nBuild Tools were still from Android 4.3.1 (18) \nWhat I noticed was that those apps that were deriving their activities from ActionBarActivity crashed with the above error those that did not still ran.So the simple fix was to use the latest \ninstead of only those of Android SDK Build Tools 18, which seems somehow the default.So the culprit seems the Appcompat library, which I use for Actionbar backward compability.And a : using the appcompat library I had to set/fix: \n (which was recommended in some other useful post and which has a value of 19 by default))In our case we wanted to compile Vagrant version and had same error. We fixed it by  and  in Build menuI just restarted the device and ran the app. It worked without any issues. Hope this helps someone :)I found this error in  when i tried do debug in a device with , so i checked the Android Studio and i noticed that . After install, i solved the problem.I had this problem several times and often I didn't do something obviously wrong with dependencies. It's always a good idea to check if this 'not found' class is present in the final apk. If it is, like it happened in my cases, the problem usually is: Check if class that you extend is available and then try to fix your build script or dependencies accordingly.I also faced the same problem,\nwe can solve this by doing some thing like1- Uninstall the app.2- Rebuild the project.3- Clean the project.4- Invalidate and restart the project from file -> invalidate and restart.I had the same issue on Windows. I had renamed the path to the project to something containing a space. Make sure the path to your project does not contain a space.For those of you who are having this issue on Android Studio, I had the same problem after a merge and for some reason it even persisted after  and  operations which was driving me crazy.Turns out, it can be fixed by running gradle build once from command line. Simply run the following n the project directory:I hope it'd save someone the time waste and frustration I had to go through.I had this issue in IntelliJ IDEA. This is how I solved it:Project Properties > Facets > Click the Android Facet created from the external library you are adding > Check the box 'Library Module'."},
{"body": "In the spirit of type safety associated with the  JPA 2.0 also has an API to support  representation of entities. Is anyone aware of a fully functional implementation of this API (to generate the Metamodel as opposed to creating the metamodel classes manually)? It would be awesome if someone also knows the steps for setting this up in Eclipse (I assume it's as simple as setting up an annotation processor, but you never know).EDIT:\nJust stumbled across . But the issue remains since I can't find any download links for the jar.EDIT 2:\nAwhile has passed since I asked this question, but I thought I'd come back and add a link to the Yes it is. Here are the implementations and instructions for the various JPA 2.0 implementations:For Hibernate, the implementation is provided by Please take a look at Using Hibernate is most recommended.()OpenJPA seems require additional element .EclipseLink requires .For Apache Maven users,Following simple configuration seems work. ()you can run it with \"mvn compiler:compile\"Note that this method works only with those old maven-compiler-plugin. Check the version in code.Eclipse's JPA 2.0 support through Dali (which is included in \"Eclipse IDE for JEE Developers\") has its own metamodel generator integrated with Eclipse.This should work on any JPA provider as the generated classes are standard.Also see .For eclipselink, only the following dependency is sufficient to generate metamodel. Nothing else is needed. For Hibernate as provider which is most common IMHO:In case of build tools like Gradle, Maven you need to have Hibernate JPA 2 Metamodel Generator jar in the classpath and compiler level>=1.6 that is all you need build the project and metamodel will be generated automatically.In case of IDE Eclipse \n1. goto Project->Properties->Java Compiler->Annotation Processing and enable it. \n2. Expand Annotation Processing->Factory Path-> Add External Jar add Hibernate JPA 2 Metamodel Generator jar check the newly added jar and say OK. Clean and Build done!Link Hibernate JPA 2 Metamodel Generator jar link from maven repo\n"},
{"body": "Eclipse is unable to open, have used eclipse before and has open before without a problem. Now I keep getting the following error message:Have gotten eclipse to open and work on projects before and won't open.Here is a screen shot of what I keep getting:. Open  and add the following lines to the top of the file:: I just nailed down the root cause on my own Windows machine. The GlassFish installer complained with exactly the same error message and after digging in GlassFish forums, the cause was clear: a corrupt JRE install on a Windows machine. My JRE came along with the JDK and the Java 6 JDK installer didn't install the JRE properly somehow. A DLL file was missing in JDK's JRE installation. After I reinstalled the standalone JRE from , overwriting the old one, the GlassFish installer continued and also Eclipse was able to start flawlessly without those two lines in .It usually is because:More details on the wiki page \"\"As mentioned in \"\":So I would check your $PATH, starting by n new shell sesion (whatever your OS is), typing '' to see if it still returns anything.Here is how I fixed mine:when you download eclipse, you get a .zip package containing eclipse.exe and all the other files needed to run eclipse but it is missing the jre files. so all you need to do is to find where jre folder is located on your hard drive and add it to the rest of the eclipse package.I had the same problem and the issue was that I had a 32 bit version of Eclipse running on my 64 bit machine and it wanted the 32 bit version of JRE. I changed  to  in the  file like so:and that solved the problem.You may want to just install the 64 bit Eclipse, but this will take care of the error.Did you install Java via the java.com web browser auto install?  If so, then that's your problem! You need to to the \"manual\" install: It's just a matter of having the correct match of 32-bit Eclipse/32-bit Java or 64-bit Eclipse/64-bit Java.  Many 64-bit Windows have 32-bit browsers and the latter is the version of Java that the auto-installer will provide - not what the 64-bit Eclipse wants.I also had same problem when developing android applications using eclipse IDE.\nI solved it by removing all the java installations (I had java 6 and 7 both) and re-install only jdk 7.Make sure the install path of JDK is in your Path variable in Windows.adding   to the .ini file helped me.I had this problem too on a win7 machine.\nI wanted to update the jre with a jdk. So i deleted the jre folder and downloaded and unzipped the new jdk.\nThe issue was i manually deleted the jre folder, when instead i should've uninstalled it. This leaves a bunch of registry entries that still point to the old jre. Somehow eclipse still wants to use the old jre.\nI couldn't uninstall the old java vm, i kept getting this error:Error 1723. There is a problem with this Windows Installer package. A DLL required for this install to complete could not be run. Contact your support personnel or package vendorSo i had to use this MS utility to fix the uninstall:Then i had to install again the vm. I installed to the same location the original one was at, to avoid losing another hour! After that eclipse started correctly.JulioI just had this problem and fixed it this way. I noticed the error message has jre in it not jre6 or jre7, so i copied jre6 from program files to eclipse folder then renamed it from jre6 to jre, then it worked :pNewb move on my part, but I had . Installed JDK and my problem went immediately away.I had this problem and it was due to my windows machine playing up. I went into control panel -> system -> advanced - environment variables.I edited the PATH variable (which was already correctly set up), changed NOTHING, clicked OK to come back out of the screens. Then eclipse worked. No idea why, except because windows. Hopefully this may help someone.I got this fixed by doing the below steps,1) Please find the screenshot for the same.I had this issue;  I fixed it by going to Computer-->Properties-->Advanced Settings-->Environmental VariablesIn the System Variables find the variable named PATH.\n-->Select Edit\n-->At the very end of the Path Variable, put a \";\" then add your path of your JDK and put \\bin\\ at the endShould be fixed. C:\\Program Files (x86)\\Common Files.......HP\\LeanFT\\bin C:\\Programs Files\\Java\\jre1.8.0_121C:\\Program Files (x86)\\Common Files.......HP\\LeanFT\\bin;C:\\Programs Files\\Java\\jre1.8.0_121\\bin\\Sources:\nCopy javaw.exe from and paste it inside Eclipse folder\nwhere eclipse.exe is there. That's all.Is so simple,only add your java path for example:in  system variable "},
{"body": "I see gain in performance when using  and  operator over  operator.Is there any guideline, which one to use  or ?Given a scenario: I know exact classes to be matched, that is ,  (these are final classes), etc.Is using  operator bad practise ?The reason that the performance of  and  is different is that they are doing different things.So the recommendation is to ignore the performance issue and use the alternative that gives you the answer that you need.And yes, overuse of either of them is \"design smell\".  If you are not careful, you end up with a design where the addition of new subclasses results in a significant amount of code reworking.  In most situations, the preferred approach is to use polymorphism.  Do you want to match a class , e.g. only matching  instead of any subclass of ? If so, use  and . I would typically do this in an , so that an instance of X isn't deemed equal to an instance of a subclass of X - otherwise you can get into tricky symmetry problems. On the other hand, that's more usually useful for comparing that two objects are of the  class than of one specific class.Otherwise, use . Note that with  you will need to ensure you have a non-null reference to start with, or you'll get a , whereas  will just return  if the first operand is null.Personally I'd say  is more idiomatic - but using  of them extensively is a design smell in most cases.I know it has been a while since this was asked, but I learned an alternative yesterdayWe all know you can do:but what if you dont know exactly what type of class it needs to be?\nyou cannot generically do:as it gives a compile error.\nInstead, here is an alternative - isAssignableFrom()For example:getClass() has the restriction that objects are only equal to other objects of the same class, the same run time type, as illustrated in the output of below code: Outputs:SubClass extends ParentClass. subClassInstance is instanceof ParentClass. Different getClass() return results with subClassInstance and parentClassInstance. "},
{"body": "I have string like \" I am a boy\". I want to print like this way\n\" I (\\n new line) am (\\n new line) a (\\n new line) boy\".Can anybody help me?You can also use :Try:It can be done several ways. I am mentioning 2 simple ways.To make the code portable to any system, I would use: This is important because different OSs use different notations for newline: Windows uses \"\\r\\n\", Classic Mac uses \"\\r\", and Mac and Linux both use \"\\n\".Commentors - please correct me if I'm wrong on this... It's better to use  as an OS independent new-line character instead of  and it's easier than using Why to use , because on each OS, new line refers to a different set of character(s); is the acronym of  and  is the acronym of . The escape characters are written inside the parenthesis. So on each OS, new line stands for something specific to the system.  is OS agnostic, it is portable. It stands for  on Unix systems or  on Windows systems and so on. Thus, Do not use , instead use .If you want to have your code os-unspecific you should use println for each wordbecause Windows uses \"\\r\\n\" as newline and unixoid systems use just \"\\n\"println always uses the correct one is used for making separate line; If you simply want to print a newline in the console you can use \u00b4\\n\u00b4 for newlines.If you want to break text in swing components you can use html:Full program example, with a fun twist:Open a new blank document and save it as .  \"iAmABoy\" is the class name.Paste the following code in and read through it.  Remember, I'm a beginner, so I appreciate all feedback!Now, in terminal/cmd, browse to  and type:You can replace the args  with anything!What about  using a formatter like ?:As  says, its available from java 1.5 and is another way to  or  and, like this two, is .you can use  tag in your string for show in html pagesSystem.out.println(\"I\\nam\\na\\nboy\");This works\nIt will give one space character also along before enter character"},
{"body": "Very similar to , except for Java.What is the recommended way of encoding strings for an XML output in Java. The strings might contain characters like \"&\", \"<\", etc.Very simply: use an XML library. That way it will actually be  instead of requiring detailed knowledge of bits of the XML spec.As others have mentioned, using an XML library is the easiest way. If you do want to escape yourself, you could look into  from the  library.Just use.This will allow any characters except the ending So you can include characters that would be illegal such as & and >. For example.However, attributes will need to be escaped as CDATA blocks can not be used for them.This has worked well for me to provide an escaped version of a text string:Try this:While idealism says use an XML library, IMHO if you have a basic idea of XML then common sense and performance says template it all the way. It's arguably more readable too. Though using the escaping routines of a library is probably a good idea.Consider this: XML  meant to be written by humans.Use libraries for generating XML when having your XML as an \"object\" better models your problem. For example, if pluggable modules participate in the process of building this XML.Edit: as for how to actually escape XML in templates, use of CDATA or  from JSTL are two good solutions,  can be used like this:The behavior of StringEscapeUtils.escapeXml() has changed from Commons Lang 2.5 to 3.0.\nIt now no longer escapes Unicode characters greater than 0x7f.This is a good thing, the old method was to be a bit to eager to escape entities that could just be inserted into a utf8 document.The new escapers to be included in Google Guava 11.0 also seem promising:\nNote: Your question is about , not . Escaping is using <, etc. to allow the parser to distinguish between \"this is an XML command\" and \"this is some text\". Encoding is the stuff you specify in the XML header (UTF-8, ISO-8859-1, etc).First of all, like everyone else said, use an XML library. XML looks simple but the encoding+escaping stuff is dark voodoo (which you'll notice as soon as you encounter umlauts and Japanese and other weird stuff like \"\" (&#FF11; is 1)). Keeping XML human readable is a Sisyphus' task.I suggest never to try to be clever about text encoding and escaping in XML. But don't let that stop you from trying; just remember when it bites you (and it will).That said, if you use only UTF-8, to make things more readable you can consider this strategy:I'm using this in an SQL editor and it allows the developers to cut&paste SQL from a third party SQL tool into the XML without worrying about escaping. This works because the SQL can't contain umlauts in our case, so I'm safe. does not escape control characters (< 0x20).  XML 1.1 allows control characters; XML 1.0 does not.  For example,  will happily serialize a Java object's control characters into XML, which an XML 1.0 parser will reject.To escape control characters with Apache commons-lang, useTo escape XML characters, the easiest way is to use the Apache Commons Lang project, JAR downloadable from: The class is this: org.apache.commons.lang3.StringEscapeUtils;It has a method named \"escapeXml\", that will return an appropriately escaped String. While I agree with Jon Skeet in principle, sometimes I don't have the option to use an external XML library. And I find it peculiar the two functions to escape/unescape a simple value (attribute or tag, not full document) are not available in the standard XML libraries included with Java.As a result and based on the different answers I have seen posted here and elsewhere, here is the solution I've ended up creating (nothing worked as a simple copy/paste):The above accommodates several different things:At some point, I will write the inversion of this function, toUnescaped(). I just don't have time to do that today. When I do, I will come update this answer with the code. :)Here's an easy solution and it's great for encoding accented characters too!OutputsFor those looking for the quickest-to-write solution: use methods from :Remember to include dependency:Use  and forget about text handling it will be done for you automatically.Try to encode the XML using Apache XML serializer "},
{"body": "How can one quickly turn off all Log4J output using a log4j.properties file?Set level to OFF\n(instead of DEBUG, INFO, ....)If you want to turn off logging programmatically then useYou can change the level to OFF which should get rid of all logging. According to the log4j website, valid levels in order of importance are TRACE, DEBUG, INFO, WARN, ERROR, FATAL. There is  called OFF which is a higher level than FATAL, and turns off all logging.You can also create an extra root logger to log nothing (level OFF), so that you can switch root loggers easily.  to get you started on that.You might also want to read the  because I think turning off all logging may not help. It will certainly not speed up your app that much, because logging code is executed anyway, up to the point where log4j decides that it doesn't need to log this entry.Change level to what you want. (I am using Log4j2, version 2.6.2). This is simplest way, change to For example: File \n"},
{"body": "This is the code:This is the test:Works fine, the class is tested. But Cobertura says that there is zero code coverage of the private constructor of the class. How can we add test coverage to such a private constructor?Well, there are ways you could potentially use reflection etc - but is it really worth it? This is a constructor which should , right?If there's an annotation or anything similar that you can add to the class to make Cobertura understand that it won't be called, do that: I don't think it's worth going through hoops to add coverage artificially.EDIT: If there's no way of doing it, just live with the slightly reduced coverage. Remember that coverage is meant to be something which is useful to  - you should be in charge of the tool, not the other way round.I don't entirely agree with Jon Skeet. I think that if you can get an easy win to give you coverage and eliminate the noise in your coverage report, then you should do it. Either tell your coverage tool to ignore the constructor, or put the idealism aside and write the following test and be done with it:Although it's not necessarily for coverage, I created this method to verify that the utility class is well defined and do a bit of coverage as well.I have placed the full code and examples in I had made private the constructor of my class of static utility functions, to satisfy CheckStyle. But like the original poster, I had Cobertura complaining about the test. At first I tried this approach, but this doesn't affect the coverage report because the constructor is never actually executed. So really all this tests is if the constructor is remaining private - and this is made redundant by the accessibility check in the subsequent test.I went with Javid Jamae's suggestion and used reflection, but added assertions to catch anybody messing with the class being tested (and named the test to indicate High Levels Of Evil).This is so overkill, but I gotta admit I like the warm fuzzy feeling of 100% method coverage.The reasoning behind testing code that doesn't do anything is to achieve 100% code coverage and to notice when the code\ncoverage drops. Otherwise one could always think, hey I don't have 100% code coverage anymore but it's PROBABLY because\nof my private constructors. This makes it easy to spot untested methods without having to check that it just was a private constructor. As your codebase grows you'll actually feel a nice warm feeling looking at 100% instead of 99%.IMO it's best to use reflection here since otherwise you would have to either get a better code coverage tool that ignores these constructors or somehow tell the code coverage tool to ignore the method (perhaps an Annotation or a configuration file) because then you would be stuck with a specific code coverage tool.In a perfect world all code coverage tools would ignore private constructors that belong to a final class because the constructor is there as a \"security\" measure nothing else:)\nI would use this code:\nWith , it is possible to find other solution.I assume that you simply want to create utility class with few public static methods. If you can use Java 8, then you can use  instead.There is no constructor and no complain from Cobertura. Now you need to test only the lines you really care about.Newer versions of Cobertura have built-in support for ignoring trivial getters/setters/constructors:Ignore trivial allows the ability to exclude constructors/methods that contain one line of code. Some examples include a call to a super constrctor only, getter/setter methods, etc. To include the ignore trivial argument add the following:or in a Gradle build:Finally, there is solution!Don't.\nWhat's the point in testing an empty constructor?\nSince cobertura 2.0 there is an option to ignore such trivial cases (together with setters/getters), you can enable it in maven by adding configuration section to cobertura maven plugin:Alternatively you can use : .I don't know about Cobertura but I use Clover and it has a means of adding pattern-matching exclusions. For example, I have patterns that exclude apache-commons-logging lines so they are not counted in the coverage.Another option is to create a static initializer similar to the following code This way the private constructor is considered tested, and the runtime overhead is basically not measurable. I do this to get 100% coverage using EclEmma, but likely it works out for every coverage tool. \nThe drawback with this solution, of course, is that you write production code (the static initializer) just for testing purposes. Sometimes Cobertura marks code not intended to be executed as 'not covered', there's nothing wrong with that. Why are you concerned with having  coverage instead of ?Technically, though, you can still invoke that constructor with reflection, but it sounds very wrong to me (in this case).If I were to guess the intent of your question I'd say:For 1, it is obvious that you want all initialisation to be done via factory methods. In such cases, your tests should be able to test the side effects of the constructor. This should fall under the category of normal private method testing. Make the methods smaller so that they only do a limited number of determinate things (ideally, just one thing and one thing well) and then test the methods that rely on them.For example, if my [private] constructor sets up my class's instance fields  to . Then I can (or rather must) test it:For 2, you can configure clover to exclude Util constructors if you have a set naming pattern for Util classes. E.g., in my own project I use something like this (because we follow the convention that names for all Util classes should end with Util):I have deliberately left out a  following  because such constructors are not meant to throw exceptions (they are not meant to do anything).There of course can be a third case where you may want to have an empty constructor for a non-utility class. In such cases, I would recommend that you put a  with the exact signature of the constructor.If you have many such exceptional classes then you can choose to modify the generalized private constructor reg-ex I suggested and remove  from it. In this case, you will have to manually make sure that your constructor's side effects are still tested and covered by other methods in your class/project.Test.java is your source file,which is having your private constructorYou can't.You're apparently creating the private constructor to prevent instantiation of a class that is intended to contain only static methods. Rather than trying to get coverage of this constructor (which would require that the class be instantiated), you should get rid of it and trust your developers not to add instance methods to the class."},
{"body": "I want to trim a string if the length exceeds 10 characters.Suppose if the string length is 12 (), then the new trimmed string will contain .How can I achieve this?Using  like this avoids an exception in the case where the string is already shorter than .Notes: from  library could be your friend:There is a  function which does this. Courtesy:Steeve McCauleyAs usual nobody cares about UTF-16 surrogate pairs. See about them:  Even authors of org.apache.commons/commons-lang3You can see difference between correct code and usual code in this sample:Or you can just use this method in case you don't have StringUtils on hand:Just in case you are looking for a way to trim and keep the LAST 10 characters of a string.s = s.substring(Math.max(s.length(),10) - 10);"},
{"body": "I'm working on a business project that done in java and needs huge computation power to computer business markets. Simple math but with huge amount of data.We ordered some cuda gpu's to try it with and since Java not supported by cuda, Im wondering where to start with. Should i build a JNI interface? should i use JQUDA or is there other ways to go with this?I dont have experience in this fields and i would like if someone direct me to something so then i can start researching and learning.First of all, you should be aware of the fact that CUDA will not automagically make computations faster. On the one hand, because GPU programming is an art, and it can be very, very challenging to get it . On the other hand, because GPUs are well-suited only for certain  of computations.This may sound confusing, because you can basically compute  on the GPU. The key point is, of course, whether you will achieve a good speedup or not. The most important classification here is whether a problem is  or . The first one refers, roughly speaking, to problems where several threads are working on their own tasks, more or less independently. The second one refers to problems where  threads are  - but on different parts of the data. The latter is the kind of problem that GPUs are good at: They have  cores, and all the cores do the same, but operate on different parts of the input data. You mentioned that you have \"simple math but with huge amount of data\". Although this may sound like a perfectly data-parallel problem and thus like it was well-suited for a GPU, there is another aspect to consider: GPUs are ridiculously fast in terms of theoretical computational power (FLOPS, Floating Point Operations Per Second). But they are often throttled down by the memory bandwidth.This leads to another classification of problems. Namely whether problems are  or . The first one refers to problems where the number of instructions that are done for each data element is low. For example, consider a parallel vector addition: You'll have to  two data elements, then perform a single addition, and then  the sum into the result vector. You will not see a speedup when doing this on the GPU, because the single addition does not compensate for the efforts of reading/writing the memory. The second term, \"compute bound\", refers to problems where the number of instructions is high compared to the number of memory reads/writes. For example, consider a matrix multiplication: The number of instructions will be O(n^3) when n is the size of the matrix. In this case, one can expect that the GPU will outperform a CPU at a certain matrix size. Another example could be when many complex trigonometric computations (sine/cosine etc) are performed on \"few\" data elements. As a rule of thumb: You can assume that reading/writing one data element from the \"main\" GPU memory has a latency of about 500 instructions....Therefore, another key point for the performance of GPUs is : If you have to read or write data (and in most cases, you will have to ;-)), then you should make sure that the data is kept as close as possible to the GPU cores. GPUs thus have certain memory areas (referred to as \"local memory\" or \"shared memory\") that usually is only a few KB in size, but particularly efficient for data that is about to be involved in a computation.So to emphasize this again: GPU programming is an art, that is only remotely related to parallel programming on the CPU. Things like Threads in Java, with all the concurrency infrastructure like ,  etc. might give the impression that you just have to split your work somehow and distribute it among several processors. On the GPU, you may encounter challenges on a much lower level: Occupancy, register pressure, shared memory pressure, memory coalescing ... just to name a few.  However, when you have a data-parallel, compute-bound problem to solve, the GPU is the way to go. A general remark: Your specifically asked for CUDA. But I'd strongly recommend you to also have a look at OpenCL. It has several advantages. First of all, it's an vendor-independent, open industry standard, and there are implementations of OpenCL by AMD, Apple, Intel and NVIDIA. Additionally, there is a much broader support for OpenCL in the Java world. The only case where I'd rather settle for CUDA is when you want to use the CUDA runtime libraries, like CUFFT for FFT or CUBLAS for BLAS (Matrix/Vector operations). Although there are approaches for providing similar libraries for OpenCL, they can not directly be used from Java side, unless you create your own JNI bindings for these libraries. You might also find it interesting to hear that in October 2012, the OpenJDK HotSpot group started the project \"Sumatra\":  . The goal of this project is to provide GPU support  in the JVM, with support from the JIT. The current status and first results can be seen in their mailing list at  However, a while ago, I collected some resources related to \"Java on the GPU\" in general. I'll summarize these again here, in no particular order.(: I'm the author of  and  ) : An open-source library that is created and actively maintained by AMD. In a special \"Kernel\" class, one can override a specific method which should be executed in parallel. The byte code of this method is loaded at runtime using an own bytecode reader. The code is translated into OpenCL code, which is then compiled using the OpenCL compiler. The result can then be executed on the OpenCL device, which may be a GPU or a CPU. If the compilation into OpenCL is not possible (or no OpenCL is available), the code will still be executed in parallel, using a Thread Pool. : An open-source library for converting parts of Java into CUDA programs. It offers dedicated interfaces that may be implemented to indicate that a certain class should be executed on the GPU. In contrast to Aparapi, it tries to automatically serialize the \"relevant\" data (that is, the complete relevant part of the object graph!) into a representation that is suitable for the GPU.  : A library for translating annotated Java code (with some limitations) into CUDA code, which is then compiled into a library that executes the code on the GPU. The Library was developed in the context of a PhD thesis, which contains profound background information about the translation process. : Scala bindings for OpenCL. Allows special Scala collections to be processed in parallel with OpenCL. The functions that are called on the elements of the collections can be usual Scala functions (with some limitations) which are then translated into OpenCL kernels. : A language extension for Java that allows parallel constructs (e.g. parallel for loops, OpenMP style) which are then executed on the GPU with OpenCL. Unfortunately, this very promising project is no longer maintained.  (JCUDA) : A library that can translate special Java Code (called JCUDA code) into Java- and CUDA-C code, which can then be compiled and executed on the GPU. However, the library does not seem to be publicly available. : Java language extension for for OpenMP constructs, with a CUDA backend : Java bindings for OpenCL: An object-oriented OpenCL library, based on auto-generated low-level bindings : Java bindings for OpenCL: An object-oriented OpenCL library, based on auto-generated low-level bindings : Java bindings for OpenCL: Auto-generated low-level bindings and object-oriented convenience classes : Java bindings for OpenCL: Low-level bindings that are a 1:1 mapping of the original OpenCL API : Java bindings for CUDA: Low-level bindings that are a 1:1 mapping of the original CUDA API : Java bindings for OpenCL. Seem to be no longer maintained since 2010 : Java bindings for CUDA. Seem to be no longer maintainedI'd start by using one of the projects out there for Java and CUDA: "},
{"body": "I have been checking the upcoming , namely: . Yes, I am impatient, there's a lot of new stuff, but, there is something I don't understand, some simple code:the javadocs areI would appreciate if somebody created some simple real-life examples about , how you could code it in previous java versions  and how you can code the same routines using .It doesn't make sense to  a  that's already flat, like the  you've shown in your question.  However, if you had a  then it would make sense and you could do this:Which would print:To do this pre-Java 8 you just need a loops:Imagine that you want to create the following sequence: 1, 2, 2, 3, 3, 3, 4, 4, 4, 4 etc. (in other words: 1x1, 2x2, 3x3 etc.)With  it could look like:where:With Java < 8 you would need two nested loops:Let's say I have a  where each  is essentially a . I want to get a list of all dates for which at least one of the time series has a value.  to the rescue:Not only is it readable, but if you suddenly need to process 100k elements, simply adding  will improve performance without you writing any concurrent code.Extract unique words sorted ASC from a list of phrases:... and the output: Am I the only one who finds unwinding lists boring? ;-)Let's try with objects. Real world example by the way. Given: Object representing repetitive task. About important task fields: reminders are starting to ring at  and repeat every  (e.g. 5 HOURS) and there will be  reminders in total(including starting one).Goal: achieve a list of task copies, one for each task reminder invocation.P.S.: I would appreciate if someone suggested a simpler solution, I'm not a pro after all.\n@RBz asked for detailed explanation so here it is.\nBasically flatMap puts all elements from streams inside another stream into output stream. A lot of streams here :). So, for each Task in initial stream lambda expression  creates a stream of long values that represent task start moments. This stream is limited to  instances. It's values start from  and each next value is calculated using lambda .  returns the stream with each long value as a Long wrapper instance. Then each Long in that stream is mapped to new Task instance that is not repetitive anymore and contains exact execution time. This sample contains only one Task in input list. But imagine that you have a thousand. You will have then a stream of 1000 streams of Task objects. And what  does here is putting all Tasks from all streams onto the same output stream. That's all as I understand it. Thank you for your question!Given this:and this:We can then do this:This method takes one Function as an argument, this function accepts one parameter T as an input argument and return one stream of parameter R as a return value. When this function is applied on each element of this stream, it produces a stream of new values. All the elements of these new streams generated by each element are then copied to a new stream, which will be a return value of this method. "},
{"body": "I'd like to scroll to the bottom of the RecyclerView list after loading the activity. throws an exception about being not supported in RecyclerView, and  doesn't seem to do anything.After the above block of code, I addedwhich doesn't work. There are 30 elements in .Just set  or  so that LLM will layout items from end.The difference between these two is that  will set the view to show the last element, the layout direction will remain the same. (So, in an left-to-right horizontal Recycler View, the last element will be shown and scrolling to the left will show the earlier elements)Whereas  will change the order of the elements added by the Adapter. The layout will start from the last element, which will be the left-most in an LTR Recycler View and then, scrolling to the right will show the earlier elements.Sample:See  for details.I was looking at this post to find the answer but... I think everyone on this post was facing the same scenario as me: scrollToPosition() was fully ignored, for an evident reason.What I was using?... what ?I know its late to answer here, still if anybody want to know solution is belowWhen you call , that does not immediately lay out and position items on the screen (that takes a single layout pass) hence your  call has no actual elements to scroll to when you call it.Instead, you should register a  (via  from a  created by ) which delays your  until after the first layout pass:To scrolldown from any position in the recyclerview to bottomandabove code works, but it's not smooth and not cool.Only Ian's answer was able to make my  scroll to a specified position. However, The  was not able to scroll afterwards when I used .  worked but the initial animation made it too slow when the list was long. \nThe reason was the listener was not removed. I used the code below to remove the current  and it worked as a charm.IF you have adapter attached with recyclerView then just do this."},
{"body": "Java is nearing version 7. It occurs to me that there must be plenty of textbooks and training manuals kicking around that teach methods based on older versions of Java, where the methods taught, would have far better solutions now.What are some boilerplate code situations, especially ones that you see people implement through force of habit, that you find yourself refactoring to utilize the latest versions of Java?Enums. Replacing withGenerics and no longer needing to create an iterator to go through all elements in a collection. The new version is much better, easier to use, and easier to understand.EDIT:Before:AfterUsing local variables of type  to perform string concatenation. Unless synchronization is required, it is now recommended to use  instead, because this class offers better performance (presumably because it is unsynchronized).reading a string from standard input::::Here is one that I see: versus . is not recommended for new code, but I still see people use it.As for compatibility, Sun makes a huge effort to have Java be backwards and forwards compatible. That partially accounts for why generics are so complex. Deprecation is also supposed to help ease transitions from old to new code.Older code using Thread instead of the many other alternatives to Thread... these days, very little of the code I run across still needs to use a raw thread. They would be better served by a level of abstraction, particular //.See:VARARGS can be useful too.For example, you can use:instead of:orUsing local variables of type Vector to hold a list of objects. Unless synchronization is required, it is now recommended to use a List implementation such as ArrayList instead, because this class offers better performance (because it is unsynchronized).Formatted printing was introduced as late as in JDK 1.5. So instead of using:or the equivalent using a StringBuilder,one can use The latter is much more readable, both from the string concatenation and the string builder versions. Still I find that people adopt this style very slowly. Log4j framework for example, doesn't use this, although I believe it would be greatly benefited to do so. Explicit conversion between primitive and wrapper types (e.g. Integer to int or vice versa) which is taken care of automatically by autoboxing/unboxing since Java 1.5.An example isCan simply be written asBut watch out for NullPointerExceptions :)Q1: Well, the most obvious situations are in the generics / type specific collections.  The other one that immediately springs to mind is the improved for loop, which I feel is a lot cleaner looking and easier to understand.Q2: In general, I have been bundling the JVM along side of my application for customer-facing apps.  This allows us to use new language features without having to worry about JVM incompatibility.  If I were not bundling the JRE, I would probably stick to 1.4 for compatibility reasons.A simple change in since 1.5 but makes a small difference - in the Swing API accessing the contentPane of a JFrame:becomesAnd of course the introduction of Enums has changed the way many applications that used constants in the past behave.String.format() has greatly improved String manipulation and the ternary if statement is quite helpful in making code easier to read.Generic collections make coding much more bug-resistant.\nOLD:NEW:Using Iterator:Or an alternate form sometimes seen:Is now all replaced with:Although I admit that static imports can easily be overused, I like to usein classes that use a lot of Math functions.  It can really decrease the verbosity of your code.  I wouldn't recommend it for lesser-known libraries, though, since that can lead to confusion.Converting a number to a String:In this case I think there has always been a better way of doing this:copying an existing array to a new array:::formerly, I had to explicitly create a new array and then copy the source elements to the new array (calling a method with a lot of parameters). now, the syntax is cleaner and the new array is returned from a method, I don't have to create it. by the way, the method  has a variation called , which copies a specific region of the source array (pretty much like ).The new -each construct to iterate over arrays and collection are the biggest for me.These days, when ever I see the boilerplate  loop to iterate over an array one-by-one using an index variable, it makes me want to scream:Replacing the above with the :Clean, concise, and best of all, it gives  to the code rather than showing  to do something. Clearly, the code has meaning to iterate over the collection, rather than the old  loop saying how to iterate over an array.Furthermore, as each element is processed independent of other elements, it may allow for future optimizations for parallel processing without having to make changes to the code. (Just speculation, of course.)Related to ; the utility method   which, starting from Java 5, takes varargs parameters is immensely useful.I often find myself simplifying something likeby usingAnnotationsI wonder no one mentioned it so far, but many frameworks rely on annotations, for example  and  It is common today to deprecate xml configuration files are in favor of annotations in code (though this means losing flexibility in moving from configuration to meta-code, but is often the right choice).The best example is EJB 2 (and older) compared to  and how programming EJB has been simplified thanks to annotations.  I find annotations also very useful in combination with some AOP tools like AspectJ or Spring AOP. Such combination can be very powerful. Changing JUnit 3-style tests:to JUnit 4-style tests:Improved singleton patterns.  Technically these are covered under the popular answer enums, but it's a significant subcategory.is cleaner and safer thanConverting classes to use generics, thereby avoiding situations with unnecessary casts.Okay, now it's my turn to get yelled at.I don't recommend 90% of these changes.It's not that it's not a good idea to use them with new code, but breaking into existing code to change a for loop to a for(:) loop is simply a waste of time and a chance to break something. (IIWDFWI) If it works, don't fix it!If you are at a real development company, that change now becomes something to code-review, test and possibly debug.If someone doing this kind of a refactor for no reason caused a problem of ANY sort, I'd give them no end of shit.On the other hand, if you're in the code and changing stuff on that line anyway, feel free to clean it up.Also, all the suggestions in the name of \"Performance\" really need to learn about the laws of optimization.  In two words, Don't!  Ever!  (Google the \"Rules of optimization if you don't believe me).I'm a little wary to refactor along these lines if that is all you are doing to your source tree.  The examples so far do not seem like reasons alone to change any working code base, but maybe if you are adding new functionality you should take advantage of all the new stuff. , they are just using the more manageable constructs of newer JDKs to .Most ways to make your code elegant are not in the JDK.Using Swing's new  to sort tables versus rolling your own from scratch.New version of Java rarely break existing code, so just leave old code alone and focus on how the new feature makes your life easier.If you just leave old code alone, then writing new code using new features isn't as scary.String comparisons, really old school Java programmers I've met would do:(Supposedly for performance reasons)Whereas these days most people just do:Using Vector instead of the new Collections.Using classes instead of enumsUsing Thread instead of the new java.util.concurrency package.It is worth noting that Java 5.0 has been out for five years now and there have only been minor changes since then.  You would have to be working on very old code to be still refactoring it."},
{"body": "I have been battling the ; the  method is excessively slow to detect printers in our application with the initial run-in. Clients with more than 100 network printers have reported that behaviour that executes this code is poorly performing the first time it is run.After seeing that the look-up results are being cached, I have initially deployed a dummy look-up within a separate thread (executed at start-up). However, for a particular client this solution is not working. I do not currently have their environment and cannot see what is causing the exact performance problem.I am trying to see if a  supports a given   performing a look-up of  and . So I pull all available s and the default :And then, obtain the  and the  from the client request. Finally, I ask the  if the  is supported by:The  declares that when  is called with null  and  and has behaved correctly up until now. However, I am not entirely sure if this is the way to perform if a printer supports a selected page size. I would appreciate your feedback and experience on this issue. Around the time I implemented my approach, my workstation decided to have serious network issues, which took me awhile to figure out. Finally, my implementation has been tested with the networking tool  (to simulate network load) and the results have not improved significantly.I will continue testing and update this question. Hopefully I can find a solution and share it with people here. I am guessing that the initial lookup:is still causing issues.The beta build is finally tested on the client environment and performance of the printing dialog is about 5 times improved (the initial pull of printer now takes about 1 minute under the same environment compared to about 5 minutes). Still the initial wait time is not an acceptable amount of time, however, is the best I could do for now. We have also heard from the client that a print server is being used and following the suggestions in the comments (@Wardy), I will be moving on in this direction. Hopefully, we can leverage the advantages of the print server.More aggressive caching. Have the client perform the look-up once and persist the cache between restarts. Better yet, save the cache to a central data store which is accessible by all clients.I'm assuming that network printers and their capabilities don't change that often but you have to update the cache eventually, but the \"who\" and \"when\" is dependent on your environment. Updates to the cache can be made by a client that runs your current discovery in the background and if changes are detected updates the cache. If you have a central component that runs continuously anyway, that would be a good place where you can check in fixed intervals.If you have some kind of directory service you can compare its list of printers with you cache before contacting each printer to get its capabilities to lessen network and cpu load.If list of printers is stored in LDAP, you may try to lookup printers using ."},
{"body": "I have an issue with the following code, which I isolated to the most closed form, I am using Java 8, which is almost ready for launch (18 March 2014), so I expect no serious issues in the implementation itself, so it may/must be my own code:The code in itself may not make most sense, but that is because I have stripped a load of other irrelevant methods.However, when you observe the output, you see something strange, at a certain point, for me personally after 30 seconds, I see the following:The time when it switches from  to , seems to depend on the number of calls the method, as with longer sleeps in between, it takes longer to switch.I am running this, for full information on Windows 8 64-bit, with as :Can anyone explain to me what is going on?\nI'd also appreciate if others with Java 8 -any build-, could run and see if they have the same issue.Some more information after using this code:Output:I have also checked the  VM option, when this has been used, it returns  as expected.So the conclusion seems to be that in my particular use case, the interpreted and JIT compiled/inlined variants of the code are not the same and hence it is a possibility that after the interpreted code is compiled it switches from interpreted to compiled and thus clarifying the switch in output.Adding the  option to the actual program in which the bug occured, has also fixed the issue there.This is a known bug in Java8.See this Jira: ....I have reproduced this issue with:Claims that this issue is resolved in b127 are confusing since I see it clearly in b129 (unless I am confused about the JVM version conventions...)Adding System.out.println(System.getProperties());"},
{"body": "Sometimes you want to filter a  with more than one condition:or you could do the same with a complex condition and a  :My guess is that the second approach has better performance characteristics, but I don't  it.The first approach wins in readability, but what is better for the performance?The code that has to be executed for both alternatives is so similar that you can\u2019t predict a result reliably. The underlying object structure might differ but that\u2019s no challenge to the hotspot optimizer. So it depends on other surrounding conditions which will yield to a faster execution, if there is any difference.Combining two filter instances creates more objects and hence more delegating code but this can change if you use method references rather than lambda expressions, e.g. replace  by . That way you have eliminated the synthetic delegating method created for your lambda expression. So combining two filters using two method references might create the same or lesser delegation code than a single  invocation using a lambda expression with .But, as said, this kind of overhead will be eliminated by the HotSpot optimizer and is negligible.In theory, two filters could be easier parallelized than a single filter but that\u2019s only relevant for rather computational intense tasks.So there is no simple answer.The bottom line is, don\u2019t think about such performance differences below the odor detection threshold. Use what is more readable.In a Set, i have 10 thousand references to a distinct objects. Then i did the \"speed test\":After 10 executions the average time was 45,5 milliseconds. Next, i use multi filter():The average time was 44,7 milliseconds.Of course this is a test with simple operations, but i believe there is no difference, because, Stream uses internal iteration, unlike \"for\" loopings that uses external iteration, in other words, the looping happens only once and after completed the result is returned. It's likely that there is a difference in time that the compiler will take to read the filters, which is insignificant.This test shows that your second option can perform significantly better.  Findings first, then the code:now the code:"},
{"body": "I am using Java NIO for my socket connections, and my protocol is text based, so I need to be able to convert Strings to ByteBuffers before writing them to the SocketChannel, and convert the incoming ByteBuffers back to Strings.  Currently, I am using this code:This works most of the time, but I question if this is the preferred (or simplest) way to do each direction of this conversion, or if there is another way to try.  Occasionally, and seemingly at random, calls to  and  will throw a \n exception, or similar, even if I am using a new ByteBuffer object each time a conversion is done.  Do I need to synchronize these methods?  Any better way to convert between Strings and ByteBuffers?  Thanks!Check out the  and  API descriptions - You should follow a  to avoid this problem.  For example, for :By the way, this is the same approach I am using for NIO although some of my colleagues are converting each char directly to a byte in the knowledge they are only using ASCII, which I can imagine is probably faster.Unless things have changed, you're better off with Usually buffer.hasArray() will be either always true or always false depending on your use case. In practice, unless you really want it to work under any circumstances, it's safe to optimize away the branch you don't need.Answer by Adamski is a good one and describes the steps in an encoding operation when using the general encode method (that takes a byte buffer as one of the inputs)However, the method in question (in this discussion) is a variant of encode - . This is a . (Please see java docs reference in P.S.)As per the docs,  (which is what is happening in ZenBlender's code -- using static encoder/decoder in a multi threaded environment).Personally, I like to use  methods (over the more general encode/decode methods) as they take away the burden by performing all the steps under the covers. ZenBlender and Adamski have already suggested multiple ways options to safely do this in their comments. Listing them all here:P.S.java docs references:"},
{"body": "I've just replaced  in the following lambda expression by :Eclipse compiler says:I haven't found any explanation in the  Lexical Structure / Keywords.The place to look is So the Eclipse message is misleading, especially as the same message is used for both cases, when an error is generated for a lambda parameter or when a warning is generated for any other  identifier."},
{"body": "What does the term  mean? I couldn't find anything explanatory enough. says that POJO is an ordinary Java Object and not a special object. Now, what makes or what doesn't make and object special in Java?The above page also says that a POJO should not have to extend prespecified classes, implement prespecified Interfaces or contain prespecified Annotations. Does that also mean that POJOs are not allowed to implement interfaces like ,  or classes like Applets or any other user-written Class/Interfaces? Also, does the above policy (no extending, no implementing) means that we are not allowed to use any external libraries?Where exactly are POJOs used? To be more specific, am I allowed to extend/implement classes/interfaces that are part of the Java or any external libraries? The name is used to emphasize that a given object is an ordinary Java Object, not a special object such as those defined by the EJB 2 framework.class A {} \nclass B extends/implements C {}Note: B is non POJO when C is kind of distributed framework class or ifc. \ne.g. javax.servlet.http.HttpServlet,  javax.ejb.EntityBean or J2EE extn\nand not serializable/comparable. Since serializable/comparable are valid for POJO.  Here A is simple object which is independent. \nB is a Special obj since B is extending/implementing C. So B object gets some more meaning from C and B is restrictive to follow the rules from C. and B is with distributed framework. Hence B object is not POJO from its definition.Code using class A object reference does not have to know anything about the type of it, and It can be used with many frameworks.So a POJO should not have to 1) extend prespecified classes and 2) Implement prespecified interfaces.JavaBean is a example of POJO that is serializable, has a no-argument constructor, and allows access to properties using getter and setter methods that follow a simple naming convention. POJO purely focuses on business logic and has no dependencies on (enterprise) frameworks.\nIt means it has the code for business logic but how this instance is created, Which service(EJB..) this object belongs to and what are its special characteristics( Stateful/Stateless) it has will be decided by the frameworks by using external xml file. Example 1: JAXB is the service to represent java object as XML;  These java objects are simple and come up with default constructor getters and setters.\n Example 2: Hibernate where simple java class will be used to represent a Table. columns will be its instances.\nExample 3: REST services. In REST services we will have Service Layer and Dao Layer to perform some operations over DB. So Dao will have vendor specific queries and operations. Service Layer will be responsible to call Which DAO layer to perform DB operations. Create or Update API(methods) of DAO will be take POJOs as arguments, and update that POJOs and insert/update in to DB. These POJOs (Java class) will have only states(instance variables) of each column and its getters and setters.In practice, some people find annotations elegant, while they see XML as verbose, ugly and hard to maintain, yet others find annotations pollute the POJO model.\nThus, as an alternative to XML, many frameworks (e.g. Spring, EJB and JPA) allow annotations to be used instead or in addition to XML:\nDecoupling the application code from the infrastructure frameworks is one of the many benefits of using POJOs. Using POJOs future proofs your application's business logic by decoupling it from volatile, constantly evolving infrastructure frameworks. Upgrading to a new version or switching to a different framework becomes easier and less risky. POJOs also make testing easier, which simplifies and accelerates development. Your business logic will be clearer and simpler because it won't be tangled with the infrastructure code References :  , he and some others came up with it as a way to describe something which was a standard class as opposed to an EJB etc.Usage of the term implies what it's supposed to tell you. If, for example, a dependency injection framework tells you that you can inject a POJO into any other POJO they want to say that you do not have to do anything special: there is no need to obey any contracts with your object, implement any interfaces or extend special classes. You can just use whatever you've already got. To give another example: while Hibernate can map any POJO (any object you created) to SQL tables, in Core Data (Objective C on the iPhone) your objects have to extend NSManagedObject in order for the system to be able to persist them to a database. In that sense, Core Data cannot work with any POJO (or rather POOCO=PlainOldObjectiveCObject) while Hibernate can. (I might not by 100% correct re Core Data since I just started picking it up. Any hints / corrections are welcome :-) ).Plain Old Java Object :)Well, you make it sound like those are all terrible restrictions.In the usual context where POJO is/are used, it's more like a benefit:It means that whatever library/API you're working with is perfectly willing to work with Java objects that haven't been doctored or manhandled in any way, i.e. you don't have to do anything special to get them to work.For example, the XStream XML processor will (I think) happily serialize Java classes that don't implement the  interface. That's a plus! Many products that work with data objects used to force you to implement  or even extend an  class. Many libraries will expect bean behavior, i.e. getters and setters.Usually, whatever works with POJOs will also work with not-so-PO-JO's. So XStream will of course also serialize Serializable classes.POJO is a Plain Old Java Object - as compared to something needing Enterprise Edition's (J2EE) stuff (beans etc...).POJO is not really a hard-and-fast definition, and more of a hand-wavy way of describing \"normal\" non-enterprise Java Objects. Whether using an external library or framework makes an object POJO or not is kind of in the eye of the beholder, largely depending on WHAT library/framework, although I'd venture to guess that a framework would make something less of a POJOThe whole point of a POJO is simplicity and you appear to be assuming its something more complicated than it appears. If a library supports a POJO, it implies an object of any class is acceptible.  It doesn't mean the POJO cannot have annotations/interface or that they won't be used if they are there, but it is not a requirement. IMHO The wiki-page is fairly clear. It doesn't say a POJO cannot have annotations/interfaces.A Plain Old Java Object (POJO) that contains all of the business logic for your extension.Exp. Pojo which contains a single method was coined by Martin Fowler, Rebecca Parsons and Josh Mackenzie when they were preparing for a talk at a conference in September 2000. Martin Fowler in  explains how to implement a  pattern in Java. After enumerating some of disadvantages of using :As an alternative, he proposed to use  for Domain Model implementation:"},
{"body": "I realize that to become a better programmer, you need to program!\nSo obviously the more practice, the better you become. My problem is this. I am currently in university, and I find my course load is a bit daunting, and I don't have a lot of free time. I don't think I could really take on a big project, particularly I don't think I would have to motivation to see it through, it would be easier just for me to keep putting it off in favour of work that is due is school.But I still want to practice. \nSo I am looking for any resources which have programming challenges which can be completed in a fairly small amount of time. Ideally something i could get done in under 10 hours of work (so just over an hour of work each day), if not smaller. I have heard of Google Code Jam, but I am not sure the length of the programs it specifies, nor the skill level. Does anyone have suggestions? Even perhaps a compendium of tutorials for different functions might be useful. For example, a tutorial on file IO would be worthwhile (if I didn't already know it), even though it can be a fairly small topic.You should look into , they do exactly what you are talking about.  Short exercises that are designed to perfect your coding/thining abilities.Other references: has some math/number related problems that are very interesting and ranged from easy to very challenging. You can pick your language of choice and submit only the solution (a large integer number). After you submitted the correct solution, you have access to a forum/comment page where others posted their comments and solutions.From experience I recommend finding a task that you do repetitively and turning it into a program. I also recommend, seriously, re-invent the wheel in order to get practice with programming. Don't let people tell you to not do something just because it exists already. If you don't know how it works, try to write it yourself. I don't exactly know what programming level you are on, but don't try to do anything too crazy off the bat, that is just a demotivator (such as trying to write a game for the PS3).If you already can navigate your way around with IO, then you should try to really learn how to use Collections effectively. I think one of the best practice assignments I have ever done was rewriting the Java TreeMap Class. It was a huge challenge and I learned a lot by doing it.Here are some suggestions for practice assignments:Take a text file that has a fair amount of information in it, grab anything, you can get something from here if you'd like:  and make a program that will do the following:One of my favorite things to do is mess with web data, go to a polling website, find a page that has poll data in a tabular form and do the following:Or just look for any site and extract data from it, just make sure the site is robot friendly , you don't want any one site to feel like it is under attack. Most of the time though this isn't normally a problem because if you read the site's terms of use it clearly states you are allowed to download 1 copy of whatever it is you are viewing so long as you don't intend to sell it. Of course this changes for every site.Go to a website and get all of the links off of the page programmatically.Here is a fun one, the Susan Program (I don't remember why it is named Susan) which I initially wrote using a C program and two Bourne shell scripts in a Unix environment. The idea in this program is to fork 4 child processes and give them each a task like so:Child 1: Reads in a file, creates a dictionary of each word and its position in the file, this is outputted to a file.Child 2: Takes Child 1's output and reconstructs the document, this is outputted to a file.Child 3: Takes Child 2's output and does what child 1 did againChild 4: Takes Child 3's output and does what child 2 did againThe goal here is to have an exact replica of the original file once Child 4 outputs it. This is challenging and somewhat pointless, but the point of this exercise is to get the practice.In your case, don't feel that you need to use different threads for this, you can just use a single program with two different functions and just call them in order.Again, not sure if you are at this level yet, but try to replace any \"for\" or \"foreach\" loop you have in your program with recursion, just as practice. Recursion is a pain in the butt, but it is valuable to know and understand.These are some suggestions which I think will really help you sharpen your skills.EnjoyI like  and  to take quick programming challenges and exercises.Code Jam is a good programming contest, although, as you mentioned, most of the problems there aren't for beginners.There's a good selection of problems from past topcoder algorithm competitions. (They are held ~2 times a month for almost 10 years already, so there're quite a lot.)\nDifficulty range from  (but still interesting) problems in the 2nd division to very hard.\nAdditionally, there're  with solutions and live environment where you can submit and test your code. You can also learn from submissions by other people.Check .\nAnother advantage of topcoder is the regular online contests they hold. I find that competing against other people in realtime is a great boost for motivation.There're many more problem archives, like ,  and , although they rarely provide solutions or even hints. might have some programming challenges to your liking.  A lot of the answers on that site are golfed (they implement the program in the least number of characters) but there are definitely some interesting examples to learn from.Try enrolling on any IT course on the following websites:These websites offer free educational IT programs from prestigious schools wherein there are lot of challenging exercises to sharpen your programming skills. I've learned to program percolation, pattern recognition, bouncing ball and so many more interesting things because of this. You will upload your program upon completion of the exercises and you will be graded accordingly (basically your progam will be checked).At the end of each course, you will even receive a certificate of completion. Cool Right?It depends of the language, but in the past  and  did great for me, also you can join to an open source initiative because usually helps to give you better code review chances.I've always thought that practicing with sample interview questions was a great way to sharpen one's skills and get exposed to types of problems that you normally wouldn't solve. Plus, if you're going to be looking for a job it helps you even more.Here's a pretty simple one that I did for fun the other day:Glassdoor.com has a lot of good interview question submitted by people who actually got them in an interview.Since you are in University and looking to improve your coding skills the hard-copy book  might be a good fit for you.  It's got great general programming questions and tidbits about interviewing with some of the best companies in tech.   Not only are there great questions, but there are decent problem breakdowns as well.[Disclosure: I own the book but otherwise have no association to it.]If you like programming and want to improve your programmer skills, you must try . It's a social young site, similar to StackOverflow but based on posting and solving programming challenges, instead of asking and answering questions. From very easy challenges to very hard ones.You can try to solve ACM problems. There are thousands of problems there and you can find the difficulty level so you can choose which problems to do first. The offcial site for this is: .  You can learn more there.regards\narefinIt may seem a little obvious, but I've noticed a real boost in my regular-expressions skills lately just from answering regex questions on Stack Overflow. Teaching forces you to break down problems into easily explainable pieces, and will also guide your research on those occasions where you know most, but not quite all, of a solution.I suggest finding a topic you're already somewhat proficient in, since this type of thing isn't so good as a beginners' tutorial. Search SO for questions tagged with that topic and try to figure out the answers. Don't just code them in your head; go ahead and write them out, test them, and explain them. If you're not sure your answer is correct, just write it without posting it."},
{"body": "I have a java class that does a binary sum, I am still trying to figure out how to do unit tests but I don't know how to do it. I've googled around and the best explanation I had was the page from Wikipedia: but I'm still unsure how to do my test for this program. What the program does is basically take 2 byte[] and add them and return the new binary array. Written in Java. How can I test it?For making unit test for your project, please follow these steps (I am using Eclipse in order to write this test):1- Click on New -> Java Project.2- Write down your project name and click on finish.3- Write click on your project. Then, click on New -> Class.4- Write down your class name and click on finish.Then, complete the class like this: 5- Click on File -> New -> JUnit Test Case.6- Check setUp() and click on finish. SetUp() will be the place that you initialize your test.7- Click on OK.8- Here, I simply add 7 and 10. So, I expect the answer to be 17. Complete your test class like this:9- Write click on your test class in package explorer and click on Run as -> JUnit Test.10- This is the result of the test.I hope it helps.This is a very generic question and there is a lot of ways it can be answered.If you want to use JUnit to create the tests, you need to create your testcase class, then create individual test methods that test specific functionality of your class/module under tests (single testcase classes are usually associated with a single \"production\" class that is being tested) and inside these methods execute various operations and compare the results with what would be correct. It is especially important to try and cover as many corner cases as possible.In your specific example, you could for example test the following:To verify the results, you can use various assertXXX methods from the org.junit.Assert class (for convenience, you can do 'import static org.junit.Assert.*'). These methods test a particular condition and fail the test if it does not validate (with a specific message, optionally).Example testcase class in your case (without the methods contents defined):If you are not used to writing unit tests but instead test your code by writing ad-hoc tests that you then validate \"visually\" (for example, you write a simple main method that accepts arguments entered using the keyboard and then prints out the results - and then you keep entering values and validating yourself if the results are correct), then you can start by writing such tests in the format above and validating the results with the correct assertXXX method instead of doing it manually. This way, you can re-run the test much easier then if you had to do manual tests.Like @CoolBeans mentioned, take a look at . Here is a short  to get you started as well with jUnit 4.xFinally, if you really want to learn more about testing and test-driven development (TDD) I recommend you take a look at the following book by Kent Beck: .Create a Class in Java to add 2 numbers and then you can create jUnit to create Test Cases for that class. You have to assert the expected vs actual output from the tests. It's really that simple."},
{"body": "I've been working with the new , and I've come across what seems like a common operation that isn't supported functionally: an \"orElseOptional\"Consider the following pattern:There are many forms of this pattern, but it boils down to wanting an \"orElse\" on an optional that takes a function producing a new optional, called only if the current one does not exist.It's implementation would look like this:I'm curious if there's a reason such a method doesn't exist, if I'm just using Optional in an unintended way, and what other ways people have come up with to deal with this case.I should say that I think that solutions involving custom utility classes/methods aren't elegant because people working with my code won't necessarily know they exist.Also, if anyone knows, will such a method be included in JDK 9, and where might I propose such a method? This seems like a pretty glaring omission to the API to me.This is part of JDK 9 in the form of , which takes a . Your example would then be:For details see  or  I wrote.The cleanest \u201ctry services\u201d approach given the current API would be:The important aspect is not the (constant) chain of operations you have to write once but how easy it is to add another service (or modify the list of services is general). Here, adding or removing a single  is enough.Due to the lazy evaluation of streams, no service will be invoked if a preceding service returned a non-empty .It's not pretty, but this will work: is a fairly handy pattern for use with .  It means \"If this  contains value , give me , otherwise give me \".  In this case, we call  and get an .  If that  contains value , we want to get , but if it is empty, we want to get . Rinse-repeat with more alternatives.Other uses of this pattern are Perhaps this is what you're after: Otherwise, you may want to have a look at . Here's an example of what I  that you're after:This is looks like a good fit for pattern matching and a more traditional Option interface with Some and None implementations (such as those in , ) or a lazy  implementation in .I'm the author of this library. With  you can also use structural  on JDK types. For Optional you can match on the present and absent cases via the .  it would look something like this -"},
{"body": "I am testing our server-application (written Java) on different operating systems and thought that OpenSolaris (2008.11) would be the least troublesome due to the nice Java integration. Turns out I was wrong, as I end up with a UnknownHostExceptionThe output is:However,  returns the correct IP address, and  returns  as expected. Also, the same code works perfectly on FreeBSD. Is there anything special to OpenSolaris that I am not aware of?Any hints appreciated, thanks.In good tradition I can answer my own question once again:It seems that  ignores the /etc/resolv.conf but only looks at the /etc/hosts file (where I hadn't specified anything besides localhost). Adding the IP and hostname to this file solves the problem and the exception is gone.Above answer is almost correct and I got hint from above and my problem get resolved...Thanks.But to improve this, I am adding steps-by-steps changes, so that it will be helpfull for even naive users.Steps:Now, overall file may look like this:Host lookups on Solaris uses  so depending on what the 'hosts:' line says it determines if , NIS, DNS and/or LDAP should be consulted.If you only use hosts and DNS you should have this in :The reason  works is because the  command directly consults . If you want to do a better command line test, use the command:Checkout  then put your hostname to hosts file.I use  as a fall back for when  throws an .  Here's the code (without exception handling for clarity).This errors shows up when I changed the workstation name and tried start Glassfish 2. You also must rename the entry at /etc/hosts, something like this:If you see this message than you need set hostname   ! After this, check which  file contain string like this .Also, check that command  returns something like this:Another option is in this post (in fact, what is in your /etc/sysconfig/network file for your hostname...by changing it to an FQDN name fixes this issue).I am having issues around this as well.  I need to do further testing, but it looks like\n can be more reliable.  I think that this does not do the lookup, but just grabs the IP.I am using it as the 'next best' when the  fails."},
{"body": "What is the difference between these 2? I found few results on google nothing conclusive. Here is a follow up question: Say I create spring mvc web app annotate couple of classes with @Controller annotation and create something that will successfully transfer some information from front end -> back end and vice versa and perhaps some database might be involved on the back end side. What would you call that? Rest web service or servlet or something else ?A  is a service that provides service methods to its clients using either the REST programming paradigm or the SOAP protocol for communication. There are several ways to implement a web service. The most simple way to write a web service would be to write a class and annotate it with the  and  annotations from , and then launch it from a -method with:The result is that you can view the  at the registered URL and if you have SoapUI or any other SOAP client you can also test and use your web service.A  on the other hand is used to transport  requests and resonses. It can be used to write a web application with JSPs and HTML, or to serve XML and JSON responses (as in a RESTful service) and of course also to receive and return SOAP messages. You can think of it as . Servlets have their own standard which is currently the A more comprehensive and practical approach is to write a web service with a framework and to publish it on an application server or servlet container such as Tomcat or JBoss. In this case you would use a Servlet to handle the transport of the HTTP requests which transmit your SOAP or REST messages.To write a web service with servlet technology you can for example use JAX-WS (e.g. for SOAP). In order to write RESTful services, you can either use JAX-RS (with the reference implementation being ), or alternatively you can use , but afaik that is not the main purpose of this framework and Jersey is considerably easier to use.Regarding the second question:\nThe  annotation is a  specific stereotype annotation that tells Spring something about what your bean is supposed to do. What exactly a method of a controller will return depends on the actual implementation of your methods, you can configure Spring to return plain text, HTML, JSON, XML, binary data or what ever you want.A note on the side, a class that is annotated with  is not yet a servlet, it is simply a bean. How you use servlets depends mainly on the Framework that you use. For example, when you use Spring, the servlet job is done by Springs  which in turn forwards requests to the correct beans. If you use Tomcat, then you can directly write your own servlets by simply subclassing the  class and overwriting the necessary methods such as  which responds to HTTP GET requests from your browser.What you're describing is a , where a human uses a browser to interact with a software system. A  is a way for software systems to communicate with each other using HTTP and XML or JSON, without any humans involved.A  is a Java-specific way of writing software that responds to HTTP requests. Spring MVC abstracts away a lot of the implementation detail to make writing web applications easier, but uses servlets under the covers.My take on it would be that Web Service defines higher level abstraction such as some business specific functionality. While Servlet is just a software implementation component responsible for transport of data.Web Service implementation would typically rely on servlet for receiving data. However, it can as well use it's custom layer of dealing with protocol data.@Controller is probably more related to Web Service than servlet which is,again, a way to implement transport.A servlet is an HTTP query handler. You can do what you want with your incoming queries. A servlet run on the JVM.A web service is tied to a more or less rigid protocol: An interface (API) is defined with available methods and their arguments and return values for the service.This interface is exposed using the protocol mechanisms. These protocols are agnostic about the host that will run the service: you can define the same web service using PHP, Java, C# or your own language. You only need to have a piece of code able to understand queries for the protocol and able to produce answers readable by the client.For example  is a web service protocol:\nWikipedia definition:Web services operate on a higher level than servlets. Servlets are API which is simple and provides capabilities to write server side components.For example RESTfull is a Web Service which contains many other \"functionality\" along with servlet.\nTo deploy, we may define the web.xml as -which is none but a servletThe most obvious difference between Servlet and Web Service is: \nYou access servlet via HTTP while access Web Service via SOAP (Simple Object \nAccess Protocol). \nBut, in fact, you can not directly invoke a servlet, you can only open URL \nconnection and put some parameter to the servlet if the caller is out of \nyour application. And you can not restrict what parameters the caller can \nput. The caller does not know what parameters your servlet can receive \neither. \nSo, You'd better use web service to provide API to other applications, the \nWSDL file of your web service can give the caller enough information to \ninvoke your web service.Web Service uses ServletContainer class which is again a Servlet class, which handles the request in clean and structured way. \nThe REST stands for REpresentational STateless Protocol. Here the request won't store any data.The REST Web Service supports HTTP methods We can map any number of URLs to Web Service class which can have any type of HTTP methods.On other hand, there can be only 1 URL mapping can be done for each servlet.\nThough the end requirement can be achieved with the help of request parameter conditions, but using servlet nowadays won't provide clean way.In webservice we can define URL path at  as well as , which allows us to code in more structured way."},
{"body": "there is a rule which says:that works fine for primitive types like int or strings:But what's about non primitive types? In most cases I've seen the following:or in singletons, where instance variable is not in upper case.The question is what is the right way to declare those types of variables (like log and instance)?That's still a . See the  for more information regarding the naming convention for constants. But in reality, it's all a matter of preference.The dialog on this seems to be the antithesis of the conversation on naming  and  classes. I find this alarming, and think that the decision runs much deeper than simply choosing one naming convention and using it always with .When naming interfaces and abstract classes, the accepted convention has evolved into not prefixing or suffixing your  or  with any identifying information that would indicate it is anything other than a class.The developer is said not to need to know that the above classes are  or an .My personal preference and belief is that we should follow similar logic when referring to  variables. Instead, we evaluate its usage when determining how to name it. It seems the all uppercase argument is something that has been somewhat blindly adopted from the C and C++ languages. In my estimation, that is not justification to continue the tradition in Java.We should ask ourselves what is the function of  in our own context. Here are three examples of how  may be used in :Could you use all uppercase in all three scenarios? Absolutely, but I think it can be argued that it would detract from the purpose of each. So, let's examine each case individually.In the case of the  example above, the logger is declared as private, and will only be used within the class, or possibly an inner class. Even if it were declared at  , its usage is the same:Here, we don't  that  is a  member variable. It could simply be a  instance variable. We don't know. We don't need to know. All we need to know is that we are logging the message to the logger that the class instance has provided.You wouldn't name it  in this scenario, so why should you name it all uppercase if it was ? Now you might say, why are you using  integers as an ? That is a   and I'd even say semi-controversial, so I'll try not to derail this discussion for long by venturing into it. However, it would be suggested that you could implement the following accepted enum pattern:There are variations of the above that achieve the same purpose of allowing explicit conversion of an  and . In the scope of streaming this information over a network, native Java serialization is simply too verbose. A simple , , or  could save tremendous bandwidth. I could delve into a long winded compare and contrast about the  of  vs  involving type safety, readability, maintainability, etc.; fortunately, that lies outside the scope of this discussion.If you can bring yourself to accept that the above statement is , we can follow that up with a discussion of style. When declaring an , the accepted style says that we don't do the following:Instead, we do the following:If your  block of integers serves as a loose , then why should you use a different naming convention for it? This usage case is perhaps the most cloudy and debatable of all. The static constant  usage example is where this is most often encountered. Java , but there are times when it is important to know how many bytes a data structure will occupy. For example, consider you are writing or reading a list of data structures to a binary file, and the format of that binary file requires that the total size of the data chunk be inserted before the actual data. This is common so that a reader knows when the data stops in the scenario that there is more, unrelated, data that follows. Consider the following made up file format:This file contains a list of  objects serialized into a byte stream and written to this file. This file has 325 bytes of  objects, but without knowing the size of each  you have no way of knowing which bytes belong to each . So, you define the size of  on :The  data structure will occupy 13 bytes when written to the file as defined above. Knowing this, when reading our binary file, we can figure out dynamically how many  objects follow in the file:This seems to be the typical usage case and argument for all uppercase  constants, and I agree that in this context, all uppercase makes sense. Here's why:Java doesn't have a  class like the C language, but a  is simply a class with all public members and no constructor. It's simply a data ure. So, you can declare a  in  like fashion:Let me preface this example by stating I personally wouldn't parse in this manner. I'd suggest an immutable class instead that handles the parsing internally by accepting a  or all 4 variables as constructor arguments. That said, accessing (setting in this case) this s members would look something like:These aren't  or , yet they are publicly exposed members that can be directly set. For this reason, I think that when a  member is exposed publicly, it makes sense to uppercase it entirely. This is the one time when it  important to distinguish it from public, non-static variables.In conclusion, the convention you choose for  variables is going to be your preference, but I strongly believe that the context of use should heavily weigh on your design decision. My personal recommendation would be to follow one of the two methodologies:Methodology 2 basically condenses its context into visibility, and leaves no room for interpretation.This is how I view the naming convention of  variables. I don't think it is something that can or should be boxed into a single catch all. I believe that you should evaluate its intent before deciding how to name it.(I do expect to be met with resistance, but also hope to gather some support from the community on this approach. Whatever your stance, please keep it civil when rebuking, critiquing, or acclaiming this style choice.)Well that's a very interesting question. I would divide the two constants in your question according to their type.  is a constant of primitive type while  is a non-primitive type.When we are making use of a constant of a primitive types, we are mutating the constant only once in our code  and we are just accessing the value of the constant elsewhere . This is the reason we are comfortable with using this convention.While in the case of non-primitive types, although, we initialize the constant in only one place , we are expected to mutate or call a method on this constant elsewhere . We guys don't like to put a dot operator after the capital characters. After all we have to put a function name after the dot operator which is surely going to be a camel-case name. That's why  would look awkward.Same is the case with  types. We are usually not mutating or calling a method on a  constant in our code and that's why we use the capital naming convention for a  type object.The language doesn't care. What's important is to follow the established styles and conventions of the project you're working on, such that other maintainers (or you five months from now) have the best possible chance of not being confused.I think an all-uppercase name for a mutable object would certainly confuse me, even if the reference to that object happened to be stored in a  variable.There is no \"right\" way -- there are only conventions. You've stated the most common convention, and the one that I follow in my own code:  static finals should be in all caps. I imagine other teams follow other conventions.A constant reference to an object is not a constant, it's just a constant reference to an object. is not what defines something to be a constant or not. It's just the Java way to define a constant, but it doesn't mean that every  declaration was put there to define a constant.When I write  I'm not trying to define a constant, I'm just trying to define a reference to an object that is  (that it is not accessible from other classes),  (that it is a class level variable, no instance needed) and  (that can only be assigned once). If it happens to coincide with the way Java expects you to declare a constant, well, bad luck, but it doesn't make it a constant. I don't care what the compiler, sonar, or any Java guru says. A constant value, like  is one thing, and a constant reference to an object is another. Gold is known to shine, but not everything that shines is gold.These variables are constants, i.e.  whether they're named in all caps or not.  The all-caps convention simply makes it more obvious that these variables are meant to be constants, but it isn't required.  I've seen in lowercase before, and I'm fine with it because I know to only use the logger to log messages, but it does violate the convention.  You could argue that naming it  is a sub-convention, I suppose.  But in general, naming constants in uppercase isn't the One Right Way, but it is The Best Way.In my opinion a variable being \"constant\" is often an implementation detail and doesn't necessarily justify different naming conventions. It may help readability, but it may as well hurt it in some cases.Don't live fanatically with the conventions that SUN have med up, do whats feel right to you and your team.Update: There were special cases that was excluded didn't know that. I however withholds to do what you and your team seems fit."},
{"body": "I have a method that returns void in a class that is a dependency of the class I want to test.This class is huge and I'm only using this single method from it.\nI need to replace the implementation of this method for the test as I want it to do something different and I need to be able to access the parameters this method receives.I cannot find a way of doing this in . I think I know how to do it with  by using  but I don't want to add another library unless absolutely necessary. If I understand what you want to do correctly, you should be able to use :The  explains:If you just call the void method for each time you're expecting it to be invoked and then invoke  prior to calling , Easymock will \u201cremember\u201d each invocation.So I don\u2019t think you need to explicitly call  (other than ) since you\u2019re not expecting anything from a void method, except its invocation.Thanks Chris! by fellow StackOverflow user  is a good blog post that provides more detail. Notable excerpt:If you only want access to the parameters for later, you might also appreciate the  class which is new to EasyMock 2.4.You can use an instance of the \"Capture\" class in place of a matcher. When your mocked method is invoked, the Capture instance will store the parameter it was invoked with.You might want to check out PowerMock. EasyMock is based on the proxy reflection API meaning everything is a proxy and you can only test interfaces, and thus only non-final methods and classes. This might work for some, but if you're testing the world as built, you'll need more power.With PowerMock the Java 5 instrumentation API removes the limitations. No need to write mock object implementations of the object to be tested (just ugly IMO). Couple PowerMock with Mockito (or JMockit) and you'll really be off to the races.Of course, there is the other direction of rewriting your code to be more easily tested, which is generally a good idea too, if possible.In situations like these I've found that making a nested class in my unit test class and overriding the methods with special requirements in that way is the best route. So if you're testing  which has that method with the parameters you need to access, you'd do something like:In my unit testing code, I then just use this instance instead. Just treat it as if it was any other mock object. Much easier than mixing libraries, which I agree is probably not a good idea."},
{"body": "I have a parsing function that parses an encoded length from a byte buffer, it returns the parsed length as an int, and takes an index into the buffer as an integer arg.  I want the function to update the index according to what it's parsed, i.e. want to pass that index by reference.  In C I'd just pass an .\nWhat's the cleanest way to do this in Java?\nI'm currently looking at passing the index arg. as an , but it's a bit ugly.You can try using  from Apache Commons library.  There is no direct way of doing this in the language itself.This isn't possible in Java. As you've suggested one way is to pass an . Another would be do have a little class e.g.  that wrapped an .Wrap the byte buffer and index into a  object. A ByteBuffer encapsulates the concept of a buffer+position and allows you to read and write from the indexed position, which it updates as you go along.You cannot pass arguments by reference in Java.What you can do is wrap your integer value in a mutable object. Using Apache Commons'  is a good option. Another, slightly more obfuscated way, is to use an  like you suggested. I wouldn't use it as it is unclear as to why you are wrapping an  in a single-celled array.Note that  is immutable.You can design new class like this:later you can create object of this class :then you can pass  as argument where you want to pass an integer variable:so for update the integer value:for getting value:You can use .You can create a Reference class to wrap primitives:Then you can create functions that take a Reference as a parameters:Usage:Hope this helps."},
{"body": "I want to encrypt a string using AES with my own key. But I'm having trouble with the bit length of the key. Can you review my code and see what I need to fix/change.Right now I get an exception \"\". Do I need to pad my key? How should I do it?Also do I need to set anything for ECB or CBC?ThanksYou should use SHA-1 to generate a hash from your key and trim the result to 128 bit (16 bytes).Additionally don't generate byte arrays from Strings through  it uses the platform default Charset. So the password \"bla\u00f6\u00e4\" results in different byte array on different platforms.Edit:\nIf you need 256 bit as key sizes you need to download the \"Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files\" , use SHA-256 as hash and remove the  line.\n\"ECB\" is the default Cipher Mode and \"PKCS5Padding\" the default padding.\nYou could use different Cipher Modes and Padding Modes through the  string using following format: \"Cipher/Mode/Padding\"For AES using CTS and PKCS5Padding the string is: \"AES/CTS/PKCS5Padding\"You should use a KeyGenerator to generate the Key, AES key lengths are 128, 192, and 256 bit depending on the cipher you want to use.Take a look at the tutorial  Here is the code for Password Based Encryption, this has the password being entered through System.in you can change that to use a stored password if you want. This wll work."},
{"body": "How can I check to make sure my variable is an int, array, double, etc...? Edit: For example, how can I check that a variable is an array? Is there some function to do this?Java is a statically typed language, so the compiler does most of this checking for you.  Once you declare a variable to be a certain type, the compiler will ensure that it is only ever assigned values of that type (or values that are sub-types of that type).The examples you gave (int, array, double) these are all primitives, and there are no sub-types of them.  Thus, if you declare a variable to be an :You can be sure it will only ever hold  values.If you declared a variable to be a , however, it is possible that the variable will hold sub-types of .  Examples of these include , , etc.If you did have a  variable, and you needed to know if it was an , you could do the following:However, if you find yourself thinking you need to do that, you may want to re-think your approach.  In most cases, if you follow object-oriented principals, you will not need to do this.  There are, of course, exceptions to every rule, though.Actually quite easy to roll your own tester, by abusing Java's method overload ability. Though I'm still curious if there is an official method in the sdk.Example:then:You may work with Integer instead of int, Double instead of double, etc. (such classes exists for all primitive types).\nThen you may use the operator instanceof, like a.getClass().getName() - will give you the datatype of the actual object referred to by a, but not the datatype that the variable, a, was originally declared as or subsequently cast to.boolean b = a instanceof String - will give you whether or not the actual object referred to by a is an instance of a specific class.\nAgain, the datatype that the variable, a, was originally declared as or subsequently cast to has no bearing on the result of the instanceof operator.I took this information from:\nThis can happen. I'm trying to parse a String into an int and I'd like to know if my Integer.parseInt(s.substring(a, b) is kicking out an int or garbage before I try to sum it up.By the way, this is known as reflection. Here's some more information on the subject: The first part of your question is meaningless. There is no circumstance in which you don't know the type of a primitive variable at compile time.Re the second part, the only circumstance that you don't already know whether a variable is an array is if it is an Object. In which case  will tell you.I did it using: Well, I think checking the type of variable can be done this way. public  void checkType(T object) {This way you need not have multiple overloaded methods. I think it is good practice to use collections over arrays due to the added benefits. Having said that, I do not know how to check for an array type. Maybe someone can improve this solution. Hope this helps! P.S Yes, I know that this doesn't check for primitives as well. public class Demo1\n{}"},
{"body": "So I'm drawing this triangle in android maps using the code below in my draw method:The pointX_returned are the coordinates which I'm getting from the fields. They are basically latitudes and longitudes.\nThe result is a nice triangle but the insider is empty and therefore I can see the map. Is there a way to fill it up somehow? You probably need to do something like :And use this color for your path, instead of your ARGB. Make sure the last point of your path ends on the first one, it makes sense also.Tell me if it works please !Ok I've done it. I'm sharing this code in case someone else will need it:Thanks for the hint Nicolas!you can also use vertice : this function shows how to create a triangle from bitmap. That is, create triangular shaped cropped image. Try the code below or The function above returns an triangular image drawn on canvas. You need remove path.moveTo after first initial.Using @Pavel's answer as guide, here's a helper method if you don't have the points but have start x,y and height and width. Also can draw inverted/upside down - which is useful for me as it was used as end of vertical barchart. "},
{"body": "An Enum in Java implements the Comparable interface.  It would have been nice to override Comparable's compareTo method, but here it's marked as final.  The default natural order on Enum's compareTo is the listed order.  Does anyone know why a Java Enum has this restriction?For consistency I guess... when you see an  type, you know  that its natural ordering is the order in which the constants are declared.To workaround this, you can easily create your own  and use it whenever you need a different ordering:You can use the  directly:or use it in collections or arrays:Further information:Providing a default implementation of compareTo that uses the source-code ordering is fine; making it final was a misstep on Sun's part.  The ordinal already accounts for declaration order.  I agree that in most situations a developer can just logically order their elements, but sometimes one wants the source code organized in a way that makes readability and maintenance to be paramount.  For example:The above ordering looks good in source code, but is not how the author believes the compareTo should work.  The desired compareTo behavior is to have ordering be by number of bytes.  The source-code ordering that would make that happen degrades the organization of the code.  As a client of an enumeration i could not care less how the author organized their source code.  I do want their comparison algorithm to make some kind of sense, though.  Sun has unnecessarily put source code writers in a bind.Enumeration values are precisely ordered logically according to the order they are declared. This is part of the Java language specification. Therefore it follows that enumeration values can only be compared if they are members of the same Enum. The specification wants to further guarantee that the comparable order as returned by compareTo() is the same as the order in which the values were declared. This is the very definition of an enumeration.One possible explanation is that  should be consistent with .And  for enums should be consistent with identity equality ().If  where to be non-final it would be possible to override it with a behaviour which was not consistent with , which would be very counter-intuitive.If you want to change the natural order of your enum\u2019s elements, change their order in the source code."},
{"body": "I would like to have a bidirectional JSON to Java serializationI'm using  the Java to JSON to JQuery path... ()\ne.g. and In JQuery I use this works  (e.g. annotations work already, thanks to all the answerers)However, how do I do the  path: have JSON be serialized to a Java Object back using RequestBody? no matter what I try, I can't get something like this to work:I have Jackson configured correctly (it serializes on the way out) and I have MVC set as annotations driven of courseHow do I make it work? is it possible at all? or is Spring / JSON / JQuery is oneway (out)? I changed this Jackson settingTo the (almost similiar one) suggested And it seems to work! I don't know what exactly did the trick, but it works...I'm pretty sure you only have to register  (the easiest way to do that )Here's a working example:You can test this setup by executing  on the command line, and then sending a POST request:I used the  to do this.Here's what the response looks like:In Addition you also need to be sure that you have in your SPring configuration xml.I also would recommend you to read this blog post. It helped me alot.\njust checked my working code where I have @RequestBody working correctly.\nI also have this bean in my config:May be it would be nice to see what Log4j is saying. it usually gives more information and from my experience the @RequestBody will fail if your request's content type is not Application/JSON. You can run Fiddler 2 to test it, or even Mozilla Live HTTP headers plugin can help.In addition to the answers here...if you are using jquery on the client side, this worked for me:Java:Jquery (you need to include Douglas Crockford's json2.js to have the JSON.stringify function):If you do not want to configure the message converters yourself, you can use either \n, add Jackson to the classpath and Spring will give you both JSON, XML (and a few other converters) by default. Additionally, you will get some other commonly used features for conversion, formatting and validation.In case you are willing to use Curl for the calls with JSON 2 and Spring 3.2.0 in hand checkout the FAQ . As AnnotationMethodHandlerAdapter is deprecated and replaced by  RequestMappingHandlerAdapter. "},
{"body": "I'd like to use Hibernate's criteria api to formulate a particular query that joins two entities. Let's say I have two entities, Pet and Owner with a owner having many pets, but crucially that association is not mapped in the Java annotations or xml.With hql, I could select owners that have a pet called 'fido' by specifying the join in the query (rather than adding a set of pets to the owner class).Can the same be done using hibernate criteria? If so how?Thanks,\nJMy understanding is that if you do this using HQL, you are creating a Cartesian join with a filter, rather than an inner join. Criteria queries do not support doing this.This is indeed possible with criteria::  This actually performs a sub-query instead of a join but it allows you to use Criteria on two entities that do not have a hibernate relationship defined.In NHibernate you can use subqueries which are defined as DetachedCriteria. Not sure if it works the same in Java, most probably it is the same:Assumed that it is joined using the name of the owner.There's a , which you can give arbitrary , and add to your .  In the  string, the token {alias} \"will be replaced by the alias of the root entity.\""},
{"body": "We use GSLB for geo-distribution and load-balancing. Each service is assigned a fixed domain name. Through some DNS magic, the domain name is resolved into an IP that's closest to the server with least load. For the load-balancing to work, the application server needs to honor the TTL from DNS response and to resolve the domain name again when cache times out. However, I couldn't figure out a way to do this in Java.The application is in Java 5, running on Linux (Centos 5).Java has some seriously weird dns caching behavior. Your best bet is to turn off dns caching or set it to some low number like 5 seconds.Per Byron's answer, you can't set  or  as System Properties by using the  flag or calling  because these are not System properties - they are  properties.If you want to use a System property to trigger this behavior (so you can use the  flag or call ), you will want to set the following  property:This system property will enable the desired effect.  But be aware: if you don't use the  flag when starting the JVM process and elect to call this from code instead:This code  execute before any other code in the JVM attempts to perform networking operations.  This is important because, for example, if you called  in a .war file and deployed that .war to Tomcat, this wouldn't work: Tomcat uses the Java networking stack to initialize itself much earlier than your .war's code is executed.  Because of this 'race condition', it is usually more convenient to use the  flag when starting the JVM process. If you don't use  or call , you will need to edit  and set those security properties in that file, e.g.But pay attention to the security warnings in the comments surrounding those properties.  Only do this if you are reasonably confident that you are not susceptible to .To expand on Byron's answer, I believe you need to edit the file  in the  directory to effect this change.Here is the relevant section:Documentation on the  file .This has obviously been fixed in newer releases (SE 6 and 7). I experience a 30 second caching time max when running the following code snippet while watching port 53 activity using tcpdump.To summarize the other answers, in  you can set the value of the property  to adjust how DNS lookups are cached.  Note that this is  a system property but a security property.  I was able to set this using:This can also be set by the system property  though this will not override a security property if it is set elsewhere.I would also like to add that if you are seeing this issue with web services in WebSphere, as I was, setting  will not be enough.  You need to set to the system property  to .  Unlike the time-to-live property, this can be set as a JVM argument or via ).IBM has a pretty detailed post on how WebSphere handles DNS caching .  The relevant piece to the above is:"},
{"body": "Take the  for example Can anyone give me an example of a  where the  and  methods are different?According to the  doc, the  method will often seek to ensure that an element exists within the  rather than adding duplicates. So my question is, what is the difference between the  and  methods?Is it that the  method will add duplicates regardless? (I doubt that it is because if a  should only have distinct elements this would circumvent that).EDIT:\nIn a  the  and  methods are the same method (see my answer below). Can anyone give me an example of a class where the  and  methods are different?I guess the difference is in the contract, that when element can not be added to collection the  method throws an exception and  doesn't.From: From: There is no difference for the implementation of :For  there actually is a difference:The difference between  and  is explained by these two excerpts from the javadocs:From the  interface:From the  interface is a  implementation that does not impose any insertion restrictions.  Therefore the  and  methods have the same semantics.By contrast,  is an implementation in which  and  behave differently, depending on how the queue was instantiated.from the source code in jdk 7 as follow:we can easily know that the add function will return true when successfully add a new element into the queue, but throw a exception when failed .The  interface specifies that  will throw an  if no space is currently available (and otherwise return ) while  will return  if the element couldn't be inserted due to capacity restrictions.The reason they are the same in a  is that this queue is specified to be unbounded, i.e. there are no capacity restrictions.  In the case of no capacity restrictions, the contracts of  and  display the same behaviour.Source: The offer method inserts an element if possible, otherwise returning false. This differs from the Collection.add method, which can fail to add an element only by throwing an unchecked exception. The offer method is designed for use when failure is a normal, rather than exceptional occurrence, for example, in fixed-capacity (or \"bounded\") queues."},
{"body": "Is anything like this possible in Java? Can one assign custom numeric values to enum elements in Java?, and then some, example from documentation:Assuming that EXIT_CODE is referring to  ( exit_code ) then you could doThen you can put the following at appropriate spots in your code"},
{"body": "How would I go about doing calculations with extremely large numbers in Java? I have tried  but that maxes out at 9223372036854775807, and when using an integer it does not save enough digits and therefore is not accurate enough for what I need. Is there anyway around this?You can use the  class for integers and  for numbers with decimal digits. Both classes are defined in  package.Example:Use the  class that is a part of the Java library.Checkout BigDecimal and BigInteger.Here is an example which gets big numbers very quickly.Depending on what you're doing you might like to take a look at GMP (gmplib.org) which is a high-performance multi-precision library. To use it in Java you need JNI wrappers around the binary library.See some of the Alioth Shootout code for an example of using it instead of BigInteger to calculate Pi to an arbitrary number of digits."},
{"body": "I am using javadoc doclets with gradle, so I need to use the package tools.jar, which is in the lib folder from the jdk (1.6.0_26 in my case).The point is that gradle does not take it automatically, so I was adding that tools package to my libs folder, and then adding it to dependencies.gradle . Now I want to take it directly from my JDK home into my dependencies.gradle. Is there a way to do that? I have tried the next in my dependencies.gradle:But it does not find it while compiling.Found it.  JAVA_HOME points to the JDK, while java.home points to the JRE. See  for more info.Soo... My problem was that my startpoint was the jre folder (C:\\jdk1.6.0_26\\jre) and not the jdk folder (C:\\jdk1.6.0_26) as I thought(tools.jar is on the C:\\jdk1.6.0_26\\lib folder ). The compile line in dependencies.gradle should be:I had this problem when I was trying to run commands through CLI. It was a problem with system looking at the JRE folder i.e. \n. If we look in there, there is no , hence the error. You need to find where the  is, in my case: , and if you look in the  directory, you will see .What I did I created a new environment variable :\nAnd then you need to edit your PATH variable to include JAVA_HOME, i.e.  \nRe-open command prompt and should run. I got the same error using Eclipse trying to execute a Gradle Task. Every time I run a command (i.e. war) the process threw an exception like: I tried the solution listed in this post but none of them solved this issue. Here my solution :Run again, Enjoy! It may be two years too late, but I ran into the same problem recently and this is the solution I ended up with after finding :It should work if java.home points to a directory that's not under the JDK directory and even on Mac OS where you'd have classes.jar instead of tools.jar.I just added a  file with the following content:I was struggling as well for this Solution. Found a better way to it with Gradle as described .\nWe can get the JVM/JDK information from Gradle itself.So simple.Add this to :Did you make sure that tools.jar made it on the compile class path? Maybe the path is incorrect.Like other answers I set  property in  file. But path with \\ separators did not work (building on windows 10): So instead of i had to usethen the build was successfulProblem is that project is build with JRE instead of JDK and since I was building it from eclipse this also worked:In my case (Windows 10) after Java update I lost my Enviroment Variables, so I fixed added the variables again, based in the following steps "},
{"body": "I need web access from Gradle through a proxy server to use the Gradle/Artifactory integration for Jenkins. To reduce possible causes for issues, I manually add the Artifactory plugin in build.gradle and run it from command line:Following  description I specified the following in .gradle/gradle.properties in my home directory:With the above proxy configuration (that is otherwise known to work), it fails:I have two proxy servers to choose from, and one always responds with  (), the other with  (), so obviously, the proxyHost and proxyPort options are used.As the user name (based on an Active Directory user) contains a backslash, I tried both  and , but neither worked. The user specified is different from the user that is logged in to the machine and Active Directory. This user's credentials aren't valid for the proxy, so I need to be able to specify a different user.Setting the same options in Jenkins' or Artifactory's GUI worked.Refinement over Daniel's response: worked for me (with grade.properties in either homedir or projet dir, build was still failing). Thanks for pointing the issue at gradle that gave this workaround.Using a  simple \"Request a URL\" Java program, I was able to replicate the issue. and  seem to be non-standard, albeit popular, options, as they're not described in ; even though the Gradle manual mentions them.It seems Java programs that wish to support proxy authentication  (and I was able to do this using the code on the linked page).I submitted this issue (and a fix) to . Raised issue GRADLE-1556 was resolved in 1.0-milestone-8 (Feb 2012)Try the following:This is my gradle.properties, please note those HTTPS portionIn my  I have the following task, which uses the usual linux proxy settings,  and , from the shell env:For me, works adding this configuration in the gradle.properties file of the project, where the build.gradle file is:Where : \nproxyUrl is the url of the proxy server (.)proxyPort is the port (usually 8080)USER is my domain userPASSWORD, my passwordIn this case, the proxy for http and https is the sameIf you are behind proxy and using eclipse, go to . Select the Active Providers as 'Manual'.Under Proxy entries section, click on HTTPS, click Edit and add proxy host & port. If username and password are required, give that as well. It worked for me!"},
{"body": "Why should I write (as my collegue says):instead of:?I know that the use of constants is recommended but I think the value of  will never change! So I write .You should not. The  name is no more meaningful than 1. If however this value has some other meaning (for example, month in the year), then using a constant (like ) will make your code clearer.I can guess that this constant in Commons Math library was created in Java 1.4 when there were no Integer cache and autoboxing, so it had sense in terms that you may reuse the same  object (not primitive ) in different places to save memory. So it was added for performance reasons, not for code clarity. Now it's obsolete: even if you need an  object, you can use  or implicit autoboxing and get the cached one.You should  write ! Neither should you write  (see exception below)!Why? A literal like  is called a . Magic numbers are \"unique values with unexplained meaning or multiple occurrences which could (preferably) be replaced with named constants\" (explanation from the same Wikipedia page).So what usually should be done is making those magic numbers to constants whose name represents or explains the meaning of that number. The constant  does not explain the meaning.So what you actually have to do is to find the meaning of the value in this context and create a constant with exactly that name. If the  represents the maximum number of allowed threads for example, you should have a constant like:EDIT as per Tagir's commentIf the literal itself has a meaning in the domain for which you are writing the code, then it should not be replaced by a named constant. Tagir's example for calculating the inverse element is a good one:Here the literal  has a meaning in this context inside the math domain. So it can be used as is.I happen to have just written style guidelines for my company and I'd suggest the following: it gives you a  object rather than primitive  1, and as it is  it acts as a constant and can be used in comparison of  objects because will always return same instance.So in the above scenario it might not look  but somewhere if you are using it while comparison, it for sure has impact.Moreover, as much as we can, should prefer the use of constants over hardcoded beacuse:You may know whether it will never change, but I won't if I start editing your code...Basically it's a way of documenting your code . The reason to use constants and examples like this is to avoid This being said, you can use it to a point where it is not advantageous anymore and clutter inducing. I tend to do it for things that are used more than once or have the concept of being changed by me or someone else... or in simpler terms  values.From  you'll see it's defined as:So, you'll see that INTEGER_ONE is not the same as 1. It's an object that's already been constructed for you. So, if we're needing an instance of , rather than create your own, you can reuse the one from the library saving time and memory.It really depends on your application, if you indeed what the  version of 1, then, you'd probably be better of using that instead of this  class.Imagine that you have this But a few thousand times...And suddenly in needs to be a 2.What it easier for you to change?EDIT: Before downvoting, im answering from the perspective of the advantages of not using magic numbers, im not in any way (i thought this was inferable, come on people) advising to change the library constant."},
{"body": "I'm trying to use ant to compile using this command :I don't know if the problem comes from my windows 64bit, or by something else. Because I have java Installed in the 64 & 32 prog files. I downloaded  and putted it in C:\\Program Files\\apache-ant-1.8.2I tried to put ant everywhere, I switched also the ENV PATH between java 64 and 32 but everytime I get this error message :I searched for tools.jar in the ant lib folder, in the java 64 and 32, but no trace of it in the system.What do you think ? A JRE doesn't have a tools.jar, you need a JDK. Set your JAVA_HOME and PATH variables so that they point to a JDK, not a JRE.I had similar issue and got solved by doing following , 1) set JAVA_HOME as C:\\Program Files (x86)\\Java\\jdk1.7.0\\ 2) ANT_HOME as F:\\ant\\apache-ant-1.8.4-bin\\apache-ant-1.8.43) add both to 'path ' in system variablesI had to copy C:\\Program Files\\Java\\jdk1.6.0_26\\lib\\tools.jar to C:\\Program Files\\Java\\jre6\\lib\\extThanks anyway.Please make sure that you are pointing to JDK and not a JRE. For example, you should set JAVA_HOME as \"C:\\Program Files\\java\\jdk1.6.0_26\" and have %JAVA_HOME%\\bin in your system path.tools.jar comes with JDK, but what happens in your case it looks for it within /Java/jre6. Change JAVA_HOME env var to one of your JDK home."},
{"body": "What is the most efficient way to remove the first 3 characters of a string?For example:Just use substring:  will return Use substring method of String class :\n       Use the  method of the  class :"},
{"body": "I have an array of numbers from 1 to 100 (both inclusive). The size of the array is 100. The numbers are randomly added to the array, but there is one random empty slot in the array. \nWhat is the quickest way to find that slot as well as the number that should be put in the slot? A Java solution is preferable.You can do this in O(n). Iterate through the array and compute the sum of all numbers. Now, sum of natural numbers from 1 to N, can be expressed as . In your case N=100.Subtract the sum of the array from , where N=100.That is the missing number. The empty slot can be detected during the iteration in which the sum is computed.We can use XOR operation which is safer than summation because in programming languages if the given input is large it may overflow and may give wrong answer.Before going to the solution, know that . So if we XOR two identical numbers the value is 0. Now, XORing [1..n] with the elements present in the array cancels the identical numbers. So at the end we will get the missing number.This was an Amazon interview question and was originally answered here: It was answered, as below:It was also blogged here: Here is a simple program to find the missing numbers in an integer array5050 - (sum of all values in the array) = missing numberThis is c# but it should be pretty close to what you need:Well, use a bloom filter.On a similar scenario, , it does not include duplicates and only one number is missing, , using binary search.The solution that doesn't involve repetitive additions or maybe the n(n+1)/2 formula doesn't get to you at an interview time for instance.You have to use an array of 4 ints (32 bits) or 2 ints (64 bits). Initialize the last int with (-1 & ~(1 << 31)) >> 3. (the bits that are above 100 are set to 1) Or you may set the bits above 100 using a for loop.Example: (32 bit version) lets say that the missing number is 58. That means that the 26th bit (left to right) of the second integer is set to 0.The first int is -1 (all bits are set) so, we go ahead for the second one and add to \"no\" the number 32. The second int is different from -1 (a bit is not set) so, by applying the NOT (~) operator to the number we get 64. The possible numbers are 2 at the power x and we may compute x by using log on base 2; in this case we get log2(64) = 6 => 32 + 32 - 6 = 58.Hope this helps.This is not a search problem. The employer is wondering if you have a grasp of a checksum. You might need a binary or for loop or whatever if you were looking for multiple unique integers, but the question stipulates \"one random empty slot.\" In this case we can use the stream sum. The condition: \"The numbers are randomly added to the array\" is meaningless without more detail. The question does not assume the array must start with the integer 1 and so tolerate with the offset start integer. Success time: 0.18 memory: 320576 signal:0I found this beautiful solution here: ========Simplest Solution for sorted Array===========Finding the missing number from a series of numbers. IMP points to remember.I think the easiest and possibly the most efficient solution would be to  loop over all entries and use a bitset to remember which numbers are set, and then test for 0 bit. The entry with the 0 bit is the missing number.This Program finds missing numbersOne thing you could do is sort the numbers using quick sort for instance. Then use a for loop to iterate through the sorted array from 1 to 100. In each iteration, you compare the number in the array with your for loop increment, if you find that the index increment is not the same  as the array value, you have found your missing number as well as the missing index. Below is the solution for finding all the missing numbers from a given array:Lets say you have n as 8, and our numbers range from 0-8 for this example\nwe can represent the binary representation of all 9 numbers as follows\n0000\n0001\n0010\n0011\n0100\n0101\n0110\n0111\n1000in the above sequence there is no missing numbers and in each column the number of zeros and ones match, however as soon as you remove 1 value lets say 3 we get a in balance in the number of 0's and 1's across the columns. If the number of 0's in a column is <= the number of 1's our missing number will have a 0 at this bit position, otherwise if the number of 0's > the number of 1's at this bit position then this bit position will be a 1. We test the bits left to right and at each iteration we throw away half of the array for the testing of the next bit, either the odd array values or the even array values are thrown away at each iteration depending on which bit we are deficient on. The below solution is in C++At each iteration we reduce our input space by 2, i.e N, N/2,N/4 ... = O(log N), with space O(N)Solution With PHP ;and  will give the index of missing numberHere program take time complexity is O(logn) and space complexity O(logn)If the array is randomly filled, then at the best you can do a linear search in O(n) complexity. However, we could have improved the complexity to O(log n) by divide and conquer approach similar to quick sort as pointed by giri given that the numbers were in ascending/descending order. Now I'm now too sharp with the Big O notations but couldn't you also do something like (in Java)where numbers is the array with your numbers from 1-100.\nFrom my reading of the question it did not say when to write out the missing number.Alternatively if you COULD throw the value of i+1 into another array and print that out after the iteration.Of course it might not abide by the time and space rules. As I said. I have to strongly brush up on Big O.Another homework question. A sequential search is the best that you can do. As for a Java solution, consider that an exercise for the reader. :PQuick sort is the best choice with maximum efficiency...."},
{"body": "I have a loop over a bunch of URLs, for each one I'm doing the following:The first query is fine, the second throws this exception:This is just a simple single-threaded app. How can I release this connection?The recommended way, by Httpcomponents 4.1, is to close connection and release any underlying resources:where  passed is a response entity.This seems to work great :And don't forget to consume the entity even if you didn't open its content. For instance, you expect a HTTP_OK status from the response and don't get it, you still have to consume the entity !To answer my own question: to release the connection (and any other resources associated with the request) you must close the InputStream returned by the HttpEntity:From the Since version 4.2, they introduced a much more convenience method that simplifies connection release: I'm chiming in with a detailed answer that specifically addresses Apache HttpClient 4.0.1.  I'm using this HttpClient version, since it's provided by WAS v8.0, and I need to use that provided HttpClient within Apache Wink v1.1.1, also provided by WAS v8.0, to make some NTLM-authenticated REST calls to Sharepoint.To quote Oleg Kalnichevski on the Apache HttpClient mailing list:If the response is not to be consumed, then the request can be aborted using the code below:Apache HttpClient Version: 4.1.3I've got this problem when I use HttpClient in Multithread envirnoment (Servlets). \nOne servlet still holds connection and another one want to get connection.  version 4.0 use version 4.2 use and set this two setters: HTTP HEAD requests must be treated slightly differently because response.getEntity() is null.\nInstead, you must capture the HttpContext passed into HttpClient.execute() and retrieve the connection parameter to close it (in HttpComponents 4.1.X anyway).HttpComponents 4.2.X added a releaseConnection() to HttpRequestBase to make this easier.I had the same issue and solved it by closing the response at the end of the method:I'm using HttpClient 4.5.3, using  worked for me."},
{"body": "I am trying to trouble shoot a JUnit. In the source code, I have set break point in two places: 1) in a line where a static member is initialized 2) the first line of one of the test cases.The debugger stops in the static field initializing line. But it doesn't stop in the test case. No matter where I set the break point in the test case, the debugger doesn't stop there. I know for sure that the test case is executed as I can see the log messages that I have added appear in the log.Any help would be greatly appreciated.I am using Eclipse Galileo and JUnit4 launcher.This could be related to one of the bugs in .If this indeed turns out to be the issue, you should move to a higher version of the JDK (that's no guarantee though, since ). The best bet is to use -XX:+UseParallelGC flag. Increasing the size of the minimum and maximum heap size, to delay the first GC, bring temporary relief.By the way, use  to track how others have been faring.Fix could be as simple as clicking run/skip all breakpoints. Worked for me.Make sure, under Run > Debug Configurations, that 'Stop in main' is selected, if applicable to your situation.Usually when this happens to me (rare but it does) means that the code being executed is different than the code in the editor.   It will happen from time to time for Eclipse that the built classes and the code in editor are out of sync.  When that happens I get all sort of weird debugger behavior (debugging empty lines, skipping lines of codes etc).Restarting Eclipse, clean all projects and rebuild everything usually clears things up.   I had also the Maven plugins (older versions... had not had it for a while now) that had a tendency to do that too.Otherwise it might be a bug, maybe the one Vineet stated,Hope this helpsYou might have accidentally skipped all break points in Eclipse toolbar. To fix this go to Eclipse -> Run -> Skip All Breakpoints. For JDK7, run->Debug Configurations, check \"Keep JUnit running after a test run when debugging\".Make sure you declare the package at the top.\nIn my groovy code this stops at breakpoints:This does not stop at breakpoints:Project -> Clean seemed to work for me on on JRE 8In order to debugger work with remote, the java .class files must be complied along with debugging information. If \"\" option was passed to compiler then the class file will not have necessary information and hence debugger will not be able to match breakpoints on source code with that class in remote. Meanwhile, if jars/class files were , then they also will not have any debug info. According to your responses, most probably this is not your case, but this info could be useful for others who face the same issue.Happened to me once, when I had unchecked \"Run > Build automatically\" and forgot to re-check it.:One additional comment regarding Vineet Reynolds answer.I found out that I had to set -XX:+UseParallelGC in eclipse.iniI setup the vm arguments as followthat solved the issue.Also verify if breakpoints on other lines DO work, it may be a bug in the debugger. I have had a problem with the Eclipse debugger where putting a breakpoint on a boolean assignment whose code was on the next line didn't work , but putting it on the previous or next line did.If nothing works- Another possible problem is that the debugger port may be blocked by the firewall. For example, I was using mule anypoint studio (v 5.4.3). The default debugger port is 6666. When a flow is executed, it would not stop at breakpoint. when I changed the port to another (e.g. 8099), it worked fine.Go to  and check if too many debug instances are created.\nMy issue was resolved when i deleted multiple debug instances from configuration and freshly started debugging.If you are on Eclipse,Right click on your project folder under \"Package Explorer\".Goto Source -> Clean up and choose your project.This will cleanup any mess and your break-point should work now.Creating a new workspace worked for me.In my case I had multiple projects in same workspace. The java file I was trying to debug was present in more than one projects with same package.I didn't need the other project, so simply closed unrelated projects (or remove the file from unrelated project).In my case the problem was that I hadn't Debug view open in Debug perspective, so:1 - Be sure you have debug perspective opened:2 - Be sure you have debug view opened:This is what works for me:I had to put my local server address in the  configuration like this:: that address, is the one I configure in my Apache  file.: the only breakpoint that was working was the 'Break at first line', after that, the breakpoints didn't work.: check your  properties in your  file, and remove any you think is not required."},
{"body": "How to write a byte array to a file in Java?You can use  from .As  points out the most straight forward now . Details for this can be found in the . Old answer:\n  would be the most straight forward. What is the data you want to write?The  may be of some use to you.As of Java 1.7, there's a new way: Java 1.7 also resolves the embarrassment that Kevin describes: reading a file is now:A commenter asked \"why use a third-party library for this?\" The answer is that it's way too much of a pain to do it yourself.  Here's an example of how to  do the inverse operation of reading a byte array from a file (sorry, this is just the code I had readily available, and it's not like I want the asker to actually paste and use this code anyway):Everyone ought to be thoroughly appalled by what a pain that is.  I, unsurprisingly, recommend Guava's .To write a byte array to a file use the method from BufferedOutputStream class. implements a buffered output stream. By setting up such an output stream, an application can write bytes to the underlying output stream without necessarily causing a call to the underlying system for each byte written. For your example you need something like: has a  method. Note that if you're doing any file/IO work then the Apache Commons IO library will do a lot of work for you.No need for external libs to bloat things - especially when working with Android. Here is a native solution that does the trick. This is a pice of code from an app that stores a byte array as an image file."},
{"body": "I have a  named  with the following content:I know I can get the array  with:And now I want to parse that  into a ...What is the easiest way to do this?Definitely the easiest way to do that is using Gson's default parsing function .  There is an implementation of this function suitable for when you need to deserialize into any  (e.g., any ), which is .In your case, you just need to get the  of a  and then parse the JSON array into that , like this:You may want to take a look at .Below code is using .\nI have printed the number of element in list as well as the elements in ListCheck this out, I believe this is what you need. "},
{"body": "I know that Android 6.0 has new permissions and I know I can call them with something like this Today I saw a Google app which needs 3 permissions: contacts, sms and camera. It's making a page 1-3 and calls them all together at the same time to activate.Can anybody tell me how I can call 4 permissions to activate at the same time like sms, camera, contacts and storage?Example (forgot the name of the google app :( )\nThe app needs sms,contacts and camera the app asked me (and made a dialog page1-3) activate sms, activate contacts and then camera. \nSo this google app was calling all 3 required permissions together and my question is how can i achive the same ?Just include all 4 permissions in the  call and Android will automatically page them together like you mentioned.I have a helper method to check multiple permissions and see if any of them are not granted.Then just send it all of the permissions.  Android will ask only for the ones it needs.The app needs 2 permissions at startup . SEND_SMS and ACCESS_FINE_LOCATION (both are mentioned in manifest.xml).I am using  which is  prepared to handle Android pre-Marshmallow and so no need to check build versions.As soon as the app starts up, it asks for multiple permissions together. If both permissions are granted the normal flow goes. In case one or more permissions are not granted, ActivityCompat.requestPermissions() will request permissions and the  control goes to onRequestPermissionsResult() callback method.You should check the value of shouldShowRequestPermissionRationale() flag in onRequestPermissionsResult() callback method. -Any time user clicks Deny permissions (including the very first time), it will return true.  So when the user denies, we can show more explanation and keep asking again-Only if user select \u201cnever asks again\u201d it will return false. In this case, we can continue with limited functionality and guide user to activate the permissions from settings for more functionalities, or we can finish the setup, if the permissions are trivial for the app.Small code :}In your onCreateThen check resultThe following methodology is about I found this is in the runtime permissions example from Google's github.Check the \"Asking for multiple permissions at a time\" section in this article:It's very well explained, and may also touch other related topics you haven't think about.I have successfully implemented simple code for Multiple permission at Once.\nFollow the below steps\n1:Make Utility.java class like below2: Now call in your Activity onCreate() or according to your logic.3:Now check permission before performing operation for particular task4: Now implement onRequestPermissionsResult() method in your Activity as belowShort and sweet :). what I believe in."},
{"body": "In Java you can mark method as final to make it  to override.In C# you have to mark method as virtual to make it  to override.Does it mean that in C# you should mark all methods virtual (except a few ones that you don't want to be overridden), since most likely you don't know in what way your class can be inherited?No. If the language designers thought that virtual should have been the default then .Overridablility is a , and like all features it has . The costs of an overrideable method are considerable: there are big design, implementation and testing costs, particularly if there is any \"sensitivity\" to the class; virtual methods are ways of introducing untested third-party code into a system and that has a security impact.If you don't know how you intend your class to be inherited then  because  Your extensibility model is definitely something you should know ahead of time; it should deeply influence your design and testing strategy. I advocate that all classes be  and all methods be  until you have a real-world customer-focussed reason to unseal or to make a method virtual. Basically your question is \"I am ignorant of how my customers intend to consume my class; should I therefore make it arbitrarily extensible?\"  No; you should ! You wouldn't ask \"I don't know how my customers are going to use my class, so should I make all my properties read-write?  And should I make all my methods read-write properties of delegate type so that my users can replace any method with their own implementation?\"  No, don't do any of those things until you have  that a user actually needs that capability!  Spend your valuable time designing, testing and implementing features that users actually want and need, and do so from a position of knowledge.No! Because you don't know how your class will be inherited, you should  mark a method as  if you  that you want it to be overridden.In my opinion the currently accepted  is unnecessarily dogmatic.Fact is that when you don't mark a method as , others cannot override its behaviour and when you mark a class as  others cannot inherit from the class. This can cause substantial pain. I don't know how many times I cursed an API for marking classes  or not marking methods  simply because they did not anticipate my use case.Theoretically it might be the correct approach to only allow overriding methods and inheriting classes which are meant to be overridden and inherited but in practice it's impossible to foresee every possible scenario and there really isn't a good reason to be so closed in.One way to make the call is to look at the name of the method or property. A  method on a List does exactly what the name implies and it doesn't allow for much of . Changing its implementation would likely be not very transparent so marking it as  is probably unnecessary. Marking the  method as virtual is far more useful as someone could create a special List which only accepts some objects via the Add method etc. Another example are custom controls. You would want to make the main drawing method  so others can use the bulk of the behaviour and just change the look but you probably wouldn't override the X and Y properties.In the end you often don't have to make that decision right away. In an internal project where you can easily change the code anyway I wouldn't worry about these things. If a method needs to be overridden you can always make it virtual when this happens.\nOn the contrary, if the project is an API or library which is consumed by others and slow to update, it certainly pays off to think about which classes and methods might be useful. In this case I think it's better to be open rather than strictly closed.No. Only methods that you want derived classes to specify should be virtual. Virtual is not related to final.To prevent overriding of a virtual method in c# you use We can conjure up reasons for/again either camp, but that's entirely useless.In Java there are millions of unintended non-final public methods, but we hear very few horror stories.In C# there are millions of sealed public methods, and we hear very few horror stories.So it is not a big deal - the need to override a public method is rare, so it's moot either way.This reminds me of another argument - whether a local variable should be final by default. It is a pretty good idea, but we cannot exaggerate how valuable it is. There are billions of local variables that could be, but are not, final, but it has been shown to be an actual problem. Making a method virtual will generally slow down any code that needs to call it.  This slowdown will be insignificant but may in some cases be quite large (among other things, because non-virtual method calls may be in-lined, which may in turn allow the optimizer to eliminate unnecessary operations).  It's not always possible to predict the extent to which virtual calls may affect execution speed, and one should generally void doing things which will make code slower except when there's a discernible benefit for doing so.The performance benefit of making methods non-virtual is probably sufficient in many cases to justify having methods be non-virtual by default, but when classes are designed to be inherited most methods should be virtual and unsealed; the primary usage for non-virtual or sealed methods should be as wrappers for other (possibly protected) virtual methods (code that wants to change the underlying behavior should override the appropriate virtual rather than the wrapper).There are frequently non-performance-related reasons for marking classes as  or limiting inheritance to other classes within the assembly.  Among other things, if a class is externally inheritable, all members with  scope are effectively added to its public API, and any changes to their behavior  may break any derived classes that rely upon that behavior.  On the other hand, if a class is inheritable, making its methods  doesn't really increase its exposure.  If anything, it may reduce derived class's reliance upon the base class internals by allowing them to completely \"bury\" aspects of the base class implementation that are no longer relevant in the derived class [e.g. if the members of  were virtual, a derived class which overrode them all could use an array of arrays to hold things (avoiding large-object-heap issues), and wouldn't have to try to keep the private array used by  consistent with the array-of-arrays."},
{"body": "I am using the Google Maps Android API v2, and I need a way to chance the position of the \"My Location\" button. I get the \"My Location\" button like this: Just use GoogleMap.setPadding(left, top, right, bottom), which allows you to indicate parts of the map that may be obscured by other views. Setting padding re-positions the standard map controls, and camera updates will use the padded region.You can get the \"My Location\" button and move it, like :This may not be the best solution, but you could place your own button over the map and handle it yourself. It would take the following:-1) Put the map in a frameLayout and add your button on top. E.g.2) Edit the maps UI settings so the button doesn't appear when you call setMyLocationEnabled(true). You can do this via map.getUiSettings(). setMyLocationButtonEnabled(false);3) Handle the click of your new button to emulate what the supplied button does. E.g. call mMap.setMyLocationEnabled(...); and pan the map to the current location.Hope that helps, or hope someone comes a long with a simpler solution for you ;-)It's already been explained above.Just a small addition to fabLouis's answer.\nYou may also get your map view from the SupportMapFragment.See the method below. It lives inside a class that extends SupportMapFragment. It gets the container view for the button and displays it at the bottom, centered horizontally.    First, obtain Google Map View:Then find MyLocation button (id's from Android Studio debugger):Finally, just set new RelativeLayout params for MyLocation button (align parent right + center vertically in this case):Boom! Now you can move it as you want ;)I solved this problem in my map fragment by re positioning my location button to the right bottom corner of view using code below, here is my Maps Activity.java :-add this lines of code in onCreate() method,and here is onMapReady() code :-I hope, this will solve your problem. Thanks.If you just want to have location indication enabled (the blue dot) but don't need default My Location button:This way you can also draw your own button where you want without strange stuff like this .I don't fancy seeing these magic view IDs others are using, I suggest using tags to find s children.Here is my solution for placing the  button above the  controls.I had the same problem. I ended up using the Hierarchy Viewer to identify the view used to display the button and manipulated it. Very hacky, I know, but could not figure out a different way.It was a bit of a struggle to get this working. But I got it done, and in the process also started to move the zoom buttons around. Here my complete code:One way to deal with this problem. Delete default button and create your own.\nIn OnCreate statement add the next:try this codeYou can use following approach:"},
{"body": "I have the following (maybe common) problem and it absolutely puzzles me at the moment:There are a couple of generated event objects which extends the abstract class  and I want to divide them to Session Beans, likeBut there could be more than two event types in future, so the if-else will be long and maybe unreadable. Additionally I think  is not really \"best practice\" in this case.I could add an abstract method to the  type and have them divide itself but then I have to inject the specific Session Beans within each entity.Is there any hint to achieve a \"pretty\" solution for this problem?Thanks for any help!The simplest approach is to have the Event provide a method you can call so the Event knows what to do.Polymorphism is your friend.Then justA number of people have raised the objection that you \"have to know the kinds of event at compile time.\"  And, yes, you clearly have to know what events you're interpreting at compile time of the generator part, when else would you be able to write the generating part?  These competing examples use Command pattern, which is fine, but means Events have to know the details not just of their representation but of how to  their representation.  That means each class may have two kinds of requirements changes to which their sensitive: changes in what events represent, and changes in the way the events are represented in print.  Now, consider, for example, needing to internationalize this.  In the Command-pattern case, you have to go to  classes for  different Event types and write new  methods.  In the polymorphism case, the changes are localized to one class.  Naturally if you need to internationalize once, you may need many languages, which drive you to adding something like a Strategy  in the Command-pattern case, requiring now  classes \u00d7  languages; again, you need only have one strategy and one class in the polymorphism case.There are reasons to choose either approach, but to claim the polymorphism approach is  is just incorrect.Each event has a function, say do.\nEach subclass overrides do, to do (:P) the appropriate action.\nDynamic dispatch does everything else afterwards.\nAll you need to do, is call event.do()I have no commenting rights and i dont know the exact answer. But is it just me or some ppl here suggest using overloading (which happens at compile time and therefore just generate compile error) to solve  this problem?Just an example. As you see, it will not compile.What's the problem with exploiting the method resolution order?Let Java do the work of matching the correct argument type, then just dispatch the event properly.This is a typical use case for , also known as tagged unions. Unfortunately, Java does not support them directly, so they have to be implemented using some variation of the visitor pattern.Here we have defined our , now to provide a dispatch mechanism:Here I used maximum possible separation of concerns so that responsibility of each class and interface is one and only one. In real life projects ,  implementation and  interface declaration are usually merged into a single class , but that introduces circular dependencies and forces some dependencies between concrete classes (and as we know, one should prefer to depend on interfaces).Additionally,  should usually be replaced with a type parameter to represent the result type, like this:This allows one to use stateless visitors, which are very nice to deal with.This technique allows to (almost?) always eliminate  mechanically rather than having to figure out a problem-specific solution.You could register each of your handler classes against each event type, and perform dispatch when event happens like this.And then get your specific handlers to implement the interface, and register those handlers with the EventRegister.You could have a  interface, defined likewith implementations like , , etc.Then define a , with entries like . Then your dispatch method could be reduced to:Here's a unit test:"},
{"body": "In Java when we declare it will give compile time error but  compiles fine. Why does this happen? The compiler will, in this case, evaluate the calculation (because it contains only constants) and try to assign the result to the variable. This calculation is done with type  and only converted to  on assignment, if at all possible.In your case, the first calculation is too large to fit into a  (). The second one will overflow the  and end up in a range that  supports (). So the assignment works in that case.Mind you, you probably don't ever want to rely on these things in code.You are facing the problem as your number is .In the first case it does not wrap around and hence it overflows the range of short. But in the second case it wraps around after the calculationa and hence it comes in the range of short and so you dont have the compile time error.A loss of precision means that you are losing information of the given value.() In your first case the range of short is crossed(1073741824) and hence you are loosing the information.From (very correctly mentioned in  similar question)"},
{"body": "Does assigning an unused object to null in Java improve the garbage collection process in any measurable way?My experience with Java (and C#) has taught me that is often counter intuitive to try and outsmart the virtual machine or JIT compiler, but I've seen co-workers use this method and I am curious if this is a good practice to pick up or one of those voodoo programming superstitions?Typically, no.But like all things: it depends. The GC in Java these days is VERY good and everything should be cleaned up very shortly after it is no longer reachable. This is just after leaving a method for local variables, and when a class instance is no longer referenced for fields.You only need to explicitly null if you know it would remain referenced otherwise. For example an array which is kept around. You may want to null the individual elements of the array when they are no longer needed.For example, this code from ArrayList:Also, explicitly nulling an object will not cause an object to be collected any sooner than if it just went out of scope naturally as long as no references remain.Both:and:Are functionally equivalent.In my experience, more often than not, people null out references out of paranoia not out of necessity. Here is a quick guideline:I would say that the vast majority of the time you will not need to null out references. Trying to outsmart the garbage collector is useless. You will just end up with inefficient, unreadable code.Explicitly setting a reference to null instead of just letting the variable go out of scope, does not help the garbage collector, unless the object held is very large, where setting it to null as soon as you are done with is a good idea.Generally setting references to null, mean to the READER of the code that this object is completely done with and should not be concerned about any more.A similar effect can be achieved with by putting in an extra set of bracesthis allows the bigThing to be garbage collected right after leaving the nested braces.At least in java, it's not voodoo programming at all.  When you create an object in java using something likeyou do two things: first, you create a reference to an object, and second, you create the Foo object itself.   So long as that reference or another exists, the specific object can't be gc'd.  however, when you assign null to that reference...and assuming nothing else has a reference to the object, it's freed and available for gc the next time the garbage collector passes by.  It depends.Generally speaking shorter you keep references to your objects, faster they'll get collected.If your method takes say 2 seconds to execute and you don't need an object anymore after one second of method execution, it makes sense to clear any references to it. If GC sees that after one second, your object is still referenced, next time it might check it in a minute or so.Yes. From \"The Pragmatic Programmer\" p.292:By setting a reference to NULL you reduce the number of pointers to the object by one ... (which will allow the garbage collector to remove it)Above program throws . If you uncomment , the  is solved. It is always good practice to set the unused variable to nullGood article is today's .The way GC's work is by looking for objects that do not have any pointers to them, the area of their search is heap/stack and any other spaces they have.  So if you set a variable to null, the actual object is now not pointed by anyone, and hence could be GC'd.But since the GC might not run at that exact instant, you might not actually be buying yourself anything.  But if your method is fairly long (in terms of execution time) it might be worth it since you will be increasing your chances of GC collecting that object. The problem can also be complicated with code optimizations, if you never use the variable after you set it to null, it would be a safe optimization to remove the line that sets the value to null (one less instruction to execute).  So you might not actually be getting any improvement.So in summary, .I was working on a video conferencing application one time and noticed a huge huge huge difference in performance when I took the time to null references as soon as I didn't need the object anymore. This was in 2003-2004 and I can only imagine the GC has gotten even smarter since. In my case I had hundreds of objects coming and going out of scope every second, so I noticed the GC when it kicked in periodically. However after I made it a point to null objects the GC stopped pausing my application. So it depends on what your doing...I assume the OP is referring to things like this:In this case, wouldn't the VM mark them for GC as soon as they leave scope anyway?Or, from another perspective, would explicitly setting the items to null cause them to get GC'd before they would if they just went out of scope? If so, the VM may spend time GC'ing the object when the memory isn't needed anyway, which would actually cause worse performance CPU usage wise because it would be GC'ing more earlier.\"\"I do not know about Java but in .net (C#, VB.net...) it is usually not required to assign a null when you no longer require a object. However note that it is \"usually not required\". By analyzing your code the .net compiler makes a good valuation of the life time of the variable...to accurately tell when the object is not being used anymore. So if you write obj=null it might actually look as if the obj is still being used...in this case it is counter productive to assign a null.There are a few cases where it might actually help to assign a null. One example is you have a huge code that runs for long time or a method that is running in a different thread, or some loop. In such cases it might help to assign null so that it is easy for the GC to know its not being used anymore.There is no hard & fast rule for this. Going by the above place null-assigns in your code and do run a profiler to see if it helps in any way. Most probably you might not see a benefit.If it is .net code you are trying to optimize, then my experience has been that taking good care with Dispose and Finalize methods is actually more beneficial than bothering about nulls.Some references on the topic: Even if nullifying the reference were marginally more efficient, would it be worth the ugliness of having to pepper your code with these ugly nullifications? They would only be clutter and obscure the intent code that contains them. Its a rare codebase that has no better candidate for optimisation than trying to outsmart the Garbage collector (rarer still are developers who succeed in outsmarting it). Your efforts will most likely be better spent elsewhere instead, ditching that crufty Xml parser or finding some opportunity to cache computation. These optimisations will be easier to quantify and don't require you dirty up your codebase with noise. "},
{"body": "I use visualVM connect a multi thread Java application, thread has 4 status, namely running, sleeping, wait, Monitor. What does this Monitoring status mean? What's the difference between wait and Monitor?These states are the same as mentioned in the  enum. \"Wait\" means, as the documentation says:\"Monitor\" is the  state, in which the thread is waiting to obtain a lock on an object (because it's trying to enter a  block or method while another thread already holds the associated lock).That's not a \"monitoring\" status... It indicates that the thread is in the  state. I see there is another good answer, i'll just point you to  for deeper explanationMonitor will mean the thread is waiting to attain a lock on an object.  For example when one thread is running a synchronized method and another one tries to invoke it on the same object, it will not be able to until the first invocation of the method is finished.  This is because the first thread has a monitor or lock on that object, so the second one must wait until it is released. From :"},
{"body": "By looking at the file  of my , I see that the keystore type to use by default is set to . , there is a list of the keystore types that can be used.Is there a recommended keystore type? What are the pros/cons of the different keystore types?There are a few more types than what's listed in the standard name list you've linked to. You can find more in the . The most common are certainly  (the default) and  (for PKCS#12 files, often with extension  or sometimes ).JKS is the most common if you stay within the Java world. PKCS#12 isn't Java-specific, it's particularly convenient to use certificates (with private keys) backed up from a browser or coming from OpenSSL-based tools ( wasn't able to convert a keystore and import its private keys before Java 6, so you had to use other tools).If you already have a PKCS#12 file, it's often easier to use the  type directly. It's possible to convert formats, but it's rarely necessary if you can choose the keystore type directly.In Java 7,  was mainly useful as a  but less for a  (see the ), because you couldn't store certificate entries without a private key. In contrast,  doesn't require each entry to be a private key entry, so you can have entries that contain only certificates, which is useful for trust stores, where you store the list of certificates you trust (but you don't have the private key for them).This has changed in Java 8, so you can now have certificate-only entries in  stores too. (More details about these changes and further plans can be found in .)There are a few other keystore types, perhaps less frequently used (depending on the context), those include:Here is a post which introduces different types of keystore in Java and the differences among different types of keystore. Below are the descriptions of different keystores from the post:"},
{"body": "I am writing a serializer to serialize POJO to JSON but stuck in circular reference problem. In  hibernate bidirectional one-to-many relation, parent references child and child references back to parent and here my serializer dies. (see example code below)\nHow to break this cycle? Can we get owner tree of an object to see whether object itself exists somewhere in its own owner hierarchy? Any other way to find if the reference is going to be circular? or any other idea to resolve this problem?Can a bi-directional relationship even be represented in JSON? Some data formats are not good fits for some types of data modelling. One method for dealing with cycles when dealing with traversing object graphs is to keep track of which objects you've seen so far (using identity comparisons), to prevent yourself from traversing down an infinite cycle.I rely on  To handle this kind of issue by using The featureSuppose a bi-directional relationship between A and B class as followsAnd BNow use GsonBuilder To get a custom Gson object as follows (Notice  method)Now our circular referenceTake a look at  class  1.6 (released september 2010) has specific annotation-based support for handling such parent/child linkage, see . ()You can of course already exclude serialization of parent link already using most JSON processing packages (jackson, gson and flex-json at least support it), but the real trick is in how to deserialize it back (re-create parent link), not just handle serialization side. Although sounds like for now just exclusion might work for you.EDIT (April 2012):  now supports true  (), so you can solve it this way also.In addressing this problem, I took the following approach (standardizing the process across my application, making the code clear and reusable):Here's the code:1)2)3)4)5) In the first case, null is supplied to the constructor, you can specify another class to be excluded - both options are added below6)or, to exclude the Date objectIf you are using Javascript, there's a very easy solution to that using the  parameter of  method where you can pass a function to modify the default serialization behavior. Here's how you can use it. Consider the below example with 4 nodes in a cyclic graph.Later, you can easily recreate the actual object with the cyclic references by parsing the serialized data and modifying the  property to point to the actual object if it's using a named reference with a  like in this example.Used a solution similar to Arthur's but instead of  I used and used  gson annotation for fields which I need in the json, other fields are excluded. on parent property in child class could solve itThis error can appened when you have two objects :With using GSon for serialization, i have got this error :To solved this, just add key word transient :As you can see here : This is how i finally solved it in my case. This works at least with Gson & Jackson.If you are using Jackon to serialize, just apply  to your bi-directinal mapping\nIt will solve the circular reference problem.the answer number 8 is the better, i think so if you know what field is throwing a error the  you only set the fild in null and solved. To make the code readable a big comment is moved from the comment  to below.The answer is very simple.For example \nProductBean has got serialBean.The mapping would be bi-directional relationship.now if we try to use gson.toJson(), it will end up with circular reference.To avoid the problem.now the problem is over.Thank U..."},
{"body": "I'm trying to execute external command from java code, but there's a difference I've noticed.\nwhen running the code:the exitValue is 0 and the command terminated ok.but when I use:Thanks, but the second code wasn't correct.  I use ProcessBuilder this way and it still doesn't work:the exit value is 1001 and the command terminates in the middle although waitFor returns.What should I do to fix the problem with ?The various overloads of  take either an array of strings or a single string.  The single-string overloads of  will tokenise the string into an array of arguments, before passing the string array onto one of the  overloads that takes a string array.  The  constructors, on the other hand, only take a varargs array of strings or a  of strings, where each string in the array or list is assumed to be an individual argument.  Either way, the arguments obtained are then joined up into a string that is passed to the OS to execute.So, for example, on Windows,will run a  program with the two given arguments.  In this case, the command-line gets tokenised and put back together.  However,will fail, unless there happens to be a program whose name is  in .  This is because there's no tokenisation: the command to run is assumed to have already been tokenised.  Instead, you should useor alternativelyLook at how  passes the String command to the . It uses a tokenizer and explodes the command into individual tokens, then invokes  which constructs a .If you construct the  with an array of strings instead of a single one, you'll get to the same result.The  constructor takes a  vararg, so passing the whole command as a single String has the same effect as invoking that command in quotes in a terminal:Yes there is a difference.  So what you are telling ProcessBuilder to do is to execute a \"command\" whose name has spaces and other junk in it.  Of course, the operating system can't find a command with that name, and the command execution fails."},
{"body": "Is there (not NotImplementedException, not supported).Or, if you use Apache Commons Lang and the operation should be supported, but has not been implemented (yet?):You can use either UnsupportedOperationException or NoSuchMethodException or extend the Exception class and create your own custom exception called NotImplementedException or whatever"},
{"body": "What is the best method of performing an scp transfer via the Java programming language? It seems I may be able to perform this via JSSE, JSch or the bouncy castle java libraries. None of these solutions seem to have an easy answer.I ended up using - it was pretty straightforward, and seemed to scale up pretty well (I was grabbing a few thousand files every few minutes).Take a lookThat is the source code for Ants' SCP task.  The code in the \"execute\" method is where the nuts and bolts of it are.  This should give you a fair idea of what is required. It uses JSch i believe.Alternatively you could also directly execute this Ant task from your java code.plug: sshj is the only sane choice! See these examples to get started: , .I wrapped Jsch with some utility methods to make it a bit friendlier and called itAvailable here: SCP utility to tar a folder, zip it, and scp it somewhere, then unzip it.Usage:Also includes useful classes - Scp and Exec, and a TarAndGzip, which work in pretty much the same way.The  lists several Java alternatives,  seems to fit what you're asking for.I use this SFTP API which has SCP called Zehon, it's great, so easy to use with a lot of sample code. Here is the site This is , no need to reinvent. Quick and dirty! First, go to  and download latest Apache Ant binary. (nowadays, apache-ant-1.9.4-bin.zip). Extract the downloaded file and find the JAR  (\"apache-ant-1.9.4/lib/ant-jsch.jar\"). . Also ant-launcher.jar and ant.jar. Go to  and download the jar. Nowadays, . Also .Now, can you easyly use into java code the Ant Classes  for copy files over network or  for commands in SSH servers.   Code Example Scp:I looked at a lot of these solutions and didn't like many of them.  Mostly because the annoying step of having to identify your known hosts.  That and JSCH is at a ridiculously low level relative to the scp command.  I found a library that doesn't require this but it's bundled up and used as a command line tool.  I looked through the source code and discovered how to use it without the command line.  Here's an example of uploading:The biggest downside is that it's not in a maven repo (that I could find).  But, the ease of use is worth it to me.jsCH has worked great for me. Below is an example of a method that will connect to sftp server and download files to specified directory. It is recommended to stay away from disabling StrictHostKeyChecking. Although a little bit more difficult to set up, for security reasons specifying the known hosts should be the norm.  recommended - not recommended Like some here, I ended up writing a wrapper around the JSch library.It's called way-secshell and it is hosted on GitHub: JSch is a nice library to work with. It has quite an easy answer for your question.You can find complete code at supports SCP transfers (as well as SFTP, FTP and FTPS).I wrote an scp server which is much easier than others. I use Apache MINA project (Apache SSHD) to develop it. You can take a look here: \nAlso you can download the jar file from  directory.\nHow to use? Take a look on: "},
{"body": "I have a question about the primitive type  in Java. I am using JDK 1.6. If I have the following: the compiler does not want to compile - it says that it \"cannot convert from int to short\" and suggests that I make a cast to , so this:really works. But my question is why do I need to cast? The values of a and b are in the range of  - the range of short values is {-32,768, 32767}.\nI also need to cast when I want to perform the operations -, *, / (I haven't checked for others).If I do the same for primitive type , I do not need to cast aa+bb to . The following works fine:I discovered this while designing a class where I needed to add two variables of type short, and the compiler wanted me to make a cast. If I do this with two variables of type , I don't need to cast. Thank you very much in advance.A small remark: the same thing also happens with the primitive type . So, this works:but this not:For , , , and , there is no need to cast. Only for  and  values. As explained in  (but also for other language compilers as well, like Java)There is a predefined implicit conversion from short to int, long, float, double, or decimal.You cannot implicitly convert nonliteral numeric types of larger storage size to short (see Integral Types Table for the storage sizes of integral types). Consider, for example, the following two short variables x and y:The following assignment statement will produce a compilation error, To fix this problem, use a cast:It is possible though to use the following statements, where the destination variable has the same storage size or a larger storage size:A good follow-up question is:\"why arithmetic expression on the right-hand side of the assignment operator evaluates to int by default\" ?A first answer can be found in:[From Electronic Notes in Theoretical Computer Science 82 No. 2 (2003)\nBlesner-Blech-COCV 2003: , Jan Olaf BLECH,\nFakult\u00e4t f\u00fcr Informatik,\nUniversit\u00e4t Karlsruhe\nKarlsruhe, Germany]In C# and Java, the arithmatic expression on the right hand side of the assignment evaluates to int by default. That's why you need to cast back to a short, because there is no implicit conversion form int to short, for obvious reasons.EDIT: Okay, now we know it's Java... states:In other words, it's like C# - the addition operator (when applied to integral types) only ever results in  or , which is why you need to cast to assign to a  variable.In C# (you haven't specified the language, so I'm guessing), the only addition operators on primitive types are:These are in the C# 3.0 spec, section 7.7.4. In addition, decimal addition is defined:(Enumeration addition, string concatenation and delegate combination are also defined there.)As you can see, there's no  operator - so both operands are implicitly converted to int, and the int form is used. That means the result is an expression of type \"int\", hence the need to cast.Given that the \"why int by default\" question hasn't been answered ...First, \"default\" is not really the right term (although close enough). As noted by VonC, an expression composed of ints and longs will have a long result. And an operation consisting of ints/logs and doubles will have a double result. The compiler promotes the terms of an expression to whatever type provides a greater range and/or precision in the result (floating point types are presumed to have greater range and precision than integral, although you do lose precision converting large longs to double).One caveat is that this promotion happens only for the terms that need it. So in the following example, the subexpression 5/4 uses only integral values and is performed using integer math, even though the overall expression involves a double. The result isn't what you might expect...OK, so why are byte and short promoted to int? Without any references to back me up, it's due to practicality: there are a limited number of bytecodes. \"Bytecode,\" as its name implies, uses a single byte to specify an operation. For example , which adds  two ints. Currently, , and integer math takes  for each type (ie, 36 total between integer and long), not counting conversion operators.If short, and byte each got their own set of opcodes, you'd be at 241, limiting the ability of the JVM to expand. As I said, no references to back me up on this, but I suspect that Gosling et al said \"how often do people actually use shorts?\" On the other hand, promoting byte to int leads to this not-so-wonderful effect (the expected answer is 96, the actual is -16):What language are you using?Many C based languages have a rule that any mathematical expression is performed in size int or larger.  Because of this, once you add two shorts the result is of type int.  This causes the need for a cast.In java, every numeric expression like:x will always result to be at least an int, or a long if one of the addition elements was a long.But there's are some quirks toughJava always uses at least 32 bit values for calculations. This is due to the 32-bit architecture which was common 1995 when java was introduced. The register size in the CPU was 32 bit and the arithmetic logic unit accepted 2 numbers of the length of a cpu register. So the cpus were optimized for such values.This is the reason why all datatypes which support arithmetic opperations and have less than 32-bits are converted to int (32 bit) as soon as you use them for calculations.So to sum up it mainly was due to performance issues and is kept nowadays for compatibility.AFAIS, nobody mentions of  usage for that. If you modify your last example and define variables a and b as \nvariables, then the compiler is  that their sum, value 5 , can be assigned to a\nvariable of type , without any loss of precision. In this case, the compiler is good\nto assign the sum of a and b to c . Here\u2019s the modified code:I'd like to add something that hasn't been pointed out. Java doesn't take into account the values you have given the variables (2 and 3) in...short a = 2;\nshort b = 3;\nshort c = a + b;So as far as Java knows, you could done this...short a = 32767;\nshort b = 32767;\nshort c = a + b;Which would be outside the range of short, it autoboxes the result to an int becuase it's \"possible\" that the result will be more than a short but not more than an int. Int was chosen as a \"default\" because basically most people wont be hard coding values above 2,147,483,647 or below -2,147,483,648Any data type witch is lower than \"int\" (except Boolean) is implicitly converts to \"int\".In Your case:result of (a+b) is implicitly converted to int. And now you are assigning it to \"short\".So that you are getting the error.short,byte,char --for all these we will get same error."},
{"body": "I was using  to make my code cleaner, and it pointed out that I'm using  instead of . Because it seems that  does not instantiate a new object so is more memory-friendly. How can  not instantiate a new object? How does it work? Is this true for all integers?Integer.valueOf implements a cache for the values -128 to +127.  See the last paragraph of the Java Language Specification, section 5.1.7, which explains the requirements for boxing (usually implemented in terms of the .valueOf methods).From the : is generaly used for autoboxing and therefore (when used for autoboxing) caches at least values from -128 to 127 to follow the autoboxing specification.Here is the  implementation for Sun JVM 1.5.? Have a look at the whole class to see how the cache is initialized.they are pushing you to use  instead of  so the method  does it for you, and caches the value in case you want to get the same number again in future. In that case, method won't instatiate new Integer, but will give you the cached one, what will make 'creation' of new Integer a lot quicker and memory friendly process..This way you may cause yourself alot of problems if you are unexperienced java programmer since you will conclude that  , because you may (or may not) have the same pointer for two Integers, and probably you will practise it in a way, let's say, you learned in C#, so that will show you bugs from time to time, and you won't know how & where those came from... From the java.lang.Integer Source Code. Integer cache is configurable. To configure the Integer cache size other than Sun we need to use the System property  as per the source code.From java.lang.Short,java.lang.Byte and java.lang.Long creates a cache of 127 to -128"},
{"body": "I'm having troubles of getting my current position coordinates using the NETWORK provider of android location system. Already read a lot of tutorials and implemented 4 or 5 existing classes to my project and all of them are giving me the last coordinates but not the current ones.I'm pretty sure that the problem is something fundamental that I am missing but I am not able to understand what exactly it is.  Acctualy GPS possitioning works fine, but NETWORK positioning dosn't.\nWhen Ive turned devices GPS on cordinates keep changing while im moving, but dosnt happence same when I have turn it off and relay on the NETWORK_PROVIDERFirst you need to define a  to handle location changes.Then get the  and ask for location updatesAnd finally make sure that you have added the permission on the Manifest, For using only network based location use this oneFor GPS based location, this oneYou need to write code in the  method, because . I.e. you need to save the new location to return it if getLocation is called.If you don't use the  it always will be the old location.I'm using  and it works nicely for my application.In my activity I put this code:also check if your emulator runs with Google API"},
{"body": "What are some guidelines for when it is  necessary to check for a null?A lot of the inherited code I've been working on as of late has null-checks ad nauseam. Null checks on trivial functions, null checks on API calls that state non-null returns, etc. In some cases, the null-checks are reasonable, but in many places a null is not a reasonable expectation.I've heard a number of arguments ranging from \"You can't trust other code\" to \"ALWAYS program defensively\" to \"Until the language guarantees me a non-null value, I'm always gonna check.\" I certainly agree with many of those principles up to a point, but I've found excessive null-checking causes other problems that usually violate those tenets. Is the tenacious null checking really worth it?Frequently, I've observed codes with excess null checking to actually be of poorer quality, not of higher quality. Much of the code seems to be so focused on null-checks that the developer has lost sight of other important qualities, such as readability, correctness, or exception handling. In particular, I see a lot of code ignore the std::bad_alloc exception, but do a null-check on a .In C++, I understand this to some extent due to the unpredictable behavior of dereferencing a null pointer; null dereference is handled more gracefully in Java, C#, Python, etc. Have I just seen poor-examples of vigilant null-checking or is there really something to this?This question is intended to be language agnostic, though I am mainly interested in C++, Java, and C#.Some examples of null-checking that I've seen that seem to be  include the following:This example seems to be accounting for non-standard compilers as C++ spec says a failed new throws an exception. Unless you are explicitly supporting non-compliant compilers, does this make sense? Does this make  sense in a managed language like Java or C# (or even C++/CLR)?Another example is when working on internal code. Particularly, if it's a small team who can define their own development practices, this seems unnecessary. On some projects or legacy code, trusting documentation may not be reasonable... but for new code that you or your team controls, is this really necessary?If a method, which you can see and can update (or can yell at the developer who is responsible) has a contract, is it still necessary to check for nulls?When developing a private or otherwise internal function, is it really necessary to explicitly handle a null when the contract calls for non-null values only? Why would a null-check be preferable to an assert?(obviously, on your public API, null-checks are vital as it's considered impolite to yell at your users for incorrectly using the API)Compared to:First note that this a special case of contract-checking: you're writing code that does nothing other than validate at runtime that a documented contract is met. Failure means that some code somewhere is faulty.I'm always slightly dubious about implementing special cases of a more generally useful concept. Contract checking is useful because it catches programming errors the first time they cross an API boundary. What's so special about nulls that means they're the only part of the contract you care to check? Still,On the subject of input validation:null is special in Java: a lot of Java APIs are written such that null is the only invalid value that it's even possible to pass into a given method call. In such cases a null check \"fully validates\" the input, so the full argument in favour of contract checking applies.In C++, on the other hand, NULL is only one of nearly 2^32 (2^64 on newer architectures) invalid values that a pointer parameter could take, since almost all addresses are not of objects of the correct type. You can't \"fully validate\" your input unless you have a list somewhere of all objects of that type.The question then becomes, is NULL a sufficiently common invalid input to get special treatment that  doesn't get?Unlike Java, fields don't get auto-initialized to NULL, so a garbage uninitialized value is just as plausible as NULL. But sometimes C++ objects have pointer members which are explicitly NULL-inited, meaning \"I don't have one yet\". If your caller does this, then there is a significant class of programming errors which can be diagnosed by a NULL check. An exception may be easier for them to debug than a page fault in a library they don't have the source for. So if you don't mind the code bloat, it might be helpful. But it's your caller you should be thinking of, not yourself - this isn't defensive coding, because it only 'defends' against NULL, not against (foo *)(-1).If NULL isn't a valid input, you could consider taking the parameter by reference rather than pointer, but a lot of coding styles disapprove of non-const reference parameters. And if the caller passes you *fooptr, where fooptr is NULL, then it has done nobody any good anyway. What you're trying to do is squeeze a bit more documentation into the function signature, in the hope that your caller is more likely to think \"hmm, might fooptr be null here?\" when they have to explicitly dereference it, than if they just pass it to you as a pointer. It only goes so far, but as far as it goes it might help.I don't know C#, but I understand that it's like Java in that references are guaranteed to have valid values (in safe code, at least), but unlike Java in that not all types have a NULL value. So I'd guess that null checks there are rarely worth it: if you're in safe code then don't use a nullable type unless null is a valid input, and if you're in unsafe code then the same reasoning applies as in C++.On the subject of output validation:A similar issue arises: in Java you can \"fully validate\" the output by knowing its type, and that the value isn't null. In C++, you can't \"fully validate\" the output with a NULL check - for all you know the function returned a pointer to an object on its own stack which has just been unwound. But if NULL is a common invalid return due to the constructs typically used by the author of the callee code, then checking it will help.In all cases:Use assertions rather than \"real code\" to check contracts where possible - once your app is working, you probably don't want the code bloat of every callee checking all its inputs, and every caller checking its return values.In the case of writing code which is portable to non-standard C++ implementations, then instead of the code in the question which checks for null and also catches the exception, I'd probably have a function like this:Then as one of the list of things you do when porting to a new system, you define PLATFORM_TRAITS_NEW_RETURNS_NULL (and maybe some other PLATFORM_TRAITS) correctly. Obviously you can write a header which does this for all the compilers you know about. If someone takes your code and compiles it on a non-standard C++ implementation that you know nothing about, they're fundamentally on their own for bigger reasons than this, so they'll have to do it themselves.One thing to remember that your code that you write today while it may be a small team and you can have good documentation, will turn into legacy code that someone else will have to maintain. I use the following rules:If you write the code and its contract, you are responsible for using it in terms of its contract and ensuring the contract is correct.  If you say \"returns a non-null\" x, then the caller should not check for null.  If a null pointer exception then occurs with that reference/pointer, it is your contract that is incorrect.Null checking should only go to the extreme when using a library that is untrusted, or does not have a proper contract.  If it is your development team's code, stress that the contracts must not be broken, and track down the person who uses the contract incorrectly when bugs occur.Part of this depends on how the code is used -- if it is a method available only within a project vs. a public API, for example. API error checking requires something stronger than an assertion.So while this is fine within a project where it's supported with unit tests and stuff like that:in a method where you don't have control over who calls it, something like this may be better:It depends on the situation.  The rest of my answer assumes C++.NULL checking in general is evil as it's add a small negative token to the code testability. With NULL checks everywhere you can't use \"pass null\" technique and it will hit you when unit testing. It's better to have unit test for the method than null check.Check out decent presentation on that issue and unit testing in general by Misko Hevery at  Older versions of Microsoft C++ (and probably others) did not throw an exception for failed allocations via new, but returned NULL. Code that had to run in both standard-conforming and older versions would have the redundant checking that you point out in your first example.It would be cleaner to make all failed allocations follow the same code path:It's widely known that there are procedure-oriented people (focus on doing things the right way) and results-oriented people (get the right answer). Most of us lie somewhere in the middle. Looks like you've found an outlier for procedure-oriented. These people would say \"anything's possible unless you understand things perfectly; so prepare for anything.\" For them, what you see is done properly. For them if you change it, they'll worry because the ducks aren't all lined up.When working on someone else's code, I try to make sure I know two things.\n1. What the programmer intended\n2. Why they wrote the code the way they did  For following up on Type A programmers, maybe this helps.So \"How much is enough\" ends up being a social question as much as a technical question - there's no agreed-upon way to measure it.(It drives me nuts too.)Personally I think null testing is unnnecessary in the great majority of cases. If new fails or malloc fails you have bigger issues and the chance of recovering is just about nil in cases where you're not writing a memory checker! Also null testing hides bugs a lot in the development phases since the \"null\" clauses are frequently just empty and do nothing.When you can specify which compiler is being used, for system functions such as \"new\" checking for null is a bug in the code.  It means that you will be duplicating the error handling code.  Duplicate code is often a source of bugs because often one gets changed and the other doesn't.  If you can not specify the compiler or compiler versions, you should be more defensive.As for internal functions, you should specify the contract and make sure that contract is enforce via unit tests.  We had a problem in our code a while back where we either threw an exception or returned null in case of a missing object from our database.  This just made things confusing for the caller of the api so we went through and made it consistant throughout the entire code base and removed the duplicate checks.   The important thing (IMHO) is to not have duplicate error logic where one branch will never be invoked.  If you can never invoke code, then you can't test it, and you will never know if it is broken or not.I'd say it depends a little on your language, but I use Resharper with C# and it basically goes out of it's way to tell me \"this reference could be null\" in which case I add a check, if it tells me \"this will always be true\" for \"if (null != oMyThing && ....)\" then I listen to it an don't test for null.Whether to check for null or not greatly depends on the circumstances.For example in our shop we check parameters to methods we create for null inside the method.  The simple reason is that as the original programmer I have a good idea of exactly what the method should do.  I understand the context even if the documentation and requirements are incomplete or less than satisfactory.  A later programmer tasked with maintenance may not understand the context and may assume, wrongly, that passing null is harmless.  If I know null would be harmful and I can anticipate that someone may pass null, I should take the simple step of making sure that the method reacts in a graceful way.I only check for NULL when I know what to do when I see NULL. \"Know what to do\" here means \"know how to avoid a crash\" or \"know what to tell the user besides the location of the crash\". For example, if malloc() returns NULL, I usually have no option but to abort the program. On the other hand, if fopen() returns NULL, I can let the user know the file name that could not be open and may be errno. And if find() returns end(), I usually know how to continue without crashing.Lower level code should check use from higher level code. Usually this means checking arguments, but it can mean checking return values from upcalls. Upcall arguments need not be checked.The aim is to catch bugs in immediate and obvious ways, as well as documenting the contract in code that does not lie.I don't think it's  code. A fair amount of Windows/Linux API calls return NULL on failure of some sort. So, of course, I check for failure in the manner the API specifies. Usually I wind up passing control flow to an error module of some fashion instead of duplicating error-handling code.If I receive a pointer that is not guaranteed by language to be not null, and am going to de-reference it in a way that null will break me, or pass out put my function where I said I wouldn't produce NULLs, I check for NULL.It is not just about NULLs, a function should check pre- and post-conditions if possible.It doesn't matter at all if a contract of the function that gave me the pointer says it'll never produce nulls. We all make bugs. There's a good rule that a program shall fail early and often, so instead of passing the bug to another module and have it fail, I'll fail in place. Makes things so much easier to debug when testing. Also in critical systems makes it easier to keep the system sane.Also, if an exception escapes main, stack may not be rolled up, preventing destructors from running at all (see C++ standard on terminate()). Which may be serious. So leaving bad_alloc unchecked can be more dangerous than it seems.Fail with assert vs. fail with a run time error is quite a different topic.Checking for NULL after new() if standard new() behavior has not been altered to return NULL instead of throwing seems obsolete.There's another problem, which is that even if malloc returned a valid pointer, it doesn't yet mean you have allocated memory and can use it. But that is another story.My first problem with this, is that it leads to code which is littered with null checks and the likes. It hurts readability, and i\u2019d even go as far as to say that it hurts maintainability because it really is easy to forget a null check if you\u2019re writing a piece of code where a certain reference really should never be null. And you just know that the null checks will be missing in some places. Which actually makes debugging harder than it needs to be. Had the original exception not been caught and replaced with a faulty return value, then we would\u2019ve gotten a valuable exception object with an informative stacktrace. What does a missing null check give you? A NullReferenceException in a piece of code that makes you go: wtf? this reference should never be null!So then you need to start figuring out how the code was called, and why the reference could possibly be null. This can take a lot of time and really hurts the efficiency of your debugging efforts. Eventually you\u2019ll figure out the real problem, but odds are that it was hidden pretty deeply and you spent a lot more time searching for it than you should have.Another problem with null checks all over the place is that some developers don\u2019t really take the time to properly think about the real problem when they get a NullReferenceException. I\u2019ve actually seen quite a few developers just add a null check above the code where the NullReferenceException occurred. Great, the exception no longer occurs! Hurray! We can go home now! Umm\u2026 how bout \u2018no you can\u2019t and you deserve an elbow to the face\u2019? The real bug might not cause an exception anymore, but now you probably have missing or faulty behavior\u2026 and no exception! Which is even more painful and takes even more time to debug. At first, this seemed like a strange question:  checks are great and a valuable tool.  Checking that  returns  is definitely silly.  I'm just going to ignore the fact that there are languages that allow that.  I'm sure there are valid reasons, but I really don't think I can handle living in that reality :)  All kidding aside, it seems like you should at least have to specify that the  should return  when there isn't enough memory.Anyway, checking for  where appropriate leads to cleaner code.  I'd go so far as to say that never assigning function parameters default values is the next logical step.  To go even further, returning empty arrays, etc. where appropriate leads to even cleaner code.  It is nice to not have to worry about getting s except where they are logically meaningful.  Nulls as error values are better avoided.Using asserts is a really great idea.  Especially if it gives you the option of turning them off at runtime.  Plus, it is a more explicitly contractual style :)"},
{"body": "I'm curious and need to find this answer quick. Google won't help much.The Java Persistence API has these properties that tell the framework to cascade operations on associated entities:I know what the first two mean: when I persist object A which has B, persist B as well, and when I delete A, delete B as well.But I can't make any sense of what the other two accomplish. Help?REFRESH means \"pull any state changes from the database into my representation\".  Cascading this is simple; it means that all associated entities are refreshed.MERGE means something complex that approximates \"save\" but is more like \"push this detached entity back into managed status and save its state changes\"; the cascading means that all associated entities get pushed back the same way, and the managed-entity handle you get back from  has all managed entities associated with it.:I myself see them this way (more readable):"},
{"body": "mvn archetype:generate provides way too many options and I am looking to create a simple java utility with junit test cases. I would like to know what archetype I should be using here?When you do a , a default selection appears in enclosing curly brackets , e.g. , if you scroll up to see what #3 is, it is usually the default Java archetype to try out or start out with, if doing simple Java projects.I use two archetypes. It depends on what kind of application you will create. If you want a web application, use , or if you want a simple application use . They are useful because you will be able to expand them with no problem.I'm using command like below:I will get a  of achetypes only from  groupId. The good ones for starting is  and  like my predecessors said.I think you should use EDITAccording to the maven : I would start with a very simple pom.xml file which has only what you need. Something likefrom "},
{"body": "I'm trying to create a very simple webapp with maven and eclipse, but I'm having no joy at all, in fact the reverse of joy.I go to File -> New Project, select Maven Project, and select the maven-archetype-webapp. When I finish the wizard, a webapp structure gets generated but with no 'java' directory under main, just resources and webapp. So I right click on main and select new Class. The class gets created under resources (?!), and furthermore, there seems to be no compilation of it by java. I can make stupid errors and no syntax highlighting comes up. It's like java isn't recognizing it.Alternatively I have tried creating a new 'java' directory under main where it should be, but still with the same non-existent java symptoms.What gives? This is driving me insane..Thanks all!Simply create a  directory under  (i.e. ) and   on your project and select .Anything else is likely to be down to the archetype and how you've configured your . The directory structure you describe is identical to the one  creates on the command line.Simply create a java directory under main (i.e. src/main/java) and right-click -> Build Path -> Use a Source FolderThis is a great article that I read when I was having trouble understanding how to build multiple projects into one using Maven. Specifically, this article explains how to set up a WEB project (war file) to consume an inner standard java project (jar file).If you have a basic understanding of Maven, skip to the sections at the end:\nHow do I build other types of projects? \nHow do I build more than one project at once? If you aren't familiar with Maven yet, check out: Trust me, mkyong knows what is up!There is an option to create a source directory in eclipse. Or you can go to build path under project properties, and add an existing directory as a source directory.If you are going to use non-standard directory structure you will have to specify it in maven thoughCreate src/main/java on your own.after creating appropriate dir structure execute the maven commandthen refresh the project in eclipse.-SEfor src/main/java \n  your project >> properties >> java build path >> source >>\n    search \"Your Project src/main/java (missin)\"   >>>       and if  errors still don't disapearSimply create new folder named java under src/main/Then right click on project and select maven->update projectin IntelliJ IDEA 13 you must first create \"java\" folder in main folder then --> go to \"open module setting\"- for this you can click on project name and press f4- , and set label of \"java\" folder to \"source\" .Here is my solution. It works without any issue. There could be questions regarding why all this steps are required and i believe they are pretty genuine. But this is one of the ways to make your web application or any other component working on eclipse using Maven from .1) Open a command window2) mvn archetype:generate -DgroupId= -DartifactId= -DarchetypeArtifactId=  -DinteractiveMode=false3) cd 4) mvn eclipse:eclipse -Dwtpversion=2.05) Go to file system. Go to your newly created project. create folders, \n              a) java under main\n              b) test under src\n              c) java and resources under test6) mvn eclipse:clean7) mvn eclipse:eclipse -Dwtpversion=2.08) import  project in eclipseThanks,\nSidDo it the other way around. First make a webapp project, then add the Maven framework (in Intellij - right click project and select Add framework support). It will create the right folders for you.Right click the Maven Project -> Build Path -> Configure Build Path\nIn Order & Export tab, you can see the message like select 'JRE System Library' and 'Maven Dependencies' checkbox\nClick OK\nNow you can them"},
{"body": "I'm trying to write a Unit Test for a simple bean that's used in my program to validate forms. The bean is annotated with  and has a class variable that is initialized using I would like to write unit tests for the validation methods inside this class, however, if possible I would like to do so without utilizing the properties file. My reasoning behind this, is that if the value I'm pulling from the properties file changes, I would like that to not affect my test case. My test case is testing the code that validates the value, not the value itself. Is there a way to use Java code inside my test class to initialize a Java class and populate the Spring @Value property inside that class then use that to test with?I did find this  that seems to be close, but still uses a properties file. I would rather it all be Java code.ThanksIf possible I would try to write those test without Spring Context. If you create this class in your test without spring, then you have full control over its fields.To set the  field you can use Springs  - it has a method  to set private fields.@see If you want, you can still run your tests within Spring Context and set the required properties inside Spring configuration class. If you use JUnit, use SpringJUnit4ClassRunner and define dedicated configuration class for your tests like that:The class under test:The test class:And the configuration class for this test:Having that said, I wouldn't recommend this approach, I just added it here for reference. In my opinion much better way is to use Mockito runner. In that case you don't run tests inside Spring at all, which is much more clear and simpler.Since Spring 4.1 you could set up property values just in code by using  annotation on Unit Tests class level. You could use this approach even for injecting properties into dependent bean instancesFor example It's necessary to have instance of  in Spring contextThis seems to work, although still a bit verbose (I'd like something shorter still):Adding PropertyPlaceholderConfigurer in configuration is working for me.}And in test class}"},
{"body": "Java PreparedStatement provides a possibility to explicitely set a Null value. This possibility is:Are the semantics of this call the same as when using a setType with a null value??This  says:6.1.5 Sending JDBC NULL as an IN parameterThe setNull method allows a programmer to send a JDBC NULL (a generic SQL NULL) value to the database as an IN parameter. Note, however, that one must still specify the JDBC type of the parameter.A JDBC NULL will also be sent to the database when a Java null value is passed to a setXXX method (if it takes Java objects as arguments). The method setObject, however, can take a null value only if the JDBC type is specified. but watch out for this....-thows null pointer exception-because the protype isNOTnice one to catch you out eh.Finally I did a small test and while I was programming it it came to my mind, that without the setNull(..) method there would be no way to set null values for the Java primitives. For Objects both ways and behave the same way.You could also consider using "},
{"body": "I am going through a socket program. In it,  is called on the  object in the catch block.\nWhat does  actually do?I am unaware of its purpose. What is it used for? It .It's a very simple, but very useful tool for diagnosing an Exception. It tells you what happened and where in the code this happened.I was kind of curious about this too, so I just put together a little sample code where you can see what it is doing:It helps to trace the exception. For example you are writing some methods in your program and one of your methods causes bug. Then printstack will help you to identify which method causes the bug. Stack will help like this:First your main method will be called and inserted to stack, then the second method will be called and inserted to the stack in LIFO order and if any error occurs somewhere inside any method then this stack will help to identify that method. helps the programmer to understand where the actual problem occurred.  is a method of the class  of  package. It prints several lines in the output console. \nThe first line consists of several strings. It contains the name of the Throwable sub-class & the package information. \nFrom second line onwards, it describes the error position/line number beginning with \"\". The last line always describes the destination affected by the error/exception. The second last line informs us about the next line in the stack where the control goes after getting transfer from the line number described in the last line. The errors/exceptions represents the output in the form a stack, which were fed into the stack by  method of  class, which itself fills in the program control transfer details into the execution stack. The lines starting with , are nothing but the values of the execution stack. \nIn this way the programmer can understand where in code the actual problem is.Along with the  method, it's a good idea to use .printStackTrace() : prints the locations where the exception occurred in the source code, thus allowing the author who wrote the program to see what went wrong. But since it shows problems in the source code, the user(s) who may or may not have any coding experience may not be able to understand what went wrong, so if the program allows the user to send error messages to the authors, the users may not be able to give good data on what went wrong.You should consider the: Logger.getLogger() method, it offers a better exception handling (logging) facility, and besides printStackTrace() without arguments is considered to be obsolete and should ONLY be used for debugging purposes, not for user display.Well, the purpose of using this method  is to see what exactly wrong is. For example, we want to handle an exception. Let's have a look at the following Example.I've used method  in order to show exactly what is wrong. In the output, we can see the following result. "},
{"body": "How does spring resolve this. Bean A is dependent on bean b, and bean b on bean a.As the other answers have said, Spring just takes care of it, creating the beans and injecting them as required.One of the consequences is that bean injection / property setting might occur in a different order to what your XML wiring files would seem to imply.  So you need to be careful that your property setters don't do initialization that relies on other setters already having been called.  The way to deal with this is to declare beans as implementing the  interface.  This requires you to implement the  method, and this is where you do the critical initialization.  (I also include code to check that important properties have actually been set.)The  explains how circular dependencies are resolved. The beans are instantiated first, then injected into each other.Consider this class:And a similar class :If you then had this configuration file:You would see the following output when creating a context using this configuration:Note that when  is injected into ,  is not yet fully initialised.It just does it. It instantiates  and , and injects each one into the other (using their setter methods).What's the problem?In the codebase I'm working with (1 million + lines of code) we had a problem with long startup times, around 60 seconds. We were getting 12000+ .What I did was set a conditional breakpoint in where it does  I printed the exception with conditional breakpoint code:Apparently this happens when s are involved in a cyclic dependency graph. We solved it by implementing  and   and manually injecting the beans. This cut down the startup time to around 15 secs.So don't always assume that spring can be good at solving these references for you.For this reason I'd recommend disabling cyclic dependency resolution with  to prevent many future problems.From the : The Spring container is able to resolve Setter-based circular dependencies but gives a runtime exception BeanCurrentlyInCreationException in case of Constructor-based circular dependencies.\nIn case of Setter-based circular dependency, the IOC container handles it differently from a typical scenario wherein it would fully configure the collaborating bean before injecting it. \nFor eg., if Bean A has a dependency on Bean B and Bean B on Bean C, the container fully initializes C before injecting it to B and once B is fully initialized it is injected to A. But in case of circular dependency, one of the beans is injected to the other before it is fully initialized.If you generally use constructor-injection and don't want to switch to property-injection then Spring's -injection will let one bean lazily lookup the other and hence workaround the cyclic dependency. See here: Say A depends on B, then Spring will first instantiate A, then B, then set properties for B, then set B into A.But what if B also depends on A?My understanding is: Spring just found that A has been constructed (constructor executed), but not fully initialized (not all injections done), well, it thought, it's OK, it's tolerable that A is not fully initialized, just set this not-fully-initialized A instances into B for now. After B is fully initialized, it was set into A, and finally, A was fully initiated now.In other words, it just expose A to B in advance.For dependencies via constructor, Sprint just throw BeanCurrentlyInCreationException, to resolve this exception, set lazy-init to true for the bean which depends on others via constructor-arg way."},
{"body": "I have a question regarding the usage of the  method.Imagine the following code:Is there any reason why you should use  instead of  (or vice versa). I think that the second option is more readable (a matter of taste of course). But, is there any \"real\" reason why one should be preferred?As of the current JRE implementation,  will always return the same instance while each occurrence of  will not only create its own instance but even have a distinct implementation class. For more details, see .The reason is that the compiler generates a synthetic method holding the trivial body of that lambda expression (in the case of , equivalent to ) and tell the runtime to create an implementation of the functional interface calling this method. So the runtime sees only different target methods and the current implementation does not analyze the methods to find out whether certain methods are equivalent.So using  instead of  might save some memory but that shouldn\u2019t drive your decision if you really think that  is more readable than .You may also consider that when compiling with debug information enabled, the synthetic method will have a line debug attribute pointing to the source code line(s) holding the lambda expression, therefore you have a chance of finding the source of a particular  instance while debugging. In contrast, when encountering the instance returned by  during debugging an operation, you won\u2019t know who has called that method and passed the instance to the operation.In your example there is no big difference between  and  since internally it is simply .But sometimes we can't use . Take a look herethis will compile finebut if you will try to compile you will get compilation error since  expects , which is not related to . Also  doesn't have  method.From the :So, no, as long as it is syntactically correct."},
{"body": "I'm looking for a way to get a list of files that match a pattern (pref regex) in a given directory.I've found a tutorial online that uses apache's commons-io package with the following code:But that just returns a base collection (According to  it's a collection of ). Is there a way to do this that returns a type safe generic collection?See .Since Java 8 you can use lambdas and achieve shorter code:The following code will create a list of files based on the accept method of the .Since java 7 you can the  package to achieve the same result:What about a wrapper around your existing code:I will throw a warning though. If you can live with that warning, then you're done. "},
{"body": "I have a JLabel which has a lot of text on it. Is there a way to make the JLabel have a max width so that it will wrap the text to make it not exceed this width?ThanksNo. You can use HTML in the label, but then you must hard code the break tag.A better approach is to use a JTextArea and turn wrapping on. You can change the background,foreground, font etc. of the text are to make it look like a label.As per @darren's answer, you simply need to wrap the string with  and  tags:You do not need to hard-code any break tags.  The text wraps as the component resizes.Yes there are two similar ways (first with css style=\"width:...px\", second with html WIDTH=...:1.2.or simply use JXLabel in the  supports wrappingYou can use HTML without hard coding break tags if you use paragraph tags instead.There's a good technique , scroll to the end of the article.Other than wrapping the text in  tags, you also have to put the label into a container that respects the preferred height and sets the width to maximum. For example, you can put the label in to the NORTH of a .Here is a simple but complete working program to illustrate this. You can resize the frame in any way you want; the label will occupy the whole width and the height will adjust accordingly to wrap the text. Notice that all that I'm doing is using  tags and putting the label in the NORTH of the .If you only want to use JLabel than you can try this approach,just display the number of characters you want to display on label using substring method."},
{"body": "This question was posted on some site. I didnt find right answers there, so I am posting it here again.     My query is not about stopping a Thread. Let me rephrase my question.\nLine A(see code above) starts a new Thread; and Line B make the thread reference null. So, the JVM now has a Thread Object(which is in running state) to which no reference exists (as t=null in Line B).\nSo my question is, why does this thread(that has no reference anymore in the main thread) keeps on running until the main thread is running. Per my understanding, the thread object should have been garbage collected post Line B. I tried to run this code for 5 minutes and more, requesting Java Runtime to run GC, but the thread just does not stop.Hope both the code and question is clear this time.A running thread is considered a so called garbage collection root and is one of those things keeping stuff from being garbage collected. When the garbage collector determines whether your object is '' or not, it is always doing so using the set of garbage collector roots as reference points.Consider this, why is your main thread not being garbage collected, no one is referencing that one either.As was explained, running threads are, by definition, immune to GC. The GC begins its work by scanning \"roots\", which are deemed always reachable; roots include global variables (\"static fields\" in Java-talk) and the stacks of all running threads (it can be imagined that the stack of a running thread references the corresponding  instance).However, you can make a thread a \"daemon\" thread (see ). A daemon thread is no more garbage-collected than a non-daemon thread, but the JVM exits when all running threads are daemon. One way to imagine it is that every thread, when it terminates, checks whether there remain some non-daemon running threads; if not, the terminating thread forces a  call, which exits the JVM (killing off the running daemon threads). This is not a GC-related issue; in a way, threads are allocated manually. However, this is how the JVM can tolerate semi-rogue threads. This is typically used for  instances.The JVM has a reference to all running threads.No thread (or the things it refers to) will be garbage-collected while it is still running.The Thread is not garbage collected because there are references to the threads that you cannot see. For example, there are references in the runtime system. When the Thread is created it is added to the current thread group. You can get a list of Threads in the current thread group, so that is another way to get a reference to it."},
{"body": "I'm trying to use Apache Lucene for tokenizing, and I am baffled at the process to obtain Tokens from a .The worst part is that I'm looking at the comments in the JavaDocs that address my question.Somehow, an  is supposed to be used, rather than s.  I'm totally at a loss.  Can anyone explain how to get token-like information from a TokenStream?Yeah, it's a little convoluted (compared to the good ol' way), but this should do it:According to Donotello,  has been deprecated in favor of . According to jpountz (and Lucene's documentation),  is more desirable than .This is how it should be (a clean version of Adam's answer):There are two variations in the OP question:Recent versions of the  say (emphasis added):And  says its API:The other answers to this question cover #2 above: how to get  information from a  in the \"new\" recommended way using attributes.  Reading through the documentation, the Lucene developers suggest that this change was made, in part, to reduce the number of individual objects created at a time.But as some people have pointed out in the comments of those answers, they don't directly answer #1: how do you get a  if you really want/need that type?With the same API change that makes  an ,  now implements  and can be used with  just like the other answers show for  and .  So they really did answer that part of the original question, they simply didn't show it.It is important that while this approach will allow you to access  while you're looping, it is still only a single object no matter how many logical tokens are in the stream.  Every call to  will change the state of the  returned from ; So if your goal is to build a collection of different  objects to be used outside the loop then you will need to do extra work to make a   object as a (deep?) copy."},
{"body": "I have the following parametrised JPA, or Hibernate, query:I want to pass the parameter as an ArrayList<String>, is this possible? Hibernate current tells me, thatIs this possible at all?: Collections as parameters only work with named parameters like \"\", not with JDBC style parameters like \"\".Are you using Hibernate's  object, or JPA? For JPA, it should work fine:For Hibernate's, you'll need to use the setParameterList:in HQL you can use query parameter and set Collection with setParameterList method.Leaving out the parenthesis and simply calling 'setParameter' now works with at least Hibernate.Using pure JPA with  as the actual provider the following seems to work with positional parameters as well:Entity.java:Dao.java:"},
{"body": "Can I define an abstract class without adding an abstract method?Of course.Declaring a class abstract only means that you don't allow it to be instantiated on its own.Declaring a method abstract means that subclasses have to provide an implementation for that method.The two are separate concepts, though obviously you can't have an abstract method in a non-abstract class. You can even have abstract classes with  methods but never the other way around.Yes you can do it. Why don't you just try doing that?Yes you can. The abstract class used in java signifies that you can't create an object of the class. And an abstract method the subclasses have to provide an implementation for that method.So you can easily define an abstract class without any abstract method.This is fine.Yes, you can declare a class you cannot instantiate by itself with only methods that already have implementations. This would be useful if you wanted to add abstract methods in the future, or if you did not want the class to be directly instantiated even though it has no abstract properties.YES You can create abstract class with out any abstract method the best example of abstract class without abstract method is HttpServlet\nAbstract Method is a method which have no body, If you declared at least one method into the class, the class must be declared as an abstract its mandatory BUT if you declared the abstract class its not mandatory to declared the abstract method inside the class.You cannot create objects of abstract class, which means that it cannot be instantiated. Yes we can have an abstract class without Abstract Methods as both are independent concepts. Declaring a class abstract means that it can not be instantiated on its own and can only be sub classed. Declaring a method abstract means that Method will be defined in the subclass. Yes, you can define an abstract class without an abstract method. However, if there is no method inside you might better go with an interfaceyes you can do that.declaring class abstract means that class will not be instantiated by any other class.and there should be at least one abstract method inside that and meaning of that you can declare abstract method in that class if you are not declaring method than its ok.example:this will work for sure.Yes you can. Sometimes you may get asked this question that what is the purpose doing this?\nThe answer is: sometimes we have to restrict the class from instantiating by its own. In that case, we want user to extend our Abstract class and instantiate child classyes, we can declare an abstract class without any abstract method. the purpose of declaring a class as abstract is not to instantiate the class.so two cases 1) abstract class with abstract methods.these type of classes, we must inherit a class from this abstract class and must override the abstract methods in our class,\nex: GenricServlet class2) abstract class without abstract methods.these type of classes, we must inherit a class from this abstract class, \nex: HttpServlet class\npurpose of doing is although you if you don't implement your logic in child class you can get the parent logic "},
{"body": "I am building a generic web service and need to grab all the query parameters into one string for later parsing. How can I do this?You can access a single param via  or all of the params via the context:The key is the  , which can be used to access:The unparsed query part of the request URI can be obtained from the  object:\n"},
{"body": "I have a  representation of a date that I need to create a  or  object from. I've looked through  and  APIs but haven't found anything that can do this other than creating my own ugly parse method. I know there must be a way, does anyone know of a solution?In brief:See  for more.And to turn it into a , do:Java 8 and later has a new  framework that makes these other answers outmoded. This framework is inspired by , defined by , and extended by the  project. See the .The old bundled classes, java.util.Date/.Calendar, are notoriously troublesome and confusing. Avoid them.Like Joda-Time, java.time has a class  to represent a date-only value without time-of-day and without time zone. If your input string is in the standard  format of , you can ask that class to directly parse the string with no need to specify a formatter. The ISO 8601 formats are used by default in java.time, for both parsing and generating string representations of date-time values.If you have a different format, specify a formatter from the  package. You can either specify your own formatting pattern or let java.time automatically localize as appropriate to a  specifying a human language for translation and cultural norms for deciding issues such as period versus comma.Read the  class doc for details on the codes used in the format pattern. They vary a bit from the old outmoded  class patterns.Note how the second argument to the  method is a , syntax added to Java 8 and later.Dump to console.Or rather than specify a formatting pattern, let java.time localize for you. Call , and be sure to specify the desired/expected  rather than rely on the JVM\u2019s current default which can change at any moment during runtime(!).Dump to console. The  is also worth a look.  This is basis for the new  that is pencilled in for Java 7.  The design is neat, intuitive,  and avoids a lot of the clumsiness of the original  /  classes.  Joda's  can parse a String to a Joda .Try this:The  class has a  method.See  for more information."},
{"body": "I currently use the following code to print a double:This works well, except that Java uses my Locale's decimal separator (a comma) while I would like to use a point. Is there an easy way to do this?Use the overload of  which lets you specify the locale:If you're  formatting a number - as you are here - then using  would probably be more appropriate. But if you need the rest of the formatting capabilities of , this should work fine.A more drastic solution is to set your Locale early in the main().Like:You can pass an additional Locale to java.lang.String.format as well as to java.io.PrintStream.printf (e.g. System.out.printf()):This results in the following (on my PC):See  in the Java API.You can use NumberFormat and DecimalFormat.Take a look at this link from Java Tutorials The section titled Locale-Sensitive Formatting is what you need.Way too late but as other mentioned here is sample usage of  (and its subclass )"},
{"body": "I'm trying to get a target to build that has quite a long list of  and  elements in its  element (in the build.xml file).  I keep getting \"package com.somecompany.somepackage does not exist\" errors, and I'm having a hard time chasing down these packages and making sure I've synced them from our repository.I'm new to this team so I'm unfamiliar with the build, but I would prefer to figure this out myself if possible (so I don't bother the other very busy team members).  I have very limited experience with Ant.I think it would save me quite a bit of time if I could have Ant print out the classpath for the target I'm trying to build.Use the  task to convert a path to a property.This is even easier with versions of Ant > 1.6See  for more information"},
{"body": "Could you help me write spring mvc style analog of this code?And how to add an element that is annotated by  annotation to session and then get access to it?If you want to deleting object after each response no need to session,If you want keep object during user session ,\nIt has some ways:5.Pass HttpSession to method:  6.Make ModelAttribute in session By @SessionAttributes(\"ShoppingCart\"):or you can add Model To entire Controller Class Such  each one has advantage and disadvantage:@session may use more memory in cloud systems it copies session to all nodes, and direct method (1 and 5) has messy approach, it is not good to unit test.To access session jsp in Jstl :in Thymeleaf:Use See the docs: \"\" also gives a very good overview of Spring MVC sessions and explains how/when s are transferred into the session (if the controller is  annotated).That article also explains that it is better to use  on the model instead of setting attributes directly on the HttpSession because that helps Spring MVC to be view-agnostic. annotation is the simplest and straight forward instead of getting session from request object and setting attribute.\n \nIn below eg,  will be available in session.The below annotated code would set \"value\" to \"name\"To access the same in JSP use \n.For the  see this When I trying to my login (which is a bootstrap modal), I used the @sessionattributes annotation. But problem was when the view is a redirect (\"redirect:/home\"), values I entered to session shows in the url. Some Internet sources suggest to follow  But I used the HttpSession instead. This session will be there until you close the browsers.\nHere is sample code You don't change specific thing on view side.After login add above codes to anyplace in you web site. If session correctly set, you will see the values there. Make sure you correctly added the jstl tags and El- expressions (Here is link to set jstl tags )Isn't it easiest and  that way? I knew it and just tested it - working perfect here:p.s.\n"},
{"body": "I'm trying to show an icon next to an item within my menu for my navigation drawer, but for some reason the icon always appears in grey rather than the original colour (brown). Is there any way of preventing this from happening in order to show the icon's original colour?I found the answer here:  To avoid the link its pretty straightforward:This disables all state based tinting, but you can also specify your own list too.  It worked great for me!Here is where you can get the details on creating a color state list, but its pretty simple too: \nUse it's right. Also If all your icons in one color scheme (i had all white)\nyou can setup through xml file -         app:itemIconTint=\"@android:color/white\"My case:I've tried something similar in one of my app. And yes, it appears that the icon color doesn't change. But I've managed to do with another workaround. Here's my Which I believe is something similar to you but it doesn't have any effect and doesn't change the color. So what I did is this.And it seems working. Here's the result.You can try using a tinted drawable, not sure if it works below 5.0. Create a drawable and add the following code.And then change your menu item drawable to the one you just created. If that doesn't work, then I'm not sure of any other solutions. You can try this library:  I use it a lot in my projects.Just add one line in xml "},
{"body": "What is the most efficient way to make the first character of a  lower case?I can think of a number of ways to do this:I am sure there are many other great ways to achieve this. What do you recommend?I tested the promising approaches using . Full benchmark .Assumption during the tests (to avoid checking the corner cases every time): the input String length is always greater than 1.The score are operations per second, the more the better. If the String length is always greater than 0, use .If not, we have to check the corner cases:If you are sure that your text will be always in ASCII and you are looking for extreme performance because you found this code in the  bottleneck, use .I came across a nice alternative if you don't want to use a third-party library:When it comes to string manipulation take a look to Jakarta Commons Lang .Despite a char oriented approach I would suggest a String oriented solution.\n is Locale specific, so I would take this issue into account.  is to prefer for lower-caseing according to .\nAlso a char oriented solution is not full unicode compatible, because   cannot handle supplementary characters.\nAs an example how important the locale setting is let us lowercase  in turkish and german:will output two different results:Strings in Java are immutable, so either way a new string will be created.Your first example will probably be slightly more efficient because it only needs to create a new string and not a temporary character array.If you want to use Apache Commons you can do the following:Result: someStringIf what you need is very simple (eg. java class names, no locales), you can also use the  class in the  library.Or you can prepare and reuse a converter object, which could be more efficient.To better understand philosophy of the Google Guava string manipulation, check out .A very short and simple static method to archive what you want:I have come accross this only today.  Tried to do it myself in the most pedestrian way.  That took one line, tho longish. Here goesGives:Before str = TaxoRanksAfter str = taxoRanks"},
{"body": "How many objects are created as a result of the statements in the sample code above and why? Is there any IDE in which we can see how many objects are created (maybe in a debug mode)?The answer, surprisingly, is zero.All the s from -128 to +127 are pre-computed by the JVM.Your code creates  to these  objects.The strictly correct answer is that the number of  objects created is .  It could be between 0 and 3, or 256 or even more, depending onThe  values for -128 to 127 are not strictly required to be .  In fact,  which specified the Boxing conversion says this:Two things to note:Even the javadoc for  does not  that the results are cached eagerly.If we examine the Java SE source code for  from Java 6 through 8, it is clear that the current Java SE implementation strategy is to precompute the values.  However, for various reasons (see above) that is still not enough to allow us to give a definite answer to the \"how many objects\" question. First of all: The answer you are looking for is , as others already mentioned.But let's go a bit deeper. As Stephen menthioned it depends on the time you execute it. Because the cache is actually lazy initialized. If you look at the documentation of java.lang.Integer.IntegerCache:This means that if it is the first time you call any Integer you actually create:From the second time on you call them, you create 0 Objects.Things get more funny once you make the numbers a bit higher. E.g. by the following example:Valid options here are: 0, 1 or any number between 1629 to 2147483776 (this time only counting the created Integer-values.\nWhy? The answer is given in the next sentence of Integer-Cache definition:So you actually can vary the size of the cache which is implemented.Which means you can reach for above line:  This is only guaranteed on Oracle / Open JDK (i checked Version 7 and 8)As you can see the completely correct answer is not so easy to get. But just saying  will make people happy.PS: using the menthoned parameter can make the following statement true: The compiler unboxes the  objects to s to do arithmetic with them by calling  on them, and it calls  to box the  results when they are assigned to  variables, so your example is equivalent to:The assignment  is a completely normal object reference assignment which creates no new objects. It does no boxing or unboxing, and doesn't need to as  objects are immutable.The  method is allowed to cache objects and return the same instance each time for a particular number. It is  to cache ints \u2212128 through +127. For your starting number of , all the numbers are small and guaranteed to be cached, so the number of objects that need to be created is . Strictly speaking,  is allowed to cache instances lazily rather than having them all pre-generated, so the example might still create objects the first time, but if the code is run repeatedly during a program the number of objects created each time  approaches 0.What if you start with a larger number whose instances will not be cached (e.g., )? Then each  call must create one new  object, and the total number of objects created each time is .(, maybe it's still zero, or maybe it's millions. Remember that compilers and virtual machines are allowed to rewrite code for performance or implementation reasons, so long as its behavior is not otherwise changed. So it could delete the above code entirely if you don't  the result. Or if you try to print , it could realize that  will always end up with the same constant value after the above snippet, and thus do all the arithmetic at compile time, and print a constant value. The actual amount of work done behind the scenes to run your code is always an implementation detail.)You can debug the Integer.valueOf(int i) method to find out it by yourself.\nThis method is called by the autoboxing process by the compiler."},
{"body": "I have a string with lots of special characters. I want to remove all those, but keep alphabetical characters.How can I do this?That depends on what you mean. If you just want to get rid of them, do this:\nor the equivalent:(All of these can be significantly improved by precompiling the regex pattern and storing it in a constant)Or, with :But if you want to turn accented characters into something sensible that's still ascii, look at these questions:I am using this. It replace all special characters from string.Here \\w : A word character, short for [a-zA-Z_0-9]\\W  : A non-word characterYou can use the following method to keep alphanumeric characters.And if you want to keep only alphabetical characters use thisHere all the special characters except space, comma, and ampersand are replaced. You can also omit space, comma and ampersand by the following regular expression.Where Input is the string which we need to replace the characters.You can use basic regular expressions on strings to find all special characters or use pattern and matcher classes to search/modify/delete user defined strings. This link has some simple and easy to understand examples for regular expressions: You can get unicode for that junk character from charactermap tool in window pc and add \\u e.g. \\u00a9 for copyright symbol.\nNow you can use that string with that particular junk caharacter, don't remove any junk character but replace with proper unicode."},
{"body": "I have an object called , and it has , , , etc. For the , I have to generate random string consist of seven numeric charaters,\neg.And I have to make sure that there is no duplicate id.Generating a random string of characters is easy - just use  and a string containing all the characters you want to be available, e.g.Now, for uniqueness you'll need to store the generated strings somewhere. How you do that will really depend on the rest of your application.This is very nice: If you want uniqueness (with high probability) consider using MD5 or SHA hashes. You can also use UUID class from java.util package, which returns random uuid of 32bit characters String. The first question you need to ask is whether you really need the ID to be random. Sometime, sequential IDs are good enough.Now, if you do need it to be random, we first note a generated sequence of numbers that contain no duplicates can not be called random. :p Now that we get that out of the way, the fastest way to do this is to have a  or  containing all the IDs already generated. Whenever a new ID is generated, check it against the hashtable, re-generate if the ID already occurs. This will generally work well if the number of students is much less than the range of the IDs. If not, you're in deeper trouble as the probability of needing to regenerate an ID increases, P(generate new ID) = number_of_id_already_generated / number_of_all_possible_ids. In this case, check back the first paragraph (do you need the ID to be random?).Hope this helps.Many possibilities...You know how to generate randomly an integer right?\nYou can thus generate a char from it... (ex 65 -> A)It depends what you need, the level of randomness, the security involved... but for a school project i guess getting UUID substring would fit :)I think the following class code will help you. It supports multithreading but you can do some improvement like remove sync block and and sync to getRandomId() method."},
{"body": "I have a \nI want to convert into a string array.\nHow do I do it?\nIs there any java built in function? Manually I can do it but I'm searching for a java built in function.I want an array where each character of the string will be a string.\nlike char 'n' will be now string \"n\" stored in an array.To start you off on your assignment,  splits strings on a regular expression, this expression may be an empty string:Yields the array:Getting rid of the empty 1st entry is left as an exercise for the reader :-)Note: In Java 8, the empty first element is no longer included.The second line allocates a String array with the length of 1. Note that you don't need to specify a length yourself, such as:instead, the length is determined by the number of elements in the initalizer. Usingcreates an array with a length of 3.Assuming you really want an array of single-character strings (not a  or )1. Using a regex:The zero width negative lookahead prevents the pattern matching at the start of the input, so you don't get a leading empty string.2. Using :I guess there is simply no need for it, as it won't get more simple thanOf course if you insist, you could write:[Edit]\nIf you want single-letter Strings, you can use:Unfortunately s[0] will be empty, but after this the letters n,a,m,e will follow. If this is a problem, you can use e.g. System.arrayCopy in order to get rid of the first array entry.In java 8, there is a method with which you can do this: toCharArray():This results to the following array:String array = array of characters ? Or do you have a string with multiple words each of which should be an array element ?Convert it to type ?An additional method:As was already mentioned, you could convert the original String \"name\" to a char array quite easily:To continue this train of thought, you could then convert the char array to a String array:At this point, your stringArray will be filled with the original values from your original string \"name\".\nFor example, now callingWill return the value \"n\" (as a String) in this case.Method  will generate empty 1st, you have to remove it from the array. It's boring. You could use , though this is quite lengthy and only works with java 8. Here are a few more methods:\n\n\nThe last one is just unnecessarily long, it's just for fun!Based on the title of this question, I came here wanting to convert a String into an array of substrings divided by some delimiter. I will add that answer here for others who may have the same question.This makes an array of words by splitting the string at every space:This creates the following array:Tested in Java 8here is have convert simple string to string array using split method.OutputSplitting an empty string with  returns a . In most cases you'd probably prefer to get an empty array, or a null if you passed in a null, which is exactly what you get with .Another option is google guava  and  which return an iterator and a list correspondingly. Unlike the apache version Splitter will throw an NPE on :If you want a list rather than an iterator then use the  flavour."},
{"body": "I am trying to read the contents of a file using FileReader . But i want to read the file without reading a line by line . Is it possible to read the whole file without loop.\nI am using the following codeIf the file is , you can read the whole data once:Java 7 one line solutionor You can try using  if you are using JDK5 or higher.Or you can also use If you are using Java 5/6, you can use  for read file to string. The class  contais several method for read files.e.g. using the method :"},
{"body": "In CDI there is the  and the ()  pseudo-scope. What is the difference between them? Besides the fact that  is proxied, and  is not.Can I just change my  bean to ? Can  bean have two (or more) instances? is not part of the CDI specification. It is part of EJB and  (JSR-330). It is not mentioned in the spec what is its behaviour, so you can only rely on what's written in the Weld documentation.\n(and works as expected in mine!)Additionally to the other answers so far I'd like to add some more points for clarification in real world scenarios.For me this question developed out of \nIn some discussion there I stated this and can't find a valid argument against it so far:(debatable but not conclusive) arguments (from my point of view) against it so far:\n(@BalusC and all others: I'd like to see them beeing conclusive, but if not, the above may hold true and nevertheless the arguments may still help the reader to get the differences/advantages/disadvantages/ bad/good practices)but:... which still holds true in my case.but:(I can't see the sledgehammer here - sorry ...)\nIt's good to know the locking defaults (I was not aware of it), but this seems to be incorrect again:  in JSR-299 refers to Singleton session beans (, not ), not JSR-299 managed beans in a built-in scope called Singleton.  You might find in your server that  is one-per EAR or one-per WAR/EJB-JAR as it is not clear in the specification, but you should definitely not expect it to be one per JVM.There is one more difference:\n@Singleton is not bean defining annotations, as the Singleton scope is not a normal scope.\nThen @ApplicationScoped is bean defining annotations.With CDI 1.1 spec: When application in discovery-mode = annotated, Weld does not identify beans with @Singleton and not  loaded thisOne of the major differences that you can write your class with default contractor has private access modifier when using , but your class should have default contractor with at least default access modifier when using  and this is  implementation "},
{"body": "I downloaded Android Studio, fixed the JDK Environmental Variable, but when I try to create a New Project, I get an error that saysI opened up android.bat in the SDK but it said I was already running version 22.Anyone else getting this?It just happened because you already have your SDK setted up for Android Developers Bundle with eclipse. Simply open your SDK manager in the ADT Bundle and update you Android SDK Tools from 21.1 to 22 and you are good to go.Worked for me.First of all, on Windows and Mac, the individual tools and other SDK packages are saved with the Android Studio application directory.Make sure your android-sdk-path is correct and the sdk tool version is 22 or later.Then open the Configure--> Project Defaults --> Project Structure, set your project sdk is Android SDK.enjoy.As for me, i make next:I did all of the above and still got the \"....missing templates blah blah\". What worked for me was to go to Configure>Project Defaults>Project Structure>Project and select Android SDK\nthen  Configure>Project Defaults>Project Structure>SDKs map the Android SDK home path to the sdk folder in the ADT bundle (for me it was \"C:\\Users\\home\\Toolbox\\adt-bundle-windows-x86\\sdk\").\nI then selected Android 4.1.2 clicked apply and it worked.\nI then went back to the Configure>Project Defaults>Project Structure>SDKs and then selected Android 4.2.2 and now that worked too (strange though as when I selected Android 4.2.2 first time the Apply button was grayed out)I ran into this problem because I wanted to update from an old version. In doing this, I downloaded the latest version from the , then unzipped and copied over my existing Android Studio install which did have the sdk folder inside.Going back and looking at it, I see quite plainly that there was a note that I previously ignored:For OS X users, this means going to your old version of Android Studio (if you haven't copied over it yet) and right-clicking and selecting , then copying the  folder that's inside, then putting that into the new version of Android Studio.If, like me, you already copied over the old version, then you'll need to  first which does contain the SDK.They released a new sdk today. You need to update to it.I was still hitting this, and figured it was due to something I had misconfigured (which turned out to be the case).  The error message is a little confusing, too, because I believe that they are referring to is the version of the ADT tools, not the SDK.  For example, the version of Android 4.3 (which is about the latest) is 18. As of the latest source for Android Studio (which you can clone from here: ), that message is generated from NewProjectWizard.java at about line 75 if TemplateManager.templatesAreValid() is false.  And it checks that by looking for the existence of the file [rootTemplatesFolder]/gradle/wrapper/gradlew .It gets the [rootTemplatesFolder] from the SDK(s) you specified in the \"Project Structure\" settings for default projects.  In my case, I had several specified - both the new ones pointing to the sdk directory that's (thankfully) part of the Android Studio, and a few old ones I had somewhere else.  I should not have included the old ones at all, but I'm a newb to this and the GUI let me do it.  The NewProjectWizard was checking the tools area of that one first, which did not have that file, since the tools version with it was older than version 22.I had to use dtruss to watch the system calls of Android Studio to see where it was looking for that file, at which point I could tell what my silly problem was.  I have a few more notes on this, including a screenshot of my particular misconfiguration, at Note: It seems you have to restart Android Studio for the \"New Project Settings\" here to take effect.for ubuntu: \nOpen sdk manager from Android Studio or configuration.\nmake sure you download or update the latest release SDK and build tools.just Update sdk with sdk manager \nit worked for me "},
{"body": "I haven't been able to find an adequate answer to what exactly the following error means: Notes:Relevant code:This usually means that there was a network error, such as a TCP timeout. I would start by placing a sniffer (wireshark) on the connection to see if you can see any problems.  If there is a TCP error, you should be able to see it.  Also, you can check your router logs, if this is applicable.  If wireless is involved anywhere, that is another source for these kind of errors.This also happens if your TLS client is unable to be authenticate by the server configured to require client authentication.The only time I've seen something like this happen is when I have a bad connection, or when somebody is closing the socket that I am using from a different thread context.Are you accessing http data?  Can you use the HttpClient library instead of the standard library?  The library has more options and will provide better error messages.Try adding 'autoReconnect=true' to the jdbc connection stringThis error occurs when a connection is closed abruptly (when a TCP connection is reset while there is still data in the send buffer). The condition is very similar to a much more common 'Connection reset by peer'. It can happen sporadically when connecting over the Internet, but also systematically if the timing is right (e.g. with keep-alive connections on localhost).An HTTP client should just re-open the connection and retry the request. It is important to understand that when a connection is in this state, there is no way out of it other than to close it. Any attempt to send or receive will produce the same error.Don't use , use Apache-Commons  which has a retry mechanism, connection pooling, keep-alive and many other features.Sample usage:This will happen from time to time either when a connection times out or when a remote host terminates their connection (closed application, computer shutdown, etc). You can avoid this by managing sockets yourself and handling disconnections in your application via its communications protocol and then calling  and  to clear up the session.Look if you have another service or program running on the http port. It happened to me when I tried to use the port and it was taken by another program.If you are using Netbeans to manage Tomcat, try to disable HTTP monitor in Tools - ServersI too had this problem. My solution was:COPY FROM A WEBSITE -->By using the  method, you can explicitly set a delay before a reset is sent, giving more time for data to be read or send.Maybe it is not the answer to everybody but to some people."},
{"body": "The book \"Essential JNI: Java Native Interface\" by Rob Gordon contains the following code example to convert a jstring to a C string:Note that it only calls  if  is true. But the book  (alternate link: ) says:I am correct in assuming this is a bug in Gordon's book?Yes, your assumption is correct (you should always call ReleaseStringUTFChars)."},
{"body": "I have seen the question  and I understand the difference between JSRs 308 and 305. I also understand that, at this time, 308 is slated for Java 7, and 305 is not, and I am curious about the overall status of 305.Specifically, I am using  and  in some of my projects (in a similar manner to what ) and was wondering if there is a more \"future direction\"-friendly approach I should be using instead. I am planning to also ask about this on the JSR-305 group, but that group does not have much activity and I was just wondering if anyone here had any more info.As described in this ,  proposes new annotations such as , while  proposes allowing annotations in new places such as on generic declarations. JSR 308 (annotations in new places) is included in  under .As far as I can tell, JSR-305 (new annotations) is dormant.  A  about it's status in the google group has been unanswered since 2010.  There is a reference implementation of the JSR-305 annotations  which is used by many projects, including guava.  With maven you can use the JSR-305 reference implementation by adding this to your pom,JSR 305 will not be part of Java 8:Java 8 is described by JSR 337: the specification has reached Final status: .According to Alex Millers , JSR-308 (and 305) are scheduled to go in to Java 7.  Perhaps he will show up here and give you more information."},
{"body": "C# has Int.TryParse: The great thing with this method is that it doesn't throw an exception for bad data.In java,  will throw an exception, and in cases where this may happen a lot performance will suffer.Is there a way around this somehow for those cases where performance is an issue?The only other way I can think of is to run the input against an regex, but I have to test to see what is faster.No. You have to make your own like this:  ...and you can use it like this:  Apache Commons has an  class which appears to do what you want. Java provides no in-built method for doing this. -- just saw your comment about the performance problems associated with a potentially bad piece of input data. I don't know offhand how try/catch on parseInt compares to a regex.  I would guess, based on very little hard knowledge, that regexes are not hugely performant, compared to try/catch, in Java.Anyway, I'd just do this:"},
{"body": "In , all the methods that require the lock copy it to a local  variable before calling .Is there any reason to copy  to a local variable  when the field  is ?Additionally, it also uses a local copy of  before acting on it:It's an extreme optimization Doug Lea, the author of the class, likes to use. Here's a post on  on the core-libs-dev mailing list about this exact subject which answers your question pretty well.from the post: gives some answers. In substance:"},
{"body": "This is a basic question but I can't find an answer.  I've looked into floating point arithmetic and a few other topics but nothing has seemed to address this.  I'm sure I just have the wrong terminology.Basically, I want to take two quantities - completed, and total - and divide them to come up with a percentage (of how much has been completed).  The quantities are s.  Here's the setup:I've tried reassigning the result to a double - it prints .  Where am I going wrong?Incidentally, the next step is to multiply this result by 100, which I assume should be easy once this small hurdle is stepped over.BTW not homework here just plain old numskull-ness (and maybe too much coding today).Converting the  is too late; the calculation has already taken place in integer arithmetic.  You need to convert the  to :Note that you don't actually need to convert  of them; so long as one is , the other will be implicitly converted.  But I prefer to do both, for symmetry.You don't even need doubles for this. Just multiply by 100  and then divide. Otherwise the result would be less than 1 and get truncated to zero, as you saw.edit: or if overflow is likely, if it would overflow (ie the dividend is bigger than 922337203685477581), divide the divisor by 100 first.Convert both  and  to  or at least cast them to  when doing the devision. I.e. cast the varaibles to double not just the result.Fair warning, there is a  when working with  and .If you don't explicitly cast one of the two values to a float before doing the division then an integer division will be used (so that's why you get 0). You just need one of the two operands to be a floating point value, so that the normal division is used (and other integer value is automatically turned into a float).Just try with and it will be fine.Just type cast either of them.As explain by the , integer operation are quite simple.So to make it short, an operation would always result in a  at the only exception that there is a  value in it.Note that the priority of the operator is important, so if you havethe  operation would result in an , it would be promote into a  during the operation "},
{"body": "I am wondering if it is possible to call python functions from java code using jython, or is it only for calling java code from python?You can easily call python functions from Java code with Jython. That is as long as your python code itself runs under jython, i.e. doesn't use some c-extensions that aren't supported.If that works for you, it's certainly the simplest solution you can get. Otherwise you can use  from the new Java6 interpreter support.A simple example from the top of my head - but should work I hope: (no error checking done for brevity)Hey I thought I would enter my answer to this even though its late. I think there are some important things to consider first with how strong you wish to have the linking between java and python.  Do you only want to call functions or do you actually want python code to change the data in your java objects? This is very important. If you only want to call some python code with or without arguments, then that is not very difficult. If your arguments are primitives it makes it even more easy. However if you want to have java class implement member functions in python, which change the data of the java object, then this is not so easy or straight forward. are we talking cpython or will jython do? I would say cpython is where its at! I would advocate this is why python is so kool! Having such high abstractions however access to c,c++ when needed. Imagine if you could have that in java. This question is not even worth asking if jython is ok because then it is easy anyway.So I have played with the following methods, and listed them from easy to difficult:  Trivially easy. Have actual references to java objects No CPython, Extremely Slow!Jython from java is so easy, and if this is really enough then great. However it is very slow and no cpython! Is life worth living without cpython I don't think so! You can easily have python code implementing your member functions for you java objects.Pyro is the remote object module for python. You have some object on a cpython interpreter, and you can send it objects which are transferred via serialization and it can also return objects via this method. Note that if you send a serialized python object from jython and then call some functions which change the data in its members, then you will not see those changes in java. You just need to remember to send back the data which you want from pyro. This I believe is the easiest way to get to cpython! You do not need any jni or jna or swig or .... You don't need to know any c, or c++. kool huh? Access to cpython, not as difficult as following methods Cannot change the member data of java objects directly from python. Is somewhat indirect, (jython is middle man).OMG this method is not for the faint of heart. And I can tell you it has taken me very long to achieve this in with a decent method. Main reason you would want to do this is so that you can run cpython code which as full rein over you java object. There are major major things to consider before deciding to try and bread java (which is like a chimp) with python (which is like a horse). Firstly if you crash the interpreter that's lights out for you program! And don't get me started on concurrency issues! In addition, there is allot allot of boiler, I believe I have found the best configuration to minimize this boiler but still it is allot! So how to go about this:\nConsider that C++ is your middle man, your objects are actually c++ objects! Good that you know that now. Just write your object as if your program as in cpp not java, with the data you want to access from both worlds. Then you can use the wrapper generator called swig () to make this accessible to java and compile a dll which you call System.load(dll name here) in java. Get this working first, then move on to the hard part!\nTo get to python you need to embed an interpreter. Firstly I suggest doing some hello interpreter programs or this tutorial . Once you have that working, its time to make the horse and the monkey dance! You can send you c++ object to python via [boost][3] . I know I have not given you the fish, merely told you where to find the fish. Some pointers to note for this when compiling.When you compile boost you will need to compile a shared library. And you need to include and link to the stuff you need from jdk, ie jawt.lib, jvm.lib, (you will also need the client jvm.dll in your path when launching the application) As well as the python27.lib or whatever and the boost_python-vc100-mt-1_55.lib.\nThen include Python/include, jdk/include, boost and only use shared libraries (dlls) otherwise boost has a teary. And yeah full on I know. There are so many ways in which this can go sour. So make sure you get each thing done block by block. Then put them together. It depends on what do you mean by python functions? if they were written in  you can not directly call them you will have to use , but if they were written in  you can easily call them from java, as jython ultimately generates java byte code.Now when I say written in cpython or jython it doesn't make much sense because python is python and most code will run on both implementations unless you are using specific libraries which relies on cpython or java.see here You can call any language from java using Depending on your requirements, options like  could be useful, which can be used to remotely call functions virtually in any language supporting the protocol.Several of the answers mention that you can use JNI or JNA to access cpython but I would not recommend starting from scratch because there are already open source libraries for accessing cpython from java. For example:Jython has some limitations:you can simply call python scripts (or bash or Perl scripts) from Java using Runtime or ProcessBuilder and pass output back to Java: Here a library that lets you write your python scripts once and decide which integration method (Jython, CPython/PyPy via Jep and Py4j) to use at runtime:  Since each method has its own benefits/drawbacks as explained in the link.It's not smart to have python code inside java. Wrap your python code with flask or other web framework to make it as a microservice. Make your java program able to call this microservice (e.g. via REST).Beleive me, this is much simple and will save you tons of issues. And the codes are loosely coupled so they are scalable."},
{"body": "The code says it all :-) Thanks for any help in advance!EDIT: What I actually want is that the \"???\" above are replaced by the value of the field . A link would not be perfect, but better than nothing :-)Do you mean ?"},
{"body": "I'm having trouble generating a session factory in Hibernate 4. In Hibernate 3 I simple did:Now I need to pass a ServiceRegistry class to buildSessionFactory, but the Javadocs are extremely vague on how to go about this. Any tips?Yes, they have deprecated the previous buildSessionFactory API, and it's quite easy to do well.. you can do something like this.. : ServiceRegistryBuilder is deprecated. you must use StandardServiceRegistryBuilderFor more reference and in depth detail, you can check the hibernate's official test case at  function (buildSessionFactory()).Try this!The following expresses the experience I had with hibernate 4.0.0.Final.The javadoc (distributed under LGPL license) of  class states that:After looking at issue 2578, i used something like this:For it to start reading configuration, i had to modify my hibernate 3.2.6 configuration and mapping files to use  and  and also remove the dtd specifications.I couldn't find a way for it to inspect mappings defined in hibernate.cfg.xml and    prefix for hibernate-related properties in  is no longer optional.This might work for some.I, for one, ran into some error because mapping files contained  and ended up using deprecated Configuration way:I had to programatically append event listeners because Configuration no longer looks for them in hibernate.cfg.xmlEven there is an update in 4.3.0 API. ServiceRegistryBuilder is also deprecated in 4.3.0 and replaced with the StandardServiceRegistryBuilder. Now the actual code for creating the session factory would look this .[quote from http://www.javabeat.net/session-factory-hibernate-4/]There are many APIs deprecated in the hibernate core framework. One of the frustrating point at this time is, hibernate official documentation is not providing the clear instructions on how to use the new API and it stats that the documentation is in complete. Also each incremental version gets changes on some of the important API. One such thing is the new API for creating the session factory in Hibernate 4.3.0 on wards. In our earlier versions we have created the session factory as below: and it is replaced with the new API. If you are using the hibernate 4.3.0 and above, your code has to be: It looks like there will be lot of changes in the 5.0 release. Still there is not much clarity on the deprecated APIs and the suitable alternatives to use. Every incremental release comes up with more deprecated API, they are in way of fine tuning the core framework for the release 5.0.The method  is deprecated from the Hibernate 4 release and it is replaced with the new API. If you are using the Hibernate 4.3.0 and above, your code has to be:In earlier versions session factory was created as below:The method buildSessionFactory is deprecated from the hibernate 4 release and it is replaced with the new API. If you are using the hibernate 4.3.0 and above, your code has to be like:"},
{"body": "How can I easily detect when a variable changes value? I would like the execution of the program to break on the debugger whenever a specified variable changes value. Right now I'm using Eclipse's debugger. For a class or instance variableOR\nToggle  Breakpoint on the line where the variable is declared, then right-click on the resulting entry, select \"breakpoint properties\" and deselect \"Field Access\"."},
{"body": "I'm new to a team working on a rather large project, with lots of components and dependencies. For every component, there's an  package where the exposed interfaces for that component are placed. Is this a good practice?My usual practice has always been interfaces and implementations go in the same package.Placing both the interface and the implementation is common place, and doesn't seem to be a problem.Take for example the Java API -- most classes have both interfaces and their implementations included in the same package. Take for example the  package:It contains the interfaces such as , , , while also having the implementations such as ,  and .Furthermore, the Javadocs are designed to work well in those conditions, as it separates the documentation into the  and  views when displaying the contents of the package.Having packages only for interfaces may actually be a little bit excessive, unless there are enormous numbers of interfaces. But separating the interfaces into their own packages just for the sake of doing so sounds like bad practice.If differentiating the name of a interface from an implementation is necessary, one could have a naming convention to make interfaces easier to identify:For any language, putting them together in the same package is fine. The important thing is what's exposed to the outside world, and how it looks from outside. Nobody's going to know or care if the implementation is in that same package or not.Let's look at this particular instance.If you have all public things in one package, and private things in another package that is not publicly exposed, the client of the library sees one package. If you move the private things to the package with the publicly exposed things, but do not expose them from within the package, the client sees exactly the same thing.Thus, this has the smell of a rule with no good reason: it's making a decision based on something being publicly visible without that decision having any effect on what's publicly visible.That said, if in any particular instance it seems like a good idea to split the interface and implementation in to separate packages, go right ahead and do that. Reasons for doing this that come to mind are that the package is huge, or you have an alternate implementation you might want to link in instead of the standard one.In many frameworks, such as OSGi, you almost have to. I think this promotes looser coupling, at the package instead of the jar level.One argument for putting interfaces in different packages is that it is easier to create 'api' jars that can be distributed to consumers of your product or service. It's perfectly possible to do this with interfaces and implementations together, but simpler to script if they are in different packages.We do this where I work (ie: put interface in one package and implementation in another) and the main advantage we get out of this is we can easily swap between implementations.I haven't much Java experience, but I like to do this as a good practice in C#/.NET because it allows for future expansion where the assemblies with the concrete classes which implement the interfaces may not be distributed all the way down to the client because they are proxied by a middleman factory or across the wire in a web service scenario.Yes, it's a very good practice, because it allows you to publish the interface without publishing your specific implementation.  That said, if you have no need to publish external interfaces, there's no problem with putting the interface definitions in the same package as the implementation.I'm doing this on a project and it is working well for me because of these reasons:Questions of program design generally involve benefits and drawbacks and there is no one-size-fits all answer.  Like why would you ever use this technique in a tiny 200-line program?  It makes sense for me, given my other architectural choices, for my specific problem. :)The book  advocates for putting interfaces in seperate projects/packages. The PCMEF+ architecture which the book talks about has the following principles:The description of principle #3 and #7 explain why it is a good idea:See this link: Put them in packages that reflect your projects.  It is fine and common to put interfaces and implementations together if they're part of the same project, but if you're writing an API, then someone else would likely be choosing a package name relevant to their project.In general, if it's for the same project, I don't see any benefit in keeping the interfaces in a separate package from their impls.  If it's getting cluttered, there may be other package naming issues, irrespective of the interface arrangement.I prefer them in the same package. Feels pointless to create a package specifically for interfaces. This is especially redundant for teams that simply love their interface prefixes and suffixes (e.g. the \"I\", and \"Impl\" for Java).If there's a needs to publish a set of interfaces as public API, it makes more sense to keep them in an entirely separate project and create project dependencies instead. But it all boils down to preference and convenience of the situation I suppose.I normally put Interfaces with the implementation however I can sort of see why you may want to keep them separate. Say, for instance, someone wanted to reimplement classes based upon your interfaces, they would need a jar/lib/etc with your implementation rather than just the interfaces. With them separate you could just say \"Here's my implementation of that interface\" and be done with it. Like I said, not what I do but I can sort of see why some might want to.I think it is important to note that for the OSGi framework, it is nicer that they are in different packages so that you can easily export a whole package while hiding the implementation packages.There are a lot of good reasons for putting interfaces in a separate package from implementation.  For example you may want to use container that supports  to wire up the necessary implementation(s) at run time, in which case only the interface needs to be present at build time and the implementation can be supplied at run time.  Alternatively, you may want to provide multiple implementations (for example using  implementations for testing) or multiple versions of a particular implementation at run time (for example for A/B testing, etc).  For these kinds of use cases it's more convenient to package interface and implementation separately."},
{"body": "Does Java have a using statement that can be used when opening a session in hibernate?In C# it is something like:So the object goes out of scope and closes automatically.Java 7 introduced  which brings this feature to the Java platform. Prior versions of Java didn't have anything resembling .As an example, you can use any variable implementing  in the following way:Java's  interface, implemented by streams, automagically extends , so you can already use streams in a  block the same way you would use them in a C#  block. This is equivalent to C#'s .As of  and can be auto-closed in ARM blocks. In previous versions of Hibernate . So you'll need to be on Hibernate >= 5.0 in order to use this feature., there was  such feature in Java (for Java 7 and up see  regarding ).You needed to do it manually and it :And that's just the code when neither  nor  can throw any exceptions.If you  only want to limit the scope of a variable, then a simple code block does the job:But that's probably not what you meant.Since Java 7 it does: The syntax for the code in the question would be:Note that  needs to implement  or one of its (many) sub-interfaces.The closest java equivalent isTechnically:No, Java has no  statement equivalent.As of now, no.However there is a proposal of  for Java 7.If you're interested in resource management,  offers the  annotation. Taken directly from their site:Please see this .To imitate such  behaviour, you will have to use a  block, where you would dispose of the resources within ., from  will be in Java 7.  This is feature is intended to bring similar functionality to Java as the .Net using syntax.To answer the question regarding limiting scope of a variable, instead of talking about automatically closing/disposing variables.In Java you can define closed, anonymous scopes using curly brackets. It's extremely simple.The variable  is only available in this scope, and not outside it.This can be useful if you have repeating variables which are only temporary.For example, each with index. Just like the  variable is closed over the for loop (i.e., is only available inside it), the  variable is closed over the anonymous scope.I also use this sometimes if you don't have a for loop to provide variable scope, but you want to use generic variable names.In java 8 you can use try. Please refer to following page. "},
{"body": "Consider this code:When using the  keyword, Java will create the   again right?\nWill this be stored on the regular heap or the  pool?\nHow many s will end in the  pool?If you use the  keyword, a new  object will be created. Note that objects are always on the heap - the string pool is not a separate memory area that is separate from the heap.The string pool is like a cache. If you do this:then the Java compiler is smart enough to make just one  object, and  and  will both be referring to that same String object. If you do this:then there will be one  object in the pool, the one that represents the literal , and there will be a separate  object, not in the pool, that contains a copy of the content of the pooled object. Since  is immutable in Java, you're not gaining anything by doing this; calling  never makes sense in Java and is unnecessarily inefficient.Note that you can call  on a  object. This will put the  object in the pool if it is not already there, and return the reference to the pooled string. (If it was already in the pool, it just returns a reference to the object that was already there). See the API documentation for that method for more info.See also  (Wikipedia).In , the first assignment is:whereas the second is:So the first is in the pool (at position #2) whereas the second will be stored in the heap.Since the   (16 bits, unsigned) the pool can contain at max  =  references. In the case you care .Each time your code create a string literalfor example: the JVM checks the string literal pool first. If the string already exists in the pool, a reference to the pooled instance returns. If the string does not exist in the pool, a new String object instantiates, then is placed in the pool. Java can make this optimization since strings are immutable and can be shared without fear of data corruptionThe only time you should use new String(foo) is when you want to break ==, which is an odd case, or when foo is a substring of a much larger string that has a limited lifetime, such asandBoth expression gives you String object, but there is subtle difference between them. When you create String object using new() operator, it always create a new object in heap memory. On the other hand, if you create object using String literal syntax e.g. \"Java\", it may return an existing object from String pool (a cache of String object in Perm gen space, which is now moved to heap space in recent Java release), if it's already exists. "},
{"body": "I'm trying to run this simple HelloWorld code written in Java from my browser ():I compiled it with , and then I created a WebApplication project. The  code that runs the applet is:If run the applet from NetBeans it works. But when I run the HTML code by double clicking it, the following message pops up from the browser:I tried with Internet\u00a0Explorer and Firefox but nothing.This message started to appear after the last update of Java. Where is the problem?After reading  mention....I was wondering how this would go for loose class files - the 'simplest' applets of all.That is the dialog seen for an applet consisting of loose class files being loaded off the  when the JRE is set to the default 'High' security setting.Note that a slight quirk of the JRE only produced that on point 3 of.If you load the simple applet (loose class file) seen at this  off the  - which boasts an  element of:It also seems to load successfully.  Implying that:- As of Java 7 update 51.I faced the same issue today, and I was able to fix the issue by changing the security settings on the Java Control Panel from  to .Well, setting the Java Security Setting to MEDIUM permanently is not really recommended as this will allow potentialy malicious software to run on your system and not be blocked. So I suggest after running your applet you may want to change back the setting to HIGH.If you are using , these settings are available using  (or your path setting to get the current Java tools). You can also edit the files in  to set \"deployment.security.level=MEDIUM\".Surprisingly, this information is not readily available from the Oracle web site. I miss java.sun.com...That's it!If you have no Medium security level, then you should add your application to the  ( \u2192  tab).If you are like me whose Java Control Panel  under Security Tab to change security level from High to Medium then follow these instructions: .Java applets do create a security risk, hence are disabled in most modern browsers. You have to lower the security to run it. There is a  for that.My problem case was to run portecle.jnlp file locally using Java8.What worked for me wasOn step 3, you might try also to add file:///c:/path/portecle.jnlp, but this addition didn't help with my case."},
{"body": "How do I redirect verbose garbage collection output to a file?  Sun\u2019s website shows an example for Unix but it doesn't work for Windows.From the output of :Documented :So the output looks something like this:If in addition you want to pipe the output to a separate file, you can do:On a ON an To add to the above answers, there's a good article:  by Patrick Peschlow.A brief excerpt:The flag  (or the alias ) activates the \u201csimple\u201d GC logging modeBy default the GC log is written to stdout. With  we may instead specify an output file. Note that this flag implicitly sets  and  as well.If we use  instead of , we activate the \u201cdetailed\u201d GC logging mode which differs depending on the GC algorithm used.With  a timestamp reflecting the real time passed in seconds since JVM start is added to every line.If we specify  each line starts with the absolute date and time. introduces a common logging system for all components of the JVM which will change (and IMO simplify) how logging works with GC. JEP 158 added a new command-line option to control logging from all components of the JVM: For example, the following option:will log messages tagged with  tag using  level to . Or this one:would log messages tagged with  tag using  level to a file called  with no decorations. For more detailed discussion, you can checkout the examples in the  page."},
{"body": "I don't have much memory on my PC and a pretty weak processor. Although netbeans is by far my favorite IDE it is almost unbearable to use on my present computer because of the project scanning that starts automatically when I open the program.Is there a way to prevent netbeans from scanning projects?Hey George I don't know  if this is much of an answer but I right-click and choose 'close' on the projects that I don't need open. There's no point in having all your past projects listed there. Just have the one that you are developing open. You  can always reopen the other projects from the menu. Once all the projects you aren't using are closed they won't be scanned each time you start Netbeans.In addition to creating smaller  for the folders you really work on and then a  to group them (Mateng), you can try excluding folders that you will never work on such as  folders and so on. To ignore those folders, go to:From NetBeans Help: Try this: i know this is an old question but this may help others...\nTo enable or disable background scanning you can find the option under menu Tools -> Options -> Miscellaneus -> FilesIn addition to  (David) you can create project groups containing related projects (or just one): . Project groups can then be opened by pointing at them from the same menu. Best of all: Each group remembers which files were open in the editor windows the last time. I organize all my projects into groups and it reduces scanning significantly. (btw: There's a handy plugin providing a ) \nI am also using  for a while now - really good. Kudos for that answer. Stop NetBeans scanning projects :  I don't know whether you can disable the project scanning or not. Even if you can, I doubt it will ever work properly again. There are a few tips which I have done and it speed up my Netbeans.Netbeans consumes a lot of memory so adding memory also increases its performance (OS does not need to swap between memory and page file when memory is running low) (but this is probably not an option for you). Also, Netbeans consists of hundreds of files which needs to be loaded at start up so the bottom neck is the speed of your hard disk.And another quick thing you can do just delete the nbproject folder inside your project then open the NeteBeans. then the project remove from the list. this I do some times when it got freeze I've stumbled upon this problem aswell.The most simple thing is to edit the netbeans config so it doesn't load all your projects. \nyou can always reopen the other projects from the menu. once all the projects you arent using are closed they wont be scanned each time you start netbeans\nJust change the following line in netbeans.conf found under etc folder# ${HOME} will be replaced by JVM user.home system property\n netbeans_default_userdir=\"${HOME}/.netbeans/changeme\"Try this Netbeans plugin. This reduces the load for some extend.Not exactly the case of question, but sometimes \"scanning projects\" can be stopped just by restarting Netbeans. In my case, with jdk 1.8, there is a big issue when there are multiple static imports (see the example). It seems that there is a problem with javac. The compiler is very slow when checking such a .java file and NetBeans scanning is very very slow. It seems that the compilation and scanning time is increasing very fast with each repeated static  import. So, if that is your case, just remove repeated importsScanning performance of Netbeans can be improved using the following procedure :\n1) Go to Window-->Files. This opens the Files Tab.\n2) In the Files Tab for each opened project open the nbproject folder and inside it open the project.properties file.\n3) Now in this file below the property \"excludes\" there are file references listed for all your referred Libraries (JARs)\n4) There might be some repeated file references with paths that may be old or on someone else's machine(if you are working in a group and transferred projects from someone's machine)\n5) Delete those old path references.\nExample -\n\n\n\n\n  6)Also locate the property \"javac.classpath\" and delete the unnecessary classpath entries corresponding to the deleted references as described above.\nExample -\n\n\n\n\n  7) So now the file reference mentioned in the file reference section and the javac.classpath property is same and points to a valid Library (JAR) address on your machine or network.\nExample -\n\n\n\n\n\n\n\n\n\n  The reason the above procedure worked (in my case) is because it prevents Netbeans from scanning unnecessary Library paths that may not be present on your machine/network.Plugin download - Direct DownloadI have the quickest and easiest way.Just put the netbeans metadata to another location instead of putting it on the project directoryIf your project is a Maven structured project you can use a simple trick to make your and NetBeans life a lot easier. I have my projects inside of c:\\dev on my machine. That's the place where Netbeans is working with. If I build in this folder then NetBean's background process get very busy. But if I copy the  project for example to  before I start  inside of  then NetBeans does not need to scan the changes that happen in this folder. It does not know about it. I use on a windows machine:It is a windows native command. No additional installation necessary. It helped me a lot decrease build time and also to avoid never ending scans on Netbeans.If you use tools like JRebel you can still work like this when you update the changed classes to your c:\\deploy\\trunk folder. You can use the same command. It is of course a bit of a workaround, but it helps a lot. :-), the  plugin from  does not work. Use  instead, as it is current and works fine on stable releases.On a personal note, this brought my netbeans memory consumption for general use down from 20gb+ during idle to about 2gb consistently, and provides a good workaround for the scanner constantly hanging and leaking memory, particularly in very large projects or those with a ton of symlinks.My project became Very Big over timeIn the below 2 cases, it is too slow:  \n1. Doing Window > Reset Windows only solves temporarily\n2. Sometimes felt my GIT repository integration with Netbeans is the main issue, but there was no clear proof for it  Run below commands:   Below commands have automated delete commandsAnd, the problem 1) is now rarely comes up, other times Netbeans loads almost immediately.  root\n....f1\n........f11\n........f12\n....f2\n........f21\n........f22  root is a folder and also it's the main NetBeans project\nf1, f2 are just folders\nf11, f12, f21, f22 are sub-folders that are also NetBeans projects too  Earlier, I was opening root Netbeans project, and the system became too slow due to netbeans scanning the whole project from root, and antivirus was working very hard to cooperate with Netbeans project scanning, result everything in system gets slow.  Now, the solution is open sub-projects like f11, f12, f21, f22, etc. you can open many small sub-project, the Netbeans project scanning issue is fully gone.My Netbeans 8.0.2 would crash on my Macbook pro due to \"Scanning projects...\" hogging up my CPU. I couldn't stop the process, however, I could make the process finish quicker by increasing the Java heap memory in netbeans.conf.Replace this:with:"},
{"body": "Since Java8 has been recently released and its brand new lambda expressions looks to be really cool, I was wondering if this means the demise of the Anonymous classes that we were so used to.I've been researching a bit about this and found some cool examples about how Lambda expressions will systematically replace those classes, such the Collection's sort method, which used to get an Anonymous instance of Comparator to perform the sort: Now can be done using Lambdas: And looks surprisingly concise. So my question is, is there any reason to keep using those classes in Java8 instead of Lambdas?Same question but in the opposite direction, what are the benefits of using Lambdas instead of Anonymous classes, since Lambdas can only be used with single method interfaces, is this new feature only a shortcut only used in few cases or is it really useful?An anonymous inner class (AIC) can be used to create a subclass of an abstract class or a concrete class. An AIC can also provide a concrete implementation of an interface, including the addition of state (fields). An instance of an AIC can be referred to using  in its method bodies, so further methods can be called on it, its state can be mutated over time, etc. None of these apply to lambdas.I'd guess that the majority of uses of AICs were to provide stateless implementations of single functions and so can be replaced with lambda expressions, but there are other uses of AICs for which lambdas cannot be used. AICs are here to stay.Another difference between AICs and lambda expressions is that AICs introduce a new scope. That is, names are resolved from the AIC's superclasses and interfaces and can shadow names that occur in the lexcially enclosing environment. For lambdas, all names are resolved lexically.Lambdas though a great feature, will only work with SAM types. That is, interfaces with only a single abstract method. It would fail as soon as your interface contains more than 1 abstract method. That is where anonymous classes will be useful.So, no we cannot just ignore anonymous classes. And just FYI, your  method can be more simplified, by skipping the type declaration for  and :You can also use method reference here. Either you add a  method in  class, and use:or, add a getter for , directly get the  from  method:When application is launched each class file must be loaded and verified.Anonymous classes are processed by compiler as a new subtype for the given class or interface, so there will be generated a new class file for each.Lambdas are different at bytecode generation, they are more efficient, used invokedynamic instruction that comes with JDK7.For Lambdas this instruction is used to delay translate lambda expression in bytecode untill runtime. (instruction will be invoked for the first time only)As result Lambda expression will becomes a static method(created at runtime).\n(There is a small difference with stateles and statefull cases, they are resolved via generated method arguments)Lambda's in java 8 was introduced for functional programming. Where you can avoid boilerplate code. I came across this interesting article on lambda's.It's advisable to use lambda functions for simple logics. If implementing complex logic using lambdas will be a overhead in debugging the code in case of issue."},
{"body": "Is there some way to see the native code produces by the JIT in a JVM?Assuming you're using the Sun Hotspot JVM. Add the flag To whatever you're running. This will only print the assembly for code that has been JIT'd (i.e. you don't get to see assembly for non JIT'd stuff) but I think that's what you want. If you want to see what everything would like if it were JIT'd you could probably tweak the JIT threshold via:As explained by other answers, you can run with the following JVM options:You can also filter on a specific method with the following syntax:Notes:If you are running Windows,  has instructions on how to build and install  and  which are required to make it work. We copy below and extend the content of that page* for reference:You can download prebuilt binaries for Windows from the  projectThe DLL can now be installed by copying it from  or  to your JRE's  or  directory. You can find all such directories on your system by searching for .Bonus tip: if you prefer Intel ASM syntax to AT&T, specify  alongside any other PrintAssembly options you use.You need an hsdis plugin to use . A convenient choice is the hsdis plugin based on FCML library.It can be compiled for UNIX-like systems and on Windows you can use pre-built libraries available in the FCML  section on Sourceforge:Additional configuration parameters: Print machine code before the mnemonic.\n Use the Intel syntax.\n Use the AT&T assembler syntax (GNU assembler compatible).\n Prints IMM and displacement as decimal values.\n Padding for the mnemonic part of the instruction.\n Padding for the machine code.\n Shows the default segment registers.\n Show leading zeros in case of HEX literals.The Intel syntax is a default one in case of Windows, whereas the AT&T one is a default for the GNU/Linux.For more details see the For the HotSpot (was Sun) JVM, even in product modes:Some assembly required:  it needs a plugin.I believe WinDbg would be helpful if you are running it on windows machine.\nI have just run one jar.Highlighted lines is direct running JIT-ed code on JVM.For additional info here is the  how to trace back JIT-ed code from memory dumps using process explorer and WinDbg.Another way to see machine code and some performance data is to use AMD's CodeAnalyst or OProfile, which have a Java plugin to visualize executing Java code as machine code.Print the assembly of your hotspots with JMH's perfasm profilers ( or ). JMH does require the  library since it relies on ."},
{"body": "I have some Junit unit tests that require a large amount of heap-space to run - i.e. 1G. (They test memory-intensive functionality for a webstart app that will only run with sufficient heap-space, and will be run internally on Win 7 64-bit machines - so redesigning the tests isn't a practical suggestion.)I am developing in Intellij IDEA, so I know I can set the JVM parameters (e.g. -Xmx1024M) for the test class. However, this is only for running the whole test class - if I want to run an individual test, I have to recreate the run congfigurations for that test method. Also, those are IDE and box specific - so if I switch boxes (I develop on multiple machines) or one of my colleagues tries to run the tests, those settings are not transferred. (Also, other IDEs like Eclipse and NetBeans are used by my colleagues.) FWIW, we're using mercurial for source code control.For the build cycle, we're using Maven, so I know how to specify the JVM parameters for that.So:\n- I'm looking for a way of specifying the JVM parameters that will apply for the whole test class and the individual test methods; and\n- I'd like to share those specification across IDEs on any machine (having picked up the code from the repository).In IntelliJ you can specify default settings for each run configuration. In  configuration dialog (the one you use to configure heap per test) click on  and . These settings will be automatically applied to each new JUnit test configuration. I guess similar setting exists for Eclipse.However there is no simple option to transfer such settings (at least in IntelliJ) across environments. You can commit IntelliJ project files to your repository: it might work, but I do not recommend it.You know how to set these for . Good. This is the most portable way (see Ptomli's answer for an example).For the rest - you must remember that JUnit test cases are just a bunch of Java classes, not a standalone program. It is up to the runner (let it be a standalone JUnit runner, your IDE,  to set those options. That being said there is no \"portable\" way to set them, so that memory settings are applied irrespective to the runner.To give you an example: you cannot define  parameter when developing a servlet - it is up to the container to define that. You can't say: \"this servlet should always be run with .In Maven you can configure the surefire pluginIf you use Maven for builds then this configuration will be carried in the source tree and applied when tests are carried out. See the  documentation.I agree with the others who said that there is no simple way to distribute these settings. For Eclipse: ask your colleagues to set the following:After that all test will run with  but unfortunately you have set it in every Eclipse installation. Maybe you could create a custom Eclipse package which contains this setting and give it to you co-workers.The following working process also could help: If the IDE cannot run a test the developer should check that Maven could run this test or not.Parameters can be set on the fly also.  See According to this support question\nthe -Xmx argument for an IntelliJ junit test run will come from the maven-surefire-plugin, if it's set.This pom.xml snippetseems to pass the -Xmx1024 argument to the junit test run, with IntelliJ 2016.2.4.An eclipse specific alternative limited to the java.library.path JVM parameter allows to set it for a  specific source folder rather than for  the whole jdk as proposed in another response: For those interested on detail on why maven argline tag should be preferred to the systemProperties one, look, for example:   You can use systemPropertyVariables (java.protocol.handler.pkgs is your JVM argument name):"},
{"body": "I am implementing a class to be Serializable (so it's a value object for use w/ RMI). But I need to test it. Is there a way to do this easily?: I'm implementing the class, so it's trivial to stick Serializable in the class definition. I need to manually serialize/deserialize it to see if it works.I found this , is there a similar answer for Java?The easy way is to check that the object is an instance of  or , but that doesn't really prove that the object really is serializable.The only way to be sure is to try it for real. The simplest test is something like:and check it doesn't throw an exception. provides a rather more brief version:and again, check for the exception.You can be more rigourous still, and check that it deserializes back into something equal to the original:and so on.utility methods based on skaffman's answer:The short answer is, you can come up with some candidate objects and actually try to serialize them using the mechanism of your choice.  The test here is that no errors are encountered during marshalling/unmarshalling, and that the resulting \"rehydrated\" object is equal to the original.Alternatively, if you don't have any candidate objects, you could implement a reflection-based test that introspects the (non-static, non-transient) fields of your class to ensure that they too are Serializable.  Speaking from experience, this gets surprisingly complex surprisingly quickly, but it can be done to a reasonable extent.The downside to this latter approach is that if a field is e.g. , then you can either fail the class for not having a strictly serializable field, or simply assume that a serializable implementation of List will be used.  Neither is perfect.  (Mind you, the latter problem exists for examples too; if every example used in the test uses serializable Lists, there's nothing to prevent a non-serializable version being used by some other code in practice).You can do following test:Here is example for serializing and deserializing object to file:This code should do it...This only works for fully populated objects, if you require that any objects composed in your top level object are also serializable then they cannot be null for this test to be valid as serialization/deserialization skips the null objects"},
{"body": "I am new to Linux system and there seem to be too many Java folders. java -version gives me:When I am trying to build a Maven project , I am getting error:Could you please tell me which files I need to modify for root as well as not-root user and where exactly is java located?For all users, I would recommend placing the following line in This will update dynamically and works well with the  system. Do note though that the update will only take place in a new login shell.You could use /etc/profile or better a file like /etc/profile.d/jdk_homeYou have to remember that this file is only loaded with new login shells.. So after bash -l or a new gnome-session and that it doesn't change with new Java versions.None of the other answers were \"sticking\" for me in RHEL 7, even setting  and  directly in  or  would not work. Each time I tried to check if  was set, it would come up blank:What I had to do was set up a  in :I initially neglected the first line (the ), and it won't work without it.Now it's working:Doing what Oracle does (as a former Sun Employee I can't get used to that one)ln -s latestJavaRelease /usr/java/default\nWhere latestJavaRelease is the version that you want to usethen export JAVA_HOME=/usr/java/defaultCopy the bin file path you installed\"YOUR PATH\"open terminal and edit environment file by typing following command,\"sudo nano /etc/environment\"In this file, add the following line (replacing YOUR_PATH by the just copied path):JAVA_HOME=\"YOUR_PATH\"That should be enough to set the environment variable. Now reload this file:\"source /etc/environment\"now test it by executing:echo $JAVA_HOMEOn Linux I add this line to my ~/.profile:It's Very easy to set path in Linux . Do as follows : Open terminal and type  sudo gedit .bashrc It will ask you your password . After typing password ,it will   open the bash file . Then go to end  and type below  \n               Then save the file and exit from fileProbably a good idea to source whatever profile you edit to save having to use a fresh login.either:\nsource /etc/\nor\n. /etc/Where  is whatever profile you edited.I use the line:to my ~/.profile so it uses the base of the default java directory at login time. This is for bash.While we are up to setting JAVA_HOME, let me share some benefits of setting JAVA_HOME or any other environment variable:1) It's easy to upgrade JDK without affecting your application startup and config file which points to JAVA_HOME. you just need to download new version and make sure your JAVA_HOME points to new version of Java. This is best benefit of using environment variable or links.2) JAVA_HOME variable is short and concise instead of full path to JDK installation directory.3) JAVA_HOME variable is platform independence i.e. if your startup script uses JAVA_HOME then it can run on Windows and UNIX without any modification, you just need to set JAVA_HOME on respective operating system.Read more: This is a very simple script to solve the problemAnd for testing:"},
{"body": "When I run my project, I get numerous outputs of this error:I notice that this problem has a pattern of being asked all over the web, but with no real answers. What is a general cause for this kind of error?NoClassDefFound error is a nebulous error and is often hiding a more serious issue. It is  the same as ClassNotFoundException (which is thrown when the class is just plain not there).NoClassDefFound  indicate the class is not there, as the javadocs indicate, but it is typically thrown when, after the classloader has loaded the bytes for the class and calls \"defineClass\" on them.  Also carefully check your full stack trace for other clues or possible \"cause\" Exceptions (though your particular backtrace shows none).The first place to look when you get a NoClassDefFoundError is in the static bits of your class i.e. any initialization that takes place during the defining of the class. If this fails it will throw a NoClassDefFoundError - it's supposed to throw an ExceptionInInitializerError and indicate the details of the problem but in my experience, these are rare. It will only do the ExceptionInInitializerError the first time it tries to define the class, after that it will just throw NoClassDefFound.  So look at earlier logs.I would thus suggest looking at the code in that HibernateTransactionInterceptor line and seeing what it is requiring. It seems that it is unable to define the class SpringFactory. So maybe check the initialization code in that class, that might help. \nIf you can debug it, stop it at the last line above (17) and debug into so you can try find the exact line that is causing the exception. Also check higher up in the log, if you very lucky there might be an ExceptionInInitializerError.You're missing the necessary class definition; typically caused by required JAR not being in classpath.From :I had faced the same issue, because the jar library was copied by other Linux user(root), and the logged in user(process) did not have sufficient privilege to read the jar file content."},
{"body": "I'm trying to implement paging using row-based limiting (for example:  and ) on a Hibernate Criteria query that has joins to other tables.Understandably, data is getting cut off randomly; and the reason for that is explained .As a solution, the page suggests using a \"second sql select\" instead of a join. How can I convert my existing criteria query (which has joins using ) to use a nested select instead?You can achieve the desired result by requesting a list of distinct ids instead of a list of distinct hydrated objects.Simply add this to your criteria:Now you'll get the correct number of results according to your row-based limiting. The reason this works is because the projection will perform the distinctness check  the sql query, instead of what a ResultTransformer does which is to filter the results for distinctness  the sql query has been performed.Worth noting is that instead of getting a list of objects, you will now get a list of ids, which you can use to hydrate objects from hibernate later.I am using this one with my codes.Simply add this to your criteria:that code will be like the select distinct * from table of the native sql. Hope this one helps.A slight improvement building on FishBoy's suggestion.It is possible to do this kind of query in one hit, rather than in two separate stages. i.e. the single query below will page distinct results correctly, and also return entities instead of just IDs.Simply use a DetachedCriteria with an id projection as a subquery, and then add paging values on the main Criteria object. It will look something like this:A small improvement to @FishBoy's suggestion is to use the id projection, so you don't have to hard-code the identifier property name.This helped me :DThe solution:works very well.I will now explain a different solution, where you can use the normal query and pagination method without having the problem of possibly duplicates or suppressed items.This Solution has the advance that it is:The complete Article can be found on Hibernate gives the possibility to define the association fetching method not only at design time but also at runtime by a query execution. So we use this aproach in conjunction with a simple relfection stuff and can also automate the process of changing the query property fetching algorithm only for collection properties.First we create a method which resolves all collection properties from the Entity Class:After doing that you can use this little helper method do advise your criteria object to change the FetchMode to SELECT on that query.Doing that is different from define the FetchMode of your entities at design time. So you can use the normal join association fetching on paging algorithms in you UI, because this is most of the time not the critical part and it is more important to have your results as quick as possible.if you want to use ORDER BY, just add:Below is the way we can do Multiple projection to perform DistinctExtraProjections.javaSample Usage:Referenced from  in some cases!\nWithout \nall query goes well!\nThis solution is bad!Another way is use SQLQuery. In my case following code works fine: In opposite to:where distinction is done in memory, after load entities!"},
{"body": "What I am trying to do is read a .java file, and pick out all of the identifiers and store them in a list.  My problem is with the .split() method.  If you run this code the way it is, you will get ArrayOutOfBounds, but if you change the delimiter from \".\" to anything else, the code works.  But I need to lines parsed by \".\" so is there another way I could accomplish this? takes a regex, and '.' has a special meaning for regexes.You (probably) want something like:Some folks seem to be having trouble getting this to work, so here is some runnable code you can use to verify correct behaviour.When splitting with a string literal delimiter, the safest way is to use the  method:As described by other answers, splitting with  is correct, but  will do this escaping for you.The argument to split is a regular expression. The period is a regular expression metacharacter that matches anything, thus every character in  is considered to be a split character, and is thrown away, and all of the empty strings between them are thrown away (because they're empty strings). The result is that you have nothing left.If you escape the period (by adding an escaped backslash before it), then you can match literal periods. ()Have you tried escaping the dot? like this:The argument to split is a regular expression.  \".\" matches anything so your delimiter to split on is anything.If performance is an issue, you should consider using  instead of .  is much much faster than , even though it is a \"legacy\" class (but not deprecated).You might be interested in the  class. However, the java docs advise that you use the .split method as StringTokenizer is a legacy class. This is  the best way to do this but, I got it done by doing something like following.   Output,   "},
{"body": "I am integrating OAuth login for Google+ on my android application, following the .According to the tutorial, I should add the Google Service plugin by adding\n dependency to top-level    in my android project.However, when I sync the gradle with the changes, I see the error as follows:In my :It seems that the android studio is not able to find google-services plugin from repositories. Does anybody have the same issue? Or, am I missing something?Any input will be greatly appreciated!Best regards,I ran into the same issue today. In the samples they use this line instead:\n\nThis works.For me I had to switch the repository to .  I was using mavenCentral and getting this error.  As soon as I switched to  it pulled the dependency down.To do this, open your  and replace each instance of  with Google updated . Where it was classpath 'com.google.gms:google-services:1.0' now reads classpath 'com.google.gms:google-services:1.3.0-beta1' like joluet suggested.Google now released the plugin v1.3.0 I was able to solve it using :For me i resolved this issue by doing following things :Apart from this make sure you have updated google play service and google repository in SDK.Hope this Helps , Cheers.As of , google released a newer version.Try adding:\nAnd don't forget to add  repository under buildscript.Thanks.I think you forgotten gradle's project level,From :Add the dependency to your  build.gradle\nAdd the plugin to your  build.gradle:\nGoogle has updated  go check it and for that you have to update your Android Studio too.I would advise you against doing what you are doing. I did it too (by following  blindly) but ended up with exceeding 65K method limit.So, you should remove the following lines from your gradle:Now import APIs of Google Plus with simple gradle import:Adding  repository to project level build.gradle helped in my case:I was trying to setup firebase for my android app when I faced this problem. Following screenshot should clarify things -Couple of things I would like to point out -\n1. Once you This line should be at the bottom of the app level gradle file. Not sure why but putting at the top did not workout for me.You maybe miss this stepHave fun.You need to check the current version as in the link below says, by now:Check this answer:We have to look for the last version in my case was: you can find a list of the versions.I got a similar problem while following the  for implementing a GCM client in Android Studio, however, the message I got was :Although I never figured out what was wrong, I simply copied my sources, resources, manifest, and keystore into a new Android Studio project. I then edited the auto-generated gradle build files for the new project by manually re-adding my dependencies.I made sure not to copy over my build files from the old project verbatim (since the source of the error likely lay in them somewhere).It is not a satisfying solution, but it worked for me and it took little time.For me adding this under  workedIf you use Android Studio, try to add google service with the IDE.Inside the  exists a  file that defines the . I suggest you to close Android Studio, then  and then import the project again. The .idea would be generated by the IDE again. For me this solution works.You should just add classpath '' to  of your  the  that has the . Hope this helps!I recently updated to Android Studio 2.3 and somehow apply plugin doesn't work. After that, I tried various ways and then what work is when I commented out app's build.gradle: and then I add this to top-level build.gradle (below ):and then it works."},
{"body": "I want to delete an object I created, (a oval which follows you), but how would I do this? didn't work.EDIT:Okay, I'll give some more context. I'm making a small game with a oval you can control, and a oval which follows you. Now I've got files named: DrawPanel.class, this class draws everything on the screen, and handles collisions, sounds, etc. I got an enemy.class, which is the oval following the player. I got an entity.class, which is the player you can control. And if the player intersects with the follower, I want my player object to get deleted. The way I'm doing it:You should remove the references to it by assigning null or leaving the block where it was declared. After that, it will be automatically deleted by the garbage collector (not immediately, but eventually).Example 1:Example 2:Not something that you are currently looking for, but FYI: you can invoke the garbage collector with the call Your C++ is showing.There is no  in java, and all objects are created on the heap. The JVM has a garbage collector that relies on reference counts.Once there are no more references to an object, it becomes available for collection by the garbage collector.  may not do it; for example:All this does is set the reference  to null, it does not affect the object  once pointed to except to simply decrement the reference count by 1. Since  still refers to that object, it is not yet available to be collected.If you want help an object go away, set its reference to null.Setting reference to null will make it more likely that the object will be garbage collected, as long as there are no other references to the object. You don't need to delete objects in java. When there is no reference to an object, it will be collected by the garbage collector automatically.Yea, java is Garbage collected, it will delete the memory for you.You can remove the reference using .Let's say You have class :last statement will remove the reference of the object  and that object will be \"garbage collected\" by JVM.\nIt is one of the easiest ways to do this."},
{"body": "I was wondering if there is any way to pull that in Java. I think it is not possible without native support for closures.Java 8 (released March 18th 2014) does support currying. The example Java code posted in  can be rewritten as:... which is quite nice. Personally, with Java 8 available I see little reason to use an alternative JVM language such as Scala or Clojure. They provide other language features, of course, but that's not enough to justify the transition cost and the weaker IDE/tooling/libraries support, IMO.Currying and partial application is absolutely possible in Java, but the amount of code required will probably turn you off.FWIW here is the Haskell equivalent of above Java code:: As of 2014 and Java 8, functional programming in Java is now not only possible, but also not ugly (I dare to say beautiful). See for example .Java isn't best choice, if you are going to use functional programming techniques. As missingfaktor wrote, you will have to write quite big amount of code to achieve what you want. On the other hand, you are not restricted to Java on JVM - you can use  or  which are functional languages (Scala is, in fact, both functional and OO).There are a lot of options for Currying with Java 8. Function type Javaslang and jOO\u03bb both offering Currying out of the box (I think this was an oversight in the JDK), and   has a set of static methods for Currying JDK Functions and method references. E.g.'Currying' is also available for Consumers. E.g to return a method with 3 params, and 2 of those already applied we do something similar to this requires to return a . This is not possible with java (no function pointers) but we can define and return a type that contains a function method:Now let's  a simple division. We need a :and a :Now we can do a curried division:Currying a method is always possible in Java, but it does not support it in a standard way. Trying to achieve this is complicated and makes the code pretty unreadable. Java is not the appropriate language for this.Well, , Clojure or Haskell (or any other functional programming language...) are definitely  to use for currying and other functional tricks.Having that said is certainly possible to curry with Java without the super amounts of boilerplate one might expect (well, having to be explicit about the types hurts a lot though - just take a look at the  example ;-)). The tests bellow showcase both,  a  into :as well as , although it's not really typesafe in this example:This is taken from a Proof Of Concept I've just implemented for fun before JavaOne tomorrow in an hour \"because I was bored\" ;-) The code is available here:  The general idea could be expanded to FunctionN => FunctionM, relatively easily, though \"real typesafety\" remains a problem for the partia application example and the currying example would need a hell lot of boilerplaty code in , but it's doable.All in all, it's doable, yet in Scala it's out of the box ;-)One can emulate currying with Java 7 MethodHandles:\nWhile you can do Currying in Java, it is ugly (because its not supported)  In Java is it simpler and faster to use plain loops and simple expressions. If you post an example of where you would use currying, we can suggest alternatives which do the same thing.One more take on the Java 8 possibilities:You can also define utility methods like this one:Which gives you an arguably more readable syntax:"},
{"body": "When trying to check the current version of Java in which I am running, I receive the error \"'java' is not recognized as an internal or external command, operable program or batch file.\". I am running Windows 7 OS and have downloaded the latest JDK and feel I may have accidentally deleted the java from machine as before I was able to check the Java version using the command \"java -version\". What software must I download to get Java working on my machine again? EDIT: I have managed to get Java running from my cmd again after ensuring all environment variables pointed to the current java sdk. Thank you for all answers to my question, KarenYou need to configure your environment variables,  and . must contain the path to java, and you should add  to Alternatively, you can simply add to your  the whole path to the bin folder, without the  variable, however, this makes a little more annoying when you need to have more than one java version on your machine (that way you only need to change  and don't even bother with )For Windows 7:\n1. This sets the path for the computer, not for the individual user. It may be that you're working on a computer which other developers also use, in which case you'd rather set the user variables, rather than the system variablesIt sounds like you haven't added the right directory to your path.First find out which directory you've installed Java in. For example, on my box it's in . Once you've found it, try running it directly. For example:Once you've definitely got the right version, add the  directory to your  environment variable.Note that you don't need a  environment variable, and haven't for some time. Some tools may use it - and if you're using one of those, then sure, set it - but if you're just using (say) Eclipse and the command-line / tools, you're fine without it. Yes, this has reminded me that I need to update...Step 1. Open your windows property i.e. (windows+Pause Break) then goto Advance System setting .\n2. select Advance Tab---> Env.variable --> add variable as shown in figure. \nNow Open your command prompt and check for:\n1. java 2. Javac  are executing successfully. If still error is there i.e. \"\" then check whether you have installed jdk twice. If yes then uninstall and follow above step.For me its start working after putting ,: in the starting of the  system variable path :--\nThis problem is on Windows 8.\nFirst copy your Path of java jdk - e.g. C:\\Program Files\\Java\\jdk1.7.0_51\\bin.Paste the path and add a ';' at the end - e.g. C:\\Program Files\\Java\\jdk1.7.0_51\\bin;I had the same problem. Just Install the exact bit of java as of your computer. If your PC is 64 bit then install 64 bit java. If it is 32 bit then vice versa :)if you have cygwin installed in the Windows Box, or using UNIX Shell then This will tell you whether java is in your classpath or NOT.In my case, PATH was properly SET but PATHEXT has been cleared by me by mistake with .exe extension. That why window can't find java or anything .exe application from command prompt. Hope it can help someone. I had this problem too.finally i solve it.you should enter a space between 'java' and '-'.  i.e you should enter 'java -version' in cmd.I did all of it, and it didn't work for me, but , finally, I found where I was mistaking all that time :).\nI didn't type \"space\" between java and -version.\nIt should be typed like this: java -version.\n With space between \"java\" and  \"-version\".\nNow it works for me. My solution was to put same value (path to JDK bin folder) in  and  \n "},
{"body": "I have a problem with authorized SSL connection. I have created Struts Action that connects to external server with Client Authorized SSL certificate. In my Action I am trying to send some data to bank server but without any luck, because I have as a result from server the following error: My Method from my Action class that sends data to serverMy merchant.properties file:For the first time I thought this is a certificate problem, I converted it from .pfx to .jks, but I have the same error, with no changes.The handshake failure could have occurred due to various reasons:Since, the underlying failure cannot be pinpointed, it is better to switch on the   to enable debugging of the SSL connection established. With the debug switched on, you can pinpoint what activity in the handshake has failed.Based on the details now available, it appears that the problem is due to an incomplete certificate trust path between the certificate issued to the server, and a root CA. In most cases, this is because the root CA's certificate is absent in the trust store, leading to the situation where a certificate trust path cannot exist; the certificate is essentially untrusted by the client. Browsers can present a warning so that users may ignore this, but the same is not the case for SSL clients (like the  class, or any HTTP Client library like Apache ).Most these client classes/libraries would rely on the trust store used by the JVM for certificate validation. In most cases, this will be the  file in the JRE_HOME/lib/security directory. If the location of the trust store has been specified using the JVM system property , then the store in that path is usually the one used by the client library. If you are in doubt, take a look at your  class, and figure out the class/library it is using to make the connection.Adding the server's certificate issuing CA to this trust store ought to resolve the problem. You can refer to my  for this purpose, but the  is sufficient for this purpose.: The trust store is essentially the list of all CAs that you trust. If you put in an certificate that does not belong to a CA that you do not trust, then SSL/TLS connections to sites having certificates issued by that entity can be decrypted if the private key is available.The keystore and the truststores used by the JVM are usually listed at the very beginning, somewhat like the following:If the wrong truststore is used, then you'll need to re-import the server's certificate to the right one, or reconfigure the server to use the one listed (not recommended if you have multiple JVMs, and all of them are used for different needs).If you want to verify if the list of trust certs contains the required certs, then there is a section for the same, that starts as:You'll need to look for if the server's CA is a subject.The handshake process will have a few salient entries (you'll need to know SSL to understand them in detail, but for the purpose of debugging the current problem, it will suffice to know that a handshake_failure is usually reported in the ServerHello.A series of entries will be reported when the connection is being initialized. The first message sent by the client in a SSL/TLS connection setup is the ClientHello message, usually reported in the logs as:Note the cipher suites used. This  with the entry in your merchant.properties file, for the same convention might be employed by the bank's library. If the convention used is different, there is no cause of worry, for the ServerHello will state so, if the cipher suite is incompatible.The server responds with a ServerHello, that will indicate if the connection setup can proceed. Entries in the logs are usually of the following type:Note the cipher suite that it has chosen; this is best suite available to both the server and the client. Usually the cipher suite is not specified if there is an error. The certificate of the server (and optionally the entire chain) is sent by the server, and would be found in the entries as:If the verification of the certificate has succeeded, you'll find an entry similar to:One of the above steps would not have succeeded, resulting in the handshake_failure, for the handshake is typically complete at this stage (not really, but the subsequent stages of the handshake typically do not cause a handshake failure). You'll need to figure out which step has failed, and post the appropriate message as an update to the question (unless you've already understood the message, and you know what to do to resolve it).I don't think this solves the problem to the first questioner, but for googlers coming here for answers: On update 51, java 1.8 prohibited[1] RC4 ciphers by default, as we can see on the Release Notes page:If your server has a strong preference for this cipher (or use only this cipher) this can trigger a  on java.You can test connecting to the server enabling RC4 ciphers (first, try without  argument to see if triggers a , then set :1 - This can also happend when the client needs to present a certificate. After the server lists the certificate chain, the following can happen:\nThe server will issue a certificate request from the client. The request will list all of the certificates the server accepts.\nThis is the certificate the client is sending to the server. If there isn't a certificate in the chain and the server requires one, you'll get the handshake error here. A likely cause is the path to your certificate wasn't found.\nThe client asks the server to verify the certificate    This step will only happen if you are sending a certificate.\nThe server will respond with a verify responseInstalling Java Cryptography Extension (JCE) Unlimited Strength ( | ) will fix this bug. Unzip the file and follow the readme to install it.I have this error while I tried to use JDK 1.7.\nWhen I upgraded my JDK to jdk1.8.0_66 all started to work fine. So the simplest solution for this problem could be -  and it could start to work well.Assuming you're using the proper SSL/TLS protocols, properly configured your  and , and confirmed that there doesn't exist any issues with the certificates themselves, you may need to .As mentioned in , one possible reason you receive this error is due to incompatible cipher suites being used. By updating my  and  jars in my JDK's  folder with the ones provided in the , I was able to complete the handshake successfully.The handshake failure could be a buggy TLSv1 protocol implementation. In our case this helped with java 7:  The jvm will negotiate in this order. The servers with the latest update will do 1.2, the buggy ones will go down to v1 and that works with the similar v1 in java 7.I meet the same problem today with OkHttp client to GET a https based url. It was .You will get many detail info, the key info is listed as follows:\nThis will get what we want.I was getting this error while using Parasoft SOATest to send request XML(SOAP) .The issue was that I had  from the dropdown after adding the certificate and authenticating it.Mine was a  version incompatible error.Previously it was  I changed it  this solved my problem.I am using com.google.api http client.  When I communicate with an internal company site, I got this problem when I mistakenly used https, instead of http.  In my case moving from jdk 1.7.0_71 to jdk 1.8.0_60 fixed the error I had a similar issue; upgrading to Apache HTTPClient 4.5.3 fixed it."},
{"body": "I'm creating a regexp for password validation to be used in a Java application as a configuration parameter.The regexp is:The password policy is:I\u2019m missing just point 5. I'm not able to have the regexp check for space, tab, carriage return, etc.Could anyone help me?Try this:Explanation:It's easy to add, modify or remove individual rules, since every rule is an independent \"module\".The  construct eats the entire string () and backtracks to the first occurrence where  can match. It succeeds if  is found, it fails otherwise. The alternative would be using a reluctant qualifier: . For a password check, this will hardly make any difference, for much longer strings it could be the more efficient variant.The most efficient variant (but hardest to read and maintain, therefore the most error-prone) would be , of course. For a regex of this length and for this purpose, I would dis-recommend doing it that way, as it has no real benefits.simple example using regexExplanations:All the previously given answers use the same (correct) technique to use a separate lookahead for each requirement.  But they contain a couple of inefficiencies and a potentially massive bug, depending on the back end that will actually use the password.I'll start with the regex from the accepted answer:First of all, since Java supports  and  I prefer to use those to make sure the entire string is validated, independently of .  This doesn't affect performance, but avoids mistakes when regexes are recycled.Checking that the password does not contain whitespace and checking its minimum length can be done in a single pass by using the all at once by putting variable quantifier  on the shorthand  that limits the allowed characters:If the provided password does contain a space, all the checks will be done, only to have the final check fail on the space.  This can be avoided by replacing all the dots with :The dot should only be used if you really want to allow any character.  Otherwise, use a (negated) character class to limit your regex to only those characters that are really permitted.  Though it makes little difference in this case,  is a very good habit.  I see far too many cases of  because the developer was too lazy to use something more appropriate than the dot.Since there's a good chance the initial tests will find an appropriate character in the first half of the password, a lazy quantifier can be more efficient:But now for the really important issue: none of the answers mentions the fact that the original question seems to be written by somebody who thinks in ASCII.  But in Java strings are Unicode.  Are non-ASCII characters allowed in passwords?  If they are, are only ASCII spaces disallowed, or should all Unicode whitespace be excluded.By default  matches only ASCII whitespace, so its inverse  matches all Unicode characters (whitespace or not) and all non-whitespace ASCII characters.  If Unicode characters are allowed but Unicode spaces are not, the  flag can be specified to make  exclude Unicode whitespace.  If Unicode characters are not allowed, then  can be used instead of  to match all ASCII characters that are not a space or a control character.Which brings us to the next potential issue: do we want to allow control characters?  The first step in writing a proper regex is to exactly specify what you want to match and what you don't.  The only 100% technically correct answer is that the password specification in the question is ambiguous because it does not state whether certain ranges of characters like control characters or non-ASCII characters are permitted or not.You should not use overly complex Regex (if you can avoid them) because they areAlthough there might be a small performance overhead in using many small regular expressions, the points above outweight it easily.I would implement like this:Password Requirement :I tested it and it worksI think this can do it also (as a simpler mode):"},
{"body": "I have a  using a  to serve several fragments. Each is a  with the following layout:When starting the activity, the soft keyboard shows. To remedy this, I did the following inside the fragment:I save the incoming  parameter from  as a way to access the window token for the main activity. This runs without error, but the keyboard doesn't get hidden from the call to  in .Originally, I tried using the inflated layout instead of , i.e:but this threw a , presumably because the fragment itself isn't an activity and doesn't have a unique window token?Is there a way to hide the soft keyboard from within a fragment, or should I create a method in the  and call it from within the fragment?As long as your Fragment creates a View, you can use the IBinder (window token) from that view  it has been attached.  For example, you can override onActivityCreated in your Fragment:Nothing but the following line of code worked for me:If you add the following attribute to your activity's manifest definition, it will completely suppress the keyboard from popping when your activity opens. Hopefully this helps:(Add to your Activity's manifest definition):Keep an instance of my root view in my classUse the view to hide the keyboardException for  though, focus of the embedded  must be hidden, instead only the first  within the embedded OnCreateView of the Fragment you want to hide the keyboard:add the following line wherever you want to hide the keyboard - inside a fragment or an activity or a method (onClick, onResume, onCreateView, etc)."},
{"body": "I just downloaded Maven and was trying to run the simple command found on the \"Maven in Five Minutes\" page (). This is the command:When I run it I get an error with SSL certificate and cannot download from the central Maven repository at . The error is \"SunCertPathBuilderException: unable to find valid certification path to requested target\". I am sitting behind a corporate firewall and have correctly configured the proxy settings for both  and  access via the  file. I doubt that everyone who downloads Maven and runs it for the first time has to import the SSL certificate of the Maven repository, so the problem must be with the proxy. Does anyone have any experience with this?Here's the stack trace in full debug mode (-X):The fact is that your maven plugin try to connect to an https remote repository\n(e.g )This is a new SSL connectivity for Maven Central was made available in august, 2014 !So please, can you verify that your settings.xml has the correct configuration.You can alternatively use the simple http maven repository like thisPlease let me know if my solution works ;)J.The answer above is a good working solution, but here's how to do it if you want to use the SSL repo:You can use the  environment variable so you don't have to worry about it again. See more info on the  variable :I just stumbled on this bug report:It appears to be the cause of our problems here.  Something with ca-certificates-java encountering an error and not fully populating cacerts.  For me, this started happening after I upgraded to 15.10 and this bug probably occurred during that process.The workaround is to execute the following command:If you check the contents of the keystore (as in my original answer), you'll now see a whole bunch more, including the needed DigiCert Global Root CA.If you went through the process in my original answer, you can clean up the key we added by running this command (assuming you did not specify a different alias):Maven will now work fine.I'd just like to expand on Andy's answer about adding the certificate and specifying a keystore.  That got me started, and combined with information elsewhere I was able to understand the problem and find another (better?) solution.Andy's answer specifies a new keystore with the Maven cert specifically.  Here, I'm going a bit more broad and adding the root certificate to the default java truststore.  This allows me to use mvn (and other java stuff) without specifying a keystore.For reference my OS is Ubuntu 15.10 with Maven 3.3.3.Basically, the default java truststore in this setup does not trust the root certificate of the Maven repo (DigiCert Global Root CA), so it needs to be added.I found it here and downloaded:Then I found the default truststore location, which resides here:You can see what certs are currently in there by running this command:When prompted, the default keystore password is \"changeit\" (but nobody ever does).In my setup, the fingerprint of \"DigiCert Global Root CA\" did not exist (DigiCert calls it \"thumbprint\" in the link above).  So here's how to add it:This should prompt if you trust the cert, say yes.Use keytool -list again to verify that the key exists.  I didn't bother to specify an alias (-alias), so it ended up like this:Then I was able to run mvn commands as normal, no need to specify keystore.This may not be the best solution. I changed my maven from 3.3.x to 3.2.x. And this issue gone.I was getting the same error about the SSL certificate when Maven tried to download the necessary modules automatically. \nAs a remedy, I was attempting to implement Luke's answer above, but found that the DigiCert Global Root CA certificate is already in Java's trusted keystore.\nWhat helped me was adding  to the Path variable (I am running Windows). And  is a JDK location, not just a JRE location, since Maven needs a JDK.\nI am not certain why it helped, but it did. I am absolutely sure that this was the only thing I changed.I actually had the same problem.when I run on my maven project, I get this certificate error by the maven tool.I followed @Andy 's Answer till the point where I downloaded the  fileafter that the rest of the answer didn't work for me but I did the following(I am running on Linux Debian machine)first of all, run:for example in my case it is:if it asks about the password, just hit enter.this command is supposed to list all the ssl certificates accepted by the java.\nwhen I ran this command, in my case I got 93 certificates for example.Now add the downloaded file  to the  file by running the following command:write your sudo password then it will ask you about the the default one is then say  that you trust this certificate.if you run the command once again, in my case, I got 94 contents of the  fileit means, it was added successfully. "},
{"body": "I need to sort my  according to the values stored in it. The  contains the contacts name stored in phone.Also I need that the keys get automatically sorted as soon as I sort the values, or you can say the keys and values are bound together thus any changes in values should get reflected in keys.Required output:Assuming Java, you could sort hashmap just like this:Just a kick-off example. This way is more useful as it sorts the HashMap and keeps the duplicate values as well.Try below code it works fine for me. You can choose both Ascending as well as descending order In Java 8:You don't, basically. A  is fundamentally unordered. Any patterns you  see in the ordering should  be relied on.There are sorted maps such as , but they traditionally sort by key rather than value. It's relatively unusual to sort by value - especially as multiple keys can have the same value.Can you give more context for what you're trying to do? If you're really only storing numbers (as strings) for the keys, perhaps a  such as  would work for you?Alternatively, you could store two separate collections encapsulated in a single class to update both at the same time?As a kind of simple solution you can use temp TreeMap if you need just a final result:This will get you strings sorted as keys of sortedMap.I extends a TreeMap and override entrySet() and values() methods. Key and value need to be Comparable.Follow the code:Unit Tests:found a solution but not sure the performance if the map has large size, useful for normal case."},
{"body": "For this two imports;I got this error:How can I resolve this error?That error is caused by your Eclipse configuration. You can reduce it to a warning. , use a Base64 encoder that isn't part of a non-public API. Apache Commons has , or when you're already on Java 1.8, then use .Go to Window-->Preferences-->Java-->Compiler-->Error/Warnings.\nSelect . Change it to \nChange  and  Reference and change it to warning. (or as your need.)Sure - just don't use the Sun base64 encoder/decoder. There are plenty of other options available, including  or this .Then read .Java 6 ships the . This class provides two static methods that support the same decoding & encoding:\nSince Java 8 we now have a much better  Support.Use this and you will not need an extra library, like .Yup, and sun.misc.BASE64Decoder is way slower: 9x slower than java.xml.bind.DatatypeConverter.parseBase64Binary() and 4x slower than org.apache.commons.codec.binary.Base64.decodeBase64(), at least for a small string on Java 6 OSX.Below is the test program I used. With Java 1.6.0_43 on OSX:Btw that's with commons-codec 1.4. With 1.7 it seems to get slower:Didn't test Java 7 or other OS.I had this problem on jdk1.6.0_37.\nThis is the only JDE/JRE on my system. I don't know why, but the following solved the problem:Maybe clarification in answer from   (Mar 16 at 9:00) has to do something with that.This error (or warning in later versions) occurs because you are compiling against a Java Execution Environment. This shows up as  in the Build path of your Eclipse Java project. Such environments only expose the Java standard API instead of all the classes within the runtime. This means that the classes used to  the Java standard API are not exposed.You can allow access to these particular classes using access rules, you could configure Eclipse to use the JDK directly or you could disable the error. You would however be hiding a serious error as  (see below for a short explanation).Java contains a  in the standard API since Java 1.8. See below for an example how to use it:Java 8 import statement:Java 8 example code:If Java 8 is not available a library such as  or  should be used.. Those classes are used to  Java. They have got public methods to allow instantiation from other packages. A good build environment however  protect you from using them.Using internal classes may break compatibility with future Java SE runtimes; the implementation and location of these classes can change at any time. It should be strongly discouraged to disable the error or warning.This works because you have multiple classes in different jar files. Removing and re-adding the jre lib will make the right classes be first. If you want a fundamental solution make sure you exclude the jar files with the same classes.I am using unix system. In eclipse project-> Properties -> Java Compiler -> Errors/Warning -> Forbidden Access(access rule) -> Turn it to warning/Ignore(Previously it was set to Error).I know this is very Old post. Since we don't have any thing sun.misc in maven \nwe can easily use StringUtils.newStringUtf8(Base64.encodeBase64(encVal));\nFrom org.apache.commons.codec.binary.Base64This error is because of you are importing below two classes\nimport sun.misc.BASE64Encoder; import sun.misc.BASE64Decoder;.Yeah instead of sun.misc.BASE64Encoder you can import\n .Now change the previous encode method as belowNow change the previous decode method as belowNow everything is done , you can save your program and run. It will run without showing any error."},
{"body": "I'm dealing with a problem in my . I created some  and I did instant  with them. Then I dragged the model elements of the classes to the Class diagram. I modified the class diagram adding some operations to these classes and I tried to update the code. But I got the warning and the  have not been updated with the new operations.Could someone help me with this error?Check the version of your SDE. Versions lower than 4.2 are not well maintained. Moreover the integration capabilities have been merged with Visual Paradigm-UML now. Its Latest Version is 14.0 right now."},
{"body": "I have been using Spring Security 3.x for handling user authentication for my projects, and so far, it has worked flawlessly.I recently received the requirements for a new project. In this project, it requires 2 sets of user authentication: one to authenticate employees against LDAP, and another to authenticate customer against database. I'm a little stumped on how to configure that in Spring Security.My initial idea was to create a login screen that has the following fields:-If the user selects \"employee\", then I want Spring Security to authenticate them against LDAP, otherwise the credential will be authenticated against database. However, the problem is the form will be submitted to  and there's no way for me to send the radio button field to my implemented custom authentication provider. My initial thought is I probably need two form submission URLs rather than relying on the default . Each URL will be handled by different authentication providers, but I'm not sure how to configure that in Spring Security.I know in Spring Security, I can configure fall back authentication, for example if LDAP authentication fails, then it will fall back to database authentication, but this is not what I'm shooting for in this new project. Can someone share how exactly I should configure this in Spring Security 3.x?Thank you.I'm trying to do the following:-The reason I want 2 different form logins is to allow me to handle the authentication differently based on the user, instead of doing a fall-back authentication. It is possible that employee and customer have same user ID, in my case.I incorporated @EasyAngel's idea, but have to replace some deprecated classes. The problem I'm currently facing is neither filter processes URLS seem registered in Spring Security because I keep getting . My gut feeling is the  bean is not wired properly, thus my custom filters are not used at all.By the way, I'm using WebSphere and I do have  property set in the server. I'm able to hit the default  without problem.Here's my complete security configuration:-I'm starting a bounty here because I can't seem to get this working for several days already... frustration is the word. I'm hoping someone will point out the problem(s), or if you can show me a better or cleaner way to handle this (in code). I'm using Spring Security 3.x. Thank you.Okay, I managed to get @Ritesh's approach to work very closely to what I wanted. I have the radiobutton that allows user to select whether they are customer or employee. It seems like this approach is working fairly well, with one problem... Here's my updated configuration. It has to be some really small tweak I need to do to prevent the authentication fall back but I can't seem to figure it out now.  Thank you.Okay, I think I have solved the problem here. Instead of having  to rely on the default , I created  for it, just like the one I created  for . These providers will then override the :-... and WALAA! It works perfectly now after several days of frustration! Hopefully, this post will be able to help somebody who is doing the same thing as I am here.You don't need to create  and  . The default one will work just fine with radio button field idea.In the custom login , you need to create different tokens for employee and customer.Here are the steps:You can define several  filters. Each of them can have different URL like  and . Here is example of the security application context that demonstrates this idea:As you can see, in this scenario you have also different s - for DB auth and LDAP. I think it's good idea to have different auth URLs for customers and employee (especially if they use different authentication strategies). You can even have different login pages for them.You can store this information in DB. For example you can have column called  in  table. You can look at my other answer (as an example):If you carefully look at  class, you will notice, that I actually test this LDAP flag and take user password either from LDAP or database.it's me again :) Can you try to use filters like this:instead of defining bean ."},
{"body": "Weld, the JSR-299 Contexts and Dependency Injection reference implementation, considers itself as a kind of successor of Spring and Guice. What makes Weld more capable for enterprise application compared to Guice? Are there any advantages or disadvantages compared to Guice? What do you think about Guice AOP compared to Weld interceptors? What about performance?In the end I decided to use Guice because I like the clean programming model which comes almost without annotations besides @Inject by default. It is much easier to use external libs with Guice than with CDI. AOP is also pretty simple with Guice.Before trying to answer your question, let me just add an important piece of information:  () was standardized by Guice and Spring projects () and is being . This covers basic DI mechanisms in terms of declaring an injection point.Now, back to the question - with the disclaimer that I have far more experience with Spring than with Guice.This is a very heavily discussed topic, and I cannot favor one over the other. Both mechanisms are very powerful but require at least a minimum understanding of the application's architecture. Also have look at  and the previously referenced . It is best to go with the right tool, but don't forget that if a developer has to work with one of these mechanisms it is a good thing if he/she understands the concept.Unfortunately I could not look into this yet, but there are a few rules I try to follow, especially when using a framework that gives you a lot of functionality without you noticing it:CDI (Weld) hasn't yet been used widely, so a comparison is hard to make. A few points:The most important feature CDI has opposed to Guice, is that it is a  part of Java EE 6.  The importance of this cannot be underestimated, as it means that CDI is the DI-standard you should use when coding web applications.A while back I had a look at the technologies to be able to determine how we could have a standard core distribution - suitably prepared - where we could add extra modules at will which could override existing functionality without having to change the core modules.  I.e. add an extra jar, and the functionality activates automatically. It turned out that the best way for us to do this for a code base used in both desktop and web applications, was to use JSR-330 annotations for our code, and then use either CDI or  Guice (SVN, coming real soon now in 3.0) as the engine. After a few projects I've found that I like the Guice configuration best instead of the opaque magic happening in Weld.  Additionally I found that the way to do what we want as described above with Weld, I have to mark the class in the extra jar as @Alternative, and then mention in beans.xml that I want the alternative class enforced (and that is not robust against refactoring).But, all in all,  JSR-330 allows us to do something which was very tedious and fragile before (because  binds so extremely tightly), and that is a great win.  I can strongly recommend looking into DI if you have any need like this. is a nice comparison. Another differentiator is that CDI is very Java EE oriented.  It provides a mechanism to  the different  together.Ie. By annotating a bean with , the bean becomes known in the unified EL (Expression Language) as ''.Then you can use it in a JSF page for instance:"},
{"body": "How is it that for a scanner object the  method returns true  while the  method returns false?Note: Based on the input file, the  method is returning the result as expected; the  does not seem to be returning the correct result.Here's the code I'm running that's creating the results below:The following is the actual content of the file that I'm passing to this scanner:The following is the end of what's printed in the console when I run my code, and includes the portion I can't make sense of:Since the scanner's delimiter is whitespace, and the  is also white space, it is possible for there to be a  in the buffer but no parseable tokens.Typically, the most common way to deal with this issue by always calling  after parsing all the tokens (e.g. numbers) in each line of your text. You need to do this when using  when reading a user's input too from . To advance the scanner past this whitespace delimiter, you must use  to clear the line delimiter. See:  is defined to be a  that matches this:The default token delimiter is this :The reason is that  checks if there are any more non-whitespace characters available.  checks to see if there is another line of text available. Your text file probably has a newline at the end of it so it has another line but no more characters that are not whitespace.Many text editors automatically add a newline to the end of a file if there isn't one already.In other words, your input file is not this (the numbers are line numbers):It is actually this:You have an empty line at the end of the file.If you take your content and save it for example into a txt file, some editors will add an empty new line to your file.The editors behave this way, because this is part of the  standard:This topic has been discussed in .Here is the documentation from the .Because of the above described facts,  will return , but  cannot find anything, which it can recognize as  and returns therefore .For additional infos see  post.You are consuming the value of , but asking for  and . , per default, returns everything to the next . So you are iterating through all whitespace seperated strings, and after each of them you are asking about the . -> ? True. ? Also true. -> ? True. ? Also true (still a whitespace left) -> ? True (Line Seperator, probably). haxNext? False, no whitespace anymore."},
{"body": "I'm trying to verify that a (void) method is being called inside of a DAO - I'm using a commit point that sends a list of results up to that point, resets the list and continues.\n Say I have 4 things in the list and I have a commit point of 1, I would expect the \"send\" method to be called 4 times.\n I can verify that the method gets called once by writingit passes.. but I want to verify the number of times it was called. I would think thatwould be sufficient, but it says the parameters are not correct for verify. Incidentally, if I change   to   or   I get the same error. Thoughts on this?The necessary method is : is your mocked object and  is the  that describes how the mock should be verified. :You'll need these static imports from the  class in order to use the  method and these verification modes:(The class  also provides the mentioned verification modes. So you could also use this class for the static imports.)So in your case the correct syntax will be:This verifies that the method  was called  times on the mocked object. It will fail if it was called less or more than 4 times.If you just want to check, if the method has been called once, then you don't need to pass a . A simplewould be enough. It internally uses ."},
{"body": "I have a console application that after performing its tasks, must give feedback to the user, such as \"operation completed\" or \"operation failed\" and the detailed error.The thing is, if I just \"let it run\", the output message will be printed but the console will close shortly afterwards, leaving no time to read the message.As far as I remember, in C++, every console application will end with a \"press any key to exit\" or something like that. In C# I can simulate this behavior with a But how can I do it in Java? I'm using the Scanner class, but given that \"input\" is my instance of Scanner:\"Any key\" will work, except for return, which is quite a big deal here. Any pointers?In Java this would be I'd like to add that usually you'll want the program to wait only if it's connected to a console. Otherwise (like if it's a part of a ) there is no point printing a message or waiting. For that you could use Java's  like this:The problem with Java console input is that it's buffered input, and requires an enter key to continue.There are these two discussions:\n and The latter of which used  to get his problem solved.I personally haven't used it.I've put in what x4u said. Eclipse wanted a try catch block around it so I let it generate it for me.It can probably have all sorts of bells and whistles on it but I think for beginners that want a command line window not quitting this should be fine.Also I don't know how common this is (this is my first time making jar files), but it wouldn't run by itself, only via a bat file.The above is what the bat file had in the same folder. Seems to be an install issue.Eclipse tutorial came from:\nSome of the answer also came from: I used simple hack, asking windows to use cmd commands , and send it to null.You can just use  as pauseHowever any button you press except Enter you have to press Enter after that but I found it better than This  is pretty good option as it will help us run next line whenever the enter key is pressed "},
{"body": "After searching literally 1 day on facebook and google for an up-to-date and  way to do something seemingly simple:I am looking for a step-by-step explanation to get offline_access for a user for a facebook app and then using this (session key) to retrieve offline & not within a browser friends & profile data.Preferrably doing this in the Fb Java API.Thanks.And yes I did check the facebook wiki.Update: Anyone? this:\n\ngives me offline_Access, however how to retrieve the session_key?Why can't facebook just do simple documentation, I mean there are like 600 people working there?The seemingly same question:\n\nDoes not answer how to retrieve the session keyEdit: I am still stuck with that. I guess nobody really tried such a batch access out yet...With the new Facebook Graph API, things got a bit simpler but far less well documented.  Here's what I did to be able to load my wall posts as me from a server side only (not part of a browser session) php script:Noting that the graph api and rest api return not just different structures, but also different information -- so here, I prefer the results from the rest api (the first one) even though I like being able to restrict the fields in the new graph api (the second one).Look at  in the sections \"Requesting Extended Permissions\" and \"Authenticating Users in a Web Application\" for the official (sparse) details.If you want to do this routinely, i.e. programmatically, here's the automated version of steps 2+3:Put this on your web server as \"facebook_access_token.php\":And direct users in their browsers to:\nIf you want finally want to use PHP, with the Facebook PHP SDK v3 (), it is pretty simple. To log someone with the  permission, you ask it when your generate the login URL. Here is how you do that.First you check if the user is logged in or not :If he is not, you generate the \"Login with Facebook\" URL asking for the  permission :And then display the link in your template :Then you can retrieve the offline access token and store it. To get it, call :To use the offline access token when the user is not logged in :And now you can make API calls for this user :Hope that helps !I did a tutorial not too long ago on my blog.  It doesn't require any plugins or whatnot, it is done in PHP, and I have tested it.  I did it for mainly wall posts, but after you authenticate you can use whatever function you want.EDIT: Post no longer exists.  FB API is updated anyway... You want to start by reading the  section in the authentication guide. Basically, start with this URL:Add your  () to the URL, which in OAuth parlance is :Add the   or  in OAuth parlance:Add a  which is where Facebook will redirect to after the user completes the authorization step (\"Allow\" or \"Dont Allow\", look at docs for response format or just try it out):If you follow , it will take you to a prompt, and then upon clicking Allow/Dont Allow it'll take you to a page that \"echos\" back the request. If you click Allow, you'll get a  parameter back, which you can exchange for an  by making an HTTP request to Facebook from your server, which does something along the lines of this:You need to pass in your , your  must be passed in as the , the same  as you used earlier and the  you received as the response. This will return the  enabled  for that user.One thing to keep in mind though is that even if you request  your application must gracefully handle invalid or expired access_tokens, as that can happen for various reasons.I know two solutions: Java and JavaScriptJava :\na.  servlet code (don't forget to import relevant jar's) ://You will get prompt to log in to facebook and permit the extended permissionsb. Don't forget to define your ConnectUrl(in your facebook account application) as c. make another servlet : YOUR_FaceBookCallback_SERVLET (see above) with this code:d. Use this secret session_key like this:If anybody wants the JavaScript solution(the big hole in security) write meI figured out how to \"retrieve\" the offline access infinite session key after a lot of hair-splitting, some trial and error & wondering about all the other productive ways I could have spent that time... agree facebook documentation could be a lot better  1) If you are using the facebook-java-api.. then take a look at the facebook demo site for \"mobile web\" on how to format the URL for requesting offline access\n    2) As to how get the offline session key from the session..The trick is : when facebook redirects the user to the \"next\" url right after granting offline access, you should get the facebook session \"again\"..this new session will have the infinite session key.\nhere is an example for mobile web...you should be able to figure it out for a regular website.The auth_token is used only for mobile web sites.. you may not need it for a regular web site  For session access, i had to use the loginurl provided by the facebook php api, as there seem to be 2/3 additional variables that it sends in the auth request, including return_session and session_version. Also the new php5-sdk sends the request to login.facebook.com instead of . Here's how i worked it out :To ask for authentication : Rember to include offline_access in $scope. \nOnce you are redirected to this page (after logging in to fb, and granting permissions), you will have a $_GET['session'] in json format.Just store it wherever you want (I do it in a database). The next time you wish to do something with the user's account, just use the following:After this any requests that the api makes will be via this user's access.The worst thing about the current facebook graph api is (correct me if I'm wrong) that the current api neglects the session (which seems to be a remain from the old api) in all its documentation and only talks about the access_token. But the current api (php5-sdk) has got no feature to send an actual request using only the access_token. If there is a function to start a session a session using only the access_token, I'm not aware of it."},
{"body": "I'm getting a  with some frequency from my code.  The URL I am trying to hit is up.  The same code works for some users, but not others.  It seems like once one user starts to get this exception they continue to get the exception.Here is the stack trace:Here is a snippet from my code:Connection timeouts (assuming a local network and several client machines) typically result froma) some kind of firewall on the way that simply eats the packets without telling the sender things like \"No Route to host\"b) packet loss due to wrong network configuration or line overloadc) too many requests overloading the serverd) a small number of simultaneously available threads/processes on the server which leads to all of them being taken. This happens especially with requests that take a long time to run and may combine with c).Hope this helps.If the URL works fine in the web browser on the same machine, it might be that the Java code isn't using the HTTP proxy the browser is using for connecting to the URL.I'd recommend raising the connection timeout time before getting the output stream, like so:Where 1000 is in milliseconds (1000 milliseconds = 1 second).There is a possibility that your IP/host are blocked by the remote host, especially if it thinks you are hitting it too hard.This can be a IPv6 problem (the host publishes an IPv6 AAAA-Address and the users host thinks it is configured for IPv6 but it is actually not correctly connected). This can also be a network MTU problem, a firewall block, or the target host might publish different IP addresses (randomly or based on originators country) which are not all reachable. Or similliar network problems.You cant do much besides setting a timeout and adding good error messages (especially printing out the hosts' resolved address). If you want to make it more robust add retry, parallel trying of all addresses and also look into name resolution caching (positive and negative) on the Java platform.The reason why this happened to me was that a remote server was allowing only certain IP addressed but not its own, and I was trying to render the images from the server's URLs... so everything would simply halt, displaying the timeout error that you had... Make sure that either the server is allowing its own IP, or that you are rendering things from some remote URL that actually exists.The error message says it all: your connection timed out. This means your request did not get a response within some (default) timeframe. The reasons that no response was received is likely to be one of:a) The IP/domain or port is incorrectb) The IP/domain or port (i.e service) is downc) The IP/domain is taking longer than your default timeout to respondd) You have a firewall that is blocking requests or responses on whatever port you are usinge) You have a firewall that is blocking requests to that particular hostf) Your internet access is downg) Your live-server is down i.e in case of \"rest-API call\".Note that firewalls and port or IP blocking may be in place by your ISP"},
{"body": "If I have a  like this:and I want to obtain a collection of values sorted using natural ordering, which method is fastest?Create an instance of a sortable collection like , add the values, then sort it:Create an instance of an ordered collection like , then add the values:Note that the resulting collection is never modified, so the sorting only needs to take place once.TreeSet has a   time complexity guarantuee for  methods.\nSorting an  takes  operations, but  takes only  operation.So if you're mainly retrieving, and don't sort often,  is the better choice. If you sort often but dont retrieve that much  would be a better choice.Theoretically, sorting at the end should be faster.\nMaintaining sorted state through the process could involve additional CPU time.From the CS points of view, both operations are NlogN, but 1 sort should have lower constant.Why not use the best of both worlds? If you are never using it again, sort using a TreeSet and initialize an ArrayList with the contentsEDIT:I have created a benchmark (you can access it at ) to test the three approaches (ArrayList + Collections.sort, TreeSet and my best of both worlds approach) and mine always wins. The test file creates a map with 10000 elements, the values of which have an intentionally awful comparator, and then each of the three strategies get a chance to a) sort the data and b) iterate over it. Here is some sample output (you can test it yourselves):EDIT: I have added an aspect that logs calls to Thingy.compareTo(Thingy) and I have also added a new Strategy based on PriorityQueues that is much faster than either of the previous solutions (at least in sorting).Strangely, my approach performs best in iteration (I would have thought there would be no differences to the ArrayList approach in iteration, do I have a bug in my benchmark?)Disclaimer: I know this is probably an awful benchmark, but it helps get the point across to you and I certainly did not manipulate it to make my approach win.(The code has a dependency to apache commons / lang for the equals / hashcode / compareTo builders, but it should be easy to refactor it out)Be sure to read my comment about TreeSet at the bottom if you choose to implement B)If your app only does occasional sorts but iterates through it a lot, I'd say you're best off using a straightforward unsorted list. Sort it the once and then benefit from faster iteration. Iteration is especially fast on an array list.However if you want sort order to be guaranteed all of the time or you are possibly adding / removing elements frequently then use a sorted collection and take the hit on iteration.So in your case I would say A) is the better option. The list is sorted once, doesn't change and therefore benefits from being an array. Iteration should be very fast, especially if you  its an ArrayList and can directly use the ArrayList.get() instead of an Iterator.I'd also add that TreeSet by definition is a Set which means objects are unique. A TreeSet determines equality by using compareTo on your Comparator / Comparable. You could easily find yourself missing data if you try to add two objects whose compareTo returns a value of 0. e.g. adding \"C\", \"A\", \"B\", \"A\" to a TreeSet will return \"A\", \"B\", \"C\" uses mergeSort which has O(nlog n). has Red-Black tree underlying, basic operations has O(logn). Hence n elements has also O(nlog n). So both are same big O algorithm."},
{"body": "I'm wondering what techniques and/or library to use to implement the functionality of the linux command \"tail -f \".  I'm essentially looking for a drop in add-on/replacement for .  Client code could look something like this:The missing piece is a reasonable implementation of .  It should be able to read parts of the file that exist before the file is opened as well as the lines that are added.  The ability to continue to read a file, and wait around until the file has some more updates for you shouldn't be that hard to accomplish in code yourself. Here's some pseudo-code:I would assume that you would want to put this type of functionality in its own Thread, so that you can sleep it and not affect any other areas of your application. You would want to expose  in a setter so that your main class / other parts of the application can safely shut the thread down without any other headaches, simply by calling  or something similar.Take a look at Apache Commons implementation of  class. It does seem to handle log rotation as well.Check , which does this logic.The main point in the code is:I've built a short implementation of \"tail -f\" in Scala some time ago: . It takes care of file rotation as well and you may define your own logic what to do when it reaches EOF or finds the file has been renamed.You may take a look and port it to Java, since actually there is nothing complex in there. Few notes: the main file is  and basically it defines  which takes care of EOF/rename and  method, which wraps  into an unbounded enumeration in . So, as soon as  ends,  requests next element from an  and another  gets created.I stumbled recently over , It is an extension of . In contrast to the other solutions this makes use of Java's NIO. Here's a short story which you could use as a pointer:I've coded TailingInputStream at work for the very same reason. It basically uses File and refreshed its contents on demand and checked against internal buffer if it has changed significantly (4kB memory stamp IIRC) and then did what the tail -f does. A bit hacky, yes, but it works perfectly and doesn't mess with Threads or anything fancy like that - it's compatible all the way back to 1.4.2 at least.That said, it was a lot easier to do than ReverseInputStream which went from file's end to start and didn't die if the file was updated on the fly...If your code only ever will have to run on Unix systems, you may be able to get away with just shelling out and calling  directly.As a more involved alternative, you could take a look at the implementation of GNU tail and port that over to Java. (I'm not sure whether this wouldn't already make your code a derivative work, though.)Just was faced with the same issue - found the \"simplest\" implementation here: .* - ready for production ;)I found this nice tail implementation.Author : amelandri Souce from : "},
{"body": "How can I watch the contents of several variables (for example, TreeSet's) simultaneously? I can watch contents of one TreeSet, clicking on it in \"Variables\" window, but I have no idea how to do that for several variables.You can use Expressions windows: while debugging, menu window -> Show View -> Expressions, then it has place to type variables of which you need to see contentsYou can add a  for each variable you're interested in.This video does an excellent job of showing you how to set breakpoints and watch variables in the Eclipse Debugger.\nYou can do so by these ways.Add  and while debugging you can see variable in  under variable tab.\nOR\nAdd  and see in console."},
{"body": "In theory, Dalvik executes any virtual machine byte code, created for example with the compilers of Are there already working versions of bytecode compilers for Dalvik available for other languages than Java?Scala works very well.I'm programming my Android application projects in Scala (, ), and it is pretty easy to setup the evnviroment (without IDE, using SBT as build tool).It could access every API in Android SDK, so anything you could do in Java, you could do it in Scala too.You may check this  to see how to build Android application with Scala and SBT. is a lovely but little known variant of Scheme that has existed quietly for many years and runs on both the JVM and Dalvik, .  Therefore, its output includes no extra VM and only includes explicitly imported libraries.  To the end-programmer, this means Kawa's performance and executable size are nearly identical to standard Java (ProGuard not required).Kawa also includes lots of macros (including some specific to Android APIs) that make for a nice clean syntax (assuming one is not averse to parentheses), and adds some tasty goodies on top of Scheme, like \"promises\" (lazy eval and futures in one).  The language is quite robust and well-documented, and has been actively maintained and evolving since the early days of Java. summarizes Kawa's merits with some informative examples and links.I haven't played with it but I know that Scala works.Another JVM language that works on Android is  with , both from .  also works on Android, using its Java backend.  I've written a  that should help someone get started (there are still few other examples), and  also for this purpose (although at this exact moment, it's short a few commits.  And neither are using ProGuard yet, so the  size is shocking.)Although the other posts here are cheerful about Scala-on-Android, posters in Scala forums are more concerned by Scala's ability to blow through some of Dalvik's limitations, and people who do use it say they reserve it for non-production code.  (Some discussion about Scala's problems .)  I can't say yet if Mercury has its own problems with Dalvik, but I've switched to it from Scala for the time being.The dynamically typed languages wont be possible until Dalvik supports JIT (Just In Time) compiling. I believe there is JIT support in one of the experimental Eclair branches, but it is not yet officially available/supported in Android.There is a  compiler available now which creates executables for the Android platform.With this solution, developers have access to practically the entire  and Android toolsets. This includes not only the complete set of Android widgets and a graphical designer for laying them out, but also access to the complete Android runtime. The Eclipse IDE will also build the executable and launch the Android emulator (using Run As | Android Application)."},
{"body": "I wrote a thread, it is taking too much time to execute and it seems it is not completely done. I want to stop the thread gracefully. Any help ?The  way to do it is to have the  of the Thread guarded by a  variable and set it to  from the outside when you want to stop it, something like:Once upon a time a  method existed but as the documentation statesThat's why you should have a guard..The bad part about using a flag to stop your thread is that if the thread is waiting or sleeping then you have to wait for it to finish waiting/sleeping. If you call the interrupt method on the thread then that will cause the wait or sleep call to be exited with an InterruptedException. Calling interrupt() also sets an interrupted property that you can use as a flag to check whether to quit (in the event that the thread is not waiting or sleeping). You can write the thread's run method so that the InterruptedException is caught outside whatever looping logic the thread is doing, or you can catch the exception within the loop and close to the call throwing the exception, setting the interrupt flag inside the catch block for the InterruptedException so that the thread doesn't lose track of the fact that it was interrupted. The interrupted thread can still keep control and finish processing on its own terms.Say I want to write a worker thread that does work in increments, where there's a sleep in the middle for some reason, and I don't want quitting the sleep to make processing quit without doing the remaining work for that increment, I only want it to quit if it is in-between increments:You should not kill Thread from other one. It's considered as fairly bad habit. However, there are many ways. You can use  statement from thread's  method.\nOr you can check if thread has already been interrupted and then it will cancel it's work. F.e. :Make a volatile boolean  somewhere. Then in the code that runs in the thread, regularly doTo stop the thread, set  to .I think you must do it manually this way. After all, only the code running in the thread has any idea what is and isn't graceful.You need to send a stop-message to the Thread and the Thread itself needs to take action if the message has been received. This is pretty easy, if the long-running action is inside loop:For a thread to stop itself, no one seems to have mentioned (mis)using exception:A subclass just need to override doRun() normally as you would with a Thread, and call stopSelf() whenever it feels like it wants to stop. IMO it feels cleaner than using a flag in a while loop. "},
{"body": "What is the difference between Reader and InputStream?\nAnd when to use what?\nIf I can use Reader for reading characters why I will use inputstream, I guess to read objects?An InputStream is the raw method of getting information from a resource.  It grabs the data byte by byte without performing any kind of translation.  If you are reading image data, or any binary file, this is the stream to use.A Reader is designed for character streams.  If the information you are reading is all text, then the Reader will take care of the character decoding for you and give you unicode characters from the raw input stream.  If you are reading any type of text, this is the stream to use.You can wrap an InputStream and turn it into a Reader by using the InputStreamReader class.InputStreams are used to read bytes from a stream. So they are useful for binary data such as images, video and serialized objects.Readers on the other hand are character streams so they are best used to read character data.One accepts bytes and the other accepts characters."},
{"body": "(for clarity and to reduce ambiguity):I'm going to start tinkering around with android apps.  I was planning on writing the in C++ using the NDK (since I have more experience in C++ and prefer it to Java) but came across the following on the :I was under the impression that you should use the language that you prefer, as long as it fits the job.  Could somebody explain why it is so heavily advised not to use C/C++ for android development?I'm going to start tinkering around with mobile apps, specifically android which is the OS of my current phone, and I was wondering if writing the app in C++ (or at least the core, then wrapping in Java) was an acceptable option.  Some background, I'm a computer science major who has taken 3 C++ courses(intro, intermediate, OOP, and am taking an STL course in the spring) and only 1 Java course(intermediate).  Because of this, I am more comfortable with C++ and prefer it to Java.  I came across the following on the :Any advice would be much appreciate.ps: many of the answers on this subject are from years ago and there are very few follow up answers that mention the NDK allowing the development of full native apps on android 2.3 and newer.Think of it this way.  You have the ability using the Java SDK to build a full working application that takes advantage of 100% of the APIs available to developers.  There is nothing you can do with the NDK that cannot be done with the SDK (from an API perspective), the NDK just provides higher performance.Now look at it in reverse.  If you choose to write an application 100% in the NDK, you can still write a fully functional application, but you are limited in the number of framework APIs you can access.  Not all of the Android framework can be accessed at the native layer; most APIs are Java only.  That's not to say that all the APIs  may need aren't available in the NDK, but nowhere near  the APIs are exposed.Beyond this, the NDK introduces platform-specific code which expands the size of your distribution.  For every device architecture you intend to support, your native code must be built into .so files (one for armv5, armv7 and x86) all packaged up into the same APK.  This duplication of executable code makes your app 3x the size (i.e. a \"fat binary\") unless you take on the task of building separate APKs for each architecture when you distribute the application.  So the deployment process becomes a bit more work if you don't want your APK to grow in size significantly.Again, while none of this is prohibits you from doing what you choose, it points out why Google describes Java as the \"preferred\" method for the majority of your code and the path of least resistance. I hope it sheds some light on why the documentation is worded the way it is.If you're only going to develop one app in your life, use the NDK.If you're aiming at learning Android development with the intention of developing more than one application during your lifetime - and want to be able to properly support them all - you're very likely to do better in the long run if you learn Java and use Android's Java SDK instead.The programmers at King use C++ for their game logic. And they seem to be doing fine judging by their turnover. In my experience, C++ is for problem solvers and Java is for problem avoiders. I love either language, but C++ is quite rewarding when you write good code. However, it may just take several moments of wizardry to get there. You could recommend C++ for Data scientists as well, who would normally get their job done by, say, Python or R. C++ can do the same with as good or not better performance, but it just takes being a genius in the language. That is why I'd never  recommend C++ to the one that wants to do it - I'd just give a heads up to the treat that they're in for. I don't see any reason to not use C++ for normal android development , If you have extensive experience in working in C++ and with complex OS like windows or any other such, then you can grasp android quickly and is not as much complicated as the other OS are. while learning java or working without learning it would be more frustrating and complex !I found this interesting article from: \nC++ was built specifically for platform independence and as such is found on every single operating system in existence. Your typical mobile user may know that Android apps are written Java and iOS apps in Objective-C, but what many don\u2019t know is that there is more C/C++ code in memory on your devices than anything else. C/C++ drives much of the technology of small devices (like the kernel, which interacts with the hardware, as well as typical run time libraries) and the telecommunications networks that enable these devices. More importantly for a development team, is that there are C/C++ interfaces and libraries for anything you need to do on any device and platform. The Android NDK toolset is a great example of full C/C++ support that was added originally for game development teams to enable them to get the best possible performance out of the device by avoiding Java and the Android Java runtime Dalvik, the virtual machine on which Android Java code is executed on. It has been regularly improved to enable every Android service.The general intent for both Java and Android is that you write the majority if not all your app in Java and use native things only when there is no other option... so everything about writing the app will lend itself to doing so in Java.You'll spare yourself a lot of aggravation in bridging between the native and Java worlds by writing in Java.As well, you will do yourself a big favor if you take the plunge and learn Java.  Not only will your Android app be the better for it, but you will expose yourself to a significantly different approach to OO and you will be a better programmer for it.Add to that the fact that you will side-step a whole bunch of security risks by writing in Java.In my mind, this is a no-brainer - use Java.I would say use java for main app. But if you have some c++ code you need to port or some library you need that is efficiently implemented in c++, then use ndk for those bits"},
{"body": "Why does Eclipse give me the warming \"Resource leak: 'in' is never closed\" in the following code?Because you don't close your ScannerAs others have said, you need to call 'close' on IO classes.  I'll add that this is an excellent spot to use the try - finally block with no catch, like this:This ensures that your Scanner is always closed, guaranteeing proper resource cleanup.Equivalently, in Java 7 or greater, you can use the \"try-with-resources\" syntax:It is telling you that you need to close the Scanner you instantiated on  with . Normally every reader should be closed.Note that if you close , you won't be able to read from it again. You may also take a look at the  class.You need call , in a  block to ensure it occurs.From the Eclipse documentation, here is  it flags this particular problem ( mine):Full explanation .You should  your Scanner when you're done with it:If you are using JDK7 or 8, you can use try-catch with resources.This will automatically close the scanner.above line will invoke Constructor of Scanner class with argument System.in, and will return a reference to newly constructed object.It is connected to a Input Stream that is connected to Keyboard, so now at run-time you can take user input to do required operation.To remove the memory leak - Generally, instances of classes that deal with I/O should be closed after you're finished with them. So at the end of your code you could add .The Scanner should be closed. It is a good practice to close Readers, Streams...and this kind of objects to free up resources and aovid memory leaks; and doing so in a finally block to make sure that they are closed up even if an exception occurs while handling those objects.adding  does not really fix the problem, it only clears out the warning.\nMaking the scanner static means it remains open forever (or until the class get's unloaded, which nearly is \"forever\"). \nThe compiler gives you no warning any more, since you told him \"keep it open forever\". But that is not what you really wanted to, since you should close resources as soon as you don't need them any more.HTH,\nManfred.I fixed it by declaring in as a private static Scanner class variable. Not sure why that fixed it but that is what eclipse recommended I do.It will close  and shut the warning."},
{"body": "Following is the annotation codeI would like to make  an optional parameter, for exampleshould be a valid code.Seems like the first example in the  says it all ...To make it optional you can assign it a default value like that:Then it doesn't need to be specified when using the Annotation."},
{"body": "The question is a bit theoretical, what is the cost of creating JAXB context, marshaller and unmarshaller?I've found that my code could benefit from keeping the same JAXB context and possibly the same marshaller for all marshaling operations rather than creating context and marshaller on each marshaling.So what is the cost of creating JAXB context and marshaller/unmarshaller? Is it okay to create context+marshaller for each marshaling operation or it's better to avoid it?  I'm the  lead and a member of the JAXB 2 () expert group. is thread safe and should only be created once and reused to avoid the cost of initializing the metadata multiple times.   and  are not thread safe, but are lightweight to create and could be created per operation.Ideally, you should have a singleton  and local instances of  and .  instances are thread-safe while  and  instances are  thread-safe and should never be shared across threads.It's a pity that this isn't specifically described in the javadoc. What I can tell is that Spring uses a global JAXBContext, shared between threads, whereas it creates a new marshaller for each marshalling operation, with a  in the code saying that JAXB marshallers are not necessarily thread-safe.The same is said on this page: .I would guess that creating a JAXBContext is a costly operation, because it involves scanning classes and packages for annotations. But measuring it is the best way to know.I solved this problem using shared thread safe  and thread local  \n\nwith synchronization only on 's initialization.Even better!! Based on the good solution from the post above, create the context  in the constructor, and save it instead of the class. Replace the line:with this one:And the main constructor with this one:so in the getMarshaller/getUnmarshaller you can remove this line:This improvement makes, in my case, that processing times drops from 60~70ms to just 5~10msJAXB 2.2 () has this to say, in section \"4.2 JAXBContext\":Unfortunately, the specification does not make any claims regarding thread-safety of  and . So it is best to assume they are not.I usually solve problems like this with a  class pattern. \nGiven the fact that you need a different marshaller for each Class, you can combine it with a -map pattern. To save you 15 minutes, of work. Here follows my implementation of a thread-safe Factory for Jaxb Marshallers and Unmarshallers.It allows you to access the instances as follows ...And the code you will need is a little Jaxb class that looks as follows:"},
{"body": "The only way that some JDBC drivers to return  is to do something of the following:Is there a way to do the same with ?The reason I asked if I can do the same with  consider the following scenario:In the  table there's a  which is a  (hence why you don't see it in the  String.Now, I populate the  using . I want to return . How can I achieve this?You can either use the  method taking an additional  parameterFor some JDBC drivers (for example, Oracle) you have to explicitly list the column names or indices of the generated keys:You mean something like this?   Not having a compiler by me right now, I'll answer by asking a question:Have you tried this? Does it work?Disclaimer: Obviously, I haven't compiled this, but you get the idea. is a subinterface of , so I don't see a reason why this wouldn't work, unless some JDBC drivers are buggy."},
{"body": "I've searched for this, but couldn't find an answer and for whatever reason I was too ashamed to ask professor, due to that feeling when hundreds of people stare at you... Anyhow, my question is what's the importance of having brackets? Is it OK if I omit them? Example:vsI know both of them will work, but if I omit the brackets (which I tend to do a lot, due to visibility) will that change anything, anything at all? As I said, I know it works, I tested it dozen of times, but now some of my uni assignments are getting larger, and for some reason I have irrational fear that in the long run, this my cause some problems? Is there a reason to fear that?It won't change anything at all  the maintainability of your code. I've seen code like this:which means this:... but which  have been this:Personally I  include the brackets to reduce the possibility of confusion when reading or modifying the code.The coding conventions at every company I've worked for have required this - which is not to say that some other companies don't have different conventions...And just in case you think it would never make a difference: I had to fix a bug once which was pretty much equivalent to the code above. It was remarkably hard to spot... (admittedly this was years ago, before I'd started unit testing, which would no doubt have made it easier to diagnose).Using braces makes the code more maintainable and understandable. So you should consider them .I sometimes skip using braces on  to make the code more compact. My requirement for this is that they're  statements that are followed by a  statement, like  or . Also, I keep them in the same line to draw attention to the idiom, e.g:.They also apply to code inside loops:And to other jump-conditions from methods that are not necessarily at the top of the method body.Some languages (like Perl or Ruby) have a kind of , where braces don't apply:I consider it to be  to what I just described, but explicitly supported by the language.There is no difference. The main problem with the second version is you might end up writing this:when you update that method, thinking that  is called inside the loop. (And that leads to head-scratching debug sessions.)There is a second problem that the brace version doesn't have, and its possibly even harder to spot:So keep the braces unless you have a good reason, it is just a few keystrokes more.I don't see the point of the convention.The reason for always use braces is pretty weak, because it's supposed that a programmer knows the language syntax, and knows that an if-statement without braces applies only to the first statement following itself.if the Oracle decides that it's a \"good practice\" always write if-statement with braces, then why don't they just change the syntax?My opinion:If I write an \"without braces statement\", I always put it in a single line. Put in two lines this kind of code is weird:I don't like conventions based on such silly reasons.Added: many people in this post have agreed on the same: you should do it to improve readability. But I think do it to avoid mistakes is unnecessary.Do you consider that change a code like this:into this:would improve readability? I don't think so. It could be in a more complex if-statement. But everybody I know code this way only in simple if-statements. True to be said, the first case looks more clear.But someone thinks that there is a possibility for some programmer to do this:thinking that the statement would be part of the if. I think there is no\nneed to worry about this. Because if some programmer is capable of such,\nit would be capable of worse.I think, what should be avoided is writing an without braces if-statement in two lines like this:or nest unbraces statements like:this I agree its error prone, and it is often done by beginners. You should avoid to write complex if alike statements without braces as well.If you have a single statement you can omit the brackets, for more that one statements brackets is necessary for declaring a block of code.When you use brackets you are declaring a block of code : The brackets should be used also with only one statement when you are in a situation of nested  statement for improve readability, so for example : it is more readable written with brackets also if not necessary : If you use brackets your code is more readable.\nAnd if you need to add some operator in same block you can avoid possible errors I think that loosing curly braces is good, if you are also using  auto-format, because than your indentation is always correct, so it will be easy to spot any errors that way.Saying that leaving the curly braces out is bad, weird or unreadable is just wrong, as whole language is based on that idea, and it's pretty popular (python).But I have to say that without using a formatter it can be dangerous.Using the brackets future proofs the code against later modifications.  I've seen cases where brackets were omitted and someone later added some code and didn't put the brackets in at that time.  The result was that the code they added didn't go inside the section they thought it did.  So I think the answer is that its good practice in light of future changes to the code.  I've seen software groups adopt that as a standard, i.e. always requiring brackets even with single line blocks for that reason.For most cases, the answers mentioned so far are correct.  But there are some disadvantages to it from the security perspective of things.  Having worked in a payments team, security is a much stronger factor that motives such decisions. Lets say you have the following code:Now lets say you have this code is not working due to some internal problem.  You want to check the input.  So you make the following change:Say you fix the problem and deploy this code (and maybe the reviewer & you think this won't cause a problem since its not inside the 'Prod' condition).  Magically, your production logs now print customer credit card information that is visible to all the personnel who can see the logs.  God forbid if any of them (with malicious intent) gets hold of this data.Thus not giving a brace and a little careless coding can often lead to breach of secure information.  It is also classified as a vulnerability in JAVA by .More support for the \"always braces\" group from me.  you omit braces for single-statement loops/branches, put the statement on the same line as the control-statement,that way it's harder to forget inserting braces when the body is expanded. Still, use curlies anyway.If you remove braces, it will only read the first line of instruction. Any additional lines will not be read. If you have more than 1 line of instruction to be executed pls use curly brace - or else exception will be thrown.Only two things to consider.If you have only one statement inside the loop it is same.For example see the following code:we have only one statement in above code. so no issueHere we are having two statements but only first statement comes into inside the loop but not the second statement.If you have multiple statements under single loop you must use braces.using redundant braces to claim that code is more maintainable raises the following question: if the guys writing, wondering about and further maintaining the code have issues like the ones described before (indentation related or readability related) perhaps they should not program at all...it should be a reflex to reformat the code as well... that is of course for professional programmers in professional teams"},
{"body": "Guava provides us with great factory methods for Java types, such as .But are there also builders for java Maps?There is no such thing for HashMaps, but you can create an ImmutableMap with a builder:And if you need a mutable map, you can just feed that to the HashMap constructor.Not quite a builder, but using an initializer: This is similar to the accepted answer, but a little cleaner, in my view:There are several variations of the above method, and they are great for making static, unchanging, immutable maps.A simple map builder is trivial to write:You can use:It's not as classy and readable, but does the work. is mutable; there's no need for a builder.If you don't use Guava but want to have something like Jake Toronto suggested. You'll get ClassCastException if the args are wrong.I had a similar requirement a while back. Its nothing to do with Guava but you can do something like this to be able to cleanly construct a  using a fluent builder.Create a base class that extends Map.Then create the fluent builder with methods that suit your needs:You can then implement it like this:This is something I always wanted, especially while setting up test fixtures. Finally, I decided to write a simple fluent builder of my own that could build any Map implementation - \n"},
{"body": "Can anyone provide a simple example that explains the difference between  and  polymorphism in Java? is the polymorphism existed at run-time. Here, Java compiler does not understand which method is called at compilation time. Only JVM decides which method is called at run-time. Method overloading and method overriding using instance methods are the examples for dynamic polymorphism. is the polymorphism exhibited at compile time. Here, Java compiler knows which method is called. Method overloading and method overriding using static methods; method overriding using private or final methods are examples for static polymorphismFor more details please read \"What is Polymorphism\" (Google it).\nPolymorphism is the ability of an object to take on many forms. The most common use of polymorphism in OOP occurs when a parent class reference is used to refer to a child class object.Run time Polymorphism also known as method overriding. In this Mechanism by which a call to an overridden function is resolved at a Run-Time.Inside start method of CarWhich method is to be called is decided at compile-time only.Output:\nInside Collection sort metho is an example of / because method binding between method call and method definition happens at compile time and it depends on the reference of the class(reference created at compile time and goes to stack). is an example of / because method binding between method call and method definition happens at run time and it depends on the object of the class (object created at runtime and goes to the heap) .   : Same method name is  with different  type  or number of parameters in  (different signature). Targeted method call is resolved at compile time. :  Same method is  with same signature in . Type of object on which method is being invoked is not known at compile time but will be decided at run time.Generally overloading won't be considered as polymorphism. From java tutorial  :You can find good examples of polymorphim at SE documentation topics"},
{"body": "I have a j2ee application using hibernate with annotation. How do I annotate the Id field in my pojo class to set it as auto increment or auto generated. and in adding the bean do I leave that field in my bean null?and you leave it  () when persisting. ( if you use the  /  wrappers)In some cases the  strategy is resolved to  rathen than to  or , so you might want to manually set it to  or  (depending on the underlying database).It seems  +  worked for you.Do it as follows :-You can use any arbitrary name instead of kaugen.\nIt worked well, I could see below queries on consoleHibernate defines five types of identifier generation strategies: - either identity column, sequence or table depending on the underlying DB - table holding the id - identity column - sequence \u2013 the identity is copied from another entityExample using Tablefor more details, check the .FYIUsing   with a  *auto_increment* column, creates you an attribute with the following annotations:This was getting me the same an error saying the column must not be null, so i simply removed the @NotNull anotation leaving the attribute null, and it works!If you have a numeric column that you want to auto-increment, it might be an option to set  directly. This has the advantage, that the schema auto-generates the value even if it is used without hibernate. This might make your code db-specific though:"},
{"body": "Is there a way to get the path of main class of the running java program.structure isI want to get the path as .I tried  but the problem is, if I run like Is there any way to do this?By This printed out:By Note that most class files are assembled into JAR files so this won't work in every case (hence the ). However, you can locate the JAR that contains the class with this technique, and you can get the content of the class file by substituting a call to  in place of , and that will work whether the class is on the file system or in a JAR.Try this code:replace 'MyClass' with your class containing the main methodUsesee You can also split it into it's elements easilyYou actually do not want to get the path to your main class. According to your example you want to get the current working directory, i.e. directory where your program started. In this case you can just say "},
{"body": "How can i convert a string to a ?I have seen examples like:But my strings are like:As you use Joda Time, you should use :If using Java 8 or later, then refer to Since Java 1.8, you can achieve this without an extra library:The syntax is nearly the same though.You may have to go from DateTime to LocalDate.Datetime formatting is performed by the . Three classes provide , and this is one. The others are  and .  is an immutable datetime class representing a date .  is , provided that the  is as well. All standard Chronology classes supplied are thread-safe and immutable. "},
{"body": "I am confused about StringPool in Java. I came across this while reading the String chapter in Java. Please help me understand, in layman terms, what StringPool actually does.This prints  (even though we don't use  method: correct way to compare strings)When compiler optimizes your string literals, it sees that both  and  have same value and thus you need only one string object. It's safe because  is immutable in Java.\nAs result, both  and  point to the same object and some little memory saved.Name 'string pool' comes from the idea that all already defined string are stored in some 'pool' and before creating new  object compiler checks if such string is already defined.I don't think it actually does much, it looks like it's just a cache for string literals.  If you have multiple Strings who's values are the same, they'll all point to the same string literal in the string pool. In case 1, literal s1 is created newly and kept in the pool. But in case 2, literal s2 refer the s1, it will not create new one instead.   Let's start with a quote from the virtual machine spec: - This is a hint, that there's something special about  objects. Usually, invoking a constructor will  create a new instance of the class. This is not the case with Strings, especially when String objects are 'created' with literals. Those Strings are stored in a global store (pool) - or at least the references are kept in a pool, and whenever a new instance of an already known Strings is needed, the vm returns a reference to the object from the pool. In pseudo code, it may go like that:So in this case, variables  and  hold references to  object. IN this case, we have .This is not the case if we use the constructor:Again,  is created on the pool but then we create a new instance from the same literal, and in this case, it leads to So  do we have a String pool? Strings and especially String literals are widely used in typical Java code. And they are immutable. And being immutable allowed to cache String to save memory and increase performance (less effort for creation, less garbage to be collected).As programmers we don't have to care much about the String pool, as long as we keep in mind:When the JVM loads classes, or otherwise sees a literal string, or some code s a string, it adds the string to a mostly-hidden lookup table that has one copy of each such string.  If another copy is added, the runtime arranges it so that all the literals refer to the same string object.  This is called \"interning\".  If you say something likeit'll return , because the first and second \"test\" are actually the same object.  Comparing interned strings this way can be much,  faster than , as there's a single reference comparison rather than a bunch of  comparisons.You can add a string to the pool by calling , which will give you back the pooled version of the string (which could be the same string you're interning, but you'd be crazy to rely on that -- you often can't be sure exactly what code has been loaded and run up til now and interned the same string).  The pooled version (the string returned from ) will be equal to any identical literal.  For example:"},
{"body": "May be this is silly question. I want to get rid of the fractional part of the  number. But I cant do that. It shows the error that incompatible types. What to do? conversion in one line....please help thanksIf you really should use Double instead of double you even can get the int Value of Double by calling:Else its already described by Peter Lawreys answer.All other answer are correct, but remember that if you cast double to int you will loss decimal value.. so 2.9 double become 2 int.You can use  function or simply do :Result is: myInt = 12try casting the value"},
{"body": "As I know ,  and  are all deprecated in Java and they are replaced with , , .These will in fact return the hour, minute and second for that particular moment. However, I would want to retrieved the hours and minutes from a Date variable. For instance,say the time retrieved from database is By retrieving the hours, minutes, and seconds, I getSo, how do I use Calendar for this function? Although the  has been deprecated but it still worked. I would still like to know if there is an alternative to this.Try this:For a time difference, note that the calendar starts at 01.01.1970, 01:00, not at 00:00. If you're using java.util.Date and java.text.SimpleDateFormat, you will have to compensate for 1 hour:This will print:Duration: 1:23:45.678I recommend looking at  - much better than the standard Java Date/Calendar classes. Their documentation is quite reasonable, you could also try searching stack overflow if you need help."},
{"body": "I have a  object. I want to determine if the type that the  object represents implements a specific interface. I was wondering how this could be achieved?I have the following code. Basically what it does is gets an array of all the classes in a specified package. I then want to go through the array and add the Class objects that implement an interface to my map. Problem is the  takes an object as a parameter. I can't instantiate an interface. So I am kind of at a loss with this. Any ideas?You should use :you can use the below function to get all the implemented interfacesYou can use  and then check to see if the interface class is in there.You can also set the instance adding \".class\""},
{"body": "This question is related to my previous question :I want to insert counter that starts from 0 in my for loop, I've tried several combinations so far :Problem with first approach is that outer loop has 3 items and inner loop has 7 items, so for each outer item the count starts from 0. The second one I get compile error. Here is basically what I want :I'm just not totally familiar with the syntax. thank youTry the following:The  references to  which has a  method.So:You can use varStatus in your c:forEach loop In your first example you can get the counter to work properly as follows...what led me to this page is that I set within a page then the inside of an included page I did the increment and here is the problem so to solve such a problem, simply use  when you declare  the variable or the increment hope this saves your time"},
{"body": "Suppose I have an enum  with 2 possible values:  and :Now suppose I have a switch statement for this enum where I have code for both possible values:Since I have code block for both possible values of the enum, what is the usage of  in the above code?Should I throw an exception if the code somehow reaches the  block like this?It is good practice to throw an Exception as you have shown in the second example. You improve the maintainability of your code by failing fast. In this case it would mean if you later (perhaps years later) add an enum value and it reaches the switch statement you will immediately discover the error. If the default value were not set, the code would perhaps run through even with the new enum value and could possibly have undesired behavior.The other answers are correct in saying that you should implement a  branch that throws an exception, in case a new value gets added to your enum in the future. However, I would go one step further and question why you're even using a  statement in the first place.Unlike languages like C++ and C#, Java represents Enum values as actual objects, which means that you can leverage object-oriented programming. Let's say that the purpose of your method is to provide an RGB value for each color:Well, arguably, if you want each color to have an RGB value, you should include that as part of its description:That way, if you add a new color later, you're pretty much forced to provide an RGB value. It's even more fail-fast than the other approach, because you'll fail at compile-time rather than run-time.Note that you can do even more complicated things if you need to, including having each color provide its own custom implementation of an abstract method. Enums in Java are really powerful and object-oriented, and in most cases I've found I can avoid needing to  on them in the first place.Compile time completeness of the switch cases doesn't guarantee runtime completenes.Class with a switch statement compiled against an older version of enum may be executed with a newer enum version (with more values). That's a common case with library dependencies.For reasons like these, the compiler considers the  without  case incomplete.In small programs, there is no practical use for that, but think of a complex system that speards among large number of files and developers - if you define the  in one file and use it in another one, and later on someone adds a value to the  without updating the  statement, you'll find it very useful...Yes, you should do it. You may change  but don't change . In the future it'll lead to mistakes. I think that  is the good practice.If you've covered all of the possibilities with your various  and the  cannot happen, this is the classic use case for :When the enum constants are too many and you need to handle only for few cases, then the  will handle the rest of the constants.Also, enum constants are references, if the reference is not yet set, or . You may have to handle such cases too. Yes, it is dead code until someone add a value to the enum, which will make your switch statement follow the principle of 'fail fast' ()This could relates to this question : To satisfy IDEs and other static linters, I often leave the default case in as a no-op, along with a comment such as  or i.e., if the switch is doing the typical thing of handling all possible enum values, either explicitly or via fall-throughs, then the default case is probably programmer error.Depending on the application, I sometimes put an assertion in the case to guard against programmer error during development. But this has limited value in shipping code (unless you ship with assertions enabled.)Again, depending on the situation I might be convinced to throw an Error, as this is really an unrecoverable situation -- nothing the user can do will correct what is probably programmer error.Apart from the possible future extending of the enum, which was pointed out by many, some day someone may 'improve' yout  or override it in a derived class and let it return an invalid value. Of course a compiler should catch that, unless someone explicitly forces unsafe type casting...But bad things just happen, and it's a good practice not to leave any unexpected  or  path unguarded.I'm surprised nobody else mentioned this. You can cast an int to an enum and it won't throw just because the value is not one of the enumerated values. This means (among other things), the compiler cannot tell that all the enum values are in the switch.Even if you write your code correctly, this really does come up when serializing objects that contain enums. A future version might add to the enum and your code choke on reading it back, or somebody looking to create mayhem may hexedit a new value in. Either way, running off the switch rarely does the right thing. So, we throw in default unless we know better.Here is how I would handle it, beside  value which would result in a null pointer exception which you can handle.If  is not , it has to be one of the singletons in , if you assign any reference to an object that is not one of the them this will cause a Runtime error.So my solution is to account for values that are not supported... or you can consider  as unsupported tooIn this case using Assertion in default is the best practice."},
{"body": "There is a question which was recently asked to me in an interview.: There is a class meant to profile the execution time of the code. The class is like: The client is expected to create an instance of the StopWatch and call methods accordingly. User code can mess up the use of the methods leading to unexpected results. Ex, start(), stop() and getTime() calls should be in order.This class has to be \"reconfigured\" so that user can be prevented from messing up the sequence. I proposed use of custom exception if stop() is called before start(), or doing some if/else checks, but interviewer was not satisfied. : The class members and method implementations can be modified.We commonly use StopWatch from  check the pattern how they've provided.IllegalStateException is thrown when the stop watch state is wrong.Straight forward. First there is the fact that implementing an own Java profiler is a waste of time, since good ones are available (maybe that was the intention behind the question).If you want to enforce the correct method order at compile time, you have to return something with each method in the chain:External Construction of those helper classes as well as other ways of accessing their methods have to be prevented of course.With minor changes to the interface, you can make the method sequence the only one that can be called - even at compile time!The usage is straightforward - every method returns a different class which only has the currently applicable methods. Basically, the state of the stopwatch is encapsuled in the type system.In comments, it was pointed out that even with the above design, you can call  twice. While I consider that to be added value, it is theoretically possible to screw oneself over. Then, the only way I can think of would be something like this:That differs from the assignment by omitting the  method, but that's potentially good design, too. All would then depend on the precise requirements...Maybe he expected this 'reconfiguration' and question was not about method sequence at all:In hindsight it sounds like they were looking for the . They're usually used to do things like enforce closing of streams. This is also more relevant due to this line:The idea is you give the thing that does the \"executing around\" some class to do somethings with. You'll probably use  but it's not necessary.  In your  class add some method like thisYou would then call it like thisThis makes it fool proof. You don't have to worry about handling stop before start or people forgetting to call one and not the other, etc. The reason  is nice is because(If you were using it to enforce stream closing then you could put the actions that need to be done with a database connection inside so the end user doesn't need to worry about how to open and close it and you simultaneously force them to close it properly.)If you wanted, you could make some  instead leave  unmodified. You could also make  not return a time and make  public instead.The Java 8 way to calling it is even simplerTo me something like this seems to be good.The reason I believe this to be good is the recording is during object creation so it can't be forgotten or done out of order (can't call  method if it doesn't exist).One flaw is probably the naming of . At first I thought maybe  but that usually implies a restarting or some sort (or at least recording since last lap/start). Perhaps  would be better? This mimics the action of looking at the time on a stop watch. I chose  to keep it similar to the original class.The only thing I'm not 100% sure about is how to get the time. To be honest that seems to be a more minor detail. As long as both  in the above code obtain current time the same way it should be fine.Throwing an exception when the methods are not called in the correct order is common. For example, 's  will throw an  if called twice.You should have probably explained better how the instance would know if the methods are called in the correct order. This can be done by introducing a state variable, and checking the state at the start of each method (and updating it when necessary). I suggest something like:It will be used like thisYou can't invoke anything in wrong order. And if you invoke  twice you get meaningful result both time (maybe it is better rename it to  and return actual time each time it invoked)This can also be done with Lambdas in Java 8. In this case you pass your function to the  class and then tell the  to execute that code. Presumably the reason for using a stopwatch is that the entity that's interested in the time is distinct from the entity that's responsible for starting and stopping the timing intervals.  If that is not the case, patterns using immutable objects and allowing code to query a stop watch at any time to see how much time has elapsed to date would likely be better than those using a mutable stopwatch object.If your purpose is to capture data about how much time is being spent doing various things, I would suggest that you might be best served by a class which builds a list of timing-related events.  Such a class may provide a method to generate and add a new timing-related event, which would record a snapshot of its created time and provide a method to indicate its completion.  The outer class would also provide a method to retrieve a list of all timing events registered to date.If the code which creates a new timing event supplies a parameter indicating its purpose, code at the end which examines the list could ascertain whether all events that were initiated have been properly completed, and identify any that had not; it could also identify if any events were contained entirely within others or overlapped others but were not contained within them.  Because each event would have its own independent status, failure to close one event need not interfere with any subsequent events or cause any loss or corruption of timing data related to them (as might occur if e.g. a stopwatch had been accidentally left running when it should have been stopped).While it's certainly possible to have a mutable stopwatch class which uses  and  methods, if the intention is that each \"stop\" action be associated with a particular \"start\" action, having the \"start\" action return an object which must be \"stopped\" will not only ensure such association, but it will allow sensible behavior to be achieved even if an action is started and abandoned.I know this already has been answered but couldn't find an answer invoking builder with  for the control flow so here is my solution :\n(Name the interfaces in a better way than me :p)Usage :As Per Interview question ,It seems to like thisSo now All user need to create object of StopWatch class at beginning and getTime() need to call at EndFor e.gI'm going to suggest that enforcing the method call sequence is solving the wrong problem; the real problem is a unfriendly interface where the user must be aware of the state of the stopwatch. The solution is to remove any requirement to know the state of the StopWatch.This allows a simple use of the  method with a result returned and logging included.This gives the nice result of;"},
{"body": "Is there a way to shutdown a computer using a built-in Java method?Create your own function to execute an OS  through the ?For the sake of an example. But know where and why you'd want to use this as others note.Here's another example that could work cross-platform:The specific shutdown commands may require different paths or administrative privileges.Here is an example using  :This method takes into account a whole lot more operating systems than any of the above answers. It also looks a lot nicer and is more reliable then checking the  property. It now has the option for the user to enter a delay if they like!The quick answer is no. The only way to do it is by invoking the OS-specific commands that will cause the computer to shutdown, assuming your application has the necessary privileges to do it. This is inherently non-portable, so you'd need either to know where your application will run or have different methods for different OSs and detect which one to use.I use this program to shutdown the computer in X minutes.Better use .startsWith than use .equals ... work fineRa.You can use  to do it in whatever way you'd do it with C/C++.On Windows Embedded by default there is no shutdown command in cmd.\nIn such case you need add this command manually or use function ExitWindowsEx from win32 (user32.lib) by using JNA (if you want more Java) or JNI (if easier for you will be to set priviliges in C code).easy single linebut only work on windows"},
{"body": "At the moment, i'm trying to create a Java-application which uses CUDA-functionality. The connection between CUDA and Java works fine, but i've got another problem and wanted to ask, if my thoughts about it are correct.When i call a native function from Java, i pass some data to it, the functions calculates something and returns a result. Is it possible, to let the first function return a reference (pointer) to this result which i can pass to JNI and call another function that does further calculations with the result?My idea was to reduce the overhead that comes from copying data to and from the GPU by leaving the data in the GPU memory and just passing a reference to it so other functions can use it.After trying some time, i thought for myself, this shouldn't be possible, because pointers get deleted after the application ends (in this case, when the C-function terminates). Is this correct? Or am i just to bad in C to see the solution? Edit: \nWell, to expand the question a little bit (or make it more clearly): Is memory allocated by JNI native functions deallocated when the function ends? Or may i still access it until either the JNI application ends or when i free it manually?Thanks for your input :)I used the following approach:in your JNI code, create a struct that would hold references to objects you need. When you first create this struct, return its pointer to java as a . Then, from java you just call any method with this  as a parameter, and in C cast it to a pointer to your struct. The structure will be in the heap, so it will not be cleared between different JNI calls.EDIT: I don't think you can use  long ptr =  since address is a static variable. Use it the way Gunslinger47 suggested, i.e. create new instance of class or a struct (using new or malloc) and pass its pointer.In C++ you can use any mechanism you want to allocate/free memory: the stack, malloc/free, new/delete or any other custom implementation. The only requirement is that if you allocated a block of memory with one mechanism, you have to free it with the same mechanism, so you can't call  on a stack variable and you can't call  on ed memory.JNI has its own mechanisms for allocating/freeing JVM memory:These follow the same rule, the only catch is that local refs can be deleted \"en masse\" either explicitly, with , or implicitly, when the native method exits.JNI doesn't know how you allocated your memory, so it can't free it when your function exits. Stack variables will obviously be destroyed because you're still writing C++, but your GPU memory will remain valid.The only problem then is how to access the memory on subsequent invocations, and then you can use Gunslinger47's suggestion:Java wouldn't know what to do with a pointer, but it should be able to store a pointer from a native function's return value then hand it off to another native function for it to deal with.  C pointers are nothing more than numeric values at the core.Another contibutor would have to tell you whether or not the pointed to graphics memory would be cleared between JNI invocations and if there would be any work-arounds.I know this question was already officially answered, but I'd like to add my solution:\nInstead of trying to pass a pointer, put the pointer in a Java array (at index 0) and pass that to JNI. JNI code can get and set the array element using /.In my code, I need the native layer to manage a file descriptor (an open socket). The Java class holds a  array and passes it to the native function. The native function can do whatever with it (get/set) and put back the result in the array.If you are allocating memory dynamically (on the heap) inside of the native function, it is not deleted.  In other words, you are able to retain state between different calls into native functions, using pointers, static vars, etc. Think of it a different way: what could you do safely keep in an function call, called from another C++ program?  The same things apply here.  When a function is exited, anything on the stack for that function call is destroyed; but anything on the heap is retained unless you explicitly delete it. Short answer: as long as you don't deallocate the result you're returning to the calling function, it will remain valid for re-entrance later.  Just make sure to clean it up when you're done. While the accepted answer from @denis-tulskiy does make sense, I've personnally followed suggestions from .So instead of using a pseudo-pointer type such as  (or  if you want to save some space on 32bits arch), use instead a . For example:which you can later re-use with:For very simple cases, this solution is very easy to use. Suppose you have:On the Java side, you simply need to do:Which saves you from writing  of boilerplate code ! One should however pay attention to byte ordering as explained .Its best to do this exactly how Unsafe.allocateMemory does.Create your object then type it to (uintptr_t) which is a 32/64 bit unsigned integer.This is the only correct way to do it.Here is the sanity checking Unsafe.allocateMemory does."},
{"body": "What's the difference between those? I'm just learning Java ATM, but it seems like I can write to a file both ways i.e. (I didnt copy the try-catch block here)andI understand the concept of buffering the data first, so does that mean the first example writes the characters one by one and the second first buffers it to the memory and writes it once?thanks for the helpBufferedWriter is more efficient if youIn your example, you have only one write, so the BufferedWriter just add overhead you don't need.In both cases, the string is written at once.If you use just FileWriter your write(String) callsThis makes one system call, per call to write(String).Where BufferedWriter improves efficiency is in multiple small writes.Without a BufferedWriter this could make 200 (2 * 100) system calls and writes to disk which is inefficient. With a BufferedWriter, these can all be buffered together and as the default buffer size is 8192 characters this become just 1 system call to write.You are right. Here is how  method of  looks:As you can see it indeed checks whether the buffer is full () and flushes the buffer. Then it adds new character to buffer ().BufferedWriter is more efficient. It saves up small writes and writes in one larger chunk if memory serves me correctly. If you are doing lots of small writes then I would use BufferedWriter. Calling write calls to the OS which is slow so having as few writes as possible is usually desirable.From the Java API specification:"},
{"body": "I'm trying to set up a multi-module Maven project, and the inter-module dependencies are apparently not being set up correctly.I have:in the parent POM (which has a packaging-type pom)\nand then subdirectories commons/ and storage/ which define JAR poms with the same name.Storage depends on Commons.In the main (master) directory, I run mvn dependency:tree and see:Why does the dependency on \"commons\" fail, even though the reactor has obviously seen it because it successfully processes its dependency tree?  It should definitely not be going to the 'net to find it as it's right there...The pom for storage:Thanks for any suggestions!(Edit)To clarify, what I am looking for here is this:  I don't want to have to install module X to build module Y which depends on X, given that both are modules referenced from the same parent POM.  This makes intuitive sense to me that if I have two things in the same source tree, I shouldn't have to install intermediate products to continue the build.  Hopefully my thinking makes some sense here...I think the problem is that when you specify a dependency Maven expects to have it as jar (or whatever) packaged and available from at least a local repo. I'm sure that if you run  on your commons project first everything will work.   As discussed in , the dependency:tree goal by itself will look things up in the repository rather than the reactor.  You can work around this by mvn installing, as previously suggested, or doing something less onerous that invokes the reactor, such asWorks for me.Realizing this is an older thread but it seems that either the tool evolved or this might have been missed the first time around.It is possible to perform a build that makes dependencies resolved without installing by doing a reactor build.If you start your build in the parent that describes the module structure of your project then  your dependencies between your modules will be resolved during the build itself through the internal Maven reactor.Of course this is not the perfect solution since it does not solve the build of a single individual module within the structure.  In this case Maven will not have the dependencies in his reactor and will bee looking to resolve it in the repository.  So for individual builds you still have to install the dependencies first.Here is some  describing this situation.for me, what led me to this thread was a similar problem and the solution was to ensure all module dependency pom's hadthe parent hadpommy model dep had pom - so there was no jar to be found.The only thing that workd for me : switching to gradle :(I have and I can just cd in war1 and use mvn tomcat7:run-war. \nI always have to install the whole project before, despite war1 references his parent and the parent references war1 and dep1 (as modules) so all dependencies should be known.I don't understand what the problem is.Make sure the module which is failing to get resolved, is pointing to the right parent by including the  configurations in the pom file of the module."},
{"body": "Are enum names interned in Java?I.e. is it guaranteed that  in case of the same name? And is it safe to compare  to a String that is guaranteed to be interned.Although there is no explicit guarantee of this, the end result is bound to be such that the comparison always succeeds for  constants with identical names:The reason for this is that Java compiler constructs subclasses of  in such a way that they end up calling 's sole protected constructor, passing it the name of  value:The name is embedded into the generated code in the form of a string literal. According to  documentation,This amounts to an implicit guarantee of your expression succeeding when names of  constants are identical. However, I would not rely on this behavior, and use  instead, because anyone reading my code would be scratching his head, thinking that I made a mistake.  is the best answer we have so far. There he says:and there they get interned, because they're string constants.But, in , there's this:So we'll call the constructor, but we aren't forced to do it in any particular way, and we can manage our own constructor in the compiler.Therefore, it's completely possible for me to write a correct and JLS-compliant Java compiler that would not intern the names somehow, probably by not having the names stored as a literals. Yes, it would do it on purpose to maliciously break your code, but it would be correct behaviour per spec.Every sane implementation will intern the strings. I'd say it's safe to  this kind of behaviour. It's not guaranteed, though, and therefore if I saw this in real code, I'd be very unsatisfied with it even if it was thoroughly described in a comment.Please, don't rely on such unspecified and implementation-specific behaviour. If you really, really have to, write a unit test for it. And put an  in the code, and lots of explaining. Measure whether your approach will actually do anything. This doesn't work reliably. See comments.With strings you're going to want to use the equals method of Strings. That aside, you already have the enum that you could compare with the equality operator. Under what scenario would this arise?That being said, yes, the .equals method will return true if they are the same.I'm not sure about equality operator, and without looking it up, I can tell you that it's poor programming to use it if it is.The Oracle documentation about Enum says (first line):If this is true then, yes, your  is guaranteed to be true if the names are the same.Also, in the method  javadoc:For example, if you had two enums,  and , where SUNDAY is a common value, == between the enum object values, SUNDAY will return true as you are comparing two strings - see the working example in ."},
{"body": "Is there any built-in method in Java to find the size of any datatype?\nIs there any way to find size?No.  There is no such method in the standard Java SE class library.The designers' view is that it is not needed in Java, since the language removes the need for an application to know about how much space needs to be reserved for a primitive value, an object or an array with a given number of elements.You might think that a sizeof operator would be useful for people that need to know how much space their data structures take.  However you can also get this information and more, simply and reliably using a Java memory profiler, so there is no need for a sizeof method.@Davor makes the point that  would be more readable than .  I'm not sure that I agree ... because I think that every Java programmer  to know that an  is  32 bits (4 bytes).  (And besides, it is rarely necessary to use the size of a type in Java code ...) However if you accept that readability argument, then the remedy is in your hands.  Simply define a class like this ...... and statically import it ...Why haven't the Java designers implemented this in standard libraries?  My guess is that:The key word in the above is .  (It does not matter what you or I think about it ... unless you have some influence in the decision making process.)There is also the issue that the next demand would be for a  method, which is fraught with technical difficulties.From the The  library is typically used for calling native shared libraries from Java.  Within this library there exist methods for determining the size of Java objects:The  method and its overloads will provide the size for most classes.Alternatively, if your classes inherit from JNA's Structure class the  method will be available.You can do bit manipulations like below to obtain the size of primitives:As mentioned , there are possibilities to get the size of primitive types through their wrappers. e.g. for a  this could be  from java 1.5 (as mentioned by  already) or  as from java 8You can use Integer.SIZE / 8, Double.SIZE / 8, etc. for primitive types from Java 1.5.The Instrumentation class has a getObjectSize() method however, you shouldn't need to use it at runtime.  The easiest way to examine memory usage is to use a profiler which is designed to help you track memory usage.I decided to create an enum without following the standard Java conventions. Perhaps you like this.The short answer is no.  The long answer is here: No. A good explanation to your question can be found here::-)I don't think it is in the java API. but most datatypes which have a number of elements in it, have a  method. I think you can easily write a function to check for size yourself?EhCache provides a  class that will try to use the  agent and will fall back to a different approach if the agent is not loaded or cannot be loaded (). Also see .There's a class/jar available on SourceForge.net that uses Java instrumentation to calculate the size of any object. Here's a link to the description: "},
{"body": "I am trying to automate keystore generation using the Java keystore tool. The command I am using is :But after this command, user is required to enter certain inputs as follows:Instead of the user entering these values , is there any way of providing these values without user interaction ,either within the command or through a script?ThanksTry this:See the   or by typing  without any arguments.Specifically you may want to look options  don't forget -noprompt, otherwise you will be asked to input Yes or No"},
{"body": "I'm trying out Android Studio. Upon creating a new project and adding a default  method to the create MyActivity class, when I try to commit the code to Git, I get a strange error I don't understand. The code is this:The error I get is this:If I try to change the method signature to , then the IDE tells me it can't resolve the symbol .What do I need to do to get rid of the warning?It's an annotation, but the correct name is :(And also)The purpose is to allow the  to warn when certain assumptions are being violated (such as a parameter of a method that should always have a value, as in this particular case, although there are others). From the  documentation:They are tools for static analysis. Runtime behavior is not altered at all.In this case, the particular warning is that the original method you're overriding (in ) has a  annotation on the  parameter, but you did not include it in the overriding method. Just adding it should fix the issue, i.e.A number of useful  were recently added in the Android support library. Their primary role is to annotate properties of various methods and parameters to help catch bugs. For example, if you pass  value to a parameter that is marked with the  annotation you will get a warning.The annotations can be added to your project with Gradle by adding the following dependency:You are getting the warning because the  parameter is marked with the  annotation and by overriding the method the annotation gets hidden. The right thing to do is to add the annotation to the overriden method's parameter as well.In addition to the other answers, the  (and it's opponent, ) annotation annotates a field, parameter or method return type. IntelliJ and thus Android Studio can warn you for possible s at compile time.An example is best here:These annotations do not alter runtime behavior (although I have  with this), but serve as a tool for preventing bugs. Note that the message you received was not an error, but just a warning, which is safe to ignore, if you choose to. The alternative is to annotate the parameter yourself as well, as Android Studio suggests:"},
{"body": "I'm looking for a good ORM for my android application and at first glance it seems like for a mobile device I would prefer to use something simpler maybe. The thing is I'm just assuming here with no real evidence, so I thought I would ask the community's opinion (maybe there's is someone that has been through the experience). It is a fairly large(for mobile) application and will be run on a dedicated tablet.What does everyone else think ? Is Hibernate too much for an android application ? Will there be performance problems ?What would you use instead if you think it is too much ?I am aware there are other questions asking for alternatives, but I decided to ask since most of those questions simply assumed it was an overkill and asked for other options and I started wondering \"Is it really and overkill ? Why ?\" Due to my lack of experience I simply think it it, but can't really provide an answer if I'm asked to explain why. Is it performance ? Is it too much configuration (Which I don't mind) ? Thanks!I'd like to recommend my  package.  It was designed to be  less heavy compared to Hibernate (and iBatis).  I think that Hibernate  too much for Android applications -- especially considering the size of the code and the number of dependencies.  The Android port of ORMLite makes direct calls to the Android database API.  A number of applications have been delivered using ORMLite successfully.Hibernate provides a number of features that cannot be supported by the Android database calls so you will be paying for complexity that you cannot even use.  I'm also not sure it has a native Android backend.  Using SQLite over JDBC is not officially supported by Android and I was unable to get it to work reliably.Yes hibernate is too much & others have searched for alternatives.Read here:Pick yours. :-)There are quite a few questions similar to yours already. Start with:though some of those questions might be outdated by now."},
{"body": "I currently do a lot of WPF development and have started creating some basic Android apps. When creating WPF apps I often use MVVM, normally using Prism, and would like to know if there are any examples of MVVM for the Android platform?I am the developer of . Like @Brentley said, it's a very new project but I do hope to get more buzz and experience so that it can be improved. Back to your question, I have written some simple introduction/tutorials on MVVM with android-binding:Potential adopters please also register on the I sometimes use ViewModels to translate from a pure Model to what the Model should be displayed as, but so much of the MVVM-isms come from the fact that you have this massive data binding engine built into the WPF framework.  You probably won't find the exact experience of WPF + MVVM in the Android world, but you can take a lot of the good concepts and implement them (just without the automatic data binding stuff).For one, just create ViewModels.  You don't need a framework like Prism to create ViewModels.  You don't have all the PropertyChanged notifications and stuff like that, but you can translate your data into information that can be better used by your UI which will clean up your code.  A perfect example of this is something I did with a slider-heavy UI.  Android's SeekBar is always zero based and works with integer values, so you can't bind to min, max, and increment values from your model.  You can use a ViewModel to translate your min/max values into 0-based equivalents that your SeekBar can use...just an example.  Same goes for displaying colors and sizes based on value ranges, etc.  To me, that's what ViewModels are all about.As far as DependencyInjection stuff, check out RoboGuice.  I just started using this in one of my projects after seeing a presentation by its creator at a local Meetup, and it's probably just what you're looking for.There is now an Official Android Data Binding Plugin although its still in beta at the moment. Work is also being done to add tooling support for the binding syntax in the beta version of Android Studio.See below for more informationThere is a relatively new framework being developed that allows for Views to be bound to ViewModels called . Using this framework and  you can get your MVVM on. The framework still needs some work, but it's a good starting point. library is a tool for connecting data to user interface elements. Once the layout file created and each item is tagged, one line of code binds all the data to user interface elements and saves your time for other tasks.Recently I have implemented the MVVM pattern for building an Android app with Data Binding Library. Here you can read the detailed review of the work I have done and the code fragments: To learn more about the topic, you can also have a look at these app samples:  There are visual examples of work done with the search and list screen.A few years ago I also do some WPF&WP development\uff0cPrism & MVVM Light Toolkit is commonly use to build WP App,it is perfect for windows phone application architecture I think ! so I use my previous experience of WP development then imitate to create (A toolkit help to build Android MVVM Application\uff0cWe have more attributes for Data Binding of View(like Uri for ImageView) ,we create some command for deal with event( like click of Button),also have a global message pipe to communicate with other ViewModel)., there are samples for reference.  hope to help you!There is one project called .It's free, open-source and well designed MVVM framework, developed by Stuart Lodge.He implemented binding for Android and iPhone, so now MVVM is applicable to all of these platforms too.For me it is one of the best MVVM frameworks - it really shows the power of MVVM. With it you can write one code (model and viewmodel layers) for different platforms (WP7, Android, iPhone, WinRT) and just change application UI (view layer).Just to post as a reference to other people who may be interested. I am a contributor to  - A data-binding Presentation Model framework for the Android platform. It is another framework for the same purpose. Apart from helping with project structure, one major focus for RoboBinding is to make testing android apps with normal JUnit tests possible instead of Android unit tests, as Unit tests are so important to guarantee the quality of projects, but Android unit tests take ages to run and make unit tests somewhat impractical.  itself comes with more than 300 JUnit tests to ensure its quality.  originated from Microsoft as a specialization of the Presentation Model design pattern introduced by Martin Fowler. Other alternatives: Android-Binding, Bindroid and MvvmCross.You can follow these steps for DataBinding in Fragments: I have posted design and java class both in Example for Binding Data in Fragment.I found this  App series written about MVVM using Android Data Binding library is really nice. In the series he explained from simple example to recyclerview, and there are tests as well.You can maybe try the , too."},
{"body": "Why does this not compile, oh, what to do?error copied from comment:Just ran into this post trying to fix it for myself. Gave me just enough information to work it out.You can give the compiler just enough to persuade it to compile by casting the return value from hasItems to a (raw) Matcher, eg:Just in case anybody else is still suffering ...Edit to add:\nIn spite of the up votes, this answer is wrong, as Arend points out below. The  answer is to turn the expected into an array of Integers, as hamcrest is expecting:hasItems checks that a collection contains some items, not that 2 collections are equal, just use the normal equality assertions for that. So either assertEquals(a, b) or using assertThatAlternatively, use the contains Matcher, which checks that an Iterable contains items in a specific orderIf you don't care about the order use  instead.You are comparing  with . The correct comparison is:-- Edit --I'm sorry, I've read it wrong. Anyway, the signature of  you want is:i.e., it accepts a variable number of arguments. I'm not sure if an  is compatible, just guessing here. Try sending each item from the expected list interspersed by comma.-- Edit 2 --Just pasting here my comment, there is an equivalent expression for what you want, without using Hamcrest:Tryto satisfy the matcher signature. No Eclipse around, so this might not work.That error message looks like one produced by the javac compiler. I've found in the past that code written using hamcrest just won't compile under javac. The same code will compile fine under, say, the Eclipse compiler.I think Hamcrest's generics are exercising corner cases in generics that javac can't deal with.I just came across the same problem and the following trick worked for me:You can get this error if you try to replace jUnit's hamcrest with a newer version. For example, using junit-dep together with hamcrest 1.3 requires that use assertThat from hamcrest instead of jUnit.So the solution is to useinstead ofFor these cases when code does compile in Eclipse but javac shows errors please do help hamcrest by providing explicitly type parameter e.g.\nMatchers.hasItem()hasItems(T..t) is being expanded by the compiler to:You are passing a single element array containing an ArrayList.  If you change the ArrayList to an Array, then your code will work.This will be expanded to:"},
{"body": "I am constructing an array of bytes in java and I don't know how long the array will be.  I want some tool like Java's StringBuffer that you can just call .append(byte b) or .append(byte[] buf) and have it buffer all my bytes and return to me a byte array when I'm done.  Is there a class that does for bytes what StringBuffer does for Strings?  It does not look like the ByteBuffer class is what I'm looking for.Anyone have a good solution?Try .  You can use  and it will grow as needed.Just to extend the previous answer, you can use  and it's method , where parameters are:If you want to use it as a \"byte builder\" and insert byte by byte, you can use this:Then you can use  method to convert the array to string. The advantage is when you need to set up encoding of input, you can simply use i.e.:I wrote one that is really easy to use and avoids a lot of byte array buffer copying.It has one method called add.You can add strings, bytes, byte, long, int, double, float, short, and chars to it.The API is easy to use and somewhat fail safe. It does not allow you to copy the buffer around and does not promote having two readers. It has a bounds check mode and a I KNOW WHAT I AM DOING MODE with no bounds checking.The bounds check mode auto-grows it so there is no hassle. Here is a complete step by step guide on how to use it. It is on github.Have you ever wanted an easy to use buffer array that grow automatically and/or you can give it a fix size and just add stuff to it? I have. I wrote one too.Look.. I can write strings to it (it converts them to UTF-8).Then later I can read the String out of the buffer:I never have to set the size of the array. It will auto-grow as needed in an efficient manner.If I know exactly how large my data is going to be than I can save some bounds checking by using . If I use create exact, then I am saying... hey.. I know exactly how big it can grow to and it will never go over this number and if it does...you can hit me over the head with a sack of rocks!The following hits you over the head with a sack of rocks!\nTHROWS AN EXCEPTION!!!!You can add all sorts of primitives to your byte array.Now we just verify that we can read everything back.Once you call then you are saying that you are done with the ByteBuffer!Once you ask for the bytes, it becomes useless as it sets the internal byte array to nothing.When you call readAndReset, it is giving you its buffer. Here is my internal state, you can have it, but I am going to set it to null so nobody else uses it.It is ok. Just create another if you are sure only one instance at a time is using the buffer (byte []).You can even use the buffer you were just using as in This is because no buffer gets copied. ByteBuf writes to the buffer you give it.\nIf you want another copy to be given to ByteBuf then do this:This is boon after all. :) Come check out boon. You get the above class and idx, and idxInt and idxLong for free!Let's see. There is the ByteBuffer class in Java.It has bulk methods that transfer contiguous sequences of bytes from a byte array to hardware buffers. It would do the trick.It also has absolute and relative get and put methods that read and write byte[]s and other primitives to / for the byte buffer.It also has methods for compacting, duplicating, and slicing a byte buffer.It also has a bulk put to put an array, which is pretty close to the append you were asking for:See:\nhttp://docs.oracle.com/javase/7/docs/api/java/nio/ByteBuffer.html#put(byte[])I wrote my own little lib for manipulating byte arrays. :)You can add them like sothis would give you all of the contents of b, and c after the contents for a.If you wanted to grow a by 21, you could do the following:If you wanted to double the size of a, you could do the following:See...CreateIndexContainsSlice:GrowShrink:Copy:Add:The add actually adds them together by using System.arraycopy (considering Unsafe, but not yet).Add one array to another:Insert:Here is a peek at a few of the methods:More...."},
{"body": "So with regex in java, I want to write a regex that will match if and only if the pattern is not preceded by certain characters. For example:I want to match if bar is not preceded by foo. So output would be:I know this is probably a very simple question. I am trying to learn regex, but in the meantime I need something to work now.You want to use  like this: ...where  means \"only if it doesn't have \"x\" before this point\"See  for more information.(edit: added the  to capture the characters before (e.g. \"beach\"))"},
{"body": "This is what I did to round a double to 2 decimal places:This works great if the amount = 25.3569 or something like that, but if the amount = 25.00 or the amount = 25.0, then I get 25.0!  What I want is both rounding as well as formatting to 2 decimal places. Are you doing money? Creating a string and then converting it back is pretty loopy.Use BigDecimal. This has been discussed quite extensively. You should have a money class and the amount should be a BigDecimal. Even if you're not doing money, consider BigDecimal.Just use: (easy as pie)The output will be 651.52Use a digit place holder (), as with '' trailing/leading zeros show as absent:  You  'round a double to [any number of] decimal places', because doubles don't have decimal places. You can convert a double to a base-10 String with N decimal places, because base-10 does have decimal places, but when you convert it back you are back in double-land, with  fractional places.You can use org.apache.commons.math.util.MathUtils from apache commonThis is the simplest i could make it but it gets the job done a lot easier than most examples ive seen.The result is 1.46.Use this String.format(\"%.2f\", doubleValue) // change 2, according to your requirement.You can use Apache Commons Math:source: Your Money class could be represented as a subclass of Long or having a member representing the money value as a native long.  Then when assigning values to your money instantiations, you will always be storing values that are actually REAL money values.  You simply output your Money object (via your Money's overridden toString() method) with the appropriate formatting. e.g $1.25 in a Money object's internal representation is 125.   You represent the money as cents, or pence or whatever the minimum denomination in the currency you are sealing with is ... then format it on output.  No you can NEVER store an 'illegal' money value, like say $1.257.double amount = 25.00;NumberFormat formatter = new DecimalFormat(\"#0.00\");System.out.println(formatter.format(amount));If you want the result to two decimal places you can doThis result is not precise but Double.toString(double) will correct for this and print one to two decimal places.  However as soon as you perform another calculation, you can get a result which will not be implicitly rounded. ;) is one answer, Presuming the amount could be positive as well as negative, rounding to two decimal places may use the following piece of code snippet.Starting java 1.8 you can do more with lambda expressions & checks for null. Also, one below can handle Float or Double & variable number of decimal points (including 2 :-)).where num is the double numberYou can try this one:orHere is an easy way that guarantee to output the  rounded to two decimal places:The result is: First declare a object of DecimalFormat class. Note the argument inside the DecimalFormat is #.00 which means exactly 2 decimal places of rounding off.private static DecimalFormat df2 = new DecimalFormat(\"#.00\");Now, apply the format in your double value:double input = 32.123456;\nSystem.out.println(\"double : \" + df2.format(input));// Output: 32.12Note in case of double input = 32.1;Then the output would be 32.10 and so on.Hope this clarifies the question."},
{"body": "I just prepare small update for my android app, but I get this strange bug when I try to build my app (in debug mode). It will be great if someone smarter could look at this to figure out what might been wrong. I was cleaning/rebuild/fix project properties, but with no results. I have no clues what is going on :(. Maybe something similar happen to anyone here?\nIf this can help I use following libraries: adMob(4.1.1), openfeint and libgdx.here is building log:You have same jar library included twice. Check your application and all referenced Android libraries and make sure you have all jars included exactly once.If that does not help, take a look at . Specifically look at first issue described in  section. Also you can read this post: I got this error after upgrading to R17.My cause was different (ie not the *_src issue that occurred in R15).  I had two different versions of a library in my \"libs\" folder.  It appears that the Android plugin now automatically adds any jars in \"libs\" to the \"Android Dependencies\" section in the Package Explorer.  Removing the old jar fixed the problem.for bugs appeared after the SDK update to r17 you could check out this:\nCheck duplicated jar files. \nCheck lib entries in project.properties. \nClean all the included libs and build from scratch.I have the same problem and here is the solution:Go to \"Build\" in the top and \"Clean Project\" and after \"Rebuild the project\" It helps me! Also you can go to \"Files\" and Invalidate caches\" and restart the Android StudioOf corse be sure that manifest is ok and no duplicate includes!I had same issue when I added android Ocr Api (tess-two) and imported sample application which was using this API but sample application and tess-two api had same packages thats why i was facing this issue, So I removed duplicate packages from my sample application and it was working fine. I had the same problem. In my case, I had 2 jars in my libs folder, let's say A and B. A was a custom jar that I created and already had B included. This wasn't a problem until I updated to R17.\n\nSolution: I removed B from libs.Have a maps project in google_play_services/samples. Install jar from libproject to maven repository, add dependency to maps project and found that error. Using provided scope in dependency section solves the issue."},
{"body": "I am trying to understand the real purpose of session configuration in Web.xml for session timeout.Now let me tell you about my question.My application is importing/uploading a .txt file, which is bound to take more than 1 hour, since there are millions of records to be imported.\nBut the session times out after 1 hour though my application is still importing that .txt file which is in progress.\nSuch an application should not timeout as the application is doing some task in the background.To set a session-timeout that never expires is not desirable because you would be reliable on the user to push the logout-button every time he's finished to prevent your server of too much load (depending on the amount of users and the hardware). Additionaly there are some security issues you might run into you would rather avoid.  The reason why the session gets invalidated while the server is still working on a task is because there is no communication between client-side (users browser) and server-side through e.g. a http-request. Therefore the server can't know about the users state, thinks he's idling and invalidates the session after the time set in your .  To get around this you have several possibilities:  There was a similar question asked, maybe you can adapt parts of this solution in your project. Have a look at .  Hope this helps, have Fun!You can use \"-1\" where the session never expires. Since you do not know how much time it will take for the thread to complete.Send AJAX Http Requests to the server periodically (say once for every 60 seconds) through javascript to maintain session with the server until the file upload gets completed.Hacky way:You could increase the session timeout programmatically when a large up-/download is expected.When the process ends, you could set the timeout back to its default.But.. when you are on Java EE, and the up-/download doesn't take a complete hour, the better way was to run the tasks asynchronous (via JMS e.g.).In the above code  The session will expired after  So if you want to more time. For Example  that is described your session never expires.The docs says:You can see many options as answer for your question, however you can use \"-1\" where the session never expires. Since you do not know how much time it will take for the thread to complete. E.g.:Or if you don't want a timeout happening for some purpose:Another option could be increase the number to 1000, etc, etc, bla, bla, bla.BUT IF YOU REALLY WANT TO STOP AND YOU CONSIDER THAT IS UNNECESSARY FOR YOUR APPLICATION TO FORCE THE USER TO LOGOUT, JUST ADD A LOGOUT BUTTON AND THE USER WILL DECIDE WHEN TO LEAVE.Here is what you can do to solve the problem if you do not need to force to logout, and in you are loading files that could take time base on server and your computer speed and the size of the file.Just comment it or deleted that's it! Tan tararantan, tan tan!you can declare time in two ways for this problem..1) either give too long time that your file reading is complete in between that time.2)declare time which is never expires your session.Another option I would recommend is to create a separate application that is stateless that would take the large file.  On your main app open a new window or iframe that will accept the file and send it through that window then hide the window or iframe once the upload has started using Javascript.If you don't want a timeout happening for some purpose:Should result in no timeout at all -> infiniteYou should consider splitting the large file to chunks and rely on multi threading capabilities to process more than one file at a time \nOR \nlet the whole process run as a background task using TimerTask and write another query to know the status of it form the browser including a progress bar can be shown if you can know the process time of a file or record.Usually the session will not expire when request processing is happening. I think there is an LB or something in between which reads the entire file and then invokes the web container.This might be causing a delay which is leading to expiry of the session."},
{"body": "I am running a program that I've written in Java in Eclipse. The program has a very deep level of recursion for very large inputs. For smaller inputs the program runs fine however when large inputs are given, I get the following error:Can this be solved by increasing the Java stack size and if so, how do I do this in Eclipse?@Jon SkeetThe code is traversing a parse tree recursively in order to build up a datastructure. So, for example the code will do some work using a node in the parse tree and call itself on the node's two children, combining their results to give the overall result for the tree.The total depth of the recursion depends on the size of the parse tree but the code seems to fail (without a larger stack) when the number of recursive calls gets into the 1000s.Also I'm pretty sure the code isn't failing because of a bug as it works for small inputs.Open the  for your application (Run/Run Configurations..., then look for the applications entry in 'Java application').The  tab has a text box , enter  (or a bigger parameter for the maximum stack size). The default value is 512 kByte (SUN JDK 1.5 - don't know if it varies between vendors and versions).It  be curable by increasing the stack size - but a  solution would be to work out how to avoid recursing so much. A recursive solution can always be converted to an iterative solution - which will make your code scale to larger inputs much more cleanly. Otherwise you'll really be guessing at how much stack to provide, which may not even be obvious from the input.Are you absolutely sure it's failing due to the size of the input rather than a bug in the code, by the way? Just how deep is this recursion?EDIT: Okay, having seen the update, I would personally try to rewrite it to avoid using recursion. Generally having a  of \"things still do to\" is a good starting point to remove recursion.Add the flag  in the VM Arguments. You can also increase stack size in  by using  for example .i also have the same problem while parsing schema definition files(XSD) using XSOM library,i was able to increase Stack memory upto 208Mb then it showed  for which i was able to increase only upto 320mb.the final configuration was  but then again it ran for some time and failed.My function prints recursively the entire tree of the schema definition,amazingly the output file crossed 820Mb for a definition file of 4 Mb(Aixm library) which in turn uses 50 Mb of schema definition library(ISO gml).with that I am convinced I have to avoid Recursion and then start iteration and some other way of representing the output, but I am having little trouble converting all that recursion to iteration.You need to have a launch configuration inside Eclipse in order to adjust the JVM parameters.After running your program with either F11 or Ctrl-F11, open the launch configurations in Run -> Run Configurations... and open your program under \"Java Applications\".  Select the Arguments pane, where you will find \"VM arguments\".This is where  goes.If you want the launch configuration to be a file in your workspace (so you can right click and run it), select the Common pane, and check the Save as -> Shared File checkbox and browse to the location you want the launch file.  I usually have them in a separate folder, as we check them into CVS.When the argument  doesn't do the job try deleting the temporary files from:This did the trick for me.Look at Morris in-order tree traversal which uses constant space and runs in O(n) (up to 3 times longer than your normal recursive traversal - but you save hugely on space). If the nodes are modifiable, than you could save the calculated result of the sub-tree as you backtrack to its root (by writing directly to the Node).   "},
{"body": "Is it possible from Spring to inject the result of calling a method on a ref bean? I'm trying to refactor some cut/pasted code from two separate projects into a common class. In one of the projects, the code lives in a class I'll call \"MyClient\" that is being instantiated from Spring. It is injected with another spring-instantiated class \"MyRegistry\", then the MyClient class uses that class to look up an endpoint. All I really need is the endpoint String in my refactored class, which can be initialized via a Setter. I really cannot have a dependency on MyRegistry from MyClient in the refactored code. So, my question is this... is there a way I can inject the endpoint String from spring that was looked up in the MyRegistry class. So, I currently have:But I'd like to have (and I know this is imaginary Spring syntax)where MyRegistry will have a method getEndPoint(Stirng endPointName)Hope that makes sense from a the standpoint of what I'm trying to achieve. Please let me know if something like this is possible in Spring!The nicest solution is to use Spring 3's expression language as described by @ChssPly76, but if you're using an older version of Spring, it's almost as easy:It's possible in Spring 3.0 via :Or in Spring 2.x, by using a BeanPostProcessorAnd register your BeanPostProcessor"},
{"body": "It was very confusing to me to observe this situation:So, as I think boxing operation is executed first (i.e. java tries to extract int value from ) and comparison operation has lower priority that's why the exception is thrown.The question is: why is it implemented in this way in Java? Why boxing has higher priority then comparing references? Or why didn't they implemented verification against  before boxing? At the moment it looks inconsistent when  is thrown with wrapped primitives and is not thrown with  object types.The key point is this:The above statements hold for any given  Java code. With this understanding, there is no inconsistency whatsoever in the snippet you presented.Here are the relevant JLS sections:This explains the following:Both operands are reference types, and that's why the  is reference equality comparison.This also explains the following:For  to be numerical equality, :This explains:Here's an excerpt from :There are places where you have no choice but to use boxed primitives, e.g. generics, but otherwise you should seriously consider if a decision to use boxed primitives is justified.Your NPE example is equivalent to this code, thanks to :Hence NPE if  is .i is an Integer and the 0 is an int so in the what really is done is something like thisAnd this cause the nullPointer because the i is null. For String we do not have this operation, thats why is no exception there.The makers of Java could have defined the  operator to directly act upon operands of different types, in which case given  the comparison  could ask the question \"Does  hold a reference to an  whose value is ?\"--a question which could be answered without difficulty even when  is null.  Unfortunately, Java does not directly check whether operands of different types are equal; instead, it checks whether the language allows the type of either operand to be converted to the type of the other and--if it does--compares the converted operand to the non-converted one.  Such behavior means that for variables , , and  with some combinations of types, it's possible to have  and  but  [e.g. x=16777216f y=16777216 z=16777217].  It also means that the comparison  is translated as \"Convert I to an  and, if that doesn't throw an exception, compare it to .\"It's because of Javas  feature. The compiler detects, that on the right hand side of the comparison you're using a primitive integer and needs to unbox the wrapper Integer value into a primitive int value as well. Since that's not possible (it's null as you lined out) the  is thrown.In  Java will try to do auto-unboxing and do a numerical comparison (i.e. \"is the value stored in the wrapper object referenced by  the same as the value ?\").Since  is  the unboxing will throw a .The reasoning goes like this:The first sentence of  reads like this:Clearly  is convertible to a numeric type and  is a numeric type, so the binary numeric promotion is performed on the operands. says (among other things): says (among other things):"},
{"body": "I have code to calculate the percentage difference between 2 numbers -  - where both of the numbers are s. I expected to have to add some sort of checking / exception handling in case oldNum is 0. However, when I did a test run with values of 0.0 for both oldNum and newNum, execution continued as if nothing had happened and no error was thrown. Running this code with s would definitely cause an arithmetic division-by-zero exception. Why does Java ignore it when it comes to s?The result of division by zero is, mathematically speaking, , which can be expressed with a float/double (as  - not a number), it isn't, however, wrong in any fundamental sense.As an integer must hold a specific numerical value, an error must be thrown on division by zero when dealing with them.Java's  and  types, like pretty much any other language out there (and pretty much any hardware FP unit), implement the  standard for floating point math, which mandates division by zero to return a special \"infinity\" value. Throwing an exception would actually violate that standard.Integer arithmetic (implemented as  representation by Java and most other languages and hardware) is different and has no special infinity or NaN values, thus throwing exceptions is a useful behaviour there.The way a double is stored is quite different to an int. See  for a more detailed explanation on how Java handles double calculations. You should also read up on Floating Point numbers, in particular the concept of . If you're interested in learning more about floating point representation, I'd advise reading  (Word format, sorry). It delves into the binary representation of numbers, which may be helpful to your understanding.Though Java developers know about the double primitive type and  class, while doing floating point arithmetic they don't pay enough attention to , ,  and other rules that govern the arithmetic calculations involving them. The simple answer to this question is that it will not throw  and return . Also, note that the comparison  always evaluates to , even if  itself is a .To test if  is a , one should use the method call  to check if given number is NaN or not. This is very close to  in .It may helpful for you."},
{"body": "In Eclipse I was able to register a set of classes for static import auto-completion, e.g. Math., EasyMock.*With this enabled I was able to hit ctrl-space assertEquals, pow, createMock etc. would appear as valid code completions.I'm struggling to find this in IntelliJ but am sure it must exist. Can anyone help?Thanks!.In the middle of the pane is the \"Packages to Use Import with '*'\" table.  You can add an entry here of a fully-qualified class name, and tick the static box; now all static methods in this class will be available for auto-completion.(I'm not sure how the static import works with specifying a package, as I've never tried it, but I don't see why it wouldn't.  Specifying a super-package and ticking the \"with subpackages\" option could be even more interesting.)If you're using IntelliJ 10, try the following:Accepting a suggestion from the resulting popup list will, by default, insert a ClassName.methodName() reference (which you can convert to a static import using an Alt-Enter intention).You can also insert a statically imported method from the completion list by choosing \"Right\" in the completion menu, and selecting \"Import Statically\":Note that once you've statically imported a single method from a class (Assert.assertSame), other static methods from that class (like Assert.assertEquals) will be included in the \"regular\" code completion (Ctrl-Space).For Intellij 12 just hit . Then to import the method statically hit . Otherwise just hitting enter will insert the fully qualified name of the method.\nSometimes just using  works too. will do the trick. You have to have the whole expression at first, and the hit  on the method you want to statically import.Just do the reference once, then put the caret on the class name (ie Math), press alt+enter and choose \"add on demand static import for 'java.lang.Math'. Intellij will addto the top of the file.In OS X you need to do a option + return.To add to what loyalBrown said in his update, all we need to do is hit  instead of Ctrl + space. (Tested on IntelliJ 13)UPDATE: Looks like you need to duck type the entire statement first, and then alt + return."},
{"body": "I was looking over some mock  questions. I came across a really baffling syntax. Here it is:Why does the output change between  and ?The question is just playing with you with confusing spacing. is the usual  (not equals) comparison.On the other hand: is better written as  which is parsed as:Thus it's two operators.The assignment operator returns the assigned value. Therefore,  evaluates to true - which is what you print out. means : the opposite of . is actually , an assignment. It's toggling 's value. An assignment evaluates to the value of the expression, so this will evaluate to  (along with having changed the value of ). is an assignment. It assigns  to  and the expression evaluates to the resulting value, which is .b =! byou are doing an assignment, you are saying that B should have the value of !B. b != bYou are asking if B is different than b"},
{"body": "I have a Spring Boot application with dependency \"spring-boot-starter-data-jpa\". My entity class has a column annotation with column name. For example:SQL generated by this created test_name as column name. After looking for solution I have found that  solved the problem (column name is taken from column annotation).Still, my question is why without naming_strategy set to  JPA is ignoring column annotation? Maybe hibernate dialect has something to do with it? I'm connecting to MS SQL 2014 Express and my logs contains:By default Spring uses  to generate table names. This is a very thin extension of . The  method in that class is passed a source  value but it is unaware if it comes from a  attribute or if it has been implicitly generated from the field name.The  will convert  to  where as the  just uses the table name unchanged.If you don't want to change the naming strategy you could always just specify your column name in lowercase:For hibernate5 I solved this issue by puting next lines in my application.properties file:It seems that is completely ignored unless there isspecified, so to me this is a bug. I spent a few hours trying to figure out why @Column(name=\"..\") was ignored., thank you so much.\nJust an added information so, everyone bumping into this question will be able to understand why.What  said is indicated on the Spring Boot Common Properties: Apparently,  is not a supported property for Spring JPA implementation using Hibernate 5.The only solution that worked for me was the one posted by teteArg above. I'm on Spring Boot 1.4.2 w/Hibernate 5. Namely For additional insight I'm posting the call trace so that its clear what calls Spring is making into Hibernate to setup the naming strategy.The only thing that worked for me was having both lines of code as posted above:Having only the single line proposed by ncaralicea did not work for me"},
{"body": "Why does this print 1? Can we mix casting and  unary operators? I know that we can do casting multiple times, but why doesn't putting  unary operators in between produce an error?You are not adding nor substracting. Those + and - operators are unary sign operators.See  at  section.The sequence at stake: is evaluated from right to left like this:  These  and  are unary ones.More specifically, it is in fact:if you remove all casting from your example, because in this case it will do nothingwill becomenow you can see that just the operators are still there and because  your result will be 1basically you can think of it like:It is simply a consequence of the consistency of Java's grammar. When you writewhat you actually wrote is a  which decomposes into two parts: Another example of a numeric expression is a  (also unary):Therefore you can substitute this for the original  above:Repeating the same consistent process we can end up with a nested unary expression of arbitrary complexity. To return to your key question:Because Java would actually need a specific rule  such expressions. "},
{"body": "The moment I added the android support annotations to my dependenciesI got this error:Anybody else experienced this issue? I have tried the solutions from .The problem is that  used to be a separate library containing the android annotations, but for some reason these annotations are already included in recent versions of the  file.Deleting the annotations jar solved the issue.Build->clean Project ,and it workedI deleted the android-support-v4.jar and it worked.If this is cordova / ionic project this worked for meadd these line to build.gradle under platforms/android after line number 22 i.e after Solved this exact issue in a Cordova project that used the facebook plugin.  I was able to successfully build by commenting out this line from , as shown:And by commenting out this line from , as shown:Then doing the build.  The problem started when I installed (katzer/cordova-plugin-local-notifications) which added these lines, but it created a conflict since the library it was adding to the build was already part of the facebook plugin build.If you are sure that there are no dependencies problems you can try this:If you don't find the task in your file you can add itI had the same problem , but i deleted build files from the build folderprojectname/app/buildand it removed all the related error. \"can't clean the project\" and also \"dex errow with $anim\"I managed to fix this issue. The reason was that I included the android support library 19.0.0 as a dependency, but 19.1.0 is required. So it has to be If you import  as a library project and you also have  in libs elsewhere, make sure to import everywhere  library only (it already includes this annotations lib). Then delete all  to avoid merging multiple versions of this library.Updating Android SDK Tools fixed it for me, now it just sees the copy in .I had the same problem when using ant, and the annotations library was being included automatically by an outdated .  Clean project works as a temporary fix, but the issue will reappear on next compilation error.To fix more reliably, I had to update the dependency to android  to .For me the reason was the new data-binding libit somehow used a conflicting version of the annotations lib, which I could not force with but the new  and  versions seem to have fixed it, so just use those versionsPut in your  the dependency of support-annotations according with your compileSdkVersion. For instance: A project with the  you can put the following dependence:This will solve your problem.In my case I had a file called  under  in the root project folder. I deleted this file, rebuild the project and it worked for me.I deleted the android-support-v4.jar and it worked.Explain - android-support-v4.jar is conflicting with my other .jar files of project\\libs files ** specially when you are running with java 8 on AS.Put android-support-v4.jar in your libs folder in eclipse. Clean and build the project. It will resolve the issue.Another reason that messages such as these can come up in Android Studio when building and launching can be the cause of application tags in your libraries.If you have several Android Library projects that you imported as modules.  Go into those projects and remove the  tags and everything between them.  These can cause issues in the build process along with the support library issues already mentioned.From /platforms/android/libs/\ndelete android-support-v4.jar.\nIt works for me."},
{"body": "I've got a few classes that implement  and some of these classes contain each other as properties. I'm marshalling the classes into a  to pass them between activities. Marshalling them TO the Parcel works fine, but when I try to unmarshall them I get the following error:The  class (where it's failing):Here's the  class:: As far as I can tell it's failing at the following bit of code (from ):Why is it not able to find the class? It both exists and implements .Because this was not answered in \"answer\" but in comment I will post an answer:\nAs @Max-Gontar pointed you should use LocationType.class.getClassLoader() to get the correct ClassLoader and get rid of ClassNotFound exception, i.e.:I had the same problem with the following setup: some handler creates a Message and sends its over a Messenger to a remote service.the Message contains a Bundle where I put my Parcelable descendant:I had the same exception when the remote service tried to unparcel. In my case, I had overseen that the remote service is indeed a separate os process. Therefore, I had to set the current classloader to be used by the unparcelling process on the service side:Bundle.setClassLoader sets the classloader which is used to load the appropriate Parcelable classes. In a remote service, you need to reset it to the current class loader.I found the problem was I was not passing my applications ClassLoader to the unmarshalling function:Rather than:ORI am not very familiar with Parcelable but if it's anything like Serialization each call to write an object that implements the interface will cause a recursive call to writeToParcel(). Therefore, if something along the call stack fails or writes a null value the class that initiated the call may not be constructed correctly. Try:\nTrace the writeToParcel() call stack through all the classes starting at the first call to writeToParcel() and verify that all the values are getting sent correctly.Just adding my 2 cents here, because I lost more than half a day scratching my head on this. You might get this error if you don't put the writes methods and reads methods in the exact same order. For instance the following would be wrong:By the way the author did this correctly but it might help someone one day.I got ClassNotFoundException too and posting my solution bc the answers here led me to the right direction. My scenario is that I have nested parcelable objects. Object A contains an ArrayList of Object's B. Both implement Parcelable. \nWriting the list of B Object's in class A:Reading the list in class A:Thank you! Instead of using writeParcelable and readParcelable use writeToParcel and createFromParcel directly.  So the better code is:Well I had the same problem and solve it in a very silly way that  I dont know if its called a solution at all.lets say you have this class you want to pass to another activityThats it When I changed the:toThe problem was solved???!!!!If you have an Object with a property of type of List objects you should pass the class loader when you read the property for example:"},
{"body": "I am wondering if I am going about splitting a string on a  the right way? My code is: I only need the first part of the string that's why I return the first item. I ask because i noticed in the API that . means any character so now I'm stuck. accepts a regular expression, so you need to escape  to not consider it as a regex meta character. Here's an exemple :Split uses regular expressions, where '.' is a special character meaning anything. You need to escape it if you actually want it to match the '.' character:(one '\\' to escape the '.' in the regular expression, and the other to escape the first one in the Java string)Also I wouldn't suggest returning fn[0] since if you have a file named , which is a valid name you won't be returning the actual file name. Instead I think it's better if you use:the String#split(String) method uses regular expressions.\nIn regular expressions, the \".\" character means \"any character\".\nYou can avoid this behavior by either escaping the \".\"or telling the split method to split at at a character class:Character classes are collections of characters. You could writeand filename would be split at every \"-\", \".\", \";\", \"l\", \"d\" or \"7\". Inside character classes, the \".\" is not a special character (\"metacharacter\").You need to know few things about .  method:You also need to know that  is  in . It represents  (except line separators but this can be changed with  flag).So for string like  if we split on   method will which means we will get as result empty array  (with no elements, not even empty string), so we can't use  because there is no index 0.To solve this problem you simply need to create regex which will represents dot. To do so we need to escape that . There are few ways to do it, but simplest is probably by using  (which in String needs to be written as  because  is also special there and requires another  to be escaped).So solution to your problem may look likeYou can also use other ways to escape that dot like As DOT( . ) is considered as a special character and split method of String expects a regular expression you need to do like this - In java the special characters need to be escaped with a \"\\\" but since \"\\\" is also a special character in Java, you need to escape it again with another \"\\\" !Usually its NOT a good idea to unmask it by hand. There is a method in the Pattern class for this task:The split must be taking regex as a an argument...  Simply change  to Wouldn't it be more efficient to useif you only want what's up to the first dot? takes a regex as argument. So you should pass \".\" instead of \".\" because \".\" is a metacharacter in regex."},
{"body": "I am receiving hex color values from a server (in this form,  , example  for black)How do I convert this to an integer value? I tried doing  to get an even more hextastic  result, but this isn't intepreted as an  here, any other suggestions?I receive an error: I am using the Android SDK for their  function, which takes - as you might have guessed - an integer color value.This is the OPPOSITE of this question: The real answer is to use: in Android,  being the  value like  or  or .However, this function  such as .I have the same problem that I found some color in form of  and I want to conver that into a form that android could make use of. \nI found that you can just use  so that android could automatically tell the color. Notice the first  is telling  value. \nHope it helpsI was facing the same problem. This way I was able to solved it. \nAs CQM said, using Color.parseColor() is a good solution to this issue.Here is the code I used:In this case my target was to change the Button's text color (Button_C) when I change the color selection from my Preferences (color_prefs). The real answer is this simplest and easiest ....Try this, create drawable in your resource...then use...with color... \"#FFFFFF\"if the color is transparent use... setAlpha with x float 0-1 Ej (0.9f)Good Luck"},
{"body": "I want to implement custom  which must look like this:So questions:This is pretty much as close as you'll get if you want to use the  APIs. I'm not sure you can place a colorstrip above the  without doing some weird  hacking, it's not worth the trouble. As far as changing the  goes, you can make those tighter via a style. It would be something like this, but I haven't tested it.If you want to customize it more than this, you may consider not using the  at all, but I wouldn't recommend that. You may also consider reading through the  to get a better idea on how to design your  If you choose to forgo the  and use your own layout instead, you should be sure to add action-able  when users long press your \"MenuItems\". This can be easily achieved .1 You can use a drawable2 Create a style for the action bar and use a custom background:3 Style again android:actionBarDividerThe  is very usefull for that.Please write following code in menu.xml file:Also write this java code in activity class file:This is the easiest way to display menus in action bar."},
{"body": "I want to subtract two timeperiods say 16:00:00 from 19:00:00. Is there any java function for this? The results can be in milliseconds, seconds, or minutes.Difference is in milliseconds.I modified .TO get pretty timing differences, then Java 8Java 8 has a  - Instant and DurationExample:Just like any other language; convert your time periods to a unix timestamp (ie, seconds since the Unix epoch) and then simply subtract.\nThen, the resulting seconds should be used as a new unix timestamp and read formatted in whatever format you want.Ah, give the above poster (genesiss) his due credit, code's always handy ;)\nThough, you now have an explanation as well :)and, to show in a nicer format, you can use:The painful way is to convert to millis and do the subtraction and then back to whatever seconds or so you want. The better way is to use .\u0410lternative option if time from different days is taken, for example: 22:00 and 01:55.Now minutes will be the correct duration between two time (in minute).class TimeCalculator\n{\n    String updateTime;}"},
{"body": "I know that the convention in Java for boolean getters is include the prefix \"is\". But what if the subject is plural? That is, what if instead of wanting to know if a store is open, I wanted to know if all the stores are open? doesn't make sense in English.I'm tempted to write getters like:And I think that would make sense, but I've been told by others that I should just suck it up and abandon subject verb agreement and use , , . Anyway, what should I do for boolean getters which operate on a plural subject? I can't remember which book this was from, but the essence is that code will be read many more times than it's written.  Write for readability.How about having decent enough english and following Java standard: or When in doubt of the right word I always like to hit up the thesaurus.The convention is to prefix the getter-method with \"is\" not the variale itself. For the plural scenario, you know the variable is just one.e.g.andIt might not make sense from the readability point of view. But, what about the the Java convention itself? It's been set already, and way too much code has been written already to change to make it sensible according to English grammer. Lots of tools expect  or  and won't likely recognize .Try rephrasing them, like  or  or things like that for better compatibility and conventions.The Java Bean specification says to use  for getters unless it's a  then use .  is non-standard and will not be recognized by anything that expects standard Bean naming.  can also be written as  in . Its just a good habit to follow the naming conventions, help when you are working with .In general I think code should be as easily readable as possible so that a method can almost be read as a paragraph (as espoused by ). Therefore, I would name the method to sound / read as easily as possible and go with the grammer rule of . With modern IDEs it is easy to find methods without looking specifically for  / .However, Kumar makes a good point about beans. A lot of tools will only look for  / . In that case I might consider having both methods. One for ease of reading and one for tool use.In object-oriented programming, this should rarely, if ever, occur since  or  or what have you should be a separate class, with its own  or  method.  If you have a higher type, consider splitting down to the more atomic level that you're actually using.  In general, objects should not be plural at the lowest level.What language do you writing at:  or ?When I am reading Java code, I expect things to be there, having me to search for both getters, with  and  prefixes, will be more complicated than searching for just one prefix.However from other hand, when I read newspaper in the morning, I am not looking for anything, so you can write in more traditional way of English.return 0;In your question you're explicitly asking about getters. A getter returns some information about one instance of your class. For example you have a class . Now,  is a perfectly fine method name for a getter.Next, you mention a method that checks if all stores are open. This method isn't a getter at all, because it doesn't return information about one instance but for all. Of course unless there is a class . If this is the case, you should rethink your design, because Java already has ways to store a number of instances, e.g. arrays or collections, so you don't have to write extra classes.If this is not the case, then this method name is perfectly fine. An alternative may be just  without the 'is'.TL;DR: If you're dealing with multiple instances, it's not a getter. If it is, your design is bad.Quite honestly I would say definitely forget about the  and stick with . Think of the  as the variable meaning and make a better name if possible. I would say is isStoresOpen doesn't sound that bad, but you can make isStoresAreOpen if that sounds better for you. But my general idea would be to stick to the conventions. Which is using \"get\" for getters and \"is\" for boolean types. Personally I think using \"is\" is sometimes already problematic. Yes - it does look good in \"if\" conditions, but sometimes I just write \"get\" when coding and check the drop down list for my needed variable and start wondering what's wrong and why I can't find it, then I realize it starts with \"is\"... in this StoresOpen is seems like a plural,When you follow that Java Naming Convention and Java Beans Standards, they have predefined prefix's for boolean and other type, so you should follow Java Beans Naming Convention. Let's come to your point\nWhen you see  as in an English prospective, yes it looks like plural.\nOnce again take deep observation into that word, Here is plural according to English grammar,The out come of the  is not plural, instead of it is singular or you can say it is scalar in terms of programming convention.It's out come is boolean, just true or falseNot like your English plural statement  or Not an array of  or , or not a collections of  or  So, here we can say that, here we are concerned with value that is return from that boolean bean method, not the name given to the property of class to point real world entity.One more important thing is, whenever such boolean properties are used in classes and those are used by predefined libraries in any framework, then framework with use prefix '' for retrieving  boolean values, why means it's not that much of smarter than you as you know English grammar like plural/singular, multiplexer etc..."},
{"body": "Please advice how to convert a  to  using  library. What I unsuccesfully do: You don't need to use . You should be using Gson to convert to/from JSON strings and your own Java objects.See the :To do it in a simpler way, consider below:Looks like the above answer did not answer the question completely.I think you are looking for something like below:where my response is something like this:As you can see, the variable name should be same as the Json string representation of the key in the key value pair. This will automatically convert your gson string to JsonObject.I do this ,and it is worked."},
{"body": "How do you define a field, eg  as having an index using JPA annotations. We need a non-unique key on  because there are literally millions of queries on this field per day, and its a bit slow without the key.I have seen a hibernate specific annotation but I am trying to avoid vendor specific solutions as we are still deciding between hibernate and datanucleus.UPDATE:As of JPA 2.1, you can do this. See: As far as I know, there isn't a cross-JPA-Provider way to specify indexes. However, you can always create them by hand directly in the database, most databases will pick them up automatically during query planning.With JPA 2.1 you should be able to do it.: If you ever need to create and index with two or more columns you may use commas. For example:JPA 2.1 (finally) adds support for indexes and foreign keys! See  for details. JPA 2.1 is a part of Java EE 7, which is out .If you like living on the edge, you can get the latest snapshot for eclipselink from their  (groupId:org.eclipse.persistence, artifactId:eclipselink, version:2.5.0-SNAPSHOT). For just the JPA annotations (which should work with any provider once they support 2.1) use artifactID:javax.persistence, version:2.1.0-SNAPSHOT.I'm using it for a project which won't be finished until after its release, and I haven't noticed any horrible problems (although I'm not doing anything too complex with it).UPDATE (26 Sep 2013): Nowadays release and release candidate versions of eclipselink are available in the central (main) repository, so you no longer have to add the eclipselink repository in Maven projects. The latest release version is 2.5.0 but 2.5.1-RC3 is also present. I'd switch over to 2.5.1 ASAP because of issues with the 2.5.0 release (the modelgen stuff doesn't work).Just go for one of them.I'd really like to be able to specify database indexes in a standardized way but, sadly, this is not part of the JPA specification (maybe because DDL generation support is not required by the JPA specification, which is a kind of road block for such a feature).  So you'll have to rely on a provider specific extension for that. Hibernate, OpenJPA and EclipseLink clearly do offer such an extension. I can't confirm for DataNucleus but since indexes definition is part of JDO, I guess it does.I really hope index support will get standardized in next versions of the specification and thus somehow disagree with other answers, I don't see any good reason to not include such a thing in JPA (especially since the database is not always under your control) for optimal DDL generation support.By the way, I suggest downloading the JPA 2.0 spec.In JPA 2.1 you need to do the followingIn the above example the table TEST_PERSON will have 3 indexes: Note 1: You get the compound index by having two @Index annotations with the same nameNote 2: You specify the column name in the columnList not the fieldNameOpenJPA allows you to specify non-standard annotation to define index on property.Details are .EclipseLink provided an annotation (e.g. ) to define an index on columns.  There is an  of its use.  Part of the example is included...The firstName and lastName fields are indexed, together and individually.To sum up the other answers:I would just go for one of them. It will come with JPA 2.1 anyway and should not be too hard to change in the case that you really want to switch your JPA provider.It's not possible to do that using JPA annotation. And this make sense: where a UniqueConstraint clearly define a business rules, an index is just a way to make search faster. So this should really be done by a DBA.This solution is for EclipseLink 2.5, and it works (tested):This assumes ascendant order."},
{"body": "I would like to get a list of files with a specific extension in a directory. In the API (Java 6), I see a method  which would do this.Since I need a specific extension, I created a . However I get a compilation error when I use  with this. I assumed that since , I should be able to do this. Code follows:The last line shows a compilation error:I am trying to use , not . Why does the compiler not recognize this?This works if I write my own extension filter extending . I would rather use  than write my own. What am I doing wrong?The  class is intended for  to be used in a .Try using a  instead. For example:Is there a specific reason you want to use ?  I know this works..  One-liner in java 8 syntax: Duh.... listFiles requires java.io.FileFilter. FileNameExtensionFilter extends javax.swing.filechooser.FileFilter. I solved my problem by implementing an instance of java.io.FileFilterEdit: I did use something similar to @cFreiner's answer. I was trying to use a Java API method instead of writing my own implementation which is why I was trying to use FileNameExtensionFilter. I have many FileChoosers in my application and have used FileNameExtensionFilters for that and I mistakenly assumed that it was also extending java.io.FileFilter. Here's something I quickly just made and it should perform far better than File.getName().endsWith(\".xxxx\");Here's an example for various images formats.With java lambdas (available since java 8) you can simply convert  to  in one line."},
{"body": "I'm having trouble fully understanding the role that the  fulfils in Streams  method. For example, the following code doesnt compile : Compile error says : \n      but this code does compile :I understand that the combiner method is used in parallel streams - so in my example it is adding together two intermediate accumulated ints. But I dont understand why the first example doesnt compile without the combiner or how the combiner is solving the conversion of string to int since it is just adding together two ints.Can anyone shed light on this? The two and three argument versions of  which you tried to use don't accept the same type for the .The two argument  is  :In your case, T is String, so  should accept two String arguments and return a String. But you pass to it an int and a String, which results in the compilation error you got - . Actually, I think passing 0 as the identity value is also wrong here, since a String is expected (T).Also note that this version of reduce processes a stream of Ts and returns a T, so you can't use it to reduce a stream of String to an int.The three argument  is  :In your case U is Integer and T is String, so this method will reduce a stream of String to an Integer.For the  accumulator you can pass parameters of two different types (U and ? super T), which in your case are Integer and String. In addition, the identity value U accepts an Integer in your case, so passing it 0 is fine.Another way to achieve what you want :Here the type of the stream matches the return type of , so you can use the two parameter version of .Of course you don't have to use  at all : described the differences between the two-arg and three-arg versions of  in that the former reduces  to  whereas the latter reduces  to . However, it didn't actually explain the need for the additional combiner function when reducing  to .One of the design principles of the Streams API is that the API shouldn't differ between sequential and parallel streams, or put another way, a particular API shouldn't prevent a stream from running correctly either sequentially or in parallel. If your lambdas have the right properties (associative, non-interfering, etc.) a stream run sequentially or in parallel should give the same results.Let's first consider the two-arg version of reduction:The sequential implementation is straightforward. The identity value  is \"accumulated\" with the zeroth stream element to give a result. This result is accumulated with the first stream element to give another result, which in turn is accumulated with the second stream element, and so forth. After the last element is accumulated, the final result is returned.The parallel implementation starts off by splitting the stream into segments. Each segment is processed by its own thread in the sequential fashion I described above. Now, if we have N threads, we have N intermediate results. These need to be reduced down to one result. Since each intermediate result is of type T, and we have several, we can use the same accumulator function to reduce those N intermediate results down to a single result.Now let's consider a hypothetical two-arg reduction operation that reduces  to . In other languages this is called a \"fold\" or \"fold-left\" operation so that's what I'll call it here. Note this doesn't exist in Java.(Note that the identity value  is of type U.)The sequential version of  is just like the sequential version of  except that the intermediate values are of type U instead of type T. But it's otherwise the same. (A hypothetical  operation would be similar except that the operations would be performed right-to-left instead of left-to-right.)Now consider the parallel version of . Let's start off by splitting the stream into segments. We can then have each of the N threads reduce the T values in its segment into N intermediate values of type U. Now what? How do we get from N values of type U down to a single result of type U?What's missing is another function that  the multiple intermediate results of type U into a single result of type U. If we have a function that combines two U values into one, that's sufficient to reduce any number of values down to one -- just like the original reduction above. Thus, the reduction operation that gives a result of a different type needs two functions:Or, using Java syntax:In summary, to do parallel reduction to a different result type, we need two functions: one that  T elements to intermediate U values, and a second that  the intermediate U values into a single U result. If we aren't switching types, it turns out that the accumulator function is the same as the combiner function. That's why reduction to the same type has only the accumulator function and reduction to a different type requires separate accumulator and combiner functions.Finally, Java doesn't provide  and  operations because they imply a particular ordering of operations that is inherently sequential. This clashes with the design principle stated above of providing APIs that support sequential and parallel operation equally.Since I like doodles and arrows to clarify concepts... let's start!Suppose having 4 strings: your goal is to concatenate such strings into one. You basically start with a type and finish with the same type.You can achieve this withand this helps you to visualize what's happening:The accumulator function converts, step by step, the elements in your (red) stream to the final reduced (green) value. The accumulator function simply transforms a  object into another .Suppose having the same 4 strings: your new goal is to sum their lengths, and you want to parallelize your stream.What you need is something like this:and this is a scheme of what's happeningHere the accumulator function (a ) allows you to transform your  data to an  data. Being the stream parallel, it's splitted in two (red) parts, each of which is elaborated independently from eachother and produces just as many partial (orange) results. Defining a combiner is needed to provide a rule for merging partial  results into the final (green)  one.What if you don't want to parallelize your stream? Well, a combiner needs to be provided anyway, but it will never be invoked, given that no partial results will be produced.There is no  version that takes two different types without a  since it can't be executed in parallel (not sure why this is a requirement). The fact that  must be associative makes this interface pretty much useless since:Produces the same results as:"},
{"body": "I just started learning Java and I'm confused about the topic of platform independence.Doesn't \"independent\" imply that Java code should run on any machine and need no special software to be installed? Yet the JVM needs to be present in the machine.For example, we need to have the Turbo C Compiler in order to compile C/C++ source code and then execute it. The machine has to have the C compiler.Could somebody please what is meant when Java is described as \"platform independent\"?Typically, the compiled code is the exact set of instructions the CPU requires to \"execute\" the program.  In Java, the compiled code is an exact set of instructions for a \"virtual CPU\" which is required to work the same on every physical machine.So, in a sense, the designers of the Java language decided that the language and the compiled code was going to be platform independent, but since the code eventually has to run on a physical platform, they opted to put all the platform dependent code in the JVM.This requirement for a JVM is in contrast to your Turbo C example.  With Turbo C, the compiler will produce platform dependent code, and there is no need for a JVM work-alike because the compiled Turbo C program can be executed by the CPU directly.With Java, the CPU executes the JVM, which is platform dependent.  This running JVM then executes the Java bytecode which is platform independent, provided that you have a JVM available for it to execute upon.  You might say that writing Java code, you don't program for the code to be executed on the physical machine, you write the code to be executed on the Java Virtual Machine.The only way that all this Java bytecode works on all Java virtual machines is that a rather strict standard has been written for how Java virtual machines work.  This means that no matter what physical platform you are using, the part where the Java bytecode interfaces with the JVM is guaranteed to work only one way.  Since all the JVMs work exactly the same, the same code works exactly the same everywhere without recompiling.  If you can't pass the tests to make sure it's the same, you're not allowed to call your virtual machine a \"Java virtual machine\".Of course, there are ways that you can break the portability of a Java program.  You could write a program that looks for files only found on one operating system (cmd.exe for example).  You could use JNI, which effectively allows you to put compiled C or C++ code into a class.  You could use conventions that only work for a certain operating system (like assuming \":\" separates directories).  But you are guaranteed to never have to recompile your program for a different machine unless you're doing something really special (like JNI).Before going into the detail,first you have to understand what is the mean of platform?\nPlatform consists of the computer hardware(mainly architecture of the microprocessor) \nand OS.\nPlatform=hardware+Operating SystemAnything that is platform indepedent can run on any operating system and hardware.Java is platform indepedent so java can run on any operating system and hardware.\nNow question is how it is platform independent?This is because of the magic of Byte Code which is OS indepedent.\nWhen java compiler compile any code then it generate the byte code not the machine native code(unlike C compiler).Now this \nbyte code need a interpreter to execute on a machine.This interpreter is JVM.So JVM read that byte code(that is machine indepedent)\namd execute it.\nDifferent JVM is designed for different OS and byte code is able to run on different OS.In case of C or C++(language that are not platform indepedent) compiler generate the .exe file that is OS depedent so when we\nrun this .exe file on another OS it will not run because this file is OS depedent so is not compatible with the another OS.Finally an intermediate OS indepedent Byte code make the java platform independent.It means the Java programmer does not (in theory) need to know machine or OS details.  These details do exist and the JVM and class libraries handle them.  Further, in sharp contrast to C, Java binaries (bytecode) can often be moved to entirely different systems without modifying or recompiling.No, it's the other way around. It's because you use the virtual machine that the Java program gets independend.The virtual machine is not independent, you have to install one that is specifically made for your type of system. The virtual machine creates an independent platform on top of the operating system.The JVM is a \"simulated machine\" that can be installed on different systems. In this way, the same Java code can run on different systems, because it relies on the JVM, not on the operational system itself.That is to say, this allows the programmer to communicate with the virtual system (JVM) and utilize its functions, instead of the specific machine and OS functions.\nSince Java only relies on JVM, it is platform independent (if the platform has JVM installed).So in short, Java is not platform independent as such, it requires a JVM-installation for all systems it should run on. However, it will run on all systems that has the JVM installed.The JVM abstracts from the concrete platform. Your program relies only upon the JVM and since the JVM is available for different platforms like Windows and Linux, your program is platform independent (but jvm depended).In c/c++ the source code(c program file) after the compilation using a compiler is directly converted to native machine code(which is understandable to particular machine on which u compiling the code). And hence the compiled code of c/c++ can not run on different OS.But in case of Java : the source file of java(.java) will be compiled using JAVAC compiler(present in JDK) which provides the Byte code(.class file) which is understandable to any JVM installed on any OS(Physical System).Here we need to have different JVM (which is platform dependent) for different operating Systems where we want to run the code, but the .class file(compiled code/Intermediate code)remains same, because it is understandable to any of the JVM installed on any OS.In c/c++ : only source code is machine independent.\nIn Java : both the source code and the compiled code is platform independent.This makes Java Platform(machine) independent.java is not platform Independent, itself is a platform,based on that platform java apps runs,but java platform itself is platform dependent(i.e java virtual machine)is a collection of programs which contains lot of files which provides various functionatiles present on a folder(i.e collections of programs on middle level format)as called . helps not to be overloaded on  where its helps to execute only the  files or java applications only by itself only.It helps to make its equalities middle level format after compliation by the java compiler then its provide the byte code (.class file)reprsentation which is not specific to  and  .\n2:jvm makes byte code to  file for proccessor to understandable and prsents memory allocation for every functions after recieving frm byte code.\n3:jvm also releases memory alocation from ram after control makes finishes thier execution .Java is not platform independent in that it runs on the JVM. Having said that, you gain platform independence via programming against a single abstract machine that has concrete realizations on most common OS platforms (and some embedded appliances).A related idea is the hardware abstraction layer present in many operating systems that allows the same OS to run on disparate hardware.In you original question, Turbo C is analagous to the javac program, and the JVM is the OS/HAL.With Java, you can compile source code on Windows and the  (bytecode to be precise) can be executed (interpreted) on any platform running a JVM. So yes you need a JVM but the JVM can run any compiled code, the compiled code is . In other words, you have both portability of source code and portability of compiled code.The machine doesn't have to have a C compiler, the machine has to use a platform specific binary. With C or C++, the  is specific to each architecture, it is . In other words, with C / C++ you have portability of source code (with some discipline) but not portability of compiled code: you need to recompile for each architecture into platform specific binaries.JVM will be platform dependent.\nBut whatever it will generate that will be platform independent. [which we called as bytecode or simply you can say...the class file]. for that why Java is called Platform independent.\nyou can run the same class file on Mac as well on Windows but it will require JRE. JVM is os dependent.\nfor every os JVM different.\".class\" is same for all JVMs.\nso, every JVM understand that \".class\" file data.windows dependent JVM give windows dependent instruction to windows\nlinux dependent JVM give linux dependent instruction to linux.that's like it for other operating systems.\nso,java runs on any operating system.that's why java is os independent.Java is platform-independent as it has JVM(Java virtual machine). Let us illustrate it with a real life example. Let's assume you are free to your family members. But why? Because you know them well and they know you as well. But, you are not free to my family members. Because you don't know them and they don't know you either. But, if I'm your friend and when I can introduce you to my family members, hence you will be able to talk to them freely.In a similar way, if you are a code and I am a JVM. Also, your family is windows platform and mine is the Linux platform. In the case you were a C or other platform-dependent languages, you only know your family members and vice versa. That's why only the platform on which you were written knows that Code and will support it. But if you are a JAVA code and when you come to my family viz. the Linux platform and if there you find me, JVM, then I can introduce you to my family, the Linux platform and you will be able to interact with it.For platform-dependent languages, there isn't any friend like JVM available to them to introduce themselves to any platform family. That is how Java is platform-independent. :)bytecode is not plateform independent, but its JVM that makes bytecode independent. Bytecode is not the matchine code. bytecodes are compact numeric codes, constants, and references (normally numeric addresses) which encode the result of parsing and semantic analysis of things like type, scope, and nesting depths of program objects. They therefore allow much better performance than direct interpretation of source code. bytecode needs to be interpreted before execution which is always done by JVM interpreter.Just a side note to the discussion about JVM and JIT Compilation.\nThis is the same principle as with C# and the CLR and to some extent in Python, and when somebody says that the code runs \"directly on hardware\" that is actually true in that instructions that is already compiled will be able to take advantage of optimization on the machine/cpu it's being run on. So even if the initial compilation of a module is rather slow, the next time this module is run, the code being executed runs at native speed and thus runs directly on hardware so to say.Java is platform independent in aspect of java developer,but this is not the case for the end-user, who need to have platform dependent JVM to run java code. Basically, when java code is compiled, a bytecode is generated which is typically platform independent. Thus, the developer has to have write a single code for entire platform series. But, this benefit comes with a headache for end-user who need to install JVM in order to run this compiled code. This JVM is differnt for every platform. Thus, dependency comes into effect only for end-user. \u2013 compiler that converts source code to byte code. \n- interpreter that converts byte code to machine language code. As we know java is both  based language. Once the java code also known as source code is compiled, it gets converted to native code known as BYTE CODE which is portable & can be easily executed on all operating systems. Byte code generated is basically represented in . This format is same on every platform be it Solaris work station or Macintosh, windows or Linux. After compilation, the interpreter reads the generated byte code & translates it according to the host machine. . Hope it helps!!!When we compile C source data, it generate native code which can be understood by current operating system.\nWhen we move this source code to the other operating system, it can't be understood by operating system because of native code that means representation is change from O.S to O.S.\nSo C or C++ are platform dependent .Now in case of java, after compilation we get byte code instead of native code. When we will run the byte code,\nit is converted into native code with the help of JVM and then it will be executed.So Java is platform independent and C or C++ is not platform independent.well good question but when the source code is changed into intermediate native byte code by a compiler in which it converts the program into the byte code by giving the errors after the whole checking at once (if found) and then the program needs a interpreter which would check the program line by line and directly change it into machine code or object code and each operating system by default cannot have an java interpreter because of some security reasons so you need to have jvm at any cost to run it in that different O.S platform independence as you said here means that the program can be run in any os like unix, mac, linux, windows, etc but this does not mean that each and every os will be able to run the codes without a jvm which saysspecification, implementation, and instance , if i advance then by changing the configuration of your pc so that you can have a class loader that can open even the byte code then also you can execute java byte code, applets, etc.\n-by nimish :) best of luckHow this is happening ?Ans: JVM have capability to read  and Response In Accordance with the underlying OS As the JVM is in Sync with OS.So we find, we need JVM with Sync with Platform.But the main thing is that the programmer dont have to know specific knowledge of the Platform and program his application keeping one specific platform in mind. This Flexibility of write Program in Java --- compile to  and run on any Machine (Yes need to have Platform DEPENDENT JVM to execute it) makes Java Platform Independent. Java doesn't directly run on anything. It needs to be converted to bytecode by a JVM.Because JVMs exist for all major platforms, this makes Java platform-independent THROUGH the JVM."},
{"body": "While developing a camera app I've encountered an exception that only happened when I switch to other app ( for my app).I did some research and found out that I need to addas a workaround for Android's camera stackmy  now looks like this:and my :and finally my  method:any ideas on how to fix this?I've got the same problem.  didn't help. In my activity I've added this to :and it works now.@ookami.kb solution worked for me too, as well as @srunni commented.I removed onDestroy method too.The docs clearly say that  releases all camera resources. After this call camera reference can not be used any more.If you want to use camera again you have to acquire it via a  method.It's all described in the .To Resume correctly, you need to do this:And also just to remind that in oncreate() do nothing except defining FrameLayout preview and Button captureButton.And re initialize the camera in on Resume function.Adding to okambi's answer.This is the function messing everything up when you resume:The try{} is not catching the exception being thrown. Namely that mCamera doesn't exist, and then when it tries to call setPreviewDisplay(holder), there is a crash.So by removing the callback, this surfaceCreated doesn't get called and avoids the crash. This is VERY POORLY DOCUMENTED by Google.I faced same issue, i fixed it by\n- Adding  in  method of  class.and\n- Adding in  method of my CameraActivity.If you got:I agree with @ookami.kb -  is not enough, behind it also add this:I have put between.and and it worked for me."},
{"body": "I've been wondering what the best (i.e. cleanest/safest/most efficient) way of handling multiple constructors in Java is? Especially when in one or more constructors not all fields are specified:What should I do when fields are not specified? I've so far been using default values in the class so that a field is never null, but is that a \"good\" way of doing things?A slightly simplified answer:Consider using the Builder pattern. It allows for you to set default values on your parameters and initialize in a clear and concise way. For example:Edit: It also removes the need for multiple constructors with different signatures and is way more readable.You need to specify what are the class invariants, i.e. properties which will always be true for an instance of the class (for example, the title of a book will never be null, or the size of a dog will always be > 0).These invariants should be established during construction, and be preserved along the lifetime of the object, which means that methods shall not break the invariants. The constructors can set these invariants either by having compulsory arguments, or by setting default values:However, the choice of these invariants highly depends on the class you're writing, how you'll use it, etc., so there's no definitive answer to your question. You should always construct a valid and legitimate object; and if you can't using constructor parms, you should use a builder object to create one, only releasing the object from the builder when the object is complete.On the question of constructor use: I always try to have one base constructor that all others defer to, chaining through with \"omitted\" parameters to the next logical constructor and ending at the base constructor.  So:If this is not possible, then I try to have an private init() method that all constructors defer to.And keep the number of constructors and parameters small - a max of 5 of each as a guideline.Some general constructor tips:The overall flow ends up being:For a nice example of evil, try figuring out what the following will print, then run itI'll add comments describing why the above works as it does... Some of it may be obvious; some is not...Another consideration, if a field is required or has a limited range, perform the check in the constructor:I would do the following:I am making the assumption here that:1) the title will never change (hence title is final)\n2) the isbn will never change (hence isbn is final)\n3) that it is not valid to have a book without both a title and an isbn. Consider a Student class:There a Student must be created with an id, a first name, and a last name.  The student ID can never change, but a persons last and first name can change (get married, changes name due to losing a bet, etc...).When deciding what constrructors to have you really need to think about what makes sense to have.  All to often people add set/get methods because they are taught to - but very often it is a bad idea. Immutable classes are much better to have (that is classes with final variables) over mutable ones.  This book:  (Effective Java) has a good discussion on immutability.  Look at items 12 and 13.Several people have recommended adding a null check.  Sometimes that's the right thing to do, but not always.  Check out this excellent article showing why you'd skip it."},
{"body": "I have the following hashmap in java:How should I go about sorting the hashmap such that the Alphabet, followed by the numerical figures are taken into account?The resulting hashmap should look like this:Appreciate the help!Use sorted :It will automatically put entries sorted by keys. I think natural  ordering will be fine in your case.Note that  due to lookup optimizations does not preserve order.Use a TreeMap with a custom comparator.As you add new elements, they will be automatically sorted.In your case, it might not even be necessary to implement a comparator because String ordering might be sufficient. But if you want to implement special cases, like lower case alphas appear before upper case, or treat the numbers a certain way, use the comparator. is your best bet for these kind of sorting (Natural).  naturally sorts according to the keys. does not preserve insertion order nor does it sort the map.  keeps the insertion order but doesn't sort the map automatically. Only  in the  interface sorts the map according to natural order (Numerals first, upper-case alphabet second, lower-case alphabet last).Use a , although having a map \"look like that\" is a bit nebulous--you could also just sort the keys based on your criteria and iterate over the map, retrieving each object.Just use a . It implements the  interface, and thus automatically sorts the keys it contains. Your keys can just be sorted alphabetically to get the desired result, so you don't even need to provide a comparator.HashMaps are never sorted. The only thing you coulkd do with a HashMap is get all the keys, and store them in a sorted set or in a List and sort the List.Using the  you can sort the Map."},
{"body": "I have noticed the following code is redirecting the User to a URL inside the project, whereas, the following is redirecting properly as intended, but requires http:// or https://I want the redirect to always redirect to the URL specified, whether it has a valid protocol in it or not and do not want to redirect to a view. How can I do that?Thanks,You can do it with two ways. First:Second:Looking into the actual implementation of  and  the redirect will always be contextRelative if your redirect target starts with /. So also sending a //yahoo.com/path/to/resource wouldn't help to get a protocol relative redirect.So to achieve what you are trying you could do something like:You can use the . Copied from the :Example:You can also use a , e.g.And of course, return  as mentioned by others.Another way to do it is just to use sendRedirect method:For external url  you have to use \"\" as the redirect url.This is explained in the  of Spring reference documentation. will redirect relative to the current Servlet context, while a name such as will redirect to an absolute URLDid you try  where you can provide the contextRelative parameter?For me works fine:In short  or  will lend you to .where as  will lend you  ie for ex- "},
{"body": "I've mapped the Spring MVC dispatcher as a global front controller servlet on .However, this mapping stops the access to static files like CSS, JS, images etc which are all in the  folder.How can I access them anyway?I've run into this also and never found a great solution.  I ended up mapping my servlet one level higher in the URL hierarchy:And now everything at the base context (and in your /res directory) can be served up by your container.Map the controller servlet on a more specific  like , put the static content in a specific folder like  and create a  listening on  which transparently continues the chain for any static content and dispatches requests to the controller servlet for other content.In a nutshell:with the following in filter's :No, this does not end up with  in browser address bar. It's fully transparent. You can if necessary make  and/or  an  of the filter.With  and higher you can useAs seen in .If you use Tomcat, you can map resources to the default servlet:and access your resources with url http://{context path}/static/res/...Also works with Jetty, not sure about other servlet containers.What you do is add a welcome file in your web.xmlAnd then add this to your servlet mappings so that when someone goes to the root of your application, they get sent to index.html internally and then the mapping will internally send them to the servlet you map it toEnd result: You visit /Application, but you are presented with /Application/MainActions servlet without disrupting any other root requests.Get it? So your app still sits at a sub url, but automatically gets presented when the user goes to the root of your site. This allows you to have the /images/bob.img still go to the regular place, but '/' is your app.Serving static content with appropriate suffix in multiple servlet-mapping definitions solved the security issue which is mentioned in one of the comments in one of the answers posted. Quoted below:which helped me a lot.\nAnd here is how I solved it:As of 3.0.4 you should be able to use  in combination with  as described in the spring documentation to achieve this.'Static' files in App Engine aren't directly accessible by your app. You either need to upload them twice, or serve the static files yourself, rather than using a static handler.The reason for the collision seems to be because, by default, the context root, \"/\", is to be handled by org.apache.catalina.servlets.DefaultServlet. This servlet is intended to handle requests for static resources.If you decide to bump it out of the way with your own servlet, with the intent of handling dynamic requests, that top-level servlet must also carry out any tasks accomplished by catalina's original \"DefaultServlet\" handler.If you read through the tomcat docs, they make mention that True Apache (httpd) is better than Apache Tomcat for handling static content, since it is purpose built to do just that. My guess is because Tomcat by default uses org.apache.catalina.servlets.DefaultServlet to handle static requests. Since it's all wrapped up in a JVM, and Tomcat is intended to as a Servlet/JSP container, they probably didn't write that class as a super-optimized static content handler. It's there. It gets the job done. Good enough. But that's the thing that handles static content and it lives at \"/\". So if you put anything else there, and that thing doesn't handle static requests, WHOOPS, there goes your static resources. I've been searching high and low for the same answer and the answer I'm getting everywhere is \"if you don't want it to do that, don't do that\".So long story short, your configuration is displacing the default static resource handler with something that isn't a static resource handler at all. You'll need to try a different configuration to get the results you're looking for (as will I).The best way to handle this is using some kind of URL re-writing.  In this way, you can have clean restful URLs, and NOT with any extensions i.e abc.com/welcom/register as opposed to abc.com/welcome/resister.htmlI use  which is pretty cool.It's got instructions on how to set up your web app.I have set it up with my Spring MVC web app. Of course, everything was fine until I wanted to use annotations for Spring 3 validations like  or  for domain objects.  When I add the Spring mvc directives:.. it breaks the good ol Tuckey code. Apparently,  replaces Tuckey, which I'm still trying to solve. Add the folders which you don't want to trigger servlet processing to the  section of your appengine-web.xml file.I just did this and looks like things are starting to work ok.  Here's my structure://pages/<.jsp files>/cssI added \"/pages/**\" and \"/css/**\" to the  section and I can now forward to a .jsp file from inside a servlet doGet without causing an infinite loop.After trying the filter approach without success (it did for some reason not enter the doFilter() function) I changed my setup a bit and found a very simple solution for the root serving problem:Instead of serving \" / * \"\nin my main Servlet, I now only listen to dedicated language prefixes\n\"EN\", \"EN/ *\", \"DE\", \"DE/ *\"Static content gets served by the default Servlet and the empty root requests go to the index.jsp which calls up my main Servlet with the default language:I found that using in the spring MVC servlet bean definition file works for me. It passes any request that isn't handled by a registered MVC controller on to the container's original default handler, which should serve it as static content.  Just make sure you have no controller registered that handles everything, and it should work just fine.  Not sure why @logixplayer suggests URL rewriting; you can achieve the effect he's looking for just adequately using Spring MVC alone.I'd recommend trying to use a Filter instead of a default servlet whenever possible.Other two possibilities:Write a FileServlet yourself. You'll find plenty examples, it should just open the file by URL and write its contents into output stream. Then, use it to serve static file request.Instantiate a FileServlet class used by Google App Engine and call service(request, response) on that FileServlet when you need to serve the static file at a given URL.You can map /res/* to YourFileServlet or whatever to exclude it from DispatcherServlets' handling, or call it directly from DispatcherServlet.And, I have to ask, what does Spring documentation say about this collision? I've never used it.I found a simpler solution with a dummy index file.Create a Servlet (or use the one you wanted to respond to \"/\") which maps to \"/index.html\"\n(Solutions mentioned here use the mapping via XML, I used the 3.0 version with annotation @WebServlet)\nThen create a static (empty) file at the root of the static content named \"index.html\"I was using Jetty, and what happened was that the server recognized the file instead of listing the directory but when asked for the resource, my Servlet took control instead. All other static content remained unaffected.In Embedded Jetty I managed to achieve something similar by adding a mapping for the \"css\" directory in web.xml. Explicitly telling it to use DefaultServlet:and if you want to use annotation based configuration use below code"},
{"body": "Why are empty Strings valid and empty chars are not ?\nI would have thought an empty String is not a string but just a placeholder. The same for a char, but creating an empty char does not even compile. What im wondering is why the following occurs - \nCompiles - Does not compile -Because  represents a single character, which  isn't. A String can contain zero or more characters, but a character cannot be anything other than a single character.Because a string literal represents a String which may consist of  characters, but a (valid) character literal represents  character.Yes.  In theory it could have been defined that way.  But trust me, if you think through  the issues (e.g. how you'd represent an empty char, how an application would deal with it, etc) you will conclude that the there are few benefits, and significant downsides.Anyway, doing this  so that there was a syntactic consistency between String and char literals would be totally crazy.  You don't break a language's performance and/or semantics so that the syntax looks nice.One comments on the accepted answer proposes that  should mean the same as .  But the counter argument to this is that  does not mean no characters.  It means one character whose value is zero.  So if   means one character it is misleading.  And since there is already a way of denoting this ...  ... a second way of denoting it is redundant.If some piece of new language syntax is both misleading and redundant, it is hard to justify adding it.In respose to SoloBold's comment, while it would be possible to define a character type to do that, it would require more space.  At least 1 bit, and more likely 16 bits to avoid awkward memory alignment problems.  A 32-bit  type would not be acceptable ... even though it does solve other problems. is an empty array of characters. is simply not a character.An empty string is like a container that holds nothing. A  must have a value and without exactly one character there is no where to derive that value from.You could see a String as a sequence of characters. Having an empty sequence with no characters makes sense, having a character that isn't a character doesn't. Also never use , just  is enough.Mathematically, an alphabet A is a set of symbols, suppose alphabet A = {a, b, c, d, ..., z}. A string L is a sequence of zero or more characters from an alphabet, i.e. L = A*. An empty string is simply a sequence of zero characters; while an \"empty chars\" is not a member of the alphabet.You can't have an empty character, it is illogical.char is a primitive type, so you need to give a value (whatever it is).\nIf you want to leave you variable as \"undefined\", you can use the wrapper object:In this way you variable c is not containing (yet) any value. But then be sure to add a value! :)By the way, you can use the object wrapper for primitive  type:This can be useful when you want a field to be \"either a character or nothing\".Probably because char is a primitive type, and String is an object. \nboolean, int etc. also don\u00b4t allow \"empty\" values.A char is a single character, that is a letter, a digit, a punctuation mark, a tab, a space or something similar. String is a set of characters which could be 0 or more. so empty strings are valid- which dont have any character. BUt char represents the primitive type of Character which has to be one valid character, which '' is not.i think you should try to know the difference between blank character/string and empty character/string. blank char/string refers to character/string that has some content, such as ' '(SPACE), '\\t' and so on, while empty ones doesn't have any content, and can be seen as an empty container."},
{"body": "I have the following Layout which does not work:This is a common problem.  Try using the following:.............. the scrollHorizontally is the \"special sauce\" that makes it work.This will also make a single line with ellipsiseThe way it worked for me on multiple devices / APIs was programmatically like this (where tv is your TextView):android:ellipsize=\"end\"\nandroid:singleLine=\"true\"android:ellipsize=\"end\"\nandroid:maxLines=\"1\"When you use maxlines = 1 it will some time truncate most of the characters."},
{"body": "How to get the double value that is only two digit after decimal point.for example if this code generating .But I want only .So what shoud I do?Use . - -How about ?Here i will demonstrate you that how to make your decimal no shorter, here i am shorter it it to 4 value after decimal.I think the best and simplest solution is (KISS):First thing that should pop in a developer head while formatting a number into char sequence should be care of such details like do it will be possible to reverse the operation.And other aspect is providing proper result. So you want to  truncate the number or round it. So before you start you should ask your self, am i interested on the value or not. To achieve your goal you have multiple options but most of them refer to  and , but i just suggest to look in ."},
{"body": "I want the message text within my dialog box to be center aligned.Create your own TextView object and then supply it to popup builder as View:You can control all other text parameters (style, color, size ...). To control margins you may programatically create LinearLayout, set LayoutParams, and then put TextView into it.Of course, you can always set the gravity of the original text view. This allows you to not have to worry about formatting and padding. For exampleBuilding off of Chase's answer, here's how to also center the title.  I think this is the easiest way.  Why android doesn't center by default or make it a simple constructor param is beyond me.we can use as like.try this in your TextView:Just use that method and your dialog title and message will appear at center:public static void openDialog(Context context, String message) {you can try this code"},
{"body": "This is related to a previous question that I asked here earlierI am trying to parse the same JSON, but now I have changed my classes a little bit.My class now looks like:This code throws an exception, The exception is understandable, because as per the solution to my previous question, GSON is expecting the Enum objects to be actually be created as  But since this is syntactically impossible, what are the recommended solutions, workarounds?From :Following is one such approach.I want to expand a bit NAZIK/user2724653 answer (for my case). Here is a Java code:in the json file you have just a field , where N=0,1,2,3 - depend on the Status values. So that's all,  works fine with the values for the nested  class. In my case i've parsed a list of  from  array:Use annotation :With GSON version 2.2.2 enum will be marshalled and unmarshalled easily."},
{"body": "I have milliseconds. \nI need it to be converted to date format of example:How to achieve it?any help is really appreciated.Just Try this Sample code:-I hope this help...Convert the  value to  instance and pass it to the choosen formatter.Call this functiontry this code might help, modify it suit your needsi finally find normal code that works for meShort and effective:You can construct java.util.Date on milliseconds. And then converted it to string with java.text.DateFormat."},
{"body": "I'm trying to send an email in Java but when I read the body of the email in Outlook, it's gotten rid of all my linebreaks. I'm putting \\n at the ends of the lines but is there something special I need to do other than that? The receivers are always going to be using Outlook. I found a page on microsoft.com that says there's a 'Remove line breaks' \"feature\" in Outlook so does this mean there's no solution to get around that other than un-checking that setting?ThanksYou need to use  as a solution.I've just been fighting with this today. Let's call the behavior of removing the extra line breaks \"continuation.\" A little experimenting finds the following behavior:Please note that I tried all of this with Outlook 2007. YMMV.\nSo if possible, end all bullet items with a sentence-terminating punctuation mark, a tab, or even three spaces.You can force a line break in outlook when attaching one (or two?) tab characters (\\t) just before the line break (CRLF).Example:It seems to work on Outlook 2010. Please test if this works on other versions.See also Microsoft Outlook 2002 and above removes \"extra line breaks\" from text messages by default .  That is, Outlook seems to simply ignore line feed and/or carriage return sequences in text messages, running all of the lines together.This can cause problems if you're trying to write code that will automatically generate an email message to be read by someone using Outlook.For example, suppose you want to supply separate pieces of information each on separate lines for clarity, like this:Transaction needs attention!\nPostedDate: 1/30/2009\nAmount: $12,222.06\nTransID: 8gk288g229g2kg89\nPostalCode: 91543Your Outlook recipient will see the information all smashed together, as follows:Transaction needs attention! PostedDate: 1/30/2009 Amount: $12,222.06 TransID: 8gk288g229g2kg89 ZipCode: 91543There doesn't seem to be an easy solution.  Alternatives are:I had the same issue, and found a solution. Try this:   to add a line break.I had been struggling with all of the above solutions and nothing helped here, because I used a String variable (plain text from a JTextPane) in combination with \"text/html\" formatting in my e-mail library.So, the solution to this problem is to use \"text/plain\", instead of \"text/html\" and no need to replace return characters at all:Put the text in  Tags and outlook will format and display the text correctly. i defined it in CSS inline in HTML Body like: CSS:i defined the font-family to have to font set. HTML: Because it is a query, only percent escaped characters work, means %0A gives you a line break. For example,I have used  html line break  instead of \"\\n\" . It worked fine.The trick is to use the  functionality from js:RESULT:You need to send HTML emails.   With s in the email, you will always have your line breaks.In my application, I was trying to send an email whose message body was typed by the user in text area. When mail was send, outlook automatically removed line break entered by user.e.g if user entered\nYadav\nMaheshoutlook displayed it as \nYadavMahesh I changed the line break character \"\\r\\n\" with \"\\par \" ( remember to hit space at the end of RTF code \"\\par\" )and line breaks are restrored.Cheers,\nMaheshIf you can add in a '.' (dot) character at the end of each line, this seems to prevent Outlook ruining text formatting.Try this:Regards,\nMohammad Rasool JaveedTry  instead of . I think @Robert Wilkinson had it right. . Memory just isn't what it used to be.The  largely works for us, but Outlook does sometimes take it upon itself to remove the line breaks as you say.I have a good solution that I tried it, it is just add the Char(13) at end of line like the following example:if the message is text/plain using, \\r\\n should work; \nif the message type is text\\html, use  must be helpful for you. try \"%0A\" instead of \"\\n\". The real source is You need to add \"%0A\" where ever you need a new line in your code. In your case I also had this issue with plain/text mail type. Earlier, I used \"\\n\\n\" but there was two line breaks. Then, I used \"\\t\\n\" and it worked. I was using  in java to append content.\nThe content got printed in next line in Outlook 2010 mail.I also had this issue with plain/text mail type.Form Feed   worked for me. For Outlook 2010 and later versions, use  rather than using \\r\\n.Sometimes you have to enter \\r\\n twice to force outlook to do the break.This will add one empty line but all the lines will have break.if work need to be done with formatted text with out html encoding.\nit can be easy achieved with following scenario that  and using  html element to keep formatting.Adding \"\\t\\r\\n\"  ( \\t for TAB)   instead of \"\\r\\n\"  worked for me on Outlook 2010  .  Note : adding 3 spaces at end of each line also do same thing but that looks like a programming hack! will not work until you set body type as text."},
{"body": "Is there a way to format a decimal as following:If it is a round number, omit the decimal part. Otherwise format with two decimal places.I doubt it. The problem is that 100 is never 100 if it's a float, it's normally 99.9999999999 or 100.0000001 or something like that. If you do want to format it that way, you have to define an epsilon, that is, a maximum distance from an integer number, and use integer formatting if the difference is smaller, and a float otherwise.Something like this would do the trick:I'd recommend using the java.text package: This has the added benefit of being locale specific.But, if you must, truncate the String you get back if it's a whole dollar: orOutputIf you don't want to use sign use this method I did not find any good solution after google search, just post my solution for other to reference. use  to format money.Yes.  You can use . You can use a formatting string like \"%10.2f\"I'm using this one (using StringUtils from commons-lang):You must only take care of the locale and the corresponding String to chop. I think this is simple and clear for printing a currency:output: $12,345.68And one of possible solutions for the question:Output:100100.10you should do something like this:which prints:100100,10I know this is an old question but...You can just do something like this and pass in the whole number and then the cents after.I agree with @duffymo that you need to use the  methods for this sort of things.  You can actually do all the formatting natively in it without doing any String compares yourself:Couple bits to point out: Whatever your logic for determining whether or not the decimals should get truncated,  should get used.If you want work on currencies, you have to use BigDecimal class. The problem is, there's no way to store some float numbers in memory (eg. you can store 5.3456, but not 5.3455), which can effects in bad calculations.There's an nice article how to cooperate with BigDecimal and currencies:Format from 1000000.2 to 1 000 000,20This post really helped me to finally get what I want. So I just wanted to contribute my code here to help others. Here is my code with some explanation.The following code:Will return:The actual jeroensFormat() method:The method displayJeroensFormat that calls the method jeroensFormat() Will have the following output:This code uses your current currency. In my case that's Holland so the formatted string for me will be different than for someone in the US.Just watch the last 3 characters of those numbers. My code has an if statement to check if the last 3 characters are equal to \",00\". To use this in the US you might have to change that to \".00\" if it doesn't work already.We will usually need to do the inverse, if your json money field is an float, it may come as 3.1 , 3.15 or just 3.In this case you may need to round it for proper display (and to be able to use a mask on an input field later):This is what I did, using an integer to represent the amount as cents instead:The problem with  is that sometimes you really want $20 to be $20, it just looks better than $20.00.If anyone finds a better way of doing this, using NumberFormat, I'm all ears."},
{"body": "I  that Unicode is permitted within Java source code not only as Unicode characters (eg.  ) but also as escaped sequences (eg.  ).The first variant makes sense to me - it allows programmers to name variables and methods in an international language of their choice. However, I don't see any practical application of the second approach.Here are a few pieces of code to illustrate usage, tested with Java SE 6 and NetBeans 6.9.1:This code will print out 3.141592653589793Explanation: \u03c0 and \\u03C0 are the same Unicode characterThis code will not print out anythingExplanation: The code above actually encodes:Which comments out the print satement.Just from my examples, I notice a number of potential problems with this language feature.First, a bad programmer could use it to secretly comment out bits of code, or create multiple ways of identifying the same variable. Perhaps there are other horrible things that can be done that I haven't thought of.Second, there seems to be a lack of support among IDEs. Neither NetBeans nor Eclipse provided the correct code highlighting for the examples. In fact, NetBeans even marked a syntax error (though compilation was not a problem).Finally, this feature is poorly documented and not commonly accepted. Why would a programmer use something in his code that other programmers will not be able to recognize and understand? In fact, I couldn't even find something about this on the .My question is this:Why does Java allow escaped Unicode sequences to be used within syntax?\nWhat are some \"pros\" of this feature that have allowed it to stay a part Java, despite its many \"cons\"?Unicode escape sequences allow you to store and transmit your source code in pure ASCII and still use the entire range of Unicode characters. This has two advantages:Both will result in exactly the same byte code and have the same power as a language feature. The only difference is in the source code.If you're concerned about a programmer  sabotaging your code's readability, this language feature is the least of your problems.That's hardly the fault of the feature or its designers. But then, I don't think it was ever intended to be used \"manually\". Ideally, the IDE would have an option to have you enter the characters normally and have them displayed normally, but automatically save them as Unicode escape sequences. There may even already be plugins or configuration options that makes the IDEs behave that way.But in general, this feature seems to be very rarely used and probably therefore badly supported. But how could the people who designed Java around 1993 have known that?The nice thing about the  encoding is that it is much less likely to be munged by a text editor with the wrong encoding settings.  For example a bug in my software was caused by the accidental transformation from UTF-8  into a MacRoman  by a misconfigured text editor.  By specifying the Unicode codepoint, it's completely unambiguous what you mean.The \\uXXXX syntax allows Unicode characters to be represented unambiguously in a file with an encoding not capable of expressing them directly, or if you want a representation guaranteed to be usable even in the lowest common denominator, namely an 7-bit ASCII encoding.You  represent all your characters with \\uXXXX, even spaces and letters, but there is rarely a need to.First, thank you for the question. I think it is very interesting.\nSecond, the reason is that the java source file is a text that can use itself various charsets. For example the default charset in Eclipse is Cp1255. This endoding does not support characters like \u03c0. I think that they thought about programmers that have to work on systems that do not support unicode and wanted to allow these programmers to create unicode enabled software. This was the reason to support \\u notation. "},
{"body": "I am using a linkedHashMap to guarantee order when someone tries to access it. However, when it comes time to iterate over it, does using entrySet() to return key/value pairs guarantee order as well? No changes will be made while iterating. Also, are there any adverse effects from iterating through the map by iterating through its keys and calling get? According to the , yes.As for the edit, no, it should work just fine. But the entry set is somewhat faster since it avoids the overhead of looking up every key in the map during iteration.If you're sure no changes will be made during the iteration, then proper ordering with  is guaranteed, as stated in the ."},
{"body": "In java, if a class implements Serializable but is abstract, should it have a serialVersionUID long declared, or do the subclasses only require that?In this case it is indeed the intention that all the sub classes deal with serialization as the purpose of the type is to be used in RMI calls.The serialVersionUID is provided to determine compatibility between a deseralized object and the current version of the class.  (Of course, it does generate a compiler warning, which you want to get rid of, right?)It turns out james' comment is correct.  The serialVersionUID of an abstract base class  get propagated to subclasses.  In light of that, you  need the serialVersionUID in your base class.The code to test:Run the main in Sub once to get it to create and save an object.  Then change the serialVersionUID in the Base class, comment out the lines in main that save the object (so it doesn't save it again, you just want to load the old one), and run it again.  This will result in an exceptionYes, in general, for the same reason that any other class needs a serial id - to avoid one being generated for it.  Basically any class (not interface) that implements serializable should define serial version id or you risk de-serialization errors when the same .class compile is not in the server and client JVMs.There are other options if you are trying to do something fancy.  I'm not sure what you mean by \"it is the intention of the sub classes...\".  Are you going to write custom serialization methods (eg. writeObject, readObject)?  If so there are other options for dealing with a super class.see:\nHTH TomActually, pointing out of Tom's link if missing  is actually calculated by serialization runtime i.e. not during compilationThis makes things even more complicated having different versions of JRE.Conceptually, the serialized data look like this:So when you deserialize, mismatch in version in any of the classes in the hierarchy causes the deserialization to fail. Nothing is stored for interfaces, so there's no need to specify version for them. yes, you do need to provide  in the base abstract class as well. Even if it does not have fields ( are stored even if there are no fields).Also note the following:In simple words: you can reorder fields, add and remove them, even change the class hierarchy. You should not rename fields or classes (it won't fail, but the values won't be deserialized). You cannot change type of fields with primitive type, and you can change reference type fields provided the new type is assignable from all values.Note: if the base class doesn't implement Serializable and only the subclass does, then fields from the base class would behave as ."},
{"body": "I'm about to build an Android application that will use a RESTful Web Service. I don't want to write the REST client by myself, as I want it to be as effective and stable as possible (this is the first time I'm using REST).Are there any (free) frameworks or utilities avaibale for Android/Java that I can use in my project? is an excellent REST framework and has an Android edition.Any HTTP Client library should be perfectly adequate to interact RESTfully with a web API.   E.g. try out Spring Android - is has very handy class RestTemplate.I'm also looking for a SMALL solution for rest client on Android. After a quick comparison, I found:Please correct me if any miss.check out Resting - \"Lightweight Java component to consume REST service and transform response into objects\"i haven't used it myself, but i plan to. to go along with it, i'm searching for example source code to implement the best practices described in this google IO session. "},
{"body": "First time I hear about markers when read:I check available methods for  object:and found interfaces:More in-depth info I get from:but still confused... Note that I ask , not  to use them, so this is not a duplicate of: Seems that when you use markers  you also required to write custom Java code instead doing configuration in  or  files... From This is a rehashed version  to the question \"\".Markers can be used to  or mark a  log statement. What you do with these colors, i.e. markers, is entirely up to you. However, two patterns seem to be common (the first more common than the second) for marker usage.Before the advent of Markers, to achieve similar behavior, you had the option 1) using custom levels 2) use modified logger names. SLF4J API currently does not support custom levels. As for option 2, suffixing (or prefixing) logger names is workable if a one or two loggers need to be modified. The approach becomes unpractical as soon 3 or more loggers need to be \"sub-classed\" because the associated configuration files become unmanageable."},
{"body": "Our company is using eclipse since several years now (we are using WTP since release 0.7)I am currently evaluating  which should replace eclipse 3.4.2 with WTP 3.0.4 as being our main IDE.And I have to say that once again I am quite disappointed in concerns of performance:\n\nIn fact I am really wondering why WTP gets slower with each release.One of our applications (dynamic web project) contain about . We only need basic WTP functionality for developing jsps, xmls and xsd. We don't need high sophistic features like  (should JPA tools really covered by a ?),  or a  in the first place.Another interesting point is that WTP seems to .\nSWT is non-reponsive for some fraction of seconds, cpu usage is very high (especially after a built took place - if you look at the system jobs, several jsp/javascript indexers are doing work for some minutes, even if all WTP build validators have been disabled), opening new files are slower, navigating through the project etc.This can be especially seen on older machines which do contains only a single core cpu.\n(e.g. have a look at the  page - last update took place in 2008).Bug reports and Newsgroup posts regarding to performance of basic features (e.g. jsp editing/validating) are often ignored or closed after some time, some examples: , , .I don't want to blame WTP.\nIn fact I believe that WTP is a good open-source project developed by a talented team.\nBut obviously the , especially in terms of performance which affects usability and user acceptance.I just want to point out that the team should focus on the things which are  in the first place and afterwards work on implementing super-duper-features.I'd like to make an update on this question to reflect the current answers and \nto sum up the current results:So this question turns a little bit into some kind of an open letter from the community to the WTP team:To respond, I'm the lead for the projects that supply the JSP, XML, and JavaScript source editing functionality in WTP.  The simple fact is that we don't spend much time on performance tests because we lack resources for doing that.  Of course we'd like to be proactive about it rather than reactive, but we tend to allocate our time to functional problems first.  We do have an adopter product running performance regression tests regularly, but I expect that tests are run on multi-core machines by now--and we haven't had any new red flags reported to us for some time.Of the 3 bugs you linked to, 2 predate the 3.0.4 version you laud and the third is either a formatting performance issue (since addressed) or one with as-you-type validation specific to XML files (the fixing of which would have triggered a memory leak in Xerces, iirc, hence us not putting it in at that time).  If you have concrete projects that you can attach to a bug and say \"doing X is slower in 3.2 by Y amount\", we'll do what we can to figure out where there's a regression.As for the indexers, they should at least  complete.  The on-disk information that is stored has changed between WTP versions, and those files need to be reprocessed so they're again included in search and (where implemented) refactoring operations.  Once the initial indexing is complete, it should act incrementally and be virtually unnoticeable.  One architectural change you may be running into is that for JSPs, the entire workspace needs to be indexed in a  workbench session for that index to be considered \"up to date\".  Shutting down Eclipse out of frustration will only prolong the impact of that reprocessing.It sounds like your company's standard install includes the entirety of WTP rather than rolling your own custom distribution.  I urge you to check the  preference page and turn off early startup of any functionality you're not interested in using.  Nothing you've mentioned interest in makes use of that facility, but there are other areas of WTP and the Platform that do.  Anything you're not interested in validating is fair game on the  preference page, as well as the setting to validate JSP fragments by default on the  /  /  preference page.We have the same problem with WTP 3.2.3 here, too. We use it in our product for several years, too but the acceptance of our developers and customers in this tool is decreasing every year because in every newer release it is slower and slower. I would like to use it if I could disable all \"advanced\" features but as you mentioned you cannot disable the indexers at all. Also you cannot stop the validator of JSP files if it is already running (you can test this if you have that many files as you have and we also have around 1000 JSP files and many tag files in our project). I also can prove that increasing the memory does not help. It only prevents crashes of the whole eclipse but it does not reduce the UI blocking internal operations of WTP.In the newest version  I got many hangs when I  from within the . The  just  about . It's not only me who has the hangs, it's all my colleagues who work on Windows have the same problem. On Linux I do not know about this problem.Also there are problems in WTP when you have no access to the internet. It seems there are request to some registries to download schemas or such things and if you do not have a connection then it just hangs and waits for the time out.  I don't know who's to blame: WTP or JBoss Tools.\nThe fact is that, as I work with GWT (minimal JSP), I went the opposite way: No WTP at all!!! I'm now using plain Eclipse for Java, and use a run configuration to deploy (programatically invoking ANT) and start the server, and I never looked back!!!\nEclipse used to take ~1.5GB and crashed several times. Now, it sits on ~800MB, and the whole environment became more stable.I have seen similar effects, here's one solution that might be suitable in some project environments...To guarantee fast and responsible Eclipse Web project environment, consider this:Result: fast & responsive Eclipse when compared to many other Eclipse installations that use Eclipse EE version with WTP stuff.Why? It might be that some Eclipse feature or plugin contains bugs or simply uses resources in a bad way and this makes Eclipse UI sluggish.Non-Java EE Eclipse is good enough even for many Java EE project environments, it all depends on your architecture and what tools you are using..Here's a quick tutorial to get started in case you wish to try Jetty Servlet Container out with Eclipse. See  . Download VaadinProjectForAnyIDE.zip, it's an Eclipse project. Just ignore that Vaadin stuff and replace HelloWorldApplication.java with your own servlet and edit web.xml accordingly.One more thing. With Eclipse EE version, you might also wish to try J2EE preview server which actually is Jetty embedded into Eclipse bundle. However, this also uses WTP mechanism.I also think the stability and performance of Eclipse/WTP is somewhat alarming. I'm using Eclipse since mid 2003 and have been trying WTP since its very first releases.At first the quality was absolute abysmal, but for a 0.x version I couldn't complain of course. While waiting for WTP to mature, I used MyEclipse, which was sort of okay but had its flaws too (and being partially based on WTP, inherited some of WTP).When MyEclipse became heavier and heavier, slower and slower and we ran into several stability issues, we switched to 'pure WTP'. All we were using was really the basic JSP/JSF editor and deployer.Since WTP doesn't do incremental deployment (at least not for the JBoss server runtime) we added the separate server runtime from JBoss tools. When we adopted Facelets, we also switched to the editor from JBoss tools.We do however run into a lot of problems we also had with MyEclipse. There are unexplainable slowdowns, but much worse are various stability problems. There are lots of awkward exceptions and crashes. A typical .log file on many different workstations I examined is chockfull of exceptions. A small selection of the last 10 exceptions in my log:1.2.3.4.5.6.7.8.9.10.Note that these are just the last 10, there are many, many more exceptions.The casual reaction would be: \" Yes, I might have a local problem, but this \"local problem\" seems widespread as many Eclipse installs I inspected seem to have this stuff in their logs.I'm also having problems with deployments like reported at the following link in various incarnations:  It may be JBoss tools specific or it may be based on the underlying WTP or even Eclipse code. I don't know, but I do know it's a nasty problem. Every WTP and JBoss tools version there is 'something' fixed, and every version a problem like that resurfaces in a slightly different form.Between the stability problems I'm able to get some work done and I love the auto completion and navigate-into features the editors offer me (which keeps me from switching to a text editor and building completely on the command line), but I sure would love some increased stability.By far the best way for speeding up my projects has been to precompile code that I am not currently using. We have about 20 projects that make up our system and when working on any specific problem I'm only touching a specific subset of those java files. Compiling most of the code that I won't be touching and throwing it into some .jar's, then using that as the source instead of including the projects has proven to speed up things by quite a bit. I imagine it will help you as well if you have 4k+ files.\nEach project just has a little build.xml that will make a jar out of it to include.As for the mind numbing slowness in the JSP editing. I have the same problems, it's just so dam slow. I don't have many more than 100 jsp files but I have the same issues as you. My solution has just been to throw money at hardware, which I must admit I enjoy doing :P.To answer the following question:\nTurning off validation and auto-building after file-saving is a good start to increase performance.I've disabled the WTP JSP editor for the reasons you mentioned above: It just needs too many resources. Some more things you should consider:WTP (3.2.3) is slow for me too. I belive I have found some ways to make it not so slow:If you need barebones Java EE then you are better off with Netbeans, if you need everything but just working you are better off with IDEA. It is as simple as that.Couldn't comment so I will just put my comment in to this answer.Have you tried upping Eclipse's memory allocation, I know it used to crash all the time when I used it on Mac OS X awhile ago. There is a config file that has the base RAM allocation in it, once I modified that file and gave it an extra 128 megabytes of memory it behaved better. Not sure if this will affect WTP, I am commenting more in regards to the core Eclipse application itself."},
{"body": "I have an Ant file that compiles my program. I want the javac task to fail if any warning was reported by the compiler. Any clue on how to do that?Use the  flag. It's not listed in the  output, but it works.I found it through  and tested on my own code (in NetBeans with Ant). The output was:Note that this is Java 6 only, though.: Example of specifying this in Ant buildfile:"},
{"body": "Each java application will run in a specific Java Virtual Machine Instance.  I am really getting confused on below aspects and Googling has confused me even more. Different articles on different sites.Yes it can.  How it is done depends on the O/S and on the web server container itself.No.  Each Java application uses an independent JVM.  Each JVM is a separate process, and that means there is no sharing of stacks, heaps, etcetera.  (Generally, the only things that might be shared are the read only segments that hold the code of the core JVM and native libraries ... in the same way that normal processes might share code segments.)The mechanism for deciding how big to make the heap if you don't specify a size depends on the JVM / platform / version you are using, and whether you using the \"client\" or \"server\" model (for Hotspot JVMs).  The heuristic doesn't take account of the number or size of other JVMs.Reference:  In practice, you would probably be better off specifying the heap size directly.Neither.  The number of JVM instances is determined by the actions of various things that can start processes; e.g. daemons scripts, command scripts, users typing commands at the command line, etcetera.  Ultimately, the OS may refuse to start any more processes if it runs out of resources, but JVMs are not treated any different to other processes.No.  The JVMs are independent processes.  They don't share any mutable state.  Garbage collection operates on each JVM independently.If your instances have to coordinate their work, you can create single main instance which would run/stop other instances.You did not explain why you need multiple JVM instances. Probably, single instance would work better. "},
{"body": "I am trying hard to get the count of unicode string and tried various options. Looks like a small problem but struck in a big way.Here I am trying to get the length of the string str1. I am getting it as 6. But actually it is 3. moving the cursor over the string \"\u0b95\u0bc1\u0bae\u0bbe\u0bb0\u0bcd\" also shows it as 3 chars. Basically I want to measure the length and print each character. like \"\u0b95\u0bc1\", \"\u0bae\u0bbe\", \"\u0bb0\u0bcd\" .PS : It is tamil language.Found a solution to your problem.Based on  I made a program that uses regex character classes to search for letters that may have optional modifiers. It splits your string into single (combined if necessary) characters and puts them into a list:where  means a Unicode letter, and  means a Unicode mark.The output of the snippet is:See  for a working DemoI now checked my regex with all valid Tamil letters taken from the tables in . I found out that with the current regex we do not capture all letters correctly (every letter in the last row in the Grantha compound table is splitted into two letters), so I refined my regex to the following solution:With this Pattern instead of the above one you should be able to split your sentence into every valid Tamil letter (as long as wikipedia's table is complete).The code I used for checking is the following one:Have a look at the  class. There is an explanation of what may be the cause of your problem. In Unicode, you can encode characters in several ways, e.g :or      You can try to use  to convert your string to the composed form and then iterate over the characters. Based on the article suggested by @halex above, try this in Java:The result I get is . If it doesn't work for all your strings, try fiddeling with other Unicode character categories in the  block.This turns out to be  ugly....\nI have debugged your string and it contains following characters (and their hex position):\u0b95  0x0b95\n\u0bc1  0x0bc1\n\u0bae   0x0bae\n\u0bbe 0x0bbe\n\u0bb0 0x0bb0\n\u0bcd 0x0bcd So tamil language obviously use diacritics-like sequences to get\nall characters which unfortunately count as separate entities.This is not a problem with UTF-8 / UTF-16 as erronously claimed by\nother answers, it is inherent in the Unicode encoding of the Tamil\nlanguage.The suggested Normalizer does not work, it seems that tamil has\nbeen designed by Unicode \"experts\" to explicitly use combination\nsequences which cannot be normalized. Aargh.My next idea is not to count , but , the visual\nrepresentations of characters.The result:\u0b95  b95 [x=0.0,y=-6.0,w=7.0,h=6.0]\n\u0bc1  bc1 [x=8.0,y=-6.0,w=7.0,h=4.0]\n\u0bae  bae [x=17.0,y=-6.0,w=6.0,h=6.0]\n\u0bbe  bbe [x=23.0,y=-6.0,w=5.0,h=6.0]\n\u0bb0  bb0 [x=30.0,y=-6.0,w=4.0,h=8.0]\n\u0bcd  bcd [x=31.0,y=-9.0,w=1.0,h=2.0]As the glyphs are intersecting, you need to use Java character type\nfunctions like in the other solution.SOLUTION:I am using this link: You need to exclude the combination characters and count them accordingly.As has been mentioned, your string contains 6 distinct code points. Half of them are letters, the other half are vowel signs. (Combining marks)You could use  built into the ICU4J library, to remove all of the vowel signs which are not Letters using the rule: [:^Letter:] Removeand count the resulting string. Try it out on their demo site: I wouldn't display the resultant string to an end user, and I'm not an expert so the rules may need to be tweaked to get to the general case but it's a thought."},
{"body": "Starting with the following code...When I try compiling this code I will get the following error...... but if  is final...the file will compile successfully.Moving on to the following code...... will print ... which is fine. The value is copied to a final variable and it can not be changed any more. Playing with the value in the array does not change the value of the  (as expected...).Why does the following require a cast?How is this different than the second example in this question? Why is the compiler giving me the following error?How can this happen?The JLS () has special rules for assignment conversion with :If we follow the link above, we see these in the definition of :If we follow the second link above, we see thatIt follows that  can only be assigned to  if  is a . To apply that to your cases:Note that whether  is itself  doesn't matter.The value 1 fits nicely into a byte; so does 1+1; and when the variable is final, the compiler can do . (in other words: the compiler doesn't use  when doing that + operation; but the \"raw\" 1 values)But when the variable is not final, then all the interesting rules about conversions and promotions kick in (see ; you want to read section 5.12 about widening primitive conversions).For the second part: making an array final still allows you to  any of its fields; so again; no constant folding possible; so that \"widening\" operation is kicking in again.It is indeed what compiler do in constant folding when used with , as we can see from byte code:And if you change your final byte to 127, it will also complain:in which cases, the compiler compute the result and know it out of limit, so it will still complain they are incompatible.More:And  is another question about constant folding with string:"},
{"body": "I'm looking for a free Java library to visualize some data. I want to do something similar as the following two images. Is there any possibility? I first thought of prefuse, but this isn't developed since 2007. So any oher libraries?Have you considered looking at ?Graphviz (short for Graph Visualization Software) is a package of open-source tools initiated by AT&T Labs Research for drawing graphs specified in DOT language scripts. It also provides libraries for software applications to use the tools. Graphviz is free software licensed under the Eclipse Public License.You can do some fairly cool stuff with it:For the timeline part, you should really consider  which contains annoted timelines, ...Try , which seems to be the successor of Prefuse and may be a good alternative option. It is written in JavaScript, but a  is available. is the successor of Protovis today. (Recommended by Protovis.) is a possibility.Check ou:Further links can be found at:An other alternative is to use  framework. If you are looking for browser/Javascript based libraries as well, checkout Another library you could consider is JGraph. It works mainly with graphs but you can easily implement a timeline as a one. The project can be found on GitHub  and was recently updated.You'd have to no doubt do a lot of customization, but Google's Chart Tools offers a lot of flexibility and options ().  I have not done anything as involved as the images that you pasted above, but it was fairly easy to set up various charts using the Google Visualization API.  It might be worth it to post your images on the Google Visualization API group () to see if anyone has done more involved charts like those you've proposed above using the Visualization API...I am surprised this hasn't been listed. I used  a while back: If you are explicitly looking for a swing library, ignore this answer!\nBut in the world of web,  and  are my favorites. Back-end could be implemented in java.If you dont mind to use javascript solution  is what you need for the second screenshot."},
{"body": "The Javadoc for  does not define any maximum or minimum.  However, it does say:(emphasis added)Is there such a maximum, even in theory?  Or is the way  operates fundamentally different, such that there is in reality  maximum except for the amount of memory available on the computer?The number is held in an  - the maximum size of an array is . So the maximum BigInteger probably is .Admittedly, this is implementation dependent, not part of the specification.In Java 8, some information was added to , giving a minimum supported range and the actual limit of the current implementation:From .It is implemented using an :From From the Wikipedia article :The first maximum you would hit is the length of a String which is 2-1 digits.  It's much smaller than the maximum of a BigInteger but IMHO it loses much of its value if it can't be printed."},
{"body": "On this Oracle page , it lists  as being available and on by default.  However in Java 6 update 29, it is off by default and in Java 7 update 2 it reports a warningDoes anyone know the thinking behind removing this option? With , this example took 4.541 seconds with the option on and 5.206 second with it off in Java 6 update 29. It is hard to see that it impacts performance.Note: Java 7 update 2 requires 2.0 G whereas Java 6 update 29 without compressed strings requires 1.8 GB and with compressed string requires only 1.0 GB.Originally, this option was added to improve SPECjBB performance.  The gains are due to reduced memory bandwidth requirements between the processor and DRAM.  Loading and storing bytes in the byte[] consumes 1/2 the bandwidth versus chars in the char[].However, this comes at a price.  The code has to determine if the internal array is a byte[] or char[].  This takes CPU time and if the workload is not memory  constrained, it can cause a performance regression.  There is also a code maintenance price due to the added complexity.Because there weren't enough production-like workloads that showed significant gains (except perhaps SPECjBB), the option was removed.There is another angle to this.  The option reduces heap usage.  For applicable Strings, it reduces the memory usage of those Strings by 1/2.  This angle wasn't considered at the time of option removal.  For workloads that are memory  constrained (i.e. have to run with limited heap space and GC takes a lot of time), this option can prove useful.If enough memory  constrained production-like workloads can be found to justify the option's inclusion, then  the option will be brought back. An average server heap dump uses 25% of the space on Strings.  Most Strings are compressible.  If the option is reintroduced, it could save half of this space (e.g. ~12%)! A feature similar to compressed strings is coming back in JDK 9 .Since there were up votes, I figure I wasn't missing something obvious so I have logged it as a bug (at the very least an omission in the documentation)(Should be visible in a couple of days)Just to add, for those interested...The  interface (which  implements), allows more compact representations of Strings than UTF-16.Apps which manipulate a lot of strings, should probably be written to accept CharSequence, such that they would work with , . 8-bit (UTF-8), or even 5, 6, or 7-bit encoded, or even compressed strings can be represented as .CharSequences can also be a lot more efficient to manipulate - subsequences can be defined as views (pointers) onto the original content for example, instead of copying.For example in , a suffix tree of ten of Shakespeare's plays,  using -based nodes, and  if using char[] or String-based nodes.Java 9 executes the  twice as fast on my machine as Java 6 and also only needs 1G of memory as it has -XX:+CompactStrings enabled by default.  Also, in Java 6, the compressed strings only worked for 7-bit ASCII characters, whereas in Java 9, it supports Latin1 (ISO-8859-1).  Some operations like charAt(idx) might be slightly slower though.  With the new design, they could also support other encodings in future.I wrote a newsletter about this on .In OpenJDK 7 (1.7.0_147-icedtea, Ubuntu 11.10) it simply fails with an when JAVA_OPTS (or command line) contains . It seems Oracle really removed the option."},
{"body": "I'm creating a generic class and in one of the methods I need to know the Class of the generic type currently in use. The reason is that one of the method's I call expects this as an argument.Example:Clearly the example above doesn't work  and results in the following error: Illegal class literal for the type parameter T.My question is: does someone know a good alternative or workaround for this?Still the same problems : Generic informations are erased at runtime, it cannot be recovered. A workaround is to pass the class T in parameter of a static method : It's ugly, but it works.I was just pointed to this solution:This works if  is given a concrete type by a subclass:Unfortunately Christoph's solution as written only works in very limited circumstances. [EDIT: as commented below I no longer remember my reasoning for this sentence and it is likely wrong: \"Note that this will only work in abstract classes, first of all.\"] The next difficulty is that  only works from DIRECT subclasses of . We can fix that, though:This will work in many situations in practice, but not ALL the time. Consider:This will throw a , because the type argument here isn't a  or a  at all; it's the  . So now you would be stuck trying to figure out what type  was supposed to stand for, and so on down the rabbit hole.I think the only reasonable, general answer is something akin to Nicolas's initial answer -- in general, if your class needs to instantiate objects of some other class that is unknown at compile-time, users of your class need to pass that class literal (or, perhaps, a Factory) to your class explicitly and not rely solely on generics.i find another way to obtain the Class of the generic objectI will elaborate on Christoph's solution.Here is the ClassGetter abstract class:Here is a static method which uses the above class to find a generic class' type:As an example of it's usage, you could make this method:And then use it like this:T can be resolved pretty easily using :"},
{"body": "Description for  from the Java docs:Is there an equivalent for  in the .NET-Framework?"},
{"body": "This is the class:Now I'm trying to get \"reflect\" this method from the class:There's just an .An alternative is .The same applies on other primitives."},
{"body": "I am trying to learn spring data JPA by testing some CRUD operation via .I came across two methods  and .\nI don't get the difference between these two. On calling  also my changes are getting saved into database so what is the use of .On , changes will be flushed to DB immediately in this command. With , this is not necessarily true, and might stay just in memory, until  or  commands are issued. But be aware, that even if you flush the changes in transaction and do not commit them, the changes still won't be visible to the outside transactions until the commit in this transaction.In your case, you probably use some sort of transactions mechanism, which issues  command for you if everything works out fine.Depending on the hibernate flush mode that you are using ( is the default) save may or may not write your changes to the DB straight away. When you call saveAndFlush you are enforcing the synchronization of your model state with the DB.If you use flush mode AUTO and you are using your application to first save and then select the data again, you will not see a difference in bahvior between  and  because the select triggers a flush first. See the ."},
{"body": "Is it possible to add a file (not necessarily a jar file) to java classpath at runtime.\nSpecifically, the file already is present in the classpath, what I want is whether I can add a modified copy of this file to the classpath.Thanks,You can only add folders or jar files to a class loader. So if you have a single class file, you need to put it into the appropriate folder structure first. is a rather ugly hack that adds to the SystemClassLoader at runtime:The reflection is necessary to access the protected method . This could fail if there is a SecurityManager.Try this one on for size.This edits the system class loader to include the given library jar. It is pretty ugly, but it works.The way I have done this is by using my own class loaderAnd create the following class:Works without any reflectionYou coud try java.net.URLClassloader with the url of the folder/jar where your updated class resides and use it  instead of the default classloader when creating a new thread. yes, you can.  it will need to be in its package structure in a separate directory from the rest of your compiled code if you want to isolate it.  you will then just put its base dir in the front of the classpath on the command line.  Yes I believe it's possible but you might have to implement your own classloader.  I have never done it but that is the path I would probably look at.  My solution:"},
{"body": "Consider the following code.I am getting i value up to  correctly. After catching the  output getting wired as follows.Consider  demo here. It is working correctly up to . Actually how this happen?  I did following code to realize what is happening here.Now previous issue not there. now value of  up to  correct and and runs further. I am hopping this may runs up to value of (max value of int) without an issue.There is some issue with . There are similar answers bellow too. But why? What will be the actual reason?Note the absence of newline characters in . It indicates that something wrong happens inside .The essential point here is that  requires some stack space to work, so that  is thrown from .Here is your code with marked points:Let's imagine what happens at level N of recursion when i = :After this point the situation repeats with . I'm not sure why some numbers are printed correclty between sequences without newlines, perhaps its related to internal work of  and buffers it uses.What I suspect being happening is this:When Exception is thrown by try Block,  has same value when it comes in catch block (as its not incremented due to exception) and then inside catch block same exception is thrown and which is again caught by catch block !  when try block throws exception it is caught by catch block but when it goes to  again Exception is thrown 4 times (in my eclipse)   Without printing As in above output, i have tested it by printing \"Before\" Text which is printed four times before it prints If the execution of  (or one of the methods called by it) causes a stack overflow, you will print the same  value from the catch clause of the enclosing  incarnation.The exact behavior is rather unpredictable as it depends on the stack space still available.As the other answers already explain it has to do with System.out.println requiring extra space on the stack and thus throwing itself a StackOverflowError.Try this code here to see some different behaviour which shows that at some point there is exceptions being thrown all over the place so that i++ cannot occur anymore.The important lession to learn is: Never catch Errors as they really indicate that there is something serious wrong with your JVM which cannot be handled normally.The bottom line is that  is an error, not an exception. You are handling an error, not an exception.So the program has already crashed when it enters the catch block.Regarding the strange behaviour of the program, below is the explanation on basis of java buffers from  official doc:The  internally calls the  which is buffered. You don't loose any data from the buffer, it gets all written to the output( terminal in your case) after it fills up, or when you explicitly call flush on it. Coming back to this scenario, it depends on the internal dynamics of how much the stack is filled up and how many print statements were able to get executed from the catch in  and those number of characters were written to the buffer. Here after the first try is executed, i.e. in the event of first occurence of the stack overflow, the first System.out.println() fails to print the new line so it flushed the buffer with remaining characters. axtavt Answer is very complete but I'd like to add this:As you may know the stack is used to store the memory of variables, based on that you cannot create new variables when you reach the limit, it is true that System.out.println will need some stack resourcesThen after calling the print, the error does not allow you to even call the newLine, it breaks again right on the print. Based on that you can make sure that's the case by changing your code like this:Now you will not ask the stack to handle the new lines, you will use the constant \"\\n\" and you may add some debugging to the exception printing line and your output will not have multiple values in the same line:And it will keep broken until get some resources to allocate new data and pass to the next i value."},
{"body": "I wonder if there are any suggestions for declarative GUI programming in Java. (I abhor visual-based GUI creator/editor software, but am getting a little tired of manually instantiating JPanels and Boxes and JLabels and JLists etc.)That's my overall question, but I have two specific questions for approaches I'm thinking of taking: lots of great answers here! (& I added #3 above) I'd be especially grateful for hearing any experiences any of you have had with using one of these frameworks for real-world applications.p.s. I did try a few google searches (\"java gui declarative\"), just didn't quite know what to look for.You might have a look at ; it uses  to build Swing UIs.A simple example from the  [PDF]:Alternatively:Or even:As the author of CookSwing, a tool that does what you need, I've given this subject a long hard look before doing the actual implementation.  I made a living writing Java Swing GUI applications.IMO, if you are going to use any kind of imperative programming languages to describe Java Swing component, you might as well just use Java.  Groovy etc only adds complications without much simplification.Declarative languages are much better, because even non-programmers can make sense out of it, especially when you need to delegate the task of fine tuning of specific layouts to artists.  XML is perfect for declarative languages (over other choices) because of simplicity, readability, and plenty of editors/transformation tools etc available.Here are the problems faced in declarative GUI programming, not in any particular order.  These issues have been addressed in CookSwing.If conciseness is important you might want to consider the double brace idiom:You then don't lose any of the power of a well known general purpose programming language (you know you are going to need it, and JellyTags suck). All you need is the one little extra idiom.It's not used very much, because actually people pissing around with XML weren't solving real pain points.In general you can use builder layers to abstract repeated code. GUI code doesn't have to be badly written, it's just that almost all of it is (including in text books).I strongly recommend  - it takes a few days to get used to the syntax, but once you've got it, it works wonders.  I used JGoodies Forms for quite awhile, and Karsten's builder concept works well, but it is a bit cryptic...  MiG is easier to pick up, and results in wonderfully concise code.If you're willing to step slightly outside plain Java, 's \"builder\" concept works pretty well with GUIs. Of course you can interop between Groovy and Java fairly easily. See the  page for more information.give Swiby a try: \"Swiby is a blend of Swing and Ruby for truly rich distributed applications.\"\nIn other words Swiby is a domain specific language mixing swing and ruby. does exactly what you need. Its a tiny (283k), unobtrusive, easy to learn declarative Swing framework.SDL/Swing is open source but enjoys commercial support. We (Ikayzo.com) developed it over a period of years and have deployed it in production systems for many customers ranging from life science companies to banks.I can find the following examples of what you're asking for:I recently come across .something new..., will be included in eclipse e4I've tried many solutions, such as SWIXML, Javabuilders, MigLayout, Cookswing. I finally found the javaFX and javaFX-Scenebuilder the best an fastest solution, XML-based GUI tool. you'd like the way scenebuilder creates GUI (with drag & drop items!). plus, it uses CSS (Cascading Style Sheets) for the GUI theme. Jsut trust the Oracle, it's the best GUI tool for java applications.\ntake a tour for creating javaFX apps with scenebuilder, here:\nAlthough it is not declarative and is limited exclusively to layouts, you might want to take a look at  which allows to programmatically define Swing layouts in a very concise manner (it's open source).Main advantages:As often, it's always a good idea to perform a search when you're looking for something.  is the first link in google while looking for \"java xml gui\", it a very nice plugin, which included GWT,XWT,SWT,Swing etc"},
{"body": "Take a look at the following example:The first  writes  but the second throws a .Why is only the second line worth an exception? And what is the difference between the two s? Is there a   and a   in Java?The first invocation will call the  method, as you have explicitly typecasted  to  reference. Conversely, the second one will invoke the overloaded  method, as  is more specific than  for a  argument. There are other overloaded versions of this method that accept primitive parameters, but those are not a valid match for a  argument.From :Now check the source code of both the methods:There are lots of overloaded  methods in Java. Further, in Java  has any and all types so that anything (that isn't a primitive) can be .So, when you call  you call the  method that takes an  as use explicitly cast  to .In the second example you don't explicitly cast the  to any particular type so in fact you call the  method with a  which throws an NPE.From the In this case  is  than  so it is called when no explicit cast of  is made.Although I accepted already an answer I would like to add the exact answer to the question, because the two answers concentrate on explaining the trap I walked into.The difference between  and  is that the type of the first is forced to  but the type of the second is not, as one could think, forced to . Instead it could also be an array instead of an object.So the conclusion is: pass  instead of  as an argument to a method to be sure to get exactly the method working on objects instead of any other method working on arrays."},
{"body": "I'm working on a project, written in Java, which requires that I build a very large 2-D sparse array.  Very sparse, if that makes a difference.  Anyway: the most crucial aspect for this application is efficency in terms of time (assume loads of memory, though not nearly so unlimited as to allow me to use a standard 2-D array -- the key range is in the billions in both dimensions).Out of the kajillion cells in the array, there will be several hundred thousand cells which contain an object.  I need to be able to modify cell contents VERY quickly.Anyway: Does anyone know a particularly good library for this purpose?  It would have to be Berkeley, LGPL or similar license (no GPL, as the product can't be entirely open-sourced).  Or if there's just a very simple way to make a homebrew sparse array object, that'd be fine too.I'm considering , but haven't heard any opinions on its quality.Sparsed arrays built with hashmaps are very inefficient for frequently read data. The most efficient implementations uses a Trie that allows access to a single vector where segments are distributed.A Trie can compute if an element is present in the table by performing only read-only TWO array indexing to get the effective position where an element is stored, or to know if its absent from the underlying store.It can also provide a default position in the backing store for the default value of the sparsed array, so that you don't need ANY test on the returned index, because the Trie guarantees that all possible source index will map at least to the default position in the backing store (where you'll frequently store a zero, or an empty string or a null object).There exists implementations that support fast-updatable Tries, with an otional \"compact()\" operation to optimze the size of the backing store at end of multiple operations. Tries are MUCH faster than hashmaps, because they don't need any complex hashing function, and don't need to handle collisions for reads (With Hashmaps, you have collision BOTH for reading and for writing, this requires a loop to skip to the next candidate position, and a test on each of them to compare the effective source index...)In addition, Java Hashmaps can only index on Objects, and creating an Integer object for each hashed source index (this object creation will be needed for every read, not just writes) is costly in terms of memory operations, as it stresses the garbage collector.I really hoped that the JRE included an IntegerTrieMap<Object> as the default implementation for the slow HashMap<Integer, Object> or LongTrieMap<Object> as the default implementation for the even slower HashMap<Long, Object>... But this is still not the case.You may wonder what is a Trie?It's just a small array of integers (in a smaller range than the full range of coordinates for your matrix) that allows mapping the coordinates into an integer position in a vector.For example suppose you want a 1024*1024 matrix containing only a few non zero values. Instead of storing that matrix in a array containing 1024*1024 elements (more than 1 million), you may just want to split it into subranges of size 16*16, and you'll just need 64*64 such subranges.In that case, the Trie index will contain just 64*64 integers (4096), and there will be at least 16*16 data elements (containing the default zeroes, or the most common subrange found in your sparse matrix).And the vector used to store the values will contain only 1 copy for subranges that are equal with each other (most of them being full of zeroes, they will be represented by the same subrange).So instead of using a syntax like , you'd use a syntax like:which will be more conveniently handled using an access method for the trie object.Here is an example, built into a commented class (I hope it compiles OK, as it was simplified; signal me if there are errors to correct):Note: this code is not complete because it handles a single matrix size, and its compactor is limited to detect only common subranges, without interleaving them.Also, the code does not determine where it is the best width or height to use for splitting the matrix into subranges (for x or y coordinates), according to the matrix size. It just uses the same static subrange sizes of 16 (for both coordinates), but it could be conveniently any other small power of 2 (but a non power of 2 would slow down the  and  internal methods), independantly for both coordinates, and up to the maximum width or height of the matrix.ideally the  method should be able to determine the best fitting sizes.If these splitting subranges sizes can vary, then there will be a need to add instance members for these subrange sizes instead of the static , and to make the static methods  and  into non static; and the initialization arrays and  will need to be dropped or redefined differently.If you want to support interleaving, basically you'll start by dividing the existing values in two of about the same size (both being a multiple of the minimum subrange size, the first subset possibly having one more subrange than the second one), and you'll scan the larger one at all successive positions to find a matching interleaving; then you'll try to match these values. Then you'll loop recursely by dividing the subsets in halves (also a multiple of the minimum subrange size) and you'll scan again to match these subsets (this will multiply the number of subsets by 2: you have to wonder if the doubled size of the subrangePositions index is worth the value compared to the existing size of the values to see if it offers an effective compression (if not, you stop there: you have found the optimum subrange size directly from the interleaving compression process). In that case; the subrange size will be mutable, during compaction.But this code shows how you assign non-zero values and reallocate the  array for additional (non-zero) subranges, and then how you can optimize (with  after assignments have been performed using the  method) the storage of this data when there are duplicate subranges that may be unified within the data, and reindexed at the same position in the  array.Anyway, all the principles of a trie are implemented there:Note that the generic Colt library, though very good as it is, is not as good when working on sparse matrice, because it uses hashing (or row-compresssed) technics which do not implement the support for tries for now, despite it is an excellent optimization, which is both space-saving  time-saving, notably for the most frequent getAt() operations. Even the setAt() operation described here for tries saves lot of time (the way is is implemented here, i.e. without automatic compaction after setting, which could still be implemented based on demand and estimated time where compaction would still save lot of storage space at the price of time): the time saving is proportional to the number of cells in subranges, and space saving is inversely proportional to the number of cells per subrange. A good compromize if then to use a subrange size such the number of cells per subrange is the square root of the total number of cells in a 2D matrix (it would be a cubic root when working with 3D matrice).Hashing technics used in Colt sparse matrix implementations have the inconvenience that they add a lot of storage overhead, and slow access time due to possible collisions. Tries can avoid all collisions, and can then warranty to save linear O(n) time to O(1) time in the worst cases, where (n) is the number of possible collisions (which, in case of sparse matrix, may be up to the number of non-default-value cells in the matrix, i.e. up to the total number of size of the matrix times a factor proportional to the hashing filling factor, for a non-sparse i.e. full matrix).The RC (row-compressed) technics used in Colt are nearer from Tries, but this is at another price, here the compression technics used, that have very slow access time for the most frequent read-only get() operations, and very slow compression for setAt() operations. In addition, the compression used is not orthogonal, unlike in this presentation of Tries where orthogonality is preserved. Tries would also be preserve this orthogonality for related viewing operations such as striding, transposition (viewed as a striding operation based on integer cyclic modular operations), subranging (and subselections in general, including with sorting views).I just hope that Colt will be updated in some future to implement another implementation using Tries (i.e. TrieSparseMatrix instead of just HashSparseMatrix and RCSparseMatrix). The ideas are in this article.The Trove implementation (based in int->int maps) are also based on hashing technics similar to the Colt's HashedSparseMatrix, i.e. they have the same inconvenience. Tries will be a lot faster, with a moderate additional space consumed (but this space can be optimized and become even better than Trove and Colt, in a deferred time, using a final compact()ion operation on the resulting matrix/trie).Note: this Trie implementation is bound to a specific native type (here double). This is voluntary, because generic implementation using boxing types have a huge space overhead (and are much slower in acccess time). Here it just uses native unidimensional arrays of double rather than generic Vector. But it is certainly possible to derive a generic implementation as well for Tries... Unfortunately, Java still does not allow writing really generic classes with all the benefits of native types, except by writing multiple implementations (for a generic Object type or for each native type), and serving all these operation via a type factory. The language should be able to automatically instanciate the native implementations and build the factory automatically (for now it is not the case even in Java 7, and this is something where .Net still maintains its advantage for really generic types that are as fast as native types).Following framework to test Java Matrix Libraries, provides also a good list of these!\nTested Libraries:Here is a paper you may be interested in which talks about data structures for matrix computations, including sparse arrays:You can download the paper as PDF or PS.  It includes source code, too.Maybe  is of help. It provides a sparse matrix implementation.This seems to be simple.You could use a binary tree of the data using row*maxcolums+column as an index.To find item, you simply calculate row*maxcolums+column and binary search the tree looking for it, if it's not there, you can return null (it's \u041e(log n) where n is the number of cells which contain an object).Not the fastest runtime solution probably, but the fastest I could come up with that seems to work. Create an Index class and use it as a key for a SortedMap, like:My Index class looks like this (with some help from Eclipse code generator).I've just used  which provided much better performance than Colt while using the int->int map (used to implement a sparse matrix). You migth look at  (Linear Algebra for Java) library. It supports  as well as  internal representaions for sparse matrices. So, these are the most efficient and fast internal stuctures for sparse data.Here is the brief example of using sparse matrices in :you could just use a nested map although if you need to do matrix calculus on it that might not be the best optionmaybe instead of object use some tuple for the actual data so you can work with it easier after extraction, something like:null check etc omitted for brevitySuanShu has a suite of  and .HashMap rocks. Just concatenate the indexes (as strings) with a separator, say '/', using StringBuilder (not + or String.format), and use that as the key. You can't get faster and more memory-efficient than that. Sparse matrices are soo 20th century. :-)"},
{"body": "I have a 2\u00a0GB file () in which every line in the file is a word, just like:I need to write a program to read every word in the file and print the word count. I wrote it using Java and C++, but the result is surprising: Java runs 2.3 times faster than C++. My code are as follows:C++:Output:Java:Output:Why is Java faster than C++ in this situation, and how do I improve the performance of C++?You aren't comparing the same thing. The Java program reads lines, depening on the newline, while the C++ program reads white space delimited \"words\", which is a little extra work.Try .You might also try and do an elementary read operation to read a byte array and scan this for newlines. On my old Linux notebook, jdk1.7.0_21 and don't-tell-me-it's-old 4.3.3 take about the same time, comparing with C++ getline. (We have established that reading words is slower.) There isn't much difference between -O0 and -O2, which doesn't surprise me, given the simplicity of the code in the loop.\nAs I suggested, fin.read(buffer,LEN) with LEN = 1MB and using memchr to scan for '\\n' results in another speed improvement of about 20%, which makes C (there isn't any C++ left by now) faster than Java.There are a number of significant differences in the way the\nlanguages handle , all of which can make a difference, one way\nor another.Perhaps the first (and most important) question is: how is the\ndata encoded in the text file. If it is single-byte characters\n( or ), then Java has to convert it into \nbefore processing; depending on the locale, C++ may (or may not)\nalso convert or do some additional checking.As has been pointed out (partially, at least), in C++,  uses\na locale specific ,  will simply compare for\n, which is probably faster. (Typical implementations of\n will use a bitmap, which means an additional memory\naccess for each character.)Optimization levels and specific library implementations may\nalso vary. It's not unusual in C++ for one library\nimplementation to be 2 or 3 times faster than another.Finally, a most significant difference: C++ distinguishes\nbetween text files and binary files. You've opened the file in\ntext mode; this means that it will be \"preprocessed\" at the\nlowest level, before even the extraction operators see it. This\ndepends on the platform: for Unix platforms, the \"preprocessing\"\nis a no-op; on Windows, it will convert CRLF pairs into ,\nwhich will have a definite impact on performance. If I recall\ncorrectly (I've not used Java for some years), Java expects\nhigher level functions to handle this, so functions like\n will be slightly more complicated. Just guessing\nhere, but I suspect that the additional logic at the higher\nlevel costs less in runtime than the buffer preprocessing at the\nlower level. (If you are testing under Windows, you might\nexperiment with opening the file in binary mode in C++. This\nshould make no difference in the behavior of the program when\nyou use ; any extra CR will be considered white space. With\n, you'll have to add logic to remove any trailing\n to your code.)I would suspect that the main difference is that  performs better than the  because it buffers, while the ifsteam does not. The BufferedReader reads large chunks of the file in advance and hands them to your program from RAM when you call , while the std::ifstream only reads a few bytes at a time when you prompt it to by calling the -operator.Sequential access of large amounts of data from the hard drive is usually much faster than accessing many small chunks one at a time.A fairer comparison would be to compare std::ifstream to the unbuffered java.io.FileReader. I am not expert in C++, but you have at least the following to affect performance:Since  cost is the major cost here, I guess 1 and 2 are the major reasons.I would also try using  instead of standard file read/write. This should let your OS handle the reading and writing while your application is only concerned with the data.There's no situation where C++ can't be faster than Java, but sometimes it takes a lot of work from very talented people. But I don't think this one should be too hard to beat as it is a straightforward task.mmap for Windows is described in  ()."},
{"body": "Why does BigInteger class has constant TEN and ONE? Any practical uses for having them as constants?  I can understand some use cases for ZERO. Let's say you have written a function that returns  after some calculations and db operations. You often may need to return values like null, 0, 1. It's easy to return . This values are public since they are needed .Also  is commonly used for power/divide/mod operations.Checkout  public methods. You will easily see their common use cases. is probably the most fundamental number in mathematics (alongside zero). Seems to deserve its own constant on that alone. Practically, it's a useful number to have as a constant in many algorithms. is important in the BigInteger context because it is the base of the decimal number system. This is important because several BigInteger functions need a radix base (e.g. . It's therefore a pretty useful constant to have.IMHO that was a design decision because 1 and 10 are used in other parts of the Java API code base. Creating Big* is an expensive operation and using constant avoid new object creation (Big* are immutable anyway) and the code is more readable.Probably other constants weren't needed by the rest of the API.Making them public was probably a fault. (The java API is full of \"bad\" design decisions)I don't know actually, but maybe:Maybe they just used these constans a lot internally? (I haven't checked the source code, but it's Open Source).E.g.:After looking at the code I think the reason is because they use ZERO and ONE a lot internally. Probably thought that others might profit from these constants as well given the reasons above. Or maybe they use these constants in some other classes as well.TEN has been added in v1.5\nIt doesn't seem to be used internally, but maybe by another class?10, 0 and 1 can answer almost everything. for example if you want to arrive at 42, you can do a (10 + 10 + 10 + 10 + 1 + 1) :)"},
{"body": "On the following code:I'm getting the error:Why?Capacity does not equal size. The size parameter that you are passing in simply allocates enough memory for the size. It does not actually define elements. It's actually kind of a silly requirement of , but it is one nonetheless.The key part from the :You should just pass the  to the 's constructor to copy all of the  to avoid the issue altogether.That's a very good question and it almost certainly has to do with the fact that setting a collections capacity does not necessarily allocate the underlying objects, but why are you doing it that way when you can just:The constructor  will copy every elements from  into the newly created instance, thus copying  into . It is the same as  also, which is really what you need.It does make sense that  requires the  array to be large enough to hold all elements from the  array. A similar analogy is the C function  and the like."},
{"body": "I get the following runtime error message (along with the first line of the stack trace, which points to line 94).  I'm trying to figure out why it says no such method exists.Line 94 of writeSummaryLink is shown below.\nWhat does \"ILcom\" or \"Z\" mean?\nWhy there are four types in parentheses \n    (ILcom/sun/javadoc/ClassDoc;Lcom/sun/javadoc/MemberDoc;Ljava/lang/String;Z) \nand one after the parentheses\n    Ljava/lang/String;\nwhen the method printDocLinkForMenu clearly has five parameters?\nThe writeSummaryLink method is:Here's the method line 94 is calling:From  of the JVM Spec:From :Thus, translates to:A method with , , ,  and  as parameters, and which returns a . Note that only reference parameters are separated with a semicolon, since the semicolon is part of their character representation.There are five parameters (int, ClassDoc, MemberDoc, String, boolean) and one return type (String).Those are mapping types for native types. You can find an overview .As to your next question:Because you're not running the code you think you're running. The  running code is trying to call exactly that method described in the error message, with actually five parameters (the  should be counted separately) and a return type, but this method doesn't exist in the runtime classpath (while it was available in the compiletime classpath), hence this error. Also see the : So, verify if you're actually running the right version of the code as you've posted in your question and are using the right dependencies in the runtime classpath and not having duplicate different versioned libraries in the classpath.: the exception signifies that the  code is (implicitly) trying to use the method like as follows:Because it is expecting a  outcome while it is declared ."},
{"body": "Given:Is there a regex that works with  to grab (up to) two words at a time, such that:results in this:This question is about . It is  about \"finding a work-around\" or other \"making it work in another way\" solutions.Is this what you are looking for? \noutput: is previous match,  is negative lookbehind.In  we are trying to Only confusion that I had at start was how would it work for first space since we want that space to be ignored. . So before first iteration regex in negative look-behind will look like  and since first space  have  before, it can't be match for split. Next space will not have this problem, so it will be matched and informations about it (like its  in  String) will be stored in  and used later in next negative look-behind.So for 3rd space regex will check if there is previously matched space  and word  before it. Since result of this test will be positive, negative look-behind wont accept it so this space wont be matched, but 4th space wont have this problem because space before it wont be the same as stored in  (it will have different position in  String).Also if someone would like to separate on lets say every 3rd space you can use this form (based on 's  which was deleted when I posted this fragment of answer) Instead of 100 you can use some bigger value that will be at least the size of length of longest word in String.I just noticed that we can also use  instead of  if we want to split with every odd number like every 3rd, 5th, 7th for exampleThis will work, but maximum word length needs to be set in advance:I like Pshemo's answer better, being shorter and usable on arbitrary word lengths, but this (as @Pshemo pointed out) has the advantage of being adaptable to groups of more than 2 words.this worked for me \nexample You can try this:"},
{"body": "I'm reading about volatile keyword in Java and completely understand the theory part of it.But, what I'm searching for is, a good case example, which shows what would happen if variable wasn't volatile and if it were.Below code snippet doesn't work as expected ( )Ideally, if keepRunning wasn't volatile, thread should keep on running indefinetely. But, it does stop after few seconds.I've got two basic question :-Volatile --> Guarantees visibility and NOT atomicitySynchronization (Locking) --> Guarantees visibility and atomicity (if done properly)Use volatile only when you are updating the reference and not performing some other operations on it.Example:will not be thread safe without use of synchronization or AtomicInteger as incrementing is an compound operation.Well that depends on various circumstances. In most cases JVM is smart enough to flush the contents. discusses various possible uses of volatile. Using volatile correctly is tricky, I would say \"When in doubt, Leave it out\", use synchronized block instead.Also:. For your particular example: if not declared volatile the server JVM could hoist the  variable out of the loop because it is not modified  the loop (turning it into an infinite loop), but the client JVM would not. That is why you see different results.General explanation about volatile variables follows:When a field is declared , the compiler and runtime are put on notice that this variable is shared and that operations on it should not be reordered with other memory operations. Volatile variables are not cached in registers or in caches where they are hidden from other \nprocessors, so . The visibility effects of volatile variables extend beyond the value of the volatile variable itself. When thread A writes to a volatile variable and subsequently thread B reads that same variable, the values of all variables that were visible to A prior to writing to the volatile variable become visible to B after reading the volatile variableThe  most  common  use  for  volatile  variables  is  as  a completion, interruption, or status flag:Volatile variables can be used for other kinds of state information, but more care is required when attempting this. For example, the semantics of volatile are not strong enough to make the increment operation () atomic, unless you can guarantee that the variable is written only from a single thread.You can use volatile variables only when all the following criteria are met: : be sure to always specify the -server JVM command line switch when invoking the JVM, even for development and testing. The server JVM performs more optimization than the client JVM, such as hoisting variables out of a loop that are not modified in the loop; code that might appear to work in the development environment (client JVM) can break in the deployment environment \n(server JVM).This is excerpt from Java Concurrency in Practice, the best book you can find about this subject.I have modified your example slightly. Now use the example with keepRunning as volatile and non volatile member :When a variable is , it is guaranteeing that it will not be cached and that different threads will see the updated value. However, not marking it  does not guarantee the oppostie.  was one of those things that was broken in the JVM for a long time and still not always well understood (and often left out by developers). So the JVM is somewhat smart about not caching variable values indefinitely, though you should mark it .Consider the code ,first  keyword,this program should  until  is pressed. But on  it may happen that variable  is  and you cannot change its value from shutdown() method which results in  printing of hello text.Thus using volatile keyword ,it is  that your variable will not be cached ,ie will  on . Thus using volatile keyword is a  and . is not going to necessarily create giant changes, depending on the JVM and compiler. However, for many (edge) cases, it can be the difference between optimization causing a variable's changes to fail to be noticed as opposed to them being correctly written.Basically, an optimizer may choose to put non-volatile variables on registers or on the stack. If another thread changes them in the heap or the classes' primitives, the other thread will keep looking for it on the stack, and it'll be stale. ensures such optimizations don't happen and all reads and writes are directly to the heap or another place where all threads will see it.Please find the solution below,The value of this variable will never be cached thread-locally: all reads and writes will go straight to \"main memory\". The volatile force the thread to update the original variable for each time. Please refer this link  to get more clarity in it.if you declare a variable as volatile, then it will not be stored in the local cache. Whenever thread are updating the values, it is updated to the main memory. So, other threads can access the updated value.If you are running in a single-processor or if your system is very busy, the OS may be swapping out the threads which causes some levels of cache invalidation.   As others have mentioned, not having a  doesn't mean that memory will  be shared but the JVM is trying to not synchronize memory if it can for performance reasons so the memory may not be updated.Another thing to note is that  is synchronized because the underlying  does synchronization to stop overlapping output.  So you are getting memory synchronization \"for free\" in the main-thread.  This still doesn't explain why the reading loop sees the updates at all however.Whether the  lines are in or out, your program spins for me under Java6 on a MacBook Pro with an Intel i7.I think your example is good.  Not sure why it isn't working with all  statements removed.  It works for me.In terms of memory synchronization,  throws up the same memory barriers as a  block except that the  barrier is uni-directional versus bi-directional.   reads throw up a load-barrier while writes throw up a store-barrier.  A  block is a bi-directional barrier.In terms of , however, the answer is \"it depends\".  If you are reading or writing a value from a field then  provides proper atomicity.  However, incrementing a  field suffers from the limitation that  is actually 3 operations: read, increment, write.  In that case or more complex mutex cases, a full  block is in order.Objects that are declared as volatile are usually used to communicate state information among threads,To ensure CPU caches are updated, that is, kept in sync, in the presence of volatile fields, a CPU instruction, a memory barrier, often called a membar or fence, is emitted to update CPU caches with a change in a volatile field\u2019s value.The volatile modifier tells the compiler that the variable modified by volatile can be changed unexpectedly by other parts of your program.The volatile variable must be used in Thread Context only. see the example "},
{"body": "I have a small Java project in Eclipse. I have a class of JUnit tests for each class in the project. I'm using JUnit 4, and this is not a maven project.Is there an easy way to tell Eclipse to run all tests in all test classes at once?Right click on a source folder then .Select the source directory containing all test classes, right-click, select \"Run as...\" and select JUnit test."},
{"body": "This code produces different outputs in Java 6 and Java 7.\nIn Java 6 the  condition returns  and in Java 7 the  returns . Why?Why does this program produces different output in Java 6 and Java 7?It seems that JDK7 process intern in a different way as before.\nI tested it with build 1.7.0-b147 and got \"both are equal\", but when executing it (same bytecode) with 1,6.0_24 I do not get the message.\nIt also depends where the  line is located in the source code. The following code also does not output the message:  it seems like  after not finding the String in its pool of strings, inserts the actual instance s1 into the pool. The JVM is using that pool when s2 is created, so it gets the same reference as s1 back. On the other side, if s2 is created first, that reference is stored into the pool.\nThis can be a result of moving the interned Strings out from the permanent generation of the Java heap.  Found here:   Not sure if that is a bug and from which version... The JLS 3.10.5 states  so the question is how pre-existing is interpreted, compile-time or execute-time: is \"Goodmorning\" pre-existing or not?\nI prefer the way it WAS implemented before 7...Let's omit unnecessary details from the example:Let's consider  as a black box. Based on a few test cases run, I would conclude that implementation is as following:Java 6:\nif the pool contains object equals to , then return reference to that object,\nelse create new string (equal to ), put to the pool, and return reference to that created instance.Java 7:\nif the pool contains object equals to , then return reference to that object,\nelse put  to the pool, and return .Neither Java 6 nor Java 7 breaks the .It seems that new intern method behavior was a result of the fix of this bug: . compares the references. The intern method makes sure strings with the same value have the same reference.The javadoc for the  explains:So without interning the compiler looks at the constants in the java code and builds its constant pool from that. There is a different pool maintained by the String class, and interning checks the string passed in against the pool and makes sure the reference is unique (so that == will work).In jdk6:\n creates a String object \"Good\" in constant pool. creates another String object \"morning\" in constant pool but this time actually JVM do: .Now as the  operator creates an object in heap therefore the reference in  is of heap not constant pool \nand the  creates a String object \"Goodmorning\" in constant pool whose reference is stored in .Therefore,  condition is false.But what happens in jdk7?FIRST CASE:In the first code snipped you are actually adding three Strings in the Pool of Strings.\n1. s1 = \"Good\"\n2. s1 = \"Goodmorning\" (after concatenating)\n3. s2 = \"Goodmorining\"While doing if(s1==s2), the objects are same but reference as different hence it is false.SECOND CASE:In this case you are using s1.intern(), which implies that if the pool already contains a string equal to this String object as determined by the equals(Object) method, then the string from the pool is returned. Otherwise, this String object is added to the pool and a reference to this String object is returned. You need to use . Using  with  objects compares the object references themselves.Edit: When I run your second code snippet, I do not get \"both are equal\" printed out.Edit2: Clarified that references are compared when you use '=='.there are mainly 4 ways to compare string:Whenever you are comparing between two String, don't use  and use  becaue you are comparing objects not references:The result code dependents runtime:If you write like this:the reason is ' ldc #N ' (Load string from constant pool) and String.intern() both will use StringTable in hotspot JVM. For detail I wrote a pool english article: "},
{"body": "I have a web archive with a file placed in the WEB-INF directory.How do I load that file in a java class?I know I can put it in the classes directory and load it from there. It would just be put it in WEB-INF. Use the  method on the ServletContext object, e.g.How you get a reference to the ServletContext depends on your application... do you want to do it from a Servlet or from a JSP?EDITED: If you're inside a Servlet object, then call . If you're in JSP, use the predefined variable .Here is how it works for me with no Servlet use.Let's say I am trying to access web.xml in project/WebContent/WEB-INF/web.xml"},
{"body": "Why can't I do:Because  doesn't extend . Here is an .As to why that's an interesting question. This isn't exactly your question but it sheds some light on it. From the :That basically suggests to me that Sun wants to distance themselves from Enumeration, which is very early Java with quite a verbose syntax.Using Collections utility class, Enumeration can be made iterable like:I have solved this problem with two very simple classes, one for  and one for .  The enumeration wrapper is as follows:Which can be used either with a static utility method (which is my preference):or by instantiating the class:The new-style-for-loop (\"foreach\") works on arrays, and things that implement the  interface.It's also more analogous to  than to , so it wouldn't make sense for  to work with foreach unless  did too (and it doesn't). \n is also discouraged in favor of . doesn't implement  and as such can't be used directly in a foreach loop. However using  it's possible to iterate over an enumeration with:You could also use a shorter syntax with  but this is less efficient (two iterations over the elements and more memory usage) :Because an Enumeration (and most classes derived from this interface) does not implement Iterable.You can try to write your own wrapper class."},
{"body": "I am a little confused over the term \"package private\" that some of the documentation uses, along with the usage of \"default access.\" Aren't package private and default access both synonymous with protected?Yes, it's almost the same. The protected modifier specifies that the member can only be accessed within its own package (as with package-private) and, , by a subclass of its class in another package. The \"default\" access modifier (the one where none of them are explicitly given) is \"package-private\", which means only things in the same package can access them. However, being in the same package implies nothing about the inheritance relationship between classes -- it's purely a naming convention.\"Protected\" means that not only classes in the same package, but also subclasses (regardless of which package those subclasses are in) will be able to access it.The default access for  is package-private, however the default access for  members is public.e.g.The default access rules for interfaces are not the same as for classes.package private and default access are synonym... An object also can access protected member of the objects whose classes are on the same package.. An object also can access protected member of its superclasses without a condition about their package. As a concrete example ;'Package private' and default access are the same. In early releases of the compiler around 1.1.2/3, 'package' was an allowed modifier, but ignored, meaning the same as no modifier, i.e. 'package private'. Shortly afterwards there was a short lived fashion for putting  (as a comment) in such situations. Similarly at that time you could declare things like synchronized classes, although again there was no actual semantic effect.Neither of them is the same as 'protected', which extends to derived classes in other packages.From  and  both are same, which means both can be used by any class till they are in same package.The  term, actually, is termed by the meaning of  modifier as  means it is available only in same class and no other classes or subclasses can access it within same package or without.Hence  means same as ."},
{"body": "I was wondering how Java orders items in the  ( or ) when they are added. Are the keys ordered by the hashcode, memory reference or by allocation precedence...?It's because I've noticed same pairs in the  are not always in the same order is unordered; you can't and shouldn't assume anything beyond that. uses insertion-order., a , uses either natural or custom ordering of the keys.First of all:  specifically  provide a stable and/or defined ordering. So anything you observe is simply an implementation detail and you  depend on it in any way.Since it is sometimes useful to know the reason for the seemingly random ordering, here's the basic idea:A  has number of buckets (implemented as an array) in which to store entries.When an item is added to the map, it is assigned to a buckets based on a value derived of its  and the bucket size of the . (Note that it's possible that the bucket is already occupied, which is called a collision. That's handled gracefully and correctly, but I'll ignore that handling for the description because it doesn't change the concept).The perceived ordering of the entires (such as returned by iterating over the ) depends on the order of the entries in those buckets.Whenever the size is rehashed (because the map exceeded its fullness threshold), then the number of buckets changes, which means that the position of each element might change, since the bucket position is derived from the number of buckets as well. does not sort at all. For a map that sorts by key values you should use  instead.From the JavaDocs for :From the documentation of :A  is not an ordered data structure - you should not rely on entries in a  being in a certain order. Some  implementations such as  and  do guarantee a certain order, but  does not.If you really want to know what happens internally, lookup the source code of  - you can find it in  which should be in your JDK installation directory.A  has a number of \"buckets\" in which it stores its entries. Which bucket an entry is stored in is determined by the hash code of the key of the entry. The order in which you see the entries in the  depends on the hash codes of the keys. But don't write programs that rely on entries being in a certain order in a  - the implementation might change in a future version of Java and your program then would not work anymore.hashmap has a not defined order of the elementsThere is no defined ordering in a hash table. Keys are placed into a slot, based on the hash code, but even that isn't a trivial order-by-hash-code.HashMap stores the values using the unique hash-value generated using a part of the key. This hash-value maps to the address where it is going to be stored. This is how it ensures an access O(1).LinkedHashmap on the other hand preserves the order in which you added to the map."},
{"body": "I'm new to Android programming and I'm having problems while passing an ArrayList of a Parcelable to a fragment.\nThis is the Activity that is launched(working well!) where  is an ArrayList of a parcelable .The fragment Activity onCreate() method:The Fragment code:I think the problem is in the line Finally this is my Music class:When I run this code the problem I get is a .\nI would appreciate a lot if someone pointed me in the right direction to see where I am failing.: Problem solved: I just needed to add this line to the fragment Activity onCreate() method(othwewise the getArguments() would return null):And add this to the fragment code:where, listMusics is an  of  Music.Two things. First I don't think you are adding the data that you want to pass to the fragment correctly. What you need to pass to the fragment is a bundle, not an intent. For example if I wanted send an  value to a fragment I would create a bundle, put the  into that bundle, and then set that bundle as an argument to be used when the fragment was created. Second to retrieve that information you need to get the arguments sent to the fragment. You then extract the value based on the key you identified it with. For example in your fragment:What you are getting changes depending on what you put. Also the default value is usually  but does not need to be. It depends on if you set a default value for that argument. Lastly I do not think you can do this in . I think you must retrieve this data within your fragment's  method. My reasoning is as follows.  runs after the underlying activity has finished its own  method. If you are placing the information you wish to retrieve within the bundle durring your activity's  method, it will not exist during your fragment's . Try using this in  and just update your  contents later. There is a simple why that I prefered to the bundle due to the no duplicate data in memory. It consists of a init public method for the fragment In two words, you create an instance of the fragment an by the init method (u can call it as u want) you pass the reference of your list without create a copy by serialization to the instance of the fragment. This is very usefull because if you change something in the list u will get it in the other parts of the app and ofcourse, you use less memory.I prefer  = no boilerplate code. For passing data to other Fragments or Activities  does not matter.I would also always provide a helper method for a  or , this way you always know, what data has to be passed. Here an example for your :great answer by @Rarw. Try using a bundle to pass information from one fragment to another"},
{"body": "I want to split a string by '=' charecter. But I want it to split on first instance only. How can I do that ? Here is a JavaScript example for '_' char but it doesn't work for me\nExample :When I try String.split('='); it gives But I needThanksAs  explains:Yes you can, just pass the integer param to the split methodHere is a java doc reference : As many other answers suggest the limit approach, This can be another wayYou can use the  method on String which will returns the first Occurance of the given character, Using that index you can get the desired outputString slpitString[] = stringInToSearch.split(\"pattern\", 2);i like writing own methods :)"},
{"body": "How can I extract a .war file with linux command prompt?Using Using Or A war file is just a zip file with a specific directory structure. So you can use unzip or the jar tool for unzipping. If you add the war file into the webapps directory of Tomcat the Tomcat will take care of extracting/installing the war file.You can use the  command."},
{"body": "For some reason Eclipse is no longer showing me Java compilation Errors in the Problems View.It is still showing Warnings.This has suddenly happened and I cannot think of anything that I have changed which would affect this.I am using the \"Maven Integration for Eclipse\" plugin but I have been for some time - not sure if this could have affected it or not.Any ideas?I had same problem and randomly did such things as (several times): 1) Project->Clean..., \n2) close and open Eclipse again, \n3) Run As...And it started to work again, without changing configuration.Right-click your project and go to Properties > Java Build Path > Source.Make sure your source directory (for example MyProject/src) is listed as a Source folder. Otherwise you won't get any red markers.I want to post my story here if Google brings you to this question.Somehow, \"Project->Build Automatically\" got turned off.Turning it back on produces correct errors list.In my case it has nothing to do with m2e 1.0.  This is default behavior for any Java project and goes back as far as Ganymede ( at the point of writing this post I am running Indigo )This is not totally an answer to your question, but is related. I thought eclipse stopped showing red/yellow flags next to files in my project. The solution was very simple - I was looking at the  tab (which doesn't show error/warning flags) instead of the  tab.I installed and deinstalled ajdt-plugin and got the same problem.Check .\nIt should have a 'Java Builder'.This code should be in the .project file (file is in the root of your project):I have the same problem in slight different situation. I have a parent POM and multiple modules under it. Project was existing and I imported it into eclipse. I can change the \"Dependency management\" only to parent project but not projects under it. They are not showing any compilation warnings. Next I'm going to try to change them all into individual projects... that's not what I wanted, but I haven't been able to solve this otherwise...I was experiencing this problem as well today.  The other solutions presented here (such as cleaning the project and restarting Eclipse) did not work or were not applicable to my setup.  What did work for me was right-clicking on the project in the Package Explorer and selecting Maven->Update Project Configuration.  Evidently some source folder restructuring I had done the previous day had caused Maven to lose track of things, and issuing this command fixed everything.At the top right corner of the problems window (next to minimize) there is a small arrow-icon. Click it  and select \"Configure filters\". There is a severity filter that might have been activated.On Ganymede, check the configuration of the Problem view:('Configure content') It can be set on 'any element in the same project' and you might currently select an element from the project.Or it might be set on a working set, and this working set has been modifiedMake sure that 'Match any configuration' is selected.I have also faced the same problem.After installing m2eclipse plugin, i was not getting any Java compilation errors. My solution was to enable dependency management by Select Project -> Right Click (to get context menu) -> m2 Maven -> Enable dependency management. Now i am able to view Java Compilation Errors. In my case Eclipse wasn't properly picking up a Java project that a current project was dependent on. You can go to Project > BuildPath > Configure BuildPath and then delete and re-add the project. There are obviously several reasons why this might occur, and I thought I'd add the solution to my issue. (I have a java project into which I have imported files with virtual links)If you have a situation like mine, you will have another folder on the same level as your 'src' folder. If you do, right-click on that other folder, then select 'Build Path' > 'Add to Build Path' (if you see 'Build Path' > 'Remove from Build Path', then it had already been added.)To further configure the Build Path, right click on your top level project dir, and select 'Build Path' > 'Configure Build Path'. Your folders should show up in the 'Source' tab.To configure what errors you see, Click on Java Compiler > Errors/Warnings and then click 'Configure Workspace Settings'. That is the same as going to Window > Preferences > Java > Compiler > Errors/Warnings. If you don't want Eclipse to ignore something, then just change it to Warning.I could reproduce this issue by creating an enumeration with a non-static member class and a static block enumerating its values:This class breaks the Ganymede compiler. If you delete the line in the static initializer block, the code compiles correctly again, and you get the error that there is no enclosing instance for the new Bar() call, as expected.-- correction: The above holds only if the project has gaeNature from Google Appengine. However, if you get an error similar as mentioned in the original question, you might be encountering another java compiler bug ...I have the same issue with Eclipse Helios and the m2eclipse plugin. They just can't seem to get this thing to work with WTP or WPT or whatever the blasted acronym is. If I do a clean on the project and watch the Maven console then I can see the compilation issues in the console but eclipse won't touch it. It seems eclipse or WTP/WPT and m2eclipse are busy playing slap hands.I experienced that problem with a MapReduce project. I closed the error window and never came back after doing what the other answers suggested.Click on the bottom left -> Kepler SP2, Java Project (Web Driver), and we use Gradle instead of MavenNone of the above helped, what did fix the problem for me was to select my projects (r-Click) > Gradle > Refresh AllIn my case I setted a old workspace and it was the problem.Try to set a new folder for workspaceI had same problem. In my case, I enable project specific setting the workspace setting. \nProject \u2192 Validation \u2192 mark \"Enabled project setting\"Edit: If \"Debug\" has been recently activated then check the top right of the program (under the Minimise button) and click back onto Java."},
{"body": "I have an ArrayList with values like \"abcd#xyz\" and \"mnop#qrs\". I want to convert it into an Array and then split it with # as delimiter and have abcd,mnop in an array and xyz,qrs in another array. I tried the following code:But it failed saying \"Ljava.lang.String;@57ba57ba\"Can you help me please. You don't need to reinvent the wheel, 's the  method:if you see the last line (new String[0]), you don't have to give the size, there are time when we don't know the length of the list, so to start with giving it as 0 , the constructed array will resize.What you did with the iteration is not wrong from what I can make of it based on the question. It gives you a valid array of String objects. Like mentioned in another answer it is however easier to use the toArray() method available for the ArrayList object => Just a side note. If you would iterate your dsf array properly and print each element on its own you would get valid output. Like this:What you probably tried to do was print the complete Array object at once since that would give an object memory address like you got in your question. If you see that kind of output you need to provide a toString() method for the object you're printing.Here is the solution for you given scenario - "},
{"body": "I am working in Windows Environment. And I am getting this error everytime as I am working with tomcat-I tried adding  in System Variables, still I am getting the same error  again and again. Any help will be appreciated. I have also read other post in stackoverflow also but it didn't worked out.The PermGen space is what Tomcat uses to store class definitions (definitions only, no instantiations) and string pools that have been interned. From experience, the PermGen space issues tend to happen frequently in dev environments really since Tomcat has to load new classes every time it deploys a WAR or does a jspc (when you edit a jsp file). Personally, I tend to deploy and redeploy wars a lot when I\u2019m in dev testing so I know I\u2019m bound to run out sooner or later (primarily because Java\u2019s GC cycles are still kinda crap so if you redeploy your wars quickly and frequently enough, the space fills up faster than they can manage).This should theoretically be less of an issue in production environments since you (hopefully) don\u2019t change the codebase on a 10 minute basis. If it still occurs, that just means your codebase (and corresponding library dependencies) are too large for the default memory allocation and you\u2019ll just need to mess around with stack and heap allocation. I think the standards are stuff like: I\u2019ve found however the best way to take care of that for good is to allow classes to be unloaded so your PermGen never runs out:Stuff like that worked magic for me in the past. One thing tho, there\u2019s a significant performance tradeoff in using those, since permgen sweeps will make like an extra 2 requests for every request you make or something along those lines. You\u2019ll need to balance your use with the tradeoffs.You have to allocate more space to the PermGenSpace of the tomcat JVM.This can be done with the JVM argument : By default, the PermGen space is 64M (and it contains all compiled classes, so if you have a lot of jar (classes) in your classpath, you may indeed fill this space).On a side note, you can monitor the size of the PermGen space with  and you can even inspect its content with To complement Michael's answer, and according to , a safe way to deal with the problem is to use the following arguments:If tomcat is running as Windows Service neither CATALINA_OPTS nor JAVA_OPTS seems to have any effect.You need to set it in Java options in GUI.The below link explains it wellIn Tomcat 7.0 Windows Service Installer Version.There is not catalina.bat in /bin .\nSo you need open Tomcat7w.exe in /bin and add blow JVM argumenton Java Option in Java Tab, like this. You also add other options.Another, if you use IntellijIDEA you need add JVM argument in Server Configurations,like this.@AndreSmiley 's code of line worked for me.only modification required is.-XX:MaxPermSize=256\"m\" means MB.Actually my application is kinda huge so i was advised to make it 1024m for performance.This one worked for me, in  the following line needs to be added if it doesn't exist  with the value . The full line:I'm running tomcat7 on CentOS 6.6. I tried creating a new /usr/share/tomcat/bin/setenv.sh file and setting both  and . But tomcat wouldn't pick up the values on restart. When I put the following line into /etc/tomcat/tomcat.conf:tomcat did pick up the new environment variable. I verified this by runningand seeing the new settings in the output. This took a long time to diagnose and I didn't see anyone else suggesting this, so I thought I'd throw it out to the internet community.Killing the tomcat process(forcefully, kill -9 for Linux) and starting it again solves the issue. My guess is, the tomcat instance doesn't get killed properly using shutdown.bat. So, we need to forcefully kill the process and start again."},
{"body": "I am relatively new to matchers. I am toying around with  in combination with JUnit and I kinda like it.Is there a way, to state that one of multiple choices is correct?Something likeThe method I am testing returns one element of a collection. The list may contain multiple candidates. My current implementation returns the first hit, but that is not a requirement. I would like my testcase to succeed, if any of the possible candidates is returned. How would you express this in Java?(I am open to hamcrest-alternatives)From : See also .Moreover, you could write your own Matcher, what is quite easy to do.marcos is right, but you have a couple other options as well. First of all, there  an either/or:but if you have more than two items it would probably get unwieldy. Plus, the typechecker gets weird on stuff like that sometimes. For your case, you could do:or if you already have your options in an array/Collection:See also ."},
{"body": "I'm quite confused about the basic concepts of a Hash table. If I were to code a hash how would I even begin? What is the difference between a Hash table and just a normal array? Basically if someone answered this question I think all my questions would be answered:\nIf I had 100 randomly generated numbers (as keys), how would I implement a hash table and why would that be advantageous over an array?Psuedo-code or Java would be appreciated as a learning tool...The answers so far have helped to define hash tables and explain some theory, but I think an example may help you get a better feeling for them.A hash table and an array are both structures that allow you to store and retrieve data.  Both allow you to specify an  and retrieve a value associated with it.  The difference, as Daniel Spiewak noted, is that the indices of an array are , while those of a hash table are based on the  associated with them.A hash table can provide a very efficient way to search for items in large amounts of data, particularly data that is not otherwise easily searchable.  (\"Large\" here means , in the sense that it would take a long time to perform a sequential search).No problem.  The simplest way is to invent an arbitrary mathematical operation that you can perform on the data, that returns a number  (usually an integer).  Then use that number as the index into an array of \"buckets\" and store your data in bucket #.  The trick is in selecting an operation that tends to place values in different buckets in a way that makes it easy for your to find them later.  A large mall keeps a database of its patrons' cars and parking locations, to help shoppers remember where they parked.  The database stores , , , and .  On leaving the store a shopper finds his car by entering the its make and color.  The database returns a (relatively short) list of license plates and parking spaces.  A quick scan locates the shopper's car.You could implement this with an SQL query:If the data were stored in an array, which is essentially just a list, you can imagine implementing the query by scanning an array for all matching entries.On the other hand, imagine a hash rule:This rule will convert each item to a number between 0 and 99, essentially  the data into 100 buckets.  Each time a customer needs to locate a car, you can hash the make and color to find the  bucket out of 100 that contains the information.  You've immediately reduced the search by a factor of 100!Now scale the example to huge amounts of data, say a database with millions of entries that is searched based on tens of criteria.  A \"good\" hash function will distribute the data into buckets in a way that minimizes any additional searching, saving a significant amount of time.First, you have to understand a what a hash function is.\nA hash function is a function that takes a key (for example, an string of arbritrary length) and returns a number . The same key must always return the same hash. A really simple string hashing function in java might look likeYou can study a good hash function at Now, the hash map uses this hash value to place the value into an array. Simplistic java method:(This map enforces unique keys. Not all maps do.)It is possible for two different keys to hash to the same value, or two different hashes to map to the same array index. There exists many techniques for dealing with this. The simplest is to use a linked list (or binary tree) for each array index. If the hash function is good enough, you will never need a linear search.Now to look up a key:Hashtables are .  This is a huge difference from arrays, which are just linear data structures.  With an array, you might do something like this:Notice how you are getting an element out of the array by specifying an exact memory offset ().  This contrasts with hashtables, which allow you to store key/value pairs, later retrieving the value based on the key:With the above table, we can make the following call:...and be assured that  will be valued at .I think this will probably answer most of your questions.  The implementation of a hashtable is a fairly interesting topic, one .\"I'm more interested in the way Hash Tables look up the key and how the key is generated.\"That's the general solution.  Two numeric calculations and you've gone from arbitrary object as key to arbitrary object as value.  Few things can be as fast.The transformation from object to hash value happens in one of these common ways.The slot in the hash table is mod( number, size of table ).If that slot has the desired value, you're done.  If that's not the desired value, you need to look somewhere else. There are several popular probing algorithms to look for a free spot in the table.  Linear is a simple search for the next free spot.  Quadratic is a non-linear hopping around looking for a free slot.  A random number generator (with a fixed seed) can be used to generate a series of probes that will spread data evenly but arbitrarily.The probing algorithms are not (1).  If the table's big enough, the odds of collision are low, and probes don't matter.  If the table's too small, then collisions happen and probing happens.  At that point, it becomes a matter of \"tuning and tweaking\" to balance probing and table size to optimize performance.  Usually we just make the table bigger.See .Something I didn't see specifically noted yet:The point of using a hash table over an array is performance. Iterating through an array would typically take anywhere from O(1) to O(x) where x is the number of items in the array. However the time to find your item will be extremely , expecially if we are talking about hundreds of thousands of items in the array.A properly weighted hash table typically has an almost  access time of just over O(1), no matter how many items are in the hash table.You wouldn't want to use a hash table for 100 randomly generated numbers.A good way to think about hash tables is to think about value pairs.  Let's use students, and say everyone has a student ID number.  In your program you store information on students (names, phone numbers, bills, etc).  You want to find all of the information about a student using only basic information (name or student ID, for example).Let's say you have 10,000 students.  If you store them all in an array, then you have to loop through the entire array comparing each entry's student ID with the one you are looking for.If, instead, you \"hash\" (see below) their student ID number to a position in the array, then you only have to search student's who's numbers have the same hash.  Much less work to find what you wanted.In this example, let's say student IDs are just 6 digit numbers.  Our hash function could be use only the bottom 3 digits of the number as the \"hash key\".  Thus 232145 is hashed to array location 145.  So then you only need an array of 999 element (each element being a list of students).That should be a good start for you.  You should, of course, read a text book or wikipedia for this kind of info.  But I assume you've already done that and are tired of reading.Here is, in short, how a hash table works.Imagine you have a library, full of books.  If you were to store the books in an array, you would put each book on a spot on a shelf, and then when someone asked you to find a book, you'd look through all the shelves -- pretty slow.  If someone said \"book #12345\", you could find it pretty easily, though. Let's say instead you say, if the book title starts with 'A', it goes in row 1. If the second letter is 'B', it goes in row 1, rack 2.  If the third letter is 'C', it goes in row 1, rack 2, shelf 3... and so on until you identify the book position.  Then, based on the title of the book, you could know exactly where it should be.Now, there are some problems in the simplistic \"hashing\" algorithm I described -- some shelves are going to be way overloaded while others stand empty, some books will be assigned to the same slot.. so the real hash functions are carefully constructed to try to avoid such problems.  But this is the basic idea.I'll answer that part about the difference between a hash table and an array... but since I've never implemented a hashing algorithm of any import before, I'll leave that to somebody more knowledgeable :)An array is just an ordered list of objects. The object itself doesn't really matter... what's important is that if you want to list the objects in order of insertion, it is always the same (meaning that the first element  has an index of 0).As for a hashtable, that's indexed by keys, not order... I think that a basic search on hashing algorithms will give you a lot more insight than I can... Wikipedia has a very decent one... that determines \"bucket\" that the keys go into for quick retrieval on arbitrary objects used as keys.As for advantages: If order of insertion is important, an array or some kind of ordered list is necessary. If fast look-up by arbitrary key (keyed by various hash functions) is important, then a hash table makes sense.That depends on your hash function. Lets suppose that your hash function hashes a word as per the length of your word, the key for chris will be 5. Similarly, key for yahoo will also be 5. Now, both values (chris and yahoo) will go under 5 (i.e. in a 'bucket' keyed by 5). This way you don't have to make an array equal to the size of your data.The question, I believe, is answered quite clearly and in many different ways by now.I would just like to add another perspective (which may confuse a new reader as well)At a level of least abstraction, arrays are just contiguous block of memory. Given the starting address (), size () and the  of a single element, the address of element is computed as:The interesting thing to note here is that arrays can be abstracted/viewed as hash tables with  as key and the above function as a hash function which calculates the location of a value in Hash table is a data structure that is created for quick look up.The hash tables are not effective when the number of entries are very small.Some examples:Output:The hash algorithm is used to generate an index into that array based on the values of the item that will be stored in the array. The maximum size of this array is typically smaller than the number of items in the set of possible values for the type of data being stored in the hashtable. When an element is added to the Hashtable , the element is placed into a bucket based on the hash code of the key. Each bucket can have multiple records which are organized in a particular order. Subsequent lookups of the key use the hash code of the key to search in only one particular bucket, thus substantially reducing the number of key comparisons required to find an element. The load factor of a Hashtable determines the maximum ratio of elements to buckets. Smaller load factors cause faster average lookup times at the cost of increased memory consumption. An instance of Hashtable has two parameters that affect its performance: initial capacity and load factor . More about...Rj"},
{"body": "after some days of trying and waitin' for answers on the springsource forums I'll try it here.\nRunning my application results in these exception:Here's the relevant codeapplication context:com.example.my.entities.user:service:Multiple things can cause this, I didn't bother to check your entire repository, so I'm going out on a limb here.First off, you could be missing an annotation (@Service or @Component) from the implementation of , if you're using annotations for configuration. If you're using (only) xml, you're probably missing the  -definition for the UserService-implementation.If you're using annotations and the implementation is annotated correctly, check that the package where the implementation is located in is scanned (check your  -value).Add this to you applicationContext:Add annotation @Repository to the head of userDao Class.If userDao is a interface,add this annotation to the implements of the interface.I have similar trouble in test config, because of using AOP.\nI added this line of code in spring-config.xmlAnd it works !I had a similar issue but I was missing the (@Service or @Component) from the implementation of com.example.my.services.myUser.MyUserServiceImplIF this is only occurring on deployments, be sure that you have the dependency of the package you are referencing in the .war.  For instance, this was working locally on my machine, with debug configurations working fine, but after deploying to Amazon's Elastic Beanstalk , I received this error and noticed one of the dependencies was not bundled in the .war package.  I had the same issue but in my case, implemented class was accidently become 'abstract' as a result autowiring was failing.In my case it was the wrong dependecy for CrudRepository. My IDE added also follwing:But I just needed:I removed the first one and everything was fine."},
{"body": "I am trying to keep a temporary container of a class that contains member :A class called myobjectsListThen I do then: Add some hashmap items to A (like2)thenthen: Add hashmap items to A; (like 4 more)then return A to the items stored in B;but when I do this B grows with A while I am adding hashmap items to A.\nA now has 6 items in it because B had 6.I want A to have original 2 still at end after last assingment\nin C++ i would use copy with objects, what is the java equivalent?Added: OK I left something out explaining this.MyObjectsList does not contain the HashMap, it is derived from a class MyBaseOjbectsList which has the HashMap member and MyObjectsList extends MyBaseOjbectsList. Does this make a difference.?If you want a copy of the HashMap you need to construct a new one with.This will create a (shallow) copy of the map.You can also useMethod to copy all elements from one hashmap to another hashmap Program for copy all elements from one hashmap to anothersource :  The difference is that in C++ your object is on the stack, whereas in Java, your object is in the heap. If A and B are Objects, anytime in java you doB = AA and B point to the SAME object. So anything you do to A you do to B and vice versause new HashMap() if you want two different objectsAnd you can use Map.putAll(...) to copy data between two MapsHere is small (HUGE) understatement. Because if you want to copy  that is more structured  will cope the value, because it doesn't know how to exactly copy you object. For example So basicaly you will need to copy all by yourself like hereIn Java, when you write: and  are the same and point to the same reference. Changing one will change the other. So if you change the state of  (not its reference)  will reflect that change too.However, if you write:Then  is still pointing to the first object you created (original ) while  is now pointing to a new Object.Since this question is still unanswered and I had a similar problem, I will try to answer this. The problem (as others already mentioned) is that you just copy references to the same object and thus a modify on the copy will also modify the origin object. So what you have to to is to copy the object (your map value) itself. The far easiest way to do so is to make all your objects implementing the serializeable interface. Then serialize and deserialize your map to get a real copy. You can do this by yourself or use the apache commons SerializationUtils#clone() which you can find here:   But be aware this is the simplest approach but it is an expensive task to serialize and deserialize a lot of objects.What you assign one object to another, all you're doing is copying the  to the object, not the contents of it. What you need to do is take your object B and manually copy the contents of object A into it. If you do this often, you might consider implementing a  method on the class that will create a new object of the same type, and copy all of it's contents into the new object."},
{"body": "I have the following code snippet:Here, how do I call the  method for the thread without creating an instance of the thread class?You're already creating an instance of the Thread class - you're just not doing anything with it. You  call  without even using a local variable:... but personally I'd normally assign it to a local variable, do anything else you want (e.g. setting the name etc) and then start it:Since anonymous classes extend the given class you can store them in a variable.eg.Alternatively, you can just call the start method on the object you have immediately created.Though personally, I would always advise creating an anonymous instance of Runnable rather than Thread as the compiler will warn you if you accidentally get the method signature wrong (for an anonymous class it will warn you anyway I think, as anonymous classes can't define new non-private methods).egNot exactly sure this is what you are asking but you can do something like:Notice the  method at the end of the anonymous class.  You create the thread object but you need to start it to actually get another running thread.Better than creating an anonymous  class is to create an anonymous  class:Instead overriding the  method in the  you inject a target  to be run by the new thread.  This is a better pattern.Just call start()The entire  expression is an object reference, so methods can be invoked on it:"},
{"body": "Ive got the following if statement:I want it to include startsWith  'Mon' 'Tues' 'Weds' 'Thrus' 'Friday' etc. Is there a simple way to this when using strings? I tried '||' but it didn't work...Thanks!Do you mean:or you could use regular expression:Besides the solutions presented already, you could use the Apache Commons Lang library:A simple solution is:A fancier solution would be:No one mentioned  so far, so here it is:Of course, be mindful that your program will only be useful in english speaking countries if you detect dates this way.  You might want to consider:  From there you can use .startsWith or .matches or whatever other method that others have mentioned above.  This way you get the default locale for the jvm.  You could always pass in the locale (and maybe default it to the system locale if it's null) as well to be more robust.You need to include the whole  for each item, since  only works with boolean expressions (true or false).There are other options if you have a lot of things to check, like , but they tend to be slower and more complicated regular expressions are generally harder to read.An example regular expression for detecting day name abbreviations would be:When you say you tried to use OR, how exactly did you try and use it? In your case, what you will need to do would be something like so:"},
{"body": "I am learning Java EE and I downloaded the eclipse with glassfish for the same. I saw some examples and also read the Oracle docs to know all about Java EE 5. Connecting to a database was very simple. I opened a dynamic web project, created a session EJB and  I used EntityManager and with the get methods could access the stored data table.For my next project I had create a simple class and then access some DB table. The very first problem I encuntered was, that the PersistenceUnit attribute would only be recognised by EJB,Servlet etc and not a simple java class. So then I could not use the EntityManager way(or can I?) I was asked to go via the \"JDBC\" way. The very first problem I encountered was to get the connection to the DB. It seems all this must be hardcoded. I had a persistence.xml with which I could easily configure the data base connection. Even setting up a driver for the DB was easy. Also there no get/set methods in the JDBC for accessing table entities.How do I understand JPA and persistence in relation to JDBC? What was JPA thought for? Why is there set/get methods? Can someone throw some light on the essence of these two and what are the pros/cons without \"jargons\"?? Please also suggest some links. A simple google search for JPA and JDBC differences led me to some sites full of \"terminology\" I couldn't follow :(Layman's terms:  is a standard for connecting to a DB directly and running SQL against it - e.g SELECT * FROM USERS, etc.  Datasets can be returned which you can handle in your app, and you can do all the usual things like INSERTS, DELETES, run stored procedures, etc.  It is one of the underlying technologies behind most java database access (including  providers).One of the issues with traditional  apps is that you can often have some crappy code where lots of mapping between datasets and objects occur, logic is mixed in with SQL, etc. is a standard for Object Relational Mapping. This is a technology which allows you to map between objects in code and database tables.  This can \"hide\" the SQL from the developer so that all they deal with are java classes, and the provider allows you to save them and load them magically.  Mostly, XML mapping files or annotations on getters, setters can be used to tell the JPA provider which fields on your object map to which fields in the DB.  The most famous JPA provider is Hibernate, so is a good place to start for concrete examples. Other examples include OpenJPA, toplink, etc.Under the hood, Hibernate and most other providers for JPA write SQL and use JDBC to read and write to the DB.  Main difference between JPA and JDBC is level of abstraction.JDBC is a low level standard for interaction with databases. JPA is higher level standard for the same purpose. JPA allows you to use an object model in your application which can make your life much easier. JDBC allows you to do more things with the Database directly, but it requires more attention. Some tasks can not be solved efficiently using JPA, but may be solved more efficiently with JDBC. JDBC is a much lower-level (and older) specification than JPA. In it's bare essentials, JDBC is an API for interacting with a database using pure SQL - sending queries and retrieving results. It has no notion of objects or hierarchies. When using JDBC, it's up to you to translate a result set (essentially a row/column matrix of values from one or more database tables, returned by your SQL query) into Java objects.Now, to understand and use JDBC it's essential that you have some understanding and working knowledge of SQL. With that also comes a required insight into what a relational database is, how you work with it and concepts such as tables, columns, keys and relationships. Unless you have at least a basic understanding of databases, SQL and data modelling you will not be able to make much use of JDBC since it's really only a thin abstraction on top of these things.JDBC is the predecessor of JPA. JDBC is a bridge between the Java world and the databases world. In JDBC you need to expose all dirty details needed for CRUD operations, such as table names, column names, while in JPA (which is using JDBC underneath), you also specify those details of database metadata, but with the use of Java annotations. So JPA creates update queries for you and manages the entities that you looked up or created/updated (it does more as well).If you want to do JPA without a Java EE container, then Spring and its libraries may be used with the very same Java annotations."},
{"body": "I am using the JSON library provided here  to convert a json string I have to CSV.\nBut the problem I have is, the order of the keys is lost after conversion.This is the conversion code:This is the content of \"someString\":This is the result:While what I expect is to keep the order of the keys:Is there any way I can have this result using this library? If not, is there any other library that will provide the capability to keep the order of keys in the result?There are (hacky) ways to do it ... but you shouldn't.In JSON, an object is defined thus:See .Most implementations of JSON make no effort to preserve the order of an object's name/value pairs, since it is (by definition) not significant.If you want order to be preserved, you need to redefine your data structure; e.g.or more simply:You need to have a hard conversation with whoever designed that file structure and won't let you change it.  It is / they are plain wrong.  You  to convince them.If they  won't let you change it:This kind of thing as really bad.  On the one hand, your software will be violating a well established / long standing specification that is designed to promote interoperability.  On the other hand, the nit-wits who designed this lame (not JSON!) file format are probably slagging off other people's systems etc 'cos the systems cannot cope with  nonsense.It is also worth reading what the  says on this subject.  Here are some excerpts:It is quite simple to maintain order. I had the same problem with maintaining the order from DB layer to UI Layer.Open JSONObject.java file. It internally uses HashMap which doesn't maintain the order.Change it to LinkedHashMap:This worked for me. Let me know in the comments. I suggest the JSON library itself should have another JSONObject class which maintains order, like JSONOrderdObject.java. I am very poor in choosing the names.  takes whatever map you pass. It may be  or  and  it will take  only when the map is null .Here is the constructor of  class that will do the checking of map.So before building a json object construct  and then pass it to the constructor like this ,A more verbose, but broadly applicable solution to this sort of problem is to use a pair of data structures: a list to contain the ordering, and a map to contain the relations.For Example:You iterate the itemOrder list, and use those to look up the map values.  Ordering is preserved, with no kludges.I have used this method many times.Another hacky solution using reflect:Apache Wink has . It keeps the order while parsing the String.Solved.I used the JSON.simple library from here  to read the JSON string to keep the order of keys and use JavaCSV library from here  to convert to CSV format.I know this is solved and the question was asked long time ago, but as I'm dealing with a similar problem, I would like to give a totally different approach to this:For arrays it says \"An array is an ordered collection of values.\" at  - but objects (\"An object is an unordered set of name/value pairs.\") aren't ordered.I wonder why that object is in an array - that implies an order that's not there.So a solution would be to put the keys in a \"real\" array and add the data as objects to each key like this:So this is an approach that tries to rethink the original modelling and its intent. But I haven't tested (and I wonder) if all involved tools would preserve the order of that original JSON array.Just stumbled upon the same problem, I believe the final solution used by the author consisted in using a custom ContainerFactory:see \nThe most safe way is probably overriding keys method that is used to generate output:patchFor(answer @gary) : You can use the following code to do custom ORDERED serialization and deserialization of JSON Array (This example assumes you are ordering Strings but can be applied to all types):Your example:add an element \"itemorder\"This code generates the desired output without the column title line:In the real world, an application will almost always have java bean or domain that is to be serialized/de-serialized to/from JSON. Its already mentioned that JSON Object specification does not guarantee order and any manipulation to that behavior does not justify the requirement. \nI had the same scenario in my application where I needed to preserve order just for the sack of readability purpose. I used standard jackson way to serialize my java bean to JSON:In order to make the json with an ordered set of elements I just use JSON property annotation in the the Java bean I used for conversion. An example below:the getObject() used above:The output shows as per Json property order annotation:Tested the wink solution, and working fine:"},
{"body": "I want to change server location but I can't it's greyed (I cannot select last radio button) how can I do it then:On the  view, delete all the webapps published under your server (right click on the server >  or right click on the server >  and  then remove manually the webapps) and finally right click on the server >  (the 'empty' content). This way you would un-gray the  area.As the dialog says : \"Server must be published with no modules present to make changes.\" \nStop the server remove any modules. After that the options will be enabled.If you are still dont see the option enabled, start the tomcat and then it will be enabled."},
{"body": "Suppose I create a temporary file in Java with the methodIf I do not explicity call the  method, when will the file be deleted?As an intuition, it might be when the JVM terminates, or  (by the Garbage Collector), or  (by some Operating System sweeping process).The file won't be deleted automatically, from the :So you have to explicitly call :As the other answers note, temporary files created with  will  be deleted automatically unless you explicitly request it.The generic, portable way to do this is to call  on the  object, which will schedule the file for deletion when the JVM terminates.  A slight disadvantage of this method, however, is that it only works if the VM terminates normally; on an abnormal termination (i.e. a VM crash or forced termination of the VM process), the file might remain undeleted.On Unixish systems (such as Linux), it's actually possible to obtain a somewhat more reliable solution by deleting the temporary file .  This works because Unix filesystems allow a file to be deleted (, to be precise) while it's still held open by one or more processes.  Such files can be accessed normally through the open filehandle, and the space they occupy on disk will only be reclaimed by the OS after the last process holding an open handle to the file exits.So here's the most reliable and portable way I know to ensure that a temporary file will be properly deleted after the program exits:On a Unixish system, running this should produce something like the following output:whereas on Windows, the output looks slightly different:In either case, however, the temp file should not remain on the disk after the program has ended. While testing this code on Windows, I observed a rather surprising fact: apparently, merely .  Of course, this also means that any crash that happens while the temp file is in use will cause it to be left undeleted, which is exactly what we're trying to  here.AFAIK, the only way to avoid this is to ensure that the temp file  gets closed using a  block.  Of course, then you could just as well delete the file in the same  block too.  I'm not sure what, if anything, using  would actually gain you over that.It won't, at least not by Java.  If you want the file to be deleted when the JVM terminates then you need to call .from: For example,The above example will create a temporary file named \u201cabc.tmp\u201d and .If you want , you can still use the File.delete().Temporary file is used to store the less important and temporary data, which should always be deleted when your system is terminated. The best practice is use the File.deleteOnExit() to do it.For example,The above example will create a temporary file named \u201cabc.tmp\u201d and delete it when the program is terminated or exited.You can manually delete the file before terminating the process if you want to, however when the process is terminated the file will be deleted as well."},
{"body": "I have a JUnit test that fails because the milliseconds are different.  In this case I don't care about the milliseconds.  How can I change the precision of the assert to ignore milliseconds (or any precision I would like it set to)?Example of a failing assert that I would like to pass:Use a  object with a format that shows only the parts you want to match and do an  on the resulting Strings. You can also easily wrap that in your own  method.Yet another workaround, I'd do it like this:There are libraries that help with this:If you have  on your classpath, you can use  to truncate the dates to some field.There is a shorthand for this:Note that 12:00:00.001 and 11:59:00.999 would truncate to different values, so this might not be ideal. For that, there is round:Starting with version 3.7.0,  added an  assertions, if you are using the Java 8 Date / Time API.It also works with legacy java Dates as well:You could do something like this:No String comparisons needed.I don't know if there is support in JUnit, but one way to do it:In JUnit you can program two assert methods, like this:This is actually a harder problem than it appears because of the boundary cases where the variance that you don't care about crosses a threshold for a value you are checking.  e.g. the millisecond difference is less than a second but the two timestamps cross the second threshold, or the minute threshold, or the hour threshold.  This makes any DateFormat approach inherently error-prone.Instead, I would suggest comparing the actual millisecond timestamps and provide a variance delta indicating what you consider an acceptable difference between the two date objects.  An overly verbose example follows:Using JUnit 4 you could also implement a  for testing dates according to your chosen precision. In this example the matcher takes a string format expression as a parameter. The code is not any shorter for this example. However the matcher class may be reused; and if you give it a describing name you can document the intention with the test in an elegant way. use AssertJ assertions for Joda-Time ()the test failing message is more readableIf you were using Joda you could use .Just compare the date parts you're interested in comparing:JUnit has a built in assertion for comparing doubles, and specifying how close they need to be.  In this case, the delta is within how many milliseconds you consider dates equivalent.  This solution has no boundary conditions, measures absolute variance, can easily specify precision, and requires no additional libraries or code to be written. It must be 100.0 instead of 100 (or a cast to double is needed) to force it to compare them as doubles.Something like this might work:Instead of using  directly, you can create a small collaborator, which you can mock out in your test:Create a DateBuilder member and change calls from  to The main method will produce:In the test you can inject a stub of  and let it return any value you like. For example with Mockito or an anonymous class which overrides :Convert the dates to String using SimpleDateFromat, specify in the constructor the required date/time fields and compare the string values:I did a small class that might be useful for some googlers that end up here : i cast the objects to java.util.Date and compare"},
{"body": "We know that quick sort is the best sorting algorithm.The collections.sort used merge sort algorithm instead of quick sort. But Arrays.sort uses quick sort.What is the reason Collections.sort uses merge sort instead of quick sort? Highly likely from Josh Bloch :Also, the  is relevant:Also, see .There isn't a single \"best\" choice. As with many other things, it's about tradeoffs."},
{"body": "Is it possible for a spring controller to handle both kind of requests? If I define a single controller of the kind:the HTTP Request with \"logout\" is not accepted.If I define two controllers to handle each request separately, Spring complains with the exception \"There is already 'Controller' bean method ... mapped\".You need to give  for  and  request parameters as well. That's because, when you provide just the  parameter, it actually expects for  and  as well as they are still mandatory.It worked when you just gave  and  because  wasn't a mandatory parameter thanks to  already given for .Create 2 methods which handle the cases. You can instruct the  annotation to take into account certain parameters whilst mapping the request. That way you can nicely split this into 2 methods. As part of  onwards you now have full support of Java 8  () therefore in your example both requests will go via your single mapping endpoint as long as you replace  with Optional for your 3 params logout, name, password:"},
{"body": "I am trying to convert a string encoded in java in UTF-8 to ISO-8859-1. Say for example, in the string '\u00e2abcd'  '\u00e2' is represented in ISO-8859-1 as E2. In UTF-8 it is represented as two bytes. C3 A2 I believe. When I do a getbytes(encoding) and then create a new string with the bytes in ISO-8859-1 encoding, I get a two different chars. \u00c3\u00a2.  Is there any other way to do this so as to keep the character the same i.e. \u00e2abcd?If you're dealing with character encodings other than UTF-16, you shouldn't be using  or the  primitive -- you should only be using  arrays or  objects.  Then, you can use  to convert between encodings:Will do the trick. From your description it seems as if you're trying to \"store an ISO-8859-1 String\". String objects in Java are  implicitely encoded in UTF-16. There's no way to change that encoding.What you can do, 'though is to get the bytes that constitute some other encoding of it (using the .getBytes() method as shown above).Starting with a set of bytes which encode a string using UTF-8, creates a string from that data, then get some bytes encoding the string in a different encoding:this outputs strings and the iso88591 bytes correctly:So your byte array wasn't paired with the correct encoding: Outputs(either that, or you just wrote the utf8 bytes to a file and read them elsewhere as iso88591)This is what I needed:If you have the correct encoding in the string, you need not do more to get the bytes for another encoding.Output:For files encoding...In addition to Adam Rosenfield's answer, I would like to add that  returns the buffer's underlying byte array, which is not necessarily \"trimmed\" up to the last character. Extra manipulation will be needed, such as the ones mentioned in  answer; in particular:evict non ISO-8859-1 characters, will be replace by '?'\n(before send to a ISO-8859-1 DB by example):utf8String = new String ( utf8String.getBytes(), \"ISO-8859-1\" );"},
{"body": "How can one make a Java class immutable, what is the need of immutability and is there any advantage to using this?An immutable object is one that will not change state after it is instantiated.In general, an immutable object can be made by defining a class which does not have any of its members exposed, and does not have any setters.The following class will create an immutable object:As can be seen in the above example, the value of the  can only be set when the object is instantiated, and by having only a getter () the object's state cannot be changed after instantiation.However, there must be care taken that all objects that are referenced by the object must be immutable as well, or it could be possible to change the state of the object. For example, allowing an reference to an array or  to be obtained through an getter will allow the internal state to change by changing the array or collection:The problem with the above code is, that the  can be obtained through  and be manipulated, leading to the state of the object itself to be altered, therefore, not immutable.One way to get around this problem is to return a copy of an array or collection when called from a getter:The advantage of immutability comes with concurrency. It is difficult to maintain correctness in mutable objects, as multiple threads could be trying to change the state of the same object, leading to some threads seeing a different state of the same object, depending on the timing of the reads and writes to the said object.By having an immutable object, one can ensure that all threads that are looking at the object will be seeing the same state, as the state of an immutable object will not change.In addition to the answers already given, I'd recommend reading about immutability in Effective Java, 2nd Ed., as there are some details that are easy to miss (e.g. defensive copies). Plus, Effective Java 2nd Ed. is a must-read for every Java developer.You make a class immutable like this: Immutable classes are useful because they're thread-safe.  They also express something deep about your design: \"Can't change this.\"  When it applies, it's exactly what you need.Ans) Immutable class is a class which once created, it\u2019s contents can not be changed. Immutable objects are the objects whose state can not be changed once constructed. e.g. String classAns) To create an immutable class following steps should be followed:Immutability can be achieved mainly in two ways:Advantages of immutability are the assumptions that you can make on these object:Immutable classes cannot reassign values after it is instantiated.The constructor assign values to its private variables. Until the object becomes null, values cannot be changed due to unavailability of setter methods.to be immutable should satisfy following,Advanteges:\nImmutable objects contains its initialized values until it dies.In short, an Immutable class is a class whose instances cannot be modified. The information contained in each immutable object is provided when it is created and is frozen for its lifetime.  Once an Immutable object has been created, it is read only, forever fixed, like a fossil.As a good programming practice in Java one should try to use immutable objects as far as possible. Immutability can have a performance cost, since when an object cannot be mutated we need to copy it if we want to write to it. When you care a lot about performance (e.g. programming a game) it may be necessary to use a mutable object. Even then it is often better to try to limit the mutability of objects.Since immutable object can not be reused and they are just a use and throw. String being a prime example, which can create lot of garbage and can potentially slow down application due to heavy garbage collection. are those whose objects cannot be changed after creation.Immutable classes is useful forString Class"},
{"body": "I'm using Spring Security 3 and Spring MVC 3.05.I would like to print username of currently logged in user,how can I fetch UserDetails in my Controller?If you already know for sure that the user is logged in (in your example if  is protected):To first check if the user is logged in, check that the current  is not a .Let Spring 3 injection take care of this.Thanks to  the easiest way is:If you just want to print user name on the pages, maybe you'll like this solution. It's free from object castings and works without Spring Security too:Note \"\" parameter added.Works fine because Spring injects it's own objects (wrappers) for HttpServletRequest, Principal etc., so you can use standard java methods to retrieve user information.if you are using spring security then you can get the current logged in user byThat's another solution (Spring Security 3):"},
{"body": "I am still quite new to java programming and I am trying to update existing value of Array list by using this codeI want to print  instead of  but I got  as the result, I still have \"Two\". I want to print . How do I do this?\nThank You..Use the  method to replace the old value with a new one.Use : To replace the existing element at specified position in Arraylist use the method,in your code block  you are using  This method inserts the specified element at the specified position in this list.Below are the few difference between add and set method,The  replaces the element at the specified position in this list with the specified element.here int index is index of the element to replace and element is element to be stored at the specified position.\nIf the index is out of range then it will throw the  exception.\nThis method returns the element previously at the specified position.method inserts the specified element E at the specified position in this list.It shifts the element currently at that position (if any) and any subsequent elements to the right (will add one to their indices).This method does not return any value.and it will also throw the  exception if the index is out of range.U must use  first.Your elements will become like this.then add this Your elements will become like this. "},
{"body": "My web server would be overloaded quickly if all the work were done there.  I'm going to stand up a second server behind it, to process data.What's the advantage of EJB over RMI, or vice versa?  What about web services (SOAP, REST)?EJBs are built on top of RMI.  Both imply Java clients and beans.  If your clients need to be written in something else (e.g., .NET, PHP, etc.) go with web services or something else that speaks a platform-agnostic wire protocol, like HTTP or XML over HTTP or SOAP.If you choose RMI, you don't need a Java EE EJB app server.  You have to keep client and server JVMs in synch; you can't upgrade the client without upgrading the server.  You have to write all the services that the EJB app server provides for you (e.g., connection pooling, naming and directory services, pooling, request queuing, transactions, etc.).RMI is quite low level when you think about it.  Why would you drop all the way back to CORBA?A better choice is EJB 3.0 versus Spring.  It depends on whether you like POJO development, want a choice of relational technologies besides ORM and JPA, among other things.You can pay for a Java EE app server (e.g., WebLogic, WebSphere) or use an open source one (JBOSS, Glassfish and OpenEJB and ActiveMQ), or you can stick to Spring and deploy on Tomcat, Jetty, Resin or any other servlet/JSP engine.Spring offers a lot of choice by being technology agnostic: persistence (Hibernate, iBatis, JDBC, JDO, JPA, TopLink), remoting (HTTP, Hessian, Burlap, RMI, SOAP web service), etc.  EJB 3.0 is a spec with many vendors; Spring can only be had from Spring Source.I would recommend .  It's very solid, has lots of traction, isn't going anywhere.    It leaves all your options open.  Web services are great in theory, but there are some gotchas that you need to watch out for: Spring's web service module is very good, but do be careful about choosing to deploy this way. Write in terms of POJO service interfaces.  These will allow you to get the conceptual isolation you want, defer the deployment choice until the last moment, and let you change your mind if the first thought doesn't perform well.Between EJB and RMI, EJB would certainly be better - it has everything RMI has and much more via the container (object pooling, transaction management, etc.)Between EJB and web services, web services would give you more portability if you want to be able to call them from non-java apps in the future.  EJB again gives you things like transaction management and pooling that you might not get \"out of the box\" with web services.Personally, if I were doing it, I would probably use EJB or some similar remote object framework (spring remoting comes to mind as well).  If you need the ability to call the objects from a non-java app, you can always front your EJBs with simple web service proxies as needed.Re: web services (SOAP, REST)\nIf your back end servers are not going to be exposed publicly, then you are not getting any benefit from using platform independent web service interfaces such as SOAP/REST.\nIn fact you'll be incurring a penalty with all of the overhead added by the XML tags wrapping the data across a remote call, not to mention the hit you'll take from marshalling and unmarshalling the XML to java objects.\nAlthough any distributed call is going to require some level of serialization - even RMI/EJB, but the price is greater when serializing to human readable XML.  You may not need to code remote calls in java at all, you could front your service with a plain apache httpd instance, which is configured to load balance across multiple java servers using  or .\nThese modules can be used to load balance across servlet containers such as tomcat/jetty, or ejb containers such as jboss/glassfish."},
{"body": "I have a string representing an URL containing spaces and want to convert it to an URI object. If is simple try to doit gives me where index  is the position of the first space in the URL string.How can i parse into a  object?You should in fact  the \"invalid\" characters. Since the string actually contains the complete URL, it's hard to properly URI-encode it. You don't know which slashes  should be taken into account and which not. You cannot predict that on a raw  beforehand. The problem really needs to be solved at a higher level. Where does that  come from? Is it hardcoded? Then just change it yourself accordingly. Does it come in as user input? Validate it and show error, let the user solve itself.At any way, if you can ensure that it are  the spaces in URLs which makes it invalid, then you can also just do a string-by-string replace with :Or if you can ensure that it's  the part after the last slash which needs to be URI-encoded, then you can also just do so with help of  utility class:Do note that  is insuitable for the task as it's designed to encode query string parameter names/values as per  rules (as used in HTML forms). See also .This will  the string. is the part after the last slash - in your case, the name of the song, as it seems.To handle spaces, @, and other unsafe characters in arbitrary locations in the url path, Use Uri.Builder in combination with a local instance of URL as I have described :I wrote this function:"},
{"body": "How to transform XML with XSLT processor in Java?Here is sample for using java api for transformer, as @Raedwald said:The Java standard library provides an (XSLT) transformation interface for XML parsing. See the API documentation for the classes  and . For example, Saxon 6.5.5 (for XSLT 1.0) and Saxon 9.1.07 (for XSLT 2.0) are written in Java. The documentation is at , which doesn't require writing a program in order to perform an XSLT transformation. For example, : .:where  is the name of the output file,  is the xml file,  is the primary xslt file and  is a name-value list of external parameters (I almost always leave this empty).JAXP provides a implementation independent way of working with XSLT transformations.  to get you started. If you are working with huge XSLT and/or working with multiple XSLT's then there is also an option of caching the parsed XSLT templates for performance reasons.  explains how to cache xslt's"},
{"body": "The  method returns the ordinal of an enum instance.\nHow can I set the ordinal for an enum?You can't set it. It is always the ordinal of the constant definition. See the :And actually - you should not need to. If you want some integer property, define one.You can control the ordinal by changing the order of the enum, but you cannot set it explicitly like in .  One workaround is to provide an extra method in your enum for the number you want:In this situation , but .You can update ordinal using reflection:From If you havethen SUNDAY has an ordinal of 0, MONDAY is 1, and so on...Check out the Java  and The easy answer: just change the order of the constants.  The first defined will be 0, the second will be 1, etc.  However, this may not be practical if you have constantly changing code, or enums will many many values.  You can define a custom method to work around the default ordinal, but MAKE SURE it is well documented to avoid confusion!"},
{"body": "I am trying to compile my JasperReports template using an Ant script and Java. I am getting this error:There is nothing complex in the template, but I still can't compile.You will have to set the  value in your template to Java. There are two ways you can do this:Then try to recompile - you should be sorted. :)Another solution is to copy groovy-all-{version}.jar from the groovy binary distribution into the application's.Change the languge to java in JRXML (ex:- language=\"java\") or add groovy*.jar to your project\u2019s classpath.If you are using TIBCOJaspersoftStudio:"},
{"body": "I'm trying to make an \"executable\" war file () that will start up a Jetty webserver that hosts the webapp contained in the WAR file I executed.I found  that described how to make what I'm looking for:However, following that advice along with how I think I'm supposed to make an executable jar (war) isn't working.I have an Ant task creating a WAR file with a manifest that looks like:The contents of the WAR file look like:When I try to execute the WAR file, the error is:There appears to be two errors here: one where it seems the JAR files can't be found, and one where the  class can't be found.To fix the first one, I put the Jetty JAR files in the base of the WAR file and tried again -- same error.  I also tried adding the  to the  attribute of the manifest.  That did not work either.Does anyone have any insight as to what I'm doing right/wrong and how I can get this executable WAR file up and running?The  you have in your question provides most of what you need. However, there are a few things that need to be done in addition to that.Any class files that Jetty needs to start up will need to be located at the root of the war file when it's packaged. We can leverage Ant to do that for us before we  the file. The war's manifest file will also need a  attribute to execute the server.Here's a step-by-step:To see what all you can configure here, have a look at the .If everything's set up properly above, you should be able to:This is an adaptation for Maven of @RobHruska's answer.  It just copies the files of the main class and merges the Jetty JAR files into the WAR file, nothing new, just to simplify your life if you are new -like me- to Maven:We have figured this out by using jetty-console-maven-plugin. Whenever you run mvn package it creates another war that can be used with java -jar whateverpackage-runnable.warIt also generates the init.d scripts and everything for you!Hudson solves this exact problem using the Winstone servlet container, which supports this use case directly.  Perhaps this would work for you?Even though this is kind of old another alternative with Jetty 8 is to simply include the Jetty jars as dependencies in your pom and add the following in your pom (versus an ant script that unpackages the war and repackages it):I take it that by \"without maven\" you want a jar that you can run by itself and not with \"mvn jetty:run\"--not that you don't want to use maven at all.It took me way to long to figure this out because I found many options--none of them dirt simple.  Eventually I found .  It works wonderfully.This is my example ANT extract. The idea is to unpackage the Jetty dependencies and then include them locally just like a normal JAR file:\n    \n    The  direcory is for the web applications dependencies. In this case we're packaging the WAR file so that it works like the normal Jetty JAR file on startupSo what to do?I have done a similar thing before but are you launchign the app as \"java -jar xxx.war\" ?. You have only 2 jars and it is not going to be enough I think. Also try using Jetty 7.0.0M1 (which is the latest version). When I added jetty-server and jetty-webapp as two dependencies (they are from org.eclipse.jetty) I get the following jar's in the lib directory. FYI the org.mortbay.jetty.Handler was in the jetty-server*.jar."},
{"body": "I am using Selenium for automating the tests. My application exclusively uses IE, it will not work on other Browsers.Code:And here is the error I am gettingCan someone help me on this?Basically, you have to set this property  you initialize driverYou are setting the path for Chrome not IE. The error message says However you're setting \"\".You must set \"\" to the file location when using InternetExplorerDriver.You can set these properties in your shell/MVN/IDE with the -DpropertyName=ValueYou need to use quotes because of spaces or slashes in your path, alternatively reverse the slashes other wise they are escape prefix.You could also useinside your code.I just put the driver files directly into my project to not get any dependency to my local machine.For spring :You will need have to download InternetExplorer driver executable on your system, download it from the source () after download unzip it and put on the place of somewhere in your computer. In my example, I will place it to D:\\iexploredriver.exeThen you have write below code in your eclipse main class "},
{"body": "My question is related to . When should I use it? Do I have to use each time I need to update the GUI components? What does it exactly do? Is there an alternative to it since it doesn't sound intuitive and adds seemingly unnecessary code?No, not if you're already on the event dispatch thread (EDT) which is always the case when responding to user initiated events such as clicks and selections. (The  methods etc, are always called by the EDT.)If you're  on the EDT however and want to do GUI updates (if you want to update the GUI from some timer thread, or from some network thread etc), you'll have to  the update to be performed by the EDT. That's what this method is for.Swing is basically thread unsafe. I.e., all interaction with that API needs to be performed on a single thread (the EDT). If you need to do GUI updates from another thread (timer thread, networking thread, ...) you need to use methods such as the one you mentioned (SwingUtilities.invokeLater, SwingUtilities.invokeAndWait, ...).usage (basic) for 1) main methods should be always wrapped into 2) delayed (but asynchronously) action/event to the end of , 3) if EDT doesn't exists then you have to create a new EDT by using can you test it with    4) there are exist , but till today I () can't found reason for using   instead of , except hard changes into GUI (JTree & JTable) but just with  (excelent for testing consistency of events on the EDT)5) 6) all output from BackGround Tasks must be wraped into Every Swing application has at least 2 threads:If you want to update the UI you should execute code within the EDT.\nMethods like SwingUtilities.invokeLater, SwingUtilities.invokeAndWait, EventQueue.invokeLater, EventQueue.invokeAndWait allow you to execute code by the EDT.What is key to understand is that Java has a separate thread (EDT) handling Swing related events.You should use  to display the main  of a desktop application (for example), instead of trying to do it in the current thread. It will also create the context for graceful closing of the application later. That's about it for most applications.No. If you modify a GUI component, it will trigger an event which is registered for later dispatching by Swing. If there is a listener for this event, the EDT thread will call it somewhere down the road. You don't need to use , just set your listeners on components properly. Keep in mind that this thread is the same thread drawing frames etc... on your screen. Hence, listeners should not perform complex/long/CPU intensive tasks, otherwise your screen will freeze.You don't need to write more code than displaying your application with  + listeners you are interested in on component. The rest is handled by Swing.Most user-initiated events (clicks, keyboard) will already be on the EDT so you won't have to use SwingUtilities for that.  That covers a lot of cases, except for your main() thread and worker threads that update the EDT."},
{"body": "I'm looking for a library to handle  data in Java.Open source, well-documented implementations with a good object model are preferred.  iCal parsing capabilities are less important to me, but still nice to have.Does anyone have any recommendations?I had limited success with  () on a project last year.It seems to be a fairly popular choice for ical work in the java community. If I remember correctly the API can be slightly confusing at first glance.\nHowever It's pretty solid in the long run.Good luck, \nBrian A challenger appears!  Please give  a try.  I'm looking for lots of feedback on how it can be improved."},
{"body": "I'm trying to build a Servlet that calls a JSP page similar to the following:I need this Servlet to respond to the domain's root (eg: ) so I'm using the following mapping in the web.xml:The problem I'm having is that this matches EVERYTHING, so when the dispatcher forwards to \"/WEB-INF/main.jsp\" this matches the url-pattern so the Servlet gets run again. This results in a loop that runs until it dies with a .How can I match the root without preventing other scripts from being runnable?Use an empty pattern, e.g.The servlet 3.0 spec has clarified this:So it should at least work on a 3.0 container, and I've verified that it works on Jetty 8Using the welcome-file element of web.xml worked for me, . Here's mine:The original question doesn't mention that they're trying to map a root servlet on App Engine - it's easy on Tomcat (and other servlet containers as far as I know) but App Engine isn't a normal servlet container.My normal way of building a web application with servlets is to extend HttpServlet, add a \"page\" object with title, content, errors, messages etc. and for output forward to a JSP template.  This has been an absolute nightmare getting working in App Engine.Here's my web.xml (edited for brevity) which finally worked.I haven't been particularly scientific about validating all this - but it seems to work for me now and I'm pretty happy about that.You can create a welcome file named index.jsp in the root with the following code using JSTL or otherwise.So in the web.xml file you will have this:So anyone requesting the root will be redirected to /main. Now your servlet can be mapped to main.Try just to remove '*' from the pattern, i.e.Have you tried the below?  (Note the missing , which is a wild card and is the reason that your configuration catches everything.)(Edited as per comments from just .)If you want your application (not just a servlet, but the entire application) to be available under the root context (\"/\" of \"\"), then you need to set up a context entry for it - not a servlet mapping. With Tomcat, you add a new  (in one of about 3 different possible places).A solution is mentioned in another thread  using URLrewrite -> "},
{"body": "I have an android project that uses ant to build, is it possible to import this ant project in eclipse IDE?update : There is an option to create project using ant  in eclipse File->New->Project->Java->Java project from existing ant Buildfile. and if the build.xml file is selected it show error I guess javac is declared in this taskFrom :just simply import \"existing projects into workspace\" and import your project. then open 'ant' window from windows-->show/view --> ant drag-drop your ant file from project explorer to the and window.click to expand, and select the target you want to run ->right click -> run as ANTyour setup should be ok with this.Try the following method, got it work for me."},
{"body": "In Java there used to be a subtle but important difference between abstract classes and interfaces: . Abstract classes could have them, interfaces could not. Java 8 though introduces default implementations for interfaces, meaning this is no longer the critical difference between an interface and an abstract class.So what is?As best as I can tell, the only remaining difference (besides perhaps some under the hood efficiency stuff) is that abstract classes follow traditional Java single-inheritance, whereas interfaces can have multiple-inheritance (or multiple-implementation if you will). This leads me to another question - How do the new Java 8 interfaces avoid the ?Interfaces cannot have state associated with them.Abstract classes can have state associated with them.Furthermore, default methods in interfaces need not be implemented. So in this way, it will not break already existing code, as while the interface does receive an update, the implementing class does not need to implement it.\nAs a result you may get suboptimal code, but if you want to have more optimal code, then your job is to override the default implementation.And lastly, in case a diamond problem occurs, then the compiler will warn you, and  will need to choose which interface you want to implement.To show more about the diamond problem, consider the following code:Here I get the compiler error on , that:The fix is:In case I wanted to inherit the  from .\nThe same holds for if  were a .To show even more about the difference between interfaces and abstract classes in Java 8, consider the following :You can in theory provide a default implementation of  such that you can add players to for example a list of players.\nBut wait...?\nHow do I store the list of players?\nThe answer is that you cannot do that in an interface, even if you have default implementations available.There have been some very detailed answers, but they seem to be missing one point that I at least consider as one of the very few justifications to have abstract classes :Abstract classes can have  members (and members with default visibility). Methods in interfaces are implicitly . The definition of the  is a vague. There are all kinds of issues that can occur with multiple inheritance. Fortunately, most of them can be easily detected at compile-time, and the programming languages support simple solutions to work around these issues. Most of these problems are not even specific to the . For example, conflicting definitions of methods can also occur without :The specific problem with  is the question of  vs. . If you have a type hierarchy where  and  derive from , and  derives from  and , then the question is:Well, in Java 8 the type  has to be an . So it makes no difference, because  have no state. It doesn't matter, that  can define , since they also have no state. They can invoke methods that have direct access to state. However, these methods are always implemented based on single inheritance.Now that interfaces can contain executable code, lots of use-cases for abstract classes are taken over by interfaces. But abstract classes can still have member variables, while interfaces can't. The diamond problem is avoided by simply not allowing a class to implement two interfaces when both interfaces provide a default implementation for the same method with the same signature.Still there are few more critical differences. Refer to this post: sAbove example produce below outout:  Above example produce below output:"},
{"body": "I would like to modify a file inside my jar. Is it possible to do this without extracting and re jarring, from within my application?File i want to modify are configuration files, mostly xml based.The reason i am interested in not un jarring is that the application is wrapped with launch4j if i unjar it i can't create the .exe file again.You can use the  option for From the Java Tutorials:\"Any files already in the archive having the same pathname as a file being added will be overwritten.\"See .Much better than making the whole jar all over again. Invoking this from within your program sounds possible too. Try Java jar files are the same format as zip files - so if you have a zip file utility that would let you modify an archive, you have your foot in the door. Second problem is, if you want to recompile a class or something, you probably will just have to re-build the jar; but a text file or something (xml, for instance) should be easily enough modified.As many have said, you can't change a file in a JAR without recanning the JAR. It's even worse with Launch4J, you have to rebuild the EXE once you change the JAR. So don't go this route.It's generally bad idea to put configuration files in the JAR. Here is my suggestion. Search for your configuration file in some pre-determined locations (like home directory, \\Program Files\\ etc). If you find a configuration file, use it. Otherwise, use the one in the JAR as fallback. If you do this, you just need to write the configuration file in the pre-determined location and the program will pick it up.Another benefit of this approach is that the modified configuration file doesn't get overwritten if you upgrade your software.You can use Vim:Vim is able to edit compressed text files, given you have  in your environment.This may be more work than you're looking to deal with in the short term, but I suspect in the long term it would be very beneficial for you to look into using  (or , or even ) instead of building jar's manually.  That way you can just click on the ant file (if you use Eclipse) and rebuild the jar.Alternatively, you may want to actually not have these config files in the jar at all - if you're expecting to need to replace these files regularly, or if it's supposed to be distributed to multiple parties, the config file should not be part of the jar at all.To expand on what dfa said, the reason is because the jar file is set up like a zip file.  If you want to modify the file, you must read out all of the entries, modify the one you want to change, and then write the entries back into the jar file.  I have had to do this before, and that was the only way I could find to do it.Note that this is using the internal to Java jar file editors, which are file streams.  I am sure there is a way to do it, you could read the entire jar into memory, modify everything, then write back out to a file stream.  That is what I believe utilities like 7-Zip and others are doing, as I believe the ToC of a zip header has to be defined at write time.  However, I could be wrong.Yes you can, using SQLite you can read from or write to a database from within the jar file, so that you won't have to extract and then re jar it, follow my post using the syntax  \"jdbc:sqlite::resource:\" you would be able to read and write to a database from within the jar fileCheck out .It does exactly what you want (to edit files inline inside a jar file), through a virtual file system API. It also supports nested archives (jar inside a jar) as well.Extract jar file for ex. with winrar and use CAVAJ:here is video tutorial if you need:\nNot sure if this help, but you can edit without extracting:Check the blog post for more details\nAs long as this file isn't .class, i.e. resource file or manifest file - you can.The simplest way I've found to do this in Windows is with :"},
{"body": "I would like to know what would be the best way to do unit testing of a servlet. Testing internal methods is not a problem as long as they don't refer to the servlet context, but what about testing the doGet/doPost methods as well as the internal method that refer to the context or make use of session parameters?Is there a way to do this simply using classical tools such as JUnit, or preferrably TestNG? Did I need to embed a tomcat server or something like that?Try , although you are likely to end up writing automated tests that are more 'integration tests' (of a module) than 'unit tests' (of a single class).Most of the time I test Servlets and JSP's via 'Integration Tests' rather than pure Unit Tests. There are a large number of add-ons for JUnit/TestNG available including:This is a JWebUnit test for a simple Order Processing Servlet which processes input from the form 'orderEntry.html'. It expects a customer id, a customer name and one or more order items:I looked at the posted answers and thought that I would post a more complete solution that actually demonstrates how to do the testing using embedded GlassFish and its Apache Maven plugin. I wrote the complete process up on my blog  and placed the complete project for download on Bitbucket here: I was looking at another post on an image servlet for JSP/JSF tags just before I saw this question. So I combined the solution I used from the other post with a complete unit tested version for this post.Apache Maven has a well defined lifecycle that includes . I will use this along with another lifecycle called  to implement my solution.Add this plugin as part of the .Add/modify the plugin as part of the .Add integration tests like the example below.I wrote the complete process up on my blog  and placed the complete project for download on Bitbucket here: If you have any questions, please leave a comment. I think that this is one complete example for you to use as the basis of any testing you are planning for servlets.Are you calling the doPost and doGet methods manually in the unit tests? If so you can override the HttpServletRequest methods to provide mock objects.The  is a convenience Java class. I suggest you to create a utility method in your unit tests to create the mock http requests:It's even better to put the mock creation methods in a base servlet superclass and make all servlets unit tests to extend it.Mockrunner () can do this.  It provides a mock J2EE container that can be used to test Servlets.  It can also be used to unit test other server-side code like EJBs, JDBC, JMS, Struts.  I've only used the JDBC and EJB capabilities myself.This implementation of a JUnit test for servlet doPost() method relies only on the Mockito library for mocking up instances of , , ,  and .  Replace parameter keys and JavaBean instance with those that correspond to values referenced in the associated JSP file from which doPost() is called.Mockito Maven dependency:JUnit test:Another solution is to use my  library, which is specifically designed for unit testing of servlets. It provides complete plain-Java implementations of all the Servlet API classes, and you can configure and inspect these as necessary for your tests.You can indeed use it to directly call doGet/doPost methods from JUnit or TestNG tests, and to test any internal methods even if they refer to the ServletContext or use session parameters (or any other Servlet API features).This doesn't need an external or embedded container, doesn't limit you to broader HTTP-based \"integration\" tests, and unlike general-purpose mocks it has the full Servlet API behaviour \"baked in\", so your tests can be \"state\"-based rather than \"interaction\"-based (e.g. your tests don't have to rely on the precise sequence of Servlet API calls made by your code, nor on your own expectations of how the Servlet API will respond to each call).There's a simple example in my answer to . For full details and a free download see the  website."},
{"body": "I defined my own custom annotationhow, if at all, can I make the attribute optionalYou can  for the attribute:Found it. It can't be optional, but a default can be declared like this:If no default can make sense as \"empty\" value then that is a problem.For Optional attribute you need to provide default value for that attribute you can provide default value using \"default\" keyword.Note : For only one attribute you can use attribute name as .\nIf you use your attribute name as  you can directly pass value like this @MyCustomAnnotation(true) instead of @MyCustomAnnotation(myType = true)."},
{"body": "is there an easy way to get the (to-be-generated) sql from a Hibernate Criteria?Ideally I would have something like:The idea would then be to use the sql as part of a huge 'MINUS' query (I need to find the differences between 2 identical schemas - identical in structure, not in data - and the MINUS is not supported by Hibernate)(BTW I know I can check the SQL from the log files)I've done something like this using Spring AOP so I could grab the sql, parameters, errors, and execution time for any query run in the application whether it was HQL, Criteria, or native SQL.This is obviously fragile, insecure, subject to break with changes in Hibernate, etc, but it illustrates that it's possible to get the SQL:Wrap the entire thing in a try/catch and use at your own risk.Here's \"another\" way to get the SQL  :For those using NHibernate, this is a port of [ram]'s codeIf you are using Hibernate 3.6 you can use the code in the accepted answer (provided by Brian Deterling) with slight modification:I like this if you want to get just some parts of the query:For instance something like this:Here is a method I used and worked for meThis answer is based on user3715338's answer (with a small spelling error corrected) and mixed with Michael's answer for Hibernate 3.6 - based on the accepted answer from Brian Deterling. I then extended it (for PostgreSQL) with a couple more types replacing the questionmarks:"},
{"body": "I am trying to understand a JMX service URL.It would be great, if someone can help me understand this.ThanksI will reuse an answer I wrote up earlier for this question: It's not complete, but might help:Suppose you have the JMX Server (alias 'JMX Agent' alias 'the JVM you want to connect to') running on 'TARGET MACHINE' with the  at 'RMI REGISTRY PORT' and the  at 'JMX RMI SERVER PORT'.Note:The following URI will lead to successful connection (tested)This looks nasty. Let's cut it apart.This URI is an RFC2609 \"Service Location Protocol URL\" (well, it's really an URI, right?)It is composed of: is decomposed into:A well-informed JMX client connects to the \"ipsite\" to do JMX-over-RMI exchanges; but what of the JMX client that doesn't KNOW that port? Patience... is decomposed into:This is somewhat cart-before-horse, as one has to contact the  given by the  part of the SLP URL first.After scratching head, intuitively, let's try: Yes, that works! The JMX RMI server port is nicely obtained from the registry. On second thoughts, the  should also be obtained from the registry, thus:Even better, that works, too!References:To explain:Previous answers suggest that the 2nd part of the URL is to obtain the server port of the JMX RMI server. That is not correct. The JMX RMI server port is (TCP) 1234 and is part of the URL. What you get from the RMI registry is the RMI stub () which you can use to talk to JMX Agent (MBean Server) over RMI.Hope this helps.According to this url is assembled like this"},
{"body": "sorry to be a pain... I have: Yet...I'm guessing that  doesn't accept the standard  ?Am I doing something wrong or will I have to wrap my code in:ThanksIt accepts only a string value of  to represent boolean . Best what you can do isOr if the  actually represents an \"entitiy\", I think a  is way much better. Or if it represents configuration settings, you may want to take a look into .I have a small utility function to convert all possible values into Boolean. According to  (emphasis mine):If you're trying to get C's behavior ( and everything else is ), you could do this:As a note ,\nfor those who need to have null value for things other than \"true\" or \"false\" strings ,  you can use the function belowThomas,  I think your wrapper code, or just the condition itself, is the cleanest way to do what you want to do in java, which is convert \"1\" to the Boolean True value.  Actually, comparing to \"0\" and taking the inverse would match the C behavior of treating 0 as false and everything else as true.  Java is strongly typed. 0 and 1 are numbers, which is a different type than a boolean. A number will never be equal to a boolean.I know this is an old thread, but what about borrowing from C syntax:Returns true if comes 'y', '1', 'true', 'on'or whatever you add in similar wayHow about this?Very simple way: if valTest has the string \"true\", the boolean result will be true, otherwise, false;\nYou may use it for 0 or 1 values:"},
{"body": "Why it was always \"GC (Allocation Failure)\"?Java HotSpot(TM) 64-Bit Server VM (25.25-b02) for linux-amd64 JRE (-b17), \"Allocation Failure\" is a cause of GC cycle to kick.\"Allocation Failure\" means that no more space left in Eden to allocate object. So, it is normal cause of young GC.Older JVM were not printing GC cause for minor GC cycles.\"Allocation Failure\" is almost only possible cause for minor GC. Another reason for minor GC to kick could be CMS remark phase (if  is enabled)."},
{"body": "In java, what does the private static method  of the Object class do?The other answers are technically correct, but not very useful for someone with no JNI experience. :-)Normally, in order for the JVM to find your native functions, they have to be named a certain way. e.g., for , the corresponding C function is named . By using  (or rather, the JNI function ), you can name your C functions whatever you want.Here's the associated C code (from OpenJDK 6):(Notice that  is not in the list; it will still be called by the \"standard\" name of .) For the functions listed, the associated C functions are as listed in that table, which is handier than writing a bunch of forwarding functions.Registering native functions is also useful if you are embedding Java in your C program and want to link to functions within the application itself (as opposed to within a shared library), or the functions being used aren't otherwise \"exported\", since these would not normally be found by the standard method lookup mechanism. Registering native functions can also be used to \"rebind\" a native method to another C function (useful if your program supports dynamically loading and unloading modules, for example).I encourage everybody to read the , which talks about this and much more. :-)What might be slightly confusing is that the code shown for  in a previous answer is just an  of how to register native functions.  This is the code that (in the implementation of OpenJDK) registers native functions for class Object.  To register native functions for your own class, you must call the JNI function  from the native code in your own library.  This might sound a bit circular, but there are a couple ways to break the loop.ORSince you looked at the source code to find it, it's pretty easy to guess isn't?It's a native method, and it's called registerNatives, so I guess it registers objects with the underlying platform.It's also private, so it's probably nothing to be concerned about."},
{"body": "There are many ways to initialize a mock object using MockIto.\nWhat is best way among these ?1.2.[EDIT]\n3.suggest me if there are any other ways better than these... , using the runner or the  are strictly equivalent solutions. From the javadoc of the  :The first solution (with the ) could be used when you have already configured a specific runner ( for example) on your test case.The second solution (with the ) is the more classic and my favorite. The code is simpler. Using a runner provides the great advantage of  (described by  in ).Both the solutions allows to share the mocks (and spies) between the test methods. Coupled with the , they allows to write unit tests very quickly. The boilerplate mocking code is reduced, the tests are easier to read. For example :Pros : The code is minimal Cons : Black magic. IMO it iss mainly due to the @InjectMocks annotation. With this annotation   (see the great comments of )The third solution is to create your mock un each test method. \nIt allow as explained by  in its answer to have \"\".Pros : You clearly demonstrate how the your api works (BDD...)Cons : there is more boilerplate code. (The mocks creation) recommandation is a compromise. Use the  annotation with the , but do not use the  :Pros : You clearly demonstrate how the your api works (How my  is instantiated). No boilerplate code.Cons : The test is not self contains, less pain of codeThere is now (as of v1.10.7) a fourth way to instantiate mocks, which is using a JUnit4  called .JUnit looks for , and uses them to . The upshot of this is that you can extract @Before methods, @After methods, and even try...catch wrappers into rules. You can even interact with these from within your test, the way that  does.MockitoRule behaves , except that you can use any other runner, such as  (which allows your test constructors to take arguments so your tests can be run multiple times), or Robolectric's test runner (so its classloader can provide Java replacements for Android native classes). This makes it strictly more flexible to use in recent JUnit and Mockito versions.In summary:See also: There is a neat way of doing this.MockitoAnnotations & the runner have been well discussed above, so I'm going to throw in my tuppence for the unloved:I use this because I find it a little bit more descriptive and I prefer (not out right ban) unit tests not to use member variables as I like my tests to be (as much as they can be) self contained."},
{"body": "Can you overlay a view on top of everything in android?In iPhone I would get the new view set its  to (0,0) and its width and height to the width and height of . Adding it to  would then cause it to act as an overlay, covering the content behind (or if it had a transparent background then showing the view behind).Is there a similar technique in android? I realise that the views are slightly different (there are three types (or more...) relativelayout, linearlayout and framelayout) but is there any way to just overlay a view on top of everything indiscriminately?Simply use  or . The last child view will overlay everything else.Android supports a pattern which Cocoa Touch SDK doesn't: Layout management.\n for iPhone means to position everything absolute (besides some strech factors). Layout in android means that children will be placed in relation to eachother.Example (second EditText will completely cover the first one): is some kind of view stack. Made for special cases. is pretty powerful. You can define rules like , , etcUsually you set the content with  in  (it will inflate the layout for you). You can do that manually and call , there's no difference.The view itself might be a single view (like ) or a complex layout hierarchy (nested layouts, since all layouts are views themselves).After calling  your activity knows what its content looks like and you can use  to retrieve any view int this hierarchy (General pattern ).Now any view you add under LinearLayout with  will appear as overlay with  on Linear Layout with You can use :The best way is  , You can add any drawable as overlay to any view as its overlay since Android JellyBeanMR2(Api 18).Add  to  as its overlay:"},
{"body": "Is there a way to set heap size from a running Java program?  No. What you can do with an app that has very variable heap requirements is to set your max heap size very high with  and tune  and  so that the app will not hang on to a lot of memory when the heap shrinks (it does that with default settings). But note that this may cause performance problems when the memory actually used by the app varies both strongly and quickly - in that case you're better off having it hang on to all the memory rather than give it back to the OS only to claim it again a second later. You might also want to fiddle with the  to ensure that the GC doesn't leave too much unclaimed objects lying around, which it tends to do when there's a lot of room for the heap to grow, and which would defeat the goal of wanting the heap size to adjust to the app's needs.According to , you can't do this at runtime, but you can spawn another process with a different heap size.You can tweak those settings when you start your application but once the JVM is up and running those values cannot be changed.  Something like this:will set the minimum heap size to 32MB and the maximum heap size to 512MB.  Once these are set, you cannot change them within the running program.The consensus may indeed be that this is not possible, but we should be looking at the JVM source to see how it can be ergonomically controlled.  It would be very nice to be able to have a JVMTI agent be able to adjust the heap/perm/tenured/new/&c sizing online/at runtime.What would this do? it would allow agents to infer sizing adjustments based upon performance or footprint goals which will be important when moving JVMs into the Cloud.You can use the  option on startup (also known as )  This is maximum size you should ever need in which cause you shouldn't need to set it to more than the maximum size you will ever need.However, a work around is to have the main() check the maximum size and restart the java if the maximum size is not as desired. i.e. start another java program and die. on startup onlyI asked same question to myself. And unlike answers above there is something I can do about  app increasing max heap JVM size. If app is a web server in cluster mode, I could start a new instance with changed min/max heap size and than shutdown initial instance. That shall be especially simple in GlassFish where you have management instance separated from nodeAgent(app server clustered instance) JVM.Since many JVM applications are web apps, I think it worth to preserve in this blog.If I understand your question correctly, you're trying to change the heap size at . I don't see any reason why this should be possible. Set the heap size at  using the  JVM option. I also advise you to set the  option only if you absolutely need to. This option sets the initial amount of head memory that is allocated for the JVM. You should know how your application behaves in terms of memory. Set the the value of  wisely. If your app is some kind of a server app you can set a higher value, otherwise compromise your choice with other possible apps running in client machines and of course available memory."},
{"body": "I have 2 jars, let's call them a.jar and b.jar.b.jar depends on a.jar.In a.jar, I defined a class, let's call it StaticClass. In the StaticClass, I defined a static block, calling a method named \"init\" : in b.jar, I have a main, so in the main, I expect that the init() method has been called, but actually not. I suspect that is because the StaticClass has not been loaded by the jvm, could anyone tell meThanksYes, you are right. Static initialization blocks are run when the JVM (class loader - to be specific) loads  (which occurs the first time it is referenced in code).You could force this method to be invoked by explicitly calling  which is preferable to relying on the JVM.You could also try using  to force the JVM to load the class and invoke its static blocks.Yes you are right, since you are not using your  it is not loaded by the vm and therefore  is never executed.For your second question, you probably have to go the hard way and scan all available classes and load them. You are right, the easiest way is to access the class, for instance do a Or something to that respect in your main method. This will ensure the class is loaded by the classloader.The static code is executed when your class ( I guess) is referenced.Thus, it should be executed if you create a  of  or if you .Yes, the static initializer will be executed when the class is loaded. This normally occurs when you access the class in the class loading context for the first time.Static block is executed when a loaded class is initialized or referenced first. Loading class doesnt mean that class is to initialized. JVM Class Loading is separate things to concern.in b.jar main method class should extend that StaticClass then automatically that static block and init() will be invokedAdding some more:   static block will be executed when jvm load class.Here in your example you can call  method of your  by intantiating  classlike \n    StaticClass staticClass=new StaticClass();or     "},
{"body": "I'm new to Spring and I'm wondering if its possible to use numerous transaction managers in the same application?I have two data access layers - one for both of the databases. I'm wondering, how do you go about using one transaction managers for one layer and different transaction manager for the other layer. I don't need to perform transactions across both databases - yet. But I do need perform transactions on each database individually. I've created an image to help outline my problem:Here is my application context configuration:Here is an example that uses this configuration:So for the account repository, I want to use an entity manager factory with the persistence unit set to accounts. However, with my BusinessData Repository, I want to use an entity manager factory with a different persistence unit. Since I can only define one transaction manager bean, how can I go about using different transaction managers for the different repositories?Thanks for any help.Where you use a  annotation, you can  by adding an attribute set to a bean name or qualifier.  For example, if your application context defines multiple transaction managers with qualifiers:You can use the qualifier to specify the transaction manager to use:This Spring Jira entry discusses the issue a bit: I think it could be one transaction manager per connection if you're not using two-phase commit.  You just need to create two transaction managers and inject them with the appropriate connection.But I must ask the question: why do you think you need two transaction managers?  You can have more than one database connection.  The DAOs that use the connections can and should be instantiated by different services, each of which can be annotated with their own transactional settings.  One manager can accommodate both.  Why do you think you need two?"},
{"body": "I have learned basics of Java but want to practice more. I was looking via Google and couldn't find many beginner level problems that I can solve using Java. Any suggestions?I recommend reading through the  for code examples and practice in  areas of Java programming, especially the areas you wish to improve in.Depending on how much of beginner examples you were looking for, check out  for some good beginner exercises.  is another good site, but depending on your skill level now, this may be too much, but it's worth trying anyways.Most importantly, Its also worth noting that  are a great way to start to learn a new language. I would also recommend starting a project that is benefical to you and get cracking right away, no time is better than the present!When learning a new language, there are some nice problem sets you can use to learn the language better.I highly recommend reading the book  from You could try the problems at , many of which lack Java solutions at the moment. The problems are of many different difficulties, but each has a solution already in another language which should help with the algorithmic side.If you wanted to learn some GUI, may be tic tac toe is good. Even for console, I still find that is a fun problem. Not challenging but a little bit fun. Later you can advance some other games or port that game to GUI, client server or java applet for the web. I think if you want to learn something and get fun as well, game is a good choice:)My recommendation is to solve problems that you're interested in, writing code that might be useful to you.Java is a huge box.  It's got a lot of computer science inside: graphics, scientific computing, relational databases, user interfaces for desktop and web, messaging and queuing, multi-threading, security, and more.  Each area has their own \"beginner problem\".  Which one do you mean?How do you define \"beginner problem\"?  Maybe you're having trouble because you aren't narrowing your search enough.  If your imagination is lacking, your best bet is to  and investigate what you get back.Or start with  and work you way all the way through it.  You'll know a fair amount about Java when you're done.Once you are quite good in Java SE (lets say you are able to pass SCJP), I'd suggest you get junior Java programmer job and improve yourself on real world problemsGo and buy the book titled \"Java examples in a nutshell\". In the book you will find most of practical examples. "},
{"body": "I created a CircularImageView with this question: Download project on 1) This is the CircularImageView class :2) I use in my layout like this :3) Current result in picture :Objectif result :You can used or download my   with  by using  :I modified the  to achieve what you want.To create a shadow around the border, I simply used these two lines:You need  due to hardware acceleration on HoneyComb and up. It didn't work without it when I tried it.Here is the full code:I hope it helps! .I forked your CircularImageView and added support for selector overlays. I also improved drawing performance significantly...to add a border by making imageview as a circle, i've done a simple thing,\nI used this class to  make my image as a circleand by using this on Oncreate i have call the image for setting it,to add a border i created a circle shape XML like this,then using layouts i added a relativeLayout with imageview inside of it, by using padding and background drawable with wrapcontent i set my relative layout like thisnow it show like this, i don't know to add the shadow, sorry for that tooHope it helps.Maybe a better solution .Create a custom drawable, and use that to define your the background attribute of your ImageView.  You can use a LayeredDrawable, to create as many different components for the component as you would like.Checkout this answer, which creates a custom Rectangle (but is exactly the same with an Oval\\Circle):  just use drawCircle() method  with more width and height before drawing the actual image. Increase the width and height of in that new method call according to your wish, and set some another color of you want on paintI found a library that doing exactly what you wish, worked fine for me.\nCheck it out.\n"},
{"body": "This is probably a newbie question, but hope you can help me. :) I have something like this:I am using NetBeans IDE and for some reason the printStackTrace is underlined in a squiggly line.  When I press Alt+Enter, it says Throwable.printStackTrace() should be removed.  What does this mean?  Could anyone give more insight as what this may mean? Or can I ignore this?Thanks!It is just a recommendation. In eclipse it is fine - I believe it is just the IDE telling you that there are more conventional methods of doing it, like some of the other answers.\nI find that it is useful for debugging, and that you should tell users when a fatal error is going to occur, to use a debug mode (like a console switch -d) to collect these logs.Try:It's probably because  doesn't really handle the error as much as it just dumps the stack in the console. It acts as a placeholder until you replace it with proper error handling (if it is needed at all) and replace the output with a logger of some sort.Is not good practice because it prints in the default ErrorStream, which most of the times is the console!NetBeans should be warning you about that. The good practice about it, is logging the message. Follow same reference:\nSee first comment bellow to more info."},
{"body": "I have read books on , saying that it is good to create setters and getters for variables such as  and .  For example:But what is the difference from that andandIf setters and getters are better, could you explain to me what practical problems would arise?Multiple reasons:then you cannot add any logic in future to validate the data.say if x cannot be less than 100 you cannot do it, however if you had setters likeThough for constants likeyou will allow field access as they cannot be changed, for instance variable you will place them with getters, setters.Though in such cases you have to be careful in getter method to ensure you don't give out reference of objects(in case your class have object as instances).We can use the private variables in any package using getters and setters.Using getter and setter functions allow for constraints and encapsulation. Lets say x is the radius. shape.x = -10 would not make much sense. Also, if someone tries to set an illegal value, you can print an error, set a default value, or do nothing.It is good practice to make member variables private so they cannot be modified directly by programs using them.\nAnother good reason to user getter and setter can be understand by the following exampleThe point of getters and setters is that only they are meant to be used to access the private varialble, which they are getting or setting. This way you provide encapsulation and it will be much easier to refactor or modify your code later.Imagine you use name instead of its getter. Then if you want to add something like a default (say the default name is 'Guest' if it wasn't set before), then you'll have to modify both the getter and the sayName function.There is no requirement for getters and setter to start with get and set - they are just normal member functions. However it's a convention to do that. (especially if you use Java Beans)A lot of people have mentioned encapsulating the specifics of the implementation, which to me is the biggest reason to use getters and setters in a class. With this, you also get a lot of other benefits, including the ability to throw out and replace the implementation on a whim without needing to touch every piece of code that uses your class. In a small project, that's not a big benefit, but if your code ends up as a well-used (internal or public) library, it can be a  benefit.One specific example: . Some languages have them as a language or framework feature, others don't. I will use a mutable class as an example here, but it could just as easily be immutable.A complex number can be written on the form  with real and imaginary parts, lending itself well to  and .However, in some cases it's easier to reason about complex numbers on polar form , giving  (r) and  (\u03b8).You can also expose methods like  and . Depending on the argument types these may or may not need different names, but then the class' consumer can use either as fits its needs.The two forms are interchangeable; you can fairly easily convert from one to the other, so which form the class uses for internal storage is irrelevant to consumers of that class. However, consumers may use either form. If you choose the form a+bi for internal representation, and , not only do you force the class consumers to use that form, you also cannot later easily change your mind and replace the internal representation with re^(i\u03b8) because that turns out to be easier to implement in your particular scenario. You're stuck with the public API you have defined, which mandates that specifically the real and imaginary parts are exposed using specific field names.One of the best reasons I can think of for getters and setters is the permanence of a class's API. In languages like python you can access members by their name and switch them to methods later. Because functions behave differently than members in java once you access a property thats it. Restricting its scope later breaks the client. By providing getters and setters a programmer has the flexibility to modify members and behavior freely as long as the adhere to the contract described by the public API.Let's say, hypothetically, you find a library that does a better job of what you have been doing in your own class (YourClass). The natural thing to do at this point is to make YourClass a wrapper interface to that library. It still has a concept of \"X\" which your client code needs to get or set. Naturally, at this point you pretty much have to write the accessor functions.If you neglected to use accessor functions and let your client code access YourClass.x directly, you would now have to rewrite all of your client code that ever touched YourClass.x. But if you were using YourClass.getX() and YourClass.setX() from the beginning, you will only need to rewrite YourClass.One of the key concepts of programming, and especially object oriented programming, is hiding implementation details so that they're not used directly by code in other classes or modules. This way, if you ever change the implementation details (as in the example above), the client code doesn't know the difference and doesn't have to be modified. For all your client code knows, \"x\" might be a variable, or it might be a value that is calculated on the fly.This is an oversimplification and doesn't cover all the scenarios where hiding implementation is beneficial, but it is the most obvious example. The concept of hiding implementation details is pretty strongly tied to OOP now, but you can find discussions of it going back decades before OOP was dreamed up. It goes back to one of the core concepts of software development, which is to take a big nebulous problem, and divide it into small well-defined problems which can be solved easily. Accessor functions help keep your small sub-tasks separate and well-defined: The less your classes know about each other's internals, the better.Originally, getter/setter pattern was created to promote good object-oriented design by  the internals of a  from its external .    this is the best answer of your question There are lots of reasons.  Here are just a few.Before get into the answer, we gotta know something prior...! \"\".\n. For our purpose, think of properties as private instance variables. since they're private, the only way they can be accessed \nfrom outside of their class is through 'methods'in the class.\n The methods that change a propertiy's value are called , and the methods that retrieve a property's value are called .I would say that neither the getters/setters nor the public members are good Object Oriented design.  They both break OOP Encapsulation by exposing an objects data to the world that probably shouldn't be accessing the properties of the object in the first place.This is done by applying the  principle of OOP.This means, you must define the visibility for the attributes and methods of your classes. There are 3 common visibilities:When you declare private/protected attributes, you are encouraged to create methods to obtain the value (get) and change the value (set). One example about visibility is the  class: it has a  property to know the actual size of the inner array. Only the class  change its value, so the code is something likeIn this example, you can see that the size value can change only inside the class methods, and you can get the actual size by calling it in your code (not mutating it):Getters and setters encapsulate the fields of a class by making them accessible only through its public methods and keep the values themselves private. That is considered a good OO principle.Granted, it often seems like redundant code if it does nothing more than setting or returning a value. However, setters also allow you to do input validation or cleanup. Having that in one place improves data integrity for your objects,Because we are using Object oriented programming language. \nHere we are using Data hiding and encapsulation.\nThe variable should not directly accessible from out side world (for achiving data hiding) so we will create it private so is not correct.\nGetter and setter method are used to get and set the value of x which is the way to achive encapsulation."},
{"body": "What are the advantages of  over compressed strings in JDK9?Compressed strings (Java 6) and compact strings (Java 9) both have the same motivation (strings are often effectively Latin-1, so half the space is wasted) and goal (make those strings small) but the implementations differ a lot.In  Aleksey Shipil\u00ebv (who was in charge of implementing the Java 9 feature) had this to say about compressed strings:In Java 9 on the other hand, compact strings are fully integrated into the JDK source.  is  backed by , where characters use one byte if they are Latin-1 and otherwise two. Most operations do a check to see which is the case, e.g. :Compact strings are enabled by default and can be partially disabled - \"partially\" because they are still backed by a  and operations returning s must still put them together from two separate bytes (due to intrinsics it is hard to say whether this has a performance impact).If you're interested in more background on compact strings I recommend to read  I linked to above and/or watch  (which also explains the new string concatenation). and  are different things.  meant that Strings that are ASCII only could be converted to , but this was off by-default. In jdk-9 this optimization is always on, but not via the flag itself, but build-in. Until java-9 Strings are stored internally as a  in UTF-16 encoding. From java-9 and up they will be store as . Why?Because in  each character can be encoded in a single byte (8 bits) vs what it is used to be until now (16 bits, 8 of each where never used). This works  for , but that is the majority of Strings used anyway.So that is done for space usage. Here is a small example that should make things more clear:In the first case we are going to get zeroes only, meaning that the most significant 8 bits are zeroes; in the second case there is going to be a non-zero value, meaning that at least one bit from the most significant 8, is present.That means that if internally we store Strings as an array of chars, there are string literals that actually waste half of each char. It turns out there are multiple applications that actually waste a lot of space because of this.You have a String made from 10 Latin1 characters? You just lost 80 bits, or 10 bytes. To mitigate this String compression was made. And now, there will be no space loss for these Strings. Internally this also means some very nice things. To distinguish between String that are  and  there's a field :Now based on this  is computed differently:If our String is Latin1 only, coder is going to be zero, so length of value (the byte array) is the size of chars. For non-Latin1 divide by two. will have best of both worlds.As can be seen in the definition provided in OpenJDK documentation: As mentioned by @Eugene, most of the strings are encoded in Latin-1 format and require one byte per character and hence do not require the whole 2-byte space provide in current String class implementation.The new String class implementation will shift from  to  . The additional  will show whether the characters are stored using UTF-16 or Latin-1 format.This also concludes that we will also be able to store strings in UTF-16 format if required. And this also becomes the main point of difference between the  and  as in Compressed String  was used for storage which was then representated as . "},
{"body": "I create a web application (WAR) and deploy it on Tomcat. In the  there is a page with a form where an administrator can enter some configuration data. I don't want to store this data in an DBMS, but just in an XML file on the file system. Where to put it?I would like to put the file somewhere in the directory tree where the application itself is deployed. Should my configuration file be in the  directory? Or put it somewhere else? And what is the Java code to use in a servlet to find the absolute path of the directory? Or can it be accessed with a relative path?What we do is to put it in a separate directory on the server (you could use something like /config, /opt/config, /root/config, /home/username/config, or anything you want). When our servlets start up, they read the XML file, get a few things out of it (most importantly DB connection information), and that's it.I asked about why we did this once.It would be nice to store everything in the DB, but obviously you can't store DB connection information in the DB.You could hardcode things in the code, but that's ugly for many reasons. If the info ever has to change you have to rebuild the code and redeploy. If someone gets a copy of your code or your WAR file they would then get that information.Putting things in the WAR file seems nice, but if you want to change things much it could be a bad idea. The problem is that if you have to change the information, then next time you redeploy it will overwrite the file so anything you didn't remember to change in the version getting built into the WAR gets forgotten.The file in a special place on the file system thing works quite well for us. It doesn't have any big downsides. You know where it is, it's stored seperatly, makes deploying to multiple machines easy if they all need different config values (since it's not part of the WAR).The only other solution I can think of that would work well would be keeping everything in the DB except the DB login info. That would come from Java system properties that are retrieved through the JVM. This the Preferences API thing mentioned by Hans Doggen above. I don't think it was around when our application was first developed, if it was it wasn't used.As for the path for accessing the configuration file, it's just a file on the filesystem. You don't need to worry about the web path. So when your servlet starts up it just opens the file at \"/config/myapp/config.xml\" (or whatever) and it will find the right thing. Just hardcodeing the path in for this one seems pretty harmless to me.WEB-INF is a good place to put your config file.  Here's some code to get the absolute path of the directory from a servlet.Putting it in  will hide the XML file from users who try to access it directly through a URL, so yes, I'd say put it in .I would not store it in the application folder, because that would override the configuration with a new deployment of the application.I suggest you have a look at the Preferences API, or write something in the users folder (the user that is running Tomcat).The answer to this depends on how you intend to read and write that config file.For example, the Spring framework gives you the ability to  (or Java property files); these can be stored in your classpath (e.g., in the WEB-INF directory), anywhere else on the filesystem, or even in memory.  If you were to use Spring for this, then the easiest place to store the config file is in your WEB-INF directory, and then use Spring's  class to access your configuration file.But again, it all depends on how you plan to access that file.If it is your custom config WEB-INF is a good place for it. But some libraries may require configs to reside in WEB-INF/classes."},
{"body": "I need to download a web page on an android app and I am having a hard time deciding whether to use the android apache http client or java's URLConnection.Any thoughts?For most things I'd say that  is the way to go.  However there are some situations and edge cases where I'd fall back to a .  Examples of edge cases  and  \nA similar question has been asked before: .   I would find  code much quicker and easier to write and maintain.  According to a comments below, the core elements of  have been performance optimised.  If performance is a major concern your best bet is to write two clients, one using each method, then benchmark them both.  If you do this, please let us know the results.Google has silently deprecated Apache HTTP client usage since Gingerbread: . And while they didn't mark it with deprecated annotation, they suggest you to use HttpURLConnection for new applications as: .Personally I don't like that decision and would rather stick to HttpClient 4.1+, as it is faster, have fewer bugs and is updated regularly. And while you can not upgrade system library to version 4.1, you can include HttpClient jar to your Android project (as the additional benefit this would allow you to not depend on Google bug fixes and vendor updates). There is one pitfall however: to prevent possible collisions with built-in library you should rename httpclient packages using JarJar tool. Turned out someone already did this (repackaged jar and Android library projects are available for download):  in Gingerbread and later, HttpURLConnection is the way to go. consider Apache HttpClient deprecated. (also note that Android doesn't use HttpClient 4.1, mentioned in another comment.)if you have a case where Apache HttpClient is faster, report it as a bug here: "},
{"body": "I found the following Java code.where  and  are .I know basic operations on primitive types are thread-safe, but I am not sure about . If the above  is necessary, is there maybe a better class to handle such operation?No.  The  operation is not thread-safe.  It requires locking and / or a proper chain of \"happens-before\" relationships for any expression involving assignment to a shared field or array element to be thread-safe.  (With a field declared as , the \"happens-before\" relationships exist ... but only on read and write operations.  The  operation consists of a read and a write.  These are individually atomic, but the sequence isn't.  And most assignment expressions using  involve both one or more reads (on the right hand side) and a write.  That  is not atomic either.)For the complete story, read JLS  ... or the relevant chapter of \"Java Concurrency in Action\" by Brian Goetz et al.Actually, that is an incorrect premise:There is an additional issue for the  type.  The JLS () says this:In a comment, you asked:In this case (where you are updating a , there is no alternative to synchronization with locks or primitive mutexes.If you had an  or a  you could replace them with  or  and make use of those classes' lock-free update.  However there is no  class, or even an  class.  ( - someone pointed out that Guava provides an  class, so that  be an option.  A good one actually.)One way of avoiding a \"global lock\" and massive contention problems might be to divide the array into notional regions, each with its own lock.  That way, one thread only needs to block another thread if they are using the same region of the array.  (Single writer / multiple reader locks could help too ... if the vast majority of accesses are reads.)Despite of the fact that there is no  or  in java, you can easily create your own based on .As you can see, I use  and  to store  as  in . They both have the same size in bits, so precision is not lost (except for -NaN, but I don't think it is important).In Java 8 the implementation of  can be even easier, as you can use  method of  that was added in java 1.8.: It appears that I virtually re-implemented guava's .Even the normal 'double' data type is not thread-safe (because it is not atomic) in 32-bit JVMs as it takes eight bytes in Java (which involves 2*32 bit operations).As it's already explained, this code is not thread safe. One possible solution to avoid synchronization in Java-8 is to use new  class which is capable to maintain the sum of double numbers in thread-safe manner.Create array of  objects before parallelizing:Then accumulate the sum in parallel threads like this:Finally get the result after parallel subtasks finished:"},
{"body": "If I write this line in Java:Which method will be called?I can test it. But in other cases similar to this, I want to know what happens.The  method will be called - in this caseThis generally comes under the  step of overload resolution in the spec (15.12.2), and in particular .Without getting into the details (which you can read just as well in the spec as here), the introduction gives a good summary:In your particular case the more specific method will be called.  In general, though, there are some cases where the method signature can be ambiguous.  Consider the following:In this case, the compiler can't decide between the method that takes an Integer and the method that takes a String.  When I try to compile that, I getor I should have known - never doubt Jon Skeet. The problem I've referred to above only occurs when it's impossible to determine which method is more specific. Here's a test case:The above will give a compiler error."},
{"body": "I need a data structure to store string-int value pairs in an 1:1 relationship, and being able too look up from either way their counterpart.I wrote a class with a Hashtable and a String array and stored the data 2 times and used the built in functions for lookup.My question is that is there a nicer way to accomplish this? And by nicer I mean being efficient and not storing the data 2 times, and preferably without writing a ton of code either :P.It seems like you may be looking for a bimap.The Google Collections (now a part of ) contains an  interface with a few implementations.From the  documentation:The  method appears to return a  with the values as the keys, and the keys as the values, so that  can be used to call  on the value and retrieve a key.In addition the  returned by  is a view of the underlying data, so it does not have to make extra copies of the original data.From the  method documentation:You can do a simple implementation like this. Please note that the data is not copied in this implementation. Only the references are ! I have added implementation for add and get. remove and other required method are left as exercise :)And ofcourse its applications responsibility to ensue even the 'values' are unique. Example usage:Apache Commons also includes the  (Bi Directional Map).The  has a  that does what you want.Using , read complete tutorial Create a hashmap that maps Object to Object - then you can use the same map to store String -> Integer and Integer -> String.When you add a string/int pair just add it both ways to the same map."},
{"body": "I have two packages,  and :I am writing the JavaDoc for  and need to provide an  to .I have tried all of the following, and none of them work:I've been able to find documentation for linking to: (a) classes within the same package, or (b) externals URLs, but not classes in another package.Any ideas what the correct syntax should be? Thanks!The  variants areYou were missing a complete package. The following example should be correctFor another package use this syntax:  In your case this should be:   If you want to show only the class name then use the label, if complete path is desired then label is not required.Reference:\n"},
{"body": "Is there a way to download dependencies from a pom.xml file to a specified folder in java? I'm able to run maven command from java and I got download messages, but I don't know where maven stores these libraries? How can I download these dependencies to a specific folder? Take a look at maven's dependency plugin, specifically the  goal. The  describes how to do exactly what you want.To do it from the command line just do:Maven stores all of these in it's local Maven2 repository.  By default, it will store them in your user home directory under a directory called repository.You can use the maven-dependency-plugin's goal called copy to take all of your project's dependencies and put them in a folder.Add something similar to the following to pom.xml:Then run  to perform the copy.\nCombine this with the  and you can package everything into a self contained archive for distribution."},
{"body": "How can I see the number of threads in a Java process? Useful tool for debugging java programs, it gives the number of threads and other relevant info on them:It will return the number of active threads in the .docs:  doesn't limit itself to thread groups as  does.There is a static method on the  Class that will return the number of active threads controlled by the JVM:Additionally, external debuggers should list all active threads (and allow you to suspend any number of them) if you wish to monitor them in real-time.I have written a program to iterate all  created and printing  of each Output:If you remove below conditionYou will get below threads in output too, which have been started by system.. Generic solution that doesn't require a GUI like jconsole (doesn't work on remote terminals), ps works for non-java processes, doesn't require a JVM installed. "},
{"body": "I would like to convert cal to a Date type to insert into table.There is a  method (unsure why it's not called getDate).Edit: Just realised you need a java.sql.Date. One of the answers which use  is what you need.Did you try ? This gets the date representation.You might also want to look at the javadoc.Use Converting is easy, setting date and time is a little tricky. Here's an example:Here is a simple way to convert  values into  instances.I found this code works:   you can find the rest in this tutorial:\n"},
{"body": "orI don't need to use 's' outside the loop ever again. \nThe first option is perhaps better since a new String is not initialized each time. The second however would result in the scope of the variable being limited to the loop itself.EDIT: In response to Milhous's answer. It'd be pointless to assign the String to a constant within a loop wouldn't it? No, here 'some Assignment' means a changing value got from the list being iterated through.Also, the question isn't because I'm worried about memory management. Just want to know which is better.Use your second option:If you disassemble code the compiled from each (with the JDK's  tool), you will see that the loop compiles to the exact same JVM instructions in both cases. Note also that  \"Option #3\" is identical to Option #1. Nothing extra is added or removed from the stack when using the tighter scope, and same data are used on the stack in both cases.The only difference between the two cases is that, in the first example, the variable  is unnecessarily initialized. This is a separate issue from the location of the variable declaration. This adds two wasted instructions (to load a string constant and store it in a stack frame slot). A good static analysis tool will warn you that you are never reading the value you assign to , and a good JIT compiler will probably elide it at runtime. You could fix this simply by using an empty declaration (i.e., ), but this is considered bad practice and has another side-effect discussed below. Often a bogus value like  is assigned to a variable simply to hush a compiler error that a variable is read without being initialized. This error can be taken as a hint that the variable scope is too large, and that it is being declared before it is needed to receive a valid value. Empty declarations force you to consider every code path; don't ignore this valuable warning by assigning a bogus value.As mentioned, while the JVM instructions are the same in both cases, there is a subtle side-effect that makes it best, at a JVM level, to use the most limited scope possible. This is visible in the \"local variable table\" for the method. Consider what happens if you have multiple loops, with the variables declared in unnecessarily large scope:The variables  and  could be declared inside their respective loops, but since they are not, the compiler uses two \"slots\" in the stack frame. If they were declared inside the loop, the compiler can reuse the same slot, making the stack frame smaller.However, most of these issues are immaterial. A good JIT compiler will see that it is not possible to read the initial value you are wastefully assigning, and optimize the assignment away. Saving a slot here or there isn't going to make or break your application.The important thing is to make your code readable and easy to maintain, and in that respect, using a limited scope is clearly better. The smaller scope a variable has, the easier it is to comprehend how it is used and what impact any changes to the code will have.In , it's a waste of resources to declare the string inside the loop. \nIn , however, both of the snippets you presented will compile down to the same code (declaration outside the loop).  So, if your compiler does any amount of optimization, there's no difference.In general I would choose the second one, because the scope of the 's' variable is limited to the loop. Benefits:If you want to speed up for loops, I prefer declaring a max variable next to the counter so that  no repeated lookups for the condidtion are needed:instead ofI preferAny other things that should be considered have already been mentioned, so just my two cents (see ericksons post)Greetz, GHadTo add on a bit to @, they will both require the creation of a new string each time through the loop (as the return value of the  expression). Those strings need to be garbage collected either way.I know this is an old question, but I thought I'd add a bit that is  related.I've noticed while browsing the Java source code that some methods, like String.contentEquals (duplicated below) makes redundant local variables that are merely copies of class variables.  I believe that there was a comment somewhere, that implied that accessing local variables is faster than accessing class variables.In this case \"v1\" and \"v2\" are seemingly unnecessary and could be eliminated to simplify the code, but were added to improve performance.It seems to me that we need more specification of the problem.The is not specified as to what kind of assignment this is.  If the assignment is then a new sting needs to be allocated.but if it is s will merely point to the constants memory location, and thus the first version would be more memory efficient.Seems i little silly to worry about to much optimization of a for loop for an interpreted lang IMHO.When I'm using multiple threads (50+) then i found this to be a very effective way of handling ghost thread issues with not being able to close a process correctly ....if I'm wrong, please let me know why I'm wrong:"},
{"body": "I am simply trying to see the H2 database content for an embedded H2 database which spring-boot creates when I don't specify anything in my application.properties and start with mvn spring:run. I can see hibernate JPA creating the tables but if I try to access the h2 console at the URL below the database has no tables.I see suggestions like this one:\nBut I don't know where to put the suggested XML in spring-boot and even if I did, I don't want the h2console to be available anymore when an external database is configured so it is more likely that I need to handle this with some kind of conditional code (or maybe just allow spring to automatically handle it in the most ideal case where I only include H2 when a maven profile is activated).Does anyone have some sample code showing how to get the H2 console working in boot (and also the way to find out what the jdbc connection string that spring is using is)?This is how I got the H2 console working in spring-boot with H2. I am not sure if this is right but since no one else has offered a solution then I am going to suggest this is the best way to do it.In my case, I chose a specific name for the database so that I would have something to enter when starting the H2 console (in this case, \"AZ\"). I think all of these are required though it seems like leaving out the spring.jpa.database-platform does not hurt anything. In application.properties:In Application.java (or some configuration):Then you can access the H2 console at {server}/console/. Enter this as the JDBC URL: jdbc:h2:mem:AZAs of Spring Boot , the H2 console can be auto-configured. The prerequisites are:Even if you don't use Spring Boot Dev Tools, you can still auto-configure the console by setting  to Check out  part of the documentation for all the details.I have found a nice tutorial about this topic: Basically the correct JDBC URL for me was: A similar answer with Step by Step guide.I had only below properties in /resources/application.properties. After running spring boot, using this URL(), the table in H2 console was visible and read to view the table data, also you can run simple SQL commands. One thing, in your java code, while fetching data, the column names are upper-case, even though schema.sql is using lower-case names :)From  H2 Web Console (H2ConsoleProperties):Adding the above two lines to my application.properties file was enough to access the H2 database web console, using the default username (sa) and password (empty).In order to get the tables all you need to do is create 2 sql files schema.sql(for table creation) and data.sql(data for the created tables). These files to be put in src/main/resources folder. Spring boot auto detects them and takes care of the rest during runtime.If your using more than 2 DB in your project ensure to use specific files like (schema-h2.sql -- for h2 DB , schema-oracle.sql -- for oracle DB). The same to be followed for data.sql too.Also ensure that you drop tables by adding drop table statement in your schema.sql as first statement. To avoid appending of duplicate records.The link for spring boot is here.My application.properties is as follows.You can follow the steps in the below link.If you use Spring Boot's developer tools, it comes with H2 Console enabled by default. It can be accessed from /. On the login interface, for input  use value . Pay attention to  string.If you don't use Spring Boot's developer tools, you can enable the console in  using . This will enable console under . If you want to change the URL then you can add another entry with .The default schema name is .More details in ."},
{"body": "I would like to concatenate a string within a ternary operator in EL(Expression Language).Suppose there is a variable named value. If it's empty, I want to use some default text. Otherwise, I need to append it with some static text.This will not compile however. What would be a correct way to write this? Or is this even possible?This answer is obsolete. Technology has moved on. Unless you're working with legacy systems see .There is no string concatenation operator in EL. If you don't need the concatenated string to pass into some other operation, just put these expressions next to each other:With EL 2 you can do the following:If you're already on EL 3.0 (Java EE 7; WildFly, Tomcat 8, GlassFish 4, etc), then you could use the new  operator for this:If you're however not on EL 3.0 yet, and the  is a genuine  instance (and thus not e.g. ), then use EL 2.2 (Java EE 7; JBoss AS 6/7, Tomcat 7, GlassFish 3, etc) capability of invoking direct methods with arguments, which you then apply on :Or if you're even not on EL 2.2 yet, then use JSTL  to create a new EL variable with the concatenated values just inlined in value:Since Expression Language 3.0, it is valid to use += operator for string concatenation.Quoting . is right. I just want to add an improvement if in case you may need to return the variable's value as:1.The +(operator) has not effect to that in using EL.\n2.so this is the way,to use that is this helpful to You ?it also can be a great idea using concat for EL + MAP + JSON problem like in this example :#{myMap[''.concat(myid)].content}"},
{"body": "Is it better to writeor I think the second one is better, should be faster and more memory optimized. But aren't they equal?For performance, it usually best to make the code as simple and clear as possible and this will often perform well (as the JIT will optimise this code best).  In your case, the simplest examples are also likely to be the fastest.I would do eitheror a longer versionorIts best not to create an object if you don't need to.Performance wise, the first is best.If you know for sure that you won't get an overflow you can useyou won't get faster than this.Use . And don'try to micro-optimize your code unless you can prove that you have a performance issue.May I propose a thirdWrapping int primitive into Integer object will cost you some memory, but the difference will be only significant in very rare(memory demand) cases (array with 1000+ elements). I will not recommend using new Integer(int a) constructor this way. This will suffice :About comparision there is Math.signum(double d).They're already ints. Why not just use subtraction?Note that Integer.compareTo() doesn't necessarily return only -1, 0 or 1 either.For pre 1.7 i would say an equivalent to Integer.compare(x, y) is:You can do this via the bit manipulation, something like this:If you are using java 8, you can create Comparator by this method:if you would like to compare with reversed order:"},
{"body": "I have a thick client, java swing application with a schema of 25 tables and ~15 JInternalFrames (data entry forms for the tables).  I need to make a design choice of straight JDBC or ORM (hibernate with spring framework in this case) for DBMS interaction.  Build out of the application will occur in the future.Would hibernate be overkill for a project of this size?  An explanation of either yes or no answer would be much appreciated (or even a different approach if warranted).TIA.Good question with no single simple answer.I used to be a big fan of Hibernate after using it in multiple projects over multiple years. \nI used to believe that any project should default to hibernate.Today I am not so sure.Hibernate (and JPA) is great for some things, especially early in the development cycle.\nIt is much faster to get to something working with Hibernate than it is with JDBC.\nYou get a lot of features for free - caching, optimistic locking and so on.On the other hand it has some hidden costs. . Follow some tutorial, put some annotations on your class - and you've got yourself persistence. But it's not simple and to be able to write good code in it requires good understanding of both it's internal workings and database design. If you are just starting you may not be aware of some issues that may bite you later on, so here is an incomplete list.The runtime performance is good enough, I have yet to see a situation where hibernate was the reason for poor performance in . The problem is the startup performance and how it affects your unit tests time and development performance. When hibernate loads it analyzes all entities and does a lot of pre-caching - it can take about 5-10-15 seconds for a not very big application. So your 1 second unit test is going to take 11 secods now. Not fun.It is very cool as long as you don't need to do some fine tuning on the database.For every transaction Hibernate will store an object in memory for every database row it \"touches\". It's a nice optimization when you are doing some simple data entry. If you need to process lots of objects for some reason though, it can seriously affect performance, unless you explicitly and carefully clean up the in-memory session on your own.Cascades allow you to simplify working with object graphs. For example if you have a root object and some children and you save root object, you can configure hibernate to save children as well. The problem starts when your object graph grow complex. Unless you are extremely careful and have a good understanding of what goes on internally, it's easy to mess this up. And when you do it is very hard to debug those problems.Lazy Loading means that every time you load an object, hibernate will not load all it's related objects but instead will provide place holders which will be resolved as soon as you try to access them. Great optimization right? It is, except you need to be aware of this behaviour otherwise you will get cryptic errors. Google \"LazyInitializationException\" for an example. And be careful with performance. Depending on the order of how you load your objects and your object graph you may hit \"n+1 selects problem\". Google it for more information.Hibernate allows easy schema changes by just refactoring java code and restarting. It's great when you start. But then you release version one. And unless you want to lose your customers you need to provide them schema upgrade scripts. Which means no more simple refactoring as all schema changes must be done in SQL. Hibernate requires exclusive write access to the data it works with. Which means you can't really use views, stored procedures and triggers as those can cause changes to data with hibernate not aware of them. You can have some external processes writing data to the database in a separate transactions. But if you do, your cache will have invalid data. Which is one more thing to care about.Hibernate sessions are single threaded. Any object loaded through a session can only be accessed (including reading) from the same thread. This is acceptable for server side applications but might complicate things unnecessary if you are doing GUI based application.I guess my point is that Hibernate is a good tool, but it's a complex tool, and it requires time to understand it properly. If you or your team members don't have such knowledge it might be simpler and faster to go with pure JDBC (or Spring JDBC) for a single application. On the other hand if you are willing to invest time into learning it (including learning by doing and debugging) than in the future you will be able to understand the tradeoffs better.Hibernate can be good but it and other JPA ORMs tend to dictate your database structure to a degree. For example, composite primary keys can be done in Hibernate/JPA but they're a little awkward. There are other examples.If you're comfortable with SQL I would strongly suggest you take a look at . It can do 90%+ of what Hibernate can but is far simpler in implementation.I can't think of a single reason why I'd ever choose straight JDBC (or even Spring JDBC) over Ibatis. Hibernate is a more complex choice.Take a look at the .No doubt Hibernate has its complexity.But what I really like about the Hibernate approach (some others too) is the conceptual model you can get in Java is better. Although I don't think of OO as a panacea, and I don't look for theoritical purity of the design, I found so many times that OO does in fact simplify my code. As you asked specifically for details, here are some examples :For all these reasons, I would choose Hibernate :-)I think either is a fine choice, but personally I would use hibernate.  I don't think hibernate is overkill for a project of that size.Where Hibernate really shines for me is dealing with relationships between entities/tables.  Doing JDBC by hand can take a lot of code if you deal with modifying parent and children (grandchildren, siblings, etc) at the same time.  Hibernate can make this a breeze (often a single save of the parent entity is enough).There are certainly complexities when dealing with Hibernate though, such as understanding how the Session flushing works, and dealing with lazy loading.Hibernate best suits for the middleware applications. Assume that we build a middle ware on top of the data base, The middelware is accessed by around 20 applications in that case we can have a hibernate which satisfies the requirement of all 20 applications.Straight JDBC would fit the simplest cases at best. If you want to stay within Java and OOD  then going Hibernate or Hibernate/JPA or any-other-JPA-provider/JPA should be your choice. If you are more comfortable with SQL then having Spring for JDBC templates and other SQL-oriented frameworks won't hurt. In contrast, besides transactional control, there is not much help from having Spring when working with JPA.You could look at  which doesn't use session objects ... and where lazy loading just works. Certainly an option, not overkill, and will be simpler to understand."},
{"body": "The idea is to have a String read and to verify that it does not contain any numeric characters. So something like \"smith23\" would not be acceptable. What do you want? Speed or simplicity? For speed, go for a loop based approach. For simplicity, go for a one liner RegEx based approach.Java 8 lambda expressions. Both fast and simple.Or if you are using Apache Commons, .I used this regex expression . With  statement it will avoid all expressions that have a letter before, at the end or between any type of other character.A  way to do it is by:Because you don't have to run the whole  to check if it isn't an .I know it's a bit crowded. I was using it with my program and felt the desire to share it with people. It can tell if any character in a string is not a letter or not. Use it if you want something easy to clarify and look back on.Faster way is below. Considering letters are only a-z,A-Z.Runtime is calculated in nano seconds. It may vary system to system.Check this,i guess this is help you because it's work in my project so once you check this codeTry using regular expressions: "},
{"body": "Have Googled extensively on this error, but I can't seem to fix the problem. I've written a basic java program in Eclipse Juno, as follows:After clicking Run, I get: \"Error: Could not find or load main class HelloWorld\". This error message applies to all my other projects in the same workspace. I've tried switching workspaces but the error still appears.I'm on Windows 7 64-bit. Any help would be appreciated!I just ran into that problem. The cause... not sure. However, only happened after I added a new jvm.\nMy solution: In the Classpath tab:I hope it helps someone out there. It took me time to figure this out.This just happened to me today after updating my JRE. I cleaned the project and it started working again. will remove any existing class files and completely rebuild the project. There's more information on Eclipse's clean function .I deleted a jar file from the bin directory.  Right click on your project - Properties then Libraries tab.  There was a red flag in there.  I removed the jar file from the Libraries and it worked.It seems that the class is not compiled by Eclipse.Few pointers could be-Same Problem occur with me.I went to project > properties > javaBuildPath.There In order of export , I moved up my java/main to the top preoritythat's because you guys created the class one time with the main method & after that may be you have been deleted that form or workplace & still some of the files exist ,i will suggest you to create that form or workspace again & then delete it by clicking on it completely,then after that if you created the some class like Runner class try to run it again.This happened to me. I noticed that someone said I have to create an entire new WORKSHOP! Why? Because I installed a newer JRE version and that won't allow other previous versions to run on it. So all those old files I have become useless in a way. Not really, Just copy and paste it to new class and change it to an unused class name.if your package name is same with your class name this problem will occur."},
{"body": "I use RegexBuddy while working with regular expressions. From its library I copied the regular expression to match URLs. I tested successfully within RegexBuddy. However, when I copied it as Java  flavor and pasted it into Java code, it does not work. The following class prints : Does anyone know what I am doing wrong?Try the following regex string instead. Your test was probably done in a case-sensitive manner. I have added the lowercase alphas as well as a proper string beginning placeholder.This works too:Note:The best way to do it now is:EDIT: Code of  from  :I'll try a standard \"Why are you doing it this way?\" answer...  Do you know about ?The above will throw a  if it can't parse the URL.The problem with all suggested approaches: all RegEx is All RegEx -based code is over-engineered: it will find only valid URLs! As a sample, it will ignore anything starting with \"http://\" and having non-ASCII characters inside.Even more: I have encountered 1-2-seconds processing times (single-threaded, dedicated) with Java RegEx package (filtering Email addresses from text) for very small and simple sentences, nothing specific; possibly bug in Java 6 RegEx...Simplest/Fastest solution would be to use StringTokenizer to split text into tokens, to remove tokens starting with \"http://\" etc., and to concatenate tokens into text again.If you want to filter Emails from text (because later on you will do NLP staff etc) - just remove all tokens containing \"@\" inside.This is simple text where RegEx of Java 6 fails. Try it in divverent variants of Java. It takes about 1000 milliseconds per RegEx call, in a long running single threaded test application:Do not rely on regular expressions if you only need to filter words with \"@\", \"http://\", \"ftp://\", \"mailto:\"; it is huge engineering overhead. If you really want to use RegEx with Java, try This works too:Note: So probably the first one is more useful for general use. In line with billjamesdev answer, here is another approach to validate an URL without using a RegEx:From  lib, look at class . Some example code:Construct a UrlValidator with valid schemes of \"http\", and \"https\".If instead the default constructor is used.prints out \"url is valid\"When using regular expressions from RegexBuddy's library, make sure to use the same matching modes in your own code as the regex from the library.  If you generate a source code snippet on the Use tab, RegexBuddy will automatically set the correct matching options in the source code snippet.  If you copy/paste the regex, you have to do that yourself.In this case, as others pointed out, you missed the case insensitivity option."},
{"body": "I've developed a simple demo application with a splash screen a map and some regular screens.I have an action bar at the top that contains a logo. It all looks fine on my phone (Galaxy s1 I9000 V2.3) but when i test it on Galaxy s2 v4 the action bar appears also in the splash screen and in the map screen.The spalsh and map activity are not even inheriting from ActionBarActivity so how is that possible and how can i make it go away?Manifest:MapActivity definition (it's a long one so i included just the definition):Splash Activity:Apply the following in your Theme for the Activity in :That should do the trick.As you are asking about how to hide in a certain activity ; I  think .hide(); is what you need or 1.Go to your  file.2. the  for which you want to hide your ActionBar and then  ,The  usually exists along  so from the  you can hide itand from the  you can do it    If you want to get full screen without actionBar and Title.Add it in style.xmland use the style at activity of manifest.xml.If you were using Theme.AppCompat.Light, a better equivalent would be Theme.AppCompat.Light.NoActionBar.I found that using Theme.AppCompat.NoTitleBar caused my button text to be invisible so I am using Theme.AppCompat.Light.NoActionBar.You can use Low Profile mode\nJust search for  that also dims the navigation buttons if they are present of screen.The above answers would help with the ActionBar thing. To add to it, use the following code in case you are using the Splash Screen:\nUse this before you set the content view:Just to clarify, here's how you do it:This would make your screen a full screen, i.e remove the top bar where you see the network bar, etc"},
{"body": "Since I implented app compat my searchview doesn't work anymore:So nullpointer for searchview while I have it:And in my menu I have this:I have no idea why it doesn't work anymore but it happened since I started using app compat 21.Regards,Try using the custom  namespace for your  too:This could also happen if you have proguard enabled and it is striping aways  class. You would need to modify proguard settings to keep the class.See  question for more details.after a while of playing \"run & error\" I found a solution.. Looks like the UI-element isn't the reason what causes the error. After setting the search to the QueryListener it is working well. Here is some code: which contains the SearchBar:And the \"SearchBar\" in And last, but not least, the  (but this should be clear)... more information -> Add the following line to  file located inside  folder:It\u00b4s an additional information to Simas answer. I found this in another answer () and it was very important for solving my exception:After you've clicked on a result, your app is expecting that an operation has not completed and is trying to go further into an Intent argument. and return  which notifies your app that the click operation has completed."},
{"body": "I've been trying to convert a value of seconds (in a BigDecimal variable) to a string in an editText like \"1 hour 22 minutes 33 seconds\" or something of the kind. I've tried this:(I have a roundThreeCalc which is the value in seconds so I try to convert it here.)Then I set the editText to sequnceCaptureTime String.\nBut that didn't work. It force closed the app every time. I am totally out of my depth here, any help is greatly appreciated. Happy coding! You should have more luck withThis will drop the decimal values after each division.Edit: If that didn't work, try this.  (I just wrote and tested it)Is it necessary to use a BigDecimal? If you don't have to, I'd use an int or long for seconds, and it would simplify things a little bit:You might want to pad each to make sure they're two digit values(or whatever) in the string, though., formats an elapsed time in the form \"\" or \"\" . It returns the String you are looking for. You can find the documentation Here is the working code:Here's my function to address the problem:I use this:know this is pretty old but in java 8:LocalTime.MIN.plusSeconds(120).format(DateTimeFormatter.ISO_LOCAL_TIME)I prefer java's built in  libraryIf you want the units ,  and  for a duration you can use this:That's a lot of conditional operators. The method will return those strings:This is my simple solution:"},
{"body": "Is Python slower than Java/C#?Here is a project that optimizes CPython:  Don't conflate Language and Run-Time.Python (the language) has many run-time implementations.Note that Python (the language) is not slow.  Some Python run-times (CPython, for example) will be slower than native-code C++.It is not really correct to ask why Python is slower than Java/C#. How fast is Java? Well, naive interpreters are around ten times slower than optimised compilers. I believe there is a Java bytcode interpreter written in JavaScript - that probably isn't very fast. So, the intended question appears to be \"Why is the CPython language system slower than the equivalent Sun, IBM and Oracle JRE and Microsoft .NET runtime?\"I believe the correct answer is non-technical. The fastest Java and .NET runtime are faster because they have large full time technical teams developing them in performance-competitive environment.Dynamic language systems are easy to implement. Any idiot can do it. I have. Static language systems are more complex to design and implement. A simple static system will tend to run much faster than the equivalent just-working dynamic equivalent. However, it is possible for highly optimised dynamic systems to run almost as fast. I understand some Smalltalk implementation were quite good. An often quoted example of a developed dynamic system is the .In addition if the real grunt is being done by library code, then the language system may not matter. Alternatively, the language may encourage (or give time(!)) to develop more efficient algorithms which can easily wipe out constant factor performance differences.As mentioned in the other answers this depends on the run-time system as well as the task at hand. So the standard (C)Python is not necessarily slower than Java or C#. Some of its modules are implemented in C. Thus combining speed of a  implementation with Python's language.We did a small experiment: We compared the execution time of a Factorial computation in different languages. The test was actually intended to evaluate the performance of arbitrary-precision integers implementations.The bar chart shows the results. Python is the clear winner. As far as I know Python uses the  to multiply large integers, which explains the speed.Besides, Python's \"arbitrary-precision integers\"-type is the built-in . Hence you don't even need special type handling which is required for Java's BigInteger-class.As suggested in comments, you should really provide a test case to reason about. Reasons behind performance differences will change depending on the test being executed.However, I'd suggest that the static vs dynamic nature may well have a lot to do with it. For non-virtual calls, the JIT-compiled C#/Java is extremely cheap as it can be determined accurately at JIT-time. Even virtual calls just involve a single level of redirection. When binding becomes dynamic, there's a wider range of things to consider.I don't know enough details about Python to claim to understand its exact runtime behaviour, which I suspect may vary with version and implementation too. There is such a thing as \"python byte code\" which is then executed by a virtual machine - whether this virtual machine actually performs JIT-compilation or not is another matter.It boils down to the fact that the compilation phase has lesser information to work with and hence the runtime needs to do more work in case of duck typed (dynamically typed) languages. Thus if I am making the method invocation foo.bar(), in case of Java or C++ the invocation to bar can be optimized in the compilation process by discovering the type of \"foo\" and then directly invoking the method at the memory location where the compiler knows it will be found. Since a python or any other dynamically typed language compiler does not know what type the object foo belongs to, it has to do a type check at runtime and then look up the address of the bar method and then invoke it. There are other difficulties a python compiler writer struggles with as well, though the one above hopefully adequately gives an indication. So even with the best compiler writers, statically typed languages are likely to perform much better at runtime.Where dynamically typed languages score are typically in the development time. Due to fewer lines of code to write and maintain, and no compile wait times for developers, the development often goes through much faster.Simply - . No matter what interpreter (currently available) you use, it is slower than Java and C. In various benchmarks, its slower than Ruby and PHP.\nDo not depend on other's answers, check and verify yourself. Personally I do not think, there is much serious contribution and development done on getting python faster. Since the productivity is good in python and it solves some of problem straight forward, speed/performance is not taken seriously. There are some architecture issues too preventing Python getting performance tweaks. - This answer probably will hurt Python lovers. I too am Python developer, loves developing webapps in Django/Flask/Pyramid rather than Spring (Java). But I see practically in my work and experience, how Python is slower. The speed is not always my priority. But I do stand with them, who says Python Interpreter should get oiling and greasing or total engine change to at least stand in marathon. It's a mainstream programming language.What you got there is clear example of writing Java in Python:A bit more pythonic:I think it's ultimately that Python doesn't go as far as it can with optimizations.  Most of the optimization techniques that are common are for static languages.  There  optimization techniques for dynamic languages, but the modern ones don't seem to make as much use of them as they could.  Steve Yegge has an excellent .:  I just wanted to point out that I'm not necessarily stating this to be critical of Python.  I prefer simplicity over unnecessary speed any day. It doesn't have anything to do with the languages themselves, it's just the fact that java  and  (JVM) are very high quality, and that lots of resources have been invested in stability, scalability and performance improvements over the years.Contrast that to the fact that CPython implementation just recently implemented eg threaded dispatch in its interpreter which gave it performance boost of up to 20% for certain problems. It's not a good thing as it sounds, it is bad because that kind of basic optimization should be there from the day one.This type of question can't be answered just by qualitative reasoning, you need good benchmarks to back it up.  Here's one set that compare  and find Python to be 3 to 300 times slower.  The Python vs. Java results are similar.  (The usual cautions about interpreting benchmarks apply.)These benchmarks also report the source code size, and Python was significantly more concise than Java and C#.I think opposite. I can do simple program in Python faster than in Java,\nand those Python scripts work really fast.Of course your question without examples is hard to answer. Maybe you have found slow library, bug etc. Give us more details please.I would argue that the ease and simplicity of writing Python code makes it possible to write more complex code; for example, code that takes advantage of multi-core processors.  Since per-core performance has been mostly stagnant for the past 5-10 years, I don't think it's clear that Python programs (whether they're running on CPython or something else) are slower in the long run.Since it's interpreted and not compiled.. it should be slower in execution time. As a table mentioned in  book, page 600, C# equals C++ in  (1:1). And Python is slower above hundred times than C++ in  (>100:1).And Java is slower than C++ by one time and a half (1.5:1). These statistics are on average. I don't know who made this study, but seems interesting.   "},
{"body": "my  do not call ,  even  constructor, therefore, does not appear anything in .\nI put logs for debugging, and no log is shown.\nWhat can be?\nMy adapter:My custom row XML:and my Fragment:Your  method . So  never tries to instantiate a view. Make it return something .Another one is make sure you set layout manager to RecyclerView:FWIW, I observed it when I set the recycler view adapter  the adapter was actually initialized. Solution was to make sure  was called with a non-null adapter This happened when my  was inside a  and I was using Android Support Library 23.0. To fix, I updated to Android Support Library 23.2:In build.gradle:This does not apply for your particular case. But this might help someone else.This reason could be careless usage of the following methodIf not used with caution, this might cause the  and  to not be called at all, with no error in the logs.Setting the height of the  in the  or . If height is , the  will not be visible.Please set layout manager to RecyclerView like below code:RecyclerView recyclerView = (RecyclerView) findViewById(R.id.recycler_view_right);\nNavigationAdapter adapter = new NavigationAdapter(this, FragmentDrawer.getData());\nrecyclerView.setAdapter(adapter);\nrecyclerView.setLayoutManager(new LinearLayoutManager(this));In my case I set the ID of my RecyclerView to \"recyclerView\". It seems that this ID was already defined somewhere, because when I changed that to different ID, the methods from the adapter were called properly.Other option is if you send this list objetc using get,verify if you have correct reference,for exampleIf using a custom adapter do not forget to set the ItemCount to the size of your collection."},
{"body": "I get connection failures that appear randomly when connecting to an HAProxy server using SSL. I have confirmed that these failures happen on JDK versions 1.7.0_21 and 1.7.0_25 but not with 1.7.0_04 or with 1.6.0_38.The exception is These failures only happen when using the TLS SSL context and not with the default context. The following code is run in a loop a thousand times and failures happen before the loop completes (about 2% of the connections fail):If, however, I create the SSL context this way I have no connections failures on any of the Java versions I mentioned:The first way uses  and the later uses . Looking at the code, I don't see any differences that would cause the exception to occur.Why would I be getting the failures and what are the advantages/disadvantages of using the  call?Note: The exceptions were first seen using the Apache HttpClient (version 4). This code is the smallest subset that reproduces the problem seen with HttpClient.Another piece of information is that the errors do not occur if I turn off Diffie-Hellman on the proxy server.Judging by the symptoms, I'm  this is related to browsers using , which is a client-side trick Google introduced to :From the : (emphasis mine)javax.net.ssl.SSLPeerUnverifiedException arise only because of http security you have to configure your connection as https else follow this code..use this. i hope it will help you"},
{"body": "I wonder if anyone could tell me how casting works? I understand  I should do it, but not really how it works. On primitive data types I understand partially but when it comes to casting objects I don't understand how it works.How can a object with the type Object just suddenly be cast to, let's say,  (just an example) and then get all the methods?Casting in Java isn't magic, it's you telling the compiler that an Object of type A is actually of more specific type B, and thus gaining access to all the methods on B that you wouldn't have had otherwise. You're not performing any kind of magic or conversion when performing casting, you're essentially telling the compiler \"trust me, I know what I'm doing and I can guarantee you that this Object at this line is actually an <Insert cast type here>.\" For example:The above is fine, not magic and all well. The object being stored in o is actually a string, and therefore we can cast to a string without any problems.There's two ways this could go wrong. Firstly, if you're casting between two types in completely different inheritance hierarchies then the compiler will know you're being silly and stop you:Secondly, if they're in the same hierarchy but still an invalid cast then a  will be thrown at runtime:This essentially means that you've violated the compiler's trust. You've told it you can guarantee the object is of a particular type, and it's not.Why do you need casting? Well, to start with you only need it when going from a more general type to a more specific type. For instance,  inherits from , so if you want to store an  as a  then that's ok (since all Integers are Numbers.) However, if you want to go the other way round you need a cast - not all Numbers are Integers (as well as Integer we have , , , , etc.) And even if there's just one subclass in your project or the JDK, someone could easily create another and distribute that, so you've no guarantee even if you think it's a single, obvious choice!Regarding use for casting, you still see the need for it in some libraries. Pre Java-5 it was used heavily in collections and various other classes, since all collections worked on adding objects and then casting the result that you got back out the collection. However, with the advent of generics much of the use for casting has gone away - it has been replaced by generics which provide a much safer alternative, without the potential for ClassCastExceptions (in fact if you use generics cleanly and it compiles with no warnings, you have a guarantee that you'll never get a ClassCastException.)Actually, casting doesn't always work. If the object is not an  the class you're casting it to you will get a  at runtime.Casting a reference will only work if it's an  that type. You can't cast random references. Also, you need to read more on e.g.Suppose you wanted to cast a String to a File (yes it does not make any sense), you cannot cast it directly because the File class is not a child and not a parent of the String class (and the compiler complains). But you could cast your String to Object, because a String is an Object (Object is parent). Then you could cast this object to a File, because a File is an Object. So all you operations are 'legal' from a typing point of view at compile time, but it does not mean that it will work at runtime !The compiler will allow this even if it does not make sense, but it will crash at runtime with this exception:"},
{"body": "This is pretty simple, I come from a swing/awt background.I'm just wondering what the proper way to set the background color for a SWT widget is?I've been trying:Except I have no idea how to create the color Object in SWT?To create a color, try this:For standard colors (including common colors and default colors used by the operating system) Use , and pass in the  constant for the color you want.Note that you do not need to dispose these colors because SWT created them.Remember that in SWT you must explicitly dispose any resources that you create when you are done with them.  This includes widgets, fonts, colors, images, displays, printers, and GCs.  If you do not dispose these resources, eventually your application will reach the resource limit of your operating system and the application will cease to run.See also: "},
{"body": "In WebDriver, if I use sendKeys it will append my string to the value that already exists in the field.  I can't clear it by using clear() method because the second I do that, the webpage will throw an error saying that it has to be between 10 and 100.  So I can't clear it or an error will be thrown before I can put in the new value using sendKeys, and if I sendKeys it just appends it to the value already there.Is there anything in WebDriver that lets you overwrite the value in the field?I think you can try to firstly select all the text in the field and then send the new sequence:You can also clear the field before sending it keys.Okay, it is a view days ago...\nIn my current case, the answer from ZloiAdun does not work for me, but brings me very close to my solution...Instead of:the following code makes me happy:So I hope that helps somebody!This worked for me.In case it helps anyone, the C# equivalent of ZloiAdun's answer is:Use this one, it is trusted solution and works well for all browsers:If input has type=\"file\" - do not clear it for IE. It will try to find file by empty path and will throw a bug.More details you could find This solved my problem when I had to deal with HTML page with embedded JavaScript Had issues using most of the mentioned methods since textfield had not accepted keyboard input, and the mouse solution seem not complete.This worked for to simulate a click in the field, selecting the content and replacing it with new."},
{"body": "I was asked the following question in my interview yesterday:Consider a Java or C++ array say  which is sorted and no two elements in it are same. How best can you find an index say  such that element at that index is also . That is .As clarification she also gave me an example:The best I could think was a linear search. After the interview I though a lot on this problem but could not find any better solution. My argument is: the element with the required property can be anywhere in the array. So it could also be at the very end of the array so we need to check every element.I just wanted to confirm from the community here that I'm right. Please tell me I'm right :)ThanksThis can be done in  time and  space by using a slightly modified .Consider a new array  such that Since the elements in  are in  order, the elements in the\nnew array  will be in  order. So a  for  in  will give the answer.But creating  will take  space and  time. So instead of\ncreating the new array you just modify the binary search such that a\nreference to  is replaced by .Algorithm:\nThere are some faster solutions, averaging O(log n) or in some cases O(log log n) instead of O(n). Have a google for  and , you're likely to find very good explanations.If the array is unsorted, then yes, the element is anywhere and you can't get under O(n), but that's not the case with sorted arrays.--Some explanation on interpolation search as requested:While the binary search only concerns with comparing two elements in terms of \"greater / not greater\", the interpolation search tries to also make use of . The point is: You have a sorted range of values from 0 to, say, 20000. You look for 300 - binary search would start at the half of range, at 10000. The interpolation search guesses that 300 would probably be somewhere closer to 0 than 20000, so it would check the element 6000 first instead of 10000. Then again - if it's too high, recurse into lower subrange, and it's too low - recurse into upper subrange.For a big array with +- uniform distribution of values, interpolation search should behave much faster than binary search - code it and see for yourself. Note that it's the thing a human does intuitively when looking up something in a dictionary.I think this would be faster.Start in the middle of the listIf X[i] > i then go to the middle of the remaining left sideif X[i] < i then go the middle of the remaining right Keep doing that and it will reduce the number of possible elements by half for each loopIts not require to think in terms of any array  as suggested in  by @codaddict.Use binary search and check the middle element of given array, if it is lower than its index, than we do not need to check for any lower index because the array is\nsorted and so if we move to the left, subtracting m indexes and (at least) m value, all subsequent elements will also be too small. E.g. if  then  and  and so on. Similar logic can be apply if middle element is greater than its index.Here is simple  implementation:Note that the above solution would work only if all elements are distinct.You can perform a binary search:\nsearch the middle, if the value is lower than the index, than no lower index will contain the same value.Then you search the higher half, and continue till you find the element, or reach one element span.Your linear search idea looks to be correct, yes. I personally can't think of another way to find the value, unless you sorted in such a way that the value you want is always in the first element.EDIT: Ok I'm wrong. Apologies!This is a solution I came up with, and it works if there are duplicates (I mistakenly overlooked that caveat of there being no duplicates).I would guess this takes O(log n) time, but this isn't clear in first glance???If you're unlucky, it'll take O(n log n) time (the height of the stack tree will be log n, and it will be a full tree, with n nodes in the last level, n/2 in next to last, etc.). So, on average it will be between O(log n) and O(n log n). Yes, I believe you are right. No logarathmic search would be possible, as there is no way to halven the data we have. We will need to look at all the index in the array.@Kos, I don't see how sorting the array would make any difference?of the top of my head, doing binary splitting might be faster.look at the middle value, if it is high then what you need, re-search in the lower half.After one comparison, you have already spilt your data set in halfAfter reading the question it seems like there is one scenario that can be used to speed up the lookup.  When comparing the position to the value, if the value is greater then the position then the value can be used as the next position to evaluate.  This will help jump through the array faster.  This can be done because the array is sorted.  The values that we are skipping are conceptually shifted to the left in the array and are in the wrong location.Example:If my current position is 2 and it has a value of 4 they are not equal and conceptually the value 4 is shifted to the left.  I can use the value of 4 as my next position because if the value 4 is out of position then everything less then 4 is out of position as well.  Some example code just for the sake of discussion:Modified version of Binary Search would suffice I guessSuppose the sequence is orFrom both the examples we see that the required result will never lie on the right side if mid < a[mid]... pseudocode would look something like thisJava:C++:"},
{"body": "I'm trying to format a date in Java in different ways based on the given locale. For instance I want English users to see \"Nov 1, 2009\" (formatted by \"MMM d, yyyy\") and Norwegian users to see \"1. nov. 2009\" (\"d. MMM. yyyy\").The month part works OK if I add the locale to the SimpleDateFormat constructor, but what about the rest?I was hoping I could add format strings paired with locales to SimpleDateFormat, but I can't find any way to do this. Is it possible or do I need to let my code check the locale and add the corresponding format string?Use  instead of creating your own patterns with .Use the :  Check  Run the following example to see the differences:Localization of date string:Based on redsonic's post:will be like 05-\u4e5d\u6708-2013The troublesome classes of  and  are now legacy, supplanted by the java.time classes.The  class represents a date-only value without time-of-day and without time zone.A time zone is crucial in determining a date. For any given moment, the date varies around the globe by zone. For example, a few minutes after midnight in  is a new day while still \u201cyesterday\u201d in .Use  to generate strings representing only the date-portion or the time-portion.The  class can automatically .To localize, specify:Example:Going the other direction, you can parse a localized string.Note that the locale and time zone are completely orthogonal issues. You can have a Montr\u00e9al moment presented in Japanese language or an Auckland New Zealand moment presented in Hindi language. Another example: Change  (Spanish) to  (standard  format). The java.time classes use ISO 8601 formats by default for parsing/generating strings.The  framework is built into Java 8 and later. These classes supplant the troublesome old  date-time classes such as , , & .The  project, now in , advises migration to java.time.To learn more, see the . And search Stack Overflow for many examples and explanations. Specification is .Where to obtain the java.time classes? The  project extends java.time with additional classes. This project is a proving ground for possible future additions to java.time. You may find some useful classes here such as , , , and ."},
{"body": "What is the best way to exit/terminate a while loop in Java?For example, my code is currently as follows:Use :However, if your code looks  like you have specified you can use a normal  loop and change the condition to :Finding a  construct with  in my code would make my eyes bleed. Use a standard  loop instead: And take a look at the link Yacoby provided in his , and this one too. Seriously. Take a look at the  by Oracle.But basically, as , use .If you can it is often clearer to avoid using break and put the check as a condition of the while loop, or using something like a do while loop. This isn't always possible though. is what you're looking for:alternatively, restructure your loop:or:You can do multiple condition logical tests within the while() check using the same rules as within any logical check.works, as doesare valid. The conditionals are checked on each iteration through the loop. As soon as one doesn't match, the while() loop is exited. You can also use break;You can use \"break\", already mentioned in the answers above. If you need to return some values. You can use \"return\" like the code below:                                                        in this case, this while is in under a method which is returning some kind of values. if you write . its means that loop will not stop in any situation for stop this loop you have to use break statement between while block."},
{"body": "I have Spring/Java App that is compiled with .I have a new Linux setup where I downloaded .I downloaded .I set the path in bash as follows:Java -version reports:And set in setnenv.sh (for Tomcat):When I deploy my WAR file I get below error.\nI think Tomcat doesn't seem to use the Java I installed.\nI have followed the setup instructions.\nPS: I also tried JRE instead of JDK and same issue.The class that's throwing the exception is using this code to check for Java version:So, when Spring 2.5 was first released, the code didn't assume it will be run in a Java version that's later than 1.7. For Java 8 and beyond, the code above will assume default 1.4 version. Because of this, the annotations part will complain.I think you either need to upgrade your Spring version or use Java 7.  for quite some time now, anyway.TO =>ORI have the similar problem. Old Spring MVC/Spring Faces application  under spring 2.5.5 doesn't run on Java 8.I spent few days trying to find solution because we need to run Java 8.  First idea was:  to upgrade complete Spring package up to 4.1.6. I used Maven. Problem of this method that after that it is  necessary to rework nearly the whole project.  It is  because for example in Spring 4 were removed JSF implementation and some special taglibs where completely removed, like . And were some more major and minor problems with configuration, adapters, handlers, mappings.... Second approach was to replace Spring JARs partially.One by one. Again no success. Impossible to replace any jar without touching dependencies.I believe that after few weeks or monthes of struggling I can get success on both approaches. But have no so much time. And I gave up.\nMy solution is:I found source file JdkVersion.java from org.springframework.core package. .\nI created org.springframework.core package in my project with only one class JdkVersion. After that made simple change of the code to check Java 8 version. Smth like that: ...Even this code change is not really necessary, only just for fun.It is because this source came from Spring 3.0.0 package where Spring guys already changed the Java version check. Versions higher than 7 are not considered as old java. Now application starts properly. It call JdkVersion class from my project instead of jar.Works so far! Thanks for all from this thread who gave this idea.ThanksI need to support Spring 2.5.5 on Java 8, so I used the approach from  to provide a future-proof drop-in replacement for  with as few side-effects as possible (nobody else posted a complete class, and I didn't want to hijack the other answer). There is no need to check for Java 8, simply default to Java 7, which is the highest version the class cared about:Extract the jar file:Check the Spring version in  (you should see something like ). Look up the  of  and use that as a starting point (the example below is for Spring 2.5.5 and you don't want to change any method signatures from the version you're working with).Check the major and minor version of the  file:We see that the class was original compiled as target  (, we find that is Java 1.4):Create  with the following content:Then compile the new class as Java 1.4:You can check the major.minor version again as above if needed.Create the modified jar file (without overwriting the original manifest):Copy the modified jar file where needed (as  or as appropriate).I happen to be another unfortunate user of a very old project (developed in 2008!) which is still using Spring 2.5. And it is not a Maven project either, so upgrading to later versions of Spring was taking a long time with dependencies failing and giving build errors. I downgraded tomcat JRE to 1.7 and it worked fine. Just documenting how to do that in eclipse in case someone needs help:Migrate your spring version from 2.5 to >=3.2.3.For Spring migration you need to do following changes - 1) In your pom.xml remove dependency for spring 2.5.6 and add dependency for spring new version.2) Update 'xsi:schemaLocation' in beans tag of applicationcontet.xml file of your project.e.g update  to \n for spring 3.2.3 version.3) Clean,build and re-deploy your project.i had the same problem, but i have a solution:in your project file pom.xml replace:for:and say good bye to your problems!!This two dependecies are the replacement for the firts dependency in the most part.I was facing the same issue. But, after trying very hard, I found out that this is because of using Java 1.8. I changed it to 1.6 and it worked.I created a fully automatic version of the answer by valismortis.\nPlease read his post first for the subtleties he addresses.build file contents:"},
{"body": "I have some junit tests which create some resources which should also be closed.One way to implement this logic is using the  and  approach.What I did was to encapsulate the creation in some utility class to be reused. For example:The whole point is for the object to close itself, rather than needing to remember to close it in .The usage should be:The problem is that junit's assert keyword throws an  - not .* Couldn't find the answer in the .It does not  anything. But it does  close all resources. blocks .The pseudo-code of a basic  statement is (cf ):As you can see it catches  not  which includes  but  in order to add as suppressed exceptions any exceptions that occurred while closing the resources.You can also notice that your resources are closed in the  block which means that  (except in case of a  of course as it terminates the currently running Java Virtual Machine) even in case an  or any sub class of  is thrown.Try-with-resources don't catch anything in and of themselves.However, you can attach a  block to the end of the try-with-resources block, to catch whatever types of  you like:The idea behind  is to make sure that the resources should be closed.The problem with conventional  statements is that let's suppose your  block throws an exception; now usually you'll handle that exception in  block. Now suppose an exception occurs in finally block as well. In such a case, the exception thrown by try catch is  and the exception generated in  block gets propagated.In  the  method of the resource will get automatically called, and if the  throws any exception, the rest of the  isn't reached, and the original exception is lost.Contrast that with this:in the above code snippet, the  method automatically gets called and if that  method also generated any exception, than that exception will automatically get suppressed.See also: Misconception on your end: try-with-resources does  do a .It does a  , therefore the kind of \"problem\" doesn't matter.See the  for further information!"},
{"body": "I'd like to know some cases in Java (or more generally:\nin programming) when it is preferred in boolean expressions to use the unconditional  () instead of the conditional version ().I know how they work, but I cannot think about a case when use the single  is worth it.I have found cases in real life where both sides of the expression were really cheap, so it shaved off a nanosecond or two to avoid the branch and to use the unconditional  instead of .  (These were extremely high-performance math utilities, though; I would almost never use this in other code, and I wouldn't have done it anyway without exhaustive benchmarking to prove it was better.)(To give specific examples,  is going to be super cheap and side-effect-free.  Why bother risking a branch misprediction to avoid a test that's going to be so cheap anyway?  Sure, since it's a  the end result is going to be used in a branch anyway, but  involves two branches, and  involves only one.)The only difference is that  and  stop the evaluation as soon as it is known. So for example:works well with , but with  you could get a NullPointerException if a is null.The only case I can think about where you want to use  is if the second operand has a side effect, for example (probably not the best example but you get the point):However, this looks like smelly code to me (in both cases).The && allows the jvm to do short circuit evaluation. That is, if the first argument is false, then it doesn't need to bother checking the second argument.A single & will run both sides regardless.So, as a contrived example, you might have:In that example, you might always want to log the fact that the owner of the account attempted to do something.I don't think I have ever used a single & in commercial programming though.Wikipedia has nicely described the  From the same link:If there are side effects that must happen, but that's a little ugly. The bitwise AND () is mostly useful for just that - bitwise math.Input validation is one possible case.  You typically want to report all the errors in a form to the user in a single pass instead of stopping after the first one and forcing them to click submit repeatedly and only get a single error each time:Granted, you could trivially avoid the need for short circuit evaluation in  by refactoring the  logic outside of ; but then you'd need to call the extracted code every time validateField() was called; at a minimum adding 10 extra lines for method calls.  As always it's a case of which tradeoff's work best for you.If the expression are trivial, you may get a micro-optimisation by using  or  in that you are preventing a branch. ie.is the same aswhich has two places a branch can occur.    However using an unconditional  or , there can be only one branch.Whetehr this helps or not is highly dependant on what the code is doing.If you use this, I sugegst commenting it to make it very clear why it has been done.There isn't any specific use of single & but you can consider the following situation.Consider that  is doing some operation which will modify instance variables or do something which will impact behavior later in processing.So in this case if you use  operator and the first condition fails it will never go in . In this case single  operator will suffice.Because  is a bit-wise operator, you can do up to 32-checks in a single operation concurrently. This can become a significant speed gain for this very specific use cases. If you need to check a large number of conditions, and do it often and the cost of boxing/unboxing the conditions are amortized by the number of checks, or if you store your data on-disk and on-RAM in that format (it is more space efficient to store 32 conditions in a single bitmask), the  operator can give a huge speed benefit over a series of 32 individual . For example if you want to select all units that can move, is an infantry, has weapon upgrade, and is controlled by player 3, you can do:See  on a related question for more on the topic.The only benefit I can think of is when you need to invoke a method or execute a code, no matter the first expression is evaluated to  or :Although you can do this without :Short-circuiting can lead to errors in branch prediction on modern processors, and dramatically reduce performance (a notable example is highly optimized ray with axis aligned box intersection code in ray tracing)[clarification needed]. "},
{"body": "Is there any simple java web framework like sinatra (for ruby) or web.py (for python)?If you want a strict Java framework  might be an alternative:  . Haven't tried it myself but heard only good things about it and seems to be quite beginner-friendly.I think the simplest thing to do to generate web content via Java is to write a Servlet.  Just like web.py allows you to define a  method, you can implement a Servlet's  method and write data directly back to the client.Here is a  to the Servlets tutorial.  You will also need to know how to package and deploy a web application; for that I usually point people to the  (see the section titled \"First Web Application\").Writing and deploying a Java web application is not going to be as fast as in Ruby or Python, but Java isn't particularly known for its succinctness.If you don't strictly require Java, check out .  It's a web application framework built on Groovy, which is a dynamic language similar to Python and Ruby that compiles to the JVM. Java EE 6 Servers like  bundles it by default.If you use Tomcat, you can use , , or  implementations.Using JAX-RS annotations the web development feels like Sinatra or Merb. BTW you don't have to use Java as the language, you can use Scala, Groovy, JRuby...If you are only looking for a presentation framework in  Java then, for me,   is the closest of the Java MVC frameworks to the RoR philosophy: simple, elegant, and requiring minimal configuration.  Stripes pioneered the  approach for Java web development. And while some other frameworks have adopted some of its principles (like Spring MVC or Struts2 with plugins), I still prefer Stripes because it does one thing, and does it well.It is possible to use  as is with look at this two as well: 1.  and 2. You might want to have a look at those 2 groovy projects:Really light akin to Sinatra. Might be a bit on the bleeding edge though:-) Interesting and promising never the less.Check  :If you have to develop business or database applications  is a good option. OpenXava allows you to develop a complete AJAX web application writing just domain classes, with no code generation and producing an application ready for production. Little code, great result.The smallest \"usable\" web server for Java that support Servlets that I can find is . And honestly there is no reason to run a Java web server that doesn't support Servlets. If you want to do REST,  has a built in HTTP daemon that means you can run it as a . is really simple. Of course, it builds like an API above Servlet API, but deals with page and component instead of request and response. In other words it is truly MVC. is a framework for Scala inspired by Sinatra.I can recommend  to you, because i like the plugin architecture and with the convention plugin it is simple and fast to develop."},
{"body": "If I'm in an interface and pointing to a method name, what can I do to quickly go to the ONLY implementation of that method ?using eclipse 3.6.xHold control, hover over the method name, and select \"Open Implementation\". I just checked this on my Eclipse 3.6 install. You may assign a keyboard shortcut to this action by using Window->Preferences->General->Keys and searching for \"Open Implementation\".  is the typical \"go to implementation\".  For interfaces that go to the  definition.Instead use  +  to see all implementations of the interface definition.  You can then easily go to the one you want with the arrow keys and Enter.  I believe that the first one is automatically selected so that  +  will do what you need. In the keymap (General > Keys) search for \"open implementation\" and map it to whatever you want.  I chose  +  + .  Make sure you select \"Editing Java Source\" in the When box.  I tested it, and having the cursor over the method name and pressing  +  +  took me directly to the implementation instead of showing the hierarchy that you get with  + .Also you can see an answer to a nearly identical question for other options:"},
{"body": "What would be the easiest way to calculate Greatest Common Divisor and Least Common Multiple on a set of numbers? What math functions can be used to find this information?I've used  to find the greatest common divisor of two numbers; it can be iterated to obtain the GCD of a larger set of numbers.Least common multiple is a little trickier, but probably the best approach is , which can be similarly iterated:There is an  for GCD,By the way,  and  should be greater or equal , and  = There are no build in function for it. You can find the GCD of two numbers using .For a set of numberApply it recursively.Same for LCM:If you can use Java 8 (and actually want to) you can use lambda expressions to solve this functionally:I oriented myself on , butThis approach is probably slightly slower due to additional function calls, but that probably won't matter at all for the most use cases.More simpler to understand:- See more at: With Java 8, there are more elegant and functional ways to solve this.LCM:GCD:Of course if one argument is 0, both methods will not work.import java.util.Scanner;\npublic class Lcmhcf {"},
{"body": "I'm trying to install a plugin in Eclipse Luna. I installed Papyrus and am trying to install SWT designer, but before the download/installation is completed I get an error:After this error I can't install anything and the install manager does not work anymore and shows me the same error all the time only one way I delete the current Eclipse directory and extract it again.This time I install Papyrus, SWT designer and some other, but I get the error between install another plugin again. This is wrong if I get an error on install any of plugin reinstalling Eclipse and the other plugin again.Is this a bug or a problem?Ok finally i find the solution for solve this problem i don't know why Eclipse showing me this error and i don't know is this a best solution but anyway i solve my problem with delete the  file in Eclipse root directory\nAfter delete this file try to install that plugin again but this time after few second everything done and work perfectly\nIf you get that's error again just go to Eclipse root directory and search for \"artifacts.xml\" and delete all the files is in the result ;)Run Eclipse as an administrator, then try to install the plugin again via help->Install New Software. it worked for meI installed E4 RCP Patch(bugzillas 445122)(Install new software -> Eclipse 4.4.1 Patches for bug 445122) and this helped me.I ran across this problem while updating eclipse's internal software. I discovered that the jar file org.eclipse.epp.mpc.help.ui_1.5.2.v20161004-1655.jar (found in the error details) in the eclipse plugins directory was corrupted (7-Zip was unable to inspect its contents). I redownloaded and manually replaced this file with one downloaded from , and I was then able to install the software without an issue. Hope this helps :)(If it was a different JAR file for you, you can click \"show directory contents\" on  and download the one you need.)Try this from the Eclipse marketplace\n1. Click Help>Eclipse marketPlace (Eclipse marketPlace dialog box will open)\n2. Type the name of your plugin (ex: type SWT Designer) in the find edit box, make sure to keep default values for All markets and all categories, and click go button.\n3. The page will refresh and display all plugins that have swt designer in their name.\n4. Click intsall or update button on the one that fits your needs.\n5. The installation or update will be done successfully.\n6. Restart your eclipse\n7. The installation will be fine.It's a failure in Eclipse.Try to uninstall it then download it from:  and install it."},
{"body": "I have a byte[] and would like to copy it into another byte[].  Maybe I am showing my simple 'C' background here, but is there an equivalent to memcpy() on byte arrays in Java?You might try  or make use of array functions in the  class like . Both should give you native performance under the hood.Arrays.copyOf is probably favourable for readability, but was only introduced in java 1.6.Use Example,\nor use \nExample, was added in JDK 1.6.\n The  method uses  to make a copy of the array, but is more flexible than  since you can make copies of parts of an array.If you just want an exact copy of a one-dimensional array, use .For other array copy operations, use / as .You can use . It copies elements from a source array to a destination array. The Sun implementation uses hand-optimized assembler, so this is fast.Java actually does have something just like memcpy(). The Unsafe class has a copyMemory() method that is essentially identical to memcpy(). Of course, like memcpy(), it provides no protection from memory overlays, data destruction, etc. It is not clear if it is really a memcpy() or a memmove(). It can be used to copy from actual addresses to actual addresses or from references to references. Note that if references are used, you must provide an offset (or the JVM will die ASAP). Unsafe.copyMemory() works (up to 2 GB per second on my old tired PC). Use at your own risk. Note that the Unsafe class does not exist for all JVM implementations.You can use "},
{"body": "How can I create a list out of all of the files in a specific directory in Clojure? Do I have to resort to calling Java or can Clojure handle this natively?Use  function. Usage example: Clojure was designed to embrace the Java platform, and this is one area where Clojure does not provide its own API. This means that you probably have to dive into Java, but the classes you have to work with are perfectly usable directly from Clojure.The one class you should read about in the javadocs is , which represents a .The  instance method returns an array (which you can use as a seq) of  objects \u2013 one for each entry in the directory identified by the  instance. There are other useful methods for determining whether a  exists, is a directory, and so on.The constructor of  can sometimes be a bit inconvenient to use (especially when merging many path segments in one go) and in this case Clojure provides a useful helper function: . As its arguments it accepts path segments as strings or files. The segments are joined with the correct path separator of the platform.Note: Clojure also provides the  function which returns a preorder walk (as a seq) though the file hierarchy starting at the given file.Also check out the . It may not be worth pulling in the extra dependency if you just need a list of files in a directory, but there are many useful utility functions there, for example for:The latter expression is an array of File-objects returned from the method listFiles, called on the file-object created from the path \"/tmp\". This is a fancy way to write:To make the modified code match the functionality of original sample code you should add the call to get the file names, like this.Usually, when we say that we want to list directory, we mean that we want to get file names or paths, so ->Simplest way to list directory:If you want to list it recursive, then:"},
{"body": "Optional is used to represent nullable object, Some uses of this class includeFor the first case, do I need to return Optional in all nullable return method?  The question we face is: will JDK 8 Optional objects get rid of null references? And the answer is an emphatic no! So, detractors immediately question its value asking: then what is it good for that we couldn't already do by other means?Unlike functional languages like SML or Haskell which never had the concept of null references, in Java we cannot simply get rid of the null references that have historically existed. This will continue to exist, and they arguably have their proper uses (just to mention an example: ).I doubt that the intention with the Optional class is to replace every single nullable reference, but to help in the creation of more robust APIs in which just by reading the signature of a method we could tell if we can expect an optional value or not  and force the programmer to use this value accordingly. But ultimately, Optional will be just another reference and subject to the same weaknesses of every other reference in the language (e.g. you could return a null Optional). It is quite evident that Optional is not going to save the day.How these optional objects are supposed to be used or whether they are valuable or not in Java has been the matter of a  in the project lambda mailing list. From the detractors we hear interesting arguments like:So, it would appear that the benefits of Optional are really questionable and are probably constrained to improving readability and enforcing public interface contracts. I do believe that the adoption of this Optional functional idiom is likely to make our code safer, less prompt to null dereferencing problems and as a result more robust and less error prone. Of course, it is not a perfect solution because, after all, Optional references can also be erroneously set to null references, but  I would expect that programmers stick to the convention of not passing null references where an optional object is expected, pretty much as we today consider a good practice not to pass a null reference where a collection or an array is expected, in these cases the correct is to pass an empty array or collection. The point here is that now we have a mechanism in the API that we can use to make explicit that for a given reference we may not have a value to assign it and the user is forced, by the API, to verify that.Quoting  about the use of optional objects: So, I guess it's up to every API designer to choose how far they want to go in the use of Optional.Some influential developers like Stephen Colebourne and Brian Goetz have published a few interesting articles more recently on the proper use of optional. I particularly found useful the following:As an observation, I think one of the most important aspects that have to be considered when architecting an application is to decide how to treat the \"null problem\". \nIn this respect, the first step would be to identify possible \"sources\" of nulls. For example, the database or external libraries used in the project. The next step would be to 'contain' the problem, namely, to wrap problematic code(using Optional) and thus block the propagation of null throughout the system, where unsuspecting code might trigger NPEs.\nTo answer your question, it depends...Most of the times I would say that's unnecessary, since it creates a lot of work with no value (for example, I wouldn't use optional for methods that call other private methods inside classes, or for methods that call methods of package-private classes), but code that exists at the thin  of different 'concerns' (or layers) in your application, (the signature of the interfaces/classes that you use to query the datastore, for example, or pojos used for 'transporting' data that might have null properties - DTOs, or, a more general description,  APIs of different modules) should avoid 'leaking' nulls into some other areas with different concerns. Compared with Guava, one annoying problem with  is that it does not provide a method like  which is, on the other hand, defined in  as The lack of this specific feature limits monadic applications of Java 8's Optional.Guava's  can be replicated as in with Java 8 Optional asorIn  (finally!) you'll be able to use :That's neat!"},
{"body": "Say I have a   relationship like the following:If I have a parent P and children C...C referencing back to P, is there a clean and pretty way in JPA to automatically remove the children C...C when P is removed (i.e. )? What I'm looking for is a functionality similar to  in SQL.This is essentially the same question as , and from what I can gather from that, the answer is \"no\"?Relationships in JPA are always unidirectional, unless you associate the parent with the child in both directions. Cascading REMOVE operations from the parent to the child will require a relation from the parent to the child (not just the opposite).You'll therefore need to do this:If you are using hibernate as your JPA provider you can use the annotation @OnDelete. This annotation will add to the relation the trigger , which delegates the deletion of the children to the database.Example:With this solution a unidirectional relationship from the child to the parent is enough to automatically remove all children. This solution does not need any listeners etc. Also a query like  will remove the children.Create a bi-directional relationship, like this:@Cascade(org.hibernate.annotations.CascadeType.DELETE_ORPHAN)Given annotation worked for me.For Example :-"},
{"body": "I want to draw circle by canvas. Here is my code:[MyActivity.java]:[View.java]:So i have just black screen without circle.\nWhy it does not work? How to fix it?You can override the onDraw method of your view and draw the circle.For a better reference on drawing custom views check out the official Android documentation.\nif you want to draw circle at centre. You could also translate your entire canvas to center then draw circle at center.using These two link also helpXml example: will produce a circle of 5dpAbove is the code to render a circle. Tweak the parameters to your suiting.Try this The entire code for drawing a circle or download project source code and test it on your android studio.  "},
{"body": "Is there any convenient way to read and parse data from incoming request.E.g client initiate post requestI\u2019m not able to get param using . The following codehowever displays the content for me What is the best way to parse incoming request? I don\u2019t want to write my own parser, probably there is a  ready solution. encoded requests are indeed not by default supported by the Servlet API prior to version 3.0. The Servlet API parses the parameters by default using  encoding. When using a different encoding, the  calls will all return . When you're already on Servlet 3.0 (, , etc), then you can use  instead. Also see  for extended examples.Prior to Servlet 3.0, a  standard to parse  requests would be using . Just carefully read its  and  sections to learn how to use it. I've posted an answer with a code example before  (it also contains an example targeting Servlet 3.0).Solutions:Solution A:Solution B:Solution C:Solution D:Use Struts. Struts 1.1 handles this automatically.Reference: Not always there's a servlet before of an upload (I could use a filter for example).\nOr could be that the same controller ( again a filter or also a servelt ) can serve many actions, so I think that rely on that servlet configuration to use the getPart method (only for Servlet API >= 3.0), I don't know, I don't like. In general, I prefer independent solutions, able to live alone, and in this case   is one of that. "},
{"body": "Suppose I have a Java class with multiple constructors:How can I extend it in Scala and still provide access to all three of Base's constructors? In Scala, a subclass can only call one of it's superclass's constructors. How can I work around this rule?Assume the Java class is legacy code that I can't change.It's easy to forget that a trait may extend a class. If you use a trait, you can postpone the decision of which constructor to call, like this:Traits may not themselves have constructor parameters, but you can work around that by using abstract members instead. - Assuming that each of your constructors ultimately create the   of the object, create a companion object with \"static\" methods to create this stateThen create a private constructor taking the state and (public) overloaded constructors which defer to the primary constructorThis is a silly answer that would probably work somewhat but might be too much effort if the Java class has way too many constructors, but:Write a subclass in Java that implements a constructor that takes all the inputs the various other constructors would and calls the proper constructor of its superclass based on the presence or absence of inputs (via usage of \"null\" or some sort of sentinel values), then subclass that Java class in Scala and assign the sentinel values as default parameters.I would pick the most generic one (in this case, String) and do the internal conversion yourself if it meets the other criteria.Although I admit this is not the best solution and something strikes me as wrong about it. :-("},
{"body": "I've been interviewed recently and the interviewer wanted me to do a technical test to see my knowledge. After I finished it he gave me feedback about how I did it, which I didn't expect and I appreciated, since few interviewers do it if they don't want to hire you.One of the things he told me that he saw bad about my code was that I used more than one try-catch block inside each method I wrote. This calls my attention since I see it interesting. I believe at the moment that I should make try-catch blocks where there is a semantically distinguishable block of code which has one or more methods that can throw exceptions needed to be caught. The only exception to this that I followed was that if two methods throw the same exception type, I better put them in different try-catch blocks to clearly distinguish when debugging where and why an exception was thrown. This strongly differs from what the interviewer wanted me to do. So is using just one try-catch block per method a known good practice? If it is a known good practice what are the benefits of doing it?For me, two try-catch blocks makes most methods too long. It obfuscates the intention if the method is doing many things.With two try-catch blocks, it's doing at least four things, to be preciseI would rather make short and clear methods out of each try-catch block- likeRobert C. Martin in 'Clean Code' takes it to next level, suggesting:I would definitely refactor the method with two separate try/catch blocks into smaller methods.I'd say that if you find yourself wrapping two separate blocks of code with  you should consider refactoring those blocks into separate methods. If this is a pattern you used in your interview than perhaps you misunderstood your interviewer.It is perfectly fine to use two  blocks if the algorithm requires it. I have often used a new  in a catch block to ensure a safe cleanup so a blanket statement is not possible.To answer your question, when we talk about modern day JVMs which are actually applying a lot of optimizations in the code, when you write some code which is inefficient then the JVM will automatically introduce optimizations.Please refer the answer in ().So the good practice thing is not of much importance. On a personal note, I believe that one must not encapsulate anything in a , ,  etc blocks un-necessarily.Let us make our code more readable to the ones who will be working on this. If an exception is caught, it is better to explicitly make it prominent that which piece of code is throwing it. No guessing for the reader, that is why JVMs are smart, write as you want , make it better for humans and JVM takes care of the optimization part. I have read plenty of books and I didn't find it any place which says that one big try catch is better than multiple small ones. Moreover, many in the developer community believe the opposite. I try to avoid duplication in catch blocks. If all the exceptions in a method receive the same treatment in the catch block, then go ahead and catch them all together. If you need to do different things with them, then catch them separately.For example, here we can catch all exceptions together, because any kind of exception means the whole method fails:Whereas here, we have different fallback behaviour for each group of calls, so we catch separately:(This code exists purely to illustrate this point about catching exceptions; i beg you to disregard the fact that it is utterly horrible in other ways)As for me, it's clearer to have just one  block wrapping all the 'hazardous' code in a method. Regarding who to blame when two lines throw the same exception, you'll always have the stacktrace. Besides, having more than one  inside a method usually means having more than one  lines (which can also make hard to follow code execution at a sight), as chances are that if something goes wrong in the first , it won't make sense to keep running the rest of the code.Here you can find some 'standard' best practices, just in case you may find them useful.-It's also important to consider the context of the code.  If you're writing code with heavy IO then you may need to know which parts of the code are failing.  I didn't see anywhere yet a point that try...catch is meant to give you a chance to recover from a problem.So if you get an IO exception in reading from one file, you may want to retry reading. Same with writing. But if you had one large try...catch you wouldn't know which to retry.This is another thing that often starts Java-flamewar... ;-)Basically, for the performance matters only throwing exceptions. So using few  blocks shouldn't affect a performance at all.\nIn some opinion writing code that way obfuscates the code and does not even recall \"clean code\", in others opinion it's better to use  only for lines which can actually throw any exception.It's up to you decide (or the team convention)."},
{"body": "I'm looking for a way to rename a Hashmap key, but i don't know if it's possible in Java.Try to remove the element and put it again with the new name. Assuming the keys in your map are , it could be achieved that way:Assign the value of the key, which need to be renamed, to an new key. And remove the old key.You don't rename a hashmap key, you have to insert a new entry with the new key and delete the old one.This will do what you want but, you will notice that the location of the key has changed.You cannot rename/modify the hashmap  once added.Only way is to delete/remove the key and insert the new key and value pair. : In hashmap internal implementation the Hashmap key modifier marked as final.For Reference : "},
{"body": "I'm using  to convert a  string to a Java-Object.\nThe value of  is exactly the same as the value of . (Copied from debugger; Backslashs added)The following exception is thrown while converting result1:\nConverting  works fine.The json string is valid according to jsonlint.com.I suspect that result1 has some characters at the end of it that you can't see in the debugger that follow the closing  character. What's the length of  versus ? I'll note that  as you've quoted it has 169 characters.GSON throws that particular error when there's extra characters after the end of the object that aren't whitespace, and it defines whitespace  narrowly (as the JSON spec does) - only , , , and space count as whitespace. .If you can't easily figure out what's causing the extra characters at the end and eliminate them, another option is to tell GSON to parse in lenient mode:From my recent experience,  basically makes the parser very tolerant, even to allow malformed JSON data.But for certain data retrieved from your trusted RESTful API(s), this error might be caused by trailing white spaces. In such cases, simply  the data would avoid the error:Then  should work as expected.In the debugger you don't need to add back slashes, the input field understands the special chars.In java code you need to escape the special chars"},
{"body": "In Java, is there any difference between  and ?\nIs there a specific code convention for these?According to ,  returns:So there shouldn't really be a difference except for an additional method invocation.Also, in case of , if the instance is , a  will be thrown, so, arguably, it's less .  2) The signature or syntax of string's valueOf() method is given below:The signature or syntax of string's  method is given below:Yes.  As the  explains,  will be treated as a special case, whereas  will just give you an NPE.No.  Use which ever is most appropriate to the requirements of the context in which you are using it.  (Do you  the formatting to work for ?)Note: that isn't a code convention.  It is just common sense programming.  It is more important that your code is  than it is to follow some stylistic convention or \"best practice\" dogma.Personal opinion:Some developers acquire the (IMO) bad habit of \"defending\" against nulls.  So you see lots of tests for nulls, and treating nulls as special cases.  The idea seems to be prevent NPE from happening.I think this is a bad idea.  In particular, I think it is a bad idea if what you do when you find a  is to try to \"make good\" ... without consideration of why there was a  there.In general, it is better to avoid the  being there in the first place ... unless it has a very specific meaning in your application or API design.  So, rather than avoiding the NPE with lots of defensive coding, it is better to let the NPE happen, and then track down and fix the source of the unexpected  that triggered the NPE.So how does this apply here?Well, if you think about it, using   be a way of \"making good\".  That is to be avoided.  If it is unexpected for  to be  in the context, it is better to use . and  are literally the same thing.If you take a look at the implementation of , you'll see that  is basically just a null-safe invocation of  of the appropriate object:The most important difference is the way they handle null String references.The below shows the implementation for java.lang.String.valueOf as described in the source for jdk8u25. So as per my comment, there's no difference. It calls \"Object.toString\". For primitive types, it wraps it in its object form and calls \"toString\" on it.See below:When argument is , the  returns , but  throws , that's the only difference.I can't say exactly what the difference is but there appears to be a difference when operating at the byte level. In the following encryption scenario Object.toString() produced a value that couldn't be decrypted whereas String.valueOf() worked as intended ...There is one more major difference between the two methods is when the object we are converting is an array.When you convert an array using Object.toString() you will get some kind of garbage value(@ followed by hashcode of array).To get a human-readable toString(), you must use String.valueOf(char[]); plz note that this method works only for Array of type char. I would recommend using Arrays.toString(Object[]) for converting arrays to String.Second difference is when the object is null, ValueOf() returns a String \"null\", while toString() will return null pointer exception."},
{"body": "So my 2009 new years resolution is to learn Java.  I recently acquired \"Java for Dummies\" and have been following along with the demo code in the book by re-writing it using Eclipse.  Anyway, every example in the book that uses a relative path does not seem to read the .txt file it's supposed to read from.Here is the sample code:And you can see in the below screen shot I have included this file.Also, I have verified that when I build the application that a copy of Hankees.txt is placed in the bin folder with the compiled .class files.Lastly, if I change line 12 to the following and place Hankees.txt in the root of my C:\\ drive the program compiles and runs fine.So basically, my question is what am I doing wrong?  Or is Eclipse responsible for this in some way?Thanks for any and all help!You need Your file is in the source folder which is not counted as the working directory.\\Or you can move the file up to the root directory of your project and just use A project's build path defines which resources from your source folders are copied to your output folders. Usually this is set to Include all files.New run configurations default to using the project directory for the working directory, though this can also be changed.This code shows the difference between the working directory, and the location of where the class was loaded from:The output is likely to be something like:This is really similar to another question.\nHow should I load my files into my Java Application?You  want to load your files in by:this is You should use getResourceAsStream.And also you should use ; which is the system-dependent name-separator character, represented as a string for convenience.Yeah, eclipse sees the top directory as the working/root directory, for the purposes of paths....just thought I'd add some extra info. I'm new here! I'd like to help.Paraphrasing from :The classes under  resolve relative pathnames against the current user directory, which is typically the directory in which the virtual machine was started.Eclipse sets the working directory to the top-level project folder.i has the same problem. If YourClass and Hankees.txt have one directory in your Project then, i find following - not so bad."},
{"body": "I have seen different approaches to define a static array in Java.  Either:...or onlyor as a Is there a difference (except for the List definition of course)?What is the better way (performance wise)?If you are creating an array then there is no difference, however, the following is neater:But, if you want to pass an array into a method you have to call it like this:Nope, no difference. It's just .  creates an additional list."},
{"body": "I have to store UTC dateTime in DB.\nI have converted the dateTime given in specific timezone to UTC. for that I followed the below code.\nMy input dateTime is \"20121225 10:00:00 Z\" timezone is \"Asia/Calcutta\" \nMy Server/DB(oracle) is running in the same timezone(IST) \"Asia/Calcutta\" DB (oracle) has stored the same given  not in UTC.I have confirmed from the below sql.My DB server also running on the same timezone \"Asia/Calcutta\"It gives me the below appearances Will  print in local timezone like  does? Not UTC?Although it is not explicitly specified for  drivers have to follow the rules established by the :When you call with  the JDBC driver uses the time zone of the virtual machine to calculate the date and time of the timestamp in that time zone. This date and time is what is stored in the database, and if the database column does not store time zone information, then any information about the zone is lost (which means it is up to the application(s) using the database to use the same time zone consistently or come up with another scheme to discern timezone (ie store in a separate column).For example: Your local time zone is GMT+2. You store \"2012-12-25 10:00:00 UTC\". The actual value stored in the database is \"2012-12-25 12:00:00\". You retrieve it again: you get it back again as \"2012-12-25 10:00:00 UTC\" (but only if you retrieve it using ), but when another application accesses the database in time zone GMT+0, it will retrieve the timestamp as \"2012-12-25 12:00:00 UTC\".If you want to store it in a different timezone, then you need to use the  with a Calendar instance in the required timezone. Just make sure you also use the equivalent getter with the same time zone when retrieving values (if you use a  without timezone information in your database).So, assuming you want to store the actual GMT timezone, you need to use:With JDBC 4.2 a compliant driver should support  (and ) for  (and ) through . The  classes are without time zones, so no conversion needs to be applied (although that might open a new set of problems if your code did assume a specific time zone).I think the correct answer should be java.sql.Timestamp is NOT timezone specific. Timestamp is a composite of java.util.Date and a separate nanoseconds value. There is no timezone information in this class. Thus just as Date this class simply holds the number of milliseconds since January 1, 1970, 00:00:00 GMT + nanos. In PreparedStatement.setTimestamp(int parameterIndex, Timestamp x, Calendar cal)\nCalendar is used by the driver to change the default timezone. But Timestamp still holds milliseconds in GMT. API is unclear about how exactly JDBC driver is supposed to use Calendar. Providers seem to feel free about how to interpret it, e.g. last time I worked with MySQL 5.5 Calendar the driver simply ignored Calendar in both PreparedStatement.setTimestamp and ResultSet.getTimestamp.It is specific from your driver.  You need to supply a parameter in your Java program to tell it the time zone you want to use.Further this:  May also be of value in handling the conversion properly.  Taken from For Mysql, we have a limitation.\nIn the , we have :So, when we do not use this parameters and we call  with calendar or without calendar, we have the timestamp in the jvm timezone.Example :The jvm timezone is GMT+2.\nIn the database, we have a timestamp : The first method returns  : The second method returns : The third method returns  : Instead of Oracle, when we use the same calls, we have :The first method returns  : The second method returns : The third method returns  : \nIt is not necessary to specify the parameters for Oracle."},
{"body": "Is there a way to exclude code from inclusion into Cobertura coverage reports? We have some methods that should not be included in the coverage report and therefore not drive down the coverage numbers.I know that Clover has such a functionality, but I have not found anything similar for Cobertura.You can exclude classes from instrumentation. Then they should not appear on reports. See  statements below.You can also ignore calls to some methods. See  statement below.If you are using maven, see . And for ant see .This has been breaking my head for some time now.My problem was that I had the cobertura maven plugin setup in the reporting section instead of the build section.The instrumentation settings, and hence the excluding of classes or packages, won't be applied if you don't set it up on build section, so watch out for this.Remember to exclude inner classes too.It took me ages to notice I was missing an asterisk!Cobertura doesn't currently provide such a feature, and neither does Emma (which we use) although it is listed as a forthcoming enhancement - although in the form of an extension to the exclusion rules I believe rather than as an annotation.Would be handy to cover off those few inaccessible corners cleanly so that you can strive for 100% without being ridiculous.I think annotations would probably be a friendlier way to do it, but they ought to be fairly explicitly named and based on a list of acceptable scenarios as I fear otherwise something like '@ExcludeFromCoverage' would get added over generously."},
{"body": "What is the difference between compile time and run time dependencies in Java?\nIt is related to class path, but how do they differ?Although compile-time dependency usually implies run-time dependency, you can have a compile-time only dependency. This is based on the fact that Java only links class dependencies on first access to that class, so if you never access a particular class at run-time because a code path is never traversed, Java will ignore both the class and its dependencies.Example of thisIn C.java (generates C.class):In A.java (generates A.class):In this case,  has a compile-time dependency on  through , but it will only have a run-time dependency on C if you pass some parameters when executing , as the JVM will only try to solve 's dependency on  when it gets to execute . This feature allows you to provide at runtime only the dependencies of the classes that you use in your code paths, and ignore the dependencies of the rest of the classes in the artifact.An easy example is to look at an api like the servlet api. To make your servlets compile, you need the servlet-api.jar, but at runtime the servlet container provides a servlet api implementation so you do not need to add servlet-api.jar to your runtime class path.The compiler needs the right classpath in order to compile calls to a library (compile time dependencies)The JVM needs the right classpath in order to load the classes in the library you are calling (runtime dependencies).They may be different in a couple of ways:1) if your class C1 calls library class L1, and L1 calls library class L2, then C1 has a runtime dependency on L1 and L2, but only a compile time dependency on L1.2) if your class C1 dynamically instantiates an interface I1 using Class.forName() or some other mechanism, and the implementing class for interface I1 is class L1, then C1 has a runtime dependency on I1 and L1, but only a compile time dependency on I1.Other \"indirect\" dependencies which are the same for compile-time and run-time:3) your class C1 extends library class L1, and L1 implements interface I1 and extends library class L2: C1 has a compile-time dependency on L1, L2, and I1.4) your class C1 has a method  and a method  where I1 is an interface and L1 is a class that takes a parameter which is interface I1: C1 has a compile-time dependency on I1 and L1. Note that the run-time dependency chain is run-time dependent or fail-slow: if the implementation of L1 sometimes depends on instantiating an object of class L2, and that class only gets instantiated in one particular scenario, then there's no dependency except in that scenario.Java doesn't actually link anything at compile time.  It only verifies the syntax using the matching classes it finds in the CLASSPATH.  It's not until runtime that everything gets put together and executed based on the CLASSPATH at that time.Compiletime dependencies are only the dependencies (other classes) which you use  in the class you're compiling. Runtime dependencies covers both the direct and indirect dependencies of the class you're running. Thus, runtime dependencies includes dependencies of dependencies and any reflection dependencies like classnames which you have in a , but are used in .For Java, compile time dependency is your source code's dependency. For instance, if class A calls a method from class B, then A is dependent to B at the compile time since A has to know about B (type of B) to be compiled. The trick here should be this: Compiled code is not a complete and executable code yet. It includes replaceable addresses (symbols, metadata) for the sources which are not yet compiled or existing in external jars. During linking, those addresses must be replaced by actual adresses in the memory. To do it properly, correct symbols/adresses should be created. And this can be done with the type of the class (B). I believe that's the main dependency at the compile time.Runtime dependency is more related with the actual flow-of-control. It involes actual memory addresses. It's a dependency that you have when your program is running. You need class B details here like implementations, not only the type info. If the class not exists, then you will get RuntimeException and JVM will exit.Both dependencies, generally and shouldn't, flow the same direction. This is a matter of OO design though.In C++, compilation is a bit different (not just-in-time) but it has a linker too. So the process might be thought similar to Java I guess."},
{"body": "I have a blank Spring MVC project, and I've installed Hibernate and the PostgreSQL drivers using Maven.I'm running short on complete tutorials that show how to connect PostgreSQL with Hibernate.Any help here?This is a hibernate.cfg.xml for posgresql and it will help you with basic hibernate configurations for posgresql.If the project is maven placed it in , in the package phase it will copy it in Make sure File Location should be under "},
{"body": "I am implementing a  for the apache HttpClient package, like so:but I'd like for the  function to return nothing, i.e. . Is this possible? The following does not compile, since  is not a valid Java type:I suppose I could replace  with  to return a  object, but that's not really what I want. : is it possible to organize this callback situation in such a way that I can return  from ?Generics only handles object classes.  void and primitive types are not supported by Generics and you cannot use these as a parameterized type.  You have to use Void instead.Can you say why you don't want to use ?The  type was created for this exact situation: to create a method with a generic return type where a subtype can be \"void\".  was designed in such a way that no objects of that type can possibly be created. Thus a method of type  will always return  (or complete abnormally), which is as close to nothing as you are going to get. You do have to put  in the method, but this should only be a minor inconvenience.In short: Do use . You can set the code to return  as you say, however you can never instanciate a  so you can't actually write a function which conforms to this specification.Think of it as: The generic function says \"this function returns something, of type X\", and you can specify X but you can't change the sentence to \"this function returns nothing\". (I'm not sure if I agree with these semantics, but that's the way they are.)In this case, what I always do, is just make the function return type , and in fact always return .You can't have primitives in generics so that  is actually an . The object  is analogous with the keyword  for generics.When you need to return java.lang.Void, just return null.This java.lang.Void implementation in Java kind of speaks for itself. Also, I wrote an article that ties this into generics. It took a bit of thought before I started understanding this: . Notice TYPE = Class.getPrimitiveClass(\"void\");package java.lang;"},
{"body": "When creating a 2D array, how does one remember whether rows or columns are specified first?Java is considered \"row major\", meaning that it does rows first. This is because a 2D array is an \"array of arrays\".For example:  It can also be visualized more like this:The second illustration shows the \"array of arrays\" aspect. The first array contains , and each of those is an array containing four elements, .TL;DR summary:For more explanations, see also .While Matt B's may be true in one sense, it may help to think of Java multidimensional array without thinking about geometeric matrices at all.  Java multi-dim arrays are simply arrays of arrays, and each element of the first-\"dimension\" can be of different size from the other elements, or in fact can actually store a null \"sub\"-array.  See comments under  Instinctively one thinks geometrically: horizontal (X) axis and then vertical (Y) axis. This is not, however, the case with a 2D array, rows come first and then columns.Consider the following analogy: in geometry one walks to the ladder (X axis) and climbs it (Y axis). Conversely, in Java one descends the ladder (rows) and walks away (columns).In Java, there are no multi-dimension arrays. There are arrays of arrays. So:It actually consists of two arrays, each has three elements.All depends on your visualization of the array. Rows and Columns are properties of  (probably in your imagination) of the array, not the array itself. I could draw it red, I could draw it greed right? Color is not an integral property of a number. In the same way representing 2D array as a grid of rows and columns is not necessary for existence of this array. 2D array has just  and , everything related to visualizing those is purely your flavour.When I have char array , I may like to print it on console rotated so that I have 25 rows of 80 characters that fits the screen without scroll. I'll try to provide viable : Let's say I need an array of 1 000 000 000 integers. My machine has 8GB of RAM, so I have enough memory for this, but if you try executing , you'll most likely get OutOfMemory exception. That's because of memory fragmentation - there is no consecutive block of memory of this size. Instead you you can create 2D array 10 000 x 100 000 with your values. Logically it is 1D array, so you'd like to draw and imagine it as a single sequence of values, but due to technical implementation it is 2D.In java the rows are done first, because a 2 dimension array is considered two separate arrays. Starts with the first row 1 dimension array."},
{"body": "I have a class as below:The logic in the constructor  and  are the things I am trying to mock. I want any calls like:  returns a dummy string \"test\".I tried:But it doesn't seem to be working.  is still going through the constructor logic instead of fetch the mocked object of A.The code you posted works for me with the latest version of Mockito and Powermockito. Maybe you haven't prepared A?\nTry this:A.javaMockA.javaBoth tests should pass with mockito 1.9.0, powermockito 1.4.12 and junit 4.8.2To my knowledge, you can't mock constructors with mockito, only methods.  But according to the wiki on the Mockito google code page there is a way to mock the constructor behavior by creating a method in your class which return a new instance of that class.  then you can mock out that method.  Below is an :If you're just wanting to return a mocked object of your class I think this should work for you.  In any case you can read more about mocking object creation here:Without Using Powermock .... See the example below based on Ben Glasser answer since it took me some time to figure it out ..hope that saves some times ... Mockito has limitations testing final, static, and private methods.with jMockit testing library, you can do few stuff very easy and straight-forward as below:Mock constructor of a java.io.File class:Mock a static method:"},
{"body": "Assuming that I'm trying to pull from a RESTful api that uses basic authentication / basic certificates, what would be the best way to store that user name and password in my program?   Right now it's just sitting there in plaintext.Is there some way of doing this that is more security minded?ThanksWith an inner-to-outer mindset, here are some steps to protect your process:First step, you should change your password-handling from  to .The reason for this is that a  object's data will not be cleansed immediately even if the object is set to ; The data is set for garbage-collection instead, and this poses security problems because malicious programs might gain access to that  (password) data before it is cleaned.This is the main reason why  method is deprecated, and why .The second step is to encrypt your credentials, only decrypting them temporarily during the authentication process.This, similarly to the first step, makes sure your vulnerability-time is as small as possible.It is recommended that your credentials are not hard-coded, and that instead, you store them in a centralized, configurable and easily-maintainable manner, such as a configuration or properties file.You should encrypt your credentials before saving the file, and additionally, you can apply a second encryption to the file itself (2-layer encryption to the credentials, and 1-layer to other file contents).Note that each of the two encryption processes mentioned above can be multiple-layered themselves. Each encryption can be an individual application of , as a conceptual example.After your local environment is properly protected (but remember, it's never ever \"safe\"!), the third step is apply basic protection to your transmission process, by using .The forth step is to apply other protection methods.For example, applying obfuscation techniques to your \"to-use\" compile, to avoid (even if shortly) the exposure of your security measures in case your program is obtained by  and decompiled.By @Damien.Bell 's request, here is an example that covers the first and second steps:A full example, addressing every protection step, would far exceed what I think is reasonable for this question, since it's about , not .It would far over-size my answer (at last the sampling), while other questions here on S.O. are already directed on the  of those steps, being far more appropriate, and offering far better explanation and sampling on the implementation of each individual step.If you are using basic auth, you should couple that with SSL to avoid passing your credentials in base64 encoded plain text. You don't want to make it easy for someone sniffing your packets to get your credentials. Also, don't hard code your credentials in your source code. Make them configurable. read them from a config file. You should encrypt the credentials before storing them in a config file and your app should decrypt the credentials once it reads them from the config file.plus probably thousand things i forgot about :)It's generally not good advice to encrypt credentials. Something that is encrypted can be decrypted. Common best practice is to store passwords as a .A hash cannot be decrypted. The salt is added to defeat brute force guessing with . As long as every userId has its own random salt, an attacker would have to generate a set of tables for every possible value of the salt, quickly making this attack impossible within the lifespan of the universe. This is the reason why websites generally can't send you your password if you have forgotten it, but they can only 'reset' it. They don't have your password stored, only a hash of it. Password hashing is not very difficult to implement yourself, but it's such a common problem to solve that countless others have done it for you. I've found  easy to use. As an extra protection against brute force guessing of passwords, it is common best practice to force a userId or remote IP to wait a few seconds after a certain number of login attempts with the wrong password. Without this, a brute force attacker can guess as many passwords per second as your server can handle. There is a huge difference between being able to guess 100 passwords per 10 second period or a million. I get the impression that you have included the username/password combination in your source code. This means that if you ever want to change the password, you'll have to recompile, stop and restart your service, and it also means that anyone who gets a hold of your source code, also has your passwords. Common best practice is never to do this, but to store the credentials (username, password hash, password salt) in your datastoreIf you cannot trust the environment your program is running in, but need to authenticate via plain passwords or certificates, there is nothing you can do to secure your credentials. The most you can do is obfuscate them with the methods described in the other answers.As a workaround, I'd run all requests to the RESTful api through a proxy that you can trust and do the cleartext password authentication from there."},
{"body": "I know that '==' doesn't work with values outside the range of [-128,127] as there is a cache maintained of Integer objects within this range and the same reference is returned if value is within the range. But why does '>', '<', '>=', '<=' give correct answers even outside the range ?Why is this happening ?The , ,  and  operators are only defined for primitive types. Therefore using them on wrapper types causes the compiler to unbox the objects into primitives.This meansis equivalent toHowever, the  and  operators exist for both primitive types and reference types, so using them to compare two objects of primitive wrapper types compares the references instead of the primitive values they wrap.As Holger commented, comparison of object references with  and  existed in the Java language before auto-boxing and auto-unboxing were introduced, but comparison with , ,  and  was not supported for any reference types before auto-unboxing was introduced.This means that in the early days of Java, the  of your code snippet would not pass compilation (since  and  are not primitive numeric types). On the other hand your  snippet would still pass compilation and return .Changing the behavior of  and  for reference types that happen to be wrappers of numeric primitives would change the behavior of existing code, thus breaking backwards compatibility, which is probably the reason it wasn't done."},
{"body": "I was asked this question in interview: \"How to detect the loop in linked list?\", I solved this but immediately the interviewer asked me how do I remove the loop in a linked list.  I fumbled.So any pointers on how to solve this, may be pseudo code, or method definition?I'm comfortable with Java so I have tagged this question under java.For Instance this linked list has a loopThere are two parts to this problem:Once you know where the loop starts, it's easy to identify the last element in the list since it's the element in the list following the start of the loop that ends up pointing back to the start of the loop. It is then trivial to set the next pointer/reference of this element to  to correct the cyclic link list (not circular linked list which is where the last elements points back to the first - this would be a specific instance of cyclic lists).Here's some quick and dirty Java code assuming a linked list of s where a  has a  reference. This could be optimized but it should give you the basic idea: might help the why behind Part II: - courtesy of :The explanation for this solution is straight from the book: - courtesy of me :)I hope this helps.\nHristoThis response is not meant to compete for the answer, but rather to explain a little more on the meeting of the two nodes in the tortoise and the hare algorithm.It's a bit late here so I hope I've articulated effectively. Let me know otherwise and I'll try and update my response.If using an identity hash map (such as ) is permissible this is terribly easy to solve. It does use more space, though.Traverse the nodes list. For each node encountered, add it to the identity map. If the node already existed in the identity map then the list has a circular link and the node which was prior to this conflict is known (either check before moving or keep the \"last node\") -- simply set \"next\" as appropriate to break the cycle.Following this simple approach should be a fun exercise: code is left as an exercise for the reader.Happy coding.Insert dummy node after every node of link list and before inserting check that node next to next is dummy or not. If next to next is dummy, insert null in next of that node.  "},
{"body": "Is there any good and free Date AND Time Picker available for Java Swing?There are a lot date pickers available but no date AND time picker. This is the closest I came across so far: Anybody?For a time picker you can use a JSpinner and set a JSpinner.DateEditor that only shows the time value.You can extend the swingx JXDatePicker component:EDIT: This article disappeared from the web, but as SingleShot discovered, it is still available in an internet archive. Just to be sure, here is the full working example:Use the both combined.. that's what i did:There is the  component with a combined Date and Time Picker.As you said Date picker is easy, there are many out there.As for a Time picker, check out how Google Calendar does it when creating a new entry.  It allows you to type in anything while at the same time it has a drop down in 30 mins increments.  The drop down changes when you change the minutes.If you need to allow the user to pick seconds, then the best you can do is a typable/drop down comboThe best of the best, JCalendar:\n\nLGPL licensed."},
{"body": "Can someone explain to me why  returns type  just returns type I'm don't understand why the map would ever map to more then one value. TIA.It returns all parameter values for controls with the  name. For example:orAny checked/selected values will come in as:It's also useful for multiple selections in tables:in combination with\"biff\" now maps to The real function to get all parameter values is is just a shortcut to get first one.In the case with multi-value controls (checkbox, multi-select, etc), the  is used to fetch the values.If you have a multi-value control like a multi-selectable list or a set of buttons mapped to the same name multiple selections will map to an array."},
{"body": "So I have a program that spawns threads (~5-150) which perform a bunch of tasks. Originally I used a FixedThreadPool because  suggested they were better suited for longer lived tasks and with my very limited knowledge of multithreading, I considered the average life of the threads (several minutes) \"long lived\". However, I recently added the capability to spawn additional threads and doing so takes me above the thread limit I set. In this case, would it be better to guess and increase the number threads I can allow or to switch to a CachedThreadPool so I have no wasted threads?Trying them both out preliminarily, there doesn't  to be a difference so I'm inclined to go with the CachedThreadPool just to avoid the waste. However, does the life span of the threads mean I should instead picked a FixedThreadPool and just deal with the unused threads?  makes it seem like those extra threads aren't wasted but I would appreciate the clarification.A CachedThreadPool is exactly what you should use for your situation as there are no negative consequence to using one for long running threads.  The comment in the java doc about CachedThreadPools being suitable for short tasks merely suggest that they are particularly appropriate for such cases, not that they cannot or should not be used for tasks involving long running tasks.To elaborate further,  and  are both backed by the same thread pool implementation (at least in the open JDK) just with different parameters.  The differences just being their thread minimum, maximum, thread kill time, and queue type.A FixedThreadPool does have its advantages when you do in fact want to work with a fixed number of threads, since then you can submit any number of tasks to the executor service while knowing that the number of threads will be maintained at the level you specified.  If you explicitly want to grow the number of threads, then this is not the appropriate choice.This does however mean that the one issue that you may have with the CachedThreadPool is in regards to limiting the number of threads that are running concurrently.  The CachedThreadPool will not limit them for you, so you may need to write your own code to ensure that you do not run too many threads.  This really depends on the design of your application and how tasks are submitted to the executor service.In my opinion, both  and  are evils in highly loaded applications.  is more dangerous than If your application is highly loaded & demands low latency, better to get rid of both options due to below drawbacksSince you know that both are evils, lesser evil does n't do good. Prefer , which provides granular control on many parameters. Are you sure you understand how threads are actually processed by your OS and hardware of choice? How Java maps threads to OS threads, how that maps threads to CPU threads etc.? I'm asking because creating 150 threads within in ONE JRE only makes sense if you have massive CPU cores/threads underneath, which most likely is not the case. Depending on the OS and RAM in use, creating more than n threads might even result in your JRE being terminated because of OOM errors.  So you should really distinguish between threads and work to do by those threads, how many work you are even able to process etc.And that's the problem with CachedThreadPool: It doesn't make sense to queue up long running work in threads which actually can't run because you only have 2 CPU cores able to process those threads. If you end up with 150 scheduled threads you might create a lot of unnecessary overhead for the schedulers used within Java and the OS to concurrently process them. This is simply impossible if you only have 2 CPU cores, unless your threads are waiting for I/O or such all the time. But even in that case a lot of threads would create a lot of I/O...And that problem doesn't occur with FixedThreadPool, created with e.g. 2+n threads, where n is reasonable low of course, because with that hardware and OS resources are used with far less overhead for managing threads which can't run anyway."},
{"body": "How can I create a barcode image in Java?  I need something that will allow me to enter a number and produce the corresponding barcode image.  Is there a free library available for this type of task? is a great Java PDF library. They also have an API for creating barcodes. You don't need to be creating a PDF to use it.This page has the details on . Here is an example from that site:The biggest thing you will need to determine is what type of barcode you need. There are many different barcode formats and iText does support a lot of them. You will need to know what format you need before you can determine if this API will work for you.There is also this free API that you can use to make free barcodes in java.There is a free library called  is a free open source Java library to read and generate barcode images. You need to get the source code and build the jars yourself. Here's a  that I wrote for building with ZXing jars and writing your first program with ZXing.[I use \n\n, it's great, and supports a very wide range of different barcode formats.\nSee if you like \n\n.Sample API:"},
{"body": "I'm using IntelliJ 9 and I'm curious if there is any IntelliJ equivalent of the Visual Studio 'immediate' debug window.  There is - to evaluate an expression, but what I'd like to be able to write code in a window that interacts with what I am currently debugging (if that's even possible).Having breakpoints that log messages to the console is helpful, but I'd like to do more than that if I can.Intellij IDEA's Expression Evaluation dialog has a button to enable , which permits multi-statement evaluations. (I'm using version 9.0.2 of the Ultimate Edition.)Same as @Noel answer, but some more details. First of all,  ( + ) can be enabled .  Community Edition, Windows:You can write code in alt-f8.. but you have to do it only 1 line at a time. If you do a return, your code will return when you hit next (I think).  It isn't ideal though..."},
{"body": "Is there any performance penalty for the following code snippet?Or does this code actually make more sense?If in byte code these two are totally equivalent then obviously the first method looks better in terms of style, but I want to make sure this is the case.In today's compilers, no.  I declare objects in the smallest scope I can, because it's a lot more readable for the next guy.  :Whether the compiler will produce marginally faster code by defining the variable outside the loop is debatable, and I imagine it won't. I would  it'll produce identical bytecode.Compare this with the number of errors you'll likely prevent by correctly-scoping your variable using in-loop declaration...There's no performance penalty for declaring the Object o within the loop.\nThe compiler generates very similar bytecode and makes the correct optimizations.See the article  for a similar example.You can disassemble the code with javap -c and check what the compiler actually emits.  On my setup (java 1.5/mac compiled with eclipse), the bytecode for the loop is identical.The first code is better as it restricts scope of  variable to the  block. From a performance perspective, it might not have any effects in Java, but it might have in lower level compilers. They might put the variable in a register if you do the first.In fact, some people might think that if the compiler is dumb, the second snippet is better in terms of performance. This is what some instructor told me at the college and I laughed at him for this suggestion! Basically, compilers allocate memory on the stack for the local variables of a method just once at the start of the method (by adjusting the stack pointer) and release it at the end of method (again by adjusting the stack pointer, assuming it's not C++ or it doesn't have any destructors to be called). So all stack-based local variables in a method are allocated at once, no matter where they are declared and how much memory they require. Actually, if the compiler is dumb, there is no difference in terms of performance, but if it's smart enough, the first code can actually be better as it'll help the compiler understand the scope and the lifetime of the variable! By the way, if it's really smart, there should no absolutely no difference in performance as it infers the actual scope.Construction of a object using  is totally different from just declaring it, of course.I think readability is more important that performance and from a readability standpoint, the first code is definitely better.I've got to admit I don't know java.  But are these two equivalent?  Are the object lifetimes the same? In the first example, I assume (not knowing java) that o will be eligible for garbage collection immediately the loop terminates.  But in the second example surely o won't be eligible for garbage collection until the outer scope (not shown) is exited?Don't prematurely optimize. Better than either of these is:because it eliminates boilerplate and clarifies intent.Unless you are working on embedded systems, in which case all bets are off. Otherwise, don't try to outsmart the JVM.I've always thought that most compilers these days are smart enough to do the latter option. Assuming that's the case, I would say the first one does look nicer as well. If the loop gets very large, there's no need to look all around for where o is declared.These have different semantics.  Which is more meaningful?Reusing an object for \"performance reasons\" is often wrong.The question is what does the object \"mean\"?  WHy are you creating it?  What does it represent?  Objects must parallel real-world things.  Things are created, undergo state changes, and report their states for reasons.What are those reasons?  How does your object model and reflect those reasons?To get at the heart of this question... [Note that non-JVM implementations may do things differently if allowed by the JLS...]First, keep in mind that the local variable \"o\" in the example is a pointer, not an actual object.All local variables are allocated on the runtime stack in 4-byte slots. doubles and longs require two slots; other primitives and pointers take one. (Even booleans take a full slot)A fixed runtime-stack size must be created for each method invocation. This size is determined by the maximum local variable \"slots\" needed at any given spot in the method.In the above example, both versions of the code require the same maximum number of local variables for the method.In both cases, the same bytecode will be generated, updating the same slot in the runtime stack.In other words, no performance penalty at all.HOWEVER, depending on the rest of the code in the method, the \"declaration outside the loop\" version might actually require a larger runtime stack allocation. For example, comparewithIn the first example, both loops require the same runtime stack allocation.In the second example, because \"o\" lives past the loop, \"x\" requires an additional runtime stack slot.Hope this helps,\n-- ScottIn both cases the type info for the object o is determined at compile time.In the second instance, o is seen as being global to the for loop and in the first instance, the clever Java compiler knows that o will have to be available for as long as the loop lasts and hence will optimise the code in such a way that there wont be any respecification of o's type in each iteration. \nHence, in both cases, specification of o's type will be done once which means the only performance difference would be in the scope of o. Obviously, a narrower scope always enhances performance, therefore to answer your question: no, there is no performance penalty for the first code snip; actually, this code snip is more optimised than the second.In the second snip, o is being given unnecessary scope which, besides being a performance issue, can be also a security issue.The first makes far more sense. It keeps the variable in the scope that it is used in. and prevents values assigned in one iteration being used in a later iteration, this is more defensive.The former is sometimes said to be more efficient but any reasonable compiler should be able to optimise it to be exactly the same as the latter.As someone who maintains more code than writes code.Version 1 is much preferred - keeping scope as local as possible is essential for understanding. Its also easier to refactor this sort of code.As discussed above - I doubt this would make any difference in efficiency. In fact I would argue that if the scope is more local a compiler may be able to do more with it!When using multiple threads (if your doing 50+) then i found this to be a very effective way of handling ghost thread problems:The answer depends partly on what the constructor does and what happens with the object after the loop, since that determines to a large extent how the code is optimized.If the object is large or complex, absolutely declare it outside the loop.  Otherwise, the people telling you not to prematurely optimize are right.I've actually in front of me a code which looks like this:So, relying on compiler abilities, I can assume there would be only one stack allocation for  and one for . Then everything would be fine except the duplicated code.As a side note, java applications are known to be slow. I never tried to do profiling in java but I guess the performance hit comes mostly from memory allocation management."},
{"body": "What are Java's equivalents of  and ?I mean, instead of writing this on my own:In Java 8, the equivalents are the  and  interfaces respectively. Similarly,  is equivalent to . As mentioned elsewhere, these are interfaces instead of delegates.Related aside: I'm currently leaning heavily on the following utility class to do LINQ-like extension method stuff:Unlike  and  the LINQ-like methods I present here are not lazy and fully traverse the source collections before returning the result collections to the caller. Still, I find them useful for purely syntactic purposes and could be made lazy if necessary. GivenOne can do the following:Which I prefer to the following: interface is similar to Func. interface is similar to Action. In general, Java uses anonymous inner classes as a replacement for C# delegates. \nFor example this is how you add code to react to button press in GUI:The elegance of the overloaded Func delegates (besides the delegate vs anonymous class issue) is that they support from 0 to 16 arguments (, , , etc.)Unfortunately, this is impossible in Java because of type erasure. Classes cannot differ by generic type parameters alone. Java 8 now brings in a zoo of names like  for  and, because Java does not allow primitive type arguments, . The \"zoo\", though, is not very big, and I am not aware of a library that expands it. There was a wonderful proposal for function type literals like  but it was not adopted.There really are no equivalents for those.  You can create anonymous inner classes in Java, but there tends to be specific interfaces rather than such generic ones like Func and Action.Java doesn't have the concept of delegates.  For a workaround approach, please see :For  use: java.util.function.Supplier\n"},
{"body": "I have a process A that contains a table in memory with a set of records (recordA, recordB, etc...)Now, this process can launch many threads that affect the records, and sometimes we can have 2 threads trying to access the same record - this situation must be denied. Specifically if a record is LOCKED by one thread I want the other thread to abort (I do not want to BLOCK or WAIT).Currently I do something like this:But this is causing me problems ... because while Process1 is performing the operation, if Process2 comes in it blocks/waits on the synchronized statement and when Process1 is finished it performs the operation. Instead I want something like this:Any clues on how this can be accomplished?\nAny help would be much appreciated.\nThanks,One thing to note is that the  you receive such information, it's stale. In other words, you could be told that no-one has the lock, but then when you try to acquire it, you block because another thread took out the lock between the check and you trying to acquire it.Brian is right to point at , but I think what you really want is its  method:You can also call  with an amount of time to wait - so you could try to acquire it for a tenth of a second, then abort if you can't get it (for example).(I think it's a pity that the Java API doesn't - as far as I'm aware - provide the same functionality for the \"built-in\" locking, as the  class does in .NET. Then again, there are plenty of other things I dislike in both platforms when it comes to threading - every object potentially having a monitor, for example!)Take a look at the  objects introduced in the Java 5 concurrency packages.e.g. The  object is essentially doing the same thing as the traditional  mechanism, but with more functionality.EDIT: As Jon has noted, the  method tells you at , and thereafter that information is out of date. The  method will give more reliable operation (note you can use this with a timeout as well)EDIT #2: Example now includes  for clarity.Whilst the above approach using a Lock object is the best way to do it, if you have to be able to check for locking using a monitor, it can be done. However, it does come with a health warning as the technique isn't portable to non Oracle Java VMs and it may break in future VM versions as it isn't a supported public API.Here is how to do it:My advice would be to use this approach only if you cannot refactor your code to use java.util.concurrent Lock objects for this and if you are running on an Oracle VM.While the Lock answers are very good, I thought I'd post an alternative using a different data structure.  Essentially, your various threads want to know which records are locked and which aren't.  One way to do this is to keep track of the locked records and make sure that data structure has the right atomic operations for adding records to the locked set.I will use CopyOnWriteArrayList as an example because it's less \"magic\" for illustration.  CopyOnWriteArraySet is a more appropriate structure.  If you have lots and lots of records locked at the same time on average then there may be performance implications with these implementations.  A properly synchronized HashSet would work too and locks are brief.Basically, usage code would look like this:It keeps you from having to manage a lock per record and provides a single place should clearing all locks be necessary for some reason.  On the other hand, if you ever have more than a handful of records then a real HashSet with synchronization may do better since the add/remove look-ups will be O(1) instead of linear.Just a different way of looking at things.  Just depends on what your actual threading requirements are.  Personally, I would use a Collections.synchronizedSet( new HashSet() ) because it will be really fast... the only implication is that threads may yield when they otherwise wouldn't have.I found this, we can use Thread.holdsLock(Object obj) to check if that object is lockedAnother workaround is (in case of you didnt have chance with the answers given here )is using timeouts. i.e. below one will return null after 1 second hanging:Thanks for this, it helped me out solving a race condition. I changed it a little to wear both belt and suspenders.You can ensure that you get safe access to the  method by doing something like this:This would avoid the situation where you might get two calling  at the almost same time, causing the return to be potentially doubt full. I'd like to now if I'm wrong, I might be over cautios here. But hey! My gig is stable now :-)..Read more on my development issues at my ."},
{"body": "My team is working with a third party CMS that uses Solr as a search index.  I've noticed that it seems like the authors are using Solr as a database of sorts in that each document returned contains two fields:So basically it runs a search against Solr, download the XML representation of the object, and then instantiate the object from the XML rather than looking it up in the database using the id.My gut feeling tells me this is a bad practice.  Solr is a search index, not a database... so it makes more sense to me to execute our complex searches against Solr, get the document ids, and then pull the corresponding rows out of the database.Is the current implementation perfectly sound, or is there data to support the idea that this is ripe for refactoring? When I say \"XML representation\" - I mean one stored field that contains an XML string of all of the object's properties, not multiple stored fields.It's perfectly reasonable to use Solr as a database, depending on  application. In fact, that's pretty much what .It's definitely  bad practice per se. It's only bad if you use it the wrong way, just like any other tool at any level, even GOTOs.When you say \"An XML representation...\" I assume you're talking about having multiple stored Solr fields and retrieving this using Solr's XML format, and not just one big XML-content field (which would be a terrible use of Solr). The fact that Solr uses XML as default response format is largely irrelevant, you can also use a , so it's quite comparable to traditional relational databases in that regard.Ultimately, it's up to your application's needs. Solr  primarily a text search engine, but can also act as a NoSQL database for many applications.Yes, you can use SOLR as a database but there are some really serious caveats : That said - there are plenty of obvious advantages to SOLR for certain tasks : (see ) -- loose queries are much easier to run and return meaningful results.  Indexing is done as a matter of default, so most arbitrary queries run pretty effectively (unlike a RDBMS, where you often have to optimize and de-normalize after the fact).   Even though you CAN use SOLR as an RDBMS, you may find (as I have) that there is ultimately \"no free lunch\" - and the cost savings of super-cool lucene text-searches and high-performance, in-memory indexing, are often paid for by less flexibility and adoption of new data access workflows.This was probably done for performance reasons, if it doesn't cause any problems I would leave it alone. There is a big grey area of what should be in a traditional database vs a solr index. Ive seem people do similar things  to this (usually key value pairs or json instead of xml) for UI presentation and only get the real object from the database if needed for updates/deletes. But all reads just go to Solr.I've seen similar things done because it allows for very fast lookup.  We're moving data out of our Lucene indexes into a fast key-value store to follow DRY principles and also decrease the size of the index.  There's not a hard-and-fast rule for this sort of thing."},
{"body": "I needed something similar to waitForElementPresent to check whether element is displayed before I click it. I thought the implicitWait should cover this. So I used the following:and then click byUnfortunately sometimes it waits for the element and sometimes not. I looked for a while and found this solution :And it waited all right, but before timing out it had to wait 10 times 5, 50 seconds. A bit much. So I set the implicitly wait to 1sec and all seemed fine until now. Because now some things wait 10s before timeout but some other things time out after 1s.How do you cover the waiting for element present/visible in your code? Any hint is appreciable.This is how I do it in my code.orto be precise.See also:You can use Explicit wait or Fluent WaitExample of Explicit Wait -Example of Fluent Wait -Check this  for more details.Above wait statement is a nice example of Explicit wait. As Explicit waits are intelligent waits that are confined to a particular web element(as mentioned in above x-path). By Using explicit waits you are basically telling WebDriver at the max it is to wait for X units(whatever you have given as timeoutInSeconds) of time before it gives up."},
{"body": "I want to connect Java class file with SQL server 2012. I have logged in with SQL server authentication. But i am receiving error in connectivity.My code ---If there are any more questions, please let me know.Thanks.Got to Start->All Programs-> Microsoft SQL Server 2012-> Configuration Tool -> Click SQL Server Configuration Manager ->Expand SQL Server Network Configuration-> Protocol ->Enable TCP/IP Right boxDouble Click on TCP/IP and go to IP Adresses Tap and Put port 1433 under TCP port.The error is self explanatory:A good check I often use is to use telnet, eg on a windows command prompt run:If you get a blank screen it indicates network connection established successfully, and it's not a network problem. If you get 'Could not open connection to the host' then this is network problemAs the error says, you need to make sure that your sql server is running and listening on port 1433. If server is running then you need to check whether there is some firewall rule rejecting the connection on port 1433.Here are the commands that can be useful to troubleshoot:Go to Start->All Programs-> Microsoft SQL Server 2012-> Configuration Tool -> Click SQL Server Configuration Manager.  If you see that SQL Server/ SQL Server Browser State is 'stopped'.Right click on SQL Server/SQL Server Browser and click start.\nIn some cases above state can stop though TCP connection to port 1433 is assigned.  "},
{"body": "When the code above is run, it produces an error on the line . Why? cannot be represented as a 32-bit integer (type ). It can be represented as a 64-bit integer (type ). long literals in Java end with an \"L\": Append suffix : .By default, java interpret all numeral literals as 32-bit integer values. If you want to explicitely specify that this is something bigger then 32-bit integer you should use suffix  for long values.You need to use a long literal: But I would expect that function to run out of memory (or time) ...The java compiler tries to interpret 600851475143 as a constant value of type int by default. This causes an error since 600851475143 can not be represented with an int.To tell the compiler that you want the number interpretet as a long you have to add either  or  after it. Your number should then look like this .Since some Fonts make it hard to distinguish \"1\" and lower case \"l\" from each other you should always use the upper case \"L\".You need 40 bits to represent the integer literal 600851475143. In Java, the maximum integer value is 2^31-1 however (i.e. integers are 32 bit, see ).This has nothing to do with . Try using a long integer literal instead (as suggested in the other answers).At compile time the number \"600851475143\" is represented in 32-bit integer, try long literal instead at the end of your number to get over from this problem.Apart from all the other answers, what you can do is : for example : "},
{"body": "I'm trying to open a file in android like this :, but in case the file does not exists a file not found exception is thrown . I'd like to know how could I test if the file exists before attempting to open it. I think the best way to know if a file exists, without actually trying to open it, is as follows:Hope that helps, bye!The documentation says Context.openFileInput either returns an inputStream (file found) or throws a FileNotFoundException (not found)So it looks like the exception is your \"test\".You could also try using standard But that is not recommended. Context.openFileInput() and Context.openFileOutput() make sure you stay in your applications storage context on the device, and that all of your files get\ndeleted when your app gets uninstalled.With the standard  this is the function I have created, and works correctly:why dont you just catch the FileNotFound exception and take that as the file not being present.If you want to ensure a file exists (i.e. if it doesn't exist create a new one, if it does then don't erase it) then use File.createNewFile:e.g.If you want to open a file in any case (i.e. if it doesn't exist create a new one, if it does append to the old one) you can use this, no testing necessary:My suggestion is to check length of the file.  that means file doesn't exist."},
{"body": "I have problem with starting Apache Tomcat 6 from Netbeans IDE 7.4 (on 7.3 version I had the same troubles. Other people mentioned that this problem exist also in other versions, like 8.0 etc). What did I do: When I now click \"start\", I got \"\". My suspicions: It affects at least NetBeans versions 7.4 through 8.0.2. It was first reported from version 8.0 and fixed in NetBeans 8.1. It would have had the problem for any tomcat version (confirmed for versions 7.0.56 through 8.0.28).Specifics are described as . This problem is also related to postings mentioning the following error output:For a tomcat installed from the zip file, I fixed it by changing the  file in the tomcat  directory.Find the bellow configuration in your  file.And change it as in below by :Now save your changes, and start your tomcat from within NetBeans.This affects:This is because Netbeans does not 'see' that tomcat is started, although it started just fine.I have filed .In the  file, in the  element for HTTP/1.1, add the following attribute: . Example:The reason for that is that prior to 8.5.3, the default was to set the server header as , while since 8.5.3 this default has now been changed to blank. Apparently Netbeans checks on this header.Maybe in the future we can expect a fix in netbeans addressing this issue.I was able to trace it back to a change in documentation.::That explains the need for explicitly adding the server attribute since version 8.5.3.For NetBeans to be able to interact with tomcat, it needs the user as setup in netbeans to be properly configured in the  file. NetBeans can do so automatically.That is, within the , which you can find in , or ,Example, changeToAddActually the netbeans online-help incorrectly states:The role should be , and not .For a more complete  file:There is another nice posting on Also, it is very likely, that problem with proxy settings.Any who didn't overcome Tomact starting problrem, - try in NetBeans choose  in the Tools -> Options -> General tab.It helped me."},
{"body": "I was working with numbers recently and I had a situation where I want to set the precision of a double value say to 6 digits or 4 digits, depending on the value stored in the database.For example, If in the database the precision is set as 4 digits then the output must look as,. I tried with  and using the string , but it is annoying to use symbols everytime. Is there any better approach, say something like below:You can't set the precision of a double (or Double) to a specified number of decimal digits, because floating-point values don't have decimal digits. They have binary digits.You will have to convert into a decimal radix, either via  or , depending on what you want to do with the value later.See also my answer to  for a refutation of the inevitable *100/100 answers.You can try  for this purpose this is a easy way to do it.it set the presition to 2 digit o any.if you only want to print it use this way.The precision of  and  is fixed by their size and the way the  are implemented.The number of decimal digits in the output, on the other hand, is a matter of formatting. You are correct that typing the same constant over and over is a bad idea. You should declare a string constant instead, and use its symbolic representation.Using a symbolic representation would let you change precision in all places the constant is used without searching through your code.Here's an efficient way of achieving the result with two caveats.See sample test cases here.Here's the code. The two caveats I mentioned above can be addressed pretty easily, however, speed mattered more to me than accuracy, so i left it here.\nString manipulations like  are computationally costly compared to mathematical operations. In my tests, the below code (without the sysout) took 1/30th the time compared to String manipulations.To expand on @EJP, the concept of 'precision' when dealing with doubles is extremely fraught. As discussed in  you can't even represent 0.1 as a double regardless of the precision, for the same reason you can't represent 1/3 in base 10 with finite precision.You need to consider the problem you are trying to solve, and consider:a) Should I be using doubles in the first place; if precision is a relevant concept, then using doubles may well be a mistake.b) If doubles are appropriate, what do I mean by precision? If you are only talking about display, wrap the logic in a display function and you will only need to deal with it in one place; ie. apply the DRY principle.I saw the answer at top:which i think is not the perfect answer. Because answer will change when you call .doubleValue() in many cases.\nExample:\noutput of BigDecimal.valueOf(toBeTruncated)\n    .setScale(3, RoundingMode.HALF_UP) is 12.500then after .doubleValue(), the output will be 12.5 i.e. precision is lost.Solution either use BigDecimal type  without .doubleValue() method to display or use string formatting after the final answerThis worked for me:Maybe this method would help you for precising double values.This method will allow to set the precision level.To set precision for double values DecimalFormate is good technique, to use this class import  and create object of it for example So it will print two digits after decimal point here it will print 12.79"},
{"body": "I've been trying to compare CSV parser libraries for my Java application.\nMy post will aim to capture most of the popular ones talked about.The popular ones I looked into are:\nReviewing the different Stackoverflow votes from other posts, OpenCSV seems to be the most popular. But it hasn't been updated in a long time. The last release been 3 years ago in 2011 ().  \nThis project came as a result of 'authors of the [OpenCSV] project do not respond'. Which gave me for reason not to use 'OpenCSV'. I haven't heard much about it, hence I'm reluctant to use it.\nHas good documentation, and the last release was about a year ago (2013).\nI really like this because of it's support for annotations, and looks really easy. And it's last updated only a few month ago. See an example of it's usage here, the first answer - . The only problem is I'm not able to find the Maven upload for the latest version, the version on maven is 0.9.3 which is 4 years old (Request for Maven Upload - ). Which demonstrates their lack of support.\nThis project aims incorporate / make redundant OpenCSV, Skif CSV and GenJavaCSV. It seems all incorporating. But it is still not released, and is unknown when it will be released (currently in sandbox).I'm interested in your personal recommendations on top of what I have already commented about these CSV libraries? Or if you know the release date, etc for these libraries. Especially JSefa, since it's annotations looks so easy to use? And Apache Commons, the all encapsulating, but not yet released?============================= 23/09/2014 (thanks Kane)14/10/2014"},
{"body": "I have successfully set up an Apache Juddi v3 installation (tomcat version) on my computer. What I want now is to publish a service whose WSDL is found at To achieve this, I created a standalone Java application (starting from the Juddi documentation) that publishes the service found at the above location.The publish part looks ok, but then I want to query the juddi database for the service but a field that should contain the found services is always  (). I really don't know what is wrong and I didn't find any good documentation or tutorial about this on the internet. you can find the sources of the program. Just unarchive it and go to the  folder. The application is found there.With out much Apache knowledge, It sounds as if  function is trying to retrieve information from the wrong sub folder when you do a query.  Try changing the location of the search Function so that it will search all folders/locations or a specific folder/location where the database is located. I could be wrong ( I have limited skills with Apache ).Good luck, sorry if this confused you or did not help.Edit: Sorry, I misread the question. I'm not sure what search criteria you've specified, but the server didn't return any results. When using the \"approximateMatch\" find qualifier, you really need to specify a wildcard character, such as % (any number of characters) or _ (a single character).Long story short, this is probably a bug that has since been fixed. Try a newer version"},
{"body": "I'm trying to send a request to an existing webservice. This webservice is not governed by me. The security policy of this webservice requires me to send my complete certificate chain in my SOAP request. My certificate chain contains 3 certificates. There are no issues with the setup of the certificate chain, as I'm able to test it's validity (and have done so).The security configuration for this setup (= sending the complete certificate chain in the request), is:I'm trying to achieve this through . Spring-WS uses spring-ws-security for security. Spring-ws-security delegates to xws-security. Xws-security comes in 2 flavors:andThe first one is used by Spring WS Security. The second is legacy.Applying my XWSS configuration in xws-security is done in a class called BinarySecurityToken. BinarySecurityToken has a field calledThe JavaDoc of valueType says it has support for X509PKIPathv1 (among others). However, it does not, as stated by this setter:The class MessageConstants does not (even) have a static for X509PKIPathv1. When I run my code, I get the expected result:I was able to look at the source code of the legacy . Despite my efforts, I have not found the source code of . However I believe the code is the same. I tried both libraries and both give me the same exception. I tried it, using the default spring-ws-security and using explicit dependency declarations to both libraries (one at a time).My questions: I have considered re-writing BinarySecurityToken, but that would probably also imply rewriting the X509 signing of SignatureProcessor in DSIG.Interesting problem you got there.As far as I could tell with my Google-fu, there exists support for #X509PKIPathv1 in some projects (e.g.,  or ), however it is not widespread and even application like Soap UI  for SOAP-WS.Not only that, but other languages/frameworks have the same lack of support, like  and , .What you could do, based on  and especially  is implementing your own WebServiceTemplate / WebServiceMessageSender.That is found here\n\nHave you tried those values specifically instead of a URL?"},
{"body": "I am creating a Blackberry application to display a full screen web view of a certain site. I have a working browserfield that displays properly but navigation from page to page is slower than that of the native browser. The browserfield does not seem to have a built in cache causing the load time to be slow. When I add the following code to manage the cache the site no longer displays properly.BrowserFieldScreen.java:CacheProtocolController.java:CacheManager.java:CacheManagerImpl.java:CacheItem.java:Any help that can be giving towards this will be greatly appreciated. This really has me stumped. Thanks. It looks like the caching only works at a certain level of the Blackberry libraries. I have added logic to check the current Software level and turn on the caching if it is supported by the device's current software level. This provides me with a good work around, but i would still like to know if there is a better way for the caching to work with all devices. Based on comments: The site no longer displaying properly pertains to site not displaying the proper layout, images and text. It basically give a white background with links and text displaying as a bulleted list, all formatting removed.I've been looking at your code, and the only thing I've found there's wrong with it, is you are completely ignoring the possibility of  returning less than zero (in ). Although this didn't happen to me at the stackoverflow.com page, some pages use , which means  is not present. This is, however, well handled, and should not cause the cache to fail (it would only be less effective).I suggest testing your code on smaller problems, one step at a time. First, create cacheable page that only contains some text (like \"hello\") without any HTML tags. That should work pretty well, and in case it does not, it shouldn't be hard to determine where the data are getting lost. Or try to manually create cache item that does not expire and contains a webpage with no (external) stylesheet nor images, and see if it's even possible to pass it to  the way you do it. Then build on, add an image, add a style sheet so you can corner the problem.The code is written very nicely, but at this point, it is not possible to help you because there are no evident flaws in the code and you are not explaining yourself very well, it is not clear how the error manifests itself, if it is every time or random, ... If I had a Blackberry device, I could probably try running the code for myself, but i don't."},
{"body": "Just recently I have had a problem with a key store. I know there are plenty of questions about this problem already. I have read them all and Googled furiously.If I type in the password very quickly it works, sometimes.It seems that opening up Eclipse and entering the password the first time lets me use the keystore.Obviously, if all else fails, I will have to create a new key store. I really would like to get this resolved, I am just not sure what to do now besides republish with a new key.If the key cannot be recovered properly, I might open source it on Github.A special thanks to user Erhannis!Here is what I did:The command would error out on me each time: Since you told me we could extract private keys from the Java Keystore(.jks), I dug deeper and ended up using a variation of the command. I followed the links you posted  and :After extracting the private key and storing as PKCS12, I think extracted my private key and put it back into a brand new Java Keystore:I may have had the same problem.  I never did figure out why it was failing (though I wonder if it was because the keystore password was shorter than 6 digits), but I was able to copy my key into a new keystore, which I then renamed to replace the old one, and it mysteriously worked after that (using the new passwords).  Needed the key password, by the way.  Working off , I did the following:After double-checking that the new one worked, I just copied it over the old one.  Hope it works for you; good luck.Try to remove  folder in your workspace and clear all temp folders. If your keystore file isn't damaged and you have tried to reinstall Eclipse, ADT, Android SDK and Java SDK correctly, I don't see other possibly causes for this strange issue excluding .metadata cache files and\\or some temp corruption.Try to use  an utility for managing and examining keystores, keys, certificates, certificate requests, certificate revocation lists etc.I will suggest couple of more heat and trials.Have patience to apply these,Hopes this will help you.I had the same problem and I tried everything that is suggested in this thread but nothing was able to save my alias password. The point is that I was  about the password, since I had updated the app four times already. I was getting the  message.It appears that at the creation of the keystore using eclipse, This nasty bug was apparently fixed at a later version rendering me unable to sign my app with the password I thought was the correct one.Based on this SO link:  I would suggest that you .Are you storing values such as key.store.password or key.alias.password in your local.properties file?  Are either of those incorrect?I'm curious if there's some bug that occurs for keys created with JDK6 and verified in JDK7 - It would explain why the new keys you created for testing work, but the old one doesn't.  Try downgrading to JDK6 and see if that fixes it- Others have had jarsigner trouble in JDK7 that went away when they downgraded to 6.  If that works, file a bug report and demand a patch so you can safely upgrade to Java 7 :)I battled this issue as well recently, and tried all suggestions listed here and elsewhere. Finally identified a silly mistake that was causing this error at my end - I wanted to share this here in case it helps any of you.This is more likely to be the case if you, like me, have multiple Java versions on your machine and had upgraded JRE / JDK between the time you originally created the keystore and now when you're trying to sign the APK.For some reason, our compile instructions were referencing the full Java path like this:C:\\Progra~1\\Java\\jdk1.6.0_45\\bin\\jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore cre80ve.keystore unsigned.apk cre80veOne of the suggestions above got me thinking that it might not be a password issue at all, and it could be version incompatibilities causing the issue. So I ran the below command :keytool -list -keystore cre80ve.keystoreUsing the password that I knew was correct, and lo and behold, it confirmed that it was the right password.I then dropped the explicit reference in the path to the (older) Java version. This made it automatically pick up the latest version of Java (jdk1.8.0_31 in my case):jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore cre80ve.keystore unsigned.apk cre80veAnd everything started working fine! Bottomline: it may not be a password issue at all, but different versions of Java or the Android SDK causing the issue, so remember to check that out. And once it starts working, remember to backup your keystore and password in a safe place :-)My key alias stoped working sudenly. (Ok, after few updates of Android Studio and Java).I tried all solutions from this thread as well as from others. In my case the solution was surprising.\nI have the keystore with few aliases. None was working except one, which had password the same as keystore. But unfortunately it wasn't the one I needed. This made me thinking with no logic involved.\nI copied single alias to new keystore withAnd then I changed alias password to the same as keystore's password with:Finally I was able to sign my apk.\nIt looks like silly bug which can waste a day of development."},
{"body": "Is it possible to do  a \"C like\" fork in java, using an new independent jvm process ?How?Funnily, I am just working on this: a Java process running other Java processes. I used the article  as a solid base, and  as a good advice how to gobble the output streams.PS.: For those wondering, I had to do that (instead of spawning new threads) because yet another Java process is checking the presence of these processes which are, normally, ran separately with shell commands.This answer is probably a little late but:seems to be exactly what your looking forThe  introduces  which addresses this use case."},
{"body": "I wanted to find unused dependencies in my project. Is there any feature for this in gradle like in maven?In  Gradle has implemented  for finding and removing unwanted dependencyThis plugin has various rules.  is one of them. It has 3 specific characteristics.To apply the rule, add:Details of  is given in the last part.For an enterprise build, we recommend defining the lint rules in a init.gradle script or in a gradle script that is included via the Gradle apply from mechanism.For multimodule projects, we recommend applying the plugin in an allprojects block:To apply the rule, add:The rule inspects compiled binaries emanating from your project's  looking for class references, and matches those references to the dependencies that you have declared in your  block.For your kind information, I want to share about previous pluginsBut . After that there is no update.The project mentioned in the earlier answers seem to be dead. I use . Setup is simple:Then do:I've had a lot of luck using the .  To get started with it, add the following two things to your Gradle build script.andOnce those are in place, run .  If there are unused dependencies, you'll get a build failure that shows output similar to the text below, plus a list of the unused dependencies (both declared and transitive).  The build failure is really handy if you want to enforce that there should be no unused dependencies via a CI build.The projects on most of the historical answers are dead, but  appears to  be alive at the time of this writing (last commit was two days ago).It's not a built-in feature, and I'm not aware of a third-party plugin (but perhaps there is one).You can try  gragle pluginAlso, there is a thread () in gradle forum about this."},
{"body": "I am looking for a high-performance, concurrent, MultiMap. I have searched everywhere but I simply cannot find a solution that uses the same approach as ConcurrentHashMap (Only locking a segment of the hash array).The multimap will be both read, added to and removed from often.The multimap key will be a String and it's value will be arbitrary.I need O(1) to find all values for a given key, O(N) is OK for removal, but O(logN) would be preferred.It is crucial that removal of the last value for a given key will remove the container of values from the key, as to not leak memory.HERE'S THE SOLUTION I BUILT, availbable under ApacheV2:\nWhy not wrap ConcurrentHashMap[T,ConcurrentLinkedQueue[U]] with some nice Scala-like methods (e.g. implicit conversion to Iterable or whatever it is that you need, and an update method)?Have you tried Google Collections?  They have various  implementations.There is  although I haven't used it.I made a  mixin which extends the mutable.MultiMap mixin and has a concurrent.Map[A, Set[B]] self type.  It locks per key, which has O(n) space complexity, but its time complexity is pretty good, if you aren't particularly write-heavy.you should give  a try. here is the .I had a requirement where I had to have a  where insertion on the Map be concurrent and also on the corresponding Set, but once a Key was consumed from the Map, it had to be deleted, think if as a Job running every two seconds which is consuming the whole  from an specific Key but insertion be totally concurrent so that most values be buffered when the Job kicks in, here is my implementation: I use Guava's helper class Maps to create the concurrent Maps, also, this solution emulates :I am a bit late on this topic but I think, nowadays, you can use Guava like this:Have you taken a look to  which is intended for Real time etc. and of course high performance.It's late for the discussion, yet...When it comes to high performance concurrent stuff, one should be prepared to code the solution. \nWith Concurrent the statement  has a complete meaning. \nIt's possible to implement the structure fully concurrent and lock-free. Starting base would be the NonBlocking Hashtable  and then depending how many values per key and how often need to add/remove some copy on write Object[] for values or an array based Set with semaphore/spin lock."},
{"body": "While writing an answer to , I noticed a strange border case for JIT optimization. The following program is  a \"Microbenchmark\" and  intended to reliably measure an execution time (as pointed out in the answers to the other question). It is solely intended as an  to reproduce the issue:It basically runs the same loop, , where the limit  is once set to , and once to . When executing this on Win7/64 with JDK 1.7.0_21 and the timing results are as follows:Obviously, for the case of , the JIT does what one could expect: It detects that the loop is useless, and completely eliminates it. However, it does  remove the loop when it is running up to . This observation is confirmed by a look at the JIT assembly output when starting with The log contains the following assembly for the method that runs up to :One can clearly see the loop, with the comparison to  and the jump back to . In contrast to that, the assembly for the case where it is running up to :So my question is: What is so special about the  that prevents the JIT from optimizing it in the same way as it does for ? My guess would be that has to do with the  instruction, which is intended for  arithmetic, but that alone is not really a convincing reason. Can anybody explain this, and maybe even give a pointer to the OpenJDK HotSpot code where this case is treated?(An aside: I hope that the answer will also explain the different behavior between  and  that was asked for in the other question, assuming that the reason for the missing optimization is (obviously)  caused by the  loop limit)I have not dug up the Java Language Specification, but I'd guess that it has to do with this difference:I assume that the JIT compiler is \"reluctant\" to optimize-out loops with such corner conditions - there was a  w.r.t. loop optimization in integer overflow conditions, so that reluctance is probably quite warranted.There may also be some hard requirement that does not allow integer overflows to be optimized-out, although I somehow doubt that since integer overflows are not directly detectable or otherwise handled in Java."},
{"body": "I am new to Scala started learning the language for fun and I am still trying to get my head around it. My understanding of Scala traits is that they are like java interfaces except that some methods can have an implementation.Java 8 is adding interfaces that can have default methods where an implementation can be provided. What are the similarities and differences between Java 8 interfaces and Scala traits?Motivations for  and  differ.The former was introduced to support safe API evolution and a limited form of multiple inheritance. With leveraging functional programming idioms in Project Lambda it's been beneficial to add, for example, a  method to  interface without altering all possible implementers (which is actually impossible to do without breaking backward compatibility). As a side effect this also offered a form of . were designed from scratch as building blocks for modular components composition. They are multiple inheritance friendly and don't have  by having strict rules on evaluation order of mix-ins due to linearization. They also support state, can reference the implementing class and place restrictions on which type can mix-in them. Look at Scala collections library where traits are used thoroughly.Note that with ,  now compiles to an interface.\nScala 2.12 is all about making optimal use of Java 8\u2019s new featuresSee  more the difference of implementation."},
{"body": "What is the fastest-track set of resources for a C# developer wishing to hit the ground running in an enterprise-class Java team?I would suggest the following books:Java really is a different kettle of fish - there's a lot more to developing enterprise apps than there is to C#. You have all kinds of different things to worry about - EJB's, Enterprise vs. \"Personal\" runtimes, etc etc..The best advice I can give you is to use the NetBeans IDE. It is big, slow and cumbersome, but it does guide you for most of the way.The language itself should be simple to understand.  There are not as many language constructs, everything possible is done in libraries.The libraries will take some getting used to.  The two most critical things you can do to hit the ground running is:1: Use NetBeans or Eclipse and hit ctrl-space ALL THE TIME.  It's like the god key.2: bookmark this page: \n(or the one appropriate for your version of java--but the version doesn't matter all that much)  Each box in the graphic represents a library package, click one ones that you want to have an overview of. Try to get a handle on what each package does.  Browse the packages that are of interest and scan the classes.  This page also links to a lot of tutorials.After that it's just a matter of learning what other libraries you'll need to do your job.   there is a lot to J2EE if your group uses that, you'll probably end up using Hibernate, and you should look into messaging & maybe RMI (you may not be using it directly, but nearly all intra-java communications are based on RMI).remember ctrl-space.  It will give you parameters, lists of functions that match what you've typed so far, it fills in import declarations, it expands macros, ...Oh, and two other Eclipse tricks:\nctrl-shift-T.  \"Lookup Type\" (in eclipse, there is one in NetBeans but I can't remember the key sequence, ctrl-shift-O maybe).  Anyway, you type in a partial classname and it will give you a list of ALL matching classes in your project.  Click one to open it.ctrl-click.  Jumps to the declaration/definition of whatever you click on.Be prepared for abstractions. Lots and lots of abstractions ;)Read the API documentation for packages , , and . Seriously. The mark of an amateur, in java, is someone writing a loop when there is a method in java.util.Collections that already does what they want.It's good to read:Love it or Hate it! :-)"},
{"body": "I'm studying for the OCPJP exam, and so I have to understand every little strange detail of Java. This includes the order in which the pre- and post-increment operators apply to variables. The following code is giving me strange results:Shouldn't the answer be 11? Or maybe 13? But not 12!What is the result of the following code? the first   becomes 4. So you have .( becomes 5 after the 2nd , but that is discarded, because the assignment  overrides it)Your statement:is equivalent to any of those:Use any of those instead. means 'the value of a, and a is then incremented by 1'. So when you runthe first  is evaluated first, and produces the value 3.  is then incremented by 1. The second  is then evaluated.  produces the value of 4, and is then incremented again (but this doesn't matter now)So this turns into which equals 12.First build the syntax tree:To evaluate it start with the outer most element and descent recursively. For each element do:The  operator is special: It gets expanded to something like , but only evaluating the expression  once. Still the left side gets evaluated to a value(and not just a variable) before the right side gets evaluated to a value.This leads to:One thing to note here is that operator precedence has no direct influence on evaluation order. It only affects the form of the tree, and thus indirectly the order. But among siblings in the tree the evaluation is always left-to right, regardless of operator precedence. is a post increment, so value of expression is 3. is post increment, so value of expression is now 4.Expression evaluation is happening from left to right.Each time the you use a++, you're post-incrementing a. That means the first a++ evaluates to 3 and the second evaluates to 4. 3 * 4 = 12.There is a general lack of understanding about how operators work. Honestly, every operator is syntactic sugar.All you have to do is understand what is actually happening behind every operator. Assume the following:Compound operators can then be rewritten using these generalizations (please ignore the return types for the sake of simplicity):You can rewrite your example:asWhich can be split out using multiple variables:It's certainly more verbose that way, but it immediately becomes apparent that you never want to perform more than two operations on a single line.In case of :In case of :Main point to note here is that in this case compiler is solving from left to right and\nin case of post increment, value before increment is used in calculation and as we move from left to right incremented value is used. means return  and increment, so\n means 3 * 4Here is the java code:Here is the bytecode:Here is what happens:Pushes 3 into the stack then pops 3 from the stack and stores it at a.\nNow a = 3 and the stack is empty.Now it pushes the value from \"a\" (3) into the stack, and then increments a(3 -> 4). So now \"a\" equals \"4\" the stack equals {3}.Then it loads \"a\" again (4), pushes into the stack and increments \"a\".Now \"a\" equals 5 and the stack equals {4,3}So it finally pops the fisrt two values from the stack (4 and 3), multiplies and stores it back into the stack (12).Now \"a\" equals 5 and the stack equals 12.Finally is pops 12 from the stack and stores at a.TADA!It is 12.\nThe expression starts evaluating from left. So it does:Once the first part (3++) is evaluated, a is 4, so in the next part, it does a = 3*4 = 12. \nNote that the last post-increment (4++) is executed but has no effect since a is assigned with the value 12 after this.Just to make sure where to put  expression which changes the value based on the location.Everyone has clearly explained the first expression, and why the value of a is 12.For the follow on question, the answer is totally obvious to the casual observer:Pre & post-prefix increments have a higher precedence than the multiplication operator. hence the expression is evaluated as 3*4.If you use a++ the next time you use a it is incremented by one. So your doing"},
{"body": "What would be the easiest way to tell  the following:Managing Maven and Ivy repositories is sort of new to me - I tried the following steps and they result in :Maybe I misunderstand something - why would getting the  version of the dependency be such a hard task that?Gradle currently neither supports Maven's  (which is rarely used and deprecated) nor Ivy's . The general recommendation is to build against exact versions. Otherwise, the build can become a lottery.It can be quite useful sometimes to get the latest release - if for example you release often your own dependencies.You can get the latest version likeor better specify at least the major version likeCheck out the Gradle-Versions-Plugin. It does exactly what you want: For the installation, see the github page. Basically you need to add these two lines to your build.gradle - project file:Then you can use the plugin, by running this command in terminal in your project dir:And it will show you which dependencies are outdated!Latest Gradle User Guide mentions and explains plus sign in versions:From :From :"},
{"body": "I have been implementing an LLRB package that should be able to operate in either of the two modes, Bottom-Up 2-3 or Top-Down 2-3-4  ( - improved code, though dealing only with 2-3 trees , thanks to RS for pointer).Sedgewick provides a very clear description of tree operations for the 2-3 mode, although he spends a lot of time talking about the 2-3-4 mode. He also shows how a simple alteration of the order of color flipping during insertion can alter the behaviour of the tree (either split on the way down for 2-3-4 or split on the way up for 2-3):However, he glosses over deletion in 2-3-4 LLRBs with the following:His delete() function:My implementation correctly maintains LLRB 2-3 invariants for all tree operations on 2-3 trees, but fails for a subclass of right-sided deletions on 2-3-4 trees (these failing deletions result in right leaning red nodes, but snowball to tree imbalance and finally null pointer dereferencing). From a survey of example code that discusses LLRB trees and includes options for construction of trees in either mode, it seems that none correctly implements the deletion from a 2-3-4 LLRB (i.e. none has the extra rotation alluded to, e.g. Sedgewick's java above and ).I'm having trouble figuring out exactly what he means by \"extra rotation when the right node off the search path is a 4-node\"; presumably this is a rotate left, but where and when?If I rotate left passing upwards past a 4-node equivalent (i.e. RR node) or a right leaning 3-node equivalent (BR node) either before calling fixUp() or at the end of the fixUp function I still get the same invariant contradiction.Here are the tree states of the smallest failing examples I have found (generated by sequential insertion of elements from 0 to the respective maximum value).The first pair of trees shows the transition from invariant-conforming state prior to deletion of element 15 to obviously broken state after.The second is essentially the same as above, but with deletion of 16 of 0..16 (deletion of 15 results in the same topology). Note that the invariant contradiction manages to cross the root node.The key is going to be understanding how to revert the violations generated during the walk down the tree to the target node. The following two trees show how the first tree above looks after a walk down the left and right respectively (without deletion and before walking back up with fixUp()).After attempt to delete '-1' without fixUp:\nAfter attempt to delete '16' without fixUp:\nTrying rotate left on the walk back up when the node has only a red right child seems to be part of the solution, but it does not deal correctly with two red right children in a row, preceding this with a flipColor when both children are red seems to improve the situation further, but still leaves some invariants violated.If I further check whether the right child of a right child is red when its sibling is black and rotate left if this is true I only fail once, but at this point I feel like I'm needing a new theory rather than a new epicycle.Any ideas?For reference, my implementation is available  (No, it's not Java).Follow-up:Part of the reason I was interested in this was to confirm the claim by many that 2-3 LLRB trees are more efficient than 2-3-4 LLRB trees. My benchmarking has confirmed this for insertion and deletion (2-3 are about 9% faster), but I find that retrieval is very slightly faster for 2-3-4 trees.The following times are representative and consistent across runs:First column is bench name, second is number of operations, third is result. Benchmark on i5M 2.27.I have had a look at branch lengths for 2-3 tree and 2-3-4 trees and there is little in that to explain the retrieval difference (mean distance from root to node and S.D. of 1000 trees each with 10000 random inserts):Of key importance to testing this is that the implementation doesn't support deleting a nonexistent or previously deleted node! I spent way too long trying to figure out why my working solution was \"broken\". This can be fixed by doing a preliminary search for the key and returning false if it's not in the tree at all, and that solution was employed in the linked code at the bottom.It doesn't appear Sedgewick wrote a deletion for 2-3-4 deletion that is publicly available. His results specifically deal with 2-3 trees (he only makes cursory mention of 2-3-4 trees in that their average path length (and thus search cost), as well as that of other red-black trees, is indistinguishable from the 2-3 case). Nobody else seems to have one easily found, either, so here's what I found after debugging the problem:To begin, take Sedgewick's code and fix the out of date bits. In the slides  (pg 31) you can see that his code still uses the old representation of 4 nodes where it was done by having two left reds in a row, rather than balance. The first bit to write a 2-3-4 deletion routine, then, is to fix this so that we can do a sanity check which will help us verify our fixes later:Once we have this, we know a couple things. One, from the paper we see that 4 nodes should not be broken on the way up when using a 2-3-4 tree. Two, there's a special case for a right 4-node on the search path. There's a third special case that isn't mentioned, and that is when you are going back up a tree, you may end up where you have  be red, which would leave you invalid with just a rotate left. This is the mirror of the case described for insert on page 4 of the paper.The rotation fix for a 4-node you need is as follows:And this removes the splitting on 2-3-4, as well as adds the fix for the third special caseFinally, we need to test this and make sure it works. They don't have to be the most efficient, but as I found during the debugging of this, they have to actually work with the expected tree behavior (i.e. not insert/delete duplicate data)! I did this with a test helper methods. The commented lines were there for when I was debugging, I'd break and check the tree for obvious imbalance. I've tried this method with 100000 nodes, and it performed flawlessly:The complete source can be found ."},
{"body": "I'm trying to understand how java deals with ambiguities in function calls. In the following code, the call to  is ambiguous, but  is not!!!. I feel both are ambiguous, but why does this compile when I comment out the call to ? Why is  not ambiguous as well?EDIT: \nThis came up in comments: A number of IDEs report both as ambiguous - IntelliJ and Netbeans so far. However, it compiles just fine from command-line/maven.An intuitive way to test whether  is more specific than  is to see whether  can be implemented by invoking  with the same parametersIf there are varargs, we may need to expand a vararg so that 2 methods have same number of params.Let's check the first two s in your example(return types are not used in determining specificity, so they are omitted)Both compile, therefore each is more specific than the other, hence the ambiguity. Same goes for your s, they are more specific than each other. Therefore the call to  is ambiguous and shouldn't compile; otherwise it's a compiler bug.So that's what the spec says; but is it proper? Certainly,  looks more specific than . Actually if we have a concrete type instead of then only  is more specific than , not vice versa.The discrepancy arises from the magic of type inference. / calls a generic method without explicit type arguments, so the compiler tries to infer the type arguments. The  of type inference algorithm is to find type arguments ! No wonder L1 and L2 compile. L2 is actually infer to be Type inference tries to guess what the programmer wants, but the guess must be wrong sometimes. Our real intention is actually"},
{"body": "If one writes two public Java classes with the same case-insensitive name in different directories then both classes are not usable at runtime. (I tested this on Windows, Mac and Linux with several versions of the HotSpot JVM. I would not be surprised if there other JVMs where they are usable simultaneously.) For example, if I create a class named  and one named  like so:Three eclipse projects containing the code above are .If try I calling  on both classes like so:The typechecker succeeds, but when I run the class file generate by the code directly above I get:In Java, names are in general case sensitive. Some file systems (e.g. Windows) are case insensitive, so I'm not surprised the above behavior happens, but it seems . Unfortunately the Java specifications are oddly non-commital about which classes are visible. The  (Section 6.6.1, page 166) says:In Section 7.3, the JLS defines observability of a compilation unit in extremely vague terms:The  is similarly vague (Section 5.3.1):All of this leads to four questions in descending order of importance:The core bits and pieces of the language, plus supporting implementation classes. Not guaranteed to include any class that you write. (The normal JVM loads your classes in a separate classloader from the bootstrap one, and in fact the normal bootstrap loader loads its classes out of a JAR normally, as this makes for more efficient deployment than a big old directory structure full of classes.)Java loads classes by mapping the full name of the class into a filename that is then searched for on the classpath. Thus  goes to  and  goes to . Some filesystems mix these things up, and may serve the other up when one is asked for. Others get it right (in particular, the variant of the ZIP format used in JAR files is fully case-sensitive and portable). There is nothing that Java can do about this (though an IDE could handle it for you by keeping the  files away from the native FS, I don't know if any actually do and the JDK's  most certainly isn't that smart).However that's not the only point to note here: class files know internally what class they are talking about. The absence of the  class from the file just means that the load fails, leading to the  you received. What you got was a problem (a mis-deployment in at least some sense) that was detected and dealt with robustly. Theoretically, you could build a classloader that could handle such things by keeping searching, but  Putting the class files inside a JAR will fix things far more robustly; those are handled correctly.More generally, if you're running into this problem for real a lot, take to doing production builds on a Unix with a case-sensitive filesystem (a CI system like Jenkins is recommended) and Donal's fine explanation leaves little to add, but let me briefly muse on this phrase:  Names and Strings in general are never case-insensitive , it's only there  that can be. And secondly, Java doesn't do such an interpretation. So, a correct phrasing of what you had in mind would be: Don't think just about folders.Use explicit different namespaces (\"packages\") for your classes, and maybe use folders to match your classes.When I mention \"packages\", I don't mean \"*.JAR\" files, but, just the concept of:When you do not specify a package for your code, the java tools (compiler, I.D.E., whatever), assume to use the same global package for all. And, in case of several similar classes, they have a list of folders, where to look for.Packages are like \"virtual\" folders in your code, and apply to all your packages on your classpath, or installation of Java.  You can have several classes, with the same I.D., but, if they are in different package, and you specify which package to look for, you won't have any problem.Just my 2 cents, for your cup of Java coffe"},
{"body": "I am learning programming (python and algo\u2019s) and was trying to work on a project that I find interesting.   I have created a few basic python scripts but I\u2019m not sure how to approach a solution to a game I am trying to build.users will be given items with a value. For exampleThey will then get a chance to choose any combo of them they like (i.e. 100 apples, 20 pears, and 1 oranges).  The only output the computer gets is the total value(in this example, its currently $143).  The computer will try to guess what they have. Which obviously it won\u2019t be able to get correctly the first turn.The next turn the user can modify their numbers but no more than 5% of the total quantity (or some other percent we may chose. I\u2019ll use 5% for example.). The prices of fruit can change(at random) so the total value may change based on that also(for simplicity I am not changing fruit prices in this example). Using the above example, on day 2 of the game, the user returns a value of $152 and $164 on day 3. Here's an example.*(I hope the tables show up right, I had to manually space them so hopefully its not just doing it on my screen, if it doesn't work let me know and I'll try to upload a screenshot).I am trying to see if I can figure out what the quantities are over time(assuming the user will have the patience to keep entering numbers). I know right now my only restriction is the total value cannot be more than 5% so I cannot be within 5% accuracy right now so the user will be entering it forever. Here\u2019s my solution so far(not much).  Basically I take all the values and figure out all the possible combos of them(I am done this part).  Then I take all the possible combos and put them in a database as a dictionary(so for example for $143, there could be a dictionary entry {apple:143, Pears:0, Oranges :0}..all the way to  {apple:0, Pears:1, Oranges :47}.  I do this each time I get a new number so I have a list of all possibilities.  Here\u2019s where I\u2019m stuck.  Is using the rules above, how can I figure out the best possible solution? I think I\u2019ll need a fitness function that automatically compares the two days data and removes any possibilities that have more than 5% variance of the previous days data.So my question with user changing the total and me having a list of all the probabilities, how should I approach this? What do I need to learn? Is there any algorithms out there  or theories that I can use that are applicable? Or, to help me understand my mistake, can you suggest what rules I can add to make this goal feasible(if its not in its current state. I was thinking adding more fruits and saying they must pick at least 3,etc..)?  Also, I only have a vague understanding of genetic algorithms but I thought I could use them here, if is there something I can use?I'm very very eager to learn so any advice or tips would be greatly appreciated(just please don't tell me this game is impossible). Thanks in advance.UPDATE: Getting feedback that this is hard to solve.   So I thought I'd add another condition to the game that won't interfere with what the player is doing(game stays the same for them) but everyday the value of the fruits change price(randomly). Would that make it easier to solve? Because within a 5% movement and certain fruit value changes, only a few combo's are probable over time. Day 1, anything is possible and getting a close enough range is almost impossible, but as the prices of fruits change and the user can only choose a 5% change, then shouldn't(over time) the range be narrow and narrow. In the above example, if prices are volatile enough I think I could brute force a solution that gave me a range to guess in, but I'm trying to figure out if there's a more elegant solution or other solutions to keep narrowing this range over time.UPDATE2: After reading and asking around, I believe this is a hidden markov/Viterbi problem that tracks the changes in fruit prices as well as total sum(weighting the last data point the heaviest).  I'm not sure how to apply the relationship though.  I think this is the case and could be wrong but at the least I'm starting to suspect this is a some type of machine learning problem.Update3: I am created a test case(with smaller numbers) and a generator to help automate the user generated data and I am trying to create a graph from it to see what's more likely.\nHere's the code, along with the total values and comments on what the users actually fruit quantities are.We'll combine graph-theory and probability:On the 1st day, build a set of all feasible solutions. Lets denote the solutions set as A1={a1(1), a1(2),...,a1(n)}.On the second day you can again build the solutions set A2.Now, for each element in A2, you'll need to check if it can be reached from each element of A1 (given x% tolerance). If so - connect A2(n) to A1(m). If it can't be reached from any node in A1(m) - you can delete this node.Basically we are building a connected directed acyclic graph.All paths in the graph are equally likely. You can find an exact solution only when there is a single edge from Am to Am+1 (from a node in Am to a node in Am+1).Sure, some nodes appear in more paths than other nodes. The probability for each node can be directly deduced based on the number of paths that contains this node.By assigning a weight to each node, which equals to the number of paths that leads to this node, there is no need to keep all history, but only the previous day.Also, have a look at  - A question I asked a while ago. The accepted answer is a great way to enumarte all combos in each step.This problem is impossible to solve.\nLets say that you know exactly for what ratio number of items was increased, not just what is maximum ratio for this. User has N fruits and you have D days of guessing.In each day you get N new variables and then you have in total D*N variables.For each day you can generate only 2 equations. One equation is sum of  n_item*price and other is based on know ratio.  In total you have at most 2*D equations if they are all independent. 2*D < N*D for all N > 2First, I would like to state what I see two main problems here:Let's lay down some bases for the upcoming examples:In order to solve this more easily , which makes the algorithm converge faster:This rule enables us to rule out solutions more easily. And, with non-tiny ranges, renders  still useless, just like your original problem and rules.In my humble opinion, this rule is not the  of the game but only a facilitator, enabling the computer to solve the problem.For starters,  can be solved using a  to find a set of potential solutions. The technique is simple: Generate random numbers for item values and quantities (within their respective accepted range). Repeat the process for the required number of items. Verify whether or not the solution is acceptable. That means verifying if items have distinct values and the total is equal to our target total (say, 143.)While this technique has the advantage of being easy to implement it has some drawbacks:How to get around these drawback? Well...Note that the more you restrict the ranges, the less useful while be the Monte Carlo algorithm is, since there will be few enough valid solutions to iterate on them all in reasonable time. For constraints { 3, [1-10], [0-100] } there is around 741,000,000 valid solutions (not constrained to a target total value.) Monte Carlo is usable there. For { 3, [1-5], [0-10] }, there is only around 80,000. No need to use Monte Carlo; brute force  loops will do just fine.I believe the  is what you would call a  (or CSP.)Given the fact that  is a CSP, I would go ahead and call , and the problem in general, a  (or DCSP.)One technique used with CSPs that might be useful to this problem is called :For this to work, you need to get a new set of possible solutions every day; Use either brute force or Monte Carlo. Then, compare solutions of D to D and keep only solutions that can succeed to previous days' solutions without violating constraints.You will probably have to keep an history of what solutions lead to what other solutions (probably in a directed graph.) Constraint recording enables you to  possible add-remove quantities and rejects solutions based on that.There is a lot of other steps that could be taken to further improve your solution. Here are some ideas:Given all of this, try and figure out a ranking system based on occurrence of solutions and heuristics to determine a candidate solution.I wrote a program to play the game.  Of course, I had to automate the human side, but I believe I did it all in such a way that I shouldn't invalidate my approach when played against a real human.I approached this from a machine learning perspective and treated the problem as a hidden markov model where the total price was the observation.  My solution is to use a particle filter.  This solution is written in Python 2.7 using NumPy and SciPy.I stated any assumptions I made either explicitly in the comments or implicitly in the code.  I also set some additional constraints for the sake of getting code to run in an automated fashion.  It's not particularly optimized as I tried to err on the side comprehensibility rather than speed.Each iteration outputs the current true quantities and the guess.  I just pipe the output to a file so I can review it easily.  An interesting extension would be to plot the output on a graph either 2D (for 2 fruits) or 3D (for 3 fruits).  Then you would be able to see the particle filter hone in on the solution.Update:Edited the code to include updated parameters after tweaking.  Included plotting calls using matplotlib (via pylab).  Plotting works on Linux-Gnome, your mileage may vary.  Defaulted NUM_FRUITS to 2 for plotting support.  Just comment out all the pylab calls to remove plotting and be able to change NUM_FRUITS to anything.Does a good job estimating the current fxn represented by UnknownQuantities X Prices = TotalPrice.  In 2D (2 Fruits) this is a line, in 3D (3 Fruits) it'd be a plane.  Seems to be too little data for the particle filter to reliably hone in on the correct quantities.  Need a little more smarts on top of the particle filter to really bring together the historical information.  You could try converting the particle filter to 2nd- or 3rd-order.Update 2:I've been playing around with my code, a lot.  I tried a bunch of things and now present the final program that I'll be making (starting to burn out on this idea).Changes:The particles now use floating points rather than integers.  Not sure if this had any meaningful effect, but it is a more general solution.  Rounding to integers is done only when making a guess.Plotting shows true quantities as green square and current guess as red square.  Currently believed particles shown as blue dots (sized by how much we believe them).  This makes it really easy to see how well the algorithm is working.  (Plotting also tested and working on Win 7 64-bit).Added parameters for turning off/on quantity changing and price changing.  Of course, both 'off' is not interesting.  It does a pretty dang good job, but, as has been noted, it's a really tough problem, so getting the exact answer is hard.  Turning off CHANGE_QUANTITIES produces the simplest case.  You can get an appreciation for the difficulty of the problem by running with 2 fruits with CHANGE_QUANTITIES off.  See how quickly it hones in on the correct answer then see how harder it is as you increase the number of fruit.You can also get a perspective on the difficulty by keeping CHANGE_QUANTITIES on, but adjusting the MAX_QUANTITY_CHANGE from very small values (.001) to \"large\" values (.05).One situation where it struggles is if on dimension (one fruit quantity) gets close to zero.  Because it's using an average of particles to guess it will always skew away from a hard boundary like zero.In general this makes a great particle filter tutorial.\nFrom my school years, I would say that if we make abstraction of the 5% changes, we have everyday an equation with 3 unknown values (sorry I don't know the maths vocabulary in english), which are the same values as previous day.\nAt day 3, you have 3 equations, 3 unknown values, the solution should be direct.I guess the 5% change each day may be forgotten if the values of the 3 elements are different enough, because, as you said, we will use approximations and round the numbers.\nToo many unknown - and changing - values in this case, so there is no direct solution I know of. I would trust Lior on this, his approach looks fine! (if you have a limited range for prices and quantities)"},
{"body": "Can I move the instruction pointer  to a line of my choice (within the current method) while debugging a Java program in Eclipse (Galileo)?It's straightforward to drag the instruction pointer to the desired line within a method in Visual Studio, but I don't see a way to do that in Eclipse (and don't find anything about it in the docs or on google).This is not possible.If you simply want to execute some code at the current place you can use the  view and enter your code as an expression. The methods called by the expression evaluation will run in the current debugging context.This is possible...I like ankon's answer best, but another option (that will only work for your specific instance -- if that) is to stop at a breakpoint on your  and modify the variable(s) evaluated in the conditional such that it returns false (from the \"Variables\" view, right click on a variable and click \"Change Value...\")I thought that this was totally possible in older versions of eclipse, I thought I had the memory of doing it, but I guess I just implanted that memory when I worked in Visual Studio. From what I'm reading it might come to the jvm and not eclipse itself, there are pages where it's suggested that the jvm cannot handle that.In my opinion Eclipse is many many times better than VS, I worked extensively in both and since I discovered Eclipse I was always in pain when I had to work in VS. But not having this feature is definitely hurting right now hehe.You can jump directly to any other method call inside of the currently debugged method. Select some method call below your current instruction pointer and use \"\" from the context menu.unfortunately not possible to step forward with instruction pointer (program counter), so what you need to do instead is to introduce your own \"debugging\" variables that you can test on - lets say you want to step around a loop that takes too long, then add a variable and test on its increased value and then encapsulate the loop in an if with that variable. I know this is ugly, but it gets it done - or you could just develop in C++ :-) Just right click on desired line and choose run to line.That's it...Put the cursor on the line of your choice and either hit ctrl-R (\"Run to line\") or right-click and select \"Run to line\" from the context menu."},
{"body": "I have recently started working with Cassandra Database. Now I am in the process of evaluating which  we should go forward with. I have seen various post on stackoverflow about which client to use for Cassandra but none has very definitive answer. My team has asked me to do some research on this and come up with certain  for each  in Java.As I mentioned, I recently got involved with  so not have that much idea why certain people choose  and why certain people go with  and some other clients. I know brief things about each of the Cassandra clients, by which I mean I am able to make that work and start reading and writing to Cassandra database.Below is the information I have so far.Below are our priorities in deciding -Can anyone provide some thoughts on this? And also any pros and cons for each  and also which client can fulfill my requirements will be of great help as well.I believe, mainly I will be revolving around  I guess basis on my research so far. But don't have certain information to back my research and present it to my team.Any comparison between Astyanax client and New Datastax client(which uses new Binary protocol) will be of great help.It will be of great help to me in my research and will get lot of knowledge on this from different people who have used different clients in the past.Thrift is becoming more of a legacy API:So I'd avoid Thrift based APIs (thrift is only kept for backwards compatibility).In saying that if you do need to use a thrift based API I'd go for Astyanax.\nAstyanax is very easy to use (compared to other thrift APIs but my personal experience is that Datastax's driver is even easier).So you should have a look at  API ()? I'm not sure if there any compiled versions of the API for download but you can easily build it with Maven. Also if you take a look at the GitHub repo's commit logs it undergoes very frequent updates. The driver works exclusively with CQL3 and is asynchronous but be warned that Cassandra 1.2 is the earliest supported version. \nAstyanax is thrift based and Datastax's drive is the binary protocol. Here are the latest  I could find between thrift and CQL (note these are definitely out of date). But in fairness the small difference in performance shown in these benchmarks will rarely matter. \nDatastax's  support is a definite advantage over Astyanax (Netflix  it but decided not to).  \nI cant really argue against . The documentation is excellent and its updated fairly frequently. Their wiki includes code examples, and you can find tests in the source code if you need to see the code at work. I struggled to find any documentation of the Datastax driver however test are provided in the GitHub repository so that is a starting point.Also have a look at  (well.. not my one anyway) It looks into some advantages/disadvantages of Thrift and CQL.I would recommend Datastax java driver for Cassandra .For JPA like support try my mapping tool.\nAnnotation driven \nNo mapping files, no scripts, no configuration files. \nNo need for DDL scripts.\nSchema automatically synchronized with the entity definition.Usage sample:available on maven centralI would also add decent support as well.  We post answers to playORM all the time on stack overflow ;).  It also is about to start supporting mongodb(work is nearly finished) so any clients can run on mongodb or cassandra.  It has it's own query language such that this port works just fine.  You always have access to the raw astyanax interface too when really need the speed.Also, your note on asynch...thrift previously did not support asynch so no clients did either as they generated the thrift code.  Since that has changed, I don't know of a client that has added the asynch stuff in.I know hbase has an asynch client though.  Anyways, just thought I would add my 2 cents in case it helps a little.EDIT: I was recently in the cassandra-thrift generated source code and it is not a very good api for async development with send and a recv() method but you don't know when to call the recv method.  Aaron morton on cassandra user list has a blog on how you can really do it but it is not clean at all...have to grab the selector from thrift deep down and do some stuff so you know when to call the recv method...pretty nasty stuff.later,\nDeanI've used Hector, Astyanax and Thrift directly.  I've also used the Python client PyCassa.The features that I found important and differentiating were:One of the major issues is getting the types correct.  You want to be able to pass in longs, Strings, byte[], etc..  Both Hector and Astyanax solve this by using Serializer objects.  In Astyanax you specify them higher up the chain so you have to specify them less often.  In Hector the syntax is often very clunky and hard to adapt if you change your schema.Since Python has dynamic types, it is much easier to deal with this in PyCassa.  Since it's not an option for you I won't say much about it, but I found it easiest to use (by far) but also quite slow.Composite column support is very confusing in Hector.  Astyanax has annotations to greatly simplify this.As far as I know, the connection pooling is the same for Hector and Astyanax.  Both will avoid downed hosts and discover new ones added to the ring.  Both of these features a crucial to reliability and maintainability.  Pelops appears to have these features but I've never tried it.A key difference between Astyanax and Hector is the latency optimizations.  Astyanax has the ability to route read and write requests to a replica node, potentially avoiding an extra networking hop.  This can reduce the latency by a few milliseconds.At last look, Astyanax had poor documentation, but it seems much improved now.The only advantage of Hector I can see today is that it is much more widely used so probably less buggy.  But Astyanax has a better feature set.I have a similar recommendation as Valchkou. DataStax java CQL driver, is very good. I tried astyanax, kundera and buffalosw's playorm. Astyanax is very low level and some what complex. Kundara and playorm are generic ORMs for nosql databases, and are complex to setup and to get started.Datastax apis are pretty much similar to a JDBC driver and you have to embed CQL statements in your DAO and write several lines of code to load and save your entities. To solve this problem, I wrote a java object mapper called cassandra-jom, built around datastax cql driver. Cassandra-jom annotations are very similar to JPA/Hibernate annotations and can even create/update your column family schema from your object model. It is easy to use and reliable and used in my other live web applications. Check it out at its github page."},
{"body": "What exactly makes the JVM (in particular, Sun's implementation) slow to get running compared to other runtimes like CPython? My impression was that it mainly has to do with a boatload of libraries getting loaded whether they're needed or not, but that seems like something that shouldn't take 10 years to fix.Come to think of it, how does the JVM start time compare to the CLR on Windows? How about Mono's CLR?UPDATE: I'm particularly concerned with the use case of small utilities chained together as is common in Unix. Is Java now suitable for this style? Whatever startup overhead Java incurs, does it add up for every Java process, or does the overhead only really manifest for the first process?Here is  (with some references).It appears that most of the time is taken just loading data (classes) from disk (i.e. startup time is I/O bound). Just to note some solutions:There are two mechanisms that allow to faster startup JVM.\nThe first one, is the class data sharing mechanism, that is supported since Java 6 Update 21 (only with the HotSpot Client VM, and only with the serial garbage collector as far as I know)To activate it you need to set  (on some implementations:  ) JVM options.To read more about the feature you may visit:\nThe second mechanism is a Java Quick Starter. It allows to preload classes during OS startup, see:\n for more details.Running a trivial Java app with the 1.6 (Java 6) client JVM seems instantaneous on my machine.  Sun has attempted to tune the client JVM for faster startup (and the client JVM is the default),  so if you don't need lots of extra jar files, then startup should be speedy.If you are using Sun's HotSpot for x86_64 (64bit compiled), note that the current implementation only works in server mode, that is, it precompiles every class it loads with full optimization, whereas the 32bit version also supports client mode, which generally postpones optimization and optimizes the most CPU-intensive parts only, but has faster start-up times.See for instance:That being said, at least on my machine (Linux x86_64 with 64bit kernel), the 32bit HotSpot version supports both client and server mode (via the -client and -server flags), but defaults to server mode, while the 64bit version only supports server mode.It really depends on what you are doing during the start up.  If you run Hello World application it takes 0.15 seconds on my machine.  However, Java is better suited to running as a client or a server/service which means the startup time isn't as important as the connection time (about 0.025 ms) or the round trip time response time (<< 0.001 ms).There are a number of reasons:I'm not sure about the CLR, but I think it is often faster because it caches a native version of assemblies for next time (so it doesn't need to JIT). CPython starts faster because it is an interpreter, and IIRC, doesn't do JIT.In addition to things already mentioned (loading classes, esp. from compressed JARs); running in interpreted mode before HotSpot compiles commonly-used bytecode; and HotSpot compilation overhead, there is also quite a bit of one-time initialization done by JDK classes themselves.\nMany optimizations are done in favor of longer-running systems where startup speed is less of a concern.And as to unix style pipelining: you certainly do NOT want to start and re-start JVM multiple times. That is not going to be efficient. Rather chaining of tools should happen within JVM. This can not be easily intermixed with non-Java Unix tools, except by starting such tools from within JVM.All VMs with a rich type system such as Java or CLR will not be instanteous when compared to less rich systems such as those found in C or C++. This is largely because a lot is happening in the VM, a lot of classes get initialized and are required by a running system. Snapshots of an initialized system do help but it still costs to load that image back into memory etc.A simple hello world styled one liner class with a main still requires a lot to be loaded and initialized. Verifying the class requires a lot of dependency checking and validation all which cost time and many CPU instructions to be executed. On the other hand a C program will not do any of these and will amount of a few instructions and then invoke the printer function."},
{"body": "I saw this list of major version numbers for Java in another post:References:\nThese come from the class version.  If you try to load something compiled for java 6 in a java 5 runtime you'll get the error, incompatible class version, got 50, expected 49.  Or something like that.See  in byte offset 7 for more info.Additional info can also be found .I found a list of Java class file versions on the Wikipedia page that describes the class file format:Under byte offset 6 & 7, the versions are listed with which Java VM they correspond to."},
{"body": "I have multiple view resolvers in a Spring configuration and wanted to use different view resolvers for different requests.Example: For URLs starting with , use Birt view resolver, and for ajax calls use Tiles resolver and so on.Tried setting order property, but all views are resolved by .You absolutely can.  has a single method,  which returnsYour  beans are registered. When a view name is returned by a handler, Spring will iterate through each , invoking their  method with the given name. If the method returns non, that  is used. If  is returned, then it continues iterating.So the implementation has to return  if Spring is to skip it.There are some implementations that never return . This seems to be the case with your custom  classes. If the  returns a , even if that  will eventually fail to be rendered, Spring will use it.You either need to fix that or order your  beans. For example, you can order them with the  interface. Have your classes implement that interface and return an appropriate value."},
{"body": "Servlet-3.0 API allows to detach a request/response context and answer to it later.However if I try to write a big amount of data, something like:It may actually block - and it does block in trivial test cases - for both Tomcat 7 and Jetty 8. The tutorials recommend to create a thread pool that would\nhandle such a setup - witch is generally the counter-positive to a traditional 10K architecture.However if I have 10,000 open connections and a thread pool of let's say 10 threads, \nit is enough for even 1% of clients that have low speed connections or just blocked\nconnection to block the thread pool and completely block the comet response or\nslow it down significantly.The expected practice is to get \"write-ready\" notification or I/O completion notification \nand than continue to push the data.How can this be done using Servlet-3.0 API, i.e. how do I get either:If this is not supported by the Servlet-3.0 API, are there any Web Server specific APIs (like Jetty Continuation or Tomcat CometEvent) that allow to handle such events truly asynchronously without faking asynchronous I/O using thread pool.Does anybody know?And if this is not possible can you confirm it with a reference to documentation?I had attached the code below that emulates event-stream.Notes:In such an example I explicitly defined thread pool of size 1 to show the problem:I want to solve such a problem without using thread pool, because with 1000-5000 open\nconnections I can exhaust the thread pool very fast.The sample code below.The sample above uses threads to prevent blocking... However if the number of blocking clients is bigger than the size of the thread pool it would block.How could it be implemented without blocking?I've found the   API tricky to implement correctly and helpful documentation to be sparse. After a lot of trial and error and trying many different approaches, I was able to find a robust solution that I've been very happy with. When I look at my code and compare it to yours, I notice one major difference that may help you with your particular problem. I use a  to write the data and not a . Here my go-to Asynchronous Servlet class adapted slightly for your  case:During my research on this topic, this thread kept popping up, so figured I mention it here:Servlet 3.1 introduced async operations on  and . See .An example can be found at this might be helpfulWe can't quite cause the writes to be asynchronous. We realistically have to live with the limitation that when we do write something out to a client, we expect to be able to do so promptly and are able to treat it as an error if we don't. That is, if our goal is to stream data to the client as fast as possible and use the blocking/non-blocking status of the channel as a way to control the flow, we're out of luck. But, if we're sending data at a low rate that a client should be able to handle, we are able at least to promptly disconnect clients that don't read quickly enough.For example, in your application, we send the keepalives at a slow-ish rate (every few seconds) and expect clients to be able to keep up with all the events they're being sent. We splurge the data to the client, and if it can't keep up, we can disconnect it promptly and cleanly. That's a bit more limited than true asynchronous I/O, but it should meet your need (and incidentally, mine).The trick is that all of the methods for writing out output which just throw IOExceptions actually do a bit more than that: in the implementation, all the calls to things that can be interrupt()ed will be wrapped with something like this (taken from Jetty 9):(I also note that this  happen in Jetty 8, where an InterruptedException is logged and the blocking loop is immediately retried. Presumably you make to make sure your servlet container is well-behaved to use this trick.)That is, when a slow client causes a writing thread to block, we simply force the write to be thrown up as an IOException by calling interrupt() on the thread. Think about it: the non-blocking code would consume a unit of time on one of our processing threads to execute anyway, so using blocking writes that are just aborted (after say one millisecond) is really identical in principle. We're still just chewing up a short amount of time on the thread, only marginally less efficiently.I've modified your code so that the main timer thread runs a job to bound the time in each write just before we start the write, and the job is cancelled if the write completes quickly, which it should.A final note: in a well-implemented servlet container, causing the I/O to throw out  to be safe. It would be nice if we could catch the InterruptedIOException and try the write again later. Perhaps we'd like to give slow clients a subset of the events if they can't keep up with the full stream. As far as I can tell, in Jetty this isn't entirely safe. If a write throws, the internal state of the HttpResponse object might not be consistent enough to handle re-entering the write safely later. I expect it's not wise to try to push a servlet container in this way unless there are specific docs I've missed offering this guarantee. I think the idea is that a connection is designed to be shut down if an IOException happens.Here's the code, with a modified version of RunJob::run() using a grotty simple illustration (in reality, we'd want to use the main timer thread here rather than spin up one per-write which is silly).Is Spring an option for you?  Spring-MVC 3.2 has a class called , which will gracefully handle your \"10,000 open connections/10 server pool threads\" scenario.Example: I've had a quick look at your listing, so I may have missed some points.\nThe advantage of a pool thread is to share thread resources between several tasks over time. Maybe you can solve your problem by spacing keepAlive responses of different http connections, instead of grouping all of them at the same time. "},
{"body": "I am trying to use hibernate annotation for writing a model class for my database tables.I have two tables each having a primary key User and Question. Question Table.And I have one more table, UserAnswer, which has userId and questionId as foreign keys from the above two tables.But I am unable to find how I can reference these constraints in the UserAnswer table.Please help me achieve this?\nThanks in advance. is not the appropriate annotation. You don't want to store a whole User or Question in a column. You want to create an association between the entities. Start by renaming  to , since an instance represents a single question, and not several ones. Then create the association:The  explains that. Read it. And also read the javadoc of the annotations.The  annotation can be used above that property or field  of class that is being referenced from some other entity."},
{"body": "What is the Java 8 functional interface for a method that takes nothing and returns nothing? I.e., the equivalent to to the C# parameterless  with  return type?If I understand correctly you want a functional interface with a method . In which case you can simply use a ."},
{"body": "I heard a lot of good things about  and the  Web framework recently, especially from  hence, I might use this technology in my next projects.  Share your experiences on the Scala/Lift Platform.I'm working on my second Lift app at the moment - it's very strongly in Lift's sweet spot - very realtime, lots of concurrency.The first one we wimped out after a few days of wrestling with the DB layer (it's better now, I am led to believe), and went to Play/Scala instead.  That maximized the existing knowledge of our team and made it possible to make deadline.  But the hot code reloading pretty much stopped happening once our project got moderately large (kept running out of PermGen - it's an ongoing problem with Scala compilation pretty much anywhere), and the manual juggling of things like method call parameters and location security in different places in the website got quite cumbersome.  We were glad when it was done - in the same way as I tended to find Rails 1, the speed increases shrank as the project size increased, and by the end it was every bit as tedious and error-prone as working in a Velocity/Spring/XML++ whatever).This time we've been committed to just working out how Lift does what it does, and the right ways to do things.  This has meant a lot of casual browsing through the mailing list (discussions that are several versions old are often still relevant), and most importantly a new ethos for the team.  It's been necessary to internalize very strongly the motto:\"This is feeling hard and repetitive.  I bet they made an easier way to do this.\"So far Lift has never disappointed us.  I'm not talking, by the way, about stuff like the Sitemap and list concatenation syntax - you MUST have a pretty good handle on functional Scala, or you just won't be able to read the source code or even configure your app.That said it's not crazy IO monads or anything, just some common idioms that you'd pick up in a few weeks of Scala anyway.The biggest problem for us has been a slow compile cycle.  It takes about 20 seconds to jetty:run our project, which is a different feeling to Play which (when it's working) hot compiles all your stuff.  On the other hand, we actually timed that the other day when one of our devs complained about it, and it worked out that although Play technically hot compiled it, the page still took 12 seconds to load in Dev mode.  So there's not a huge loss, it just feels a bit slow to have to hop out to the command line.Lift lets you do a great deal, and there are many places in our app where (because it's available), we've said \"Yeah, we really WOULD prefer to have that live updated immediately to all viewers of that page, instead of them discovering later that they're out of date (think of all the times you've posted simultaneously to someone on SO, with the same answer).  COMET is everywhere, it turns out - it's not a specialist use case, it's the way things should work.  And Lift makes it really easy.We also love the strong, programatically configurable, security model - once we switched our mindsets to \"We have to whitelist every location, and specify the necessary entrance conditions\", we never saw another session problem - you know, those ones where you assumed that the user would have traversed a certain path, and thus would know a whole bunch of parameters?  Like, a valid username, and an area of interest or whatever?  (I'm being intentionally vague).  That can be one of the awkward things about a stateful framework, that you're going to want to have usable state when the user hits a page, instead of (for instance) just demanding that all the state gets carried along at each request.My takeaway from this renewed shot at Lift:It's worth it.  Not just to build the app that you're trying to build, but to build the app that you didn't know you needed.There's a lot of head scratching, but not a lot of code.  And when it works it really works.  It's fast, and clean, and for all of the miracles that it's working between the browser and the server, I've never yet seen it get confused.I'm developing enterprise financial application in Lift for more than 6 months and I was JAVA programmer former. I have noticed a few points, which could help you:I can't imagine that I have to return to JAVA code now. But my little advice is to try to code some simple application and you will see."},
{"body": "If I am creating a java class to be generic, such as:  How can one determine internally to that class, what 'T' ended up being? I've poked around the Java API and played with the Reflection stuff, instanceof, getClass, .class, etc, but I can't seem to make heads or tails of them. I feel like I'm close and just need to combine a number of calls, but keep coming up short.To be more specific, I am attempting to determine whether the class was instantiated with one of 3 possible types.I've used a similar solution to what he explains here for a few projects and found it pretty useful.The jist of it is using the following: In contrast to .NET Java generics are implemented by a technique called \"type erasure\".What this means is that the compiler will use the type information when generating the class files, but not transfer this information to the byte code. If you look at the compiled classes with javap or similar tools, you will find that a  is a simple  (of ) in the class file, just as it was in pre-Java-5 code.Code accessing the generic List will be \"rewritten\" by the compiler to include the casts you would have to write yourself in earlier versions. In effect the following two code fragments are identical from a byte code perspective once the compiler is done with them:Java 5:Java 1.4 and before:When reading values from a generic class in Java 5 the necessary cast to the declared type parameter is automatically inserted. When inserting, the compiler will check the value you try to put in and abort with an error if it is not a String.The whole thing was done to keep old libraries and new generified code interoperable without any need to recompile the existing libs. This is  a major advantage over the .NET way where generic classes and non-generic ones live side-by-side but cannot be interchanged freely.Both approaches have their pros and cons, but that's the way it is in Java.To get back to your original question: You will not be able to get at the type information at runtime, because it simply is not there anymore, once the compiler has done its job. This is surely limiting in some ways and there are some cranky ways around it which are usually based on storing a class-instance somewhere, but this is not a standard feature. Because of , there is no way to do this directly. What you could do, though, is pass a  into the constructor and hold onto it inside your class. Then you can check it against the three possible  types that you allow.However, if there are only three possible types, you might want to consider refactoring into an  instead.The Problem is that most of the Generic stuff will disappear during compilation.One common solution is to save the type during the creation of the Object. For a short introduction in the Type Erasure behaviour of java read this  If you know a few specific types that are meaningful, you should create subclasses of your generic type with the implementation.SoAnd thenThe whole point of a generic class is that you dont need to know the type that is being used....It looks like what you want is in fact not a Generic class, but an interface with a number of different implementations. But maybe it would become clearer if you stated your actual, concrete goal.I agree with Visage. Generics is for compile-time validation, not runtime dynamic typing. Sounds like what you need is really just the factory pattern. But if your \"do this\" isn't instantiation, then a simple Enum will probably work just as well. Like what Michael said, if you have a slightly more concrete example, you'll get better answers."},
{"body": "I've compiled a  file and specified the Main-Class in the manifest (I used the Eclipse  function). My dependencies are all in a directory labeled . I can't seem to get a straight answer on how to execute my JAR file while specifying it should use the  as the classpath.I've tried:etc...Each gives an error saying:or gives the  indicating the libraries are not being found.I even tried remaking the JAR file and included the  directory and contents, but still no dice...How can I execute a JAR file from the command line and specify the classpath to use?When you specify  then the  parameter will be ignored. From :You also cannot \"include\" needed jar files into another jar file (you would need to extract their contents and put the .class files into your jar file)You have two options:Run a jar file and specify a class path like this: is the full name of the JAR you want to execute is a path to your dependency JARs is the fully qualified name of the class from the JAR that has the  methodThe jar and dependent jar should have execute permissions."},
{"body": "Is there any way in Gson to map multiple JSON fields to a single Java object member variable?Let's say I have a Java class...I want to use this single class with two different services. However, these two services differ in how they return their data...... and ...... respectively.Is there any way to map both the  and  fields in the JSON string to the  field in the Java object? (Note: I only ever need to convert from JSON string to Java object - never the other way around.)In October 2015,  () added the ability to use alternate/multiple names for  when deserializing. No more custom TypeAdapter needed!It is not supported to define multiple  annotations to a field at Gson.   By default Deserialization is managed with a LinkedHashMap and the keys are defined by incoming json's field names (not the custom class's field names or the serializedNames) and there is a one to one mapping. You can see the implementation(how deserialization works) at  class's inner class 's  method.\nYou can write a custom  which handles ,  and  json tags and maps them to name field of your custom class : As @Mathieu Castets has written at his answer, it is supported now. (That is the correct answer for this question.)"},
{"body": "I'm using maven 2.0.9 with Eclipse 3.3.2.I'm used to launching a fresh build once per day by a .\nThen, if I refresh my Eclipse project, it will be \"polluted\" by files from Maven's  directory.That's very annoying while performing searches, getting resources by \"open resource\" and so on.Is there a way to avoid Eclipse looking in this folder?Right click on the folder you want to ignore, open the \"Properties\" dialog, chose the \"Resource\" tab and check the box that says \"Derived\"Reconfigure \"clean\" in Maven not to delete target directory:(found at: )Solution for Indigo [SR2] >  >  > I have been so pissed by this problem that I wrote a plugin to solve it. You get get the source and jar from:Preferences > Team > Ignored ResourcesAdd \"target\", and restart Eclipse.\nTo solve this problem here is what I did:\n\n-----------Cut below here for script--------------Did you try configuring the \"Java Element Filters\" option dialog box, (through the top-right arrow of the project explorer) ?If needed, you can define your own The maven plugin does not hide away the target directory. It does however use the maven target folders to configure eclipse. So target/classes and target/test-classes are used by eclipse, and eclipse filters these folders out. This is done by \"mvn eclipse:eclipse\" as well as by the m2eclipse plugin. What is left visible is everything in the target directory besides these two folders (the generated jar file for example).You can create a filter for the package explorer, but that will not influence the \"open resource\". I had some issues because some solutions here only work for some views, so I made an illustrated summary. \u2192  \u2192  check  and input .Be careful, this will hide all folders and files named , not just the default maven build directory! The  view has a better option without this issue.\nProject Explorer View Menu \u2192  \u2192  search for \"maven\" and check .Checking this option hides the build directory as defined in the projects pom.xml configuration.\nAre you using the Maven plugin for Eclipse?I would imagine it would hide some of the 'pollution' for you.It would also allow you to perform the build within Eclipse - meaning it would refresh the project view for you at the same time.Using Resource filter looks solve issue if you using 'mvn clean install' frequently.Basically it will add 'target' to and sub folders to exclude folder directly to .project file. After run this script, if you import project to eclipse, you can see the setting 'Project'->'Properties'->'Resource'->'Resource Filters'.  Before this whenever I run mvn clean install, eclipse took 50% of my CPU but now it stay under 5% while build project.When Eclipse freezes, looking at the process activity, I can see it browsing all my target, .hg and .git directories. Moreover, those directories are also copied into Eclipse's bin directory. A lot of CPU and disk usage for nothing.Not cleaning the target directory is not an acceptable solution.There was a solution using a Monkey script (http://maven.40175.n5.nabble.com/Eclipse-amp-target-directory-td72354.html) but the project has been closed.I still look for a solution to tell Eclipse to ignore Maven target directories, as well as .hg and .git directories.Eclipse continuously watching those is a pain.I also use m2eclipse but it doesn't solve that issue."},
{"body": "So, I have a class with a constructor like this:and I want to construct a new  object with an empty set. Following Joshua Bloch's advice in his book Effective Java, I don't want to create a new object for the empty set; I'll just use  instead:This gives me an error, complaining that  is not a . OK, how about this:This also gives me an error! Ok, how about this:Hey, it works! But why? After all, Java doesn't have type inference, which is why you get an unchecked conversion warning if you do  instead of . But  works without even a warning. Why is that?The short answer is - that's a limitation of the type inference in Java's generic system.  It can infer generic types against concrete variables, but not against method parameters.I  this is because methods are dispatched dynamically depending on the runtime class of the owning object, so at compile time (when  generic information is resolved) you can't actually know for sure what the class of the method parameter will be and hence can't infer.  Variable declarations are nice and constant, so you can.Someone else might be able to give more detail and/or a nice link. :-)In any case, you can always specify the type parameters explicitly for generic calls like so:or even several parameters at once, e.g.This often looks a little cleaner than having to cast, in cases where inference doesn't kick in.try You can force the type parameter for methods that have them, in cases where the inference isn't good enough, or to allow you to use subtypes; for example:Java does have a type inference, it's just pretty limited. If you are interested in knowing exactly how it works and what its limitations are, this is a really good read:You want to do this:That tells the  method that its generic parameter should explicitly by  instead of the default . And yes, the syntax is completely funky and non-intuitive for this. :)"},
{"body": "I'm getting a  when trying to run the following method: The error is on the line I don't understand this error, because monStart is a field of the  class: I'm just learning to use reflection, so I'm sure this is some sort of a syntactical error...The  method will only find the field if it's .  You will need to use the  method instead, which will find any field that is declared  on the class, even if it's not .According to the javadoc,  \"Returns a  object that reflects the specified public member field of the class or interface represented by this  object\".\nUse  if you want to access non-public fields.Best solutions for  problem are:Use () instead of ()2)     Replace  with your class nameIf you want to get the annotation length of the columnI came to this question based on the title. I was getting the same error () in my Android project but for a different reason. So for others who come here, this error can also potentially be caused by the caches getting out of sync in Android Studio. Go to See  also "},
{"body": "How do I count the number of files in a directory using Java ? For simplicity, lets assume that the directory doesn't have any sub-directories.I know the standard method of :But this will effectively go through all the files in the directory, which might take long if the number of files is large. Also, I don't care about the actual files in the directory unless their number is greater than some fixed large number (say 5000). I am guessing, but doesn't the directory (or its i-node in case of Unix) store the number of files contained in it? If I could get that number straight away from the file system, it would be much faster. I need to do this check for every HTTP request on a Tomcat server before the back-end starts doing the real processing. Therefore, speed is of paramount importance.I could run a daemon every once in a while to clear the directory. I know that, so please don't give me that solution.This might not be appropriate for your application, but you could always try a native call (using jni or ), or exec a platform-specific command and read the output before falling back to list().length.  On *nix, you could exec  (note - that's dash-one-a for the first command, and dash-lowercase-L for the second).  Not sure what would be right on windows - perhaps just a  and look for the summary.Before bothering with something like this I'd strongly recommend you create a directory with a very large number of files and just see if list().length really does take too long.  As  suggests, you may not want to sweat this.I'd probably go with Varkhan's answer myself.Ah... the rationale for not having a straightforward method in Java to do that is file storage abstraction: some filesystems may not have the number of files in a directory readily available... that count may not even have any meaning at all (see for example distributed, P2P filesystems, fs that store file lists as a linked list, or database-backed filesystems...).\nSo yes,is probably your best bet.Since Java 8, you can do that in one line:Regarding the 5000 child nodes and inode aspects:This method will iterate over the entries but as Varkhan suggested you probably can't do better besides playing with JNI or direct system commands calls, but even then, you can never be sure these methods don't do the same thing!However, let's dig into this a little:Looking at JDK8 source,  exposes a  that uses an  from  that delegates to .On UNIX systems (decompiled ), it loads an iterator: A  is used (with file locks while iterating through the directory).So, there is an iterator that will loop through the entries here.Now, let's look to the counting mechanism.The actual count is performed by the count/sum reducing API exposed by . In theory, this API can perform parallel operations without much effort (with multihtreading). However the stream is created with parallelism disabled so it's a no go...The  of this approach is that  as the entries will be counted by an iterator as they are read by the underlying (Filesystem) API.Finally, for the information, conceptually in a filesystem, a directory node is not required to hold the  of the files that it contains, it can  contain the list of it's child nodes (list of inodes). I'm not an expert on filesystems, but I believe that UNIX filesystems work just like that. So you can't assume there is a way to have this information directly (i.e: there can always be some list of child nodes hidden somewhere).Unfortunately, I believe that is already the best way (although  is slightly better than , since it doesn't construct  objects).Since you don't really need the total number, and in fact want to perform an action after a certain number (in your case 5000), you can use . The benefit is that you can exit early instead having to go through the entire directory just to get a count.The  for  also has some good examples. If you have directories containing really (>100'000) many files, here is a (non-portable) way to go: Using sigar should help.  has native hooks to get the statsUnfortunately, as mmyers said, File.list() is about as fast as you are going to get using Java. If speed is as important as you say, you may want to consider doing this particular operation using . You can then tailor your code to your particular situation and filesystem."},
{"body": "Question is simple:I have two ListAnd I need to get the intersection of these. Is there a quick way to achieve this?You can use  method:Since retainAll won't touch the argument collection, this would be faster:The intersection will be the values left in columnsNew. Removing already compared values fom columnsOld will reduce the number of comparisons needed.Using Guava: How aboutThere is a nice way with streams which can do this in one line of code and you can two lists which are not from the same type which is not possible with the containsAll method afaik:An example for lists with different types. If you have a realtion between foo and bar and you can get a bar-object from foo than you can modify your stream:If you put the second list in a set say HashSet. And just iterate over the first list checking for presence on the set and removing if not present, your first list will eventually have the intersection you need.\nIt will be way faster than retainAll or contains on a list.\nThe emphasis here is to use a set instead of list. Lookups are O(1).\nfirstList.retainAll (new HashSet (secondList)) will also work.using retainAll if don't care occurrences, otherwise using N.intersectionN is an utility class in "},
{"body": "When I add the configurations for  to my Android project and build the project I get the following error:A little late to the game here but this is  a problem with the dependencies you have listed in your  file for you app. After lots of testing i successfully chased down my problem and believe it could be of help to others.Things I do not recommend:Things to look out for:Google has a comprehensive list of the libraries for selectively compiling With all that said you probably only need to include this one line in gradle for your Google Analytics:Also, you can view the dependency tree by going to the root of your project (or using terminal in Android studio) and running:Good Luck and happy coding!Now as of Android Studio 2.2 you no longer need to trial and error whether you need to use multi-dex in your application. Use the  to see if its really needed! \nThis allows you to refer to all methods of the app. It is as if you have two modules (limit: 2 x 65K) but compacted into one. This entails a cost (time) in the build process. For me it was related to simplexml converter for retrofit 2. And it fixed by:That means your app would working fine on API level 21 or above.So, Firstly making sure you have imported correct dependency, which It seems you did it.In your manifest add the  class from the multidex support library to the application element.Alternative to that, If your app extends the  class, you can override the  method and call  to enable .Finally, you will need to update your build.gradle file as below by adding  :I hope it will help you out.in my case, I had this twice in the build.grade fileOnce I removed the 2nd entry, it worked fine.What i did to fix this is removed the gradle changes from here () then in Android Studio went into 'file/Project Structure' then click into analytics and if the box is checked uncheck it, let gradle sync then check the box again and click the button to sign in. After all this to get your analytics tracker working you just have to copy your actual tracker id into  look at this page for help. Exactly the same problem as I encountered! I found out that it was due to duplicate dependencies. In build.gradle, one dependency may be already included in others, thus generate conflicts. I removed necessary dependencies and solved my problem. Include specific dependencies in the build file. i think you are using google analytic sdk V3  use V4 instead i have also facing the same issue while using sdk V3 of google analytic  see this link for more information.This could happen if you updated Android Studio to the latest version 1.4. Did you update the support libraries to the latest versions? Your  should be 23.I actually found that having too many Android Studio modules was contributing to having this error without multidex enabled. If you are trying to avoid enabling multidex the limit seemed to be around 26 modules. This was with Android Studio 1.5.1The same problem but when using react-native-svg. This helped me:"},
{"body": "I'd like to get an id unique to a computer with Java, on Windows, MacOS and, if possible, Linux. It could be a disk UUID, motherboard s/n... can be used (it is not an applet).Ideas?It is common to use the MAC address is associated with the network card.The address is available in Java 6 through through the following API:I haven't used it in Java, but for other network identification applications it has been helpful.The problem with MAC address is that there can be many network adapters connected to the computer. Most of the newest ones have two by default (wi-fi + cable). In such situation one would have to know which adapter's MAC address should be used. I tested MAC solution on my system, but I have 4 adapters (cable, WiFi, TAP adapter for Virtual Box and one for Bluetooth) and I was not able to decide which MAC I should take... If one would decide to use adapter which is currently in use (has addresses assigned) then new problem appears since someone can take his/her laptop and switch from cable adapter to wi-fi. With such condition MAC stored when laptop was connected through cable will now be invalid.For example those are adapters I found in my system:Code I've used to list them:From the options listen on this page, the most acceptable for me, and the one I've used in my solution is the one by @Ozhan Duz, the other one, similar to @finnw answer where he used JACOB, and worth mentioning is  - sample which makes use of WMI is available :This will print some computer information together with computer Serial Number. Please note that all classes required by this example has to be generated by maven-com4j-plugin. Example configuration for maven-com4j-plugin:Above's configuration will tell plugin to generate classes in target/generated-sources/com4j directory in the project folder.For those who would like to see  solution, I'm including links to the three classes I wrote to get machine SN on Windows, Linux and Mac OS:As an alternative way of finnw's solution  command line utility could be used to querying devices serial numbers. Without external dependency most of the WMI things could be established with wmic.What do you want to do with this unique ID? Maybe you can do what you want without this ID.The MAC address maybe is one option but this is not an trusted unique ID because the user can change the MAC address of a computer.To get the motherboard or processor ID check on this .The  project provides  hardware utilities.Maven dependency:For instance, you could use something like the following code to identify a machine uniquely:Output for my machine:Your output will be different since at least the processor serial number will differ.On Windows only, you can get the motherboard ID using , through a COM bridge such as .Example:And if you choose to use the MAC address to identify the machine, you can use WMI to determine whether an interface is connected via USB (if you want to exclude USB adapters.)It's also possible to get a hard drive ID via WMI but this is unreliable.Be careful when using the MAC address as an identifier.  I've experienced several gotchas:Even with the above issues, I still think it's the best pure Java approach to hardware locking a license.Not Knowing all of your requirements. For example, are you trying to uniquely identify a computer from all of the computers in the world, or are you just trying to uniquely identify a computer from a set of users of your application. Also, can you create files on the system?If you are able to create a file. You could create a file and use the creation time of the file as your unique id. If you create it in user space then it would uniquely identify a user of your application on a particular machine. If you created it somewhere global then it could uniquely identify the machine.Again, as most things, How fast is fast enough.. or in this case, how unique is unique enough.I think you should look at this  ... you can make a mixed key using several\nidentifiers such as mac+os+hostname++.The usage of  id is most easier way if the task is about logging the unique id a system.the change of mac id is though possible, even the change of other ids of a system are also possible is that respective device is replaced.so, unless what for a unique id is required is not known, we may not be able to find an appropriate solution.However, the below link is helpful extracting mac addresses.\n In the java programs I have written for release I used the motherboard serial number (which is what I beleive windows use); however, this only works on windows as my function creates a temporary VB script which uses the WMI to retrieve the value.For identifying a windows machine uniquely.\nMake sure when you use wmic to have a strategy of alternative methods. Since \"wmic bios get serialnumber\" might not work on all machines, you might need to have additional methods:Resources:\nThe Best Way To Uniquely Identify A Windows Machine\n"},
{"body": "I'm trying to have a default  object in my class, with the default properties it accepts, and let the developer override some of them by specifying another  object, but I couldn't find a nice way for doing that.The intended usage is the following: implements the  interface, and so you  just treat it as such, and use methods like  to add the contents of another .However, if you treat it like a Map, you need to be very careful with this:This often catches people out, because it  like a copy constructor, but it isn't. If you use that constructor, and then call something like  (inherited from its  superclass), you'll get an empty set, because the  methods of  do not take account of the default  object that you passed into the constructor. The defaults are only recognised if you use the methods defined in  itself, such as  and , among others.So if you need to merge two Properties objects, it is safer to do this:This will give you more predictable results, rather than arbitrarily labelling one of them as the \"default\" property set.Normally, I would recommend not treating  as a , because that was (in my opinion) an implementation mistake from the early days of Java (Properties should have contained a , not extended it - that was lazy design), but the anemic interface defined in  itself doesn't give us many options.Assuming you eventually would like to read the properties from a file, I'd go for loading both files in the same properties object like:You're almost good: replaced  by .putAll():\nCopies all of the mappings from the specified map to this hashtable. These mappings will replace any mappings that this hashtable had for any of the keys currently in the specified map. Line 2 has no effect at all. None of the properties from the first file will be in the merged properties object.Yea you're right just invoke the putAll method and you're done. "},
{"body": "How can i get the name of the class\nI am only interested in getting last part  ie only String\n\nAny Api can do that?or programmaticaly Social.class.getSimpleName()getSimpleName() :\nReturns the simple name of the underlying class as given in the source code. Returns an empty string if the underlying class is anonymous.\nThe simple name of an array is the simple name of the component type with \"[]\" appended. In particular the simple name of an array whose component type is anonymous is \"[]\".The below both ways works fine.Output as below:You can use following simple technique for print log with class name.Suppose we have to check coming variable value in method then we can use log like bellow : Importance of this line is that, we can check method name along with class name. To write this type of log.write :-   and Enter.will print on console "},
{"body": "I am actually new to REST WS but really I don't get this . I am testing my REST with Poster on Firefox and the  works fine for me, also the  (when it's a ) but when I try  it doesn't not reach the WS at all, the server rejects it.This is my URL: http:// localhost:8081/RestDemo/services/customers/addthis is  I'm sending: this is  I'm sending:and this is my Resource class:I would appreciate your help, Thanks.This is my Customer class:The issue is in the deserialization of the bean Customer. Your programs knows how to do it in XML, with JAXB as Daniel is writing, but most likely doesn't know how to do it in JSON.Here you have an example with Resteasy/Jackson\nThe same with Jersey:\nAdd  and \nin REST Client header sectionJust in case this is helpful to others, here's my anecdote:I found this thread as a result of a problem I encountered while I was using Postman to send test data to my RESTEasy server, where- after a significant code change- I was getting nothing but 415 Unsupported Media Type errors.Long story short, I tore everything out, eventually I tried to run the trivial file upload example I knew worked; it didn't.  That's when I realized that the problem was with my Postman request.  I normally don't send any special headers, but in a previous test I had added a \"Content-Type\": \"application/json\" header.  OF COURSE, I was trying to upload \"multipart/form-data.\" Removing it solved my issue.Moral: Check your headers before you blow up your world. ;)I had the same problem: I resolved it by adding the dependency to pom.xml as follows. Please try it. I had this issue and found that the problem was that I had not registered the JacksonFeature class:Without doing this your application does not know how to convert the JSON to a java object. Don't return Strings in your methods but Customer objects it self and let JAXB take care of the de/serialization."},
{"body": "I'd like to retrieve all table names from a database schema, and, if possible, get all table starting with a specified prefix. I tried using JDBC's  but it didn't work at all.Could someone help me on this?You need to iterate over your ResultSet calling .This is an example from :Column  is the  (see documentation of ).If you want to use a high-level API, that hides a lot of the JDBC complexity around database schema metadata, take a look at this article: In your example problem is passed table name pattern in getTables function of DatabaseMetaData. Some database supports Uppercase identifier, some support lower case identifiers. For example oracle fetches the table name in upper case, while postgreSQL fetch it in lower case. DatabaseMetaDeta provides a method to determine how the database stores identifiers, can be mixed case, uppercase, lowercase see: From below example, you can get all tables and view of providing table name pattern, if you want only tables then remove \"VIEW\" from TYPES array.public static ArrayList getTablesList(Connection conn)\n            throws SQLException {"},
{"body": "How to make the RequestMapping to handle GET parameters in the url?\nFor example i have this url(from jqGrid)how should my RequestMapping look like? I want to get the parameters using HttpReqestTried this:but it doesn't work.Use  in your method arguments so Spring can bind them, also use the  array to narrow the method that will be used by spring. Sample code:This way Spring will only execute this method if ALL PARAMETERS are present saving you from null checking and related stuff.You can add  like so:This will get ALL parameters from the request. For Debugging purposes only:If you are willing to change your uri, you could also use . The first foo is part of the path, the second one is the This works in my case:You should write a kind of template into the :Now define your business method like following:So, framework will map  to appropriate . Since sort may be either asc or desc I'd define it as a enum:Spring deals with enums very well. "},
{"body": "I want a list of dates between start date and end date.  The result should be a list of all dates including the start and end date.  I suggest to use  for that. Add one day at a time until reaching the end date.It wouldn't be too hard to implement your own iterator to do this as well, that would be even nicer.Get the number of days between dates, inclusive.If you are using , there is a much cleaner approach. The new  in Java 8 incorporates the features of the  API.Your requirement can be solved using the below code:please find the below code.output:  Here is the Java 8 way, using streams and .You can do the same with the java.time framework built into Java 8 and later, using its  class.Something like this should definitely work:With  it looks like this in Java:and the output is:One solution would be to create a  instance, and start a cycle, increasing it's  field until it reaches the desired date. Also, on each step you should create a  instance (with corresponding parameters), and put it to your list.Some dirty code:You can also look at the  API. That gives a long to which you can add your increment. Then create a new Date.and maybe apache commons has something like this in DateUtils, or perhaps they have a CalendarUtils too :)including the start  enddate may not be possible if your interval is not perfect :)With  , maybe it's better:It's my solution.... very easy :)In  (which will probably be released still in 2017), you can use following new method:The new method  works with an exclusive end date, hence the shown hack to add a day.Once you have obtained a stream you can exploit all the features offered by - or -packages. Or if you look for a stream-based solution which operates on inclusive dates by default but can also be configured otherwise then you might find the class  in my library  interesting because it offers a lot of special features around date streams including a performant spliterator which is faster than in Java-9:Or even simpler in case of full months:Like as @folone, but correctA tail-recursive version:Enhancing one of the above solutions. As adding 1 day to end date sometimes adds an extra day beyond the end date.Here is my method for getting dates between two dates, including / w.o. including business days. It also takes source and desired date format as parameter.And the method call would be like :You can find the demo code : Recursive solution"},
{"body": "Why do we need to close a FileInputStream (and streams in general)  before we leave the program? What would happen otherwise? If the program stops before the input stream is closed explicitly in the program, doesn't the stream also close automatically?File handles are scarce, finite resources.  You can run out of them if you don't clean them up properly, just like database connections.If you've written a small program with just one user you can get away with being sloppy and not closing in a finally block.But if you end up using that idiom in an application that has many users and file handles you might have a problem.\"First we make our habits, then they make us.\"  I try to apply best practices even when they aren't necessary.Yes, when the process terminates the unmanaged resources will be released. For InputStreams this is fine. For OutputStreams, you could lose an buffered data, so you should  flush the stream before exiting the program.Dude.  If you don't close your stream, your unit test will fail.  Or at least, it should.  So, that's why you need to close it.  ;)And while the OS will almost certainly clean up if you just exit, they'll generally get freed up faster if you explicitly close them.  Furthermore, what if your code ends up in a long-running program sometime down the road?  Then they'll have problems and curse you.  :(So, it's like washing your hands after using the bathroom.  Eventually someone will pay the price if you don't do it.  You can get away with it for a while, but it's still a good practice.In addition to Jon's answer, it is generally a good idea to close any resource.Think of a database connection. Your database cannot have infinite connections opened, in this case when you don't need it, it's better you close it as soon as you're done with it.It is also good to make this a habit. \"finally\" block is your friend. In case of C++, you can also use .Sort of. The stream is backed by a \"real\" operating system file descriptor, and when the process terminates the OS will clean up any open file descriptors.Anyway, it's good practice to always close your resources when you're done, so close the streams :)If you don't close streams, you may have problems opening them back up again. This is especially true if they're hanging off the end of sockets.Closing a stream also makes sure that data is flushed through the stream if there is any data left to send. "},
{"body": "I am getting an exception and I can't find the reason of it.The exception I get is :The method is public.i am using apache tomcat 5.5.12\nand JAVA 1.6You are almost certainly using a different version of the class at runtime to the one you expect.  In particular, the runtime class would be different to the one you've compiled against (else this would have caused a compile-time error) - has that method  been ?  Do you have old versions of the classes/jars on your system anywhere?As the javadocs for  state,I'd definitely look at your classpath and check whether it holds any surprises.This happens when accessing a package scoped method of a class that is in the same package but is in a different jar and classloader.  If  is protected then try making it public. The problem could exist in JAVA 1.6 and be absent in 1.5x  I got this for your problem. This happened to me when I had a class in one jar trying to access a private method in a class from another jar.  I simply changed the private method to public, recompiled and deployed, and it worked ok afterwards.\nI was getting this Issue primarily because i was using some thing that is not available/deprecated in that Android versionWrong way:Right way:here Notification.Action is not available prior to  and my min version was Just an addition to the solved answer: be a problem with Android Studio's Instant Run feature, for example, if you realized you forgot to add the line of code:  to your activity after opening another one, and you already re-opened the activity you shouldn't have reopened (which the  solved), then you add  and Instant Run occurs, then the app will crash since the logic has been broken. This is not necessarily a code problem, just an Instant Run problemI was getting this error on a Spring Boot application where a  had a nested class . It seems the  was using a different class loader. I moved the nested class  to a separate .java file and got rid of the problem."},
{"body": "How can I enable the  keyword in Eclipse?To be specific: If anyone wants to  (in contrast to enabling them for just a single run configuration), it is possible with the following steps:You need to go to run configurations and add vm arguments as \"-enableassertion\" (or) \"-ea\"After that when you run code with assert statement, you will see assert in action. Java introduced the  keyword, so the way to enable source-level support is to make sure that Eclipse's Java compliance level is 1.4 or higher.  (The chances are that the compliance level is already higher than that ...)To cause a Java application launched from Eclipsed to run with assertion checking enabled, add the \"-ea\" argument to the VM arguments in the launcher configuration's \"Arguments\" tab."},
{"body": "I am new to using JAX-RS and wrote a sample application that outputs a json object. but I am getting an exception. Here is my code:}My data is simply a POJO class:I get an exception:What am i doing wrong ?I finally found my answer. I added to my pom.xml file. Then I added to my web.xml file, and everything works fine. No change was required to my code above.I added following jars and it worked for meJust a small addition. In case if you do not use the web.xml descriptor file, you may enable the POJOMappingFeatire programatically as shown belowXML output is supported by default. So no dependency needed for it.Working with Jersey 1.8, I was getting the same error while creating a JSON object and hitting a REST API from client side.If you are facing issue at server side then, make sure that you have correctly included jersey-json.jar in classpath and mapped correct init-param in web.xml as mentioned in other answers.As per , the following snippet shows how to use the POJO JSON mapping feature on the client side:I had the same issue:\n A message body writer for Java type, class java.lang.String, and MIME media type, application/json, was not foundThe problem was that the class\njavax.ws.rs.ext.MessageBodyWriter was taken from Was colliding with the same class from:"},
{"body": " I do not really understand how the substring method works. Does the index start at 0? If I start with 0,  is at index 4 but char  is at 7 so the output would be .0: U1: n2: i3: v7: i8: t9: yStart index is inclusiveEnd index is exclusivesee , it's an inclusive index for the 1st arg and exclusive for the 2ndBoth are 0-based, but the start is inclusive and the end is exclusive. This ensures the resulting string is of length . Think of them as positions in the string rather than actual characters.Quoting the :Like you I didn't find it came naturally. I normally still have to remind myself thatso returns the 4-character string \" even though there is no character at position 10.Yes the index starts at zero (0). The two arguments are startIndex and endIndex, where per the docs:\"The substring begins at the specified beginIndex and extends to the character at index endIndex - 1\"See  for more info.For substring(startIndex, endIndex), startIndex is inclusive and endIndex are exclusive. The startIndex and endIndex are very confusing.\nI would understand substring(startIndex, length) to remember that. The Substring starts at, and includes the character at the location of the first number given and goes to but does not include the character at the last number givenThe endIndex is very confusing term. I guess the motive was to keep the length of the new string to endIndex - startIndex. But so what? I guess it was easier to remember both are inclusive, rather than remembering start is inclusive and end is exclusive. \u2014the begin index, inclusive.\u2014the end index, exclusive.Example:Output: \"lo Wo\" from 3 to 7 indexAlso there is another kind of  method.\u2014the begin index, inclusive.\nReturns a sub string starting from  to the end of the main String.example:Output: \"lo World\" from 3 to last index"},
{"body": "Is there a way to obtain the post data itself? I know spring handles binding post data to java objects. But if I had two fields that I want to process manually, how do I obtain that data?Assuming I had two fields in my formHow would I go about retrieving those values in my controller? If you are using one of the built-in controller instances, then one of the parameters to your controller method will be the Request object.  You can call  to get the Post data value.If you are using Spring MVC annotations, you can add an annotated parameter to your method's parameters:Spring MVC runs on top of the Servlet API. So, you can use  for this:The  should already be available to you inside Spring MVC as one of the method arguments of the  method.Another answer to the OP's exact question is to set the  content type to  and then declare a  input parameter. This will pass the text of the POST data in as the declared  variable ( in the following example).Of course, this presumes your POST payload is text data (as the OP stated was the case).Example:"},
{"body": "I have heard that Java must use a JIT to be fast. This makes perfect sense when comparing to interpretation, but why can't someone make an ahead-of-time compiler that generates fast Java code? I know about , but I don't think its output is typically faster than Hotspot for example.Are there things about the language that make this difficult? I think it comes down to just these things:What am I missing? If I avoid these features, would it be possible to compile Java code once to native machine code and be done?The real killer for any AOT compiler is:This means that you cannot write a AOT compiler which covers  Java programs as there is information available only at runtime about the characteristics of the program.  You can, however, do it on a subset of Java which is what I believe that gcj does.Another typical example is the ability of a JIT to inline methods like getX() directly in the calling methods if it is found that it is safe to do so, and undoing it if appropriate, even if not explicitly helped by the programmer by telling that a method is final.  The JIT can see that in the running program a given method is not overriden and is therefore in this instance can be treated as final.  This might be different in the next invocation.A JIT compiler can be faster because the machine code is being generated on the exact machine that it will also execute on.  This means that the JIT has the best possible information available to it to emit optimized code.If you pre-compile bytecode into machine code, the compiler cannot optimize for the target machine(s), only the build machine.I will paste an interesting answer given by the  in the Book .Java's JIT compiler is also lazy and adaptive.Being lazy it only compiles methods when it gets to them instead of compiling the whole program (very useful if you don't use part of a program). Class loading actually helps make the JIT faster by allowing it to ignore classes it hasn't come across yet.Being adaptive it emits a quick and dirty version of the machine code first and then only goes back and does a through job if that method is used frequently.In the end it boils down to the fact that having more information enables better optimizations. In this case, the JIT has more information about the actual machine the code is running on (as Andrew mentioned) and it also has a lot of runtime information that is not available during compilation.Java's ability to inline across virtual method boundaries and perform efficient interface dispatch requires runtime analysis before compiling - in other words it requires a JIT. Since all methods are virtual and interfaces are used \"everywhere\", it makes a big difference.In theory, a JIT compiler has an advantage over AOT . For instance, if you have an enterprise app running for days and months on a multiprocessor server with plenty of RAM, the JIT compiler  produce better code than any AOT compiler.Now, if you have a desktop app, things like fast startup and initial response time (where AOT shines) become more important, plus the computer may not have sufficient resources for the most advanced optimizations.And if you have an embedded system with scarce resources, JIT has no chance against AOT.However, the above was all theory. In practice, creating such an advanced JIT compiler is way more complicated than a decent AOT one. How about some ?JITs can identify and eliminate some conditions which can only be known at runtime. A prime example is the elimination of virtual calls modern VMs use - e.g., when the JVM finds an  or  instruction, if only one class overriding the invoked method has been loaded, the VM can actually make that virtual call static and is thus able to inline it. To a C program, on the other hand, a function pointer is always a function pointer, and a call to it can't be inlined (in the general case, anyway).Here's a situation where the JVM is able to inline a virtual call:Assuming we don't go around creating  or  instances elsewhere and that  is set to , the JVM knows that the call to  always means , and can therefore avoid the method table lookup, and then inline the call. A similar construct in a non-JITted environment would not be inlinable.I think the fact that the official Java compiler is a JIT compiler is a large part of this. How much time has been spent optimizing the JVM vs. a machine code compiler for Java?"},
{"body": "When I executing the following code: I'm facing the following error: \nCould someone help me to find the solution or reason for this?I had the same problem, and finally I found that I forgot to add the . I had only added the client jar, .Hope this helps.A  is thrown when the JRE can't find a class. In your case, it can't find the class , which you most probably did not add to your classpath.After downloading the following libraries:and unzipping them and putting all JAR files in a folder called , the test class:ran without any problems.You can compile and run the class as follows:you don't have the  library on your .There are a number of , so please provide more info regarding how you are executing your program.if from the command line, you can add libraries to the classpath via I had the same error and after the investigation i found that library selenium-api 2.41.0 requires guava 15.0 but it was overridden by an older version so i declared guava 15.0 as direct dependency by adding following configuration in pom.xml:For me, in addition to selecting the jar - selenium-java-2.45.0.jar, I had to select all the jars in the \"libs\" folder under selenium root folder.It looks like you're trying to import some google code:And it's not finding it the class Function.  Check to make sure all the required libraries are in your build path, and that you typed the package correctly.I met the same problem and fail even after installing the 'selenium-server-standalone-version.jar', I think you need to install the guava and guava-gwt jar () as well. I added all of these jar, and finally it worked in my PC. Hope it works for others meeting this issue.I had the same issue. I found that I forgot to add selenium-2.53.0/selenium-java-2.53.0-srcs.jar file to my project's Reference library.I got the same error, but it was resolved if you add the libraries of selenium (again if you haven't), if you are using INTELIJSame needs to be done for other IDE's as well, like eclipse.When I caught the exception  it was caused by errors in Project Libraries. Please check it in your project settings. For Intellij IDEA go to  and select  tab. All I needed to do to resolve this exception was re-adding the selenium libraryPlease include all the jar files of selenium stand-alone and lib folder, then this error will resolvedAfter you extract your \"selenium-java-.zip\" file you need to configure your build path from your IDE. Import all the jar files under \"lib\" folder and both selenium standalone server & Selenium java version jar files.I wanted to try a simple class outside IDE and stuff. So downloaded selenium zip from website and run the class like this:I had the issue that I initially used  instead of . I  need to add selenium standalone jar. This is Java 8 that understands wildcards in classpath. I think java 7 would also do.I had the same problem, and finally I found that I forgot to add the selenium-server-standalone-version.jar. I had only added the client jar, selenium-java-version.jar."},
{"body": "I googled a lot and read about  and  a lot, know purpose of each method, but still have a question. Is it good practice to call  method by hand? As said in  docs, Could you explain me purpose of calling  by hand if  will call it automatically?Thanks!In the Hibernate Manual you can see this exampleWithout the call to the flush method, your first-level cache would throw an OutOfMemoryException One common case for explicitly flushing is when you create a new persistent entity and you want it to have an artificial primary key generated and assigned to it, so that you can use it later on in the same transaction. In that case calling flush would result in your entity being given an id. Another case is if there are a lot of things in the 1st-level cache and you'd like to clear it out periodically (in order to reduce the amount of memory used by the cache) but you still want to commit the whole thing together. This is the case that  covers (+1 from me). will synchronize your database with the current state of object/objects held in the memory but it does not commit the transaction. So, if you get any exception after  is called, then the transaction will be rolled back.\nYou can synchronize your database with small chunks of data using  instead of committing a large data at once using  and face the risk of getting an . will make data stored in the database permanent. There is no way you can rollback your transaction once the  succeeds. Flushing is the process of synchronizing the underlying persistent store with persistable state held in memory.it will update or insert into your tables in the running transaction, but it may not commit those changes.  Commit will make the database commit.When you have a persisted object and you change a value on it, it becomes dirty and hibernate needs to flush these changes to your persistence layer.So You should commit but it also ends the unit of work.By default flush mode is AUTO which means that: \"The Session is sometimes flushed before query execution in order to ensure that queries never return stale state\", but most of the time session is flushed when you commit your changes. Manual calling of the flush method is usefull when you use FlushMode=MANUAL or you want to do some kind of optimization. But I have never done this so I can't give you practical advice.session.flush() is synchronise method means to insert data in to database sequentially.if we use this method data will not store in database but it will store in cache,if any exception will rise in middle we can handle it.\nBut commit() it will store data in database,if we are storing more amount of data then ,there may be chance to get out Of Memory Exception,As like in JDBC program in Save point topic "},
{"body": "I am aware that it is better to call the  method over using the  operator (see ). I want two strings to compare as equal if they are both null or if they represent the same string. Unfortunately the  method will throw an  if the strings are . My code is currently:This is inelegant. What is the correct way to perform this test?If Java 7+, use ; its documentation explicitly specifies that:which is what you want.If you don't, your method can be rewritten to:This works because the  contract guarantees that for any object ,  is always false.From :Very simple, self-explaining and elegant.If you can't use Java 7+ solution, but you have Guava or Commons Lang in classpath, then you can use the following:::or"},
{"body": "I have a very simple question. I am brand new to Mac and I am trying to get my Java project moved over to my new Mac. The project has a Gradlew file that I thought I could run from the command line to build and run on any machine. When I do gradlew from the command line (in the location of the gradlew file) it says gradlew not found. Am I missing something on how to run a command from a bash shell?Your directory with gradlew is not included in the PATH, so you must specify path to the gradlew.   means \"current directory\". Also, if you don't have the  file in your current directory:You can install gradle with  with the following command:As mentioned in . Then, you are not going to need to include it in your path (homebrew will take care of that) and you can just run (from any directory):"},
{"body": "I am using retrofit 2.0.0-beta1 with SimpleXml. I want the retrieve a Simple (XML) resource from a REST service.\nMarshalling/Unmarshalling the Simple object with SimpleXML works fine.When using this code (converted form pre 2.0.0 code):Service:I get this exception:What am i missing? I know that wrapping the return type by a  works. But I want the service to return business objects as type (and working in sync mode).After added the extra dependancies and  as suggested by different answers, I still get this error:Short answer: return  in your service interface.It looks like Retrofit 2.0 is trying to find a way of creating the proxy object for your service interface. It expects you to write this:However, it still wants to play nice and be flexible when you don't want to return a . To support this, it has the concept of a , which is supposed to know how to adapt a  into a .The use of  is only useful if you are trying to return .The simplest solution is to return a  as Retrofit expects. You could also write a  if you really need it.add dependencies:create your adapter this way: and  both need to be called.Service:Modify  to .With the new Retrofit(2.+) you need to add addCallAdapterFactory which can be a normal one or a RxJavaCallAdapterFactory(for Observables). I think you can add more than both too. It automatically checks which one to use. See a working example below. You can also check  for more details. Add the following dependencies for retrofit 2for GSONfor observablesIn your case for XML , you would have to include the following dependenciesUpdate the service call as below If you want use  and you don't want always return , you have to create your own  which return simple type as you expected. The simple code can look like this:Then simple register the  in Retrofit should solved your problem.After that you can return simple type without .in my case using this with this solved the problem when nothing else workedYou can implement a Callback, get the Simple from onResponse function.The way I fixed this issue was adding this to the application gradle file, if the configuration is not set there will be conflicts, maybe this will be fixed in the stable release of the library:and create your adapter this way:Hope it helps!"},
{"body": "This is referring to  ..wasnt able to reply or comment to any so created a new one. Why are my giving warnings-The static field MyUnits.MILLSECONDS should be accessed in a static way ?\nThanks.Because when you access a static field, you should do so on the class (or in this case the enum).  As inNot on an instance as in To address the question of : In Java, when you declare something as , you are saying that it is a member of the class, not the object (hence why there is only one).  Therefore it doesn't make sense to access it on the object, because that particular data member is associated with the class.There's actually a good reason: \n.Suppose we have two classes, A and B, the latter being a subclass of A, with static fields with the same name:Direct access to the static variable:Indirect access using an instance (gives a compiler warning that VALUE should be statically accessed):So far, so good, the compiler can guess which static variable to use, the one on the superclass is somehow farther away, seems somehow logical.Let's remove the static variable from B, and observe following situations:The statement  is now , as the . And that's exactly the reason why static variables should be accessed in a static way.Because ... it () is a static field (hiding in an enumeration, but that's what it is) ... however it is being invoked upon an  of the given type (but see below as this isn't  true).javac will \"accept\" that, but it should really be  (or non-prefixed in the applicable scope). Actually, javac \"rewrites\" the code to the preferred form -- if  happened to be  it would not throw an NPE at run-time -- it is never actually invoked upon the instance).Happy coding.I'm not really seeing how the question title fits in with the rest :-) More accurate and specialized titles increase the likely hood the question/answers can benefit other programmers."},
{"body": "I'm using the  (and parser) in an Android app to parse a JSON feed. Which is the best way to determine if a property exists or not in one of the objects returned?Say I have a JSON feed including \"News\". Some of the news have a property called \"UnpublishDate\" (which is the date the news in question is no longer active), while some of the news don't have this property.The best solution I've come up with (though not implemented yet) is to simply have a \"try-catch\" around the  - do you know of any better solution (that is more graceful when the class scales to several \"optional\" properties in the JSON feed)?You might use the  function :"},
{"body": "I'm using a progress bar (in bar form). I wish to make the bar increase and decrease smoothly using an interpolator, but It's not working. This is what I have at the moment:Am I doing something really wrong?The Interpolator have to be attached to an animation and this will work only on Honeycomb or higher :If your minimum SDK is Gingerbread or lower, add to your function/class.I used a DecelerateInterpolator, but this is optional and there are others possibilities.Here is a self-contained drop in solution:replace  with  in your layoutYou many also change the type to AnimatingProgressBar to utilize  to disable animation (could be useful when restoring activity state)If you change progress value each time by 1 (for example from 45 to 46) you'll not see animation. Better to change progress by 100 points, for this you just need to multiply your max value to 100 and each progress value to 100 too. For example:I worked out how to do it, by using a runnable I was able to update the progress bar several times a second and so give the sliding effect. The code is below:Here, 'track' keeps track of how many increments have been done, and increase is the total number of increments that should be done. I can dynamically increase the number of increments from the UI thread to give a smooth effect. The code only works for progress bars that won't need to decrease.To run it, simply use this code:Above link is my library.\nJust use it if you want.According to documentation interpolator applies to indeterminate progress.\nSince you set progress I think you intend to use regular one with values. \nI think the best for you would be to increase maximum value of progress and \ngo in smaller increments.I used android Animation for this:and call it like so:Note: if from and to value are too low to produce smooth animation just multiply them by a 100 or so. If you do so, don't forget to multiply setMax(..) as well.I am not sure but please check it:Bounce is probably not the best animation if you want it to look smooth. Try easein or easeout."},
{"body": "Are there named parameters in JDBC instead of positional ones, like the ,  in the ADO.NET query below?JDBC does not support named parameters. Unless you are bound to using plain JDBC (which causes pain, let me tell you that) I would suggest to use Springs Excellent JDBCTemplate which can be used without the whole IoC Container. supports named parameters, you can use them like that:To avoid including a large framework, I think a simple homemade class can do the trick.Example of class to handle named parameters:Example of calling the class:Please note that the above simple example does not handle using named parameter twice. Nor does it handle using the : sign inside quotes.Vanilla JDBC only supports named parameters in a  (e.g. ), and even then, I suspect the underlying stored procedure implementation has to support it.An example of how to use named parameters:You can't use named parameters in JDBC itself. You could try using Spring framework, as it has some extensions that allow the use of named parameters in queries.I ended up just creating my own wrapper meothod.The biggest downfall is that you have to ensure that the variable is indeed safe for binding. I now just use Spring's Hibernate, much betterPlain vanilla JDBC does not support named parameters.If you are using DB2 then using DB2 classes directly:"},
{"body": "In the work that I do on a day to day in Java, I use builders quite a lot for fluent interfaces, e.g.: With a quick-and-dirty Java approach, each method call mutates the builder instance and returns . Immutably, it involves more typing, cloning the builder first before modifying it. The build method eventually does the heavy lifting over the builder state.What's a nice way of achieving the same in Scala?If I wanted to ensure that  was called only once, and then subsequently only  and  could be called, a-la a directed builder, how would I go about approaching this?Another alternative to the Builder pattern in Scala 2.8 is to use immutable case classes with default arguments and named parameters. Its a little different but the effect is smart defaults, all values specified and things only specified once with syntax checking...The following uses Strings for the values for brevity/speed...You can then also use existing immutable instances as kinda builders too...You have three main alternatives here.It's the same exact pattern.  Scala allows for mutation and side effects.  That said, if you'd like to be more of a purest, have each method return a new instance of the object that you're constructing with the element(s) changed.  You could even put the functions within the Object of a class so that there's a higher level of separation within your code.so that your code might look like(Note: I've probably screwed up some syntax here.)Case classes solve the problem as shown in previous answers, but the resulting api is difficult to use from java when You have scala collections in your objects. To provide a fluent api to java users try this:Then in java code the api is really easy to useusing Scala partial applies are feasible if you are building a smallish object that you don't need to pass over method signatures. If any of those assumptions don't apply, I recommend using a mutable builder to build an immutable object. With this being scala you could implement the builder pattern with a case class for the object to build with a companion as the builder.Given that the end result is a constructed immutable object I don't see that it defeats any of the Scala principles.  I think scala's Stackable Modification could be used here. Check this out : \nIt works for me, but I think it is write Java for Scala compiler. I`m still learning the scala way, functionnaly way.The usage is:The structure is:"},
{"body": "I have a java project written using eclipse ide and I want to run it through ssh on a different machine, but I have to do this using the command line and I don't know exactly how.I am a beginner at both shell commands and java.Could you please give me a useful link with answers regarding this question, or perhaps a set instructions of how to do this?Maven or Ant are the best option but for an  solution\nyou can choose  and select \nthen transfer the  to your other machine and run this from the command line:Running java applications using command line is very easy.\nThe simplified syntax looks like this:where: - list of directories and/or JAR-files where needed classes reside separated by \";\" for Windows or \":\" for linux (default classpath is \".\" - the current directory); - fully qualified name of the class containig main() method (for example, org.myself.HelloWorld) - various arguments for application if any.So, if you find the directory where Eclipse stored compiled classes (usually it's bin) you may use the command, likeOr, if you use some libraries and classes in other directories, it could be:To build and run a Java project, Its good to use an ant or maven tool. you can find many tutorials on google for the same.a good tutorial on ant is here This is what I did and it worked for me. Hope it could help. \n"},
{"body": "Probably a repeat! I am using Tomcat as my server and want to know what is best way to spawn threads in the servlet with deterministic outcomes. I am running some long running updates from a servlet action and would like for the request to complete and the updates to happen in the background. Instead of adding a messaging middleware like RabbitMQ, I thought I could spawn a thread that could run in the background and finish in its own time.  I read in other SO threads that the server terminates threads spawned by the server in order for it to manage resources well. Is there a recommended way of spawning threads, background jobs when using Tomcat. I also use Spring MVC for the application. Your safest bet is using an applicaton wide  with a max amount of threads, so that the tasks will be queued whenever necessary. The  is very helpful in this.Upon application startup or servlet initialization use the  class:Then during servlet's service (you could ignore the result for the case that you aren't interested):Finally, during application's shutdown or servlet's destroy: You could maybe use a CommonJ WorkManager (JSR 237) implementation like : Just to clarify, here is what the  (looks like this is the successor of JSR-236 & JSR-237) writes about unmanaged threads:So nothing new IMO, the \"old\" problem is the same, unmanaged thread are still unmanaged threads: Spring supports asynchronous task (in your case long running) through spring-scheduling. Instead of using Java threads direct I suggest to use it with Quartz. Strictly speaking, you're not allowed to spawn threads according to the Java EE spec. I would also consider the possibility of a denial of service attack (deliberate or otherwise) if multiple requests come in at once.A middleware solution would definitely be more robust and standards-compliant.I know it is an old question, but people keep asking it, trying to do this kind of thing (explicitly spawning threads while processing a servlet request) all the time... It is a very flawed approach - for more than one reason... Simply stating that Java EE containers frown upon such practice is not enough, although generally true...Most importantly, one can never predict how many concurrent requests the servlet will be receiving at any given time. A web application, a servlet, by definition, is meant to be capable of processing multiple requests on the given endpoint at a time. If you are programming you request processing logic to explicitly launch a certain number of concurrent threads, you are risking to face an all but inevitable situation of running out of available threads and choking your application. Your task executor is always configured to work with a thread pool that is limited to a finite reasonable size. Most often, it is not larger than 10-20 (you don't want too many threads executing your logic - depending on the nature of the task, resources they compete for, the number of processors on your server, etc.) Let's say, your request handler (e.g. MVC controller method) invokes one or more @Async-annotated methods (in which case Spring abstracts the task executor and makes things easy for you) or uses the task executor explicitly. As your code executes it starts grabbing the available threads from the pool. That's fine if you are always processing one request at a time with no immediate follow-up requests. (In that case, you are probably trying to use the wrong technology to solve your problem.) However, if it is a web application that is exposed to arbitrary (or even known) clients who may be hammering the endpoint with requests, you will quickly deplete the thread pool, and the requests will start piling up, waiting for threads to be available. For that reason alone, you should realize that you may be on a wrong path - if you are considering such design. A better solution may be to  the data to be processed asynchronously (that could be a queue, or any other type of a temporary/staging data store) and return the response. Have an external, independent application or even multiple instances of it (deployed outside your web container) poll the staging endpoint(s) and process the data in the background, possibly using a finite number of concurrent threads. Not only such solution will give you the advantage of asynchronous/concurrent processing, but will also scale because you will be able to run as many instances of such poller as you need, and they can be distributed, pointing to the staging endpoint.\nHTH Since Spring 3, you can use @Async annotations:with  and  in the context filePlease refer to this tutorial: Works great for me on Tomcat7 and you don't have to managed a thread pool."},
{"body": "I want to use the binary search algorithm to search the string which has been entered by the user in a very big sorted file. I can not compare the string which has been entered by the user with the string which has been located in the middle line of the file to continue my binary search.For example, if the user's string is  and the file's string is , it is obvious that the user's string is smaller than the file's string. How is it implemented in java? it will be great if you can help me with a sample code.You can useIf  is lexicographically less than ,  will be returned,  if equal or  if  is greater. E.g., If you would like to ignore case you could use the following:Haven't you heard about the  interface being implemented by  ? If no, try to useAnd it will output a good root for a solution to your problem."},
{"body": "Findbug told me that I use incorrect lazy initialization.I don't see anything wrong here. Is it wrong behaviour of findbug, or I missed something?Findbug is referencing a potential threading issue.  In a multi thread environment, there would be potential for your singleton to be created more than once with your current code.There is a lot of reading , but it will help explain.The race condition here is on the .  On the first call, a thread will get into the , and will create the instance and assign it to 'instance'.  But there is potential for another thread to become active between the  and the instance creation/assignment.  This thread could also pass the  because the assignment hasn't happened yet.  Therefore, two (or more, if more threads got in) instances would be created, and your threads would have references to different objects.Your code is slightly more complex than needed which might be why it's confused.Edit: It's definitely the threading issue as the others posted but thought I'd post the double lock check implementation here for reference below:: JohnKlehm's double lock checking solution is better. Leaving this answer here for historical reasons.It should actually be You need to put a lock around instantiation to make this correctThanks to John Klehm for posted samplealso may try to assign object instance in sychronised block directlyi.e.You missed multi threading issue, your static object is not  synchronized. Moreover your method is not a lazy initialization. Normally what you do is you keep a Map of object,and you initialize the desired one on demand. So you do not initialize all of them at the beginning rather than calling them when it is needed(called)."},
{"body": "Actually i trying to extract code of an .apk file called cloudfilz.apk and wanted to manipulate in its source code so i followed the steps given below:-make a new folder and put .apk file (which you want to decode) now rename this .apk file with extension .zip (eg:rename from filename.apk to filename.apk.zip) and save it..now you get classes.dex files etc...at this stage you are able to see drawable but not xml and java file...so continue...step 2:now extract this zip apk file in the same folder(in this eg or case NEW FOLDER). now dowmload dex2jar from this link  and extract it to the same folder (in this case NEW FOLDER).....now open command prompt and reach to that folder (in this case NEW FOLDER)....after reaching write \"dex2jar classes.dex\" and press enter.....now you get classes.dex.dex2jar file in the same folder......=>Question:-I was successfull to achieve step 1 but in step2 when i am executing dex2jar classes.dex i am getting an error on command prompt  ,I know this is due incompability between my installed jdk version and classes.dex jdk version number so stuck here and dnt have way out...As we now know that apk file is just a zip file containing all program resource file, we can now get java code from apk files with ease. Following are steps to get java code from apk files.Above steps will generate  but to get  files perform following steps.or Visit .... It will definitely help you to extract XML and source Java files from a APK file. It worked for me.Any .apk file from market or unsignedstep 1:step 2: Download java decompiler    this is a good tutorial for both window/ubuntu.Procedure:it will become .zip.\u2013 cd \n\u2013 sh dex2jar.sh classes.dex (result of this command \u201cclasses.dex.dex2jar.jar\u201d will be in your   itself)."},
{"body": "I'm trying to build a  in eclipse using Java 8 (and Wildfly appServer if that matters) but I'm unable to make Eclipse Luna M5 use Java 8 (I do have Java 8 BETA support installed and it works on JavaSE projects). In my POM I set the level to Java 8:But after I do  I get the following error:And indeed there is no java 1.8 project facet under Can I manually create such  and add It to to eclipse or I'll have to wait until java 8 is released and the eclipse guys decide to add it ?There are additional patches available for Kepler SR2 officially.\nIn ecliplse, go to \"Help\" --> \"Market Place\" --> Search for java 8 kepler.\nThen choose and install the following.Reference: After this, my multi-module maven project with java 8 is building fine without any error in eclipse kepler SR2.: If you are using Spring Tool Suite (STS), then version 3.5.1 has included these features.There is an official bug report/patch for Kepler SR2. It also works with Spring Tool Suite 3.5.0.RC4 (which is based on Kepler). It should work for Luna too.Bug report :  (see comment #12)Update site for the Java 8 facet : While we await official Java 1.8 support, I've made a github fork that contains what I believe are the required changes - these require the Java 8 patches from here first:  To install the 1.8 facet support (assuming that you're running 4.3.1 or 4.3.2, and have write access to the main .../eclipse/plugins dir):After restarting Eclipse, you should find that 1.8 is now selectable as a Java facet :) (and it also works with M2E enabled projects that specify source/target of 1.8). Note the instruction from the standard 1.8 patch instructions that the installed JDK /must/ be called \"JavaSE-1.8\" within the Eclipse properties.Also note that if/when you update Eclipse (e.g. to upgrade to 4.3.2), you will probably need to re-install the patched version again as the update will put the \"official\" version of the plugin back in.I hit exactly the same problem a few days ago. Looks like this will be included into the next release of Eclipse Luna.Eclipse Luna M6 is scheduled for release on March 14th so hopefully it will be included then.Recently Java updated to Java 8 so you need to update to the new Eclipse for it to work. I was running Eclipse 4.3 (Kepler) and I had to upgrade to Eclipse 4.4 (Luna)Go to Your  search for  and change java version"},
{"body": "Sometimes, I'll run a program that accidentally contains an infinite loop or something. Eclipse will let me continue editing the program, but be super slow. How can I stop it? (Do I want to restart the JVM?) Restarting eclipse itself always works, but that breaks my workflow.Open the Console view, locate the console for your running app and hit the Big Red Button.Alternatively if you open the Debug perspective you will see all running apps in (by default) the top left. You can select the one that's causing you grief and once again hit the Big Red Button.For newer versions of Eclipse:I have a .bat file on my quick task bar (windows) with:It's very quick, but it may not be good in many situations!The easiest way to do this is to click on the Terminate button(red square) in the console:For Eclipse:\nmenu bar-> window -> show view then find \"debug\" option if not in list then select other ... new window will open and then search using keyword \"debug\" -> select debug from listit will added near console tab.\nuse debug tab to terminate and remove previous executions. ( right clicking on executing process will show you many option including terminate)"},
{"body": "I don't know much regex, but I need to match a simple pattern. The following should return true,when inputLine isHowever, I'm getting this exception:What am I doing wrong?The  and  are special in Java's regex dialect (and most other dialects for that matter): they are the opening and closing tokens for the repetition quantifier  where  and  are integers. Hence the error message: \"Illegal repetition\".You should escape them: .And since you seem to be trying to parse JSON, I suggest you have a look at .There should be plus operator:Double apostrophes only when the string has to contain it.When the string including curly brackets use:"},
{"body": "My Eclipse javadoc view has a black background which makes it look  and partly unreadable (e.g. links are dark blue on black). Even worse, the javadoc popup has black background, too. I can't find the corresponding setting.The answer by Sumit Singh showed me how to change the background for the javadoc view. However, I still see no way how to change the foreground. Even worse, the javadoc popup background color didn't change.I don't think it's caused by a plugin, as it happens with a fresh install, too. This happens on Ubuntu 10.4. In Windows the colors can't be changed either, but there are fine.You need to change the 'Tooltip' color in Ubuntu at the OS level.  None of the answers here worked for me (I have Eclipse Mars and Ubuntu 14.04). I had to edit . I've changed  to  and  to . After restarting eclipse, the change took effect.As a KDE user you have to change the tooltip background color with .\nNavigate to and adjust the  and  colors.On ubuntu 12.10 (quantal) you can use the following two commands:(Thanks to the other answers and  that helped me to figure this out)Install the \"GNOME Color Chooser\" in Ubuntu (worked also on Xubuntu)There you can set the Tooltip colors under the tab \"Specific\"Had same issue with Neon on Ubuntu 16.04 Mate edition.To fix it, I have created a small, user-specific GTK3 CSS settings file. \nIt is stored as you HOMEDIR/.config/gtk-3.0/gtk.cssIn my case, I compressed the spacing a bit, specified default font and also, set the appearance for the tooltip windows:Please note, this issue has been resolved in Eclipse as of 8th November 2016.\nTo have this fixed, please download one of the latest  builds: \n\n(The maintenance builds don't have the patch at the time of writing 2016-11Nov-09Wed).I wrote a patch that introduced a new preference in Eclipse \"Information Background/Text\" under General -> Appearance -> Colors and Fonts.\nThis preference generates the correct color on Linux/Gtk (White background, black text).\nSee:\nBug 505738 \u2013 Define a information hover color which JDT, CDT or others can use \nSubsequently I made Javadoc colors inherit it's color from that preference. See:\nBug 501742 \u2013 Default Javadoc text and background color should use colors consistent with Java editor background/foreground. \nAs an added bonus, it also works on the Dark Theme:\nBug 505851 \u2013 [Dark Theme] Style the HOVER_ colors for the dark theme \nAlso try this  after I installed the lib the javadoc looks so much bettersource: I think the answer here to have a properly formattet tooltip (at least for people who use ubuntu and want to have a nice hover tooltip) with html elements like links working is to install libwebkitgtk as it is used by eclipse to show javadoc. It is not preinstalled on e.g. Ubuntu and does not come with eclipse.. use:and restart eclipse to have good looking tooltips.You can change the color in\n ."},
{"body": "I'm trying to find a way to iterate through an enum's values while using generics.  Not sure how to do this or if it is possible.  The following code illustrates what I want to do. Note that the code  is not valid in the following code.Here is how I would instantiate a Filter object:The enum is defined as follows:I realize it might not make sense to copy a enum's values to a list, but I'm using a library that needs a list of values as input and won't work with enums.EDIT 2/5/2010:Most of the answers proposed are very similar and suggest doing something like this:This would work great if I can be sure that selectedOption has a non-null value.  Unfortunately, in my use case, this value is often null, as there is a  no-arg constructor as well. This means I can't do a selectedOption.getClass() without getting an NPE.  This filter class manages a list of available options which of the options is selected. When nothing is selected, selectedOption is null.The only thing I can think to solve this is to actually pass in a Class in the constructor.  So something like this:Any ideas how to do this without needing an extra Class parameter in the constructors?This is a hard problem indeed. One of the things you need to do is tell java that you are using an enum. This is by stating that you extend the Enum class for your generics. However this class doesn't have the values() function. So you have to take the class for which you can get the values.The following example should help you fix your problem:Another option is to use EnumSet:Using an unsafe cast:For completeness, JDK8 gives us a relatively clean and more concise way of achieving this without the need to use the synthethic  in Enum class:Given a simple enum:And a test client:This will print :Code can be trivially adapted to retrieve different elements or to collect in a different way. If you are sure that  of the constructor  is not null. You can use reflection. Like this.Hope this helps.The root problem is that you need to convert an array to a list, right? You can do this, by using a specific type (TimePeriod instead of T), and the following code.So use something like this:Now you can pass list into any method that wants a list.If you declare Filter asthenAnd usage is quite easy:Here below an example of a wrapper class around an Enum.\nIs a little bit weird bu is what i need :}To get the  of the generic enumeration:Note in the above method the call to the toString() method.And then define the enumeration with such a toString() method."},
{"body": "I have my class  with subclasses.I will get value of object  from parse :I try use .When I run my application without  app run success.\nWhen I run my app with  my app crash.I think problem is:  rename attribute  of my class to short . I try keep the names of the methods and attributes is constant, but  rename its:What is right way to keep names of the methods and attributes of the my one (static) class?If you dont want your class members to be obfuscated then use  annotation provided by Gson. For example:Moreover, make sure you do add proper proguard configuration for Gson library too. For example:For more info read .Thanks Waqas!I find solution for my case:Also I don't use  in my class, aboved config work fine without serialization.I also found I need to  when using Dexguard's optimise option. Without this several of my model objects failed to deserialise  If you use the  annotation like I do, you can tell ProGuard to keep any field annotated with it:To exclude your class from obfuscation, Keep the attributes of InnerClasses, keep your class and keep the class members of the class eg.For more information "},
{"body": "I need to write an application with which I can do complex queries using spring-data and mongodb. I have been starting by using the MongoRepository but struggled with complex queries to find examples or to actually understand the Syntax. I'm talking about queries like this:or the use of JSON based queries which I tried by trial and error because I don't get the syntax right. Even after reading the mongodb documentation (non-working example due to wrong syntax).After reading through all the documentation it seems that  is far better documented then . I'm referring to following documentation: Can you tell me what is more convenient and powerful to use?  or ? Are both same mature or does one of them lack more features then the other?\"Convenient\" and \"powerful to use\" are contradicting goals to some degree. Repositories are by far more convenient that the templates but the latter of course give you more fine-grained control over what to execute.As the repository programming model is available for multiple Spring Data modules you find more in-depth documentation of it in the general section of the Spring Data MongoDB .We generally recommend the following approach:For your example this would look something like this:This way you essentially get the choice: everything that just easy to declare goes into , everything that's better implemented manually goes into . The customization options are documented .This answer may be a bit delayed, but I would recommend avoiding the whole repository route. You get very little implemented methods of any great practical value. In order to make it work you run into the Java configuration nonsense which you can spend days and weeks on without much help in the documentation. Instead, go with the  route and create your own Data access layer which frees you from the configuration nightmares faced by Spring programmers.  is really the savior for engineers who are comfortable architecting their own classes and interactions since there is lot of flexibility. The structure can be something like this:"},
{"body": "I ran the following code in my Android appIn  (Lollipop), it  throw any exception as  is an integer. But in  (KitKat) and lower versions it throws:How is the version of Android causing this difference?Support for explicit  was added in :which has been included starting with . If you have fetched the Git repository, you can verify with:which gives youEven though documentation can give insights into  the change was made (to achieve Java 7 behavior as other answers point out), analyzing the history of the source code gives the most accurate answer to  the behavior changed, since documentation does not necessarily match implementation.This behaviour is actually part of Java 7, as the  state: , in Java 6 only the  symbol was accepted. The Android SDK 21+ has JDK7 dependencies, which is presumably why you are experiencing this behaviour. It works after Java 7.Android 5 introduces the new parseInt feature like the Java 7 version - So this means that your Lollipop uses a newer sdk based on Java 7  which has the parseInt method with the sign handling part too. KitKat did introduce  into Android sdk 19, but not the new parseInt. Lower versions use an earlier implementation of parseInt (Java 6's version) so they will obviously fail as well.The difference between parseInt implementations : \n  vs This is a Java-specific issue. As you see in the documentation,  allows  and  allows  or . With Android Version 19 (KitKat) Java 7 is supported, so you don't get this error. I recommend not to use , because you only need a sign if you have a negative integer."},
{"body": "I am trying to make a Java tool that will scan the structure of a Java application and provide some meaningful information.   To do this, I need to be able to scan all of the .class files from the project location (JAR/WAR or just a folder) and use reflection to read about their methods.   This is proving to be near impossible.I can find a lot of solutions based on URLClassloader that allow me to load specific classes from a directory/archive, but none that will allow me to load classes without having any information about the class name or package structure.EDIT:\nI think I phrased this poorly.  My issue is not that I can't get all of the class files, I can do that with recursion etc. and locate them properly.  My issue is obtaining a Class object for each class file.   The following code loads all classes from a JAR file. It does not need to know anything about the classes. The names of the classes are extracted from the JarEntry.edit:As suggested in the comments above, javassist would also be a possibility. \nInitialize a ClassPool somewhere before the while loop form the code above, and instead of loading the class with the class loader, you could create a CtClass object:From the ctClass, you can get all methods, fields, nested classes, ....\nTake a look at the javassist api:\nList All the classes inside jar file.Scanning all of the files in a folder is simple.  One option is to call  on the  that denotes the folder, then iterate the resulting array.  To traverse trees of nested folders, use recursion.Scanning the files of a JAR file can be done using the  API ... and you don't need to recurse to traverse nested \"folders\".Neither of these is particularly complicated.  Just read the javadoc and start coding."},
{"body": "Following my previous question, , I decided to use just a single DAO for my data layer (at least at the beginning) in an application using JPA/Hibernate, Spring and Wicket. The use of generic CRUD methods was proposed, but I'm not very sure how to implement this using JPA. Could you please give me an example or share a link regarding this?Here is an example interface:And an implementation:Based on the article  we used this kind of technique for many years. We always struggled with problems with our patterns after we realized that we made a big mistake.By using an ORM tool such as Hibernate or JPA you will not have to think DAO and Service layer separately. You can use EntityManager from your service classes as you know the lifecycle of transactions and the logic of your entity classes there.Do you save any minute if you call  instead of simply ? No. You will have an unnecessary dao class that does nothing else but will be a wrapper around EntityManager. Do not afraid to write selects in your service classes with the help of EntityManager (or session in hibernate).One more note: You should define the borders of your service layer and do not let programmers to return or wait for Entity classes. The UI or WS layer programmers should not know at all about entity classes only about DTO-s. Entity objects have lifecycles that most of the programmers do not know about. You will have really serious issues if you store an entity object in a session data and try to update it back to the database seconds or hours later. Well you may would not do it but a programmer of the UI who knows the parameter types and return types of your service layer only would do to save some lines of code.I was looking for this same thing.  I found what appears to be exactly that- the  JPA project provided by SpringSource.  This is a code port from  and has now (Early 2011) been swallowed by Spring and better integrated.\nIt allows you to use a single dao (SimpleJpaRepository) with a static create, or extend the base JpaRepository class to create any object specific dao with ready made CRUD+ methods.  Also allows grails like queries just by using params names as the name of the method- in the interface (no implementation required!) i.e. \nLooks very promising- being part of Spring projects will certainly ensure some future for it too.\nI have begun implementing this in my upcoming project now.if you are looking for a third party implementation , you can check \n . it is a nnotation based generic DAO framework which supports JPA and hibernateYou may also have a look at The related code can be found on github It has integration with Spring and configuration examples for Hibernate and EclipseLink"},
{"body": "What is the difference between Java exception handling and using  conditions?It's known that Assert is of two types. But when should we use  keyword?Use assertions for internal logic checks within your code, and normal exceptions for error conditions outside your immediate code's control.Don't forget that assertions can be turned on and off - if you care about things like argument validation, that should be explicit using exceptions. (You could, however, choose to perform argument validation on  methods using assertions, on the grounds that a violation at that point is due to an internal bug rather than an external error.)Alternatively it's entire reasonable (IMO) to use exceptions for everything. I personally don't use assertions much at all, but it's a matter of personal preference to some extent. (There can certainly be objective arguments for and against assertions, but it's not sufficiently clear cut to remove preference altogether.)Java assertions are built on top of Java exceptions and exception handling.  Indeed, when a Java assertion fails, the result is an AssertionError exception that can be caught like any other Java exception. The key differences between exceptions and assertions are:Note: some people say that you should  run production code with assertion checking turned off.  I tend to disagree with this as a blanket statement.  If your production code is known to be stable AND you need to squeeze that last bit of performance out of it, then turning off assertions is good.  But, if a (say) 10% performance hit is not a real problem, I'd prefer to have an application die with an assertion error if the alternative is continue and corrupt my database.@Mario Orteg\u00f3n commented thus:Whether or not you think it is  to turn off assertions in production, it is definitely  to write assertions that have a significant impact on performance when enabled.  Why?  Because it means that you no longer have the option of enabling assertions in production (to trace a problem) or in your stress / capacity testing.  In my opinion, if you need to do  pre/post-condition testing, you should do it in your unit tests. Exception is a mechanism of checking if the implementation is executing without any expected or unexpected errors or not. So, we see that exceptions are basically used for handling even the unforseen conditions during the execution of an application in a better way and hence using exceptions effectively results into a robust application.Assertions should never be a part of the implementation of some functionality of the application. They should only be used to verify the assumptions - just to be sure that whatever we assumed while desinging the solution is actually valid in practical as well.reference: Example of a good use of Assert:I personally think that Assert should  be used when you know something is outside  limits, but you can be sure it's reasonably safe to continue. In all other circumstances (feel free point out circumstances I haven't thought of) use exceptions to fail hard and fast.The key tradeoff for me is whether you want to bring down a live/production system with an Exception to avoid corruption and make troubleshooting easier, or whether you have encountered a situation that should never be allowed to continue unnoticed in test/debug versions but could be allowed to continue in production (logging a warning of course).cf.  see also my c# copy of this answer: Assertions are very similar to exceptions, in fact just like exceptions they will flag a problem, but unlike exceptions - they won\u2019t suggest any alternative execution path, but will simply fail.\nWhy use assertions, if you can do the same thing, plus more with exceptions ?Use them when the problems should not be fixed, and actually SHOULD NEVER HAPPEN IN THE FIRST PLACE.   This sounds weird at first: don\u2019t we want to safeguard our code from ALL potential problems ?   Usually yes.   But there is a case where we don\u2019t.   This case is called: \u201cDesign by contract\u201d.Let say you are writing an application for a bank.  As a developer you can not possibly support all possible financial conditions.  So before starting to code, you get a spec from the bank which gives you the valid ranges that this application should support.   So your application is designed by a contract (by the spec from the bank).    This contract will define the fundamental principles that should always be true in order for your application to work.   These fundamental principles are called \u201cinvariants\u201d (because they can\u2019t change).  Design by contract simplifies your life as a developer - you are only responsible to support the scope of work defined in the contract.\nIts important to check the values of these invariants in your code, but you shouldn\u2019t check them as if they are exceptions and try to work around them.   If they are wrong - you must fail because the inputs have not fulfilled their contractual obligations.The interesting thing is: if you don\u2019t put an assertion into the critical place and invariants become invalid - your code will fail anyway.  You just won\u2019t know why.   So to summarize - assertions are used for verifying the invariants.  They go hand-in-hand with the \u201cdesign by contract\u201d principle.  Use them to debug a problem, thats why they are turned off in production.Another use case: if you are relying on an external library that you don\u2019t completely trust - you may want to use assert statements when calling it.Some also use assertions as a quick and dirty substitute for an exception (since its so easy to do), but conceptually that is not the proper thing to do.Assert is for debugging purpose only and its trigger condition should not happen (null pointer when there shouldn't be, etc.)Exception is for special system events that may always happen : FileNotFound, ConnectionToServerLost, etc.Assertion is used for debugging of the required assumptions to be checked at runtime only by enabling the assert feature while exception is to check the specific conditions to be checked during execution of the program to prevent the program from terminating.  "},
{"body": "I occasionally use a  instance variable in cases where I have two threads reading from / writing to it and don't want the overhead (or potential deadlock risk) of taking out a lock; for example a timer thread periodically updating an int ID that is exposed as a getter on some class:My question: Given that the JLS only guarantees that 32-bit reads will be atomic is there any point in  using a volatile long? (i.e. 64-bit).: Please do not reply saying that using  over  is a case of pre-optimisation; I am well aware of how / when to use  but there are cases where  is preferable.  For example, when defining a Spring bean for use in a single-threaded application I tend to favour  instance variables, as there is no guarantee that the Spring context will initialise each bean's properties in the main thread.Not sure if I understand your question correctly, but the  states:and, perhaps more importantly,  :That is, the \"entire\" variable is protected by the volatile modifier, not just the two parts. This tempts me to claim that it's  to use volatile for s than it is for s since  is atomic for non-volatile longs/doubles.This can be demonstrated by exampleCodeOutputNote this only happens for me when running on a 32 bit VM, on 64 bit VM I couldn't get a single error in several minutes.\"volatile\" serves multiple purposes:Is there more?"},
{"body": "Is there a way to get the parameters of a running JVM? Is there a command line tool like jstat which takes as input the pid of the JVM and returns its starting parameters? I am particularly interested in the -Xmx and -Xms values that were given when starting the JVM. Thank you.: To clarify my constraints. The JVM we would like to check is running on a production server. That's why, we prefer the minimum disruption. We are able to monitor the JVM using jstat, and so we hope there's a similar simple solution to access the parameters.: We also tried to get the parameters using jvisualvm. But in order to connect to a remote jvm, we need to run jstatd and modify the security settings of the JVM, which we found to be very disruptive and risky on a production server.You can use jps likeprints something likeAlternatively, you can use On Linux:On Mac OSX:On Windows:Source: JConsole can do it. Also you can use a powerful jvisualVM tool, which also is included in JDK since 1.6.0.8.If you can do this in java, try:You can use the JConsole command (or any other JMX client) to access that information.This technique applies for any java application running local or remote.jvisualvm can be found in any JDK since JDK 6 Update 7.  Video tutorial on jvisualvm is "},
{"body": "I have an object of type X which I want to convert into byte array before sending it to store in S3. Can anybody tell me how to do this? I appreciate your help.What you want to do is called \"\". There are several ways of doing it, but if you don't need anything fancy I think using the  would do just fine. Perhaps you could use something like this?There are several improvements to this that can be done. Not in the least the fact that you can only read/write one object per byte array, which might or might not be what you want. Note that \"Only objects that support the  interface can be written to streams\" (see ).Since you might run into it, the continuous allocation and resizing of the  might turn out to be quite the bottle neck. Depending on your threading model you might want to consider reusing some of the objects.For serialization of objects that do not implement the  interface you either need to write your own serializer, for example using the read*/write* methods of  and the get*/put* methods of  perhaps together with reflection, or pull in a third party dependency. has a list and performance comparison of some serialization frameworks. Looking at the APIs it seems  might fit what you need.As i've mentioned in other, similar questions, you may want to consider compressing the data as the default java serialization is a bit verbose.  you do this by putting a GZIPInput/OutputStream between the Object streams and the Byte streams.Yeah. Just use . You have to have each object use  but it's straightforward from there.Your other option, if you want to avoid implementing the Serializable interface, is to use reflection and read and write data to/from a buffer using a process this one below:.Use  and  methods in  from .To convert the  use the  concept of .The complete  explained in is tutorial. "},
{"body": "I wrote a servlet in Java and I would like to know if the request to that servlet was executed using HTTP or HTTPS.I thought I can use  but it returns HTTP/1.1 on both methods.Any ideas? is the answer. The ServletContainer is responsible for returning true in the following cases:The Container should also make this request attributes available when the request is received on :You can't reliably depend on port numbers.\nBut you can depend on the scheme:  Use:  to see if it is .  If it is then it is secure connection.  I believe this should work regardless of Tomcat version.  Be sure to check the inherited methods.https and http runs on different ports. So you can get the port from the request and know from which port the request came and so that you can know the protocol.\n    int port=request.getServerPort();"},
{"body": "I want to merge many PDF files into one using  and this is what I've done:Where  is an  containing all the PDF files.When I'm running the above, I'm always getting:Am I doing something wrong?  Is there any other way of doing it?Why not use the  of pdfbox?A quick Google search returned this bug: .It looks like you need to keep the PDFs to be merged open, until after you have saved and closed the combined PDF.This is a ready to use code, merging four pdf files with itext.jar from , more on If you want to combine two files where one overlays the other (example:  document A is a template and document B has the text you want to put on the template), this works:after creating \"doc\", you want to write your template (templateFile) on top of that -"},
{"body": "I want to use Mockito to test the (simplified) code below. I don't know how to tell Mockito to fail the first time, then succeed the second time.I can setup the success test with:And the failure test with:But how can I test that if it fails once (or twice) then succeeds, it's fine?From :So in your case, you'd want:The shortest way to write what you want isWhen you supply mutiple arguments to  like this, each argument will be used at most once, except for the very last argument, which is used as many times as necessary.  For example, in this case, if you make the call 4 times, you'll get \"Success\", \"you failed\", \"you failed\", \"you failed\".Since the comment that relates to this is hard to read.  I'll add a formatted answer.If you are trying to do this with a void function.  Where you might want an exception than no behavior.  Then you would do something like this:"},
{"body": "What is \"runnable\" in Java, in layman's terms? I am an AP programming student in high school, whose assignment is to do research, or seek out from others what \"runnable\" is (we are just getting into OOP, and haven't touched threads yet).A Runnable is basically a type of class (Runnable is an Interface) that can be put into a thread, describing what the thread is supposed to do.The  requires of the class to implement the method  like so:And then use it like this:If you did not have the  interface, the Thread class, which is responsible to execute your stuff in the other thread, would not have the promise to find a  method in your class, so you could get errors. That is why you need to implement the interface.Note that you do not need to define a class as usual, you can do all of that inline:This is similar to the above, only you don't create another named class. is an interface defined as so:To make a class which uses it, just define the class as It can be used without even making a new Thread. It's basically your basic interface with a single method, run, that can be called. If you make a new Thread with runnable as it's parameter, it will call the run method in a new Thread. It should also be noted that Threads implement , and that is called when the new Thread is made (in the new thread). The default implementation just calls whatever Runnable you handed in the constructor, which is why you can just do  without overriding Thread's  method. "},
{"body": "I have rather simple HttpClient 4 code that calls HttpGet to get HTML output. The HTML returns with scripts and image locations all set to local (e.g. ) so I need calling URL to make these into absolute () Now comes the problem - during the call there may be one or two 302 redirects so the original URL is no longer reflects the location of HTML. How do I get the latest URL of the returned content given all the redirects I may (or may not) have?I looked at  and  - couldn't find anything.Edited:  returns original calling addressThat would be the current URL, which you can get by calling EDIT: You didn't mention how you are doing redirect. That works for us because we handle the 302 ourselves.Sounds like you are using DefaultRedirectHandler. We used to do that. It's kind of tricky to get the current URL. You need to use your own context. Here are the relevant code snippets,The default redirect didn't work for us so we changed but I forgot what was the problem.In HttpClient 4, if you are using  or any subclass of , this is the recommended way (see source code of ) :Since HttpClient 4.3.x, the above code can be simplified as:An IMHO improved way based upon ZZ Coder's solution is to use a ResponseInterceptor to simply track the last redirect location. That way you don't lose information e.g. after an hashtag. Without the response interceptor you lose the hashtag. Example: use it just like ZZ Coder's solution: I think easier way to find last URL is to use DefaultRedirectHandler.Code to use this handler:  In version 2.3 Android still do not support following redirect (HTTP code 302). I just read location header and download again:No circular redirects protection here so be careful. More on by blog I found this on This is how I managed to get the redirect URL:Or, if you are sure that there is only one redirect location, do this:"},
{"body": "What is the difference between return 0, return 1 and return -1 in compareTo() in java?..From the reference docs of :In short:returns where the implementation of this method determines the actual semantics of   and  (I don't mean  in the sense of java's object identity operator)will yield something smaller than 0 as  is alphabetically before .will yield something larger than 0 because 2 is larger than 1. It is good practice for a class that implements Comparable to declare the semantics of it's compareTo() method in the javadocs. you should read at least one of the following: you should never rely on the return values of compareTo being ,  and . You should always test for , , , respectively.I use this mnemonic :You keep the signs and always compare the result of  to 0Answer in short: (search your situation)take example if we want to compare \"a\" and \"b\", i.e (\"a\" == this)It can be used for sorting, and 0 means \"equal\" while -1, and 1 means \"less\" and \"more (greater)\".Any return value that is less than 0 means that left operand is lesser, and if value is bigger than 0 then left operand is bigger.The  method returns an int with the following characteristics:"},
{"body": "The following is a simple loop in C++. The timer is using QueryPerformanceCounter() and is quite accurate. I found Java to take 60% of the time C++ takes and this can't be?! What am I doing wrong here? Even strict aliasing (which is not included in the code here) doesn't help at all...This C++ runs through in about 9.5 seconds. I am using the Intel Compiler 12.1 with host processor optimization (specifically for mine) and everything maxed. So this is Intel Compiler at its best! Auto-Parallelization funnily consumes 70% CPU instead of 25% but doesn't get the job done any faster ;)...Now I use the following Java code for comparison:The Java code is invoked with aggressive optimization and the server VM (no debug). It runs in about 7 seconds on my machine (only uses one thread).Is this a failure of the Intel Compiler or am I just too dumb again?[EDIT]: Ok now heres the thing... Seems more like a bug in the Intel compiler ^^. \n[Please note that I am running on the Intel Quadcore Q6600, which is rather old. And it might be that the Intel Compiler performs way better on recent CPUs, like Core i7][EDIT]: Another nice case ;). Consider the following trivial lambda expressionIntel compiler shines again:Uhm?! Well, I guess 90 times slower is not a bad thing...I am not really sure anymore that this applies:\n Here is the x64 output of the Intel Compiler:And this one is the assembly of the MSVC x64 build:Intel Compiler configured without Vectorization, 64-Bit, highest optimizations (this is surprisingly slow, 12 seconds):Intel Compiler without vectorization, 32-Bit and highest optimization (this one clearly is the winner now, runs in about 3 seconds and the assembly looks much better):tl;dr: What you're seeing here seems to be .Here's the critical loop:What you see here is the standard loop unrolling by the compiler. MSVC is unrolling to 4 iterations, and splitting the  variable across four registers: , , , and . Then at the end of the loop, these 4 registers are summed up back together.Here's where the 4 sums are recombined:What you're seeing here is an attempt by ICC to vectorize this loop. This is done in a similar manner as what MSVC did (splitting into multiple sums), but using SSE registers instead and with two sums per register.If we walk these instructions down one-by-one, we can see how ICC tries to vectorize it:So it's doing some very messy unpacking just to vectorize. The mess comes from needing to sign-extend the 32-bit integers to 64-bit using only SSE instructions.SSE4.1 actually provides the  instruction for this purpose. But either the target machine doesn't support SSE4.1, or ICC isn't smart enough to use it in this case.But the point is:You changed the data-type to . So now it's floating-point. There's no more of that ugly sign-fill shifts that were plaguing the integer version.Not much here - standard vectorization + 4x loop-unrolling.No vectorization + only 2x loop-unrolling.All things equal, disabling vectorization will hurt performance in this floating-point case.The example is simple enough that the different languages should not make a difference, and stupid enough not to prove anything. The loop could be optimised away by a compiler into a simple assignment, or left running for the whole number of iterations, or some of the iterations might be unrolled... I am not sure why you decided to write that test program, but it does not test anything regarding the languages, as once the logic optimisations are performed it all boils down to exactly the same assembly.Also, regarding the performance of the intel compiler, it will greatly depend on the exact hardware and the compiler version. The compiler generates different versions of the code, and has a tendency to generate horrible code for AMD processors. Even for intel, if it does not recognise the specific processor it falls back into a safe slow mode.You've got some data in one hand, and an assumption (C++ is always faster than Java) in the other.  Why ask for people to justify your assumption when the data tells you otherwise?If you wish to obtain assembly from the JVM in order to compare what's being run then the commandline option is '-XX:+PrintOptoAssembly', but you'll need to download a debug jvm in order to do so.  Looking at the assembly would at least tell you why one is faster than the other.Just for the record, I ran both codes on my box (x86_64 linux), the C++ with , a plain  and, for completeness also with  instead of . Java (open-jdk 1.6) clocked it at 3.8s, C++ (int) at 3.37s, and C++ (long) at 3.9s. My compiler was g++ 4.5.1. Maybe it's just Intel's compiler that's not as good as thought.I think Java compiler implements JITC (Just in time compilation, or some more recent technology) to approach native compilers speed, and could infer that your array doesn't change, and thus could apply constant folding to the inner loop...I suspect the culprit is simple loop unrolling.  Replacewithand observe how much faster the C++ version runs.i see you are running the following looptwice in the Java code; while once in the c++ code;\nthis might bring a caches warmup which makes the Java code finally execute faster than the C++."},
{"body": "I have learned that the JNI interface pointer (JNIEnv *) is only valid in the current thread. Suppose I started a new thread inside a native method; how it can asynchronously send events to a Java method? As this new thread can't have a reference of (JNIEnv *). Storing a global variable for (JNIEnv *) apparently will not work?This is how I've used it in the past, see my Since the callback is on another thread the VM context must be attached to the current thread. Once attached the method can be called.You can obtain a pointer to the JVM () with . You can safely store that pointer as a global variable. Later, in the new thread, you can either use  to attach the new thread to the JVM if you created it in C/C++ or simply  if you created the thread in java code which I do not assume since JNI would pass you a  then and you wouldn't have this problem."},
{"body": "Here is the question: write a method that swaps two variables. These two variables should be primitives. It doesn't need to be generic e.g. two  variables. Is there a way?!Without using an array or objects, no, it is not possible to do it within a method.While it is not possible to write a function that simply swaps two variables, it is possible to write a  that allows you to:That's how you could do it:This works because the Java language guarantees (Java Language Specification, Java SE 7 Edition, section 15.12.4.2) that all arguments are evaluated from left to right (unlike some other languages, where the order of evaluation is undefined), so the execution order is:If  is too long, you can choose a shorter name to make code more compact (e.g. ). Use this to impress your friends and confuse your enemies :-)Check out this JavaWorld article that explains it in detail:A swap of two primitives will never work because primitives are passed by value in Java. You can't even write a method to swap two objects for that matter.  Like @Thomas said, the only thing you could do is have your primitives contained within other objects/arrays and modify those.You can make a generic version of @marcus's swap method that swaps any number of objects of the same type:The AtomicInteger class (and others) have  atomic methods ..To write a swap method that swaps primitives you'd have to have the concept of \"out\" variables, i.e. variables whose values are passed up to the calling context. C# has those but you must still specify that they're out variables.One-liner for any primitive numbers:This function will swap two intsHere's a method that swaps two primitive variablesIt might not be of much use though ;)Ok seriously, it could be done if the variables are class level:Again though, I fail to see what the use of this could beI have read the above answers seeking an explanation as to why it is said that a swapping program cannot be written in java in the way it is written in c++.\n I did the following way\nAs Thomas Owens said. You could probably do it in C by passing variables by &reference, but afaik not in Java without using objects.Yes it is possible to swap two variable using a method.\n .\nHere is an example that illustrates swapping of two variable using a method.public class Swapping{}By compiling the above code the output comes as follows:Before swappingA= AppleB= BatAfter swappingA= BatB= Apple//In case of call by reference original value is changed if we made changes in the called method"},
{"body": "I've created a  and it only has two buttons  .After  pops out , I want to click  to continue opening the  and if I clicked  it should cancel the operation.It seems pretty easy but I'm not sure where is my mistake.Code Snippet:You need to look at the return value of the call to .  I.E.:You were testing against , which you were using to set the buttons that should be displayed by the dialog, and this variable was never updated - so  would never have been anything other than .Per the Javadoc for :Try this,First Take Result (Value) of  to integer variable as it always gives integer result and then compare that variable with  that is Yes or NO, in your case written as.IF you want Help on MessageDialogues or any.... visit link below it will help you.\n"},
{"body": "Is there any overhead in Java for using a  block, as opposed to an  (assuming that the enclosed code otherwise does not request so)?For example, take the following two simple implementations of a \"safe trim\" method for strings:If the  input is only rarely ,  between the two methods?Furthermore,  to use the  approach for simplifying the layout of code, especially when many  checking rare error conditions can be avoided by enclosing the code in one try/catch block?For example, it is a common case to have a method with , which uses  of them near its start, failing quickly and deterministically if any such parameter is \"invalid\" (e.g., a null or empty string), without affecting the rest of the code.In such cases, instead of having to write   (where  is the average number of checks per parameter, e.g.  for null or empty strings), a  block would significantly shorten the code and a 1-2 line comment could be used to explicitly note the \"unconventional\" logic.Such a pattern would also speed up the method, especially if the error conditions occur rarely, and it would do so without compromising program safety (assuming that the error conditions are \"normal\", e.g. as in a string processing method where null or empty values are acceptable, albeit seldom in presence).I know you're asking about performance overhead, but you really should not use / and  interchangeably./ is for things that go wrong that are outside of your control and not in the normal program flow.  For example, trying to write to a file and the file system is full?  That situation should typically be handled with /. statements should be normal flow and ordinary error checking.  So, for example, user fails to populate a required input field?  Use  for that, not /.It seems to me that your example code strongly suggests that the correct approach there is an  statement and not a /.To answer your question, I would surmise that there is generally more overhead in a / than an .  To know for sure, get a Java profiler and find out for the specific code you care about.  It's possible that the answer may vary depending on the situation.This question has almost been \"answered to death\", but I think there are a few more points that could usefully be made: There are also issues with the way that you've written the example:... and most of the points in my answer are not about null values!Yes there are situations where  values are expected, and you need deal with them.But I would argue that what  is doing is (typically) the wrong way to deal with .  Compare these three bits of code:Ultimately you have to deal with the  differently from a regular string, and it is  a good idea do this as soon as possible.  The further the  is allowed to propagate from its point origin, the more likely it is that the programmer will  that a  value is a possibility, and write buggy code that assumes a non-null value.  And forgetting that an HTTP request parameter could be missing (i.e. ) is a classic case where this happens.I'm not saying that  is inherently bad.  But the fact that a programmer feels the need write methods like this is  indicative of less than ideal null handling. Use the second version. Never use exceptions for control flow when other alternatives are available, as that is not what they are there for. Exceptions are for exceptional circumstances. While on the topic, do not catch  here, and especially do not swallow it. In your case, you would expect a . If you were to catch something, that is what you would catch (). When you catch (and swallow!) , you are saying \"no matter what goes wrong, I can handle it. I don't care what it is.\" Your program might be in an irrevocable state! Only catch what you are prepared to deal with, let everything else propogate to a layer that  deal with it, even if that layer is the top layer and all it does is log the exception and then hit the eject switch.Otherwise exceptions are fast to throw and catch (though an  is probably still faster), but the slow thing is creating the exception's stack trace, because it needs to walk through all of the current stack. (In general it's bad to use exceptions for control flow, but when that really is needed and the exceptions must be fast, it's possible to skip building the stack trace by overriding the  method, or to save one exception instance and throw it repeatedly instead of always creating a new exception instance.)As far as overhead goes, you can test for yourself:}The numbers I got are:As far as what style - it is a whole separate question. The if statement looks pretty natural, but the try looks  really strange for multiple reason:\n- you caught Exception even though you are checking for NULL value, are you expecting something \"exceptional\" to happen (otherwise catch NullException)?\n- you caught that Exception, are you going to report it or swallow?\netc. etc. etc. Edit: See my comment for why this is an invalid test, but I really didn't want to leave this standing here. Just by swapping tryTrim and ifTrim, we suddenly get the following results (on my machine):Instead of starting to explain all of this, just read  for the beginning - Cliff also has some great slides about the whole topic, but I can't find the link at the moment.Knowing how exception handling works in Hotspot, I'm fairly certain that in a correct test try/catch without an exception) would be the baseline performance (because there's no overhead whatsoever), but the JIT can play some tricks with Nullpointer checks followed by method invocations (no explicit check, but catch the hw exception if the object is null) in which case we'd get the same result. \nAlso don't forget: We're talking about the difference of one easily predictable if which would be ONE CPU cycle! The trim call will cost a million times that."},
{"body": "I have a long text in one of the strings at strings.xml. I want to make bold and change the color of some words in that text.How can I do it?thanks in advanceYou could basically use html tags in your string resource like: And use Html.fromHtml or use spannable, check the link I posted. Old similar question: "},
{"body": "What is the correct way to invoke stored procedures using modern day (circa 2012) Spring JDBC Template?Say, I have a stored procedure that declares both  and  parameters, something like this:I have come across  based approaches where we have to explicitly register  and  parameters. Consider the following method in  class:Of course, I do know that I can use it like so:What is the purpose of  when I am already registering them in my  implementation? In other words, why would I need to pass in a  when spring can simply do  internally? Basically, can't I pass in either one of them instead of both of them?Or, is there a much better way to call stored procedures (using Spring JDBC Template) than what I have come across so far? You may find many questions that appear to have a similar title but they are not the same as this one.There are a number of ways to call stored procedures in Spring.If you use  to declare parameters, you will be using Java's standard interface of , i.e register out parameters and set them separately. Using  abstraction will make your code cleaner.I recommend you looking at . It may be used like this:For simple procedures you may use 's  method:I generally prefer to extend Spring based  class to execute stored procedures.Hope this helps you.Here are the ways to call the stored procedures from javaHere we externally manage the resource closingOne more way to call stored procedure is:In this example 'ClientInvestigateDTO' is the POJO class and 'ClientInvestigateMapper' is the mapper class.'client' stores all the result you get on calling the stored procedure."},
{"body": "Is it no option to exclude some tests in IntelliJ IDEA Ultimate? I want to run unit tests in IntelliJ but exclude the integration tests. I name the integration tests with  so the Maven failsafe plugin can run them seperatly from the unit tests.In the  Run configuration set the  to , specify the following regular expression as the pattern:It matches against the class name, so you don't need to match  extension. Regular expression will not match if the class name ends with  using the .I would split them to that they are in different packages. They are doing different things after all. You can then run your tests per package.  link details how to do this."},
{"body": "Is there a Maven 2 archetype for a simple Servlet (2.5) web application? There  an archetype for :This will generate the following structure:Where the web.xml is a Servlet 2.3 web.xml:For a Servlet 2.5 web application, replace it with something like this:I don't know for NetBeans but Eclipse (more precisely M2Eclipse) relies on the  to set the project facets (so you need to change the  before the import, Eclipse won't update the web facet if you change the  after the facts).I have created simple archetype for creating Servlet 3 based webapps: Just clone it, install and generate project that uses Servlet 3, no XML, Tomcat7 ready (plugin included)you can start with For a list of other archetypes,please refere to \nUpdated archetype number.Refer this link  and follow this link for .Frequently used archetype numbers are:OR just use below handy maven command-command:\nmvn archetype:create -DgroupId=com.lei.webapp.quickstart  -DartifactId=webapp-quick-start   -DarchetypeArtifactId=maven-archetype-webapp I let the IDE (mine is Intellij IDEA) create the basic webapp structure for me.Go to:This will give the basic webapp structure."},
{"body": "MySQL has a handy function:This can be used to create simple, but very specific, name based locks for an application. However, it requires a database connection.I have many situations like:It doesn't make sense to simply synchronize this method, because, for example, if this method is called for user B in the meantime, user B does not need to wait for user A to finish before it starts, only operations for the user A and feature X combination need to wait.With the MySql lock I could do something like:Since Java locking is based on objects, it seems like I would need to create a new object to represent the situation for this lock and then put it in a static cache somewhere so all the threads can see it. Subsequent requests to lock for that situation would then locate the lock object in the cache and acquire its lock. I tried to create something like this, but then the lock cache itself needs synchronization. Also, it is difficult to detect when a lock object is no longer being used so that it can be removed from the cache.I have looked at the Java concurrent packages, but nothing stands out as being able to handle something like this. Is there an easy way to implement this, or am I looking at this from the wrong perspective?To clarify, I am not looking to create a predefined pool of locks ahead of time, I would like to create them on demand. Some pseudo code for what I am thinking is:maybe this is useful for you: Edit:My initial response was probably a bit short. I am the author and was faced with this problem several times and could not find an existing solution. That's why I made this small library on Google Code.All those answers I see are way too complicated. Why not simply use:The key point is the method : it ensures that the String returned is a global unique object, and so it can be used as a vm-instance-wide mutex. All interned Strings are held in a global pool, so that's your static cache you were talking about in your original question. Don't worry about memleaks; those strings will be gc'ed if no other thread references it. Note however, that up to and including Java6 this pool is kept in PermGen space instead of the heap, so you might have to increase it.There's a problem though if some other code in your vm locks on the same string for completely different reasons, but a) this is very unlikely, and b) you can get around it by introducing namespaces, e.g. Can you have a ? Each time you require a lock, you basically call .Here's an example using :Then  will cause a new lock to be created  and returned to you. You can then call  on that lock.  returns a Map that is thread-safe, so you can just share that with all your threads.For locking on something like a user name, in-memory s in a map might be a bit leaky. As an alternative, you could look at using s with  to create mutex objects that can be garbage collected when nothing refers to them. This avoids you having to do any manual reference counting to free up memory.You can find an implementation . Note that if you're doing frequent lookups on the map you may run into contention issues acquiring the mutex.A generic solution using java.util.concurrentBased on the  and his class , I have written the generic class  that uses  to store lock objects.  can be used to retrieve a lock object for a key, which can then be used with the Java  statement to apply a lock. Unused lock objects are automatically freed during garbage collection.Example of how to use the LockMap class:A simple test program for the LockMap class:If anyone knows a better way to automatically test the LockMap class, please write a comment.Maybe a little later but you can use Google Guava Maybe something like that:I didn't test it though.2 years later but I was looking for a simple named locker solution and came across this, was usefull but I needed a simpler answer, so below what I came up with. Simple lock under some name and release again under that same name.Here is the code:After some disappointment that there is no language level support or simple Guava/Commons class for named locks,This is what I settled down to:Here I achieved: little boilerplate code with no library dependency, atomically acquiring the lock object, not polluting the global interned string objects, no low-level notify/wait chaos and no try-catch-finally mess.I'd like to notice that  has built-in locking facility that is enough for simple exclusive multithread lock. No additional  objects needed.Here is an example of such lock map used to enforce at most one active jms processing for single client.Similar to the answer from Lyomi, but uses the more flexible ReentrantLock instead of a synchronized block.Yes this will grow over time - but using the ReentrantLock opens up greater possibilities for removing the lock from the map. Although, removing items from the map doesn't seem all that useful considering removing values from the map will not shrink its size. Some manual map sizing logic would have to be implemented.Often times, synchronization needed for a particular key is short-lived.  Keeping around released keys can lead to excessive memory waste, making it non-viable.Here's an implementation does not internally keep around released keys.If one wants re-entrant lock semantics, they can extend the above by wrapping the mutex object in a class that keeps track of the locking thread and locked count.e.g.:If one wants  to return an object to make releases easier and safer, that's also a possibility.Putting it all together, here's what the class could look like:And here's how one might use it:In response to the suggestion of using new MapMaker().makeComputingMap()...MapMaker().makeComputingMap() is deprecated for safety reasons. The successor is CacheBuilder. With weak keys/values applied to CacheBuilder, we're soooo close to a solution.The problem is a note in CacheBuilder.weakKeys():This makes it impossible to select an existing lock by string value. Erg.(4 years later...)\nMy answer is similar to user2878608's but I think there are some missing edge cases in that logic. I also thought Semaphore was for locking multiple resources at once (though I suppose using it for counting lockers like that is fine too), so I used a generic POJO lock object instead. I ran one test on it which demonstrated each of the edge cases existed IMO and will be using it on my project at work. Hope it helps someone. :) I've created a tokenProvider based on the  of McDowell.\nThe manager uses a  which takes care of cleaning up unused locks.TokenManager:\nUsage:or rather use Integers?Your idea about a shared static repository of lock objects for each situation is correct.\nYou don't need the cache itself to be synchronized ... it can be as simple as a hash map.Threads can simultaneously get a lock object from the map. The actual synchronization logic should be encapsulated within each such object separately (see the java.util.concurrent package for that - )TreeMap because in HashMap size of inner array can only increase "},
{"body": "I have a package in which I import javax.servlet.* and javax.servlet.http.*\nWhen I try to compile it in command prompt I get the errorI use JDK 1.7.0 and Tomcat 6.0.You need to add the path to Tomcat 6's  file to the compile time classpath.The classpath is where Java needs to look for imported dependencies. It will otherwise default to the current folder which is included as  in the above example. The  is the path separator for Windows; if you're using an Unix based OS, then you need to use  instead.If you are working with maven project, then add following dependency to your pom.xmlIs it a JSP or Servlet?Well, these two packages aren\u2019t actually built into Java like java.io is. Instead, they come with the Servlet-capable Web server (e.g. Tomcat). So before the Java compiler will be able to compile our Servlet, we need to let it know where to find the classes in these two packages.The classes required are normally stored in a file called servlet.jar. The exact location of this file will depend on the particular Web server software you use, but in the case of Tomcat you can find it in the lib subdirectory of the main Tomcat installation directory (e.g. d:\\Program Files\\Apache Group\\jakarta-tomcat-3.2.3\\lib\\servlet.jar). For the Java compiler to be able to compile Servlets, you need to add this file to your Java class path. By default, Java looks for classes in the current directory (\".\") only. Thus, \".\" is the default class path. If you change the class path to include the servlet.jar file (\".;d:...\\lib\\servlet.jar\" under Windows, \".:/usr/.../lib/servlet.jar\" in Unix), then the Servlet should compile just fine.You can specify a class path to use when you run javac.exe as follows:Or in Linux javac uses : instead of ;In a linux environment the soft link apparently does not work. you must use the physical path. for instance on my machine I have a softlink at  and using this as my classpath argument led to a failed compile with the same error. instead I had to use  which is the file that the soft link pointed to.This is what solved the problem for me:Add servlet-api.jar into your classpath. It will be available into Tomcat's lib folder.This is what I found. Adding /usr/local/apache-tomcat-7.0.64/lib/servlet-api.jar in my environment variable as CLASSPATH. OS is iOS.if using bash: ~/.bash_profile if using zsh: ~/.zshrc export Force it work right now, run  (or .zshrc)\nor one can restart computer and it works for the current user.JSP and Servlet are Server side Programming. As it comes as an built in package inside a Server like Tomcat. \nThe path may be like wise  Just you want to Do is Add this in the following way "},
{"body": "Let's say I want this query to be a valid string in Java. Do I have to convert it to escape all double quotes with a trailing slash in front?Or is there a faster way to make this whole query a valid string at once? I thought you could use single quotes around the whole string to do that but that doesn't work either.Escaping the double quotes with backslashes is the only way to do this in java. Some IDEs around such as  do this escaping automatically when pasting such a String into a String literal (i.e. between the double quotes surrounding a java String literal)One other option would be to put the String into some kind of text file that you would then read at runtimeUse Java's For example, Use a substitution char for the quotes and then replace that char with or replace all instances of  with For a String constant you have no choice other than escaping via backslash.Maybe you find the  project interesting. It is a thin layer over JDBC where you can externalize your SQL queries in XML configuration files without the need to escape double quotes.Yes you will have to escape all double quotes by a backslash."},
{"body": "Is there a specific rule on how Overriding  &  in  considering  ?? knowing that there is many parameters : super fields are private/public , with/without getter ...For instance, Netbeans generated equals() & hashCode() will not consider the super fields ... andwill return true :(If you want to see the Netbeans generated equals() & hashCode() :But , all significant fields should be taken into account for equality and hashing.Fortunately, you you can easily satisfy both rules.Assuming you're not stuck using the NetBeans-generated equals and hashcode, you can modify Hominidae's equals method to use instanceof comparison rather than class equality, and then use it straightforwardly. Something like this:Of course, hashcode is easy:Seriously, though: what's up with NetBeans not taking superclass fields into account by calling the superclass methods?I prefer to use  (and HashcodeBuilder) from the  to make my equals() and hashcode() methods a lot easier to read.Example:Generally speaking implementing equals across subclasses is hard to keep symmetric and transitive.Consider a superclass that checks for field x and y, and subclass checks for x y and z.So a Subclass == Superclass == Subclass  where z is different between the first instance of Subclass and the second, violating the transitive part of the contract.This why the typical implementation of equals will check for  instead of doing an instanceof. In the above example, if SubClass or Superclass does an instanceof check it would break symmetry.So the upshot is that a subclass can certainly take into account super.equals() but should also do its own getClass() check to avoid the above issues and then check for equals on its own fields in addition. It would be a strange duck of a class that changed its own equals behavior based on specific fields of the superclass rather than just if the superclass returns equals.The rules are:from .  So, use the fields needed to fulfill the rules.Because inheritance breaks encapsulation, subclasses that implement equals() and hashCode() must, necessarily, account for the peculiarities of their superclasses.  I've had success encoding calls to the parent class's equals() and hashCode() methods from the subclass's methods.Regarding the accepted @CPerkins answer, I don't think the given equals() code will work reliably, due to the likelihood that the super.equals() method will also check for class equality. A subclass & superclass will not have equal classes.It sounds like your parent (super) class doesn't override equals. If this is the case then you need to compare the fields from the parent class when you override this method in the sub-class. I agree that using the commons EqualsBuiler is the way to go but you do need to be careful that you don't break the symmetry/transative portions of the equals contract.If your sub-class adds attributes to the parent class and the parent class isn't abstract and overrides equals you're going to get in to trouble. In this scenario you should really look at object composition instead of inheritance.I'd strongly recommend the section in Effective Java by Joshua Block on this. It's comprehensive and really well explained.Well,  will be enough with CPerkins's answer.If you want those parent's fields(, , ) in action, one way is creating an actual instance of parent type and use it. Thank God, it's not an abstract class.I'm adding a way to (I think) solve this. The key point is adding a method loosely checks the equality.And here comes the .public class Child extends Parent {Testing...It's worth noting that the IDE auto generation maybe has taken into consideration super class\uff0cjust provided that the equals() and hashCode() of super class exists yet. That is, should auto generate these two functions of super first, and then auto generate of the child. I got below right example under Intellj Idea:The problem happens just when you don't auto generate super's in first. Please check above under Netbeans."},
{"body": "Is it possible in Java to make a Dictionary with the items already declared inside it? Just like the below C# code:How do I do this and what type do I use? I've read that Dictionary is obsolete.This will do what you want:This statment creates an anonymous subclass of HashMap, where the only difference from the parent class is that the 4 entries are added during instance creation. It's a fairly common idiom in the Java world (although some find it controversial because it creates a new class definition).Bite the bullet and type out the map name!You could also do something like this, which might save some typing with a long list:If you use the , you can use its  class, either by itself (examples 1 and 2), or as an initializer for a HashMap (examples 3 and 4):Java7 almost introduced \"collection literals\" that would allow syntax like that. They'll probably try to shove it in Java8. I have no idea what is wrong with these people.This can be easily achieved by some kind of wrapper APINot too bad. I would prefer something likeThis kind of thing must have been implemented by various people, unfortunately the standard API doesn't inculde such things."},
{"body": "Can somebody explain what the exact difference is between  and ?In what situations would we have to use each Receiver class?There is only one difference between  and .When you receive the broadcast inside  method,Suppose,  : :Example:Here, when you receive broadcast, you are starting a service, as you are using , it will hold  and won't let the CPU sleep until you finish the work inside service and fire Code:"},
{"body": "I am aware that you can lock an object in c# using lock but can you give up the lock and wait for something else to notify you that it's changed like you can in java with wait and notify?It seems to me that synchronised and lock in java and c# respectively are synonomous.The equivalent functionality (including the normal locking) is in the  class. The  statement in C# is equivalent to calling  and  with an appropriate try/finally block.See  or  for more details.I think Wait Handles may work for you. See if  helps."},
{"body": "I am trying to use Gson to deserialize a json string returned from my webservice The structure would be returned as .where  is likeand ItemDTO is likeWhen I call the code as followsEverything inside the objects is nullHowever, If I use the  and  to pull them out piece by piece from the org.json jars, it works fine and the fields are populated accordingly.Any ideas as to what I'm doing wrong? is Gson extremely fast?\nOr am I better to stick with what I've got working already?Thanks,\nDavid The example Java data structure in the original question does not match the description of the JSON structure in the comment.The JSON is described as \"an array of {object with an array of {object}}\".In terms of the types described in the question, the JSON translated into a Java data structure that would match the JSON structure for easy deserialization with Gson is \"an array of {TypeDTO object with an array of {ItemDTO object}}\".But the Java data structure provided in the question is not this.  Instead it's \"an array of {TypeDTO object with an array of an array of {ItemDTO object}}\".A two-dimensional array != a single-dimensional array.This first example demonstrates using Gson to simply deserialize and serialize a JSON structure that is \"an array of {object with an array of {object}}\".This second example uses instead a JSON structure that is actually \"an array of {TypeDTO object with an array of an array of {ItemDTO object}}\" to match the originally provided Java data structure.Regarding the remaining two questions:Not compared to other deserialization/serialization APIs.  Gson has traditionally been  the .  The current and next releases of Gson reportedly include significant performance improvements, though I haven't looked for the latest performance test data to support those claims.That said, if Gson is fast enough for your needs, then since it makes JSON deserialization so easy, it probably makes sense to use it.  If better performance is required, then Jackson might be a better choice to use.  It offers much (maybe even all) of the conveniences of Gson.I wouldn't.  I would most always rather have one simple line of code like ...to easily deserialize into a complex data structure, than the thirty lines of code that would otherwise be needed to map the pieces together one component at a time."},
{"body": "I'm confused with Heap,Young,Tenured and Perm generation. Could anyone please explain?The Java garbage collector is referred to as a . Objects in an application live for varying lengths of time depending on where they are created and how they are used. The key insight here is that using different garbage collection strategies for short lived and long lived objects allows the GC to be optimised specifically for each case.Loosely speaking as objects \"survive\" repeated garbage collections in the  they are migrated to the . The  is a special case, it contains objects that are needed by the JVM that are not necessarily represented in your program, for example objects that represent classes and methods.Since the  will usually contain a lot of garbage in it is optimised for getting rid of a lot of unused objects at once. The  since it contains longer lived objects is optimised for speedy garbage collection without wasting a lot of memory.With improvements in garbage collection technology the details have become pretty complex and vary depending on your JVM and how it has been configured. You should read the  for the specific JVM you are using if you need to know exactly what is happening.That said there is a simple historical arrangement this is still useful at a conceptual level. Historically the  would be a  and the  be a . A  pays essentially no CPU cost for getting rid of garbage, most of the cost is in maintaining live objects, the price of this efficiency is heavier memory usage. A  pays some CPU cost for both live and and unused objects but utilizes memory more efficiently. is part of memory allocated to JVM by Operating System. Whenever we create objects they are created inside . is divided into three regions or generation for sake of garbage collection called . Permanent generation is garbage collected during full gc in hotspot JVMThe  is where all new objects are allocated and aged. When the young generation fills up, this causes a minor garbage collection.  A young generation full of dead objects is collected very quickly. Some surviving objects are aged and eventually move to the old generation.The  is used to store long surviving objects. Typically, a threshold is set for young generation object and when that age is met, the object gets moved to the old generation. Eventually the old generation needs to be collected. This event is called a major garbage collection.The  contains metadata required by the JVM to describe the classes and methods used in the application. The permanent generation is populated by the JVM at runtime based on classes in use by the application. has been replaced with  since Java 8 release.  parameters will be ignored now. Have a look this  by .Image source:Refer to same article for more details.All objects in the heap survive will they are being referenced. When they're not more, the garbage collector (GC) will reclaim their memory.PermGen, Young and Tenured are diferent clasifications of objects (or spaces in the heap where they can be). these objects will be always there, they're not garbage collected. Classes objects are there, interned strings, etc. I don't know if there is a GC there (when system UNloads classes... but it's not a normal thing) when an object is created it's here. an object goes to this classification/category when it survives N GC passes (survive = GC passes but this object is referenced so it can't be reclaimed).Depending of GC used and some parametrization, GC passes more or less often.Then garbage collection can have different approaches to maange objects in the heap. This classification of objects helps to do it.Here's another excellent (though long) article on how to tune/size your GC parameters, which may help you understand even more:A very useful read if you're having GC issues and need to know how to read GC logs, or need to understand how your current GC collector works.If you want to hook up remote monitoring of a running system to see realtime memory usage and GC runs check this tool out:"},
{"body": "I want to do this:Currently this results in a label that displaysI want it to do this instead:Any suggestions?Thank youEDIT: Implemented solutionIn body of method:Helper method:You can use  in . To use it, your text has to start with .Set your text to  and it should work.See  and  for more information.It totally looks the same for me, but its uglyAnother easy way (but changes the text style a bit) is to use a  html block.This will persist any formatting the user entered if the string you are using came from a user input box.Example:The direct procedure of writing a multi-line text in a jlabel is:The problem with using html in  or any Swing component is that you then have to style it as html, not with the usual , , etc. If you're ok with that, fine.Otherwise you can use something like  from JIDE, which extends . It's part of their open source .JLabel can accept html code. Maybe you can try to use the \"< b r >\" tag. Example:\nJLabel myLabel = new JLabel();\nmyLabel.setText(\" This is a < b r > multi-line string \");I don't have the JDK with me right now, So I am not 100% confirm with the solution, but you can give it a shot.p.s. Please remove the whitespace between the < and b and r and > when you try. "},
{"body": "The heap memory is garbage collected in Java.Is the stack garbage collected as well?How is stack memory reclaimed?The memory on the stack contains method-parameters and local variables (to be precise: the references for objects and variables itself for primitive types). That will be automatically removed if you leave the method. If the variables are references (to objects) the objects itself are on the heap and handled by the garbage collector.So the stack isn't garbage collected in the same way as the heap, but stack is a form of automatic memory-management in it's own (which predates garbage collection).A , look into that for more details.The stack is not garbage collected in Java.The stack allocated for a given method call is freed when the method returns. Since that's a very simple LIFO structure, there's no need for garbage collection.One place where the stack and garbage collection interact is that references on the stack are GC roots (which means that they are the root references from which reachability is decided).The stack  be garbage collected. However, in most JVM implementations, it is handled as, well, a \"stack\", which by definition precludes garbage collection.What we call the stack is the accumulation of : for each invoked method, this is the conceptual structure which contains the method arguments, local variables, a hidden pointer to the context for the calling method, and a slot to save the instruction pointer. The activation context is not accessible as such from the Java language itself. A context becomes useless when the method exits (with a  or because of a thrown exception). It so happens that when a method A calls a method B, it is guaranteed that when A regains control, the context for B has become useless. This implies that the lifetime of the context for B is a subrange of the lifetime of the context for A. Therefore, activation contexts (for a given thread) can be allocated with a LIFO (\"Last In, First Out\") discipline. In simpler words, a stack: a new activation context is pushed on top of the stack of contexts, and the context on top will be the first to be disposed of.In practice, the activation contexts (also called ) are concatenated, in stack order, in a dedicated area. That area is obtained from the operating system when the thread is started, and the operating system gets it back when the thread terminates. The top of the stack is designated by a specific pointer, often contained in a CPU register (this depends on whether the JVM is interpreting or compiling code). The \"pointer to caller's context\" is virtual; the caller's context is necessarily located just below in stack order. The GC does not intervene: the area for the stack is created and reclaimed synchronously, from the thread activity itself. This is also how it works in many languages such as , which do not have a GC at all.Now nothing prevents a JVM implementation from doing otherwise, e.g. allocating activation contexts in the heap and having them collected by the GC. This is not usually done in Java Virtual Machines since stack allocation is faster. But some other languages need to do such things, most notably those which play with  while still using a GC (e.g.  and its  function), because such games break the LIFO rule explained above.The stack part of the memory works just like a \"stack\". I know it sounds bad, but that's exactly how it works. Data is added to the top, on top of each other () and is automatically removed from the top () as your program runs. It is not garbage collected - and it doesn't need to be since that memory is automatically reclaimed once data is popped off the stack. And when I say reclaimed I don't mean it gets de-allocated - it's just that the location in the stack memory where the next data will be stored is decreased, as data is popped off.Of course that's not to say that you don't need to worry at all about the stack. If you run a recursive function many times it will eventually use up all the stack space. The same if you call many functions, especially if they have many parameters and/or local variables.But the bottom line is that the memory of the stack is used and reclaimed as functions enter and leave scope - automatically. So at the end of your program's execution all the stack memory would be free and then released back to the operating system.If you refer to the memory used on the stack, it is not garbage collected.\nThe java virtual machine uses explicit bytecode instructions to reserve and release memory on the stack, these instructions are generated by the compiler and manage the lifetime of primitives like int,boolean,double and object-references on the stack.\nThere have been plans to implement a so called tail call optimisation, which would remove some entries from the stack once it is known that they are no longer used, but I don't know any jvm which already supports this.\nSo no there is no garbage collection for the stack itself, only the compiler generated push and pop instructions to manage the memory use.The stack itself is part of a thread. The stack is allocated when the thread object is created and garbage collected after the thread terminated and the thread object is no longer referenced.All objects in Java are allocated on the heap. (At least as far as the spec goes, the actual implementation may allocate them on the stack if they transparently behave as if they were on the heap.) Exactly what is collectible is a bit subtle. If the only reference to an object is in a single stack frame, and it can be shown that reference will not be used again, then the object may be collected. If the object is only used to read a field, then that field read may be optimised forward and the object collected earlier than you might expect.This doesn't usually matter unless you are using finalisers (or presumably s). In that case you should be careful and use locks/volatile to enforce a  relationship.When threads stop, then typically the entire stack will be deallocated.Everything located on stack is treated as global roots by a garbage collector. So, yes, you definitely can say that stack is \"garbage collected\".No one, data is pushed and popped from stack as you have inner variables in methods, during method calls, etc. You don't need to care about this.No. The stack is not garbage collected in Java. \nEach thread has its own stack and contains :These values are pushed as stack frames to the stack for every method call. Since the stack follows 'Last-in First-out' order, at the end of every method call, each stack frame containing all the method specific data and the references to objects, if any, is popped out.Hence, data in stack are automatically cleaned once the method/program goes out of scope. "},
{"body": "I have two byte arrays and I am wondering how I would go about adding one to the other or combining them to form a new byte array. You're just trying to concatenate the two byte arrays?Or you could use System.arraycopy:Or you could just use a List to do the work:You can do this by using Apace common lang package ( class ). You need to do the followingAssuming your  array is biger than ...you're going to it's length, not . You're trying to copy from beyond the array end.The problem with your code here is that the variable i that is being used to index the arrays is going past both the byteSalt array and the byteData array.  So, Make sure that byteData is dimensioned to be at least the maximum length of the passwordSalt string plus 32.  What will correct it is replacing the following line:with:I've used this code which works quite well just do appendData and either pass a single byte with an array, or two arrays to combine them :I think it is best approach,"},
{"body": "This error is just bizarre, my code compiles fine, I can see there are no problems with it, yet this error has just popped up. I have tried re-starting NetBeans and there is no additional exception information.What can cause this?I guess you are using an IDE (like Netbeans) which allows you to run the code even if certain classes are not compilable.  During the application's runtime, if you access this class it would lead to this exception.If it is Netbeans, try to uncheck \"Compile on save\" setting in the project properties (Build -> Compiling). This is the only thing which helped me in a similar situation.Source:\nIt's caused by NetBeans retaining some of the old source and/or compiled code in its cache and not noticing that e.g. some of the code's dependencies (i.e. referenced packages) have changed, and that a proper refresh/recompile of the file would be in order.The solution is to force that refresh by either:a) locating & editing the offending source file to force its recompilation (e.g. add a dummy line, save, remove it, save again),\nb) doing a clean build (sometimes will work, sometimes won't),\nc) disabling \"Compile on save\" (not recommended, since it can make using the IDE a royal PITA), or\nd) simply remove NetBeans cache by hand, forcing the recompilation.As to how to remove the cache:If you're using an old version of NetBeans:If you're using a newer one:The paths may vary a little e.g. on different platforms, but the idea is still the same.I also got the same error and I did clean build and it worked.Add selenium-server-standalone-3.4.0.jar. It works to me. \nDisable Deploy on Save in the Project's Properties/Run screen.  That's what worked for me finally.  Why the hell NetBeans screws this up is beyond me.Note: I was able to compile the file it was complaining about using right-click in NetBeans.  Apparently it wasn't really compiling it when I used Build & Compile since that gave no errors at all.  But then after that, the errors just moved to another java class file.  I couldn't compile then since it was grayed out.  I also tried deleting the build and dist directories in my NetBeans project files but that didn't help either.Organize your code as a maven module.\nOnce done run the command from terminal\n  \n\nto check  if your code builds fine.\nFinally import the project in netbeans or eclipse as maven project.Just check the packaging, the simplest answer I can provide is that your package has been mislabeled (within a class).Also, you may have some weird characters. Try white-flushing the code in a Notepad (or Gedit) and then pasting it into a newly created class with your IDE.change the package of classes, your files are probably in the wrong package, happened to me when I copied the code from a friend, it was the default package and mine was another, hence the netbeans could not compile because of it.I had this problem with NetBeans 8.0.1. Messages about problem in project deleted class. Deleting the ~/.netbeans didn't work. Also I looked for ANY reference to the deleted class in ALL my projects, nothing found. I deleted the build classes, everything. Then, when I started Netbeans again, compile and magically appears the message in Run and into the mother compiled class. I tried the uncheck \"Compile on save\" Dime solution, and works, but it's not practical.\nFinally, my solution was edit and force recompile of the mother class. This way the new .class doesn't contains the message and Run works OK.If you are using Netbeans, try to hit the Clean and Build button, let it do the thing and try again. Worked for me!"},
{"body": "this is my log outputI would like a time stamp per log message iehere is my log4j config fileHow do I do it?Use %d in your PatternLayout.Also %d can take a format pattern as in %d{dd MMM yyyy HH:mm:ss,SSS} you can pick and choose the elements that you want.  When the format pattern is omitted the date will be in ISO8601 format.A extract from my properties fileYou can find more conversion characters usage in log4j javadoc.For example, at ."},
{"body": "I want to choose a random item from a set, but the chance of choosing any item should be proportional to the associated weightExample inputs:So, if I have 4 possible items, the chance of getting any one item without weights would be 1 in 4.In this case, a user should be 10 times more likely to get the sword of misery than the triple-edged sword.How do I make a weighted random selection in Java?I would use a NavigableMapYou will not find a framework for this kind of problem, as the requested functionality is nothing more then a simple function. Do something like this:There is now a class for this in Apache Commons: where  is a , like (assuming Item interface in Arne's answer):or in Java 8:Note:  here needs to be , not .If you're gonna roll a lot of times (as in a game), you should use an alias method.The code below is rather long implementation of such an alias method, indeed. But this is because of the initialization part. The retrieval of elements is very fast (see the  and the  methods they don't loop).This implementation:Anyways, here's the code. (Note that .)If you need to remove elements after choosing you can use another solution. Add all the elements into a 'LinkedList', each element must be added as many times as it weight is, then use  which, according to Finally, get and remove elements using  or "},
{"body": "How do I set Java's min and max heap size through environment variables?I know that the heap sizes can be set when launching java, but I would like to have this adjusted through environment variables on my server.You can't do it using environment variables directly. You need to use the set of \"non standard\" options that are passed to the java command. Run: java -X for details. The options you're looking for are -Xmx and -Xms (this is \"initial\" heap size, so probably what you're looking for.)Some products like Ant or Tomcat might come with a batch script that looks for the JAVA_OPTS environment variable, but it's not part of the Java runtime.  If you are using one of those products, you may be able to set the variable like:  You can also take this approach with your own command line like:  If you want any  process, not just ant or Tomcat, to pick up options like  use the environment variable .In bash: You can't do it using environment variables. It's done via \"non standard\" options. Run:  for details. The options you're looking for are  and  (this is \"initial\" heap size, so probably what you're looking for.)Actually, there is a way to set global defaults for Sun's JVM via environment variables.See .I think your only option is to wrap java in a script that substitutes the environment variables into the command lineA couple of notes:"},
{"body": "We have some code wich sorts a list of addresses based on the distance between their coordinates. this is done through collections.sort with a custom comparator.However from time to time an adress without coordinates is in the list causing a NullPointerException. My initial idea to fix this was to have the comparator return 0 as dististance for addresses where at least one of the coordinates is null. I fear this might lead to corruption of the order the 'valid' elements in the list.so is returning a '0' values for null data in a comparator ok, or is there a cleaner way to resolve this.Handle it like  means infinitely far away. Thus:With this, you get a consistent ordering.Just to expand on Willi Sch\u00f6nborn's answer, I came here to say that  is exactly what you're after here. In the general case, you can just write your own  to ignore nulls (assume non-null, so it can concentrate on the important logic), and then use  to handle the nulls:In your case, though, it's data WITHIN the Address (the Coordinates) that is being used to sort, right? google-collections is even  useful in this case. So you might have something more like:then when you want to sort:and that's where the power of google-collections really starts to pay off.My take on this is that anything you try to do to \"make good\" the  coordinates is just papering over the cracks.  What you really need to do is find and fix the bugs that are injecting the spurious  coordinates.In my experience, infestations of NPE bugs are frequently caused by the following bad coding habits:(Better solutions to the \"no value\" problem typically involve rewriting code so that you don't  to represent this and/or using a non-null value instead; e.g. an empty String, a special instance, a reserved value.  You can't always find a better solution, but you often can.)If this describes your application, you should be spending time to root out the code problems rather than thinking of ways to hide the NPEs.My solution (might be useful for someone looking here) is to do the comparison normal, with null values replaced not by 0, but the maximum value possible (e.g. Integer.MAX_VALUE). Returning 0 is not consistent, if you have values that are themselves 0. Here a correct example:I just wanted to add that you don't necessary need the max value for integer. It depends of what your giveMeSomeMeasure() method can return. If for example you compare Celsius degrees for weather, you can set l and r to -300 or +300, depending where you want to set the null objects - to the head or the tail of the list.You probably dont want to return 0 as that implies the addresses are equidistant and you really dont know. This is quite a classic problem where you are trying to deal with bad input data. I dont think its the responsibility of the comparator to try and determin how far the address is in realtive terms when you  the distance. I would remove those addresses from the list before sorting.The hack would be to move them to the bottom of the list (but thats ugly !)Instead of looking at this like it's a technical problem with the comparator, it's better to take a look at the requirements again: what you're really trying to do here, what are you going to do with this sorted list?As you already realize, always returning 0 when one of them is null is not a good idea here; it can corrupt the result indeed. But what you should do instead depends on what you need, not on what others usually do/need. How your program behaves with addresses that don't have a location (so what the user is going to see) should not depend on some technical detail like what the \"best practice\" for comparators is.\n(To me, asking what the \"best practice\" is here, sounds like asking what the \"best requirements\" are).No, there is no cleaner way. Perhaps:But more importantly - try to get rid of / fill in the missing coordinates, or, better: don't put addresses with missing coordinates in the list.Actually, not putting them in the list is the most logical behaviour. If you put them in the list, the result won't be actually ordered by distance.You may create another list, containing the addresses with missing coordinates, and make it clear to whoever needs that information (end-user, API user), that the first list only contains addresses with the needed data, while the second list contains addresses that lack required information.I personally hate dealing with special null cases everywhere in my comparators so i was looking for a cleaner soluation and finally found google collections. Their Ordering is just awesome. They support compound comparators, offer to sort nulls to the top and to the end and allow to run certain functions before comparing. Writing comparators has never been so easy. You should give it a try.If you are using Java 8, you have 2 new static methods in the Comparator class, which come in handy:The comparison will be null safe and you can choose where to place the null values in the sorted sequence. The following example:will print:\n[null] [null] [] [Chimp] [banana] [eat] [run] [sleep] [smile] [throw banana peel] "},
{"body": "I need for example to pass  argument to Jetty which run as maven-plugin (maven-jetty-plugin) by \"\" command.  is the answer. The string content of MAVEN_OPTS variable is passed to jvm (java.exe).: in shell type \"\"\n: in shell (cmd.exe) type \"\":\n (01.04.2013)Matthew Farwell (please upvote his answer to give him a credit) comes with solution of using forked jvm process to run jetty which is new feature of jetty plugin - see  This is better solution as the former running inside same jvm processs as maven (thus share memory).With more recent versions of the maven-jetty-plugin, you can use . The option jvmArgs will allow you to set -Xmx etc.For more information, see: .I think the original issue was .It seems like your current approach is correct - when running jetty through maven, jetty is a thread inside the maven process.  So increasing maven's heap will increase jetty's heap.How are you setting MAVEN_OPTS?One example I found looks like this:   Note that  is an environment variable here, and not passed to the JVM (who wouldn't know what to do with it).The  param mentioned here :  \ndidn't work for me . Maven version : Apache Maven 3.0.3Jetty Maven plugin version : jetty-maven-plugin:8.1.10.v20130312This worked :How about:  On Linux/Unix will do the trickTo specify vm arguments via the command line (as originally asked) you can do the following:The plugin allows you to specify jvmArgs like this:you can use  to pass -Xmx argument like;There is no way using the commandline. But you could copy the  /  to  and change the line To "},
{"body": "Specifically, I have TabPane, and I would like to know if there is element with specific ID in it.So, I would like to do this with lambda expression in Java:Try to use  of Lambda Expression. It is much better approach.While the accepted answer is correct, I'll add a more elegant version (in my opinion):Don't neglect using  which allows to flatten the data structure before applying the ."},
{"body": "First up - yes, I have read the multiple questions & answers on this topic, and can't get any of the solutions within those to help me. I'm not running Tomcat or JBoss and I don't have a web.xml file to change. I'm using Java 6.0 and log4j-1.2.8.jarI am creating a runnable jar file with IDEA IntelliJ with jar libraries packaged separately and linked via the manifest. I am running my code on a linux server thus:My log4j configuration file (which I've placed both in mydir and mydir/code, just in case) is:And I have created the log/ directory in mydir and mydir/code, again, just in case.Any ideas?There are many possible options for specifying your log4j configuration. One is for the file to be named exactly \"log4j.properties\" and be in your classpath. Another is to name it however you want and add a System property to the command line when you start Java, like this:All of them are outlined here I had moved my log4j.properties into the resources folder and it worked fine for me !Man, I had the issue in one of my eclipse projects, amazingly the issue was the order of the jars in my .project file. believe it or not!You will find de  in .If you don't find the file, i put it here:RegardsMove Your log4j.properties file into the src folder.\nOpen Windows explorer, browse to the directory where your project resides in.\nBrowse to bin directory and delete all the  with in it.Now in eclipse click project---->clean---->OKThis would force it to build the project again,all the contents delete from bin directory will be recreated.I took while to figure this out.\nAt times directly clicking clean doesn't workput the folder which has the properties file for log in java build path source. You can add it by right clicking the project ----> build path -----> configure build path ------> add t"},
{"body": "I have recently created a library Jar file that I imported in my Android project. I am able to call functions and use classes that are present in this Jar file, but Android Studio keeps telling me that it cannot \"resolve symbol\" of the class I am using. Please see the screenshot below:The code builds and executes successfully. The function  simply returns , and that is just what  gets set to.I have tried pressing the  button and using the  option from Android Studio's  menu, but none of this solved the issue. What can I do to make the Android Studio IDE not display the  error?I have faced this issue when IntelliJ IDEA got closed abruptly due to OS crash.You can do \"File\" -> \"Invalidate Caches...\", and select \"Invalidate and Restart\" option to fix this.I found the issue - my  was not generated correctly. It included  files instead of  files. This explains why the IDE was not able to find the SDK class. The package structure was still correct in the Jar, which is why the package name itself is not a red color. The code worked correctly, because the compiler knew to compile the  files.To solve the issue, I modified my  of my SDK project to include  files, instead of  files, when creating the Jar. Including this new Jar instead of the old Jar  fixed the IDE issue.Try adding the library to the .To do this, on the menu choose  -> . Select the  option and click the green  to add your library.This was always happening to me after switching branches on my current project: a lot of non-sense erros being reported by the IDE.The solution is to modify and  a  ."},
{"body": "I have a Java class  that I am interested in deserializing from JSON. I have configured a special MixIn class, , to assist me with the deserialization.  has only  and  instance variables combined with proper getters and setters.  looks something like this:In my test client I do the following, but of course it does not work at compile time because there is a  related to a type mismatch.I am aware that I could alleviate this issue by creating a \"Response\" object that has only an  in it, but then I would have to create these somewhat useless objects for every single type I want to return.I also looked online at  but had a terrible time understanding the stuff about  and how it relates to my issue. If you cannot tell, I'm entirely new to Java and come from an Obj-C background. They specifically mention: How can I deserialize directly to ?You can deserialize directly to a list by using the  wrapper. An example method:And is used thus:.Another way is to use an array as a type, e.g.:This way you avoid all the hassle with the Type object, and if you really need a list you can always convert the array to a list by:IMHO this is much more readable.And to make it be an actual list (that can be modified, see limitations of ) then just do the following:I am also having the same problem. I have a json which is to be converted to ArrayList. Account looks like this.All of the above classes have been annotated properly.\nI have tried TypeReference>() {} \nbut is not working.It gives me Arraylist but ArrayList has a linkedHashMap which contains some more linked hashmaps containing final values.My code is as Follows:I finally solved the problem. I am able to convert the List in Json String directly to ArrayList as follows:This variant looks more simple and elegant."},
{"body": "Every now and again, I make use of the Eclipse refactoring feature. Some techniques are more obvious then others and some I never tried.What refactoring is most useful for you and why?Note: I find this presentation very useful, perhaps because it is example driven therefore easy to understand:\"\"Edit: This article is useful as well (Thanks jitter)It is an interesting question. I know what works for me and it is interesting to see what others use. I decided to take a more scientific approach to determine the most commonly used refactoring commands. Eclipse has a  feature built in. The data is . I took the data and extracted the following graph which shows the most commonly used editing commands (without navigation commands).However, I am a strong believer in \"Save Actions\" for formatting and organizing imports (read ), so I wouldn't count those. I would also remove the commenting actions. The picture looks like this:   - because giving things meaningful names is the best way to write self-documenting code. ++ - whenever a method gets too long. ++ - because magic numbers are bad. ++ (refactoring menu, there's no direct shortcut). - to remove clutter from methods. ++ (inline), ++ (introduce)My favourites (in order of using):My favorites:The most popular refactorings have been stated, and I entirely agree with them. (,  or   ) is one of the features of the IDE I use very often. True, it is not refactoring, but it improves code readability while maintaining your coding style: simply head to , , ,  and tell Eclipse how you want your code to look! is also a feature I find to save time when writing Java beans.Eclipse has perhaps the least refactorings for all the popular IDEs. You might consider Netbeans or IntelliJ (Community edition is free). Conversely Eclipse has possibly the best debugger. ;)I use refactoring as I write the code (which I have found speeds up writing by about 15%) so IntelliJ's ability to refactor code which does not compile very useful for me.  The other IDEs may support this now (does any one know?)\nI find IntelliJ's smart complete is a fair bit smarter as well.I have tested retyping a files from printout (originally written in eclipse) and found I used 30% less keys and 50% less mouse movements when typing the file with IntelliJ (compared with Eclipse) I would estimate Netbeans to be somewhere in the middle.My favorites are:1) Rename - It works on method names, variable names, class names, fields-- really anything with a name.\n2) Convert Anonymous Class to Nested - Helps with debugging, lets you reuse logic (such as a comparator) that you only thought that you'd use in one place. \n3) Convert Member Type to Top Level - Frequently after making an anonymous class into a nested class I discover that the class is useful elsewhere. This refactoring is perfect then.What I use the most is Rename, Extract Method and Change Method Signature, in that order.CTRL + 1 on a red lined section, i.e. quick fix.I like the Extract Method (++), and since , it now handles selections that contain continue statements.  I use :1- Rename  - to correct better method name 2- Move  - to organize my package in better ways, like when I start my project, it was so small so no need of a io package, but now yes.3- Generate Comments -when I create a .class  avoid me to re-copy the GPL license, etc4- Correct Indentation - to keep my code readable.It's also worth reading this research:  by D. Dig and R. Johnson.The authors noticed that 80% of the changes were refactorings and classified them.  Here is the abstract:\"It's also worth reading this research: How do API evolve? A story of refactoring. by D. Dig and R. Johnson.The authors noticed that 80% of the changes were refactorings and classified them. Here is the abstract ... \"80% of the BREAKING changes were observed to be refactorings.\nThe refactorings themselves formed only 20 - 30% of the API changes.."},
{"body": "I'm trying to parse a string to a date field in an android application but I can't seem to get it correct. Here is the string I'm trying to convert to a date \"03/26/2012 11:49:00 AM\". The function I'm using is:But I keep getting 3/1/112 11:49AM as the result.. Any help I would really appreciate. thanksYou are wrong in the way you display the data I guess, because for me:Prints:it went OK when i used  parametre in Try thisThis code will help you to make a result like   FEB 17 20:49 .Result :Date  : FEB 17Time  : 20:49Output:"},
{"body": "I'm working on some legacy code that has a class that is 10,000+ lines of code and has 100s of methods.  Is there a shortcut for any jetbrains IDE (since the shortcut would likely be shared across all of them) to collapse all the methods / functions so that only the method signatures are shown? something like this: You may take a look at . I guess that ++ is exactly what you need.The above suggestion of ++ code folds all code blocks recursively. I only wanted to fold the methods for my classes. I managed to achieve this by using the menu option . I re-assigned it to + which gives me a quick way to collapse my classes down to their methods.This works at the 'block level' of the file and assumes that you have classes defined at the top level of your file, which works for code such as PHP but not for JavaScript (nested closures etc.)go to menu option  to access all code folding related options and their shortcuts."},
{"body": "I have a LinearLayout and ImageView inside this LinearLayout. There is a translation effect for ImageView.Animation working but it's disappearing when ImageView go outside of LinearLayout. You can see problem here : How can i fix it without modify LinearLayout's height.Find the ViewGroup that the ImageView belongs to and apply .\nBy default, the drawing of the children is limited to the bounds of the parent ViewGroup.Two attributes exist that may cause this to happen: clipChildren and clipToPadding. You'll need to set clipChildren to false for each parent ViewGroup whose bounds the object will animate out of. You also need to set clipToPadding to the immediate parent (and maybe more, but I haven't seen a case for it yet).You can set both attributes in the XMLor in codeMy implementation. It can probably help somebody:call\n to disable the clipping in all the parents.In my case clipChildren did nothing but  fixed the problem. Go figure."},
{"body": "What is the difference between these two declarations?Is generic where you want to hide implementation details while returning it to client, at later point of time you may change implementation from  to  transparently.This mechanism is useful in cases where you design libraries etc., which may change their implementation details at some point of time with minimal changes on client side.This mandates you always need to return . At some point of time if you would like to change implementation details to , there should be changes on client side also to use  instead of . is an interface and  is an implementation of the List interface. The  class has only a few methods in addition to the methods available in the List interface. There is not much difference in this. If you use the first, you will be able to call the methods available in the List interface and you cannot make calls to the new methods available in the  class. Where as, you are free to use all the methods available in the  if you use the second one. I would say the first approach is a better one because, when you are developing java applications, when you are supposed to pass the collection framework objects as arguments to the methods, then it is better to go with first approach. In future due to performance constraints, if you are changing the implementation to use  or someother classes which implements  interface, instead of , you need to  change at one point only(the instantiation part).Else you will be supposed to change at all the places, wherever, you have used the specific class implementation as method arguments.The difference is that variant 1 forces you to use an  while variant 2 only guarantees you have anything that implements .Later on you could change that to  without much hassle. Variant 1 might require you to change not only that line but other parts as well if they rely on working with an .Thus I'd use  in almost any case, except when I'd need to call the additional methods that  provides (which was never the case so far):  and . Basically it allows Java to store several types of objects in one structure implementation, by generic type declaration (like ), which is one of Javas main features. Object-oriented approaches are based in modularity and reusability by separation of concerns - the ability to use a structure with any kind of types of object (as long as it obeys a few rules).You could just instantiate things as followed:instead ofBy declaring and using generic types you are informing a structure of the kind of objects it will manage and the compiler will be able to inform you if you're inserting an illegal type into that structure, for instance. Let's say:If you want to see some examples check the documentation :Then you could instantiate things like:The main thing to draw from this is you're specifying which type of object you want to box.As for using , you're not accessing the  or  implementation so you won't be able to do much with the collection.The first declaration has to be an ArrayList, the second can be easily changed to another List type.  As such, the second is preferred as it make it clear you don't require a specific implementation. (Sometimes you really do need one implementation, but that is rare)It is easy to change the implementation to  to :There are a few situations where you might prefer the first one to (slightly) improve performance, for example on some JVMs .Out of that kind of very specific context, you should use the first one.Possibly you can refer to this link\nList is an interface.ArrayList,LinkedList etc are classes which implement list.Whenyou are using List Interface,you have to itearte elements using ListIterator and can move forward and backward,in the List where as in ArrayList Iterate using Iterator and its elements can be accessed unidirectional way.List is interface and ArrayList is implemented concrete class. \nIt is always recommended to use.Because here list reference is flexible. It can also hold  object.Whenever you have seen coding from open source community like Guava and from Google Developer (Android Library) they used this approachbecause it's hide the implementation detail from user.\nYou precisely it's generic approach and this specialized approach For Reference:\nEffective Java 2nd Edition: Item 52: Refer to objects by their interfaces"},
{"body": "This is what I can do in JUnit:and the entire class will be ignored. How can I do the same in TestNG?I believe what you want is:(You can apply the @Test annotation to the class, as well as to methods individually.)The  has a comprehensive list of the supported annotations, and also describes exclusion/inclusion of tests by group if that's of any interest. Here's a quote from the relevant section::\nIgnoring a class by applying  is apparently buggy functionality in some versions of TestNG according to  that was raised against TestNG. "},
{"body": "I'm trying to access an XML file within a jar file, from a separate jar that's running as a desktop application.  I can get the URL to the file I need, but when I pass that to a FileReader (as a String) I get a FileNotFoundException saying \"The file name, directory name, or volume label syntax is incorrect.\"As a point of reference, I have no trouble reading image resources from the same jar, passing the URL to an ImageIcon constructor.  This seems to indicate that the method I'm using to get the URL is correct.Inside the ServicesLoader class I have What's wrong with using this technique to read the XML file?Looks like you want to use , seeYou don't say if this is a desktop or web app.  I would use the  method from an appropriate ClassLoader if it's a desktop or the Context if it's a web app.It looks as if you are using the  result as the argument to the  constructor.  is a bit broken, and instead you should generally use . In any case, the string is not a file path.Instead, you should either:The problem was that I was going a step too far in calling the parse method of XMLReader. The parse method accepts an InputSource, so there was no reason to even use a FileReader. Changing the last line of the code above toworks just fine.I'd like to point out that one issues is what if the same resources are in multiple jar files.\nLet's say you want to read /org/node/foo.txt, but not from one file, but from each and every jar file.I have run into this same issue several times before.\nI was hoping in JDK 7 that someone would write a classpath filesystem, but alas not yet.Spring has the Resource class which allows you to load classpath resources quite nicely.I wrote a little prototype to solve this very problem of reading resources form multiple jar files. The prototype does not handle every edge case, but it does handle looking for resources in directories that are in the jar files.I have used Stack Overflow for quite sometime. This is the second answer that I remember answering a question so forgive me if I go too long (it is my nature).This is a prototype resource reader. The prototype is devoid of robust error checking.I have two prototype jar files that I have setup.The jar files each have a file under /org/node/ called resource.txt.This is just a prototype of what a handler would look like with classpath://\nI also have a resource.foo.txt in my local resources for this project.It picks them all up and prints them out.Outside of your technique, why not use the standard Java  to get the references you want? From there most of your problems should go away.If you use resources extensively, you might consider using \n .Also supports:\n * Local Files\n * FTP, SFTP\n * HTTP and HTTPS\n * Temporary Files \"normal FS backed)\n * Zip, Jar and Tar (uncompressed, tgz or tbz2)\n * gzip and bzip2\n * resources\n * ram - \"ramdrive\"\n * mimeThere's also  - but it's not much documented.I have 2 CSV files that I use to read data. The java program is exported as a runnable jar file. When you export it, you will figure out it doesn't export your resources with it. I added a folder under project called data in eclipse. In that folder i stored my csv files.When I need to reference those files I do it like this...Then when you put the jar in a location so it can be ran via commandline, make sure that you add the data folder with the resources into the same location as the jar file."},
{"body": "Here are the facts:As an example of a Java program that has memory leaks (not for the faint of heart, the question may shake your beliefs), see here about a little Java program called Tomcat that even has a \"find leaks\" button: So I am wondering: will programs written in Go exhibit the same kind of (subtle or not) memory leaks that some programs written in Java exhibit?You are confusing different types of memory leaks here.  The heinous, explicit-memory-management based memory leaks are gone in Java (or any other GC based language).  These leaks are caused by completely losing access to chunks of memory without marking them as unused.The \"memory leaks\" still present in Java and every other language on the face of the planet until the computer can read our minds are still with us, and will be for the foreseeable future.  These leaks are caused by the code/programmer keeping references to objects which are technically no longer needed.  These are fundamentally logic bugs, and cannot be prevented in any language using current technologies.It's very possible that Go programs will exhibit memory leaks.  The current implementation of Go has a simple mark-and-sweep garbage collector.  This is only intended as a temporary solution and is not intended as the long term garbage collector. See this  for more info. Look under the header . That page even has a link to code for the current version if you are so inclined.Garbage collection or not, you can write a program that has memory-leaks in Java, Go, or any other language for the most part.Garbage Collection does take some of the burden off the programmer but it does not prevent leaks entirely.A 'memory leak' is when a piece of memory that the programmer thought would be freed isn't freed. This can happen in any language, garbage collected or not. The usual cause in GC languages is retaining an additional reference to the memory.\"Languages don't cause memory leaks, programmers cause memory leaks\".You are mixing abstraction levels here: the memory leaks are due to bugs in the library (where objects reference each other though chains of 'a holds reference to b' as well as a trade-off in the implementation of the garbage collector between efficiency and accuracy.  How much time do you want to spend on finding out such loops?  If you spend twice as much, you'll be able to detect loops twice as long.So the memory leak issue is not programming language specific, there is no reason that by itself GO should be better or worse than Java."},
{"body": "I am trying to call a web service but facing a strange behavior. we have a web-service running on my server but the code is not open to us so can not see what going on behind the wall\nThe owner of the service have exposed  web based test client UI which take input in a text box and will show the response to testing purpose.This input box is taking the input in the below mentioned formatits working fine on this UI but when i am trying to call this web service through my java code its getting connected as well getting authorized by the service but when i trying to call the above method it giving me the below error messagebelow is the code for generating the required XMLand the generated XML is as belowi even did timing of the generated string something as below but unable to find out whats going wrong,one thing i am sure there is some problem in the input XML as its working find on the test Page UI for the same XMLany help in this regard is much appricatedThis error is probably related to a byte order mark (BOM) prior to the actual XML content.  You need to parse the returned String and discard the BOM, so SAXParser can process the document correctly.  You will find a possible solution .to simply remove it, paste your xml file into notepad, you'll see the extra character before the first tag. Remove it & paste back into your file - bofCheck the XML. It is not a valid xml. Prolog is the first line with xml version info. It ok not to \ninclude it in your xml.  This error is thrown when the parser reads an invalid tag at the start of the document. Normally where the prolog resides.e.g.This error can come if there is validation error either in your wsdl or xsd file. For instance I too got the same issue while running wsdl2java to convert my wsdl file to generate the client.\nIn one of my xsd it was defined as belowWhere the schemaLocation was empty. By providing the proper data in schemaLocation resolved my problem.I faced the same issue. Our application running on four application servers and due to invalid schema location mentioned on one of the web service WSDL, hung threads are generated on the servers . The appliucations got down frequently. After corrected the schema Location , the issue got resolved.   "},
{"body": "I'm wondering about best practices when creating Javadocs. I have a project with many files. Code has been created by many developers. Each file has an annotation , so it is obvious who has created a particular class. But when some other developer adds new code to a file, modifies it, etc., how should he inform the rest of the team that he has created some new function or has modified existing code? In other words, how should we \"keep the Javadocs compatible with reality\"? ;)Of course, since we use SVN, it is easy to investigate who has made what, but for keeping things clear this Javadoc stuff should be taken into consideration as well.What's the best way to use these  tags?I would say that for most purposes  is unwanted noise.  The user of your API shouldn't - and probably doesn't - care, or want to know, who wrote which parts.And, as you have already stated, SVN already holds this information in a much more authoritative way than the code can.  So if I was one of the team, I would always prefer SVN's log and ignore the . I'd bet that the code will get out of sync with reality, whatever policy you adopted. Following the Don't Repeat Yourself principle, why hold this information in two places?If, however, there is some bureaucratic or policy reason that this information MUST be included in the code, have you considered automatically updating the  tag in the code on check in?  You could  achieve this with an SVN hook.  You could for example list all the developers who changed a given file in the order they changed it; or who changed it most; or whatever. Or, if the  is mandated in (source) code you release to the outside world, you could consider adding the  automatically as part of the release build (I suspect you could get this information out of SVN somehow).As for adding more than a single class level  tag (or other comment), I'd say you'd be accumulating a lot of unhelpful noise. (Again, you have SVN.)In my experience it is much more useful to identify a historical change (say a change to a line of code, or a method), then to work out which change set this relates to (and which track ticket).  Then you have the full context for the change: you have the ticket, the change set, you can find other change sets on the same ticket, or around the same time, you can find related tickets, and you can see ALL the changes that formed that unit of work.  You are never going to get this from annotation or comments in code.You may want to consider  you want author tags in the source.  The Apache Foundation do not and I agree.To my best understanding this is a cargo cult way of working from when sources were printed on paper.  With modern version control systems this information and more can be found in the history anyway.You can have more than one  tag. In case you make some big changes to a class, just add a new  tag with your own name in it. There's no need to mark the changes you've done or to put your name around the changes, as the revision history should be able to display that clearly.In really big and long-running projects with lots of developers, it is useful to know ho is responsible for given code, who can provide you with extra information and such. In that case it would be handy to have such an informationin the file using @author tag. Not marking who created the file or who made some major contributions, but who is a contact person for that code. Those might be very different people as original author may be already on different project or left the company years ago.I think on huge project that approach may be handy, however there is a caveat. Keeping every single file's author information is very difficult as there is huge amount of files and sooner or later will fail. More and more files will have outdated information and developers will no longer trust this @author as source of information and will just ignore it.Solution, which may work, is not to keep @author on every single file, but only per module (high level packages). Javadoc has a feature, where you can document not only files but whole packages ().This is however a special case and as long as your project is not that big or old, I reccomend ommiting the author information."},
{"body": "Using JAXB to generate XML binding classes.The schema is based on a set of legacy XML files, and includes this snippet:The 'Value' attribute conflicts with the 'value' property of , and the code generation fails with the error:The answer lies in making use of JAXB bindings ():The XPath expressions locate the nodes and renames it, thereby avoiding the naming conflict.Using this bindings XML file, the generated Java class ends up having the desired  (as well as the ).Once after xxxx.xjb file is created for duplicate attribute name \"value\" (duplicate is default 'value' provided by JAXB) as below, run XJC command to create JAXB objects:-:-If you want to avoid creating/changing a JAXB bindings file, and you don't mind annotating your XSD, you can add the  annotation to your attribute's definition, e.g.:with suitable additions to the xs:schema tag:I had a problem using the solution with Eclipse (tried both Helios SR1 and Juno SR1) and CXF 2.6.3. The solution was similar to what Kaitsu says. Namely the New > Web Service wizard of Eclipse copies the wsdl into the foldre WebContent/wsdl. I had to place the wsdl and the binding file there myself. Otherwise the binding file gave the \"is not a part of this compilation\" error.I wasn't able to use an inline schema in the WSDL but it did work with an external schema like in answer #1.I'm using the CXF Servlet endpoint config option. In my WSDL I have:The wizard generated this into my web.xml, which works ok:But it put this into cxf-servlet.xml:I had to change the address into the full URL, like this:This bindings file mentioned in the other answer did not work for me with CXF 3.0.0.\nNotice that jaxb namespace has an element \"bindings\" and so do the namespace jaxws, so we need to declare them:In my case the schema was already inside the WSDL so I did no have to specify the schemaLocation attribute."},
{"body": "I need to determine if a user-supplied String is a valid file path (i.e. if createNewFile() will succeed or throw an Exception) but i don't want to bloat the file system with useless files created just for validation purposes, so is there a way to determine if the String i have is a valid file path without attempting to create the file?I know the definition of \"valid file path\" varies depending on the OS, but i was wondering if there was any quick way of accepting \"C:/foo\" or \"/foo\" and rejecting \"banana\"...a possible approach may be attempting to create the file and eventually deleting it if the creation succeeded, but i hope there is a more elegant way of achieving the same result...This would check for the existance of the directory as well.It seems like file.canWrite() does not give you a clear indication if you have permissions to write to the directory.Path class introduced in Java 7 adds new alternatives, like the following : \n(Does  work properly under  - always returns true)A number of things can go wrong when you try and create a file:More to the point, those can change between when you try and query to see if you can and when you actually can.  In a multithreaded environment this is one of the primary causes of race conditions and can be a real vulnerability of some programs.Basically you just have to try and create it and see if it works.  And that's the correct way to do it.  It's why things like  has a  so the check and insert is an atomic operation and doesn't suffer from race conditions.  Exactly the same principle is in play here.If this is just part of some diagnostic or install process, just do it and see if it works.  Again there's no guarantee that it'll work later however.Basically your program has to be robust enough to die gracefully if it can't write a relevant file. is quite useful for this purpose. IO exceptions are thrown for certain types of invalid filenames (e.g. , ,  in Windows) when resolving against the OS or file system. However, this only serves as a preliminary check; you will still need to handle other failures when actually creating the file (e.g. insufficient permissions, lack of drive space, security restrictions)."},
{"body": "I have a need to include  in my JavaDoc comment. The problem is that this is also the same sequence for closing a comment. What the proper way to quote/escape this?Example:: It appears I can use  for the slash. The only downside is that this isn't all that readable when viewing the code directly in a text editor.Use HTML escaping. So in your example: escapes as a \"/\" character. Javadoc should insert the escaped sequence unmolested into the HTML it generates, and that should render as \"*/\" in your browser. If you want to be very careful, you could escape both characters:  translates to So? The point isn't for your code to be readable, the point is for your code  to be readable. Most Javadoc comments embed complex HTML for explaination. Hell, C#'s equivalent offers a complete XML tag library. I've seen some pretty intricate structures in there, let me tell you. \nIf it bothers you too much, you might embed a non-javadoc inline comment that explains the encoding:This is the \u2018right\u2019 solution, but for readability's sake I'd probably go for:Use the entity In your documentation it will show up as a \"*/\"Nobody mentioned . This is another way to go:Unfortunately you cannot escape  at a time. With some drawbacks, this also fixes:I would suggest you also add a line comment somewhere near saying something likeAnother way I stumbled upon, just for completeness: add some HTML markup which doesn't alter the output between the * and /. Compared to the HTML escape solution, this seems something of an ugly hack, but it also yields the right result in HTML output."},
{"body": "What is the best way to create Velocity Template from a String?I'm aware of  method where I can pass String or StringReader, but I'm curios is there a better way to do it (e.g. any advantage of creating an instance of Template).There is some overhead parsing template. You might see some performance gain by pre-parsing the template if your template is large and you use it repeatedly. You can do something like this,Then you can call  over and over again without parsing it everytime.BTW, you can pass String directly to .The above sample code is working for me. It uses Velocity version 1.7 and log4j.  A  so question."},
{"body": "My program that connects to a MySQL database was working fine. Then, without changing any code used to set up the connection, I get this exception:What happened?The code used to get the connection:This is a wrapped exception and not really interesting. It is the  of the exception which actually tells us something about the root cause. Please look a bit further in the stacktrace. The chance is big that you'll then face a  or .If this is true in your case as well, then all the possible causes are:To solve the one or the either, follow the following advices:By the way (and unrelated to the actual problem), you don't necessarily need to load the JDBC driver on   call. Just only once during startup is enough.check your wait timeout set on the DB server.\nSome times it defaults to 10 seconds. This looses the connection in 10 seconds.update it make it something like 28800I've been having this issue also for about 8-9 days.\nHere's some background: I'm developing a simple Java application that runs in bash.Details:The application works fine in Arch Linux, Mac OS X 10.6, and FreeBSD 7.2.\nWhen I moved the jar file to another arch linux in a different host, using the same mysql, a similar my.cnf, and the similar kernel version, the connection died and obtained the same error as the original poster:I tried every possible combination for this that I found on so and the forums ( for example, which is closed now and I can't post .. ), specifically:As it was pointed out (if you look up for the same exception , you will find several so threads about the issue \n for example ).If the link get's removed, just add mysqld:ALL to /etc/hosts.allow, but it may help anybody using GNU/Linux and having this exception and this thread seemed the best place to post my research.Hope it helpsI got the same error\nbut then I figured it out its because the  at that time.So to change the status of the serverHope this will help.We have a piece of software (webapp with Tomcat) using Apache commons connection pooling, and worked great for years. In the last month I had to update the libraries due to an old bug we were encountering. The bug had been fixed in a recent version.Shortly after deploying this, we started getting exactly these messages. Out of the thousands of connections we'd get a day, a handful (under 10, usually) would get this error message. There was no real pattern, except they would sometimes cluster in little groups of 2 to 5.I changed the options to on the pool to validate the connection every time one is taken from or put back in the pool (if one is found bad, a new one is generated instead) and the problem went away.Have you updated your MySQL jar lately? It seems like there may be a new setting that didn't used to be there in our (admittedly very old) jar.I agree with BalusC to try some other options on your config, such as those you're passing to MySQL (in addition to the connection timeout).If this failure is transient like mine was, instead of permanent, then you could use a simple try/catch and a loop to keep trying until things succeed or use a connection pool to handle that detail for you.Other random idea: I don't know what happens why you try to use a closed connection (which exception you get). Could you be accidentally closing the connection somewhere?Ensure skip-networking is commented out in my.cnf/my.iniAs BalusC mentioned, it would be very useful to post the  stacktrace (always post a full stacktrace, it is useless and frustrating to have only the first lines of a stacktrace). Anyway, you mentioned that your code  fine and that this problem started suddenly to occur without any code change so I'm wondering if this could be related to you other question  Actually, if this problem started while debugging, then I think it is (you ran out of connections). In that case, restart you database server (and follow the suggestions of the other question to avoid this situation).I encountered same problem. I am using spring & dbcp & mysql 5.5But If I change  to  then everything works. What make things more weird is  just works fine.update: Finally found a solution. Changing bindaddress to  or  in  will fix the problem. In my case, the local loopback interface wasn't started, so \"localhost\" couldn't be resolved.\nYou can check this by running \"ifconfig\" and you should see an interface called \"lo\". If it is not up, you can activate it by running \"ifup lo\" or \"ifconfig lo up\".In my case, the  whereas the .This happened when building a Google appengine application in Android Studio (gradle, Windows x64), communicating to a Linux MySQL server on the local network/local VM.I see you are connecting to a remote host. Now the question is what type of a network are you using to connect to the internet? If it's a  then get your machines IP address and add it to your hosting server so that your host server can allow connections coming from your machine.[your host might have turned this off due to security reasons].\nNote that every time you use a different network device your IP changes.If you are using a LAN then set a static IP address on your machine then add it to your host. I hope this helps!!  I got the communications failure error when using a java.sql.PreparedStatement with a specific statement.  This was running against MySQL 5.6, Tomcat 7.0.29 and JDK 1.7.0_67 on a Windows 7 x64 machine.  The cause turned out to be setting an integer to a string parameter and a string to an integer parameter then trying to perform executeQuery on the prepared statement.  After I corrected the order of parameter setting the statement performed correctly.This had nothing to do with network issues as the wording of the error message suggested.The escential problem is that Mysql JDBC pool connections is not used, then the Timeout from Mysql, close the Connections.  You need change the pool Parameters to get restart connection when the connection has failures, on this way::       Required    (Check)\n           autocommitYou can change the Validation Method if you cannot get it works!If you use WAMP, make sure it is online. What I did was, first turned my firewall off, then it worked, so after that I allowed connection for all local ports, specially port 80. Than I got rid of this problem. For me it was the Firewall who was blocking the connection.I had the same problem and I used most of the params (autoreconnect etc..), but didn't try the (test_on_idle, or test_on_connect) , I am going to do them next.However, I had this hack that got me through this: I have a cron job called Healthcheck, It wakes up every 10 mins and makes a REST API call to the server. The web / app server picks this up, connects to the db, makes a small change and comes back with a 'yes all quiet on western front' or 'shitshappening'. When the latter, it sends a pager / email to the right people.It has the side effect of always keeping the db connection pool fresh.  So long as this cron is running, I don't have the db connection timeout issues. otherwise, they crop up."},
{"body": "With intent to get m2e 1.0 working correctly I have had to specify the lifecycle mapping:But then I get this warning:if I run some specific maven task for example  (If I run only  then there is no such message)I know that the problem is that this POM does not exists, because it is only defined to hold the mapping information. ()Anyway, I want to keep my build clean, without any warnings, so how can I get rid of this specific one? ()I use Maven 3.0.2 and tried Maven 3.0.3 too, but the same result.My team works around this problem by wrapping the relevant configuration in a profile:This a  with  resolution. The suggested solution is the simplest in my opinion:and  this project.Regards\nMirkoNow there's now better solution (for the error messages in Eclipse only).Press  on the error  and then select this option:This works with  plugin (maybe earlier also)"},
{"body": "I need to write a project that's only compatible with Java 1.5. I have Java 1.6 installed. Is there some form of backwards compatibility to get Eclipse to compile with 1.5?Do I have to install Java 1.5 to get it to show here? Or maybe there is another way?.Click on the  button. It brings your  to point to the Java location.Select \"\", button right besides JRE home and point to the installed folder location.Even though you want to just 1.5 compiler project, you can achieve it by changing compiler settings in Eclipse instead of removing 1.6 JRE and add 1.5 JRE.As davidfmatheson suggested,Just be careful, especially if you're setting this up for a team of people to work on. If anyone uses anything that is new or changed in 1.6, it will compile, but not run in an environment with JRE 1.5.Click on the  tab in Eclipse, go to  and when that window comes up, go to  \u2192  \u2192  and choose JavaSE-1.5. You then have to go to  and set the .Right click project -> Properties ->  -> select  click  and select  or  after then click  and select   to   Eclipse - specific Project change JDK Version -If you want to change any jdk version of A specific project than you have to click ---> Project --> JRE System Library --> Properties ---> Inside Classpath Container (JRE System Library) change the Execution Environment to which ever version you want e.g. 1.7 or 1.8.See the page . From the add button you can add a different version of the JDK...The JDK (JAVA_HOME) used to launch Eclipse is not necessarily the one used to compiled your project.To see what JRE  can select for your project, check the preferences: \u2192 By default, if you have not added any JRE, the only one declared will be the one used to launched Eclipse (which can be defined in your ).  You can add any other JRE you want, including one compatible with your project.After that, you will need to check in your project properties (or in the general preferences) what JRE is used, with what compliance level:In the preferences section under Java -> Installed JREs click the Add button and navigate to the 1.5 JDK home folder.  Then check that one in the list and it will become the default for all projects:As I was facing this issue minutes ago, in case you are trying to open an existing project in an environment with a newer JDK, make sure you pdate the JDK version in Project Properties -> Project Facets -> Java."},
{"body": "I'm looking for a book or any other resource that will help me learn how to create RESTful APIs in Java. \nLooking on Amazon, I saw that there are , but I'm looking for the one that is tailored to a novice.Looking forward to getting your advices/opinions, thanks!I don't think I can point to only one resource but I would take a path (which you can customize based on your level of understanding of REST). I'm somebody who would like to get my concepts real clear first and then think about the tools to implement the concepts.Obviously, I haven't provided a single resource, but something in the lines I've provided would serve well, IMO.I found  to be the best book covering different styles of REST architectures.  It's also far more practical in its advice than many other books (I wasn't impressed by RESTful Web Services as I think it lacks focus).My recommendation would be this one:I'd recommend this extensive ,  and maybe having at look at the  framework.I have used  to learn about REST concepts. It's an early access book so only the first few chapters are currently available, but I found the writing to be very clear."},
{"body": "I am wondering when static variables are initialized to their default values.\nIs it correct that when a class is loaded, static vars are created (allocated),\nthen static initializers and initializations in declarations are executed?\nAt what point are the default values are given?  This leads to the problem of forward reference.Also please if you can explain this in reference to the question asked on  and especially the answer given by Kevin Brock on the same site. I can't understand the 3rd point.Instance and class (static) variables are automatically initialized to standard default values if you fail to purposely initialize them.  Although local variables are not automatically initialized, you cannot compile a program that fails to either initialize a local variable or assign a value to that local variable before it is used.What the compiler actually does is to internally produce a single class initialization routine that combines all the static variable initializers and all of the static initializer blocks of code, in the order that they appear in the class declaration.  This single initialization procedure is run automatically, one time only, when the class is first loaded.In case of  classes, they can not have static fieldsSee JLS  fields in Java can be initialized separately from their declaration place this is however can not be applicable to  fields. See the example below.This is because there is just one  of the  variables associated with the type, rather than one associated with each instance of the type as with instance variables and if we try to initialize  of type  within the constructor, it will attempt to reinitialize the  type field  because the constructor is run on each instantiation of the class that must not occur to static  fields.See:The last in particular provides  that spell out when static variables are initialized, and in what order (with the caveat that  class variables and interface fields that are compile-time constants are initialized first.)I'm not sure what your specific question about point 3 (assuming you mean the nested one?) is. The detailed sequence states this would be a recursive initialization request so it will continue initialization.The order of initialization is:The details of the process are explained in the JVM  document.Static fields are initialized when the class is loaded by the class loader.  Default values are assigned at this time.  This is done in the order than they appear in the source code.Starting with the code from the other question:A reference to this class will start initialization.  First, the class will be marked as initialized.  Then the first static field will be initialized with a new instance of MyClass().  Note that myClass is immediately given a reference to a  MyClass instance.  The space is there, but all values are null.  The constructor is now executed and prints , which is null.Now back to initializing the class:   is made a reference to a new real object, and we're done.If this was set off by a statement like:   space for a new MyClass instance is again allocated (and the reference placed in ).  The constructor is again executed and again prints , which  is not null.The real trick here is that when you use , as in   is immediately given a reference to a bit of nulled memory.  The JVM will then go on to initialize values and run the constructor.  But if you somehow reference   it does so--by referencing it from another thread or or by referencing from the class initialization, for instance--you are looking at a class instance filled with null values.The static variable can be intialize in the following three ways as follow choose any one you like*"},
{"body": "Does anybody have an example of how to use Google Guice to inject properties from a .properties file.  I was told Guice was able to validate that all needed properties exist when the injector starts up.At this time I cannot find anything on the guice wiki about this.You can bind properties using , where  returns a  object or a  (reading the properties file as a  object is up to you).You can then inject them by name using . If you had a properties file:You could inject the values of those properties anywhere you wanted, like this:Guice can convert values from strings to the type being injected, such as the  above, automatically (assuming the string is an appropriate format). This works for primitive types, enums and class literals. "},
{"body": "I am trying to understand PrintWriter for a small program I'm making, and I cant seem to get java to make the file and then write on it. When I execute the program below it gives me a Filenotfoundexeption error on line 9. It also fails to make the file in the directory that I specified. I am new to this so please try and keep the answers simple. I am using Eclipse.If the directory doesn't exist you need to create it. Java won't create it by itself since the  class is just a link to an entity that can also not exist at all.As you stated the error is that the file cannot be created. If you read the documentation of PrintWriter constructor you can seeYou should try creating a path for the folder it contains before:throw an exception for the file.Pass the File object to the constructor :You should have a clear idea of exceptions in java.\nIn java there are checked exceptions and unchecked exceptions.Checked exceptions are checked (not thrown,just checked) by the compiler at Compile time for the smooth execution of the program at run time.NOTE: And in our program if their is a chance that a checked exception will rise, then we should handle that checked exception either by try catch or by throws key word.Otherwise we will get a compile time Error:CE:Unexpected Exception java.io.FileNotFoundException;must be caught or declared to be thrown.How to resolve:\n1.Put your code in try catch block:2.use throws keyword as shown by other guys above.Advice:Read more about Exceptions.(I personally love this topic)Java doesn't normally accept \"/\" to use in defining a file directory, so try this:If the file doesn't exist do:Need any Java help, just come to me.Well I think firstly keep whole main into try catch(or you can use as  and then also use full path of file in which you are writing asall those directies like users,Me,Desktop,directory should be user made. java wont make directories own its own.\nit should be as}The  can actually create the file for you. For a list of valid encodings, Alternatively, you can just pass the file path to the  class without declaring the encoding."},
{"body": "I would like to know if a  exists for Java. In Perl exists  and there's a port to Ruby called , for JavaScript . Someone know about a  for Java, that can provide random names, phone number, P.O. box number, etc...If you're using Hibernate, try .Also: Try . This is new project in early stage. PS. I'm a contributor.There is a Java port of the Perl Data::Faker - \nHow to use:Output :"},
{"body": "Personally I've never understood the idea of factory classes because it seems a whole lot more useful to just instantiate an Object directly. My question is simple, in what situation is the use of a factory class pattern the best option, for what reason, and what does a good factory class look like?The idea here is separation of concerns: If the code that uses the object also has enough information to instantiate it, you don't need a factory. However, if there is some logic or configuration involved that you don't want to have the API user to think about (or mess with), you can hide all that (and encapsulate it for reuse) in a factory.Here is an example: You want to access one of the services provided by Google App Engine. The same code should work at both the development environment (of which there are two versions, master-slave and high-availabilty) and the completely different local development environment. Google does not want to tell you about the inner workings of their internal infrastructure, and you don't really want to know. So what they do is provide interfaces and factories (and several implementations of those interfaces for the factories to choose from that you don't even need to know about).Here is a real live factory from my code base. It's used to generated a sampler class that knows how to sample data from some dataset (it's originally in C#, so excuse any java faux-pas)and here is an example usage:As you see, it's not much code, and it might even be shorter and faster just to dothan to use the factory. So why do I even bother? Well, there are two basic reasons, that build on each other:Personally, I use the factory pattern when the implementation of an interface is unknown at run time or it can be made dynamic.This means that as a developer, I work against a known interface to the instance of the object, but I'm not concerned with how the implementation works.Take, for example.  You could use a factory pattern to provide you with objects from a database.  You don't care if that database is a flat file, local/single user database, server database or web resource, only that the factory can generate and manage those objects.I'd hate to have to write implementations for each of those cases :PFrom Effective Java book by Joshua Bloch, partially rewritten by me:1) Static factory methods (), unlike constructors, have names.2) It is not required to create a new object each time  is/are invoked3)  can return an object of any subtype of their return type.4)  reduce the verbosity of creating parameterized type instances.To complement Thilo's answer, let us suppose that you have an object which only has a boolean as a constructor: it would be a total waste to build one each time, since it only has two possible values.In this case, you can create static factory methods. Java's  class is an example: .Factory by itself does not show its beauty so easily. Is when you combine it with other patterns when you see the real benefits for example, if you want to use the decorator pattern, instantiating an object directly may add some additional coupling to your code. As the OOP teacher says, coupling is bad :) so if you were to instantiate the decorated object and didn't want to increase coupling then you could use a factory.You may refer to the , but basic idea of most design patterns is to introduce some abstraction to achieve better maintainability and/or reusability. Factory method pattern is no exception, what it does is to abstract away the complexity of creation from the code.For simple case it seems unnecessary to use factory pattern, a simply  is enough. But when you need more flexibility or functionality, this pattern may help.For example, unless a new instance is required, the static factory  is generally a better choice than , for it avoids creating unnecessary objects. Factory method pattern is also known as . As we know, polymorphism is one of the key features of OOP, but constructor cannot be polymorphic, this shortcoming can be overcome by factory method pattern.In essence, instantiating an object directly(typically via ) is barely a concrete , while factory method pattern shields a   by a  (not limited to the  in Java), pushing the logic of object-creating behind some abstraction to ensure more maintainable and reusable code.As a final word, to fully understand the benefit of factory method pattern and other design patterns, one need grasp the essence of OOP, including , polymorphic abstraction and  principle."},
{"body": "Suppose, I am doing a full build on my large project which has 7 modules and on the 6th module, the build failed because a test failed. Is there any way by which I can start the build from the point it failed?You can resume the build from the 6th module using  or :See the  for details.you can resume the build from any module you want by using the  command.\nFor example, if your build failed in myproject-proxy, you can use the following command:look at the maven summary and you will see the executed modules and where maven is stopped.\nthen try this: You could run the build of module 6 separately to see if it still fails, but I'm afraid that you need to build all modules from the beginning when you want to run the \"big\" build.Edit: Of course the subsequent builds will be faster because the code of modules 1-5 are already compiled, unless you run clean as part of your build. "},
{"body": "There are number of performance tips made obsolete by Java compiler and especially . For example, these platform-provided optimizations can drastically (according to sources) reduces the cost of virtual function calls. VM is also capable of method inlining, loop unrolling etc.What are other performance optimization techniques you came around still being applied but are actually made obsolete by optimization mechanisms found in more modern JVMs?The final modifier on methods and method parameters doesn't help with the performance at all.Also, the  gives a good overview of the optimizations used by HotSpot and how to efficiently use them in Java code.People replacing  with multiple calls to StringBuilder or StringBuffer.  It actually already uses StringBuilder behind the scenes.It is necessary to define time/memory trade-offs before starting the performance optimization. This is how I do it for my memory/time critical application (repeating some answers above, to be complete):In 2001 I made apps for a J2ME phone.  It was the size of a brick.  And very nearly the computational power of a brick.Making Java apps run acceptably on it required writing them in as procedural fashion as possible.  Furthermore, the very large performance improvement was to catch the  to exit for-loops over all items in a vector.  Think about that!Even on Android there are 'fast' loops through all items in an array and 'slow' ways of writing the same thing, as mentioned in the Google IO videos on dalvik VM internals.However, in answer to your question, I would say that it is most unusual to have to micro-optimise this kind of thing these days, and I'd further expect that on a JIT VM (even the new Android 2.2 VM, which adds JIT) these optimisations are moot.\nIn 2001 the phone ran KVM interpreter at 33MHz.  Now it runs dalvik - a much faster VM than KVM - at 500MHz to 1500MHz, with a much faster ARM architecture (better processor even allowing for clock speed gains) with L1 e.t.c. and JIT arrives.We are not yet in the realms where I'd be comfortable doing direct pixel manipulation in Java - either on-phone or on the desktop with an i7 - so there are still normal every-day code that Java isn't fast enough for.   that claims an expert has said that Java is 80% of C++ speed for some heavy CPU task; I am sceptical, I write image manipulation code and I see an order of magnitude between Java and native for loops over pixels.  Maybe I'm missing some trick...? :D:64bit JVM use 30%-50% more memory in comparision to 32bit JVM because of bigger ordinary object pointers. You can heavily reduce this factor by using JDK6+.From JDK6u6p to JDK6u22 it is optional and can be enabled by adding JVM argument:From JDK6u23 (JDK7 also) it is enabled by default. More info .I found links above outdated. Here is a new one on Java optimization: "},
{"body": "When dealing with real world monetary values, I am advised to use BigDecimal instead of Double.But I have not got a convincing explanation except, \"It is normally done that way\".Can you please throw light on this question?It's called loss of precision and is very noticeable when working with either very big numbers or very small numbers. The binary representation of decimal numbers with a radix is in many cases an approximation and not an absolute value. To understand why you need to read up on floating number representation in binary. Here is a link: . Here is a quick demonstration: \nin bc (An arbitrary precision calculator language) with precision=10:(1/3+1/12+1/8+1/30) = 0.6083333332\n(1/3+1/12+1/8) = 0.541666666666666\n(1/3+1/12) = 0.416666666666666Java double:\n0.6083333333333333\n0.5416666666666666\n0.41666666666666663Java float:0.60833335\n0.5416667\n0.4166667\nIf you are a bank and are responsible for thousands of transactions every day, even though they are not to and from one and same account (or maybe they are) you have to have reliable numbers. Binary floats are not reliable - not unless you understand how they work and their limitations.While BigDecimal can store more precision than double, this is usually not required.  The real reason it used because it makes it clear how rounding is performed, including a number of different rounding strategies.  You can achieve the same results with double in most cases, but unless you know the techniques required, BigDecimal is the way to go in these case.  A common example, is money.  Even though money is not going to be large enough to need the precision of BigDecimal in 99% of use cases, it is often considered best practice to use BigDecimal because the control of rounding is in the software which avoids the risk that the developer will make a mistake in handling rounding. Even if you are confident you can handle rounding with  I suggest you use helper methods to perform the rounding which you test thoroughly.I think this describes solution to your problem:  and the problem with double From the original blog which appears to be down now.Many traps lay before the apprentice programmer as he walks the path of software development. This article illustrates, through a series of practical examples, the main traps of using Java's simple types double and float. Note, however, that to fully embrace precision in numerical calculations you a text book (or two) on the topic is required. Consequently, we can only scratch the surface of the topic. That being said, the knowledge conveyed here, should give you the fundamental knowledge required to spot or identify bugs in your code. It is knowledge I think any professional software developer should be aware of.This is primarily done for reasons of precision. BigDecimal stores floating point numbers with unlimited precision. You can take a look at this page that explains it well. When BigDecimal is used, it can store a lot more data then Double, which makes it more accurate, and just an all around better choice for the real world.Although it is a lot slower and longer, it's worth it.Bet you wouldn't want to give your boss inaccurate info, huh?Another idea: keep track of the number of cents in a . This is simpler, and avoids the cumbersome syntax and slow performance of .Precision in financial calculations is extra important because people get very irate when their money disappears due to rounding errors, which is why  is a terrible choice for dealing with money."},
{"body": "I am trying to install IDEA on Ubuntu 11.10. First, I installed . Then I tried running the  file as instructed. However it complains:Trying to  these three variables prints an empty line to the screen. How (and to what values) do I set these variables and proceed with the installation? Thanks.It's recommended to use OpenJDK 1.7+ or Oracle JDK to run IntelliJ IDEA on Linux, OpenJDK 1.6 is strictly unsupported because of the known performance and visual issues.Starting from IntelliJ IDEA 16, custom JRE is bundled with Linux distributions.The tricky part is that Oracle JDK is no longer distributed via .deb packages and you can't just install it with apt-get or Ubuntu Software Center.Their site is also confusing and you can easily download JRE instead of the JDK (which will not work as IntelliJ IDEA needs tools.jar that is missing from JRE package). for the JDK downloads (version 1.6.0_29). From this URL download the appropriate  file, for example  if you need 32-bit Java or  for 64-bit version.to install in the  directory.Inside  add the following on the second line:Normally resides under . Now IntelliJ IDEA should start fine under Oracle JDK 1.6.0_29. You can verify it in  | .You can set  variable and add to your , by doing the following.  As root open up  and add the following to the end of the file. When you reboot, try running the following:if you had install java ,tryif you see like thisthen you should edit .bash_profile,addthen execute if you not install java,you should install manual or auto.I have had this problem a few times...then run it from the terminal:OR 2: navigate into the IDEA_HOME/bin and run it from there.You install JDK 8 with:Then, sometimes the problem lies on the default version of JAVA you are running. For this, use  to modify it:See how I did it:And now Intellij IDEA 2016.3 is running fine.Here is a bash script for developers that installs IDEA so that you can run it from the shell via It also:i also face a question... in firs day all works without problems, but then...\ni solve a problem: add to file  line with path to JDK add after 46 lineActually, you can configure the JAVA_HOME in bash. But, IDEA use javac and java from standard bin folders. So, you have to configure like this."},
{"body": "I have a simple marker annotation for methods (similar to the first example in Item 35 in  (2nd ed)):Then, in a given package (say ), which has a few subpackages containing some 20 classes, I'd like to find all methods that are annotated with it. (Because I'd like to do some checks regarding all the annotated methods in a unit test.)What (if any) is the easiest way to do this? Preferably without adding new 3rd party libraries or frameworks.: to clarify, obviously  will be the way to check if a method has the annotation - but this problem includes finding all the methods.If you want to implement it yourself, these methods will find all the classes in a given package:Then you can just filter on those classes with the given annotation:You should probably take a look at the open source . With it you can easily achieve what you want with few lines of code:If you're happy to use Spring, then that does something along these lines using it's context:component-scan functionality, where Spring scans for annotated classes in a given package. Under the covers, it's pretty gruesome, and involves grubbing about on the filesystem and in JAR files looking for classes in the package.Even if you can't use Spring directly, having a look through its source code might give you some ideas.Certainly, the Java reflection APi is no use here, it specifically does not provide a means to obtain all classes in a package."},
{"body": "I have a Java class that takes in the latitude/longitude of a location and returns the GMT offset when daylight savings time is on and off.  I am looking for an easy way to determine in Java if the current date is in daylight savings time so I can apply the correct offset.  Currently I am only performing this calculation for U.S. timezones although eventually I would like to expand this to global timezones as well.This is the answer for the machine on which the question is being asked:A server trying to figure this out for a client will need the client's time zone.  See @Powerlord answer for the reason why.For any particular TimeZone Here is the modern  (see ) version of the  by . Example code:Note how in the last line we had to extract an  object from our  object with a simple call to .You're going to have to do a bit more work using those coordinates and figure out which time zone they're in.  Once you know which TimeZone that is, the isDayLight() method would be useful.For example, you have no way of telling whether -0500 is EST (US/Canada Eastern Standard Time), CDT (US/Canada Central Daylight Time), COT (Colombia Time), AST (Brazil Acre Standard Time), ECT (Ecuador Time), etc...Some of these may or may not support daylight saving time. contains handling methods which will calculate the offsets for you. See To supplement this, you will need to look up the current time zone with your latitude/longitude info.   provides a java client for its web service, as well as a simple web-request framework (i.e. )"},
{"body": "Confused by java compilation processOK i know this: We write java source code, the compiler which is platform independent translates it into bytecode, then the jvm which is platform dependent translates it into machine code.So from start, we write java source code. The compiler javac.exe is a .exe file. What exactly is this .exe file? Isn't the java compiler written in java, then how come there is .exe file which executes it? If the compiler code is written is java, then how come compiler code is executed at the compilation stage, since its the job of the jvm to execute java code. How can a language itself compile its own language code? It all seems like chicken and egg problem to me.Now what exactly does the .class file contain? Is it a abstract syntax tree in text form, is it tabular information, what is it?can anybody tell me clear and detailed way about how my java source code gets converted in machine code.Actually the compiler itself  as a native executable (hence javac.exe). And true, it transforms source file into bytecode. The bytecode is platform independent, because it's targeted at Java Virtual Machine.Not always. As for Sun's JVM there are two jvms: client and server. They both can, but not certainly have to compile to native code.This  file is a wrapped java bytecode. It's for convenience - to avoid complicated batch scripts. It starts a JVM and executes the compiler.That's exactly what wrapping code does.True, confusing at first glance. Though, it's not only Java's idiom. The Ada's compiler is also written in Ada itself. It may look as a \"chicken and egg problem\", but in truth it's only bootstrapping problem.It's not Abstract Syntax Tree. AST is only used by tokenizer and compiler at compiling time to represent code in memory.  file is like an assembly, but for JVM. JVM in turn is an abstract machine which can run specialized machine language - targeted only at virtual machine. In it's simplest,  file has very similar structure to normal assembly. At the beginning there are declared all static variables, then comes some tables of extern function signatures and lastly the machine code.If You are really curious You can dig into classfile using \"javap\" utility. Here is sample (obfuscated) output of invoking :So You should have an idea already what it really is.I think it should be more clear right now, but here's short summary:Edit: Without the  one would have to invoke compiler using something similar to this:As You can see it's calling Sun's private API so it's bound to Sun JDK implementation. It would make build systems dependent on it. If one switched to any other JDK (wiki lists 5 other than Sun's) then above code should be updated to reflect the change (since it's unlikely the compiler would reside in com.sun.tools.javac package). Other compilers could be written in native code.So the standard way is to ship  wrapper with JDK.Where do you get this information from? The  executable could be written in any programming language, it is irrelevant, all that is important is that it is an executable which turns  files into  files.For details on the binary specification of a .class file you might find these chapters in the  useful (although possibly a bit technical):You can also take a look at the  which covers:The Java compiler (at least the one that comes with the Sun/Oracle JDK) is indeed written in Java.  is just a launcher that processes the command line arguments, some of which are passed on to the JVM that runs the compiler, and others to the compiler itself.Many (if not most) compilers are written in the language they compile. Obviously, at some early stage the compiler itself had to be compiled by something else, but after that \"bootstrapping\", any new version of the compiler can be compiled by an older version.The details of the class file format are described in the .Well, javac and the jvm are typically native binaries. They're written in C or whatever. It's certainly possible to write them in Java, just you need a native version first. This is called \"boot strapping\".Fun fact: Most compilers that compile to native code are written in their own language. However, they all had to have a native version written in another language first (usually C). The first C compiler, by comparison, was written in Assembler. I presume that the first assembler was written in machine code. (Or,  ;).class files are bytecode generated by javac. They're not textual, they're binary code similar to machine code (but, with a different instruction set and architechture).The jvm, at run time, has two options: It can either intepret the byte code (pretending to be a CPU itself), or it can JIT (just-in-time) compile it into native machine code. The latter is faster, of course, but more complex.The .class file contains bytecode which is  like very . The compiler could very well be written in Java, but the JVM would have to be compiled to native code to avoid the chicken/egg problem. I believe it is written in C, as are the lower levels of the standard libraries. When the JVM runs, it performs just-in-time compilation to turn that bytecode into native instructions.Windows doesn't know how to invoke Java programs before installing a Java runtime, and Sun chose to have native commands which collect arguments and then invoke the JVM instead of binding the jar-suffix to the Java engine.Write code on a text editor, save it in a format that compiler understands -  file extension,  (java compiler) converts this to  format file (byte code - class file). JVM executes the .class file on the operating system that it sits on.Always remember java is not the base language that operating system recognizes. Java source code is interpreted to the operating system by a translator called . JVM cant understand the code that you write in a editor, it needs compiled code. This is where a compiler comes into picture.Every computer process indulges in memory manipulation. We cant just write code in a text editor and compile it. We need to put it in the computer's memory, i.e save it before compiling.  - We have a separate text format that the compiler recognizes, i.e  . Save the file in .java extension and the compiler will recognize it and compile it when asked.  Compiler is a second translator(not a technical term) involved in the process, it translates user understood language(java) into JVM understood language(Byte code - .class format). The compiler produces .class file that JVM understands. The program is then executed, i.e the .class file is executed by JVM on the operating system. 1) Java is not  it is .2) JVM is developed using . One of the reason why people call Java a slower language than C/C++3) Java byte code (.class) is in , the only language understood by JVM. Any code that produces .class file on compilation or generated Byte code can be run on the JVM.The compiler was originally written in C with bits of C++ and I assume that it still is (why do you think the compiler is written in Java as well?). javac.exe is just the C/C++ code that is the compiler.As a side point you could write the compiler in java, but you're right, you have to avoid the chicken and egg problem.  To do this you'd would typically write one or more bootstrapping tools in something like C to be able to compile the compiler.The .class file contains the bytecodes, the output of the javac compilation process and these are the instructions that tell the JVM what to do.  At runtime these bytecodes have are translated to native CPU instructions (machine code) so they can execute on the specific hardware under the JVM.  To complicate this a little, the JVM also optimises and caches machine code produced from the bytecodes to avoid repeatedly translating them.  This is known as JIT compilation and occurs  as the program is running and bytecodes are being interpreted."},
{"body": "When we must use a _ to separate digits in a number I don't' understand the\nfollowing case in which I can't use it:Some examples?You don't  to use \"_\", you . And examples given in the proposal are credit card numbers, phone numbers, or simply numbers for witch it makes sense to have a separator in the code.For the \"In positions where a string of digits is expected\" it's simply in places where it's supposed to start (or end) with a digit. Here are some examples.As written in :It looks like someone killed the URL in the original post (OP). Here's the whole nasty URL just in case some formatting feature kills it again:The specific quote from that page to which you are speaking is as follows:I too found the third point rather curious. I mean, for the most part, all of the scenarios are covered by the first three points, so what is this mysterious 'string of digits' for which they speak? Which scenario  doesn't actually get addressed by the first three points that forces them to add this mysterious fourth?Initially I thought they were speaking about hexadecimal notation or binary notation, where a number is expected after the b or the x, as with the following examples that don't work:Still, I think that might technically be the same as the first point, which says an underscore can't be at the beginning of the number; but certainly, a 'string of numbers' is expected after a 'b' or an 'x' when using binary or hex, right? So if I was a betting man, I might put some money behind the binary/hexadecimal scenario. But I have another plausible scenario on which I might hedge my bet. Here it goes.Personally, I wish there was a rule in Java that said you can only use the word 'string' when talking about a java.lang.String. Allowing the term 'string' to retain it's pedestrian meaning causes confusion, and this is a perfect example.Now, if the fourth point said \"In positions where a java.lang.String of digits is expected\" I might come to the conclusion that they're talking about actual java.lang.String objects that represent numbers that need to be parsed. So, take this piece of code:Will that compile? Will that run? It will compile fine, but of course, the parseInt method expects a java.lang.String of numbers, and validation or parsing of that numeric java.lang.String will trigger the following error at runtime:Of course, this is a runtime error, and it appears that the Oracle documentation is really speaking about errors that will be flagged at compile time. But this certainly is a scenario where a 'String of numbers' is expected. Now if only the Oracle documentation was in a Wiki format. It might tempt me to go in and add something like the following:By the way, I just wrote a little article on the topic over at TheServerSide. Feel free to take a look. The article is designed to hit on the Oracle Certified Professional, Java 7 Programmer certification objective, but it's a pretty comprehensive and easy to read article to just generally explain the rules around using underscores.Hope that helps.no idea, but here's the grammar, enjoy. (I don't see \"string of digits\" anywhere)My interpretation of this is that underscores cannot be placed  in positions where a string of digits would normally be expected:I believe the \"In positions where a string of digits is expected\" covers things like escape sequences in string literals.  For example, you can't say \"\\u00_11\".\"In positions where a string of digits is expected\" means where a variable of type String which contains digits is expected, then using an underscore will make the underscore part of the number. For example look at the code below:So if you have a method expecting a String of digits as one of the arguments, DO NOT use underscore to separate the digits because it will be treated as any other String."},
{"body": "I know how to change the font of \"Java editor\" in Eclipse in menu  \u2192  \u2192  \u2192 , but I could not find an option for changing the font of \"layout editor\" for files like myLayout.xml or strings.xml.Where is it?Use menu  \u2192  \u2192  \u2192  \u2192  \u2192 . This is a common text font setting that is applied to XML file editors by default.I also found .For my Eclipse\u00a0v4.4 (Luna) installation, the XML editor font size is changed under: Menu  \u2192  \u2192  \u2192  \u2192  \u2192  \u2192 .I had to expand General to get to Appearance... I figured it out in about 3.2 seconds, but just in case anyone wants to save that 3.2 seconds:This is in Eclipse IDE for Android Developers v23.0.2.  I'm pretty sure this changes all font sizes for everything in the editor.. ?  But I'm assuming if you want XML font to be bigger, you want all files to be that font size."},
{"body": "I have an element with the ID  type of . How can I find and access this object if I have the instance  of ?Try"},
{"body": "I have quite a lot spots in my code which do:where  creates a new collector on every use.This leads me to the question if it is allowed and advisable to do something like:for every type I use and then make use of that single Collector like:when a collector is required.As the collectors are stateless and just a collection of functions and characteristics, I should think it should work, but OTOH,  creates a new  on every call.What are the downsides of reusing a Collector?I think this is more of a  question, but lets give some thoughts:What I mean with that: if you are worried of \"wasting\" performance; you would rather look into each and any line of code that uses streams to determine whether that stream is working with \"enough\" objects to justify the usage of streams in the first place. Those streams come with  overhead!Long story short: the java community has yet to find \"standard best practices\" for streams; thus my (personal) two cent at this time: prefer those patterns that \"everybody\" is using - avoid doing your own thing. Especially when it is \"performance related\".Since the  is basically a container for the four functions and characteristics flags, there is no problem reusing it, but also rarely any advantage, as the impact of such a lightweight object on the memory management is negligible, if not removed entirely by the optimizer anyway.The main reason not to reuse s, as seen with the builtin , is, that you can\u2019t do it in a type safe way. When offering a collector for arbitrarily typed s, you\u2019ll need unchecked operations to always hand out the same  instance. If you store a  in a properly typed variable instead, to be used without unchecked operations, you can use it only for one type of s, to stay with that example.In the case of , etc., the JRE developers went a different way, but the constants , ,  already existed before the introduction of Generics, and I\u2019d say they are more versatile than the few cacheable , which are just four special cases out of the other more than thirty builtin collectors, which can\u2019t be cached due to their function parameters. Since function parameters are often implemented via lambda expressions, which generate objects of unspecified identity/equality, a cache mapping them to collector instances would have an unpredictable efficiency, but very likely be far less efficient than the memory manager will deal with the temporary instances.It is a good practice for a library to provide a  for obtaining useful objects. As the library  such a method: , it is again a good practice to  whether to create a new instance each time the object is requested or not, instead of tampering with the library, thus decreasing readability and risking the future problems when the implementation changes.This to be added to the GhostCat's and Holger's answer as a supportive argument :)Just a tiny side-note, what @Holger is saying in his answer about the optimizer being smart and replacing that construct entirely is totally doable and it is called a . When an Object used inside a method is  and its fields are . So that resulting  might not be treated at the JVM level as a Object per-se. That would happen at . The classic issue of using a single static object to stand in for one created on-the-fly is mutability. A quick scan of the Java 8 source highlights the  field as a possible problem.Clearly it would be possible for some code somewhere to do something like:This  globally change the functionality of  use of  which could create very obscure bugs.So IMHO - don't!This would be a case of premature optimization. Object creation is pretty cheap. On a normal laptop I would expect to be able to create between 10M-50M objects per second. With these numbers in mind the whole exercise becomes pointless. "},
{"body": "In  Notepad++ , it has a very nice feature that if I select a word , it will highlight all the same words throughout the text . Added to this , I can set the hot-keys to highlight up to five different  words with different styles (See the effect below) .Is there any ways /plug-ins to get this similar effect in eclipse  ? I know when editing Java   , it will highlight all the same variables ,but it will not work when I highlight the comments and editing other files type (eg  xml , html , js , css and etc).Thanks so much and best regardsI've been working with Eclipse for quite a while and I'm pretty certain that there is no canonical way of doing this.In Eclipse these things are managed on a per-editor basis and the Java editor does not support what your looking for for all I know. At least for the Java editor you can do some minor configuration in what is highlighted and how (), but I guess you already know that.As for plugins, I'm not aware of any plugin that achieves what you're looking for. As a matter of fact I'd be surprised if there really was a plugin which achieves what you're looking for.If something comes up I'd much appreciate you sharing it here, I've been trying to get decent highlighting into Eclipse for years unsuccessfully... :)Here is a plugin for eclipse: It highlights all occurrences as with notepad++ upon hitting Ctrl + Alt + F.If you enable \"Mark Occurrences\" , then all words that are the same as the one you have marked will be highlighted.  Below is what I found works for me but you can also assign a key shortcut to 'Find Text in File':As mentioned by @Kislingk you can modify how the words are highlighted/marked in 'Preferences > General >Editors>Text Editors > Annotations'.Use file search to search selected resource can highlight same word in single file. Another useful eclipse plugin is . It has extensive feature set. This is also available in eclipse marketplace.There are other options needed to enable.(Preferences > General >Editors>Text Editors > Annotations).  Find Occurrences and WriteOccurrences and enable Text as 'Hightlight' Have tried all of the above answer, but all not working. At the end, i found that it's due to i have accidentally remove some of the , after add back, it's work correctlyHere is the closest solution I have found:"},
{"body": "I am trying to run a Java application, but getting this error:  After the colon comes the location of the class that is missing. However, I know that that location does not exist since the class is located elsewhere. How can I update the path of that class? Does it have something to do with the class path?Your classpath is broken (which is a  common problem in the Java world).  Depending on how you start your application, you need to revise the argument to , your Class-Path entry in MANIFEST.MF or your disk layout.A classpath is a list of locations to load classes from. These 'locations' can either be directories, or jar files. For directories, the JVM will follow an expected pattern for loading a class. If I have the directory  in my classpath, and I attempt to load a class , it will look under the classes directory for a directory called , then under that a directory called , and finally it will look for a file called  in that directory.In the second instance, for jar files, it will search the jar file for that class. A jar file is in reality just a zipped collection of directories like the above. If you unzip a jar file, you'll get a bunch of directories and class files following the pattern above. So the JVM traverses a classpath from start to finish looking for the definition of the class when it attempts to load the class definition. For example, in the classpath :C:/myproject/classes;C:/myproject/lib/stuff.jar;C:/myproject/lib/otherstuff.jarThe JVM will attempt to look in the directory  first, then in  and finally in .When you get a ClassNotFoundException, it means the JVM has traversed the entire classpath and not found the class you've attempted to reference. The solution, as so often in the Java world, is to check your classpath.You define a classpath on the command line by saying  and then your classpath. In an IDE such as Eclipse, you'll have a menu option to specify your classpath.This is the  I found so far.Suppose we have a package called  containing the classes:and the files defining this package are stored physically under the directory  (on Windows) or  (on Linux).The file structure will look like this:\nWhen we invoke Java, we specify the name of the application to run: . However we must also tell Java where to look for the files and directories defining our package. So to launch the program, we have to use the following command:\nIf you know the path of the class or the jar containing the class then add it to your classpath while running it. You can use the classpath as mentioned here:on Windowson UNIX/LinuxTo add the location of a class to your classpath via command line simply add  or  and the location of the class while running it. I.E.Or if you're running an IDE such as eclipse you can right click on the \nand add the external JAR containing your class to the build path then it should work fine.Use ';' as the separator. If your environment variables are set correctly, you should see your settings. If your PATH and CLASSPATH is correct, windows should recognize those commands. You do NOT need to restart your computer when installing Java.Add the  of jar file to the CLASSPATH.\nIn linux use: . Other way worked (without editing the CLASSPATH) was unzipping the jar in the current project folder.Ways didn't work for me:1) Using  option with full path of jar file.2) Using with only the name of jar when located in the current folder3) Copying the jar to the current project folder4) Copying the jar to standard location of java jars (/usr/share/java)Go up to the top and remove the import statement if there is one, and re import the class.  But if that isn't the case do a clean then build.  Are you using Netbeans or Eclipse?I ran into this as well and tried all of the other solutions. I did not have the .class file in my HTML folder, I only had the .java file. Once I added the .class file the program worked fine.Depends on your project. I use maven for my project and when i do \"mvn clean install\" and try to run a program it throws the exception. So, i clean the project and run it again and it works for me. I use eclipse IDE.For Class Not Found Exception when running Junit testtry running \"mvn clean test\" once it will compile all the test classes (worked for me)If you are using maven \ntry to maven update all projects and force for snapshots.\nIt will clean as well and rebuilt all classpath..\nIt solved my problem..ClassNotFoundException is very often a result of build errors. If you have an IDE, you can rebuild the project. From the command line, you can recompile the java file.Put all the code in try block then catch exception in a catch block"},
{"body": "If I have an ArrayList, and I added an object to it, and later I modified this object, will this change reflect in the ArrayList? or when I add the object to the ArrayList, Java creates a copy and add it to the ArrayList?What if I change the reference to this object to null? Does that mean that the object in the ArrayList now null too?Yes, since you added a  to the object in the list. The reference you added will still point to the same object, (which you modified).No, it won't copy the object. (It will copy the reference to the object.)No, since the content of the original reference was  when added to the list. (Keep in mind that it is the  that is copied, not the object.)Any change to the object will be reflected in the list.However, when you deal with objects like Strings that are immutable, a new object will be created on \"change operations\". Than actually your old object is still in the list while you got a new one elsewhere.Wanted to add another demonstration where the ArrayList is inside of a Map as the value. The ArrayList is modified after adding to the Map and the Map reflects the changes.The Map has one element with mother's name as the key and children as the value."},
{"body": "I'm currently trying to stream live microphone audio from an Android device to a Java program. I started off with sending the live audio between two android devices to confirm my method was correct. The audio could be heard perfectly with barely any delay on the receiving device. Next I send the same audio stream to a small Java program and I verified that the data was being sent here correctly too. Now what I want to do is encode this data and somehow play it back on the server running the Java program. I would rather play it in a web browser using HTML5 or JavaScript but I am open to alternative methods such as VLC.Here is the code for the Android app which sends the live microphone audioAnd here is the code for the Java program reading in the data..I know that I should encode the audio on the app side before sending this to the Java program but I'm not to sure how to go about encoding while using AudioRecorder. I would prefer not to use NDK as I have no experience with it and do not really have time to learn how to use it....yet :)So I got my problem fixed. The problem was mainly on the receiving side. The receiver takes in the audio stream and pushes it out to the PC's speakers. The resulting voice is still quite laggy and broken but it works none the less. Playing around with the buffer size may improve this.Edit : you use a thread to read the audio in order the avoid lag. Also, it is better to use a sampling size of 16 000 as it is ok for voice. Android Code:Android XML:Server code:I hope this helps save someone a few hours of pain :)}The voice is broken because of the following line in your android code:You're just adding empty bytes. Also, use  instead of "},
{"body": "I was wondering, whether is there any need for me to close the InputStream, after I close the reader?No, you don't have to.Since the decorator approach used for streams in Java can build up new streams or reader by attaching them on others this will be automatically be handled by  implementation.If you look at its source  you see that:So the close operation actually closes the  underlying the stream reader.EDIT: I wanna be sure that  close works also on input stream, stay tuned.Checked it, in which is called when sd's close is called.Technically, closing the  will close the . However, if there was a failure between opening the  and creating the , you should still close the . If you close the  [the resource] there shouldn't be a good reason to close the  [the decorator]. There are also popular bugs where closing a decorator can throw an exception before closing the decorated. So:There are some complications to watch out for. Some decorators may actually contain native resources due to their implementation. Output decorators will generally need to be flushed, but only in the happy case (so in the  not the  block).You don't have to close stream, if you  the reader.No you don't the reader will close the underlying InputStreamAcordding to source sniffing the reader closes its underlying inputstream. According to javadoc it seams that InputStreamReader \"closes the stream\" when reader.close() is invoked.I'm not sure if ANY Reader must close its sources when you do reader.close(). I think that this is important so your code can use a reader no matter what concrete type it is.Anyway it makes sense that it's enforced."},
{"body": "In Java 8, the Collection interface was extended with two methods that return : , which returns a sequential stream, and , which returns a possibly-parallel stream.  Stream itself also has a  method that returns an equivalent parallel stream (either mutating the current stream to be parallel or creating a new stream).The duplication has obvious disadvantages:Why does Collection.parallelStream() exist when calling Collection.stream().parallel() does the same thing?The Javadocs for  and  itself don't answer the question, so it's off to the mailing lists for the rationale.  I went through the lambda-libs-spec-observers archives and found  and another thread that touched on whether  to match (or actually, whether it should be removed).  There was no once-and-for-all conclusion, so perhaps I've missed something from another list or the matter was settled in private discussion.  (Perhaps , one of the principals of this discussion, can fill in anything missing.)The participants made their points well, so this answer is mostly just an organization of the relevant quotes, with a few clarifications in , presented in order of importance (as I interpret it). in the first thread, explaining why  is valuable enough to keep even after other parallel stream factory methods have been removed: stands by this position in the later discussion about ::In response to Kevin Bourrillion's skepticism about whether the effect is significant, :, but hedges his position:Indeed, the later discussion about  .At the time of the discussion, switching a stream from sequential to parallel and back could be interleaved with other stream operations.  , explains why sequential/parallel mode switching may complicate future development of the Java platform:This mode switching was .  In the current version of the library, a stream pipeline is either sequential or parallel; last call to / wins.  Besides side-stepping the statefulness problem, this change also improved the performance of using  to set up a parallel pipeline from a sequential stream factory., in response to  that  allows programmers to understand streams sequentially before going parallel:"},
{"body": "I'm working on rest api with spring boot. I need to log all requests with input params (with methods, eg. GET, POST, etc), request path, query string, corresponding class method of this request, also response of this action, both success and errors.For an example:successful request:Log should be looked something like this:Or request with error:Log should be something like this:I want Request/Response to be a single entity, with custom information related to this entity, both in successful and error cases.What is best practice in spring to achieve this, may be with filters? if yes, can you provide concrete example?(I've played with @ControllerAdvice and @ExceptionHandler, but as I mentioned, I need to handle all success and error requests in single place (and single log)).Don't write any Interceptors, Filters, Components, Aspects, etc., this is a very common problem and has been solved many times over. Spring Boot has a modules called  which provides HTTP request logging out of the box. There's an endpoint mapped to  which will show you last few HTTP requests. You can customize it to log each request, or write to a DB.Also, where will this application run? Will you be using a PaaS? Hosting providers, Heroku for example, provide request logging as part of their service and you don't need to do  coding whatsoever then.You could use  if there wasn't a requirement to log java method that been executed.But with this requirement you have to access information stored in  of . That said, you can override  to accomplish logging of request/response pair.Below is an example of idea that can be further enhanced and adopted to your needs. - contains the information about request handler.You then can register this dispatcher as following:And here's the sample of logs:In case of errors Spring does automatic error handling. Therefore,  is shown as request handler. If you want to preserve original request handler, then you can override this behavior at  before  is called, to cache original handler.If you dont mind trying Spring AOP, this is something I have been exploring for logging purposes and it works pretty well for me. It wont log requests that have not been defined and failed request attempts though.Add these three dependenciesAdd this to your xml config file Create an annotation which can be used as a pointcut Now annotate all your rest API methods which you want to logNow on to the Aspect. component-scan the package which this class is in.If you want to read in detail read through this.\nSpring already provides a filter that does this job. Add following bean to your configDon't forget to change log level of  to . This code works for me in a Spring Boot application - just register it as a filterHere is how I do it in spring data rest\nby using\n  and\n required a bit of modification for it to work for me, but it is by far the most customizable thing I could get.It didn't work for me, probably because I also have a HandlerInterceptorAdapter[??] but I kept getting a bad response from the server in that version. Here's my modification of it.After adding  to the spring boot bassed application you have  endpoint available with latest requests informations. This endpoint is working based on  and default implementation is  that saves last 100 calls. You can change this by implementing this interface by yourself and make it available as a Spring bean. For example to log all requests to log (and still use default implementation as a basic storage for serving info on  endpoint) I'm using this kind of implementation: This  map contains basic informations about request and response in this kind of form:\n. There is NO response content here. Logging POST dataYou can access POST data by overriding , but don't think it is a good idea (e.g. all uploaded file content will go to logs)\nHere is sample code, but  use it:"},
{"body": "Is there some event/receiver or something for handling first execution after installation or directly after installation? Or Do I need it emulate with preferences?There is the  Broadcast Intent, but the application being installed doesn't receive this.So checking if a preference is set is probably the easiest solution.See  - you can put whatever you want in there. I believe this is how  works - the app that can send back your phone's location after it's stolen, that you install from the website  it's been stolen.I don't think there is such a thing, and I don't think this would be a good idea : usually you have to handle not only installations but some updates (say : a new version with features) or the proper initialization of some resources.  For the resources, the best way is to check them directly.For the version, I use the database, it's so easy.The SQLiteOpenHelper's OnUpgrade method is called when the database version changed. I suppose this could be used to do other things than just handling the new schema."},
{"body": "As we all know, many Android apps display a white screen very briefly before their first  comes into focus. This problem is observed in the following cases:Setting  obviously does not work here. Nor can I set the parent theme of the splash screen to  as described , because [unfortunately] my splash screen makes use of an .Meanwhile, apps that do not extend the  class  show the white screen at startup.The thing is, ideally the initializations performed in the  object need to occur  the first  is shown. So my question is, how can I perform these initializations on app startup  using an  object? Possibly using a  or , I suppose?This is an interesting problem to think about. I can't bypass it the usual way (by setting the  theme), as tragically my Splash screen actually has an  due to some unrelated reasons.I have already referred to the following questions:The problem with white background is caused because of android's cold start while the app loads to memory, and it can be avoided with this:layoutimg faceAdd this theme to your splashscreen in the manifestwhich will produce efect like thisfor more details and more solutions you can check this\nFirst of all, to remove the white screen read this - But more importantly, optimize your initial load and defer any heavy work to when you have time to run it. Post your application class here if you want us to take a look at it.Within the lifecycle callback methods, you can declare how your activity behaves when the user leaves and re-enters the activity. Remember that the way Android is designed, there is a lifecycle for each and every app. If you put too much load to the  method (which is the method used to load the layout files and initalise any controls you have in it), then the white screen will become more visible, as the layout file will take longer to load.I suggest using several different methods when starting an activity. Such are the  (being called as the first thing once the app is loaded),  (being called after the layout is displayed and useful if you are making any data processing upon starting the activity).To make it easier for you, below is the official activity lifecycle diagram:please add this line into your theme Have you tried setting the attribute in the theme of your launcher activity, to either a color or a drawable?For example this: when added to the Launcher activity theme will show a black color (rather than the white color) on startup. This is an easy trick to hide long initialisation, while showing your users something,  even if you subclass the Application object.Avoid using other constructs (even Threads) for doing long initialisation tasks, because you may end up not being able to control the lifecycle of such constructs. The Application object is the correct place for doing exactly this type of actions. Both properties worksDid you try to put initialization to ?Inside  class :As you are already aware why this white screen is there, as due to background processes or application initialization or large files, so just check below idea for overcome from this.To prevent this white screen on beginning of the app, one way is splash screen, this is just a way not final and you must have to use.When you will show splash screen from your splash.xml file, then also this issue will be remain same,So you have to create ont style in style.xml file for splash screen and there you have to set window background as your splash image and then apply that theme to your splash activity from manifest file. So now when you will run app, first it will set theme and by this way user will be able to see directly splash image instead of white screen.Just write the item in values/styles.xml:For example, in the AppTheme:I had same issue, you have to update your style.Your manifest file should looks like below.Hope this would help you."},
{"body": "What is the difference between  and  in JDK 1.5? Put simply, the main difference is in format string:Just have a look at javadoc of both methods to find out more details.String.format is just a shortcut to , this is a \"printf-style\" formatter. On the other side,  uses a different formatting convention, as described in the linked documentation.Use the first  and the second ."},
{"body": "If I have an enum object, is it considered a primitive or a reference?It's a reference type.Unlike many languages, in which an  is a set of integral constansts, Java enums are immutable object instances.  You can get the numeric value of an enum instance by calling .You can even add your own members to the enum class, like this:The way enums work is actually not too different from how they were used before their introduction with Java 5:By instantiating the different suits on class loading it is ensured that these will be mutually exclusive and the private constructor ensures that no further instances will be created.These would be comparable either through == or equals.The Java 5 enum works pretty much the same way, but with some necessary features to support serialization etc.I hope this background sheds some further light. essentially shows you how enums are implemented, and as SLaks says, they are references.Enums are reference types, in that they can have methods and can be executed from command line as well , if they have main method.See following \"Planet\" example from Sun/Oracle "},
{"body": "I'm working on a web site project with a Java component and am currently testing for cross-browser compatibility. Most is fine but the Java part won't load on 64-bit browsers. Looks like I need a 64-bit JRE to test. Where does one download the (off-line) 64-bit Java runtime installer for Windows?The official download page is here: Unless I'm blind, nothing 64-bit there for Windows except a link to notes. Said notes are here: Particularly relevant excerpt: The only off-line installer, as far as I can tell, has only installed the 32-bit runtime. Then we're back at square one! Am I missing something or going nuts?? I believe the link below will always give you the latest version of the 64-bit JRE\nThe trick is to visit the original page using the 64-bit version of Internet Explorer. The site will then offer you the appropriate download options.Java7 update 45 64 bit direct download link is: You can also just search on sites like Tucows and CNET, they have it there too."},
{"body": "I need to generate classes from xml that doesn't provide a schema. I understand this is near useless, but the fact is we have xml, it's structured, and we should be able to create a model from the xml. In the past I've done it by hand, but the current xml documents I am working with are quite large and my time would probably be better spent building something that does what I need. But, I am guessing it has already been done, and I just can't find it.Any pointers?There are many tools available (a quick google search should fetch you some) that can generate XSD from XML assuming string type for almost everything. You should be able to use that XSD to run JAXB to get classes.Here's an  that lets you do that.And here is a screen cap:\nFrom your xml file, you can create a XML Schema Definition (XSD) file. Once you have the XSD, you'll be able to generate the code, need it be for java, C#, C++, or all of the above.If you have Visual Studio, you can use xsd.exe to generate the XSD file.References: XSD to Java:\nReference:XSD to C++:\nReferences:XSD to C#: \nReference:If the XML was created by JAXB, it can easily be converted back into objects. There's a  over at oracle which illustrates one way to do this. Spring framework offers similiar features using JAXB which are very conveniant. "},
{"body": "I've stumbled upon a piece of code that has me wondering why it compiles successfully:What is interesting is that if I modify the signature of method  with  it doesn't work anymore.\nIf I move the generic type from the method to the class the code doesn't compile anymore:If you declare a type parameter at a method, you are allowing the caller to pick an actual type for it, as long as that actual type will fulfill the constraints. That type doesn\u2019t have to be an actual concrete type, it might be an abstract type, a type variable or an intersection type, in other, more colloquial words, a hypothetical type. So, , there could be a type extending  and implementing . We can\u2019t manually specify an intersection type for the invocation, but we can use a type variable to demonstrate the logic:Of course,  can\u2019t fulfill the expectation of returning such a type, but that\u2019s the problem of the definition (or implementation) of this method. You should get an \u201cunchecked\u201d warning when casting  to . The only possible correct implementation would be returning  here, which renders the method quite useless.The point, to repeat the initial statement, is that the  of a generic method chooses the actual types for the type parameters. In contrast, when you declare a generic  like withthe type parameter is part of the contract of the class, so whoever creates an instance will pick the actual types for that instance. The instance method  is part of that class and has to obey that contract. You can\u2019t pick the  you want; the actual type for  has been set and in Java, you usually can\u2019t even find out what  is.The key point of generic programming is to write code that works independently of what actual types have been chosen for the type parameters.But note that you can create , independent instance with whatever type you like and invoke the method, e.g.Here, the creator of the new instance picks the actual types for that instance. As said, that actual type doesn\u2019t need to be a concrete type.I'm guessing this is because  is an interface. If we ignore the fact that  is  for a second, you could, in theory, have a class that  (meaning you could assign it to ) but  (meaning it could be returned from ). Once you change the return type from an interface () to a concrete class () the compiler can deduce they aren't assignable from each other, and produces an error.This, of course, breaks down since  is, in fact, , and we could expect the compiler to take this into account. IMHO, it's a bug, although I must admit I'm no compiler-expert and there might be a good reason to ignore the  modifier at this point.I don't know why this compile. On the other hand, I can explain how you can fully leverage the compile-time checks. So,  is a generic method, it has one type parameter. If you specify this parameter, then the compiler will check that for you:The type parameters provide compile-time checking only. This is by design, java uses  for generic types. In order to make the compiler work for you, you have to specify those types in the code.The most common case is to specify the patterns for an object instance. I.e. for lists:Here we can see that  specifies the type for the list items. On the other hand, new  doesn't. It uses the  instead. I.e. the java compiler  the type based on the declaration.When you invoke a static method, then you have to specify the type in another way. Sometimes you can specify it as a parameter:The you can use it like this:Or like this:Say for instance, this is how you can create a type-safe empty list:The type parameter  is passed to the method . The only constraint is that you have to specify the class too. I.e. you cannot do this:If none of these tricks can help you, then you can specify a . I.e. you provide a class as a parameter. A common example is the :"},
{"body": "I'm looking for a way of getting an SHA-1 checksum with a Java byte array as the message.Should I use a third party tool or is there something built in to the JVM that can help?What about:This a snippet of code we use to convert to SHA-1 but takes a  instead of a  see this  for further info    You can do it yourself or you can rely on libraries that have been proven to work like . The  class has several methods to calculate hashes..From CommonCodec DigestUtils Implementation the Hex coversion after the Digest calculation as shown before :should be  : ...another option is to use Spring:read more HTHI Just used this to compute the hash sum inside of a dex file and compare it with the value which is saved in the dex file.i know this code hasnt very good style but its more PoC and only needed for some research which isnt time critical. may someone can use it!How about Using This: public class sha1Calculate {"},
{"body": "I like constructor-based injection as it allows me to make injected fields . I also like annotation driven injection as it simplifies my . I can mark my constructor with  and everything works fine, as long as I don't have two parameters of the same type. For example, I have a class:and an application context with:There should be a way to specify the bean ID on the constructor of the class , but I can't find it in the documentation.  Is it possible, or am I dreaming of a solution that does not exist yet?Following , I modified my class to be:and it works. is by-type (in this case); use  to autowire by-name, following the example :(below that text is the full example)"},
{"body": "I tried the following code with Spring 3.x which failed with  and it should according to the answers of a question which I asked before -   Since I was trying this with Java 6, I found the following code works fine:but I don't understand how it resolves the cyclic dependency.EDIT:\nHere's the error message. The OP mentioned it in a comment on one of the answers: will be officially supported in Spring Framework 4.3. The implementation can be seen in this .The definitive reason that you cannot autowire yourself is that the implementation of Spring's  method explicitly excludes the possibility. This is visible in the following code excerpt from this method:FYI: the name of the bean (i.e., the bean that's trying to autowire itself) is . That bean is in fact an autowire candidate, but the above if-condition returns false (since  in fact equals the ). Thus you simply cannot autowire a bean with itself (at least not as of Spring 3.1 M1).Now as for whether or not this is intended behavior semantically speaking, that's another question. ;)I'll ask Juergen and see what he has to say.Regards,Sam (Core Spring Committer)p.s. I've opened a Spring JIRA issue to consider supporting self-autowiring by type using @Autowired. Feel free to watch or vote for this issue here: This code works too:I don't know why, but it seems that Spring can get the bean from ApplicationContext if is , but not . @Autowired works before initialization and it cannot find the same bean. So, @Resource maybe works after @Autowired and before @PostConstruct.But I don't know, just speculating. Anyway, good question.By the way, the more elegant solution to the self-invocation problem is to use AspectJ Load-Time Weaving for your transactional proxies (or whatever AOP-introduced proxy you're using).For example, with annotation-driven transaction management, you can use the \"aspectj\" mode as follows:Note that the default mode is \"proxy\" (i.e., JDK dynamic proxies).Regards,Sam question suggests alternative hacky approach with  that may be suitable for special cases.It looks like spring creates and configures an object and then places it in the bean look up context. But, in the case of Java, I think it creates the object and ties it to the name and the during configuration when the object is looked up by the name it is found in the context. Given above code I don't see a cyclic dependency.\nYou injecting some instance of Service into UserService.\nThe implementation of the injected Service does not necessarily need to be another UserService so there is no cyclic dependency.I do not see why you would inject a UserService into UserService but I'm hoping this is a theoretic try out or such.Use  annotation:Why not use 'this' instead of injecting the same object into itself?"},
{"body": "Should we have a team coding standard that the names of abstract classes have prefix  ? e.g.Yes, in fact if you look at the javadocs of the standard library at  you'll find that the list of classes in the bottom-left frame begins with abstract classes using the naming convention you have mentioned in your question.Take any one of them, say the first one, and check its definition: . It indeed implements  which is again similar to your convention. It's subclasses are named like: , , etc.Generally any kind of standard is a good thing in a team setting.\nOtherwise team members might name classes in such a way that only they understand and then you could get a mix of people's different coding styles which leads to confusion.For Readability it does sound like a good idea. When reading code you will be able to know right away what the class is. As long as everyone follows the standard it is good.Modern IDEs will pop up descriptive text when you hover over an object.  Prefixing is redundant in this case.I won't say yay or nay in an answer, but whatever you choose, use a good  to ensure it.As with most questions of this type: \"it depends\".  I like consistency and clarity, so if it works for you and your shop, great.  However, if you have legacy Abstract classes, you would then want to go back and refactor them to the same naming convention."},
{"body": "I am trying to deserialize an instance of this class using Jackson 1.9.10:When I try this I get the followingIs there a way to deserialize a class with overloaded constructors using Jackson?ThanksThough its not properly documented, you can only have one creator per type. You can have as many constructors as you want in your type, but only one of them should have a  annotation on it.This still hold true for Jackson databind 2.7.0.The Jackson  or  grammar () let believe indeed that one can  multiple constructors.Looking at the code where the  are identified, it looks like the Jackson  is ignoring  because it only .That means that code like that But this code will work : .The documentation is vague about how object creation works; from what I gather from the code though, it's that it is possible to mix different methods :For example one can have a static factory method annotated with It works but it is not ideal. In the end it could make sense, e.g. if the json is that  then maybe one should look to use a delegate constructor to handle payload variations much more elegantly than with multiple annotated constructors.Also note that Jackson , for example in this code : This time Jackson won't raise an error, but Jackson will only use the  constructor , that means the  is never used."},
{"body": "How do I add a Java library from its GitHub repo (the library uses Maven as a build system) as a dependency to my Maven project? Can I do that without downloading and compiling the library?Now you can import a Java library from a GitHub repo using .\nIn your pom.xml:It works because JitPack will check out the code and build it. So you'll end up downloading the jar.\nIf the project doesn't have a GitHub release then its possible to use a commit id as the version.At the moment there is no way you can do this unless the maintainer of the library provided a way to do this.So on the title page of the library the should be an instruction containing the repository address like:And a dependency name:This means that all artifact of your project including your dependency will be searched in this repo.You could also have a glance at  to check if there was an effort made to deploy artifacts to a remote repo. Typically the keywords are  or  like in this case.FYI, here is a way to provide a repo for your gihub artifact: ."},
{"body": "How is the compiler not complaining when I write the following code?Even though it is an instance of the same class in which  is written, shouldn't it give a compilation error at ? After all, I am trying to access a private variable directly.\nThe code even runs fine.A private member is accessible from any method within the class in which it is declared, regardless of whether that method accesses its own () instance's private member or some other instance's private member.This is stated in :This feature of Java allows you to write methods that accept an instance of the class as an argument (for example - , ) without relying on the class having non private getters for all the private properties that need to be accessed.Private fields are private to the class as a whole, not just to the object.Other classes do not know that MyClass has a field called count; however, A MyClass object knows that another MyClass object has the count field.Accessors are not security!  They are encapsulation, to keep others from having to know about the code.Consider if someone wrote a , but disappeared once he quashed the last bug -- understanding the code causes one to be either deleted from the universe or to go mad.Despite this minor drawback, if properly encapsulated, this should become your prefered sorting algorithm, as all fields and methods except Sort should be private.You don't know how it works, and you don't want to know how it works, but it works and that's enough.  If on the other hand, everything is public, and you have to understand how it does what it does to use it correctly -- that's just to much bother, I'll stick with quicksort.. It will never throw a compilation error.This is much similar to what a simple getter and setter does or a copy constructor does. Remember we can access  members using Your  method accepts an instance of MyClass. Since  is a method inside , it will have access to  properties.Methods defined inside the class will always have access to it's  members, through  and instance variable.But if you define  outside of  then, you won't have access to  members. There you will have to use a method or a setter or a getter.Methods, Variables and Constructors that are declared private can only be accessed within the declared class itself. Check the "},
{"body": "I am developing a Spring Boot application with a Rest interface and a dart fronted. The XMLHttpRequest does execute a OPTIONS request which is handled totally correct. After this, the final GET (\"/products\") request is issued and fails:After some debugging I have found the following:\nThe AbstractHandlerMapping.corsConfiguration is populated for all Subclasses except RepositoryRestHandlerMapping. In the RepositoryRestHandlerMapping no corsConfiguration is present / set at creation time and so it won't get recognized as cors path / resource.\n=> No CORS headers attached\nCould that be the problem? How can I set it?  Configuration classes:I even tried to set the Cors per annotation:Raw request headers:Raw response headers:Versions used:\nSpring Boot 1.3.0.M2\nSpring 4.2.0.RC2What do I miss?Indeed, when using Spring Data REST + Spring Framework 4.2, only  instances created by Spring MVC  and controllers annotated with  will be CORS aware.Spring Data REST still compiles against Spring Framework 4.1, and does not support builtin Spring Framework CORS implementation. Feel free to vote for the  related issue.Right now, I think the best solution is to use a filter based approach. You could obviously use Tomcat, Jetty or , but be aware that Spring Framework 4.2 also provides a  that use the same CORS processing logic that  and  approaches. By passing an  instance to the  constructor parameter, you could easily get something as powerful as Spring native CORS global support.If you are using Spring Boot (which supports  beans), it could be something like:The Spring Data team is currently looking into ways to let the user customize the CORS handling on it (i.e. calling  on the  instance Spring Data REST deploys), but I think it is better to use the  approach until  is resolved.Hendy's addition: In my case, the simple  definition above does not work, I had to use this: (It  have something to do with my usage of Spring Security or , but Sebastien is more expert in this.. I don't really know why)Since , the support of CORS in Spring Data is on now. There are two ways to deal with:"},
{"body": "Can Java properties file reference other properties file?Is this possible?This is what you want, it is a bit old , but may work for your needs.  which provides variable substitution along with a few other features - although substitution may arguably be the most useful.  It is a subclass of java.util.Properties, and will can be used by any other class that may take configuration information as Properties.Standard properties files are just key-value pairs. In the text format,  just separates key from value and does some simple things such as allowing escaped characters. You might be able to define entities in the verbose XML syntax.If you want your own substitution syntax, then you can manipulate a returned value as you would with any other string. Alternatively, you could write your own version of  or do the substitution when generating the file.The java.util.Properties class won't do this for you.  It wouldn't be too difficult to subclass Properties, override the load() method and do the substitution yourself. The Commons Config lib can also do this. However, as pointed out already, have a look at the EProperties library;  It supports a number of neat features (like substitution, nesting, lists) including inclusion, extends Java Properties and is a little more light weight than Commons Config (which also allows you to include properties using the include syntax). Since eproperties is sort of not maintained and commons configuration has a dependency on logging (which ironically means you can't use it to configure logging) I use this code snippet which only requires  to load interpolated properties:::Obviously you can convert the  back to a  object if you need it. I resolve based on previously declared properties and system properties but you could obviously adjust that in the .In this particular case (and in  too), you'd better resolve the duplication by defining different properties:Do the same for the other projects.Below is a code snippet in Java for reading properties that reference other properties. Specifically, these are are reusable queries but can be other stuff as well.Example properties:After running this,  will have the value .* Using apache's ."},
{"body": "I have a generic  and am trying to work out how I can sort the items contained within it. I've tried a few things but I can't get any of them working.Collections by themselves do not have a predefined order, therefore you must convert them to\na .  Then you can use one form of A  does not have an ordering, so wanting to sort it does not make sense. You can sort  instances and arrays, and the methods to do that are  and If your collections object is a list, I would use the sort method, as proposed in the other answers.However, if it is not a list, and you don't really care about what type of Collection object is returned, I think it is faster to create a TreeSet instead of a List:You have two basic options provided by :Depending on what the  is, you can also look at  or .You can't if T is all you get.  You have to have the it injected by the provider via:or pass in the Comparator via the Collections.sort(...) methodHere is an example. (I am using  class from Apache for convenience, although this can be done without using it.)If you have a specific code that you are working on and are having issues, you can post your pseudo code and we can try to help you out!"},
{"body": "I need to cut out an image in the shape of the text in another image. I think it's best shown in images.This is a photo of a cat:and this is the text I wish to cut out:The resulting image would be this:The text image will always be black with a transparent background, and the resulting cut-out should too have a transparent background. Both input images will also be the same size.Create a new BufferedImage and iterate over all the pixels of word cat and if they are black, copy the cat-image pixels to the new image.Here is some code: ()Use . Use  classYou can get outline  from glyph vector by public abstract Shape Assign the outline  as a clip to your  instance.Draw the image on the graphics.Only clipped shape will be filled.No java here, but the needed image operations are easy to understand. In Mathematica:  You can do it in Java with just a few lines of source code, using First, make the black portion of the \"Cat\" image transparent.  See  for help with this.  Then,  that image over the picture of your favorite cat (mine is Sheeba).  The nice thing about this is you can make the transparent text image once, save it, and then apply it to all of Sheeba's family and friends!  "},
{"body": "The following code:causes:  Can someone explain me what is meant by \"further generic type information will be erased at runtime\" and how to fix this?It means that if you have anything that is parameterized, e.g. , the Generics information will be erased at runtime. Instead, this is what the JVM will see .This is called . The JVM has no parameterized type information of the  (in the example) during runtime.A fix? Since the JVM has no information of the Parameterized type on runtime, there's no way you can do an  of . You can \"store\" the parameterized type explicitly and do a comparison there.You could always do this insteadDue to type erasure, the parameterized type of the  won't be known at runtime. The best you can do with  is to check whether  is an  (of anything). To do this in a generics-friendly way, use: This is sufficient: In fact,  checks whether the left operand is  or not and returns  if it is actually .\nSo: no need to catch .You can't fix that. The type information for Generics is not available at runtime and you won't have access to it. You can only check the content of the array.instanceof operator works at runtime. But java does not carry the parametrized type info at runtime. They are erased at compile time. Hence the error. You could always do thisCreate a classIs not the same but ...You can use"},
{"body": "Every single view in my Spring 3 app has a set of attributes they can rely on.  So the first line of every controller is something like:In there I'll addThis all allows each view to display the logged in user's name, easily reference an image location, a list of languages and some overall stats about the site.So the question is, is the controller model object the best place to store all the data or is there a more convenient place which makes it just as easy for views to access this info?And secondly, I'd REALLY love not to have to have the  line above as the first line in every controller.  It's actually not always the first line, sometimes I first check if I need to redirect in that controller, because I don't want to waste resources filling the model for no reason.  Maybe a filter or annotation or some Spring callback mechanism could make sure the  code is called  the controller is finished but right  the view is rendered, skipping this if a redirect was returned?You could write an . (or its convenience subclass )@See: It has the method:This method is invoked after the controller is done and before the view is rendered. So you can use it, to add some properties to the An example:webmvc-config.xmlYou can also use @ModelAttribute on methods e.g.This will add it for all request mappings in a controller. If you put this in a super class then it could be available to all controllers that extend it.You could use a Controller Class annotated with @ControllerAdvice\"@ControllerAdvice was introduced in 3.2 for @ExceptionHandler, @ModelAttribute, and @InitBinder methods shared across all or a subset of controllers.\"for some info about it have a look at this part of the video recorded during SpringOne2GX 2014\nThere is one issue that occurs with redirection when using @ModelAttribute or HandlerInterceptor approach. Another way to handle this situation is to create session-scoped bean, that can be autowired in base application controller, or explicitelly in every controller where access is needed.Details about available scopes and usage can be found .if you need add some global variables that every view can resolve these variables\uff0c\nwhy not define into a properties or map\uff1f\nthen use spring DI\uff0c refer to the view resolver bean.\nit is very useful,such as static veriable, e.g. resUrl"},
{"body": "Is there a way to retrieve the auto generated key from a DB query when using a java query with prepared statements. For example, I know AutoGeneratedKeys can work as follows. However. What if I want to do an insert with a prepared Statement. Is there a way to do this that I don't know about. It seems from the javadoc that PreparedStatements can't return the Auto Generated ID.Yes. See . Section 7.1.9. Change your code to:There's a couple of ways, and it seems different jdbc drivers handles things a bit different, or not at all in some cases(some will only give you autogenerated primary keys, not other columns) but the basic forms areOr use this form:Yes, There is a way. I just found this hiding in the java doc. They way is to pass the AutoGeneratedKeys id as followsI'm one of those that surfed through a few threads looking for solution of this issue ... and finally get it to work. FOR THOSE USING jdbc:oracle:thin: with ojdbc6.jar PLEASE TAKE NOTE:\nYou can use either methods:\n(Method 1)(Method 2)Basically, try not used Method1 if you just want the value of SEQ.Nextval, b'cse it just return the RowID ref that you may cracked your head finding way to make use of it, which also don fit all data type you tried casting it to! This may works fine (return actual val) in MySQL, DB2 but not in Oracle.AND, turn off your SQL Developer, Toad or any client which use the same login session to do INSERT when you're debugging. It MAY not affect you every time (debugging call) ... until you find your apps freeze without exception for some time. Yes ... halt without exception!"},
{"body": "How to make moving money from one account to another atomic? For:I expect that pseudo-code:update accounts safely in multithreading environment, I see danger case as:Easiest solution is to make blocking on shared object, but it will be inefficient for cases like:I expect that independent moves performed in parallel, dependent in sequence. Seems that suggested solution:lead to deadlock as 2 locks acquired sequentially...  If  and  and  I expect consistency:  has  value, not  or  if you get intermediate account value during simultaneous execution. 1000-10000 - so lock on shared object isn't efficient.A simple solution could be to use a lock per account, but to avoid deadlock you have to acquire locks in the same order always. So, you could have a final account ID, and acquire the lock of the account with a less id first:One way to do this is to have a transaction log. Before moving the money, you'll need to write to the transaction log of each account what you intend to do. The log should contain: the amount of money that's taken in/out of the account, and an lock which is shared between the log pair.Initially the lock should be in a blocked state. You created the log pair, one with amount of X and the other with amount of -X, and both shares a lock. Then deliver the log entry to the inbox of the respective accounts, the account from which money is taken out should reserve that amount. Once you've confirmed that they're delivered safely, then release the lock. The moment the lock is released you're at a point if no return. The accounts then should resolve themselves.If either of the party want to fail the transaction at any time before the lock is released, then simply remove the logs and return the reserved amount to the main balance.This approach may be a bit heavy, but it would also work in a distributed scenario where the accounts actually are in different machines, and the inboxes actually would have to be persisted, to ensure money never get lost if any of the machine crashes/goes offline unexpectedly. Its general technique is called two phase locking.I would propose to create a method Account.withdraw(amount) which throws an exception if it doesn't have sufficient funds. This method needs to be synchronized on the account itself.Edit:There also needs to be a Account.deposit(amount) method which is synchronized on the receiving account instance.Basically this will result in a lock of the first account while withdrawing and then another lock on the receiving account while depositing. So two locks but not at the same time. Assumes that withdraw/deposit are synchronized and return boolean success status rather than throw exception.You can create an extra   that exists solely for transferring the money. So if you want to transfer from  to  you actually transfer from  to  and then from  to . For each of these transfers you only lock either  or  depending on which account is participating in the transfer. Since you are using the same type for transfers, you end up with little extra code and therefore low maintenance costs.To reduce the number of extra accounts you could hold them in a pool. If you have a thread pool that is processing transfers, than you can assign each thread it's own extra account. Therefore you don't need to request and release those extra accounts from/to a pool too often.One approach is to use kind of \"striped lock\" with lock/unlock methods operating on several locks. Accounts are mapped to locks using , the more locks you allocate, the more parallelism you get.Here's code sample:Don't use built-in synchronization, use a Lock object. Use tryLock() to get an exclusive lock on both accounts at the same time. If either one fails, then release both locks and wait a random amount of time and try again.As you have mentioned there will be 1000-10000 concurrent transaction you expecting at a time than you can store accounts on which some transaction is going on and handle concurrencyOne Solution is to allow system to create only one object of particulate account id, means that if you want to make a transaction between account \"123\" and \"456\" than your thread will create account object and in that constructor of account class we will check if any other object of account is there with particulate account id, if other object of account is there with same account id means that some transaction is going on with particulate account id so you have to wait to get the account object.So we can do transaction between \"123\" and \"456\" and at same time we can do transaction between \"abc\" and \"xyz\" but if at same time some other thread will try to create object of account \"123\" than system will say please wait for reference you can see below code Please note :As stated previously, you should lock on both accounts, always in the same order. The key part, however, is ensuring both high granularity and singularity across the VM instance. This can be done using :An approach which will remain robust even if threads may get arbitrarily waylaid is to have each account maintain a list of transactions requested or posted against it.  To request a transfer from one account to another, create a transaction object defining the request and add it to the request queue for the source account.  If that account can perform the transaction, it should move it to its list of posted transactions and add it to the request queue for the destination.  Using  it's possible to ensure that from the moment the transaction is placed into the queue for the first account, the state of the system will always thereafter either have the transaction pending, completed, or aborted, and even if some or all threads were to get waylaid, examining the transaction lists would make it possible to determine what money belonged where.By contrast, when using locks, events which unexpectedly delay one thread can arbitrarily impede the execution of many others, and if a thread gets killed off while holding a lock it may be impossible to determine what exactly it had or had not done prior to that.Thanks all for interest to question.I found several solutions in As one link answer was removed here essential piece of code that help anyone when cert.org fall. Pieces are long so I didn't include any pros/cons.:::"},
{"body": "Here is an image of my default JDK (which is 1.6) and the JDK I want to set as default (which is 1.7)If I remember correctly, you'll need to set the  property in your netbeans config file. Should be in your  file."},
{"body": "I'm wondering if there is any ideomatic way to chain multiple InputStreams into one continual InputStream in Java (or Scala).What I need it for is to parse flat files that I load over the network from an FTP-Server. What I want to do is to take file[1..N], open up streams and then combine them into one stream. So when file1 comes to an end, I want to start reading from file2 and so on, until I reach the end of fileN. I need to read these files in a specific order, data comes from a legacy system that produces files in barches so data in one depends on data in another file, but I would like to handle them as one continual stream to simplify my domain logic interface. I searched around and found PipedInputStream, but I'm not positive that is what I need. An example would be helpful.It's right there in JDK! Quoting :You want to concatenate arbitrary number of s while  accepts only two. But since  is also an  you can apply it recursively (nest them):...you get the idea.This is done using SequencedInputStream, which is straightforward in Java, as Tomasz Nurkiewicz's answer shows.  I had to do this repeatedly in a project recently, so I added some Scala-y goodness via the \"pimp my library\" pattern.With that, I can do stream sequencing as followsor evenAnother solution: first create a list of input stream and then create the sequence of input streams:Here is a more elegant solution using Vector, this is for Android specifically but use vector for any Java"},
{"body": "Short of parsing the output of , does anyone have a 100% pure java way of doing this?This is pretty easy:Some of this will only work in JDK 1.6 and above (one of the methods was added in that release.)Prior to 1.6, it's a bit more difficult - isUp() isn't supported until then.FWIW: The  note that this is the correct approach for getting all of the IP addresses for a node:This code only works in Java 1.6 because of the added InterfaceAddress code.The \"toMACAddrString\" method looks like this:and the \"toIPAddrString\" method is here:I have that first set of code in the try/catch above in a method called dump() in class called IPConfig.  Then I just put a main method in IPConfig to call new IPConfig().dump() so that when I'm trying to figure out some wacky network problem, I can see Java thinks is going on.  I figured out that my Fedora box reports different information than Windows for the LocalHost information and it was causing my Java programs some issues.I realize its similiar to the other answers but it prints out nearly everything interesting that you can get from the interface and ipaddress apis.As highlighted by Sam Skuce comment:"},
{"body": "Am torn between wicket and vaadin. i am starting a micro-isv and need to make a choice of web framework. I have narrowed down my choices to wicket and vaadin. I have used both frameworks and i love them both. however i need to make a choice. If i choose vaadin:If i go the wicket way:\nI will have to style my applications and i can hardly give them a desktop look and feel. Any advice. anyone with experience on either framework kindly tell me the cons and pros and how you made your decision. I think I've invested some time for both frameworks. I really like both because they bring the Swing-alike coding to web development. And I don't know easier ones for me (although there is click but I don't like the velocity templating thing)And yes, there are differences.true, but every serious company will style its app differently (unless you are prototyping)Then Vaadin would be 'better'.What are the advantages of that? (BTW: you could code declarative in groovy ;-)) But ok. I know what you mean: if you can effort a separate designers than wicket is 'better'.Why not? Or what do you mean here? Wicket supports ajax and there are components which supports nice 'desktop-alike' things (ajaxlink, lazycomponent, autocompletion, progressbar, see wicket stuff + extensions). ok, for any more complex component you'll have to code in javascript BUT BTW did you know that you could even Some minor experiences:Vaadin is surely faster while coding (no css, html stuff). But if you go production keep in mind that the ease of programming can come to the cost of performance on the client side: e.g. if you use the 'wrong' layouts such as Horizontal/VerticalLayout, ... the massive use of javascript could slow down old browser.But Vaadin is not slow! Use appropriate layouts such as CssLayout or FastLayout and also old browser can serve it. (Although if you would use CssLayout your coding-style is really wicket-alike.)One issue with Vaadin is that it is a bit harder to profile, because you don't see easily where the client needs all the CPU and the nested divs gets cryptic id-names.One great thing about Wicket is its (Guice can be integrated in Vaadin and Wicket)Testing the UI should be easy with Vaadin (although I didn't found unit testing stuff) and is very easy .Last but not least creating lists/tables is VERY easy in Vaadin compared to wicket.I've worked extensively with Wicket but I've not had any experience with Vaadin so this might be (a little) biased.I'd recommend Wicket for obvious reasons, but what's probably of interest to you is Wickets openness. As Gweebz rightly pointed out, Wicket uses basic HTML markup as its foundation, so any structural or cosmetic changes are often trivial to implement. Personally one of the things I really enjoy about out wicket work is the flow between front end presentation and the data backend, we've implemented Spring & JPA/Hibernate which means that any changes in the front end can be translated back into the data base with a single line of code thanks to Wickets model based architecture.Again I can't say much for Vaadin having never worked with it, but if you're looking for architectures to start off with, I'd also recommend you have a look at GWT.(continued from the comment in the first Wicket-related answer)The major difference between Vaadin and Wicket is with how UI composition and client side code is written. With Vaadin you usually compose your UI without any templates or HTML at all and you get a sleek, fully Ajax'ed UI out of the box. However, if you prefer the templating approach just use CustomLayout which does exactly that.Client side coding is rarely needed, but when it is you do it with the Java-based GWT which is IMO a lot more nicer than writing Javascript by hand. Besides, with GWT you automatically get cross-browser compliant solution instead of having to deal with those issues yourself.When comparing frameworks you also should take a look at community activity and documentation. With Vaadin both of those are excellent. Also note the Vaadin Directory which currently contains 100+ very useful UI components and other addons.I have a limited amount of experience with each but I prefer Vaadin. It allowed a richer experience with the web application I was developing. The main benefit that sold us though was how easy it was to write unit tests around our UI classes, ensuring the components functioned correctly when interacted with in the expected ways. This is also possible with Wicket however it was more difficult in my experience.I will also mention that either framework will require some styling. Wicket starts off as plain old HTML and Vaadin starts off with a MacOSX-like theme by default but almost any web-app you write will require at least SOME customization. With this in mind, customizing the CSS of a Wicket app is SIGNIFICANTLY easier than Vaadin for the simple reason that you control the markup. Vaadin hides the markup from you and generates elements with weird IDs and structures so it is harder to customize the look. Just remember this when making your decision.Also do notice that even though Vaadin base framework is free, for some additional functionality you might need to  extensions.Ex - If you need to integrate a good charting solution such as Highcharts, you'd have to pay and buy the vaadin charts extension (even though highcharts is available free for FOSS apps, the vaadin charts plugin built on that is not given free for FOSS apps).I am currently working with Wicket and I have worked in the pass with Vaadin. I wil be short in my observations:Appart from that, we are talking about two different types of frameworks, two different approach, which have pros and cons that I advice you to search and compare and see what really fits your needs.Edit: Oh, and about the look and feel, for instance you always have "},
{"body": "Based on my understanding of the Java language, static variables can be initialized in .However, when I try to implement this in practice ( variables that are  too), I get the error shown in the screenshot below.Screenshot can be directly accessed at  (in case the image below is unreadably small).Yes of course:  variables can be initialized in a static block .... you have implicit GOTOs in that example ( is essentially a ).If an exception is thrown your  variables will not be initialized.Note that the use of static constructs goes against Object-Oriented dogma. It may complicate your testing and make debugging more difficult.You can do this but you need to exit the static block by throwing an exception - you can rethrow the exception that was caught or a new one. Generally this exception must be a . You really should not catch a generic  but more specific exception(s) that might be thrown from within your  block. Finally, if a static initializer throws an exception then it will render the class unusable during that specific run because the JVM will only attempt to initialize your class once. Subsequent attempts to use this class will result in another exception, such as .So, to work, your initializer should read something like this:Assuming that  is a custom , but you could use an existing one.Assuming no where upstream is in a position to catch either an  or a general  then the program should not ever try to use .  If however those are caught and the program doesn't end, then you need to code to watch for and handle  being null (or be happy with NullPointerExceptions coming out all over).I'm not sure there is a good way to handle this.Can you put the declaration in the finally block?"},
{"body": "I've been searching all over for a consistent and clear explanation of what 'self time' actually refers to in the VisualVM context and how does it differ to 'self time (cpu)'. Also does 'self time [%]' refer to self time or self time cpu. There doesn't appear to be much documentation on this or at least I haven't found it. So any thoughts/input will be appreciated.'self time' is a 'wall-clock' time spent in method itself (without time in methods invoked from that method). 'self time (cpu)' is a time processor time, so it does not include time spent waiting, sleeping, etc. Both 'self-time' and 'self (cpu) time' in sampler are approximation of actual data. 'self time[%]' refer to 'self time'. "},
{"body": "I'm using Mockito to write a unit test in Java, and I'd like to verify that a certain method is the  called on an object.I'm doing something like this in the code under test:In my mock, I don't care about the order in which I edit everything on the row, but it's very important that I  try to do anything more to it after I've saved it. Is there a good way to do this? Note that I'm not looking for verifyNoMoreInteractions: it doesn't confirm that saveToDatabase is the last thing called, and it also fails if I call anything on the row that I don't explicitly verify. I'd like to be able to say something like:If it helps, I'm switching to Mockito from a JMock test that did this:I think it requires more custom work.and then Previous Answer:You are right. verifyNoMoreInteractions is what you need.Not 100% on topic but I was just looking to find the opposite of verify, and this was the only relevant result, it ends up I was after Mockito.verifyZeroInteractions(mock);Just incase anyone else ends up here looking for this...This question led me to make some enhancements to the  API in  (available in the upcoming release 0.983).The solution I came up with allows you to write (in a test method):... if you only want to verify that a certain method is called after everything else. To verify it happens  all other invocations, simply move the call to the top. This actually applies to any sequence of consecutive invocations.If in addition to the above verification, you also want to verify that some other methods are called in any order, a second  block can be added to the test (before or after the other block, it doesn't matter):Although a bit long because of the use of anonymous inner classes, this syntax is both simple and flexible; notice how it adds structure to the test and avoids the repetition of method calls (like ). There is more to it than I described here (Hamcrest matchers, invocation counts, etc.), and it's not limited to the verification of instance methods (static methods and constructors can be mocked and verified in the same way)."},
{"body": "Which of the following collection types do you use in your JPA domain model and why:I was wondering whether there are some ground rules for this. I know the difference between a  and a . A  allows duplicates and has an order and a  cannot contain duplicate elements and does not define order. I'm asking this question in the context of JPA. If you strictly follow the definition, then you should always end up using the  type, since your collection is stored in relational database, where you can't have duplicates and where you have define an order by yourself, i.e. the order in you Java  is not necessarily preserved in the DB.For example, most of the time I'm using the  type, not because it has an order or allows duplicates (which I can't have anyway), because some of the components in my component library require a list.Like your own question suggests, . JPA is just a framework which you can (and should) use in a way which best fits your problem. Choosing a suboptimal solution because of framework (or its limits) is usually a warning bell.When I need a set and never care about order, I use a . When for some reason order is important (ordered list, ordering by date, etc.), then a .You seem to be well aware of the difference between , , and . The only reason to use one vs. the other depends only on your needs. You can  (which may be subtle or implicit).  This is follows the exact same rules as using different collection types anywhere else throughout your code. You could use  or  for all your references, yet in most cases you use more concrete types.For example, when I see a , I know it comes sorted in some way, and that duplicates are either acceptable or irrelevant for this case. When I see a , I usually expect it to have no duplicates and no specific order (unless it's a ). When I see a , I don't expect anything more from it than to contain some entities.Regarding list ordering... Yes, it can be preserved. And even if it's not and you just use , it still can be useful. Think about the example of event log sorted by timestamp by default. Artificially reordering the list makes little sense, but still it can be useful that it comes sorted by default.The question of using a Set or a List is much more difficult I think. At least when you use  as JPA implementation. If you use a List in hibernate, it automatically switch to the  paradigm, where duplicates CAN exist. And that decision has significant influence on the queries hibernate executes. Here a little example:There are two entities,  and , a typical many-to-many relation. for mapping those entities to each other, a JoinTable (lets call it \"employeeCompany\") exist.You choose the  on both entities (Company/Employee)So if you now decide to  Employee  from , hibernate executes the following queries:And now the question: why the hell does hibernate not only execute that query?The answer is simple (and thx a lot to Nirav Assar for his blogpost): . In a world of bags, delete all & re-insert all remaining is the only proper way! Read that for more clarification. Now the big conclusion: And why that? Because hibernate is no longer in a world of bags (as you know, Sets allows no duplicates) and executing only one query is now possible.So the decision between List and Sets is not that simple, at least when it comes to queries & performance!I generally use a List.  I find the List API far more useful and compatible with other libraries than Set.  List is easier to iterate and generally more efficient for most operations and memory.The fact that a relationship cannot have duplicates and is not normally ordered should not require usage of a Set, you can use whatever Collection type is most useful to your application.It depends on your model though, if it is something you are going to do a lot of contains checks on, then a Set would be more efficient.You can order a relationship in JPA, either using an @OrderBy or an @OrderColumn.See,\nDuplicates are not generally supported in JPA, but some mappings such as ElementCollections may support duplicates.I use:I think using Collection as the generic default when generating entities with Netbeans is a good starting point, then when you figure out what your model actually is and need more functionality you can easily change it and stay backwards compatible."},
{"body": "I am studying the source of the OpenJDK.My attention was attracted by the methods  and :Why do the methods  and  have different implementations?The implementation of  does not use subtraction, as this could cause an overflow in case you're comparing an integer that is close to  with another that is close to .This overflow cannot happen in case of , as there the byte values are implicitely converted to integers before  is calculated.(see also: )The Byte method can be implemented this way, becasue the result of the subtraction is representable in . This is not so in the other case. For example:and this is negative, hence the comparision would wrongly indicate that 0 is smaller than -2^31"},
{"body": "Usually, during software development, there are all sorts of utility functions I need. Like zipped file, extract zip file, launching Web Browser, get scaled image...What I did is, I place all this utility functions as static function within a single class named \"Utils\"Is it a good practice? Will things grow unmanageable when the number of functions grow larger and larger?Its absolutely a best practice! you don't want to mix all those utility functions with the rest of your application business logic. However, as your utils files and/or classes grow it is recommended to group them according to the function they provide.For example, in a web application you could end up with a package structure like this.Yes, utility classes are a good idea but, as with all object-oriented programming, you should be aiming for maximum cohesion, minimal coupling.Maximum cohesion means that everything in a single class should be heavily related  Minimal coupling means there should be no unnecessary dependencies  classes.In other words, lumping together compression with image manipulation or the launching of external processes in a single class is a bad idea. By all means have a compression utility class and an image manipulation utility class but  put them together.Doing so is akin to using the singleton pattern as a god object, a ghetto where you just dump all your rubbish that should be better organised. I would say it's okay to use an uber-utility class during development but make sure your code is better organised before shipping. Maintenance will be a lot easier.No, not in the long term although it's useful when done temporarily.Yes, no question about it.No, I don't think utilities classes are a good practice. Psycologically, the word 'Utilities' is just too broad and even if you split it into multiple classes *Util will just become a dumping ground for things that are 'too difficult' to fit into a proper class design.For an example take a pseudo-ficticious StringUtils class. You could have hundreds of methods for encoding/decoding for different schemes, case transformations, handling whitespace, etc. A better approach, I think, is to use the strategy pattern to handle these transformations, which potentially would even allow for the possibilty of client code introducing new transforms without needing to edit/recompile the original code. You get a more powerful, more flexible and more maintainable system.If it's at least , then it makes sense in a  class. That's easy! Cohesion and coupling are meant to make your life , this is a clear situation in which they wouldn't, so I would suggest to just keep it up your way.In  most cases, I use this way.Don't kill your productivity by strictly following those rules, you can see many great frameworks out there break them.Actually, the concept of  and  classes comes from the inability to write free functions in environments where every function need be owned by a class (either because of language or project restrictions). The  class with nothing but static functions ends up acting the role of a package with free functions.   Because it is a recurring phenomenon in many software projects, I'd consider it somewhat of an idiom to OOP designs, and therefore a Good Practice because people relate to it. As other replies point out, a beneficial enhancement would be to factor out your  classes to some separate project to facilitate reuse and maintenance.I agree with Mike's comment. I use C#, but similar implementation. I have a util project that I maintain secretly and then just drop the DLL in the new project. That way as bugs/changes occur I can update projects simply by replacing DLL. I do keep a separate class for different areas of the application as Mike suggested in his comment.A util class (or package of classes) is very useful. \nI generally tend to separate my utils by functionality into classes, so I may have FileUtils, DatabaseUtils, etc.I would highly suggest, however, maintaining your utils in a separate jar or project (very easy with Eclipse). If you end up having multiple projects that use the same utilities, it is a good idea to avoid code replication. Having a project or jar to include is priceless. My practice is to have both  clases and  classes. The former contains reusable static functions (for the case of Java and PHP) that are application-unrelated, where the latter are reusable application/domain logics - non static methods and usually with dependencies to other services/beans/managers.These are a few rules that I apply before I create a method or a  class:Utility classes usually tend to produce procedure style code. The go against pure OO conventions. However, they simplify your life so use them. But have each one do it's own thing otherwise you will end up with a God class that will become a catch all for methods that don't quite seem to fit the object they should reside on. Breaking up the utilities is a good approach. In general you want to avoid turning your classes into blobs."},
{"body": "I'm trying to simply add TimeZone information back into a LocalDate before performing some more calculations. The LocalDate came from using the ObjectLab LocalDateCalculator to add days to an existing DateTime but the method needs to return a modified ReadableInstant to form an Interval which I can then inspect.The code I'm trying amounts to a conversion of Joda LocalDate to Joda DateTime:The error I get is from Joda's conversion system:I'm looking for a fix to this problem, or a workaround that results in an accurate Interval with full timezone information.There are various methods on  for this, including:You have to be explicit about what you want the time component to be in the resulting  object, which is why 's general-conversion constructor can't do it."},
{"body": "I have some server code that is generating thumbnails when an image is uploaded.  The issue is that when the image was taken and the camera/device was rotated, the thumbnails are rotated, even though the full size images themselves are displayed in the correct orientation in any image viewing software.  This is only happening with jpgs.Using Preview on OSX, I can see that jpgs have orientation metadata embedded within.  When I use ImageTools (Grails Plugin) to generate a thumbnail, the EXIF metadata is not in the thumbnail, which is why the thumbnails appear rotated. Via offline conversations, I have learned that while it is relatively easy to read EXIF metadata, there is no easy way to write it, which is why the data is lost when generating a jpg thumbnail.So it seems I have two options: Does anyone know of any other options?If you want to rotate your images, I would suggest to use the metadata extractor library . You can get the image information with the following code:Then given the orientation you retrieve, you can rotate and/or flip the image to the right orientation. The Affine transform for the EXIF orientation is given by the following method:The rotation of the image would be done by the following method:In a server environment, don't forget to run with The  library honors EXIF orientation flags. To read an image at full size with correct orientation:Exif seems to be hard to write because of proprietary stuff in it.\nHowever, you can consider another optionRead original but only write orientation tag to thumbnails.Apache Sanselan seems to have nice collection of tools to do it.Look at ExifRewriter class, for example.This can be done surprisingly easily by using the  :That's it!I have tried Apache Commons Imaging, but that was a mess. JavaXT is way more elegant.If you just want it to look right. You can just add a \"rotate\" -PI/2 (-90 degrees), PI/2 (90 degrees), or PI (+180 degrees) as necessary depending on the 'orientation' you've already extracted. The browser or any other program will correctly display the image as the orientation will have been applied and the metadata stripped from the thumbnail output."},
{"body": "I want to detect when a  contained in a  gets clicked, so that I can launch an intent to manage that selection.I would have done like this in my layout  file:And the following in my  code:But the method  is deprecated.Here you can check the  layout structure that my activity has, and a snapshot of the application:After clicking on the About (or Access Label Taxonomy) , I'd like to open an  of some kind (could also be a video or anything else...the names are misleading). If you are using  on API Level 11+ devices, you would call  on it. Otherwise, call  on your , as you have no choice.It will work.API Level 11+ introduced  as another way of constructing the contents of a . You are welcome to use them, but if you are still supporting older devices, you cannot use  for those devices.That being said:You do not need Java code for this. Use:(as seen in the )This will create an entry in the preference UI that, when clicked, will start an activity with the specified .If you use fragments, you can use the method \"findPreference()\" on the basis of a preferences fragment.maybe  link are  not clear. But using that feature is very simple. for example, you can use that as a twitter  page like thisit doesnt need any java code. Thanks to CommonsWare!"},
{"body": "What does the following statements mean?I have seen this message generated by Eclipse when the programmer asks Eclipse to add a Javadoc comment to some code in a location where [EDIT: Eclipse thinks] the Javadoc tool will not actually  it.A common example is the implementation of a method in an interface implemented by the class (which in Java 6 needs the @Override annotation).  Javadoc will use the javadoc placed on the method in the , not the one provided in the implementation.The rest of the comment was most likely written by a person that did not know this.Javadoc looks for comments that start with /*.\nBy tradition, method comments that are not intended to be part of the java docs start with \"/* (non-Javadoc)\" (at least when your dev environment is Eclipse).As an aside, avoid using multi-line comments  methods. For example, avoid this:The following is preferred:The reason is that you open the possibility to comment out the entire method:Now you can still see the old method's behaviour while implementing the new method. This is also useful when debugging (to simplify the code).It's just a normal comment. The note means, if you create a manual, base of javadoc, this text won't be added."}